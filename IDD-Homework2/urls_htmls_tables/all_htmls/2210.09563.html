<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2210.09563] FedForgery: Generalized Face Forgery Detection with Residual Federated Learning</title><meta property="og:description" content="With the continuous development of deep learning in the field of image generation models, a large number of vivid forged faces have been generated and spread on the Internet.
These high-authenticity artifacts could gro‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedForgery: Generalized Face Forgery Detection with Residual Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedForgery: Generalized Face Forgery Detection with Residual Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2210.09563">

<!--Generated on Thu Mar 14 03:48:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Facial forgery detection,  residual feature learning,  federated learning,  privacy preserving.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FedForgery: Generalized Face Forgery Detection with Residual Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Decheng¬†Liu,¬†Zhan¬†Dang,¬†Chunlei¬†Peng,¬†¬†,¬†Yu¬†Zheng,¬†Shuang¬†Li,¬†Nannan¬†Wang,¬†¬†and Xinbo Gao, 


</span><span class="ltx_author_notes">D. Liu, Z. Dang, and C. Peng are with the State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi‚Äôan 710071, Shaanxi, P. R. China and with Shanghai Key Laboratory of Computer Software Evaluating and Testing, Shanghai 201112, P. R. China (e-mail: dchliu@xidian.edu.cn; zd.xidian@gmail.com; clpeng@xidian.edu.cn).
<br class="ltx_break">Y. Zheng is with the School of Cyber Engineering, Xidian University, Xi‚Äôan 710071, Shaanxi, P. R. China. (e-mail: yzheng@xidian.edu.cn).
<br class="ltx_break">S. Li is with Shanghai Key Laboratory of Computer Software Evaluating and Testing, Shanghai 201112, P. R. China. (e-mail: ls@sscenter.sh.cn).
<br class="ltx_break">N. Wang is with the State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi‚Äôan 710071, Shaanxi, P. R. China (e-mail: nnwang@xidian.edu.cn).
<br class="ltx_break">X. Gao is with the Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, P. R. China.(e-mail: gaoxb@cqupt.edu.cn).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">With the continuous development of deep learning in the field of image generation models, a large number of vivid forged faces have been generated and spread on the Internet.
These high-authenticity artifacts could grow into a threat to society security.
Existing face forgery detection methods directly utilize the obtained public shared or centralized data for training but ignore the personal privacy and security issues when personal data couldn‚Äôt be centralizedly shared in real-world scenarios.
Additionally, different distributions caused by diverse artifact types would further bring adverse influences on the forgery detection task.
To solve the mentioned problems, the paper proposes a novel generalized residual <span id="id1.id1.1" class="ltx_text ltx_font_bold">Fed</span>erated learning for face <span id="id1.id1.2" class="ltx_text ltx_font_bold">Forgery</span> detection (<span id="id1.id1.3" class="ltx_text ltx_font_bold">FedForgery</span>).
The designed variational autoencoder aims to learn robust discriminative residual feature maps to detect forgery faces (with diverse or even unknown artifact types).
Furthermore, the general federated learning strategy is introduced to construct distributed detection model trained collaboratively with multiple local decentralized devices, which could further boost the representation generalization.
Experiments conducted on publicly available face forgery detection datasets prove the superior performance of the proposed FedForgery.
The designed novel generalized face forgery detection protocols and source code would be publicly available at <em id="id1.id1.4" class="ltx_emph ltx_font_italic">https://github.com/GANG370/FedForgery.</em></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Facial forgery detection, residual feature learning, federated learning, privacy preserving.

</div>
<section id="S1" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the large development of deep generative models, face forgery technology has been spread widely and rapidly. Consequently, the artifact forgery clue has become more and more difficult to identify, even undistinguishable to human eyes. Meanwhile, the forgery technology may be abused by criminals, by changing the faces of public stars and politicians‚Äô videos, thereby spreading some negative public information; attacking the face identification system in the transportation hub, impersonating target identities for pursuit-evasion, etc.
There is no doubt that these dangerous behaviors are very likely to bring about unpredictable effects on social security.
Although a lot of researchers have been focused on face forgery detection tasks, these artifact videos contain large amounts of redundant data, complex backgrounds, and diverse artifact types, which would inevitably bring negative effects on forgery detection tasks. Thus, face forgery detection is still a challenging and important problem in real-world scenarios.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Face forgery detection can be easily defined as a binary classification problem.
Existing forgery detection methods can be roughly divided into two categories: forgery image detection methods and forgery video detection methods.
The forgery image detection methods mainly focus on the difference between the real and the fake images in the low-level information, such as utilizing the image frequency domain information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, the image mixed boundary information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and the extra head pose features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, etc. Different from forgery image detection, forgery video detection methods mainly perform authenticity detection based on the visually unnatural image cross-frame transition and temporal inconsistency of fake videos.
For example, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> utilized a multi-instance learning framework to capture the temporal inconsistency of faces for deep fakes detection. Sabir et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> proposed the convolution recursive model to extract the temporal information of the video stream to detect the authenticity of the video.
It is noted that existing detection methods usually required centralized training data for training model parameters, which makes it easy to leak personal privacy.
How to effectively train models with distributed training data on different devices and protect personal privacy draws more and more attention in recent years.
In addition, different forgery distributions caused by diverse artifact types would further bring adverse influences.
<em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">To mimic the real-world scenarios, we newly design two novel face forgery detection tasks: Hybrid-dataset forgery detection and Generalized-dataset forgery detection task as shown in Figure 1.
</em></p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2210.09563/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="529" height="223" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S1.F1.2.1" class="ltx_text ltx_font_bold">Problem setup.</span> The left subfigure shows the traditional forgery detection task. The same artifact type forgery dataset is selected in both the training and testing stages.
The middle subfigure shows the designed Hybrid-dataset forgery detection task, where multiple artifact types are mixed as the training data and the evaluation model aims to distinguish the authenticity of input faces.
The right subfigure shows the designed Generalized-dataset forgery detection task. Different from the middle task, the goal of this task is to distinguish the real from the fake even for unknown artifact types.
</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Recently, federated learning has been developed rapidly and widely deployed in the real world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
In the federated learning architecture, each local client could only use local private data for training the local model firstly, and then upload the model parameters to the global server for training the global model.
After aggregating the model parameters several times, the server model parameters will be sent to each data center for updating. The aggregation update process will be iterative until the training loss converges.
The federated learning strategy inspires us to design a suitable training method to protect local data privacy, and further learn robust forgery discriminative features with strong generalization ability.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This paper proposes a novel generalized residual Federated learning for face Forgery detection (FedForgery), which not only could train a global model collaboratively for security restrictions but also would improve the discriminative forgery representation generalization ability.
Firstly, considering diverse artifact distribution in the generalized forgery detection tasks, we design the variational autoencoder model to learn robust residual feature maps for forgery clues.
Secondly, the proposed residual federated learning algorithm is introduced to update distributed local model parameters and global server model parameters collaboratively, which could further boost the forgery representation generalization ability.
Finally, the global model in the server could directly detect different artifact types and even unknown type forgery.
<em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">The main reason for superior performance is that we effectively propose the residual feature map for generalized forgery detection, and simultaneously introduce a specific federated learning strategy to boost performance and protect data privacy.</em></p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To the best of our knowledge, it is the first exploration to introduce federated learning and explore generalization ability in the face forgery detection field. The main contributions of our paper can be summarized as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We firstly explore a residual federated learning framework for face forgery detection, which could effectively construct a distributed model with multiple local decentralized devices, and also boost the representation generalization ability.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">The designed variational autoencoder is proposed to analyze the difference of reconstruction residuals between the real and fake images in diverse artifact types, which can help representation identify hybrid and even unknown artifact types.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Experimental results on several public face forgery detection datasets illustrate the superior performance of the proposed FedForgery compared with state-of-the-art methods. The designed protocols and code would be publicly available at <em id="S1.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">https://github.com/GANG370/FedForgery.</em></p>
</div>
</li>
</ol>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We organized the rest of this paper as follows. Section I gives a brief introduction to the proposed method, and Section II shows some representative face forgery detection algorithms. In Section III, we present the novel generalized face forgery detection with residual federated learning for face forgery detection. Section IV shows the experimental results and analysis. Section V shows the ablation results and visualized analysis. The conclusion is drawn in Section VI.</p>
</div>
</section>
<section id="S2" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<section id="S2.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Face Forgery Detection</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In recent years, with the increasing popularity of face forgery technology, research on face forgery detection has gradually developed.
Face forgery detection is essentially a binary classification problem, the purpose of it is to train a classifier with a high degree of precision and generalizability.
As far as the currently proposed methods are concerned, they can be divided into image-based face forgery detection methods and video-based face forgery detection methods.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">There are currently methods to detect forgery images with the help of image-level labels.
For example, Chen <em id="S2.SS1.p2.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> proposed a general method that utilizes the RFAM module to fuse image RGB domain information and frequency domain information to obtain a more comprehensive local feature representation, so as to conduct face image authenticity detection.
The x-ray surveillance system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> is designed to detect deepfakes with the artifact clues generated by mixing two images.
Nirkin <em id="S2.SS1.p2.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> described a method using the proposed face recognition network and background recognition network.
Zhou <em id="S2.SS1.p2.1.3" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> designed a two-stream network to detect low-level inconsistencies between tampered faces and image patches in order to distinguish fake face images.
Yang <em id="S2.SS1.p2.1.4" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> observed that these deepfake images are generated by stitching synthesized face regions into original images, thus the novel method is proposed to detect fake videos by inputting 3D head pose features into support vector machines.
Li <em id="S2.SS1.p2.1.5" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> utilized the designed convolutional neural network to capture the artifacts in fake images to identify the authenticity of the image.
Yu <em id="S2.SS1.p2.1.6" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> designed the novel U-net structure and several designed losses to train a universal forgery feature extractor, which aims to explore robust forgery traces and learn a better generalization ability when detecting unknown forgery types.
Scherhag <em id="S2.SS1.p2.1.7" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> proposed a differential MAD algorithm based on deep face representation to extract rich and compact deep facial representations from pairs of reference and probe images in combination with training a machine learning-based classifier to detect image changes caused by the morphing algorithm.
Yang <em id="S2.SS1.p2.1.8" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> studied a multi-scale texture difference model MTD-Net, which uses a special convolution operation of central difference convolution for robust face forgery detection. This is the first attempt to introduce a special convolution operation for feature extraction and information fusion in the field of face forgery detection.
In order to adapt to insufficient annotated data, Zhao <em id="S2.SS1.p2.1.9" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> proposed the mCNN to learn invariant representation to improve the representation generalization in face analysis task.
Miao <em id="S2.SS1.p2.1.10" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> pointed out that a new hierarchical frequency-aided interaction network for face forgery detection, which utilizes a frequency-based feature refinement module to extract mid-high frequency traces on rgb features, making full use of more general image frequency domain features.
Wang <em id="S2.SS1.p2.1.11" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> designed a new localization Invariant Siamese network, which uses the localization invariant loss to improve the localization consistency between two segmentation maps, so as to strengthen the localization invariance to different image degradations, and to perform more efficient deepfake detection.
Wang <em id="S2.SS1.p2.1.12" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> proposed an attention mechanism to capture local artifact features from facial attention regions, and allows multiple attention maps to focus on different regions of the face, thereby improving forgery detection performance.
The method based on frequency domain analysis is widely used in image analysis, image reconstruction and other image processing.
Durall <em id="S2.SS1.p2.1.13" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> used the DFT transformations to extract features and then send them to a classifier for training.
Dong <em id="S2.SS1.p2.1.14" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> proposed the novel identity consistency transformer to find identity inconsistency in face regions, which also exhibits its good generalization ability in real-world applications.
Zhu <em id="S2.SS1.p2.1.15" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> firstly disentangled a face into four graphic components with the designed 3D decomposition method, and then utilized the composition search strategy to mine forgery clues from relevant components.
Zhao <em id="S2.SS1.p2.1.16" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> proposed a novel multi-attention deepfake detection network, which incorporates the designed region-independence loss and an attention-guided data augmentation strategy to improve performance.
Different from Cao <em id="S2.SS1.p2.1.17" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> distinguished between real faces and fake faces by learning a common compact representation of real faces, the proposed method exploits the similarity between the reconstructed residuals of different forged types of data to improve generalization.
However, these image-based methods need to collect all data from the data center during model training, but could not be applied in distributed storage non-public video data scenarios.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Video-based methods are mainly based on the detection of visually unnatural image cross-frame transitions and temporal inconsistencies in fake videos.
Li <em id="S2.SS1.p3.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> proposed a multi-instance learning framework to treat faces and input videos as instances and bags respectively.
They further utilized a sharp mapping method to map instance embeddings to bag prediction.
Sabir <em id="S2.SS1.p3.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> studied the novel convolutional recurrent models to extract features in terms of temporal information of image streams to detect fake data.
CIFTCIUA <em id="S2.SS1.p3.1.3" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> found that the authenticity of the videos can be detected by biological signals. From this point, a video classifier based on the synthesis of physiological signal changes was created. However, getting a heart rate signal from the video is not an easy job.
Saikia <em id="S2.SS1.p3.1.4" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> described a CNN model based on optical flow volume, pre-trained CNN model and LSTM layer to model the inconsistent motion of each pixel in a video frame, so as to distinguish the true and false video.
Masi <em id="S2.SS1.p3.1.5" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> designed a deep fake detection method based on a two-branch network structure, one branch is used to propagate the original information, and the other branch is used to suppress the face content. In the later stage of the network, a bidirectional long short-term memory architecture is used to learn the temporal features between video sequences.
Ganiyusufoglu <em id="S2.SS1.p3.1.6" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> proposed to use 3D convolutional neural networks to model spatio-temporal features to capture the local spatio-temporal relationships and inconsistencies of deepfake videos, so as to extend the generalization function to detect new types of deepfake videos.
Trinh <em id="S2.SS1.p3.1.7" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> designed to consider unnatural motion and temporal artifacts as a form of visual interpretation, learn temporally inconsistent prototype representations in the latent space by combining spatial and temporal information, and then make predictions based on the similarity between the dynamic prototype of the test video and the learned dynamic prototype.
Guera <em id="S2.SS1.p3.1.8" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> studied a time-aware convolutional neural network that created sequence descriptors and a fully connected layer to automatically detect deep fake videos.
Gu <em id="S2.SS1.p3.1.9" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> designed a spatial-temporal inconsistency learning module, which takes advantage of the temporal differences between adjacent frames along horizontal and vertical directions. The inconsistencies between single and consecutive frames in deepfake videos are jointly learned to obtain a more comprehensive representation.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, the image sequence of the eye region was exacted and the LSTM network was utilized to predict the blink probability to determine the authenticity.
The limitation of this method is that the person in the video must be in a state of open eyes.
The new spatiotemporal convolution method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> is proposed to detect artifact traces across video frames for video authenticity identification. Video-based detection methods are always computationally expensive compared with image-based methods, because of fusing temporal inconsistencies.
Overall, most image-based forgery detection and video-based forgery detection methods both ignore the issue of data privacy.
They always utilized shared or centralized images when training the model, which increases the risk of data leakage.
In addition, limited research has explored the distributed storage of training data in the forgery detection field.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Federated Learning </span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Federated learning could help protect data privacy and has drawn more and more attention recently.
There always exist two components: data center and global server in a typical federated learning framework.
Each local data center only uploads parameters to update the global server model with a specific aggregated strategy.
McMahan <em id="S2.SS2.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> firstly introduced the idea of the federated learning pipeline.
The distinctive feature of the algorithm is the weighted average of model parameters on the global server. The FedProx algorithm proposed by Li <em id="S2.SS2.p1.1.2" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> solves the problem of data heterogeneity distributed across systems and networks in federated learning, and significantly improves the convergence behavior of federated learning with heterogeneous networks in the real world.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">The privacy-preserving performance of federated learning has received more and more attention.
To protect sensitive personal information in person re-identification tasks, a distributed federated learning method with unlabeled data is adopted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> for cloud and edge federated optimization.
Yao <em id="S2.SS2.p2.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> proposed the DualAdapt model for multi-objective domain adaptation tasks in image classification and semantic segmentation, which utilized federated learning distributed framework to deal with the domain gap between unlabeled data on the client and labeled centralized datasets on the server.
Shao <em id="S2.SS2.p2.1.2" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> studied that common face representation can be detected by introducing a federated domain decoupling strategy. This is the first to study the federated learning technique for the task of face presentation attack detection.
Zhou <em id="S2.SS2.p2.1.3" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> designed to apply federated learning to edge computing. By designing a flexible participation training mechanism, it achieved low communication overhead and protected the privacy of edge clients, which benefited edge computing.
Liu <em id="S2.SS2.p2.1.4" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> proposed a privacy-enhanced based federated learning framework using homomorphic encryption as the underlying technique, which is the early exploration to effectively detect poisoning behavior in the federated learning process.
Niu <em id="S2.SS2.p2.1.5" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> focused on the problem of unconstrained face recognition with private decentralized data, and they proposed a softmax-based regularization method to revise the class embedding gradients to enhance the discriminative power of class embedding across clients.
Zhuang <em id="S2.SS2.p2.1.6" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> studied a cluster-based domain-adaptive federated learning method to improve the recognition performance of the target domain, addressing the problem of face recognition under privacy constraints.
However, limited works applied federated learning in face forgery detection tasks.
The number of training data has grown rapidly, and the issue of data privacy protection becomes more and more important.
Besides, the distributed data collaborative training strategy also could help improve the model to avoid overfitting.
Considering these issues, the paper proposes a novel generalized residual federated learning for face forgery detection to solve these problems.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Proposed Approach</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.9" class="ltx_p">In this section, we will give details of the proposed FedForgery.
We analyze the residual feature maps between input images and reconstruction images under different artifact types.
The designed variational autoencoder module could help identify hybrid-dataset artifacts and even unknown artifact types.
The overall framework of FedForgery is shown in Figure 2.
The face forgery images are distributed storage.
<math id="S3.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">K</annotation></semantics></math> data centers possess <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">K</annotation></semantics></math> private different datasets: <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p1.3.m3.1a"><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">D</annotation></semantics></math><sub id="S3.p1.9.1" class="ltx_sub"><span id="S3.p1.9.1.1" class="ltx_text ltx_font_italic">1</span></sub>, <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p1.5.m5.1a"><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">D</annotation></semantics></math><sub id="S3.p1.9.2" class="ltx_sub"><span id="S3.p1.9.2.1" class="ltx_text ltx_font_italic">2</span></sub>, ‚Ä¶ <math id="S3.p1.7.m7.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p1.7.m7.1a"><mi id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">D</annotation></semantics></math><sub id="S3.p1.9.3" class="ltx_sub"><span id="S3.p1.9.3.1" class="ltx_text ltx_font_italic">K</span></sub>.
Each data center only performs local training processing with local private data.
And then, the local face forgery detection model parameterized by <math id="S3.p1.9.m9.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p1.9.m9.1a"><mi id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><ci id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1">ùë§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">w</annotation></semantics></math> is obtained.</p>
</div>
<section id="S3.SS1" class="ltx_subsection ltx_indent_first ltx_pruned_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Discriminative Residual Feature Learning</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.6" class="ltx_p">Related researches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> have proved that different data distribution could bring adverse effects on forgery detection performance, especially in defined Hybrid-dataset and Generalized-dataset forgery detection scenarios in Section I. Due to the diverse forgery artifact types, these existing domain gaps even may be larger than the difference between real and fake images. It makes it still a challenging problem to distinguish the authenticity in unknown artifact scenarios. Thus, we assume that exploring the specific characteristics of reconstruction residual is easier than inputting raw images in the multiple domain forgery scenarios. It also inspires us to design suitable robust residual features learning to avoid overfitting and effectively capture domain-invariant discrepancy information between real and fake images.
As shown in Figure 2, each data center aims to train a local face forgery detection model first.
We design a variational autoencoder to analyze the difference between real images and artifact reconstruction residuals under different artifact types.
The local client model consists of two networks: RecNet represents the face reconstruction network, and ClsNet represents the forgery classification network.
In the RecNet module, we utilized the variational autoencoder <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="G(\cdot)" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.2" xref="S3.SS1.p1.1.m1.1.2.cmml"><mi id="S3.SS1.p1.1.m1.1.2.2" xref="S3.SS1.p1.1.m1.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.1.2.1" xref="S3.SS1.p1.1.m1.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p1.1.m1.1.2.3.2" xref="S3.SS1.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.1.2.3.2.1" xref="S3.SS1.p1.1.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S3.SS1.p1.1.m1.1.2.3.2.2" xref="S3.SS1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.2"><times id="S3.SS1.p1.1.m1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.1.2.1"></times><ci id="S3.SS1.p1.1.m1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.2.2">ùê∫</ci><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">G(\cdot)</annotation></semantics></math> with similar architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> to reconstruct input face <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">x</annotation></semantics></math> to <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="G(X)" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.2" xref="S3.SS1.p1.3.m3.1.2.cmml"><mi id="S3.SS1.p1.3.m3.1.2.2" xref="S3.SS1.p1.3.m3.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.3.m3.1.2.1" xref="S3.SS1.p1.3.m3.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p1.3.m3.1.2.3.2" xref="S3.SS1.p1.3.m3.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.3.m3.1.2.3.2.1" xref="S3.SS1.p1.3.m3.1.2.cmml">(</mo><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">X</mi><mo stretchy="false" id="S3.SS1.p1.3.m3.1.2.3.2.2" xref="S3.SS1.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.2.cmml" xref="S3.SS1.p1.3.m3.1.2"><times id="S3.SS1.p1.3.m3.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.2.1"></times><ci id="S3.SS1.p1.3.m3.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.2.2">ùê∫</ci><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ùëã</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">G(X)</annotation></semantics></math>.
Then we calculate the residual <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="x-G(X)" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.2" xref="S3.SS1.p1.4.m4.1.2.cmml"><mi id="S3.SS1.p1.4.m4.1.2.2" xref="S3.SS1.p1.4.m4.1.2.2.cmml">x</mi><mo id="S3.SS1.p1.4.m4.1.2.1" xref="S3.SS1.p1.4.m4.1.2.1.cmml">‚àí</mo><mrow id="S3.SS1.p1.4.m4.1.2.3" xref="S3.SS1.p1.4.m4.1.2.3.cmml"><mi id="S3.SS1.p1.4.m4.1.2.3.2" xref="S3.SS1.p1.4.m4.1.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.4.m4.1.2.3.1" xref="S3.SS1.p1.4.m4.1.2.3.1.cmml">‚Äã</mo><mrow id="S3.SS1.p1.4.m4.1.2.3.3.2" xref="S3.SS1.p1.4.m4.1.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.4.m4.1.2.3.3.2.1" xref="S3.SS1.p1.4.m4.1.2.3.cmml">(</mo><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">X</mi><mo stretchy="false" id="S3.SS1.p1.4.m4.1.2.3.3.2.2" xref="S3.SS1.p1.4.m4.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.2.cmml" xref="S3.SS1.p1.4.m4.1.2"><minus id="S3.SS1.p1.4.m4.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.2.1"></minus><ci id="S3.SS1.p1.4.m4.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.2.2">ùë•</ci><apply id="S3.SS1.p1.4.m4.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.2.3"><times id="S3.SS1.p1.4.m4.1.2.3.1.cmml" xref="S3.SS1.p1.4.m4.1.2.3.1"></times><ci id="S3.SS1.p1.4.m4.1.2.3.2.cmml" xref="S3.SS1.p1.4.m4.1.2.3.2">ùê∫</ci><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ùëã</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">x-G(X)</annotation></semantics></math> between the original image and the reconstructed image, denoted as <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="Res(x)" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.2" xref="S3.SS1.p1.5.m5.1.2.cmml"><mi id="S3.SS1.p1.5.m5.1.2.2" xref="S3.SS1.p1.5.m5.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.2.1" xref="S3.SS1.p1.5.m5.1.2.1.cmml">‚Äã</mo><mi id="S3.SS1.p1.5.m5.1.2.3" xref="S3.SS1.p1.5.m5.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.2.1a" xref="S3.SS1.p1.5.m5.1.2.1.cmml">‚Äã</mo><mi id="S3.SS1.p1.5.m5.1.2.4" xref="S3.SS1.p1.5.m5.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.2.1b" xref="S3.SS1.p1.5.m5.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p1.5.m5.1.2.5.2" xref="S3.SS1.p1.5.m5.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m5.1.2.5.2.1" xref="S3.SS1.p1.5.m5.1.2.cmml">(</mo><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS1.p1.5.m5.1.2.5.2.2" xref="S3.SS1.p1.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.2.cmml" xref="S3.SS1.p1.5.m5.1.2"><times id="S3.SS1.p1.5.m5.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.2.1"></times><ci id="S3.SS1.p1.5.m5.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.2.2">ùëÖ</ci><ci id="S3.SS1.p1.5.m5.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.2.3">ùëí</ci><ci id="S3.SS1.p1.5.m5.1.2.4.cmml" xref="S3.SS1.p1.5.m5.1.2.4">ùë†</ci><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">Res(x)</annotation></semantics></math>. Finally, <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="Res(x)" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1.2" xref="S3.SS1.p1.6.m6.1.2.cmml"><mi id="S3.SS1.p1.6.m6.1.2.2" xref="S3.SS1.p1.6.m6.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.6.m6.1.2.1" xref="S3.SS1.p1.6.m6.1.2.1.cmml">‚Äã</mo><mi id="S3.SS1.p1.6.m6.1.2.3" xref="S3.SS1.p1.6.m6.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.6.m6.1.2.1a" xref="S3.SS1.p1.6.m6.1.2.1.cmml">‚Äã</mo><mi id="S3.SS1.p1.6.m6.1.2.4" xref="S3.SS1.p1.6.m6.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.6.m6.1.2.1b" xref="S3.SS1.p1.6.m6.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p1.6.m6.1.2.5.2" xref="S3.SS1.p1.6.m6.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.6.m6.1.2.5.2.1" xref="S3.SS1.p1.6.m6.1.2.cmml">(</mo><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS1.p1.6.m6.1.2.5.2.2" xref="S3.SS1.p1.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.2.cmml" xref="S3.SS1.p1.6.m6.1.2"><times id="S3.SS1.p1.6.m6.1.2.1.cmml" xref="S3.SS1.p1.6.m6.1.2.1"></times><ci id="S3.SS1.p1.6.m6.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.2.2">ùëÖ</ci><ci id="S3.SS1.p1.6.m6.1.2.3.cmml" xref="S3.SS1.p1.6.m6.1.2.3">ùëí</ci><ci id="S3.SS1.p1.6.m6.1.2.4.cmml" xref="S3.SS1.p1.6.m6.1.2.4">ùë†</ci><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">Res(x)</annotation></semantics></math> is used to directly input ClsNet for distinguishing authenticity.
It is noted that the reconstruction model and the classification model are trained simultaneously.
In the training process, the suitable dynamic balance point between multiple tasks is trained by minimizing the equation (1).</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2210.09563/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="420" height="236" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The framework of a novel generalized residual Federated learning for face Forgery detection (FedForgery). Each data center uses its own data to train the model locally, and the local model further analyzes the difference between real image and artifact reconstruction residuals under different artifact types through a variational autoencoder. After a round of local training is completed, each data center uploads the obtained model parameters to the global server for weighted aggregation. After the aggregation is completed, the global server sends the updated parameters to each data center. This communication process continues until the model converges and is eventually tested using the updated aggregated global server model.</figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.3" class="ltx_p">We jointly train parameters in mentioned RecNet and ClsNet by optimizing the proposed objective, which combines the training objective <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="L_{G}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">L</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">G</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ùêø</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">ùê∫</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">L_{G}</annotation></semantics></math> of VQ-VAE<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, the pixel reconstruction loss <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="L_{rec}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">L</mi><mrow id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml"><mi id="S3.SS1.p3.2.m2.1.1.3.2" xref="S3.SS1.p3.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.2.m2.1.1.3.1" xref="S3.SS1.p3.2.m2.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS1.p3.2.m2.1.1.3.3" xref="S3.SS1.p3.2.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.2.m2.1.1.3.1a" xref="S3.SS1.p3.2.m2.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS1.p3.2.m2.1.1.3.4" xref="S3.SS1.p3.2.m2.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">ùêø</ci><apply id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3"><times id="S3.SS1.p3.2.m2.1.1.3.1.cmml" xref="S3.SS1.p3.2.m2.1.1.3.1"></times><ci id="S3.SS1.p3.2.m2.1.1.3.2.cmml" xref="S3.SS1.p3.2.m2.1.1.3.2">ùëü</ci><ci id="S3.SS1.p3.2.m2.1.1.3.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3">ùëí</ci><ci id="S3.SS1.p3.2.m2.1.1.3.4.cmml" xref="S3.SS1.p3.2.m2.1.1.3.4">ùëê</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">L_{rec}</annotation></semantics></math> and the forgery classification loss <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="L_{cls}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">L</mi><mrow id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3.2" xref="S3.SS1.p3.3.m3.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.3.1" xref="S3.SS1.p3.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS1.p3.3.m3.1.1.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.3.1a" xref="S3.SS1.p3.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS1.p3.3.m3.1.1.3.4" xref="S3.SS1.p3.3.m3.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ùêø</ci><apply id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3"><times id="S3.SS1.p3.3.m3.1.1.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3.1"></times><ci id="S3.SS1.p3.3.m3.1.1.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.2">ùëê</ci><ci id="S3.SS1.p3.3.m3.1.1.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3">ùëô</ci><ci id="S3.SS1.p3.3.m3.1.1.3.4.cmml" xref="S3.SS1.p3.3.m3.1.1.3.4">ùë†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">L_{cls}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="L=\mu_{1}L_{G}+\mu_{2}L_{rec}+\mu_{3}L_{cls}." display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">L</mi><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><msub id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.2.cmml">Œº</mi><mn id="S3.E1.m1.1.1.1.1.3.2.2.3" xref="S3.E1.m1.1.1.1.1.3.2.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">‚Äã</mo><msub id="S3.E1.m1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.3.2" xref="S3.E1.m1.1.1.1.1.3.2.3.2.cmml">L</mi><mi id="S3.E1.m1.1.1.1.1.3.2.3.3" xref="S3.E1.m1.1.1.1.1.3.2.3.3.cmml">G</mi></msub></mrow><mo id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml"><msub id="S3.E1.m1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.2.2" xref="S3.E1.m1.1.1.1.1.3.3.2.2.cmml">Œº</mi><mn id="S3.E1.m1.1.1.1.1.3.3.2.3" xref="S3.E1.m1.1.1.1.1.3.3.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.3.3.1.cmml">‚Äã</mo><msub id="S3.E1.m1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.3.2.cmml">L</mi><mrow id="S3.E1.m1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.3.3.1" xref="S3.E1.m1.1.1.1.1.3.3.3.3.1.cmml">‚Äã</mo><mi id="S3.E1.m1.1.1.1.1.3.3.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.3.3.1a" xref="S3.E1.m1.1.1.1.1.3.3.3.3.1.cmml">‚Äã</mo><mi id="S3.E1.m1.1.1.1.1.3.3.3.3.4" xref="S3.E1.m1.1.1.1.1.3.3.3.3.4.cmml">c</mi></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.3.1a" xref="S3.E1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.3.4" xref="S3.E1.m1.1.1.1.1.3.4.cmml"><msub id="S3.E1.m1.1.1.1.1.3.4.2" xref="S3.E1.m1.1.1.1.1.3.4.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.4.2.2" xref="S3.E1.m1.1.1.1.1.3.4.2.2.cmml">Œº</mi><mn id="S3.E1.m1.1.1.1.1.3.4.2.3" xref="S3.E1.m1.1.1.1.1.3.4.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.4.1" xref="S3.E1.m1.1.1.1.1.3.4.1.cmml">‚Äã</mo><msub id="S3.E1.m1.1.1.1.1.3.4.3" xref="S3.E1.m1.1.1.1.1.3.4.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.4.3.2" xref="S3.E1.m1.1.1.1.1.3.4.3.2.cmml">L</mi><mrow id="S3.E1.m1.1.1.1.1.3.4.3.3" xref="S3.E1.m1.1.1.1.1.3.4.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.4.3.3.2" xref="S3.E1.m1.1.1.1.1.3.4.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.4.3.3.1" xref="S3.E1.m1.1.1.1.1.3.4.3.3.1.cmml">‚Äã</mo><mi id="S3.E1.m1.1.1.1.1.3.4.3.3.3" xref="S3.E1.m1.1.1.1.1.3.4.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.4.3.3.1a" xref="S3.E1.m1.1.1.1.1.3.4.3.3.1.cmml">‚Äã</mo><mi id="S3.E1.m1.1.1.1.1.3.4.3.3.4" xref="S3.E1.m1.1.1.1.1.3.4.3.3.4.cmml">s</mi></mrow></msub></mrow></mrow></mrow><mo lspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><ci id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2">ùêø</ci><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><plus id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></plus><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><times id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1"></times><apply id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.2">ùúá</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2.3">1</cn></apply><apply id="S3.E1.m1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.2">ùêø</ci><ci id="S3.E1.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.3">ùê∫</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1"></times><apply id="S3.E1.m1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2.2">ùúá</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2.3">2</cn></apply><apply id="S3.E1.m1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.2">ùêø</ci><apply id="S3.E1.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3"><times id="S3.E1.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3.2">ùëü</ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3.3">ùëí</ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.4.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3.4">ùëê</ci></apply></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.1.1.3.4"><times id="S3.E1.m1.1.1.1.1.3.4.1.cmml" xref="S3.E1.m1.1.1.1.1.3.4.1"></times><apply id="S3.E1.m1.1.1.1.1.3.4.2.cmml" xref="S3.E1.m1.1.1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.4.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.4.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.4.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.4.2.2">ùúá</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.3.4.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.4.2.3">3</cn></apply><apply id="S3.E1.m1.1.1.1.1.3.4.3.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.4.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.4.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.2">ùêø</ci><apply id="S3.E1.m1.1.1.1.1.3.4.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.3"><times id="S3.E1.m1.1.1.1.1.3.4.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.3.4.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.3.2">ùëê</ci><ci id="S3.E1.m1.1.1.1.1.3.4.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.3.3">ùëô</ci><ci id="S3.E1.m1.1.1.1.1.3.4.3.3.4.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.3.4">ùë†</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">L=\mu_{1}L_{G}+\mu_{2}L_{rec}+\mu_{3}L_{cls}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.12" class="ltx_p">Here the variational autoencoder <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="G(\cdot)" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><mrow id="S3.SS1.p5.1.m1.1.2" xref="S3.SS1.p5.1.m1.1.2.cmml"><mi id="S3.SS1.p5.1.m1.1.2.2" xref="S3.SS1.p5.1.m1.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.1.m1.1.2.1" xref="S3.SS1.p5.1.m1.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p5.1.m1.1.2.3.2" xref="S3.SS1.p5.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p5.1.m1.1.2.3.2.1" xref="S3.SS1.p5.1.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S3.SS1.p5.1.m1.1.2.3.2.2" xref="S3.SS1.p5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.2"><times id="S3.SS1.p5.1.m1.1.2.1.cmml" xref="S3.SS1.p5.1.m1.1.2.1"></times><ci id="S3.SS1.p5.1.m1.1.2.2.cmml" xref="S3.SS1.p5.1.m1.1.2.2">ùê∫</ci><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">G(\cdot)</annotation></semantics></math> aims to generate input face with high quality.
Inspired by the good performance of the discrete latent model in image generation tasks, we also introduce the discrete representation learning to construct <math id="S3.SS1.p5.2.m2.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS1.p5.2.m2.1a"><mi id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><ci id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">ùê∫</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">G</annotation></semantics></math>.
The RecNet module consists of three components: the encoder, the decoder and the potential embedding space.
The embedding space <math id="S3.SS1.p5.3.m3.1" class="ltx_Math" alttext="e\in R^{m\times d}" display="inline"><semantics id="S3.SS1.p5.3.m3.1a"><mrow id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><mi id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml">e</mi><mo id="S3.SS1.p5.3.m3.1.1.1" xref="S3.SS1.p5.3.m3.1.1.1.cmml">‚àà</mo><msup id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml"><mi id="S3.SS1.p5.3.m3.1.1.3.2" xref="S3.SS1.p5.3.m3.1.1.3.2.cmml">R</mi><mrow id="S3.SS1.p5.3.m3.1.1.3.3" xref="S3.SS1.p5.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.p5.3.m3.1.1.3.3.2" xref="S3.SS1.p5.3.m3.1.1.3.3.2.cmml">m</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p5.3.m3.1.1.3.3.1" xref="S3.SS1.p5.3.m3.1.1.3.3.1.cmml">√ó</mo><mi id="S3.SS1.p5.3.m3.1.1.3.3.3" xref="S3.SS1.p5.3.m3.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><in id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1.1"></in><ci id="S3.SS1.p5.3.m3.1.1.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2">ùëí</ci><apply id="S3.SS1.p5.3.m3.1.1.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m3.1.1.3.1.cmml" xref="S3.SS1.p5.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p5.3.m3.1.1.3.2.cmml" xref="S3.SS1.p5.3.m3.1.1.3.2">ùëÖ</ci><apply id="S3.SS1.p5.3.m3.1.1.3.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3.3"><times id="S3.SS1.p5.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p5.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.p5.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p5.3.m3.1.1.3.3.2">ùëö</ci><ci id="S3.SS1.p5.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3.3.3">ùëë</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">e\in R^{m\times d}</annotation></semantics></math> is defined here, <math id="S3.SS1.p5.4.m4.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS1.p5.4.m4.1a"><mi id="S3.SS1.p5.4.m4.1.1" xref="S3.SS1.p5.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m4.1b"><ci id="S3.SS1.p5.4.m4.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1">ùëö</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m4.1c">m</annotation></semantics></math> is the size of the discrete embedding space, <math id="S3.SS1.p5.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS1.p5.5.m5.1a"><mi id="S3.SS1.p5.5.m5.1.1" xref="S3.SS1.p5.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.5.m5.1b"><ci id="S3.SS1.p5.5.m5.1.1.cmml" xref="S3.SS1.p5.5.m5.1.1">ùëë</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.5.m5.1c">d</annotation></semantics></math> is the dimension of each embedding vector in this space.
The encoder is denoted as <math id="S3.SS1.p5.6.m6.1" class="ltx_Math" alttext="E_{\varphi}(x)" display="inline"><semantics id="S3.SS1.p5.6.m6.1a"><mrow id="S3.SS1.p5.6.m6.1.2" xref="S3.SS1.p5.6.m6.1.2.cmml"><msub id="S3.SS1.p5.6.m6.1.2.2" xref="S3.SS1.p5.6.m6.1.2.2.cmml"><mi id="S3.SS1.p5.6.m6.1.2.2.2" xref="S3.SS1.p5.6.m6.1.2.2.2.cmml">E</mi><mi id="S3.SS1.p5.6.m6.1.2.2.3" xref="S3.SS1.p5.6.m6.1.2.2.3.cmml">œÜ</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p5.6.m6.1.2.1" xref="S3.SS1.p5.6.m6.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p5.6.m6.1.2.3.2" xref="S3.SS1.p5.6.m6.1.2.cmml"><mo stretchy="false" id="S3.SS1.p5.6.m6.1.2.3.2.1" xref="S3.SS1.p5.6.m6.1.2.cmml">(</mo><mi id="S3.SS1.p5.6.m6.1.1" xref="S3.SS1.p5.6.m6.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS1.p5.6.m6.1.2.3.2.2" xref="S3.SS1.p5.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.6.m6.1b"><apply id="S3.SS1.p5.6.m6.1.2.cmml" xref="S3.SS1.p5.6.m6.1.2"><times id="S3.SS1.p5.6.m6.1.2.1.cmml" xref="S3.SS1.p5.6.m6.1.2.1"></times><apply id="S3.SS1.p5.6.m6.1.2.2.cmml" xref="S3.SS1.p5.6.m6.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p5.6.m6.1.2.2.1.cmml" xref="S3.SS1.p5.6.m6.1.2.2">subscript</csymbol><ci id="S3.SS1.p5.6.m6.1.2.2.2.cmml" xref="S3.SS1.p5.6.m6.1.2.2.2">ùê∏</ci><ci id="S3.SS1.p5.6.m6.1.2.2.3.cmml" xref="S3.SS1.p5.6.m6.1.2.2.3">ùúë</ci></apply><ci id="S3.SS1.p5.6.m6.1.1.cmml" xref="S3.SS1.p5.6.m6.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.6.m6.1c">E_{\varphi}(x)</annotation></semantics></math>, which is parameterized by <math id="S3.SS1.p5.7.m7.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS1.p5.7.m7.1a"><mi id="S3.SS1.p5.7.m7.1.1" xref="S3.SS1.p5.7.m7.1.1.cmml">œÜ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.7.m7.1b"><ci id="S3.SS1.p5.7.m7.1.1.cmml" xref="S3.SS1.p5.7.m7.1.1">ùúë</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.7.m7.1c">\varphi</annotation></semantics></math>.
Parameters and <math id="S3.SS1.p5.8.m8.1" class="ltx_Math" alttext="\mu_{1}" display="inline"><semantics id="S3.SS1.p5.8.m8.1a"><msub id="S3.SS1.p5.8.m8.1.1" xref="S3.SS1.p5.8.m8.1.1.cmml"><mi id="S3.SS1.p5.8.m8.1.1.2" xref="S3.SS1.p5.8.m8.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p5.8.m8.1.1.3" xref="S3.SS1.p5.8.m8.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.8.m8.1b"><apply id="S3.SS1.p5.8.m8.1.1.cmml" xref="S3.SS1.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.8.m8.1.1.1.cmml" xref="S3.SS1.p5.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p5.8.m8.1.1.2.cmml" xref="S3.SS1.p5.8.m8.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p5.8.m8.1.1.3.cmml" xref="S3.SS1.p5.8.m8.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.8.m8.1c">\mu_{1}</annotation></semantics></math>, <math id="S3.SS1.p5.9.m9.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S3.SS1.p5.9.m9.1a"><msub id="S3.SS1.p5.9.m9.1.1" xref="S3.SS1.p5.9.m9.1.1.cmml"><mi id="S3.SS1.p5.9.m9.1.1.2" xref="S3.SS1.p5.9.m9.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p5.9.m9.1.1.3" xref="S3.SS1.p5.9.m9.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.9.m9.1b"><apply id="S3.SS1.p5.9.m9.1.1.cmml" xref="S3.SS1.p5.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.9.m9.1.1.1.cmml" xref="S3.SS1.p5.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.p5.9.m9.1.1.2.cmml" xref="S3.SS1.p5.9.m9.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p5.9.m9.1.1.3.cmml" xref="S3.SS1.p5.9.m9.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.9.m9.1c">\mu_{2}</annotation></semantics></math> and <math id="S3.SS1.p5.10.m10.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S3.SS1.p5.10.m10.1a"><msub id="S3.SS1.p5.10.m10.1.1" xref="S3.SS1.p5.10.m10.1.1.cmml"><mi id="S3.SS1.p5.10.m10.1.1.2" xref="S3.SS1.p5.10.m10.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p5.10.m10.1.1.3" xref="S3.SS1.p5.10.m10.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.10.m10.1b"><apply id="S3.SS1.p5.10.m10.1.1.cmml" xref="S3.SS1.p5.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.10.m10.1.1.1.cmml" xref="S3.SS1.p5.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.p5.10.m10.1.1.2.cmml" xref="S3.SS1.p5.10.m10.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p5.10.m10.1.1.3.cmml" xref="S3.SS1.p5.10.m10.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.10.m10.1c">\mu_{3}</annotation></semantics></math> indicate the weights of the generative model, pixel reconstruction and classification terms. The higher quality of the reconstructed image may bring adverse effects in detection forgery clues, which focus on real data distribution but ignore the discrepancy. Thus, both hyperparameters <math id="S3.SS1.p5.11.m11.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S3.SS1.p5.11.m11.1a"><msub id="S3.SS1.p5.11.m11.1.1" xref="S3.SS1.p5.11.m11.1.1.cmml"><mi id="S3.SS1.p5.11.m11.1.1.2" xref="S3.SS1.p5.11.m11.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p5.11.m11.1.1.3" xref="S3.SS1.p5.11.m11.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.11.m11.1b"><apply id="S3.SS1.p5.11.m11.1.1.cmml" xref="S3.SS1.p5.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.11.m11.1.1.1.cmml" xref="S3.SS1.p5.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p5.11.m11.1.1.2.cmml" xref="S3.SS1.p5.11.m11.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p5.11.m11.1.1.3.cmml" xref="S3.SS1.p5.11.m11.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.11.m11.1c">\mu_{2}</annotation></semantics></math> and <math id="S3.SS1.p5.12.m12.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S3.SS1.p5.12.m12.1a"><msub id="S3.SS1.p5.12.m12.1.1" xref="S3.SS1.p5.12.m12.1.1.cmml"><mi id="S3.SS1.p5.12.m12.1.1.2" xref="S3.SS1.p5.12.m12.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p5.12.m12.1.1.3" xref="S3.SS1.p5.12.m12.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.12.m12.1b"><apply id="S3.SS1.p5.12.m12.1.1.cmml" xref="S3.SS1.p5.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.12.m12.1.1.1.cmml" xref="S3.SS1.p5.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p5.12.m12.1.1.2.cmml" xref="S3.SS1.p5.12.m12.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p5.12.m12.1.1.3.cmml" xref="S3.SS1.p5.12.m12.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.12.m12.1c">\mu_{3}</annotation></semantics></math> balance the importance of the influence of forgery detection discriminability.
Thus, the training objective function is followed:</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.4" class="ltx_Math" alttext="L_{G}=\alpha||sg[E_{\varphi}(x)]-e||_{2}^{2}+\beta||E_{\varphi}(x)-sg[e]||_{2}^{2}," display="block"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1" xref="S3.E2.m1.4.4.1.1.cmml"><msub id="S3.E2.m1.4.4.1.1.4" xref="S3.E2.m1.4.4.1.1.4.cmml"><mi id="S3.E2.m1.4.4.1.1.4.2" xref="S3.E2.m1.4.4.1.1.4.2.cmml">L</mi><mi id="S3.E2.m1.4.4.1.1.4.3" xref="S3.E2.m1.4.4.1.1.4.3.cmml">G</mi></msub><mo id="S3.E2.m1.4.4.1.1.3" xref="S3.E2.m1.4.4.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1.2" xref="S3.E2.m1.4.4.1.1.2.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.3.cmml">Œ±</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.2.cmml">‚Äã</mo><msubsup id="S3.E2.m1.4.4.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.2a" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">E</mi><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">œÜ</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">‚Äã</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml">‚àí</mo><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml">e</mi></mrow><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="S3.E2.m1.4.4.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml">2</mn><mn id="S3.E2.m1.4.4.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S3.E2.m1.4.4.1.1.2.3" xref="S3.E2.m1.4.4.1.1.2.3.cmml">+</mo><mrow id="S3.E2.m1.4.4.1.1.2.2" xref="S3.E2.m1.4.4.1.1.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.2.2.3" xref="S3.E2.m1.4.4.1.1.2.2.3.cmml">Œ≤</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.2.2.2" xref="S3.E2.m1.4.4.1.1.2.2.2.cmml">‚Äã</mo><msubsup id="S3.E2.m1.4.4.1.1.2.2.1" xref="S3.E2.m1.4.4.1.1.2.2.1.cmml"><mrow id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.2.1.cmml">‚Äñ</mo><mrow id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.cmml"><msub id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.2.cmml">E</mi><mi id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.3" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.3.cmml">œÜ</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.1" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.1.cmml">‚Äã</mo><mrow id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.3.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.3.2.1" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">x</mi><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.3.2.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1.cmml">‚àí</mo><mrow id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.1" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.1.cmml">‚Äã</mo><mi id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.3" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.1a" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.1.cmml">‚Äã</mo><mrow id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.2.1" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.1.1.cmml">[</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">e</mi><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.2.2" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.1.1.cmml">]</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="S3.E2.m1.4.4.1.1.2.2.1.1.3" xref="S3.E2.m1.4.4.1.1.2.2.1.1.3.cmml">2</mn><mn id="S3.E2.m1.4.4.1.1.2.2.1.3" xref="S3.E2.m1.4.4.1.1.2.2.1.3.cmml">2</mn></msubsup></mrow></mrow></mrow><mo id="S3.E2.m1.4.4.1.2" xref="S3.E2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.1.1.cmml" xref="S3.E2.m1.4.4.1"><eq id="S3.E2.m1.4.4.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.3"></eq><apply id="S3.E2.m1.4.4.1.1.4.cmml" xref="S3.E2.m1.4.4.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.4.1.cmml" xref="S3.E2.m1.4.4.1.1.4">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.4.2.cmml" xref="S3.E2.m1.4.4.1.1.4.2">ùêø</ci><ci id="S3.E2.m1.4.4.1.1.4.3.cmml" xref="S3.E2.m1.4.4.1.1.4.3">ùê∫</ci></apply><apply id="S3.E2.m1.4.4.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.2"><plus id="S3.E2.m1.4.4.1.1.2.3.cmml" xref="S3.E2.m1.4.4.1.1.2.3"></plus><apply id="S3.E2.m1.4.4.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2"></times><ci id="S3.E2.m1.4.4.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3">ùõº</ci><apply id="S3.E2.m1.4.4.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1">superscript</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1"><minus id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.3">ùë†</ci><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.4">ùëî</ci><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></times><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ùê∏</ci><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">ùúë</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ùë•</ci></apply></apply></apply><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3">ùëí</ci></apply></apply><cn type="integer" id="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E2.m1.4.4.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.3">2</cn></apply></apply><apply id="S3.E2.m1.4.4.1.1.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2"><times id="S3.E2.m1.4.4.1.1.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.2"></times><ci id="S3.E2.m1.4.4.1.1.2.2.3.cmml" xref="S3.E2.m1.4.4.1.1.2.2.3">ùõΩ</ci><apply id="S3.E2.m1.4.4.1.1.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.2.2.1.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1">superscript</csymbol><apply id="S3.E2.m1.4.4.1.1.2.2.1.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.2.2.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1">subscript</csymbol><apply id="S3.E2.m1.4.4.1.1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.2">norm</csymbol><apply id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1"><minus id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1"></minus><apply id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2"><times id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.1"></times><apply id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.2">ùê∏</ci><ci id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2.3">ùúë</ci></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ùë•</ci></apply><apply id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3"><times id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.1"></times><ci id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.2">ùë†</ci><ci id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.3">ùëî</ci><apply id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.2"><csymbol cd="latexml" id="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.1.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.1.1.1.3.4.2.1">delimited-[]</csymbol><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">ùëí</ci></apply></apply></apply></apply><cn type="integer" id="S3.E2.m1.4.4.1.1.2.2.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.1.3">2</cn></apply><cn type="integer" id="S3.E2.m1.4.4.1.1.2.2.1.3.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">L_{G}=\alpha||sg[E_{\varphi}(x)]-e||_{2}^{2}+\beta||E_{\varphi}(x)-sg[e]||_{2}^{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p6.9" class="ltx_p">where the former term is the alignment loss, which aims to make the embedding vectors <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><mi id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><ci id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">ùëí</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">e</annotation></semantics></math><sub id="S3.SS1.p6.9.1" class="ltx_sub"><span id="S3.SS1.p6.9.1.1" class="ltx_text ltx_font_italic">i</span></sub> closer together the encoder outputs <math id="S3.SS1.p6.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS1.p6.3.m3.1a"><mi id="S3.SS1.p6.3.m3.1.1" xref="S3.SS1.p6.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.1b"><ci id="S3.SS1.p6.3.m3.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.1c">E</annotation></semantics></math><sub id="S3.SS1.p6.9.2" class="ltx_sub"><span id="S3.SS1.p6.9.2.1" class="ltx_text ltx_font_italic">œÜ</span></sub>(<math id="S3.SS1.p6.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p6.5.m5.1a"><mi id="S3.SS1.p6.5.m5.1.1" xref="S3.SS1.p6.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.5.m5.1b"><ci id="S3.SS1.p6.5.m5.1.1.cmml" xref="S3.SS1.p6.5.m5.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.5.m5.1c">x</annotation></semantics></math>) as possible.
sg[¬∑] stands for stop gradient.
The stop gradient operator on the encoder output indicates that the term is only used to update the embedding vector, which is conducive to better learning the embedding space.
The latter term aims to force the encoder output to commit as much as possible to its closest embedding vector.
The stop gradient on the embedding vector helps to limit the volume of the discrete embedding space and prevent its free growth.
Parameters <math id="S3.SS1.p6.6.m6.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p6.6.m6.1a"><mi id="S3.SS1.p6.6.m6.1.1" xref="S3.SS1.p6.6.m6.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.6.m6.1b"><ci id="S3.SS1.p6.6.m6.1.1.cmml" xref="S3.SS1.p6.6.m6.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.6.m6.1c">\alpha</annotation></semantics></math> and <math id="S3.SS1.p6.7.m7.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS1.p6.7.m7.1a"><mi id="S3.SS1.p6.7.m7.1.1" xref="S3.SS1.p6.7.m7.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.7.m7.1b"><ci id="S3.SS1.p6.7.m7.1.1.cmml" xref="S3.SS1.p6.7.m7.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.7.m7.1c">\beta</annotation></semantics></math> indicate the weights of the embedding and encoder alignment terms, which also balance the importance of generative model performance.
The settings of hyper-parameters <math id="S3.SS1.p6.8.m8.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p6.8.m8.1a"><mi id="S3.SS1.p6.8.m8.1.1" xref="S3.SS1.p6.8.m8.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.8.m8.1b"><ci id="S3.SS1.p6.8.m8.1.1.cmml" xref="S3.SS1.p6.8.m8.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.8.m8.1c">\alpha</annotation></semantics></math> and <math id="S3.SS1.p6.9.m9.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS1.p6.9.m9.1a"><mi id="S3.SS1.p6.9.m9.1.1" xref="S3.SS1.p6.9.m9.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.9.m9.1b"><ci id="S3.SS1.p6.9.m9.1.1.cmml" xref="S3.SS1.p6.9.m9.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.9.m9.1c">\beta</annotation></semantics></math> are shown in the following.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p">To reduce the difference between the reconstructed face and the input face, formula (3) is introduced here to optimize the parameters of the encoder and decoder:</p>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="L_{rec}=||x-G(x)||_{2}^{2}," display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.3.2" xref="S3.E3.m1.2.2.1.1.3.2.cmml">L</mi><mrow id="S3.E3.m1.2.2.1.1.3.3" xref="S3.E3.m1.2.2.1.1.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.3.3.2" xref="S3.E3.m1.2.2.1.1.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.3.3.1" xref="S3.E3.m1.2.2.1.1.3.3.1.cmml">‚Äã</mo><mi id="S3.E3.m1.2.2.1.1.3.3.3" xref="S3.E3.m1.2.2.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.3.3.1a" xref="S3.E3.m1.2.2.1.1.3.3.1.cmml">‚Äã</mo><mi id="S3.E3.m1.2.2.1.1.3.3.4" xref="S3.E3.m1.2.2.1.1.3.3.4.cmml">c</mi></mrow></msub><mo id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml">=</mo><msubsup id="S3.E3.m1.2.2.1.1.1" xref="S3.E3.m1.2.2.1.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.1.cmml">‚Äñ</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml">‚àí</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.3.2.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.3.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="S3.E3.m1.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml">2</mn><mn id="S3.E3.m1.2.2.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1"><eq id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2"></eq><apply id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.3.2">ùêø</ci><apply id="S3.E3.m1.2.2.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3"><times id="S3.E3.m1.2.2.1.1.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1"></times><ci id="S3.E3.m1.2.2.1.1.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.3.3.2">ùëü</ci><ci id="S3.E3.m1.2.2.1.1.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3">ùëí</ci><ci id="S3.E3.m1.2.2.1.1.3.3.4.cmml" xref="S3.E3.m1.2.2.1.1.3.3.4">ùëê</ci></apply></apply><apply id="S3.E3.m1.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1">subscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1"><minus id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1"></minus><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.2">ùë•</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3"><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.2">ùê∫</ci><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ùë•</ci></apply></apply></apply><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E3.m1.2.2.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">L_{rec}=||x-G(x)||_{2}^{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p8.3" class="ltx_p">where <math id="S3.SS1.p8.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p8.1.m1.1a"><mi id="S3.SS1.p8.1.m1.1.1" xref="S3.SS1.p8.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.1.m1.1b"><ci id="S3.SS1.p8.1.m1.1.1.cmml" xref="S3.SS1.p8.1.m1.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.1.m1.1c">x</annotation></semantics></math> is the input face, and <math id="S3.SS1.p8.2.m2.1" class="ltx_Math" alttext="G(x)" display="inline"><semantics id="S3.SS1.p8.2.m2.1a"><mrow id="S3.SS1.p8.2.m2.1.2" xref="S3.SS1.p8.2.m2.1.2.cmml"><mi id="S3.SS1.p8.2.m2.1.2.2" xref="S3.SS1.p8.2.m2.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.2.m2.1.2.1" xref="S3.SS1.p8.2.m2.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p8.2.m2.1.2.3.2" xref="S3.SS1.p8.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p8.2.m2.1.2.3.2.1" xref="S3.SS1.p8.2.m2.1.2.cmml">(</mo><mi id="S3.SS1.p8.2.m2.1.1" xref="S3.SS1.p8.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS1.p8.2.m2.1.2.3.2.2" xref="S3.SS1.p8.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.2.m2.1b"><apply id="S3.SS1.p8.2.m2.1.2.cmml" xref="S3.SS1.p8.2.m2.1.2"><times id="S3.SS1.p8.2.m2.1.2.1.cmml" xref="S3.SS1.p8.2.m2.1.2.1"></times><ci id="S3.SS1.p8.2.m2.1.2.2.cmml" xref="S3.SS1.p8.2.m2.1.2.2">ùê∫</ci><ci id="S3.SS1.p8.2.m2.1.1.cmml" xref="S3.SS1.p8.2.m2.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.2.m2.1c">G(x)</annotation></semantics></math> is the constructed images with the variational autoencoder <math id="S3.SS1.p8.3.m3.1" class="ltx_Math" alttext="G(\cdot)" display="inline"><semantics id="S3.SS1.p8.3.m3.1a"><mrow id="S3.SS1.p8.3.m3.1.2" xref="S3.SS1.p8.3.m3.1.2.cmml"><mi id="S3.SS1.p8.3.m3.1.2.2" xref="S3.SS1.p8.3.m3.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.3.m3.1.2.1" xref="S3.SS1.p8.3.m3.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p8.3.m3.1.2.3.2" xref="S3.SS1.p8.3.m3.1.2.cmml"><mo stretchy="false" id="S3.SS1.p8.3.m3.1.2.3.2.1" xref="S3.SS1.p8.3.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p8.3.m3.1.1" xref="S3.SS1.p8.3.m3.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S3.SS1.p8.3.m3.1.2.3.2.2" xref="S3.SS1.p8.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.3.m3.1b"><apply id="S3.SS1.p8.3.m3.1.2.cmml" xref="S3.SS1.p8.3.m3.1.2"><times id="S3.SS1.p8.3.m3.1.2.1.cmml" xref="S3.SS1.p8.3.m3.1.2.1"></times><ci id="S3.SS1.p8.3.m3.1.2.2.cmml" xref="S3.SS1.p8.3.m3.1.2.2">ùê∫</ci><ci id="S3.SS1.p8.3.m3.1.1.cmml" xref="S3.SS1.p8.3.m3.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.3.m3.1c">G(\cdot)</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p9" class="ltx_para">
<p id="S3.SS1.p9.2" class="ltx_p">Since face forgery detection is essentially considered as a binary classification task, the cross-entropy loss function <math id="S3.SS1.p9.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS1.p9.1.m1.1a"><mi id="S3.SS1.p9.1.m1.1.1" xref="S3.SS1.p9.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.1.m1.1b"><ci id="S3.SS1.p9.1.m1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1">ùêø</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.1.m1.1c">L</annotation></semantics></math><sub id="S3.SS1.p9.2.1" class="ltx_sub"><span id="S3.SS1.p9.2.1.1" class="ltx_text ltx_font_italic">cls</span></sub> is used in formula (4) to evaluate the forgery detection performance as followed:</p>
</div>
<div id="S3.SS1.p10" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="L_{cls}=-log\ P(Res(x),y)," display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml">L</mi><mrow id="S3.E4.m1.3.3.1.1.3.3" xref="S3.E4.m1.3.3.1.1.3.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.3.1" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">‚Äã</mo><mi id="S3.E4.m1.3.3.1.1.3.3.3" xref="S3.E4.m1.3.3.1.1.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.3.1a" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">‚Äã</mo><mi id="S3.E4.m1.3.3.1.1.3.3.4" xref="S3.E4.m1.3.3.1.1.3.3.4.cmml">s</mi></mrow></msub><mo id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml"><mo id="S3.E4.m1.3.3.1.1.1a" xref="S3.E4.m1.3.3.1.1.1.cmml">‚àí</mo><mrow id="S3.E4.m1.3.3.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.E4.m1.3.3.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.2a" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.E4.m1.3.3.1.1.1.1.5" xref="S3.E4.m1.3.3.1.1.1.1.5.cmml">g</mi><mo lspace="0.500em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.2b" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.E4.m1.3.3.1.1.1.1.6" xref="S3.E4.m1.3.3.1.1.1.1.6.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.2c" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">(</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.cmml">‚Äã</mo><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1a" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.cmml">‚Äã</mo><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1b" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.cmml">‚Äã</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.5.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.5.2.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.5.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">y</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"></eq><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2">ùêø</ci><apply id="S3.E4.m1.3.3.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3"><times id="S3.E4.m1.3.3.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.3.1"></times><ci id="S3.E4.m1.3.3.1.1.3.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2">ùëê</ci><ci id="S3.E4.m1.3.3.1.1.3.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3.3">ùëô</ci><ci id="S3.E4.m1.3.3.1.1.3.3.4.cmml" xref="S3.E4.m1.3.3.1.1.3.3.4">ùë†</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"><minus id="S3.E4.m1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1"></minus><apply id="S3.E4.m1.3.3.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2"></times><ci id="S3.E4.m1.3.3.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.3">ùëô</ci><ci id="S3.E4.m1.3.3.1.1.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4">ùëú</ci><ci id="S3.E4.m1.3.3.1.1.1.1.5.cmml" xref="S3.E4.m1.3.3.1.1.1.1.5">ùëî</ci><ci id="S3.E4.m1.3.3.1.1.1.1.6.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6">ùëÉ</ci><interval closure="open" id="S3.E4.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1"><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1"></times><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2">ùëÖ</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.3">ùëí</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.4">ùë†</ci><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">ùë•</ci></apply><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">ùë¶</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">L_{cls}=-log\ P(Res(x),y),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p10.9" class="ltx_p">where <math id="S3.SS1.p10.1.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS1.p10.1.m1.1a"><mi id="S3.SS1.p10.1.m1.1.1" xref="S3.SS1.p10.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.1.m1.1b"><ci id="S3.SS1.p10.1.m1.1.1.cmml" xref="S3.SS1.p10.1.m1.1.1">ùëÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.1.m1.1c">P</annotation></semantics></math> means the prediction probability of the residual <math id="S3.SS1.p10.2.m2.1" class="ltx_Math" alttext="Res(x)" display="inline"><semantics id="S3.SS1.p10.2.m2.1a"><mrow id="S3.SS1.p10.2.m2.1.2" xref="S3.SS1.p10.2.m2.1.2.cmml"><mi id="S3.SS1.p10.2.m2.1.2.2" xref="S3.SS1.p10.2.m2.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p10.2.m2.1.2.1" xref="S3.SS1.p10.2.m2.1.2.1.cmml">‚Äã</mo><mi id="S3.SS1.p10.2.m2.1.2.3" xref="S3.SS1.p10.2.m2.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p10.2.m2.1.2.1a" xref="S3.SS1.p10.2.m2.1.2.1.cmml">‚Äã</mo><mi id="S3.SS1.p10.2.m2.1.2.4" xref="S3.SS1.p10.2.m2.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p10.2.m2.1.2.1b" xref="S3.SS1.p10.2.m2.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p10.2.m2.1.2.5.2" xref="S3.SS1.p10.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p10.2.m2.1.2.5.2.1" xref="S3.SS1.p10.2.m2.1.2.cmml">(</mo><mi id="S3.SS1.p10.2.m2.1.1" xref="S3.SS1.p10.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS1.p10.2.m2.1.2.5.2.2" xref="S3.SS1.p10.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.2.m2.1b"><apply id="S3.SS1.p10.2.m2.1.2.cmml" xref="S3.SS1.p10.2.m2.1.2"><times id="S3.SS1.p10.2.m2.1.2.1.cmml" xref="S3.SS1.p10.2.m2.1.2.1"></times><ci id="S3.SS1.p10.2.m2.1.2.2.cmml" xref="S3.SS1.p10.2.m2.1.2.2">ùëÖ</ci><ci id="S3.SS1.p10.2.m2.1.2.3.cmml" xref="S3.SS1.p10.2.m2.1.2.3">ùëí</ci><ci id="S3.SS1.p10.2.m2.1.2.4.cmml" xref="S3.SS1.p10.2.m2.1.2.4">ùë†</ci><ci id="S3.SS1.p10.2.m2.1.1.cmml" xref="S3.SS1.p10.2.m2.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.2.m2.1c">Res(x)</annotation></semantics></math> through the ClsNet.
<math id="S3.SS1.p10.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS1.p10.3.m3.1a"><mi id="S3.SS1.p10.3.m3.1.1" xref="S3.SS1.p10.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.3.m3.1b"><ci id="S3.SS1.p10.3.m3.1.1.cmml" xref="S3.SS1.p10.3.m3.1.1">ùë¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.3.m3.1c">y</annotation></semantics></math> is the label of the input face <math id="S3.SS1.p10.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p10.4.m4.1a"><mi id="S3.SS1.p10.4.m4.1.1" xref="S3.SS1.p10.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.4.m4.1b"><ci id="S3.SS1.p10.4.m4.1.1.cmml" xref="S3.SS1.p10.4.m4.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.4.m4.1c">x</annotation></semantics></math>.
In the following experiments, hyper-parameters are used to control the trade-off between reconstruction and classification tasks.
According to the experiment analysis shown in Section IV, we set the hyperparameters to be <math id="S3.SS1.p10.5.m5.1" class="ltx_Math" alttext="\mu_{1}" display="inline"><semantics id="S3.SS1.p10.5.m5.1a"><msub id="S3.SS1.p10.5.m5.1.1" xref="S3.SS1.p10.5.m5.1.1.cmml"><mi id="S3.SS1.p10.5.m5.1.1.2" xref="S3.SS1.p10.5.m5.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p10.5.m5.1.1.3" xref="S3.SS1.p10.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.5.m5.1b"><apply id="S3.SS1.p10.5.m5.1.1.cmml" xref="S3.SS1.p10.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p10.5.m5.1.1.1.cmml" xref="S3.SS1.p10.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p10.5.m5.1.1.2.cmml" xref="S3.SS1.p10.5.m5.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p10.5.m5.1.1.3.cmml" xref="S3.SS1.p10.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.5.m5.1c">\mu_{1}</annotation></semantics></math>=1, <math id="S3.SS1.p10.6.m6.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S3.SS1.p10.6.m6.1a"><msub id="S3.SS1.p10.6.m6.1.1" xref="S3.SS1.p10.6.m6.1.1.cmml"><mi id="S3.SS1.p10.6.m6.1.1.2" xref="S3.SS1.p10.6.m6.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p10.6.m6.1.1.3" xref="S3.SS1.p10.6.m6.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.6.m6.1b"><apply id="S3.SS1.p10.6.m6.1.1.cmml" xref="S3.SS1.p10.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p10.6.m6.1.1.1.cmml" xref="S3.SS1.p10.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p10.6.m6.1.1.2.cmml" xref="S3.SS1.p10.6.m6.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p10.6.m6.1.1.3.cmml" xref="S3.SS1.p10.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.6.m6.1c">\mu_{2}</annotation></semantics></math>=1, <math id="S3.SS1.p10.7.m7.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S3.SS1.p10.7.m7.1a"><msub id="S3.SS1.p10.7.m7.1.1" xref="S3.SS1.p10.7.m7.1.1.cmml"><mi id="S3.SS1.p10.7.m7.1.1.2" xref="S3.SS1.p10.7.m7.1.1.2.cmml">Œº</mi><mn id="S3.SS1.p10.7.m7.1.1.3" xref="S3.SS1.p10.7.m7.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.7.m7.1b"><apply id="S3.SS1.p10.7.m7.1.1.cmml" xref="S3.SS1.p10.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p10.7.m7.1.1.1.cmml" xref="S3.SS1.p10.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p10.7.m7.1.1.2.cmml" xref="S3.SS1.p10.7.m7.1.1.2">ùúá</ci><cn type="integer" id="S3.SS1.p10.7.m7.1.1.3.cmml" xref="S3.SS1.p10.7.m7.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.7.m7.1c">\mu_{3}</annotation></semantics></math>=1, <math id="S3.SS1.p10.8.m8.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p10.8.m8.1a"><mi id="S3.SS1.p10.8.m8.1.1" xref="S3.SS1.p10.8.m8.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.8.m8.1b"><ci id="S3.SS1.p10.8.m8.1.1.cmml" xref="S3.SS1.p10.8.m8.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.8.m8.1c">\alpha</annotation></semantics></math>=1, <math id="S3.SS1.p10.9.m9.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS1.p10.9.m9.1a"><mi id="S3.SS1.p10.9.m9.1.1" xref="S3.SS1.p10.9.m9.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p10.9.m9.1b"><ci id="S3.SS1.p10.9.m9.1.1.cmml" xref="S3.SS1.p10.9.m9.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p10.9.m9.1c">\beta</annotation></semantics></math>=4 respectively.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.44.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.45.2" class="ltx_text ltx_font_italic">Residual Federated Learning</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.25" class="ltx_p">To further improve the representation discriminability to detect different forgery artifact patterns, we design the residual federated learning strategy. The designed global model not only updates parameters through training decentralized data collaboratively to protect privacy, but also aggregates the captured discrepancy information in several local models in a federated learning strategy.
As shown in Figure 2, the residual federated learning framework is designed for the distributed forgery detection models deployment, which aims to mimic real-world scenarios.
There are <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">K</annotation></semantics></math> data centers in diverse local clients and forgery face datasets <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">D</annotation></semantics></math> are distributed and stored in each data center (<math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">D</annotation></semantics></math><sub id="S3.SS2.p1.25.1" class="ltx_sub"><span id="S3.SS2.p1.25.1.1" class="ltx_text ltx_font_italic">1</span></sub>‚Ä¶<math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">D</annotation></semantics></math><sub id="S3.SS2.p1.25.2" class="ltx_sub"><span id="S3.SS2.p1.25.2.1" class="ltx_text ltx_font_italic">K</span></sub>), satisfying <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mi id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">D</annotation></semantics></math>=<math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">D</annotation></semantics></math><math id="S3.SS2.p1.9.m9.1" class="ltx_math_unparsed" alttext="{}_{1}\cup...\cup" display="inline"><semantics id="S3.SS2.p1.9.m9.1a"><mrow id="S3.SS2.p1.9.m9.1b"><mmultiscripts id="S3.SS2.p1.9.m9.1.1"><mo id="S3.SS2.p1.9.m9.1.1.2">‚à™</mo><mprescripts id="S3.SS2.p1.9.m9.1.1a"></mprescripts><mn id="S3.SS2.p1.9.m9.1.1.3">1</mn><mrow id="S3.SS2.p1.9.m9.1.1b"></mrow></mmultiscripts><mi mathvariant="normal" id="S3.SS2.p1.9.m9.1.2">‚Ä¶</mi><mo id="S3.SS2.p1.9.m9.1.3">‚à™</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">{}_{1}\cup...\cup</annotation></semantics></math><math id="S3.SS2.p1.10.m10.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.10.m10.1a"><mi id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><ci id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">D</annotation></semantics></math><sub id="S3.SS2.p1.25.3" class="ltx_sub"><span id="S3.SS2.p1.25.3.1" class="ltx_text ltx_font_italic">K</span></sub> and <math id="S3.SS2.p1.12.m12.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.12.m12.1a"><mi id="S3.SS2.p1.12.m12.1.1" xref="S3.SS2.p1.12.m12.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m12.1b"><ci id="S3.SS2.p1.12.m12.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m12.1c">D</annotation></semantics></math><math id="S3.SS2.p1.13.m13.1" class="ltx_math_unparsed" alttext="{}_{1}\cap...\cap" display="inline"><semantics id="S3.SS2.p1.13.m13.1a"><mrow id="S3.SS2.p1.13.m13.1b"><mmultiscripts id="S3.SS2.p1.13.m13.1.1"><mo id="S3.SS2.p1.13.m13.1.1.2">‚à©</mo><mprescripts id="S3.SS2.p1.13.m13.1.1a"></mprescripts><mn id="S3.SS2.p1.13.m13.1.1.3">1</mn><mrow id="S3.SS2.p1.13.m13.1.1b"></mrow></mmultiscripts><mi mathvariant="normal" id="S3.SS2.p1.13.m13.1.2">‚Ä¶</mi><mo id="S3.SS2.p1.13.m13.1.3">‚à©</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m13.1c">{}_{1}\cap...\cap</annotation></semantics></math><math id="S3.SS2.p1.14.m14.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.14.m14.1a"><mi id="S3.SS2.p1.14.m14.1.1" xref="S3.SS2.p1.14.m14.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.14.m14.1b"><ci id="S3.SS2.p1.14.m14.1.1.cmml" xref="S3.SS2.p1.14.m14.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.14.m14.1c">D</annotation></semantics></math><sub id="S3.SS2.p1.25.4" class="ltx_sub"><span id="S3.SS2.p1.25.4.1" class="ltx_text ltx_font_italic">K</span></sub>=<math id="S3.SS2.p1.16.m16.1" class="ltx_Math" alttext="\varnothing" display="inline"><semantics id="S3.SS2.p1.16.m16.1a"><mi mathvariant="normal" id="S3.SS2.p1.16.m16.1.1" xref="S3.SS2.p1.16.m16.1.1.cmml">‚àÖ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.16.m16.1b"><emptyset id="S3.SS2.p1.16.m16.1.1.cmml" xref="S3.SS2.p1.16.m16.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.16.m16.1c">\varnothing</annotation></semantics></math>.
Additionally, the data set between each data center should be independent and cannot be exchanged.
Here each data center has a local face forgery detection model (<math id="S3.SS2.p1.17.m17.1" class="ltx_Math" alttext="FFD" display="inline"><semantics id="S3.SS2.p1.17.m17.1a"><mrow id="S3.SS2.p1.17.m17.1.1" xref="S3.SS2.p1.17.m17.1.1.cmml"><mi id="S3.SS2.p1.17.m17.1.1.2" xref="S3.SS2.p1.17.m17.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.17.m17.1.1.1" xref="S3.SS2.p1.17.m17.1.1.1.cmml">‚Äã</mo><mi id="S3.SS2.p1.17.m17.1.1.3" xref="S3.SS2.p1.17.m17.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.17.m17.1.1.1a" xref="S3.SS2.p1.17.m17.1.1.1.cmml">‚Äã</mo><mi id="S3.SS2.p1.17.m17.1.1.4" xref="S3.SS2.p1.17.m17.1.1.4.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.17.m17.1b"><apply id="S3.SS2.p1.17.m17.1.1.cmml" xref="S3.SS2.p1.17.m17.1.1"><times id="S3.SS2.p1.17.m17.1.1.1.cmml" xref="S3.SS2.p1.17.m17.1.1.1"></times><ci id="S3.SS2.p1.17.m17.1.1.2.cmml" xref="S3.SS2.p1.17.m17.1.1.2">ùêπ</ci><ci id="S3.SS2.p1.17.m17.1.1.3.cmml" xref="S3.SS2.p1.17.m17.1.1.3">ùêπ</ci><ci id="S3.SS2.p1.17.m17.1.1.4.cmml" xref="S3.SS2.p1.17.m17.1.1.4">ùê∑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.17.m17.1c">FFD</annotation></semantics></math>).
The global server will update model parameters according to these local parameters uploaded by each data center. The local <math id="S3.SS2.p1.18.m18.1" class="ltx_Math" alttext="FFD" display="inline"><semantics id="S3.SS2.p1.18.m18.1a"><mrow id="S3.SS2.p1.18.m18.1.1" xref="S3.SS2.p1.18.m18.1.1.cmml"><mi id="S3.SS2.p1.18.m18.1.1.2" xref="S3.SS2.p1.18.m18.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.18.m18.1.1.1" xref="S3.SS2.p1.18.m18.1.1.1.cmml">‚Äã</mo><mi id="S3.SS2.p1.18.m18.1.1.3" xref="S3.SS2.p1.18.m18.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.18.m18.1.1.1a" xref="S3.SS2.p1.18.m18.1.1.1.cmml">‚Äã</mo><mi id="S3.SS2.p1.18.m18.1.1.4" xref="S3.SS2.p1.18.m18.1.1.4.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.18.m18.1b"><apply id="S3.SS2.p1.18.m18.1.1.cmml" xref="S3.SS2.p1.18.m18.1.1"><times id="S3.SS2.p1.18.m18.1.1.1.cmml" xref="S3.SS2.p1.18.m18.1.1.1"></times><ci id="S3.SS2.p1.18.m18.1.1.2.cmml" xref="S3.SS2.p1.18.m18.1.1.2">ùêπ</ci><ci id="S3.SS2.p1.18.m18.1.1.3.cmml" xref="S3.SS2.p1.18.m18.1.1.3">ùêπ</ci><ci id="S3.SS2.p1.18.m18.1.1.4.cmml" xref="S3.SS2.p1.18.m18.1.1.4">ùê∑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.18.m18.1c">FFD</annotation></semantics></math> model by the <math id="S3.SS2.p1.19.m19.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.19.m19.1a"><mi id="S3.SS2.p1.19.m19.1.1" xref="S3.SS2.p1.19.m19.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.19.m19.1b"><ci id="S3.SS2.p1.19.m19.1.1.cmml" xref="S3.SS2.p1.19.m19.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.19.m19.1c">k</annotation></semantics></math>-th data center is parameterized by <math id="S3.SS2.p1.20.m20.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S3.SS2.p1.20.m20.1a"><mi id="S3.SS2.p1.20.m20.1.1" xref="S3.SS2.p1.20.m20.1.1.cmml">œâ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.20.m20.1b"><ci id="S3.SS2.p1.20.m20.1.1.cmml" xref="S3.SS2.p1.20.m20.1.1">ùúî</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.20.m20.1c">\omega</annotation></semantics></math> <sup id="S3.SS2.p1.25.5" class="ltx_sup"><span id="S3.SS2.p1.25.5.1" class="ltx_text ltx_font_italic">k</span></sup> (<math id="S3.SS2.p1.22.m22.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.22.m22.1a"><mi id="S3.SS2.p1.22.m22.1.1" xref="S3.SS2.p1.22.m22.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.22.m22.1b"><ci id="S3.SS2.p1.22.m22.1.1.cmml" xref="S3.SS2.p1.22.m22.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.22.m22.1c">k</annotation></semantics></math> = 1, 2, 3, ‚Ä¶ , <math id="S3.SS2.p1.23.m23.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p1.23.m23.1a"><mi id="S3.SS2.p1.23.m23.1.1" xref="S3.SS2.p1.23.m23.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.23.m23.1b"><ci id="S3.SS2.p1.23.m23.1.1.cmml" xref="S3.SS2.p1.23.m23.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.23.m23.1c">K</annotation></semantics></math>), denoted as <math id="S3.SS2.p1.24.m24.1" class="ltx_Math" alttext="FFD(\omega^{k})" display="inline"><semantics id="S3.SS2.p1.24.m24.1a"><mrow id="S3.SS2.p1.24.m24.1.1" xref="S3.SS2.p1.24.m24.1.1.cmml"><mi id="S3.SS2.p1.24.m24.1.1.3" xref="S3.SS2.p1.24.m24.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.24.m24.1.1.2" xref="S3.SS2.p1.24.m24.1.1.2.cmml">‚Äã</mo><mi id="S3.SS2.p1.24.m24.1.1.4" xref="S3.SS2.p1.24.m24.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.24.m24.1.1.2a" xref="S3.SS2.p1.24.m24.1.1.2.cmml">‚Äã</mo><mi id="S3.SS2.p1.24.m24.1.1.5" xref="S3.SS2.p1.24.m24.1.1.5.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.24.m24.1.1.2b" xref="S3.SS2.p1.24.m24.1.1.2.cmml">‚Äã</mo><mrow id="S3.SS2.p1.24.m24.1.1.1.1" xref="S3.SS2.p1.24.m24.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.24.m24.1.1.1.1.2" xref="S3.SS2.p1.24.m24.1.1.1.1.1.cmml">(</mo><msup id="S3.SS2.p1.24.m24.1.1.1.1.1" xref="S3.SS2.p1.24.m24.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.24.m24.1.1.1.1.1.2" xref="S3.SS2.p1.24.m24.1.1.1.1.1.2.cmml">œâ</mi><mi id="S3.SS2.p1.24.m24.1.1.1.1.1.3" xref="S3.SS2.p1.24.m24.1.1.1.1.1.3.cmml">k</mi></msup><mo stretchy="false" id="S3.SS2.p1.24.m24.1.1.1.1.3" xref="S3.SS2.p1.24.m24.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.24.m24.1b"><apply id="S3.SS2.p1.24.m24.1.1.cmml" xref="S3.SS2.p1.24.m24.1.1"><times id="S3.SS2.p1.24.m24.1.1.2.cmml" xref="S3.SS2.p1.24.m24.1.1.2"></times><ci id="S3.SS2.p1.24.m24.1.1.3.cmml" xref="S3.SS2.p1.24.m24.1.1.3">ùêπ</ci><ci id="S3.SS2.p1.24.m24.1.1.4.cmml" xref="S3.SS2.p1.24.m24.1.1.4">ùêπ</ci><ci id="S3.SS2.p1.24.m24.1.1.5.cmml" xref="S3.SS2.p1.24.m24.1.1.5">ùê∑</ci><apply id="S3.SS2.p1.24.m24.1.1.1.1.1.cmml" xref="S3.SS2.p1.24.m24.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.24.m24.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.24.m24.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p1.24.m24.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.24.m24.1.1.1.1.1.2">ùúî</ci><ci id="S3.SS2.p1.24.m24.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.24.m24.1.1.1.1.1.3">ùëò</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.24.m24.1c">FFD(\omega^{k})</annotation></semantics></math>.
As shown in formula (5), <math id="S3.SS2.p1.25.m25.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p1.25.m25.1a"><mi id="S3.SS2.p1.25.m25.1.1" xref="S3.SS2.p1.25.m25.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.25.m25.1b"><ci id="S3.SS2.p1.25.m25.1.1.cmml" xref="S3.SS2.p1.25.m25.1.1">ùêø</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.25.m25.1c">L</annotation></semantics></math> is the loss of the forgery detection model in each data center, its specific form is in equation (1).</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.6" class="ltx_Math" alttext="L_{FFD(\omega^{k})}=\sum_{(x,y)\sim D_{k}}L(x,y)." display="block"><semantics id="S3.E5.m1.6a"><mrow id="S3.E5.m1.6.6.1" xref="S3.E5.m1.6.6.1.1.cmml"><mrow id="S3.E5.m1.6.6.1.1" xref="S3.E5.m1.6.6.1.1.cmml"><msub id="S3.E5.m1.6.6.1.1.2" xref="S3.E5.m1.6.6.1.1.2.cmml"><mi id="S3.E5.m1.6.6.1.1.2.2" xref="S3.E5.m1.6.6.1.1.2.2.cmml">L</mi><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.E5.m1.1.1.1.4" xref="S3.E5.m1.1.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.2a" xref="S3.E5.m1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.E5.m1.1.1.1.5" xref="S3.E5.m1.1.1.1.5.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.2b" xref="S3.E5.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml">œâ</mi><mi id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.3.cmml">k</mi></msup><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo rspace="0.111em" id="S3.E5.m1.6.6.1.1.1" xref="S3.E5.m1.6.6.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.6.6.1.1.3" xref="S3.E5.m1.6.6.1.1.3.cmml"><munder id="S3.E5.m1.6.6.1.1.3.1" xref="S3.E5.m1.6.6.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E5.m1.6.6.1.1.3.1.2" xref="S3.E5.m1.6.6.1.1.3.1.2.cmml">‚àë</mo><mrow id="S3.E5.m1.3.3.2" xref="S3.E5.m1.3.3.2.cmml"><mrow id="S3.E5.m1.3.3.2.4.2" xref="S3.E5.m1.3.3.2.4.1.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.2.4.2.1" xref="S3.E5.m1.3.3.2.4.1.cmml">(</mo><mi id="S3.E5.m1.2.2.1.1" xref="S3.E5.m1.2.2.1.1.cmml">x</mi><mo id="S3.E5.m1.3.3.2.4.2.2" xref="S3.E5.m1.3.3.2.4.1.cmml">,</mo><mi id="S3.E5.m1.3.3.2.2" xref="S3.E5.m1.3.3.2.2.cmml">y</mi><mo stretchy="false" id="S3.E5.m1.3.3.2.4.2.3" xref="S3.E5.m1.3.3.2.4.1.cmml">)</mo></mrow><mo id="S3.E5.m1.3.3.2.3" xref="S3.E5.m1.3.3.2.3.cmml">‚àº</mo><msub id="S3.E5.m1.3.3.2.5" xref="S3.E5.m1.3.3.2.5.cmml"><mi id="S3.E5.m1.3.3.2.5.2" xref="S3.E5.m1.3.3.2.5.2.cmml">D</mi><mi id="S3.E5.m1.3.3.2.5.3" xref="S3.E5.m1.3.3.2.5.3.cmml">k</mi></msub></mrow></munder><mrow id="S3.E5.m1.6.6.1.1.3.2" xref="S3.E5.m1.6.6.1.1.3.2.cmml"><mi id="S3.E5.m1.6.6.1.1.3.2.2" xref="S3.E5.m1.6.6.1.1.3.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.6.6.1.1.3.2.1" xref="S3.E5.m1.6.6.1.1.3.2.1.cmml">‚Äã</mo><mrow id="S3.E5.m1.6.6.1.1.3.2.3.2" xref="S3.E5.m1.6.6.1.1.3.2.3.1.cmml"><mo stretchy="false" id="S3.E5.m1.6.6.1.1.3.2.3.2.1" xref="S3.E5.m1.6.6.1.1.3.2.3.1.cmml">(</mo><mi id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml">x</mi><mo id="S3.E5.m1.6.6.1.1.3.2.3.2.2" xref="S3.E5.m1.6.6.1.1.3.2.3.1.cmml">,</mo><mi id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml">y</mi><mo stretchy="false" id="S3.E5.m1.6.6.1.1.3.2.3.2.3" xref="S3.E5.m1.6.6.1.1.3.2.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E5.m1.6.6.1.2" xref="S3.E5.m1.6.6.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.6b"><apply id="S3.E5.m1.6.6.1.1.cmml" xref="S3.E5.m1.6.6.1"><eq id="S3.E5.m1.6.6.1.1.1.cmml" xref="S3.E5.m1.6.6.1.1.1"></eq><apply id="S3.E5.m1.6.6.1.1.2.cmml" xref="S3.E5.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.1.1.2.1.cmml" xref="S3.E5.m1.6.6.1.1.2">subscript</csymbol><ci id="S3.E5.m1.6.6.1.1.2.2.cmml" xref="S3.E5.m1.6.6.1.1.2.2">ùêø</ci><apply id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><times id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.2"></times><ci id="S3.E5.m1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.3">ùêπ</ci><ci id="S3.E5.m1.1.1.1.4.cmml" xref="S3.E5.m1.1.1.1.4">ùêπ</ci><ci id="S3.E5.m1.1.1.1.5.cmml" xref="S3.E5.m1.1.1.1.5">ùê∑</ci><apply id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2">ùúî</ci><ci id="S3.E5.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3">ùëò</ci></apply></apply></apply><apply id="S3.E5.m1.6.6.1.1.3.cmml" xref="S3.E5.m1.6.6.1.1.3"><apply id="S3.E5.m1.6.6.1.1.3.1.cmml" xref="S3.E5.m1.6.6.1.1.3.1"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.1.1.3.1.1.cmml" xref="S3.E5.m1.6.6.1.1.3.1">subscript</csymbol><sum id="S3.E5.m1.6.6.1.1.3.1.2.cmml" xref="S3.E5.m1.6.6.1.1.3.1.2"></sum><apply id="S3.E5.m1.3.3.2.cmml" xref="S3.E5.m1.3.3.2"><csymbol cd="latexml" id="S3.E5.m1.3.3.2.3.cmml" xref="S3.E5.m1.3.3.2.3">similar-to</csymbol><interval closure="open" id="S3.E5.m1.3.3.2.4.1.cmml" xref="S3.E5.m1.3.3.2.4.2"><ci id="S3.E5.m1.2.2.1.1.cmml" xref="S3.E5.m1.2.2.1.1">ùë•</ci><ci id="S3.E5.m1.3.3.2.2.cmml" xref="S3.E5.m1.3.3.2.2">ùë¶</ci></interval><apply id="S3.E5.m1.3.3.2.5.cmml" xref="S3.E5.m1.3.3.2.5"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.2.5.1.cmml" xref="S3.E5.m1.3.3.2.5">subscript</csymbol><ci id="S3.E5.m1.3.3.2.5.2.cmml" xref="S3.E5.m1.3.3.2.5.2">ùê∑</ci><ci id="S3.E5.m1.3.3.2.5.3.cmml" xref="S3.E5.m1.3.3.2.5.3">ùëò</ci></apply></apply></apply><apply id="S3.E5.m1.6.6.1.1.3.2.cmml" xref="S3.E5.m1.6.6.1.1.3.2"><times id="S3.E5.m1.6.6.1.1.3.2.1.cmml" xref="S3.E5.m1.6.6.1.1.3.2.1"></times><ci id="S3.E5.m1.6.6.1.1.3.2.2.cmml" xref="S3.E5.m1.6.6.1.1.3.2.2">ùêø</ci><interval closure="open" id="S3.E5.m1.6.6.1.1.3.2.3.1.cmml" xref="S3.E5.m1.6.6.1.1.3.2.3.2"><ci id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4">ùë•</ci><ci id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5">ùë¶</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.6c">L_{FFD(\omega^{k})}=\sum_{(x,y)\sim D_{k}}L(x,y).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.3" class="ltx_p">The global server will calculate aggregated model parameters according to formula (6) as followed:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\omega\leftarrow\sum_{k=1}^{K}p_{k}\omega^{k}," display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">œâ</mi><mo rspace="0.111em" stretchy="false" id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml">‚Üê</mo><mrow id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><munderover id="S3.E6.m1.1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E6.m1.1.1.1.1.3.1.2.2" xref="S3.E6.m1.1.1.1.1.3.1.2.2.cmml">‚àë</mo><mrow id="S3.E6.m1.1.1.1.1.3.1.2.3" xref="S3.E6.m1.1.1.1.1.3.1.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.1.2.3.2" xref="S3.E6.m1.1.1.1.1.3.1.2.3.2.cmml">k</mi><mo id="S3.E6.m1.1.1.1.1.3.1.2.3.1" xref="S3.E6.m1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.1.1.3.1.2.3.3" xref="S3.E6.m1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.1.1.1.1.3.1.3" xref="S3.E6.m1.1.1.1.1.3.1.3.cmml">K</mi></munderover><mrow id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml"><msub id="S3.E6.m1.1.1.1.1.3.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.2.cmml">p</mi><mi id="S3.E6.m1.1.1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.1.1.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.1" xref="S3.E6.m1.1.1.1.1.3.2.1.cmml">‚Äã</mo><msup id="S3.E6.m1.1.1.1.1.3.2.3" xref="S3.E6.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.3.2" xref="S3.E6.m1.1.1.1.1.3.2.3.2.cmml">œâ</mi><mi id="S3.E6.m1.1.1.1.1.3.2.3.3" xref="S3.E6.m1.1.1.1.1.3.2.3.3.cmml">k</mi></msup></mrow></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><ci id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1">‚Üê</ci><ci id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2">ùúî</ci><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><apply id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.1.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.3.1.2.cmml" xref="S3.E6.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1">subscript</csymbol><sum id="S3.E6.m1.1.1.1.1.3.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.1.2.2"></sum><apply id="S3.E6.m1.1.1.1.1.3.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.1.2.3"><eq id="S3.E6.m1.1.1.1.1.3.1.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1.2.3.1"></eq><ci id="S3.E6.m1.1.1.1.1.3.1.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.1.2.3.2">ùëò</ci><cn type="integer" id="S3.E6.m1.1.1.1.1.3.1.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.1.1.1.1.3.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3.1.3">ùêæ</ci></apply><apply id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2"><times id="S3.E6.m1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1"></times><apply id="S3.E6.m1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2">ùëù</ci><ci id="S3.E6.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3">ùëò</ci></apply><apply id="S3.E6.m1.1.1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3">superscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2">ùúî</ci><ci id="S3.E6.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.3">ùëò</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\omega\leftarrow\sum_{k=1}^{K}p_{k}\omega^{k},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.2" class="ltx_p">where p<sub id="S3.SS2.p3.2.1" class="ltx_sub"><span id="S3.SS2.p3.2.1.1" class="ltx_text ltx_font_italic">k</span></sub> is the proportion of the number of data points of the <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">k</annotation></semantics></math>-th participant to the total number of data points, which is also the weight of each local model when aggregated.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">To improve the forgery detection accuracy, we further extend the number of communication rounds between the global server and the data center to <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">t</annotation></semantics></math> rounds.
The detailed update strategy is shown in formula (7) as followed:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="\omega_{t}\leftarrow\sum_{k=1}^{K}p_{k}\omega_{t}^{k}," display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.2.cmml"><mi id="S3.E7.m1.1.1.1.1.2.2" xref="S3.E7.m1.1.1.1.1.2.2.cmml">œâ</mi><mi id="S3.E7.m1.1.1.1.1.2.3" xref="S3.E7.m1.1.1.1.1.2.3.cmml">t</mi></msub><mo rspace="0.111em" stretchy="false" id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.cmml">‚Üê</mo><mrow id="S3.E7.m1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.3.cmml"><munderover id="S3.E7.m1.1.1.1.1.3.1" xref="S3.E7.m1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E7.m1.1.1.1.1.3.1.2.2" xref="S3.E7.m1.1.1.1.1.3.1.2.2.cmml">‚àë</mo><mrow id="S3.E7.m1.1.1.1.1.3.1.2.3" xref="S3.E7.m1.1.1.1.1.3.1.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.1.2.3.2" xref="S3.E7.m1.1.1.1.1.3.1.2.3.2.cmml">k</mi><mo id="S3.E7.m1.1.1.1.1.3.1.2.3.1" xref="S3.E7.m1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E7.m1.1.1.1.1.3.1.2.3.3" xref="S3.E7.m1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E7.m1.1.1.1.1.3.1.3" xref="S3.E7.m1.1.1.1.1.3.1.3.cmml">K</mi></munderover><mrow id="S3.E7.m1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.3.2.cmml"><msub id="S3.E7.m1.1.1.1.1.3.2.2" xref="S3.E7.m1.1.1.1.1.3.2.2.cmml"><mi id="S3.E7.m1.1.1.1.1.3.2.2.2" xref="S3.E7.m1.1.1.1.1.3.2.2.2.cmml">p</mi><mi id="S3.E7.m1.1.1.1.1.3.2.2.3" xref="S3.E7.m1.1.1.1.1.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.2.1" xref="S3.E7.m1.1.1.1.1.3.2.1.cmml">‚Äã</mo><msubsup id="S3.E7.m1.1.1.1.1.3.2.3" xref="S3.E7.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.2.3.2.2" xref="S3.E7.m1.1.1.1.1.3.2.3.2.2.cmml">œâ</mi><mi id="S3.E7.m1.1.1.1.1.3.2.3.2.3" xref="S3.E7.m1.1.1.1.1.3.2.3.2.3.cmml">t</mi><mi id="S3.E7.m1.1.1.1.1.3.2.3.3" xref="S3.E7.m1.1.1.1.1.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow><mo id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><ci id="S3.E7.m1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1">‚Üê</ci><apply id="S3.E7.m1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.2.2">ùúî</ci><ci id="S3.E7.m1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.2.3">ùë°</ci></apply><apply id="S3.E7.m1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.3"><apply id="S3.E7.m1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.1.1.cmml" xref="S3.E7.m1.1.1.1.1.3.1">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.3.1.2.cmml" xref="S3.E7.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.1">subscript</csymbol><sum id="S3.E7.m1.1.1.1.1.3.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.1.2.2"></sum><apply id="S3.E7.m1.1.1.1.1.3.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.1.2.3"><eq id="S3.E7.m1.1.1.1.1.3.1.2.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.1.2.3.1"></eq><ci id="S3.E7.m1.1.1.1.1.3.1.2.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.1.2.3.2">ùëò</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.3.1.2.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E7.m1.1.1.1.1.3.1.3.cmml" xref="S3.E7.m1.1.1.1.1.3.1.3">ùêæ</ci></apply><apply id="S3.E7.m1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2"><times id="S3.E7.m1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.2.1"></times><apply id="S3.E7.m1.1.1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2.2.2">ùëù</ci><ci id="S3.E7.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.2.2.3">ùëò</ci></apply><apply id="S3.E7.m1.1.1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.2.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.2.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3.2.2">ùúî</ci><ci id="S3.E7.m1.1.1.1.1.3.2.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3.2.3">ùë°</ci></apply><ci id="S3.E7.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3.3">ùëò</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\omega_{t}\leftarrow\sum_{k=1}^{K}p_{k}\omega_{t}^{k},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p4.5" class="ltx_p">where <math id="S3.SS2.p4.2.m1.1" class="ltx_Math" alttext="\omega_{t}^{k}" display="inline"><semantics id="S3.SS2.p4.2.m1.1a"><msubsup id="S3.SS2.p4.2.m1.1.1" xref="S3.SS2.p4.2.m1.1.1.cmml"><mi id="S3.SS2.p4.2.m1.1.1.2.2" xref="S3.SS2.p4.2.m1.1.1.2.2.cmml">œâ</mi><mi id="S3.SS2.p4.2.m1.1.1.2.3" xref="S3.SS2.p4.2.m1.1.1.2.3.cmml">t</mi><mi id="S3.SS2.p4.2.m1.1.1.3" xref="S3.SS2.p4.2.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m1.1b"><apply id="S3.SS2.p4.2.m1.1.1.cmml" xref="S3.SS2.p4.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m1.1.1.1.cmml" xref="S3.SS2.p4.2.m1.1.1">superscript</csymbol><apply id="S3.SS2.p4.2.m1.1.1.2.cmml" xref="S3.SS2.p4.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m1.1.1.2.1.cmml" xref="S3.SS2.p4.2.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m1.1.1.2.2.cmml" xref="S3.SS2.p4.2.m1.1.1.2.2">ùúî</ci><ci id="S3.SS2.p4.2.m1.1.1.2.3.cmml" xref="S3.SS2.p4.2.m1.1.1.2.3">ùë°</ci></apply><ci id="S3.SS2.p4.2.m1.1.1.3.cmml" xref="S3.SS2.p4.2.m1.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m1.1c">\omega_{t}^{k}</annotation></semantics></math> represents the model parameters owned by the <math id="S3.SS2.p4.3.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p4.3.m2.1a"><mi id="S3.SS2.p4.3.m2.1.1" xref="S3.SS2.p4.3.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m2.1b"><ci id="S3.SS2.p4.3.m2.1.1.cmml" xref="S3.SS2.p4.3.m2.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m2.1c">k</annotation></semantics></math>-th data center in the <math id="S3.SS2.p4.4.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p4.4.m3.1a"><mi id="S3.SS2.p4.4.m3.1.1" xref="S3.SS2.p4.4.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m3.1b"><ci id="S3.SS2.p4.4.m3.1.1.cmml" xref="S3.SS2.p4.4.m3.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m3.1c">t</annotation></semantics></math>-th round of update. The initial parameters of the next round of data center models are issued after the weighted average of the global server.
After <math id="S3.SS2.p4.5.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p4.5.m4.1a"><mi id="S3.SS2.p4.5.m4.1.1" xref="S3.SS2.p4.5.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m4.1b"><ci id="S3.SS2.p4.5.m4.1.1.cmml" xref="S3.SS2.p4.5.m4.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m4.1c">t</annotation></semantics></math> rounds updates, the global server model can be obtained without accessing data privacy in local clients.</p>
</div>
<figure id="S3.SS2.39" class="ltx_table">
<table id="S3.SS2.39.39" class="ltx_tabular ltx_align_middle">
<tr id="S3.SS2.39.39.40" class="ltx_tr">
<td id="S3.SS2.39.39.40.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.SS2.39.39.40.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.39.39.40.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="S3.SS2.39.39.40.1.1.1.1" class="ltx_text ltx_font_bold">Algorithm 1.</span> FedForgery</span>
</span>
</td>
</tr>
<tr id="S3.SS2.5.5.5" class="ltx_tr">
<td id="S3.SS2.5.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.SS2.5.5.5.5.5" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.5.5.5.5.5.5" class="ltx_p" style="width:411.9pt;"><span id="S3.SS2.5.5.5.5.5.5.1" class="ltx_text ltx_font_bold">Require</span>: Local data center have <math id="S3.SS2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.1.1.1.1.1.1.m1.1a"><mi id="S3.SS2.1.1.1.1.1.1.m1.1.1" xref="S3.SS2.1.1.1.1.1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.1.1.1.1.1.1.m1.1b"><ci id="S3.SS2.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.SS2.1.1.1.1.1.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.1.1.1.1.1.1.m1.1c">K</annotation></semantics></math> Data centers <math id="S3.SS2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.2.2.2.2.2.2.m2.1a"><mi id="S3.SS2.2.2.2.2.2.2.m2.1.1" xref="S3.SS2.2.2.2.2.2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.2.2.2.2.2.2.m2.1b"><ci id="S3.SS2.2.2.2.2.2.2.m2.1.1.cmml" xref="S3.SS2.2.2.2.2.2.2.m2.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.2.2.2.2.2.2.m2.1c">D</annotation></semantics></math><sub id="S3.SS2.5.5.5.5.5.5.2" class="ltx_sub"><span id="S3.SS2.5.5.5.5.5.5.2.1" class="ltx_text ltx_font_italic">1</span></sub>, ‚Ä¶ , <math id="S3.SS2.4.4.4.4.4.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.4.4.4.4.4.4.m4.1a"><mi id="S3.SS2.4.4.4.4.4.4.m4.1.1" xref="S3.SS2.4.4.4.4.4.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.4.4.4.4.4.4.m4.1b"><ci id="S3.SS2.4.4.4.4.4.4.m4.1.1.cmml" xref="S3.SS2.4.4.4.4.4.4.m4.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.4.4.4.4.4.4.m4.1c">D</annotation></semantics></math><sub id="S3.SS2.5.5.5.5.5.5.3" class="ltx_sub"><span id="S3.SS2.5.5.5.5.5.5.3.1" class="ltx_text ltx_font_italic">K</span></sub>;</span>
</span>
</td>
</tr>
<tr id="S3.SS2.12.12.12" class="ltx_tr">
<td id="S3.SS2.12.12.12.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.12.12.12.7.7" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.12.12.12.7.7.7" class="ltx_p" style="width:411.9pt;"><span id="S3.SS2.12.12.12.7.7.7.1" class="ltx_text ltx_font_bold">1</span>: <math id="S3.SS2.6.6.6.1.1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.6.6.6.1.1.1.m1.1a"><mi id="S3.SS2.6.6.6.1.1.1.m1.1.1" xref="S3.SS2.6.6.6.1.1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.6.6.6.1.1.1.m1.1b"><ci id="S3.SS2.6.6.6.1.1.1.m1.1.1.cmml" xref="S3.SS2.6.6.6.1.1.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.6.6.6.1.1.1.m1.1c">K</annotation></semantics></math> data centers have <math id="S3.SS2.7.7.7.2.2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.7.7.7.2.2.2.m2.1a"><mi id="S3.SS2.7.7.7.2.2.2.m2.1.1" xref="S3.SS2.7.7.7.2.2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.7.7.7.2.2.2.m2.1b"><ci id="S3.SS2.7.7.7.2.2.2.m2.1.1.cmml" xref="S3.SS2.7.7.7.2.2.2.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.7.7.7.2.2.2.m2.1c">K</annotation></semantics></math> face forgery detection models(<math id="S3.SS2.8.8.8.3.3.3.m3.1" class="ltx_Math" alttext="FFD" display="inline"><semantics id="S3.SS2.8.8.8.3.3.3.m3.1a"><mrow id="S3.SS2.8.8.8.3.3.3.m3.1.1" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.cmml"><mi id="S3.SS2.8.8.8.3.3.3.m3.1.1.2" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.8.8.8.3.3.3.m3.1.1.1" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.1.cmml">‚Äã</mo><mi id="S3.SS2.8.8.8.3.3.3.m3.1.1.3" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.8.8.8.3.3.3.m3.1.1.1a" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.1.cmml">‚Äã</mo><mi id="S3.SS2.8.8.8.3.3.3.m3.1.1.4" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.4.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.8.8.8.3.3.3.m3.1b"><apply id="S3.SS2.8.8.8.3.3.3.m3.1.1.cmml" xref="S3.SS2.8.8.8.3.3.3.m3.1.1"><times id="S3.SS2.8.8.8.3.3.3.m3.1.1.1.cmml" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.1"></times><ci id="S3.SS2.8.8.8.3.3.3.m3.1.1.2.cmml" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.2">ùêπ</ci><ci id="S3.SS2.8.8.8.3.3.3.m3.1.1.3.cmml" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.3">ùêπ</ci><ci id="S3.SS2.8.8.8.3.3.3.m3.1.1.4.cmml" xref="S3.SS2.8.8.8.3.3.3.m3.1.1.4">ùê∑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.8.8.8.3.3.3.m3.1c">FFD</annotation></semantics></math>) parameterized by <math id="S3.SS2.9.9.9.4.4.4.m4.1" class="ltx_Math" alttext="w^{K}" display="inline"><semantics id="S3.SS2.9.9.9.4.4.4.m4.1a"><msup id="S3.SS2.9.9.9.4.4.4.m4.1.1" xref="S3.SS2.9.9.9.4.4.4.m4.1.1.cmml"><mi id="S3.SS2.9.9.9.4.4.4.m4.1.1.2" xref="S3.SS2.9.9.9.4.4.4.m4.1.1.2.cmml">w</mi><mi id="S3.SS2.9.9.9.4.4.4.m4.1.1.3" xref="S3.SS2.9.9.9.4.4.4.m4.1.1.3.cmml">K</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.9.9.9.4.4.4.m4.1b"><apply id="S3.SS2.9.9.9.4.4.4.m4.1.1.cmml" xref="S3.SS2.9.9.9.4.4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.9.9.9.4.4.4.m4.1.1.1.cmml" xref="S3.SS2.9.9.9.4.4.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.9.9.9.4.4.4.m4.1.1.2.cmml" xref="S3.SS2.9.9.9.4.4.4.m4.1.1.2">ùë§</ci><ci id="S3.SS2.9.9.9.4.4.4.m4.1.1.3.cmml" xref="S3.SS2.9.9.9.4.4.4.m4.1.1.3">ùêæ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.9.9.9.4.4.4.m4.1c">w^{K}</annotation></semantics></math>, <math id="S3.SS2.10.10.10.5.5.5.m5.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS2.10.10.10.5.5.5.m5.1a"><mi id="S3.SS2.10.10.10.5.5.5.m5.1.1" xref="S3.SS2.10.10.10.5.5.5.m5.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.10.10.10.5.5.5.m5.1b"><ci id="S3.SS2.10.10.10.5.5.5.m5.1.1.cmml" xref="S3.SS2.10.10.10.5.5.5.m5.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.10.10.10.5.5.5.m5.1c">E</annotation></semantics></math> is the number of epochs for the local train, <math id="S3.SS2.11.11.11.6.6.6.m6.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.11.11.11.6.6.6.m6.1a"><mi id="S3.SS2.11.11.11.6.6.6.m6.1.1" xref="S3.SS2.11.11.11.6.6.6.m6.1.1.cmml">Œª</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.11.11.11.6.6.6.m6.1b"><ci id="S3.SS2.11.11.11.6.6.6.m6.1.1.cmml" xref="S3.SS2.11.11.11.6.6.6.m6.1.1">ùúÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.11.11.11.6.6.6.m6.1c">\lambda</annotation></semantics></math> is the learning rate, <math id="S3.SS2.12.12.12.7.7.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.12.12.12.7.7.7.m7.1a"><mi id="S3.SS2.12.12.12.7.7.7.m7.1.1" xref="S3.SS2.12.12.12.7.7.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.12.12.12.7.7.7.m7.1b"><ci id="S3.SS2.12.12.12.7.7.7.m7.1.1.cmml" xref="S3.SS2.12.12.12.7.7.7.m7.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.12.12.12.7.7.7.m7.1c">t</annotation></semantics></math> is the number of rounds of global communications between the local data center and global server;</span>
</span>
</td>
</tr>
<tr id="S3.SS2.13.13.13" class="ltx_tr">
<td id="S3.SS2.13.13.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.13.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.13.13.13.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="S3.SS2.13.13.13.1.1.1.1" class="ltx_text ltx_font_bold">2</span>: Global Server Aggregates: initialize <math id="S3.SS2.13.13.13.1.1.1.m1.1" class="ltx_Math" alttext="w_{0}" display="inline"><semantics id="S3.SS2.13.13.13.1.1.1.m1.1a"><msub id="S3.SS2.13.13.13.1.1.1.m1.1.1" xref="S3.SS2.13.13.13.1.1.1.m1.1.1.cmml"><mi id="S3.SS2.13.13.13.1.1.1.m1.1.1.2" xref="S3.SS2.13.13.13.1.1.1.m1.1.1.2.cmml">w</mi><mn id="S3.SS2.13.13.13.1.1.1.m1.1.1.3" xref="S3.SS2.13.13.13.1.1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.13.13.13.1.1.1.m1.1b"><apply id="S3.SS2.13.13.13.1.1.1.m1.1.1.cmml" xref="S3.SS2.13.13.13.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.13.13.13.1.1.1.m1.1.1.1.cmml" xref="S3.SS2.13.13.13.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.13.13.13.1.1.1.m1.1.1.2.cmml" xref="S3.SS2.13.13.13.1.1.1.m1.1.1.2">ùë§</ci><cn type="integer" id="S3.SS2.13.13.13.1.1.1.m1.1.1.3.cmml" xref="S3.SS2.13.13.13.1.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.13.13.13.1.1.1.m1.1c">w_{0}</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S3.SS2.16.16.16" class="ltx_tr">
<td id="S3.SS2.16.16.16.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.16.16.16.3.3" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.14.14.14.1.1.1" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉfor each round <math id="S3.SS2.14.14.14.1.1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.14.14.14.1.1.1.m1.1a"><mi id="S3.SS2.14.14.14.1.1.1.m1.1.1" xref="S3.SS2.14.14.14.1.1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.14.14.14.1.1.1.m1.1b"><ci id="S3.SS2.14.14.14.1.1.1.m1.1.1.cmml" xref="S3.SS2.14.14.14.1.1.1.m1.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.14.14.14.1.1.1.m1.1c">t</annotation></semantics></math>=0, 1, ‚Ä¶ , do</span>
<span id="S3.SS2.16.16.16.3.3.3" class="ltx_p">for each Data Center <math id="S3.SS2.15.15.15.2.2.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.15.15.15.2.2.2.m1.1a"><mi id="S3.SS2.15.15.15.2.2.2.m1.1.1" xref="S3.SS2.15.15.15.2.2.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.15.15.15.2.2.2.m1.1b"><ci id="S3.SS2.15.15.15.2.2.2.m1.1.1.cmml" xref="S3.SS2.15.15.15.2.2.2.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.15.15.15.2.2.2.m1.1c">k</annotation></semantics></math>=1, 2, ‚Ä¶ , <math id="S3.SS2.16.16.16.3.3.3.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.16.16.16.3.3.3.m2.1a"><mi id="S3.SS2.16.16.16.3.3.3.m2.1.1" xref="S3.SS2.16.16.16.3.3.3.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.16.16.16.3.3.3.m2.1b"><ci id="S3.SS2.16.16.16.3.3.3.m2.1.1.cmml" xref="S3.SS2.16.16.16.3.3.3.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.16.16.16.3.3.3.m2.1c">K</annotation></semantics></math> in parallel do</span>
</span>
</td>
</tr>
<tr id="S3.SS2.20.20.20" class="ltx_tr">
<td id="S3.SS2.20.20.20.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.20.20.20.4.4" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.20.20.20.4.4.4" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉ‚ÄÉ<math id="S3.SS2.17.17.17.1.1.1.m1.1" class="ltx_Math" alttext="\omega_{t}^{k}" display="inline"><semantics id="S3.SS2.17.17.17.1.1.1.m1.1a"><msubsup id="S3.SS2.17.17.17.1.1.1.m1.1.1" xref="S3.SS2.17.17.17.1.1.1.m1.1.1.cmml"><mi id="S3.SS2.17.17.17.1.1.1.m1.1.1.2.2" xref="S3.SS2.17.17.17.1.1.1.m1.1.1.2.2.cmml">œâ</mi><mi id="S3.SS2.17.17.17.1.1.1.m1.1.1.2.3" xref="S3.SS2.17.17.17.1.1.1.m1.1.1.2.3.cmml">t</mi><mi id="S3.SS2.17.17.17.1.1.1.m1.1.1.3" xref="S3.SS2.17.17.17.1.1.1.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.17.17.17.1.1.1.m1.1b"><apply id="S3.SS2.17.17.17.1.1.1.m1.1.1.cmml" xref="S3.SS2.17.17.17.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.17.17.17.1.1.1.m1.1.1.1.cmml" xref="S3.SS2.17.17.17.1.1.1.m1.1.1">superscript</csymbol><apply id="S3.SS2.17.17.17.1.1.1.m1.1.1.2.cmml" xref="S3.SS2.17.17.17.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.17.17.17.1.1.1.m1.1.1.2.1.cmml" xref="S3.SS2.17.17.17.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.17.17.17.1.1.1.m1.1.1.2.2.cmml" xref="S3.SS2.17.17.17.1.1.1.m1.1.1.2.2">ùúî</ci><ci id="S3.SS2.17.17.17.1.1.1.m1.1.1.2.3.cmml" xref="S3.SS2.17.17.17.1.1.1.m1.1.1.2.3">ùë°</ci></apply><ci id="S3.SS2.17.17.17.1.1.1.m1.1.1.3.cmml" xref="S3.SS2.17.17.17.1.1.1.m1.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.17.17.17.1.1.1.m1.1c">\omega_{t}^{k}</annotation></semantics></math> <math id="S3.SS2.18.18.18.2.2.2.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="S3.SS2.18.18.18.2.2.2.m2.1a"><mo stretchy="false" id="S3.SS2.18.18.18.2.2.2.m2.1.1" xref="S3.SS2.18.18.18.2.2.2.m2.1.1.cmml">‚Üê</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.18.18.18.2.2.2.m2.1b"><ci id="S3.SS2.18.18.18.2.2.2.m2.1.1.cmml" xref="S3.SS2.18.18.18.2.2.2.m2.1.1">‚Üê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.18.18.18.2.2.2.m2.1c">\leftarrow</annotation></semantics></math> Data Center Update(<math id="S3.SS2.19.19.19.3.3.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.19.19.19.3.3.3.m3.1a"><mi id="S3.SS2.19.19.19.3.3.3.m3.1.1" xref="S3.SS2.19.19.19.3.3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.19.19.19.3.3.3.m3.1b"><ci id="S3.SS2.19.19.19.3.3.3.m3.1.1.cmml" xref="S3.SS2.19.19.19.3.3.3.m3.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.19.19.19.3.3.3.m3.1c">k</annotation></semantics></math>, <math id="S3.SS2.20.20.20.4.4.4.m4.1" class="ltx_Math" alttext="\omega_{t}" display="inline"><semantics id="S3.SS2.20.20.20.4.4.4.m4.1a"><msub id="S3.SS2.20.20.20.4.4.4.m4.1.1" xref="S3.SS2.20.20.20.4.4.4.m4.1.1.cmml"><mi id="S3.SS2.20.20.20.4.4.4.m4.1.1.2" xref="S3.SS2.20.20.20.4.4.4.m4.1.1.2.cmml">œâ</mi><mi id="S3.SS2.20.20.20.4.4.4.m4.1.1.3" xref="S3.SS2.20.20.20.4.4.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.20.20.20.4.4.4.m4.1b"><apply id="S3.SS2.20.20.20.4.4.4.m4.1.1.cmml" xref="S3.SS2.20.20.20.4.4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.20.20.20.4.4.4.m4.1.1.1.cmml" xref="S3.SS2.20.20.20.4.4.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.20.20.20.4.4.4.m4.1.1.2.cmml" xref="S3.SS2.20.20.20.4.4.4.m4.1.1.2">ùúî</ci><ci id="S3.SS2.20.20.20.4.4.4.m4.1.1.3.cmml" xref="S3.SS2.20.20.20.4.4.4.m4.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.20.20.20.4.4.4.m4.1c">\omega_{t}</annotation></semantics></math>)</span>
</span>
</td>
</tr>
<tr id="S3.SS2.39.39.41" class="ltx_tr">
<td id="S3.SS2.39.39.41.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.39.39.41.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.39.39.41.1.1.1" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉ‚ÄÉend for</span>
</span>
</td>
</tr>
<tr id="S3.SS2.25.25.25" class="ltx_tr">
<td id="S3.SS2.25.25.25.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.25.25.25.5.5" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.25.25.25.5.5.5" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉ‚ÄÉ<math id="S3.SS2.21.21.21.1.1.1.m1.1" class="ltx_Math" alttext="\omega_{t}" display="inline"><semantics id="S3.SS2.21.21.21.1.1.1.m1.1a"><msub id="S3.SS2.21.21.21.1.1.1.m1.1.1" xref="S3.SS2.21.21.21.1.1.1.m1.1.1.cmml"><mi id="S3.SS2.21.21.21.1.1.1.m1.1.1.2" xref="S3.SS2.21.21.21.1.1.1.m1.1.1.2.cmml">œâ</mi><mi id="S3.SS2.21.21.21.1.1.1.m1.1.1.3" xref="S3.SS2.21.21.21.1.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.21.21.21.1.1.1.m1.1b"><apply id="S3.SS2.21.21.21.1.1.1.m1.1.1.cmml" xref="S3.SS2.21.21.21.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.21.21.21.1.1.1.m1.1.1.1.cmml" xref="S3.SS2.21.21.21.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.21.21.21.1.1.1.m1.1.1.2.cmml" xref="S3.SS2.21.21.21.1.1.1.m1.1.1.2">ùúî</ci><ci id="S3.SS2.21.21.21.1.1.1.m1.1.1.3.cmml" xref="S3.SS2.21.21.21.1.1.1.m1.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.21.21.21.1.1.1.m1.1c">\omega_{t}</annotation></semantics></math> <math id="S3.SS2.22.22.22.2.2.2.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="S3.SS2.22.22.22.2.2.2.m2.1a"><mo stretchy="false" id="S3.SS2.22.22.22.2.2.2.m2.1.1" xref="S3.SS2.22.22.22.2.2.2.m2.1.1.cmml">‚Üê</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.22.22.22.2.2.2.m2.1b"><ci id="S3.SS2.22.22.22.2.2.2.m2.1.1.cmml" xref="S3.SS2.22.22.22.2.2.2.m2.1.1">‚Üê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.22.22.22.2.2.2.m2.1c">\leftarrow</annotation></semantics></math> <math id="S3.SS2.23.23.23.3.3.3.m3.1" class="ltx_Math" alttext="\sum_{k=1}^{K}" display="inline"><semantics id="S3.SS2.23.23.23.3.3.3.m3.1a"><msubsup id="S3.SS2.23.23.23.3.3.3.m3.1.1" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.cmml"><mo id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.2" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.2.cmml">‚àë</mo><mrow id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.cmml"><mi id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.2" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.2.cmml">k</mi><mo id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.1" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.1.cmml">=</mo><mn id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.3" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.3.cmml">1</mn></mrow><mi id="S3.SS2.23.23.23.3.3.3.m3.1.1.3" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.3.cmml">K</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.23.23.23.3.3.3.m3.1b"><apply id="S3.SS2.23.23.23.3.3.3.m3.1.1.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.23.23.23.3.3.3.m3.1.1.1.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.1.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1">subscript</csymbol><sum id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.2.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.2"></sum><apply id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3"><eq id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.1.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.1"></eq><ci id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.2.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.2">ùëò</ci><cn type="integer" id="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.3.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.2.3.3">1</cn></apply></apply><ci id="S3.SS2.23.23.23.3.3.3.m3.1.1.3.cmml" xref="S3.SS2.23.23.23.3.3.3.m3.1.1.3">ùêæ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.23.23.23.3.3.3.m3.1c">\sum_{k=1}^{K}</annotation></semantics></math> <math id="S3.SS2.24.24.24.4.4.4.m4.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S3.SS2.24.24.24.4.4.4.m4.1a"><msub id="S3.SS2.24.24.24.4.4.4.m4.1.1" xref="S3.SS2.24.24.24.4.4.4.m4.1.1.cmml"><mi id="S3.SS2.24.24.24.4.4.4.m4.1.1.2" xref="S3.SS2.24.24.24.4.4.4.m4.1.1.2.cmml">p</mi><mi id="S3.SS2.24.24.24.4.4.4.m4.1.1.3" xref="S3.SS2.24.24.24.4.4.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.24.24.24.4.4.4.m4.1b"><apply id="S3.SS2.24.24.24.4.4.4.m4.1.1.cmml" xref="S3.SS2.24.24.24.4.4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.24.24.24.4.4.4.m4.1.1.1.cmml" xref="S3.SS2.24.24.24.4.4.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.24.24.24.4.4.4.m4.1.1.2.cmml" xref="S3.SS2.24.24.24.4.4.4.m4.1.1.2">ùëù</ci><ci id="S3.SS2.24.24.24.4.4.4.m4.1.1.3.cmml" xref="S3.SS2.24.24.24.4.4.4.m4.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.24.24.24.4.4.4.m4.1c">p_{k}</annotation></semantics></math> <math id="S3.SS2.25.25.25.5.5.5.m5.1" class="ltx_Math" alttext="\omega_{t}^{k}" display="inline"><semantics id="S3.SS2.25.25.25.5.5.5.m5.1a"><msubsup id="S3.SS2.25.25.25.5.5.5.m5.1.1" xref="S3.SS2.25.25.25.5.5.5.m5.1.1.cmml"><mi id="S3.SS2.25.25.25.5.5.5.m5.1.1.2.2" xref="S3.SS2.25.25.25.5.5.5.m5.1.1.2.2.cmml">œâ</mi><mi id="S3.SS2.25.25.25.5.5.5.m5.1.1.2.3" xref="S3.SS2.25.25.25.5.5.5.m5.1.1.2.3.cmml">t</mi><mi id="S3.SS2.25.25.25.5.5.5.m5.1.1.3" xref="S3.SS2.25.25.25.5.5.5.m5.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.25.25.25.5.5.5.m5.1b"><apply id="S3.SS2.25.25.25.5.5.5.m5.1.1.cmml" xref="S3.SS2.25.25.25.5.5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.25.25.25.5.5.5.m5.1.1.1.cmml" xref="S3.SS2.25.25.25.5.5.5.m5.1.1">superscript</csymbol><apply id="S3.SS2.25.25.25.5.5.5.m5.1.1.2.cmml" xref="S3.SS2.25.25.25.5.5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.25.25.25.5.5.5.m5.1.1.2.1.cmml" xref="S3.SS2.25.25.25.5.5.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.25.25.25.5.5.5.m5.1.1.2.2.cmml" xref="S3.SS2.25.25.25.5.5.5.m5.1.1.2.2">ùúî</ci><ci id="S3.SS2.25.25.25.5.5.5.m5.1.1.2.3.cmml" xref="S3.SS2.25.25.25.5.5.5.m5.1.1.2.3">ùë°</ci></apply><ci id="S3.SS2.25.25.25.5.5.5.m5.1.1.3.cmml" xref="S3.SS2.25.25.25.5.5.5.m5.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.25.25.25.5.5.5.m5.1c">\omega_{t}^{k}</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S3.SS2.26.26.26" class="ltx_tr">
<td id="S3.SS2.26.26.26.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.26.26.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.26.26.26.1.1.1" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉ‚ÄÉDownload <math id="S3.SS2.26.26.26.1.1.1.m1.1" class="ltx_Math" alttext="\omega_{t}" display="inline"><semantics id="S3.SS2.26.26.26.1.1.1.m1.1a"><msub id="S3.SS2.26.26.26.1.1.1.m1.1.1" xref="S3.SS2.26.26.26.1.1.1.m1.1.1.cmml"><mi id="S3.SS2.26.26.26.1.1.1.m1.1.1.2" xref="S3.SS2.26.26.26.1.1.1.m1.1.1.2.cmml">œâ</mi><mi id="S3.SS2.26.26.26.1.1.1.m1.1.1.3" xref="S3.SS2.26.26.26.1.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.26.26.26.1.1.1.m1.1b"><apply id="S3.SS2.26.26.26.1.1.1.m1.1.1.cmml" xref="S3.SS2.26.26.26.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.26.26.26.1.1.1.m1.1.1.1.cmml" xref="S3.SS2.26.26.26.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.26.26.26.1.1.1.m1.1.1.2.cmml" xref="S3.SS2.26.26.26.1.1.1.m1.1.1.2">ùúî</ci><ci id="S3.SS2.26.26.26.1.1.1.m1.1.1.3.cmml" xref="S3.SS2.26.26.26.1.1.1.m1.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.26.26.26.1.1.1.m1.1c">\omega_{t}</annotation></semantics></math> to Data Centers</span>
</span>
</td>
</tr>
<tr id="S3.SS2.39.39.42" class="ltx_tr">
<td id="S3.SS2.39.39.42.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.39.39.42.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.39.39.42.1.1.1" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉend for</span>
</span>
</td>
</tr>
<tr id="S3.SS2.28.28.28" class="ltx_tr">
<td id="S3.SS2.28.28.28.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.28.28.28.2.2" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.28.28.28.2.2.2" class="ltx_p" style="width:411.9pt;"><span id="S3.SS2.28.28.28.2.2.2.1" class="ltx_text ltx_font_bold">3</span>: Data Center Update(<math id="S3.SS2.27.27.27.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.27.27.27.1.1.1.m1.1a"><mi id="S3.SS2.27.27.27.1.1.1.m1.1.1" xref="S3.SS2.27.27.27.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.27.27.27.1.1.1.m1.1b"><ci id="S3.SS2.27.27.27.1.1.1.m1.1.1.cmml" xref="S3.SS2.27.27.27.1.1.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.27.27.27.1.1.1.m1.1c">k</annotation></semantics></math>, <math id="S3.SS2.28.28.28.2.2.2.m2.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S3.SS2.28.28.28.2.2.2.m2.1a"><mi id="S3.SS2.28.28.28.2.2.2.m2.1.1" xref="S3.SS2.28.28.28.2.2.2.m2.1.1.cmml">œâ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.28.28.28.2.2.2.m2.1b"><ci id="S3.SS2.28.28.28.2.2.2.m2.1.1.cmml" xref="S3.SS2.28.28.28.2.2.2.m2.1.1">ùúî</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.28.28.28.2.2.2.m2.1c">\omega</annotation></semantics></math>)</span>
</span>
</td>
</tr>
<tr id="S3.SS2.30.30.30" class="ltx_tr">
<td id="S3.SS2.30.30.30.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.30.30.30.2.2" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.30.30.30.2.2.2" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉfor each local epoch <math id="S3.SS2.29.29.29.1.1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.29.29.29.1.1.1.m1.1a"><mi id="S3.SS2.29.29.29.1.1.1.m1.1.1" xref="S3.SS2.29.29.29.1.1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.29.29.29.1.1.1.m1.1b"><ci id="S3.SS2.29.29.29.1.1.1.m1.1.1.cmml" xref="S3.SS2.29.29.29.1.1.1.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.29.29.29.1.1.1.m1.1c">i</annotation></semantics></math> from 1 to <math id="S3.SS2.30.30.30.2.2.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS2.30.30.30.2.2.2.m2.1a"><mi id="S3.SS2.30.30.30.2.2.2.m2.1.1" xref="S3.SS2.30.30.30.2.2.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.30.30.30.2.2.2.m2.1b"><ci id="S3.SS2.30.30.30.2.2.2.m2.1.1.cmml" xref="S3.SS2.30.30.30.2.2.2.m2.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.30.30.30.2.2.2.m2.1c">E</annotation></semantics></math> do</span>
</span>
</td>
</tr>
<tr id="S3.SS2.31.31.31" class="ltx_tr">
<td id="S3.SS2.31.31.31.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.31.31.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.31.31.31.1.1.1" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉ‚ÄÉ<math id="S3.SS2.31.31.31.1.1.1.m1.5" class="ltx_Math" alttext="min\ L_{FFD(\omega^{k})}=\sum_{(x,y)\sim D_{k}}L(x,y)" display="inline"><semantics id="S3.SS2.31.31.31.1.1.1.m1.5a"><mrow id="S3.SS2.31.31.31.1.1.1.m1.5.6" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.cmml"><mrow id="S3.SS2.31.31.31.1.1.1.m1.5.6.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.cmml"><mi id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1.cmml">‚Äã</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.3" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1a" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1.cmml">‚Äã</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.4" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.4.cmml">n</mi><mo lspace="0.500em" rspace="0em" id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1b" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1.cmml">‚Äã</mo><msub id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5.cmml"><mi id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5.2.cmml">L</mi><mrow id="S3.SS2.31.31.31.1.1.1.m1.1.1.1" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.cmml"><mi id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.3" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.4" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2a" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2.cmml">‚Äã</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.5" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.5.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2b" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.2" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.2" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.2.cmml">œâ</mi><mi id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.3" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.3.cmml">k</mi></msup><mo stretchy="false" id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.3" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow><mo rspace="0.111em" id="S3.SS2.31.31.31.1.1.1.m1.5.6.1" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.1.cmml">=</mo><mrow id="S3.SS2.31.31.31.1.1.1.m1.5.6.3" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.cmml"><msub id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1.cmml"><mo id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1.2.cmml">‚àë</mo><mrow id="S3.SS2.31.31.31.1.1.1.m1.3.3.2" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.cmml"><mrow id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.2" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.1.cmml"><mo stretchy="false" id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.2.1" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.1.cmml">(</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.2.2.1.1" xref="S3.SS2.31.31.31.1.1.1.m1.2.2.1.1.cmml">x</mi><mo id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.2.2" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.1.cmml">,</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.2" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.2.3" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.1.cmml">)</mo></mrow><mo id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.3" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.3.cmml">‚àº</mo><msub id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.cmml"><mi id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.2" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.2.cmml">D</mi><mi id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.3" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.3.cmml">k</mi></msub></mrow></msub><mrow id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.cmml"><mi id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.1" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.1.cmml">‚Äã</mo><mrow id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.2.1" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.1.cmml">(</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.4.4" xref="S3.SS2.31.31.31.1.1.1.m1.4.4.cmml">x</mi><mo id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.2.2" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.1.cmml">,</mo><mi id="S3.SS2.31.31.31.1.1.1.m1.5.5" xref="S3.SS2.31.31.31.1.1.1.m1.5.5.cmml">y</mi><mo stretchy="false" id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.2.3" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.31.31.31.1.1.1.m1.5b"><apply id="S3.SS2.31.31.31.1.1.1.m1.5.6.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6"><eq id="S3.SS2.31.31.31.1.1.1.m1.5.6.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.1"></eq><apply id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2"><times id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.1"></times><ci id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.2">ùëö</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.3.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.3">ùëñ</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.4.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.4">ùëõ</ci><apply id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5"><csymbol cd="ambiguous" id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5">subscript</csymbol><ci id="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.2.5.2">ùêø</ci><apply id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1"><times id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.2"></times><ci id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.3.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.3">ùêπ</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.4.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.4">ùêπ</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.5.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.5">ùê∑</ci><apply id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.2">ùúî</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.1.1.1.1.1.1.3">ùëò</ci></apply></apply></apply></apply><apply id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3"><apply id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1"><csymbol cd="ambiguous" id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1">subscript</csymbol><sum id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.1.2"></sum><apply id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2"><csymbol cd="latexml" id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.3.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.3">similar-to</csymbol><interval closure="open" id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.4.2"><ci id="S3.SS2.31.31.31.1.1.1.m1.2.2.1.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.2.2.1.1">ùë•</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.2">ùë¶</ci></interval><apply id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5"><csymbol cd="ambiguous" id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5">subscript</csymbol><ci id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.2">ùê∑</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.3.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.3.3.2.5.3">ùëò</ci></apply></apply></apply><apply id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2"><times id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.1"></times><ci id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.2.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.2">ùêø</ci><interval closure="open" id="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.1.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.6.3.2.3.2"><ci id="S3.SS2.31.31.31.1.1.1.m1.4.4.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.4.4">ùë•</ci><ci id="S3.SS2.31.31.31.1.1.1.m1.5.5.cmml" xref="S3.SS2.31.31.31.1.1.1.m1.5.5">ùë¶</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.31.31.31.1.1.1.m1.5c">min\ L_{FFD(\omega^{k})}=\sum_{(x,y)\sim D_{k}}L(x,y)</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S3.SS2.38.38.38" class="ltx_tr">
<td id="S3.SS2.38.38.38.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.38.38.38.7.7" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.38.38.38.7.7.7" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉ‚ÄÉ<math id="S3.SS2.32.32.32.1.1.1.m1.1" class="ltx_Math" alttext="\omega^{k}" display="inline"><semantics id="S3.SS2.32.32.32.1.1.1.m1.1a"><msup id="S3.SS2.32.32.32.1.1.1.m1.1.1" xref="S3.SS2.32.32.32.1.1.1.m1.1.1.cmml"><mi id="S3.SS2.32.32.32.1.1.1.m1.1.1.2" xref="S3.SS2.32.32.32.1.1.1.m1.1.1.2.cmml">œâ</mi><mi id="S3.SS2.32.32.32.1.1.1.m1.1.1.3" xref="S3.SS2.32.32.32.1.1.1.m1.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.32.32.32.1.1.1.m1.1b"><apply id="S3.SS2.32.32.32.1.1.1.m1.1.1.cmml" xref="S3.SS2.32.32.32.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.32.32.32.1.1.1.m1.1.1.1.cmml" xref="S3.SS2.32.32.32.1.1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.32.32.32.1.1.1.m1.1.1.2.cmml" xref="S3.SS2.32.32.32.1.1.1.m1.1.1.2">ùúî</ci><ci id="S3.SS2.32.32.32.1.1.1.m1.1.1.3.cmml" xref="S3.SS2.32.32.32.1.1.1.m1.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.32.32.32.1.1.1.m1.1c">\omega^{k}</annotation></semantics></math> <math id="S3.SS2.33.33.33.2.2.2.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="S3.SS2.33.33.33.2.2.2.m2.1a"><mo stretchy="false" id="S3.SS2.33.33.33.2.2.2.m2.1.1" xref="S3.SS2.33.33.33.2.2.2.m2.1.1.cmml">‚Üê</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.33.33.33.2.2.2.m2.1b"><ci id="S3.SS2.33.33.33.2.2.2.m2.1.1.cmml" xref="S3.SS2.33.33.33.2.2.2.m2.1.1">‚Üê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.33.33.33.2.2.2.m2.1c">\leftarrow</annotation></semantics></math> <math id="S3.SS2.34.34.34.3.3.3.m3.1" class="ltx_Math" alttext="\omega^{k}" display="inline"><semantics id="S3.SS2.34.34.34.3.3.3.m3.1a"><msup id="S3.SS2.34.34.34.3.3.3.m3.1.1" xref="S3.SS2.34.34.34.3.3.3.m3.1.1.cmml"><mi id="S3.SS2.34.34.34.3.3.3.m3.1.1.2" xref="S3.SS2.34.34.34.3.3.3.m3.1.1.2.cmml">œâ</mi><mi id="S3.SS2.34.34.34.3.3.3.m3.1.1.3" xref="S3.SS2.34.34.34.3.3.3.m3.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.34.34.34.3.3.3.m3.1b"><apply id="S3.SS2.34.34.34.3.3.3.m3.1.1.cmml" xref="S3.SS2.34.34.34.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.34.34.34.3.3.3.m3.1.1.1.cmml" xref="S3.SS2.34.34.34.3.3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.34.34.34.3.3.3.m3.1.1.2.cmml" xref="S3.SS2.34.34.34.3.3.3.m3.1.1.2">ùúî</ci><ci id="S3.SS2.34.34.34.3.3.3.m3.1.1.3.cmml" xref="S3.SS2.34.34.34.3.3.3.m3.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.34.34.34.3.3.3.m3.1c">\omega^{k}</annotation></semantics></math> <math id="S3.SS2.35.35.35.4.4.4.m4.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S3.SS2.35.35.35.4.4.4.m4.1a"><mo id="S3.SS2.35.35.35.4.4.4.m4.1.1" xref="S3.SS2.35.35.35.4.4.4.m4.1.1.cmml">‚àí</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.35.35.35.4.4.4.m4.1b"><minus id="S3.SS2.35.35.35.4.4.4.m4.1.1.cmml" xref="S3.SS2.35.35.35.4.4.4.m4.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.35.35.35.4.4.4.m4.1c">-</annotation></semantics></math> <math id="S3.SS2.36.36.36.5.5.5.m5.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.36.36.36.5.5.5.m5.1a"><mi id="S3.SS2.36.36.36.5.5.5.m5.1.1" xref="S3.SS2.36.36.36.5.5.5.m5.1.1.cmml">Œª</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.36.36.36.5.5.5.m5.1b"><ci id="S3.SS2.36.36.36.5.5.5.m5.1.1.cmml" xref="S3.SS2.36.36.36.5.5.5.m5.1.1">ùúÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.36.36.36.5.5.5.m5.1c">\lambda</annotation></semantics></math> <math id="S3.SS2.37.37.37.6.6.6.m6.1" class="ltx_Math" alttext="\nabla" display="inline"><semantics id="S3.SS2.37.37.37.6.6.6.m6.1a"><mo id="S3.SS2.37.37.37.6.6.6.m6.1.1" xref="S3.SS2.37.37.37.6.6.6.m6.1.1.cmml">‚àá</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.37.37.37.6.6.6.m6.1b"><ci id="S3.SS2.37.37.37.6.6.6.m6.1.1.cmml" xref="S3.SS2.37.37.37.6.6.6.m6.1.1">‚àá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.37.37.37.6.6.6.m6.1c">\nabla</annotation></semantics></math> FFD(<math id="S3.SS2.38.38.38.7.7.7.m7.1" class="ltx_Math" alttext="\omega^{k}" display="inline"><semantics id="S3.SS2.38.38.38.7.7.7.m7.1a"><msup id="S3.SS2.38.38.38.7.7.7.m7.1.1" xref="S3.SS2.38.38.38.7.7.7.m7.1.1.cmml"><mi id="S3.SS2.38.38.38.7.7.7.m7.1.1.2" xref="S3.SS2.38.38.38.7.7.7.m7.1.1.2.cmml">œâ</mi><mi id="S3.SS2.38.38.38.7.7.7.m7.1.1.3" xref="S3.SS2.38.38.38.7.7.7.m7.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.38.38.38.7.7.7.m7.1b"><apply id="S3.SS2.38.38.38.7.7.7.m7.1.1.cmml" xref="S3.SS2.38.38.38.7.7.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.38.38.38.7.7.7.m7.1.1.1.cmml" xref="S3.SS2.38.38.38.7.7.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.38.38.38.7.7.7.m7.1.1.2.cmml" xref="S3.SS2.38.38.38.7.7.7.m7.1.1.2">ùúî</ci><ci id="S3.SS2.38.38.38.7.7.7.m7.1.1.3.cmml" xref="S3.SS2.38.38.38.7.7.7.m7.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.38.38.38.7.7.7.m7.1c">\omega^{k}</annotation></semantics></math>)</span>
</span>
</td>
</tr>
<tr id="S3.SS2.39.39.43" class="ltx_tr">
<td id="S3.SS2.39.39.43.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.SS2.39.39.43.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.39.39.43.1.1.1" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉend for</span>
</span>
</td>
</tr>
<tr id="S3.SS2.39.39.39" class="ltx_tr">
<td id="S3.SS2.39.39.39.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S3.SS2.39.39.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.SS2.39.39.39.1.1.1" class="ltx_p" style="width:411.9pt;">‚ÄÉ‚ÄÉUpload <math id="S3.SS2.39.39.39.1.1.1.m1.1" class="ltx_Math" alttext="\omega^{k}" display="inline"><semantics id="S3.SS2.39.39.39.1.1.1.m1.1a"><msup id="S3.SS2.39.39.39.1.1.1.m1.1.1" xref="S3.SS2.39.39.39.1.1.1.m1.1.1.cmml"><mi id="S3.SS2.39.39.39.1.1.1.m1.1.1.2" xref="S3.SS2.39.39.39.1.1.1.m1.1.1.2.cmml">œâ</mi><mi id="S3.SS2.39.39.39.1.1.1.m1.1.1.3" xref="S3.SS2.39.39.39.1.1.1.m1.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.39.39.39.1.1.1.m1.1b"><apply id="S3.SS2.39.39.39.1.1.1.m1.1.1.cmml" xref="S3.SS2.39.39.39.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.39.39.39.1.1.1.m1.1.1.1.cmml" xref="S3.SS2.39.39.39.1.1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.39.39.39.1.1.1.m1.1.1.2.cmml" xref="S3.SS2.39.39.39.1.1.1.m1.1.1.2">ùúî</ci><ci id="S3.SS2.39.39.39.1.1.1.m1.1.1.3.cmml" xref="S3.SS2.39.39.39.1.1.1.m1.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.39.39.39.1.1.1.m1.1c">\omega^{k}</annotation></semantics></math> to global server</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.3" class="ltx_p">The detailed procedures of the proposed FedForgery are shown in <span id="S3.SS2.p5.3.1" class="ltx_text ltx_font_bold">Algorithm 1</span>.
The variational autoencoder analyzes the difference of the reconstruction residual <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="Res(x)" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mrow id="S3.SS2.p5.1.m1.1.2" xref="S3.SS2.p5.1.m1.1.2.cmml"><mi id="S3.SS2.p5.1.m1.1.2.2" xref="S3.SS2.p5.1.m1.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.1.m1.1.2.1" xref="S3.SS2.p5.1.m1.1.2.1.cmml">‚Äã</mo><mi id="S3.SS2.p5.1.m1.1.2.3" xref="S3.SS2.p5.1.m1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.1.m1.1.2.1a" xref="S3.SS2.p5.1.m1.1.2.1.cmml">‚Äã</mo><mi id="S3.SS2.p5.1.m1.1.2.4" xref="S3.SS2.p5.1.m1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.1.m1.1.2.1b" xref="S3.SS2.p5.1.m1.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS2.p5.1.m1.1.2.5.2" xref="S3.SS2.p5.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p5.1.m1.1.2.5.2.1" xref="S3.SS2.p5.1.m1.1.2.cmml">(</mo><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS2.p5.1.m1.1.2.5.2.2" xref="S3.SS2.p5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.2"><times id="S3.SS2.p5.1.m1.1.2.1.cmml" xref="S3.SS2.p5.1.m1.1.2.1"></times><ci id="S3.SS2.p5.1.m1.1.2.2.cmml" xref="S3.SS2.p5.1.m1.1.2.2">ùëÖ</ci><ci id="S3.SS2.p5.1.m1.1.2.3.cmml" xref="S3.SS2.p5.1.m1.1.2.3">ùëí</ci><ci id="S3.SS2.p5.1.m1.1.2.4.cmml" xref="S3.SS2.p5.1.m1.1.2.4">ùë†</ci><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">Res(x)</annotation></semantics></math> between real and fake images.
The classification network ClsNet is used to process the residual image <math id="S3.SS2.p5.2.m2.1" class="ltx_Math" alttext="Res(x)" display="inline"><semantics id="S3.SS2.p5.2.m2.1a"><mrow id="S3.SS2.p5.2.m2.1.2" xref="S3.SS2.p5.2.m2.1.2.cmml"><mi id="S3.SS2.p5.2.m2.1.2.2" xref="S3.SS2.p5.2.m2.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.2.m2.1.2.1" xref="S3.SS2.p5.2.m2.1.2.1.cmml">‚Äã</mo><mi id="S3.SS2.p5.2.m2.1.2.3" xref="S3.SS2.p5.2.m2.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.2.m2.1.2.1a" xref="S3.SS2.p5.2.m2.1.2.1.cmml">‚Äã</mo><mi id="S3.SS2.p5.2.m2.1.2.4" xref="S3.SS2.p5.2.m2.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.2.m2.1.2.1b" xref="S3.SS2.p5.2.m2.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS2.p5.2.m2.1.2.5.2" xref="S3.SS2.p5.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS2.p5.2.m2.1.2.5.2.1" xref="S3.SS2.p5.2.m2.1.2.cmml">(</mo><mi id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS2.p5.2.m2.1.2.5.2.2" xref="S3.SS2.p5.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.2.cmml" xref="S3.SS2.p5.2.m2.1.2"><times id="S3.SS2.p5.2.m2.1.2.1.cmml" xref="S3.SS2.p5.2.m2.1.2.1"></times><ci id="S3.SS2.p5.2.m2.1.2.2.cmml" xref="S3.SS2.p5.2.m2.1.2.2">ùëÖ</ci><ci id="S3.SS2.p5.2.m2.1.2.3.cmml" xref="S3.SS2.p5.2.m2.1.2.3">ùëí</ci><ci id="S3.SS2.p5.2.m2.1.2.4.cmml" xref="S3.SS2.p5.2.m2.1.2.4">ùë†</ci><ci id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">Res(x)</annotation></semantics></math> to output the final prediction result.
The federated learning distributed framework is used to train and deploy the forgery detection model, and upload model parameters <math id="S3.SS2.p5.3.m3.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S3.SS2.p5.3.m3.1a"><mi id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml">œâ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><ci id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">ùúî</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">\omega</annotation></semantics></math> from different local data centers to the global server for boosting generalization and protecting data privacy.
Noting that the proposed FedForgery not only protects the data privacy of non-public videos through distributed storage, but also improves the discriminative representation avoid overfitting to distinguish the authenticity.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we first introduce the representative public face forgery datasets: FaceForensics++, WildDeepfake and Deeperforensics-1.0.
Then the self-constructed datasets Hybrid-domin forgery dataset and generalized forgery dataset are introduced to evaluate the performance in hybrid dataset and generalized dataset face forgery detection tasks.
In addition, we further evaluate the novel generalized residual federated learning for face Forgery detection algorithm and compare it with state-of-the-art methods.</p>
</div>
<section id="S4.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Datasets</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In this paper, we use three public datasets: FaceForensics++ dataset (abbreviated as FF++), WildDeepfake dataset and Deepforensic-1.0 dataset.
Example samples are shown in Figure 3.
It is noted that the large-scale Deepforensic-1.0 dataset can help evaluate the method‚Äôs ability for real-world face forgery detection tasks.
In addition, we constructed two datasets: Hybrid-domain forgery dataset and generalized forgery dataset to mimic complex real-world scenarios.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">FaceForensics++</span> The FaceForensics++ dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> is a benchmark dataset for evaluating face forgery detection methods. It consists of 1000 real videos extracted from YouTube, in addition to using four different algorithms to generate their corresponding fake videos, respectively DeepFakes (DF), Face2Face (F2F) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, FaceSwap (FS) and NeuralTextures (NT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. In addition, there are three different compression factors, corresponding to the original video (c0), the high compression rate video (c40), and the lower compression rate video (c23). Our experiments are all based on the c23 compression format.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">WildDeepfake</span>
The WildDeepfake dataset contains 7314 face sequences extracted from 707 deepfake videos <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. The videos in WildDeepfake are all collected from the Internet, and the sources are different, and some videos may have been compressed many times, which makes the detection of the WildDeepfake dataset more challenging, so it is often used as a benchmark video to evaluate the performance of deepfake detection models.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Hybrid-domain forgery dataset</span>
To effectively evaluate the proposed FedForgery performance in mentioned hybrid-dataset face forgery detection task, we utilize these two public datasets to construct a novel Hybrid-domain forgery dataset.
The details of the designed protocol are shown as follows: combine four diverse forgery subtypes of the FF++ dataset and the WildDeepfake dataset into the whole dataset with five different artifact types;
the training set contains 100,000 images where true images have the same number of fake images;
the ratio of the training set and testing set is kept at 7: 3.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Generalized forgery dataset</span>
To effectively evaluate the proposed FedForgery performance in mentioned generalized-dataset face forgery detection task, we utilize these two public datasets to construct a novel generalized forgery dataset.
The details of the designed protocol are shown as follows:
the forgery artifact types in the training set of each data center are diverse, and the forgery artifact type in the testing set of the global server is different from the training set;
choose four artifact types of the training set from the mentioned Hybrid-domain forgery dataset each time, and the last artifact type is selected as the testing set on the global server.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p"><span id="S4.SS1.p6.1.1" class="ltx_text ltx_font_bold">Large-scale Deeperforensics-1.0</span> The Deepforensics-1.0 dataset<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> is a large-scale and widely used real-world face forgery detection benchmark, which consists of 1000 high-quality videos in total. The fake videos are generated by an end-to-end face swap framework. The split ratio of the training, validation and test set is 7:1:2. With the same protocol in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, we compare the proposed FedForgery with representative algorithms to prove the strong avoid overfitting.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2210.09563/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="80" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The samples of public face forgery datasets: (a) WildDeepfake. (b) DeepFakes. (c) Face2Face. (d) FaceSwap. (e) NeuralTexture. (f) Deepforensics-1.0.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Implement Details</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Preprocessing</span>
We select the Dlib <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> tool to detect faces to reduce disturbance of complex background.
Next, we normalize all aligned faces and resize them to the size of 296√ó296.
We perform frame-by-frame extraction on the video dataset.
The proposed deep network model is implemented on the PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> platform.
We utilize a variational autoencoder with several convolutional layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> to reconstruct input images and the pre-trained Resnet 50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> as the classifier following.
We employ SGD with a momentum factor of 0.5. The initial learning rate is 0.01.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Federated learning settings</span>
In the following experiment, we set 10 diverse data centers as local clients, and allocate the same number of datasets to each data center.
The local training batch size is set to 32.
All data centers participate in the aggregation update process of model parameters.
After a round of completing the training steps in each data center, we upload local center training model parameters to the global server to aggregate and update the parameters.
The global server then sends the updated parameters to each local data center.
Finally, the global server model is evaluated on the testing set.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">We conducted experiments on the settings of cyber-parameters in the FedFogery method.
For the convenience of experiments, we sampled 10% images from the WildDeepfake dataset.
Here we utilized the simple grid search strategy to choose optimal hyper-parameters manually.
To promise the choices of hyperparameter choice is optimal for other kinds of cases, we conduct the optimal parameter choices in two different kinds of datasets (WildDeepfake and Hybrid-domain forgery datasets) as shown in Figure 4.
</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.6" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Influence of parameter <math id="S4.SS2.p4.1.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p4.1.1.m1.1a"><mi id="S4.SS2.p4.1.1.m1.1.1" xref="S4.SS2.p4.1.1.m1.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.1.m1.1b"><ci id="S4.SS2.p4.1.1.m1.1.1.cmml" xref="S4.SS2.p4.1.1.m1.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.1.m1.1c">\beta</annotation></semantics></math></span>
To evaluate the effect of parameter <math id="S4.SS2.p4.2.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p4.2.m1.1a"><mi id="S4.SS2.p4.2.m1.1.1" xref="S4.SS2.p4.2.m1.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m1.1b"><ci id="S4.SS2.p4.2.m1.1.1.cmml" xref="S4.SS2.p4.2.m1.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m1.1c">\beta</annotation></semantics></math> on the evaluation performance, parameters of different sizes are selected to conduct experiments on different kinds of datasets.
In the left subgraph of Figure 4, we evaluate the effect of parameter <math id="S4.SS2.p4.3.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p4.3.m2.1a"><mi id="S4.SS2.p4.3.m2.1.1" xref="S4.SS2.p4.3.m2.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m2.1b"><ci id="S4.SS2.p4.3.m2.1.1.cmml" xref="S4.SS2.p4.3.m2.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m2.1c">\beta</annotation></semantics></math> from a set of {0.10, 0.50, 1.00, 2.00, 3.00, 4.00, 5.00, 7.00} is illustrated when we set parameter <math id="S4.SS2.p4.4.m3.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.SS2.p4.4.m3.1a"><msub id="S4.SS2.p4.4.m3.1.1" xref="S4.SS2.p4.4.m3.1.1.cmml"><mi id="S4.SS2.p4.4.m3.1.1.2" xref="S4.SS2.p4.4.m3.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p4.4.m3.1.1.3" xref="S4.SS2.p4.4.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m3.1b"><apply id="S4.SS2.p4.4.m3.1.1.cmml" xref="S4.SS2.p4.4.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.4.m3.1.1.1.cmml" xref="S4.SS2.p4.4.m3.1.1">subscript</csymbol><ci id="S4.SS2.p4.4.m3.1.1.2.cmml" xref="S4.SS2.p4.4.m3.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p4.4.m3.1.1.3.cmml" xref="S4.SS2.p4.4.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m3.1c">\mu_{2}</annotation></semantics></math> as 1 and <math id="S4.SS2.p4.5.m4.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.SS2.p4.5.m4.1a"><msub id="S4.SS2.p4.5.m4.1.1" xref="S4.SS2.p4.5.m4.1.1.cmml"><mi id="S4.SS2.p4.5.m4.1.1.2" xref="S4.SS2.p4.5.m4.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p4.5.m4.1.1.3" xref="S4.SS2.p4.5.m4.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m4.1b"><apply id="S4.SS2.p4.5.m4.1.1.cmml" xref="S4.SS2.p4.5.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.5.m4.1.1.1.cmml" xref="S4.SS2.p4.5.m4.1.1">subscript</csymbol><ci id="S4.SS2.p4.5.m4.1.1.2.cmml" xref="S4.SS2.p4.5.m4.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p4.5.m4.1.1.3.cmml" xref="S4.SS2.p4.5.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m4.1c">\mu_{3}</annotation></semantics></math> as 1. We find that when the parameter <math id="S4.SS2.p4.6.m5.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p4.6.m5.1a"><mi id="S4.SS2.p4.6.m5.1.1" xref="S4.SS2.p4.6.m5.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.6.m5.1b"><ci id="S4.SS2.p4.6.m5.1.1.cmml" xref="S4.SS2.p4.6.m5.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.6.m5.1c">\beta</annotation></semantics></math> is set as 4, the forgery detection accuracy becomes better. It is because the suitable weight of encoder alignment terms could improve generative model performance.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.6" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">Influence of parameter <math id="S4.SS2.p5.1.1.m1.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.SS2.p5.1.1.m1.1a"><msub id="S4.SS2.p5.1.1.m1.1.1" xref="S4.SS2.p5.1.1.m1.1.1.cmml"><mi id="S4.SS2.p5.1.1.m1.1.1.2" xref="S4.SS2.p5.1.1.m1.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p5.1.1.m1.1.1.3" xref="S4.SS2.p5.1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.1.m1.1b"><apply id="S4.SS2.p5.1.1.m1.1.1.cmml" xref="S4.SS2.p5.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.1.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p5.1.1.m1.1.1.2.cmml" xref="S4.SS2.p5.1.1.m1.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p5.1.1.m1.1.1.3.cmml" xref="S4.SS2.p5.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.1.m1.1c">\mu_{2}</annotation></semantics></math></span>
We also investigated the effect of another parameter <math id="S4.SS2.p5.2.m1.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.SS2.p5.2.m1.1a"><msub id="S4.SS2.p5.2.m1.1.1" xref="S4.SS2.p5.2.m1.1.1.cmml"><mi id="S4.SS2.p5.2.m1.1.1.2" xref="S4.SS2.p5.2.m1.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p5.2.m1.1.1.3" xref="S4.SS2.p5.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m1.1b"><apply id="S4.SS2.p5.2.m1.1.1.cmml" xref="S4.SS2.p5.2.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.2.m1.1.1.1.cmml" xref="S4.SS2.p5.2.m1.1.1">subscript</csymbol><ci id="S4.SS2.p5.2.m1.1.1.2.cmml" xref="S4.SS2.p5.2.m1.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p5.2.m1.1.1.3.cmml" xref="S4.SS2.p5.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m1.1c">\mu_{2}</annotation></semantics></math> on different kinds of datasets.
In the middle subgraph of Figure 4, we evaluate the effect of parameter <math id="S4.SS2.p5.3.m2.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.SS2.p5.3.m2.1a"><msub id="S4.SS2.p5.3.m2.1.1" xref="S4.SS2.p5.3.m2.1.1.cmml"><mi id="S4.SS2.p5.3.m2.1.1.2" xref="S4.SS2.p5.3.m2.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p5.3.m2.1.1.3" xref="S4.SS2.p5.3.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.3.m2.1b"><apply id="S4.SS2.p5.3.m2.1.1.cmml" xref="S4.SS2.p5.3.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.3.m2.1.1.1.cmml" xref="S4.SS2.p5.3.m2.1.1">subscript</csymbol><ci id="S4.SS2.p5.3.m2.1.1.2.cmml" xref="S4.SS2.p5.3.m2.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p5.3.m2.1.1.3.cmml" xref="S4.SS2.p5.3.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.3.m2.1c">\mu_{2}</annotation></semantics></math> from a set of {0.10, 0.30, 0.70, 1.00, 2.00} is illustrated when we set parameter <math id="S4.SS2.p5.4.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p5.4.m3.1a"><mi id="S4.SS2.p5.4.m3.1.1" xref="S4.SS2.p5.4.m3.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.4.m3.1b"><ci id="S4.SS2.p5.4.m3.1.1.cmml" xref="S4.SS2.p5.4.m3.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.4.m3.1c">\beta</annotation></semantics></math> as 4 and <math id="S4.SS2.p5.5.m4.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.SS2.p5.5.m4.1a"><msub id="S4.SS2.p5.5.m4.1.1" xref="S4.SS2.p5.5.m4.1.1.cmml"><mi id="S4.SS2.p5.5.m4.1.1.2" xref="S4.SS2.p5.5.m4.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p5.5.m4.1.1.3" xref="S4.SS2.p5.5.m4.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.5.m4.1b"><apply id="S4.SS2.p5.5.m4.1.1.cmml" xref="S4.SS2.p5.5.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.5.m4.1.1.1.cmml" xref="S4.SS2.p5.5.m4.1.1">subscript</csymbol><ci id="S4.SS2.p5.5.m4.1.1.2.cmml" xref="S4.SS2.p5.5.m4.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p5.5.m4.1.1.3.cmml" xref="S4.SS2.p5.5.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.5.m4.1c">\mu_{3}</annotation></semantics></math> as 1. The weights of the pixel reconstruction would affect the exploration of forgery clues in the pixel level. We find that when parameter <math id="S4.SS2.p5.6.m5.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.SS2.p5.6.m5.1a"><msub id="S4.SS2.p5.6.m5.1.1" xref="S4.SS2.p5.6.m5.1.1.cmml"><mi id="S4.SS2.p5.6.m5.1.1.2" xref="S4.SS2.p5.6.m5.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p5.6.m5.1.1.3" xref="S4.SS2.p5.6.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.6.m5.1b"><apply id="S4.SS2.p5.6.m5.1.1.cmml" xref="S4.SS2.p5.6.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.6.m5.1.1.1.cmml" xref="S4.SS2.p5.6.m5.1.1">subscript</csymbol><ci id="S4.SS2.p5.6.m5.1.1.2.cmml" xref="S4.SS2.p5.6.m5.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p5.6.m5.1.1.3.cmml" xref="S4.SS2.p5.6.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.6.m5.1c">\mu_{2}</annotation></semantics></math> reaches approximately 1, the detection performance improves.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.9" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Influence of parameter <math id="S4.SS2.p6.1.1.m1.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.SS2.p6.1.1.m1.1a"><msub id="S4.SS2.p6.1.1.m1.1.1" xref="S4.SS2.p6.1.1.m1.1.1.cmml"><mi id="S4.SS2.p6.1.1.m1.1.1.2" xref="S4.SS2.p6.1.1.m1.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p6.1.1.m1.1.1.3" xref="S4.SS2.p6.1.1.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.1.1.m1.1b"><apply id="S4.SS2.p6.1.1.m1.1.1.cmml" xref="S4.SS2.p6.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.1.1.m1.1.1.1.cmml" xref="S4.SS2.p6.1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p6.1.1.m1.1.1.2.cmml" xref="S4.SS2.p6.1.1.m1.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p6.1.1.m1.1.1.3.cmml" xref="S4.SS2.p6.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.1.1.m1.1c">\mu_{3}</annotation></semantics></math></span>
We evaluate the effect of parameter <math id="S4.SS2.p6.2.m1.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.SS2.p6.2.m1.1a"><msub id="S4.SS2.p6.2.m1.1.1" xref="S4.SS2.p6.2.m1.1.1.cmml"><mi id="S4.SS2.p6.2.m1.1.1.2" xref="S4.SS2.p6.2.m1.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p6.2.m1.1.1.3" xref="S4.SS2.p6.2.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.2.m1.1b"><apply id="S4.SS2.p6.2.m1.1.1.cmml" xref="S4.SS2.p6.2.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.2.m1.1.1.1.cmml" xref="S4.SS2.p6.2.m1.1.1">subscript</csymbol><ci id="S4.SS2.p6.2.m1.1.1.2.cmml" xref="S4.SS2.p6.2.m1.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p6.2.m1.1.1.3.cmml" xref="S4.SS2.p6.2.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.2.m1.1c">\mu_{3}</annotation></semantics></math> according to the evaluation performance on different kinds of datasets.
In the right subgraph of Figure 4, we test the effect of parameter <math id="S4.SS2.p6.3.m2.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.SS2.p6.3.m2.1a"><msub id="S4.SS2.p6.3.m2.1.1" xref="S4.SS2.p6.3.m2.1.1.cmml"><mi id="S4.SS2.p6.3.m2.1.1.2" xref="S4.SS2.p6.3.m2.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p6.3.m2.1.1.3" xref="S4.SS2.p6.3.m2.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.3.m2.1b"><apply id="S4.SS2.p6.3.m2.1.1.cmml" xref="S4.SS2.p6.3.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.3.m2.1.1.1.cmml" xref="S4.SS2.p6.3.m2.1.1">subscript</csymbol><ci id="S4.SS2.p6.3.m2.1.1.2.cmml" xref="S4.SS2.p6.3.m2.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p6.3.m2.1.1.3.cmml" xref="S4.SS2.p6.3.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.3.m2.1c">\mu_{3}</annotation></semantics></math> from a set of {0.01, 0.10, 0.50, 1.00, 5.00, 10.00} is illustrated when we set parameter <math id="S4.SS2.p6.4.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p6.4.m3.1a"><mi id="S4.SS2.p6.4.m3.1.1" xref="S4.SS2.p6.4.m3.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.4.m3.1b"><ci id="S4.SS2.p6.4.m3.1.1.cmml" xref="S4.SS2.p6.4.m3.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.4.m3.1c">\beta</annotation></semantics></math> as 4 and <math id="S4.SS2.p6.5.m4.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.SS2.p6.5.m4.1a"><msub id="S4.SS2.p6.5.m4.1.1" xref="S4.SS2.p6.5.m4.1.1.cmml"><mi id="S4.SS2.p6.5.m4.1.1.2" xref="S4.SS2.p6.5.m4.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p6.5.m4.1.1.3" xref="S4.SS2.p6.5.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.5.m4.1b"><apply id="S4.SS2.p6.5.m4.1.1.cmml" xref="S4.SS2.p6.5.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.5.m4.1.1.1.cmml" xref="S4.SS2.p6.5.m4.1.1">subscript</csymbol><ci id="S4.SS2.p6.5.m4.1.1.2.cmml" xref="S4.SS2.p6.5.m4.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p6.5.m4.1.1.3.cmml" xref="S4.SS2.p6.5.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.5.m4.1c">\mu_{2}</annotation></semantics></math> as 1. The weights of the classification loss terms are the key parameters to improve the representation discriminability. However, higher values of parameter <math id="S4.SS2.p6.6.m5.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.SS2.p6.6.m5.1a"><msub id="S4.SS2.p6.6.m5.1.1" xref="S4.SS2.p6.6.m5.1.1.cmml"><mi id="S4.SS2.p6.6.m5.1.1.2" xref="S4.SS2.p6.6.m5.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p6.6.m5.1.1.3" xref="S4.SS2.p6.6.m5.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.6.m5.1b"><apply id="S4.SS2.p6.6.m5.1.1.cmml" xref="S4.SS2.p6.6.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.6.m5.1.1.1.cmml" xref="S4.SS2.p6.6.m5.1.1">subscript</csymbol><ci id="S4.SS2.p6.6.m5.1.1.2.cmml" xref="S4.SS2.p6.6.m5.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p6.6.m5.1.1.3.cmml" xref="S4.SS2.p6.6.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.6.m5.1c">\mu_{3}</annotation></semantics></math> may cause overfitting in the specific data domain. We find that when parameter <math id="S4.SS2.p6.7.m6.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.SS2.p6.7.m6.1a"><msub id="S4.SS2.p6.7.m6.1.1" xref="S4.SS2.p6.7.m6.1.1.cmml"><mi id="S4.SS2.p6.7.m6.1.1.2" xref="S4.SS2.p6.7.m6.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p6.7.m6.1.1.3" xref="S4.SS2.p6.7.m6.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.7.m6.1b"><apply id="S4.SS2.p6.7.m6.1.1.cmml" xref="S4.SS2.p6.7.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.7.m6.1.1.1.cmml" xref="S4.SS2.p6.7.m6.1.1">subscript</csymbol><ci id="S4.SS2.p6.7.m6.1.1.2.cmml" xref="S4.SS2.p6.7.m6.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p6.7.m6.1.1.3.cmml" xref="S4.SS2.p6.7.m6.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.7.m6.1c">\mu_{3}</annotation></semantics></math> achieves approximately 1, the performance achieves the best.
The parameter <math id="S4.SS2.p6.8.m7.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS2.p6.8.m7.1a"><mi id="S4.SS2.p6.8.m7.1.1" xref="S4.SS2.p6.8.m7.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.8.m7.1b"><ci id="S4.SS2.p6.8.m7.1.1.cmml" xref="S4.SS2.p6.8.m7.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.8.m7.1c">\alpha</annotation></semantics></math>, <math id="S4.SS2.p6.9.m8.1" class="ltx_Math" alttext="\mu_{1}" display="inline"><semantics id="S4.SS2.p6.9.m8.1a"><msub id="S4.SS2.p6.9.m8.1.1" xref="S4.SS2.p6.9.m8.1.1.cmml"><mi id="S4.SS2.p6.9.m8.1.1.2" xref="S4.SS2.p6.9.m8.1.1.2.cmml">Œº</mi><mn id="S4.SS2.p6.9.m8.1.1.3" xref="S4.SS2.p6.9.m8.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.9.m8.1b"><apply id="S4.SS2.p6.9.m8.1.1.cmml" xref="S4.SS2.p6.9.m8.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.9.m8.1.1.1.cmml" xref="S4.SS2.p6.9.m8.1.1">subscript</csymbol><ci id="S4.SS2.p6.9.m8.1.1.2.cmml" xref="S4.SS2.p6.9.m8.1.1.2">ùúá</ci><cn type="integer" id="S4.SS2.p6.9.m8.1.1.3.cmml" xref="S4.SS2.p6.9.m8.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.9.m8.1c">\mu_{1}</annotation></semantics></math> are set as the fixed value of 1 with our experience.
Experimental results prove these chosen hyperparameters are optimal and applicable in most similar kinds of cases.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2210.09563/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="113" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>In the first row of subplots of this figure, the left subfigure shows the evaluation accuracies of different numbers of the parameter <math id="S4.F4.7.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.F4.7.m1.1b"><mi id="S4.F4.7.m1.1.1" xref="S4.F4.7.m1.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.F4.7.m1.1c"><ci id="S4.F4.7.m1.1.1.cmml" xref="S4.F4.7.m1.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.7.m1.1d">\beta</annotation></semantics></math> on WildDeepfake; The middle subfigure shows the evaluation accuracies of different numbers of the parameter <math id="S4.F4.8.m2.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.F4.8.m2.1b"><msub id="S4.F4.8.m2.1.1" xref="S4.F4.8.m2.1.1.cmml"><mi id="S4.F4.8.m2.1.1.2" xref="S4.F4.8.m2.1.1.2.cmml">Œº</mi><mn id="S4.F4.8.m2.1.1.3" xref="S4.F4.8.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F4.8.m2.1c"><apply id="S4.F4.8.m2.1.1.cmml" xref="S4.F4.8.m2.1.1"><csymbol cd="ambiguous" id="S4.F4.8.m2.1.1.1.cmml" xref="S4.F4.8.m2.1.1">subscript</csymbol><ci id="S4.F4.8.m2.1.1.2.cmml" xref="S4.F4.8.m2.1.1.2">ùúá</ci><cn type="integer" id="S4.F4.8.m2.1.1.3.cmml" xref="S4.F4.8.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.8.m2.1d">\mu_{2}</annotation></semantics></math> on WildDeepfake; The right subfigure presents the evaluation accuracies of different numbers of the parameter <math id="S4.F4.9.m3.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.F4.9.m3.1b"><msub id="S4.F4.9.m3.1.1" xref="S4.F4.9.m3.1.1.cmml"><mi id="S4.F4.9.m3.1.1.2" xref="S4.F4.9.m3.1.1.2.cmml">Œº</mi><mn id="S4.F4.9.m3.1.1.3" xref="S4.F4.9.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F4.9.m3.1c"><apply id="S4.F4.9.m3.1.1.cmml" xref="S4.F4.9.m3.1.1"><csymbol cd="ambiguous" id="S4.F4.9.m3.1.1.1.cmml" xref="S4.F4.9.m3.1.1">subscript</csymbol><ci id="S4.F4.9.m3.1.1.2.cmml" xref="S4.F4.9.m3.1.1.2">ùúá</ci><cn type="integer" id="S4.F4.9.m3.1.1.3.cmml" xref="S4.F4.9.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.9.m3.1d">\mu_{3}</annotation></semantics></math> on WildDeepfake. In the second row of subplots of this figure, the left subfigure shows the evaluation accuracies of different numbers of the parameter <math id="S4.F4.10.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.F4.10.m4.1b"><mi id="S4.F4.10.m4.1.1" xref="S4.F4.10.m4.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S4.F4.10.m4.1c"><ci id="S4.F4.10.m4.1.1.cmml" xref="S4.F4.10.m4.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.10.m4.1d">\beta</annotation></semantics></math> on Hybrid-domain forgery dataset; The middle subfigure shows the evaluation accuracies of different numbers of the parameter <math id="S4.F4.11.m5.1" class="ltx_Math" alttext="\mu_{2}" display="inline"><semantics id="S4.F4.11.m5.1b"><msub id="S4.F4.11.m5.1.1" xref="S4.F4.11.m5.1.1.cmml"><mi id="S4.F4.11.m5.1.1.2" xref="S4.F4.11.m5.1.1.2.cmml">Œº</mi><mn id="S4.F4.11.m5.1.1.3" xref="S4.F4.11.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F4.11.m5.1c"><apply id="S4.F4.11.m5.1.1.cmml" xref="S4.F4.11.m5.1.1"><csymbol cd="ambiguous" id="S4.F4.11.m5.1.1.1.cmml" xref="S4.F4.11.m5.1.1">subscript</csymbol><ci id="S4.F4.11.m5.1.1.2.cmml" xref="S4.F4.11.m5.1.1.2">ùúá</ci><cn type="integer" id="S4.F4.11.m5.1.1.3.cmml" xref="S4.F4.11.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.11.m5.1d">\mu_{2}</annotation></semantics></math> on Hybrid-domain forgery dataset; The right subfigure presents the evaluation accuracies of different numbers of the parameter <math id="S4.F4.12.m6.1" class="ltx_Math" alttext="\mu_{3}" display="inline"><semantics id="S4.F4.12.m6.1b"><msub id="S4.F4.12.m6.1.1" xref="S4.F4.12.m6.1.1.cmml"><mi id="S4.F4.12.m6.1.1.2" xref="S4.F4.12.m6.1.1.2.cmml">Œº</mi><mn id="S4.F4.12.m6.1.1.3" xref="S4.F4.12.m6.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F4.12.m6.1c"><apply id="S4.F4.12.m6.1.1.cmml" xref="S4.F4.12.m6.1.1"><csymbol cd="ambiguous" id="S4.F4.12.m6.1.1.1.cmml" xref="S4.F4.12.m6.1.1">subscript</csymbol><ci id="S4.F4.12.m6.1.1.2.cmml" xref="S4.F4.12.m6.1.1.2">ùúá</ci><cn type="integer" id="S4.F4.12.m6.1.1.3.cmml" xref="S4.F4.12.m6.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.12.m6.1d">\mu_{3}</annotation></semantics></math> on Hybrid-domain forgery dataset.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Comparison Results</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this section, we compare our proposed method with state-of-the-art methods on the large-scale Deeperforensics-1.0 face forgery datasets, Hybrid-domain forgery dataset and the Generalized forgery dataset separately. To sufficiently evaluate forgery detection performance, we utilized the classification accuracy and the area under the receiver operating characteristic curve (AUC) as the quantitative metrics.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Evaluation accuracy rate (in %) and area under the receiver operating characteristic curve (in %) of forgery detection performance on constructed hybrid-domain forgery dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.4.5" class="ltx_tr">
<td id="S4.T1.4.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T1.4.5.2" class="ltx_td ltx_align_center ltx_border_t">Accuracy(%)</td>
<td id="S4.T1.4.5.3" class="ltx_td ltx_align_center ltx_border_t">AUC(%)</td>
</tr>
<tr id="S4.T1.4.6" class="ltx_tr">
<td id="S4.T1.4.6.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T1.4.6.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T1.4.6.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy Issue</span></td>
</tr>
<tr id="S4.T1.4.7" class="ltx_tr">
<td id="S4.T1.4.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">KNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>
</td>
<td id="S4.T1.4.7.2" class="ltx_td ltx_align_center ltx_border_t">53.23</td>
<td id="S4.T1.4.7.3" class="ltx_td ltx_align_center ltx_border_t">55.01</td>
</tr>
<tr id="S4.T1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r">CNNDetection<sub id="S4.T1.1.1.1.1" class="ltx_sub">1</sub> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>
</td>
<td id="S4.T1.1.1.2" class="ltx_td ltx_align_center">74.73</td>
<td id="S4.T1.1.1.3" class="ltx_td ltx_align_center">83.36</td>
</tr>
<tr id="S4.T1.4.8" class="ltx_tr">
<td id="S4.T1.4.8.1" class="ltx_td ltx_align_center ltx_border_r">Xception <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>
</td>
<td id="S4.T1.4.8.2" class="ltx_td ltx_align_center">76.31</td>
<td id="S4.T1.4.8.3" class="ltx_td ltx_align_center">86.06</td>
</tr>
<tr id="S4.T1.2.2" class="ltx_tr">
<td id="S4.T1.2.2.1" class="ltx_td ltx_align_center ltx_border_r">CNNDetection<sub id="S4.T1.2.2.1.1" class="ltx_sub">2</sub> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>
</td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center">78.21</td>
<td id="S4.T1.2.2.3" class="ltx_td ltx_align_center">88.05</td>
</tr>
<tr id="S4.T1.4.9" class="ltx_tr">
<td id="S4.T1.4.9.1" class="ltx_td ltx_align_center ltx_border_r">RECCE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S4.T1.4.9.2" class="ltx_td ltx_align_center">85.03</td>
<td id="S4.T1.4.9.3" class="ltx_td ltx_align_center">92.75</td>
</tr>
<tr id="S4.T1.4.10" class="ltx_tr">
<td id="S4.T1.4.10.1" class="ltx_td ltx_align_center ltx_border_r">GFFD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="S4.T1.4.10.2" class="ltx_td ltx_align_center">86.56</td>
<td id="S4.T1.4.10.3" class="ltx_td ltx_align_center">93.21</td>
</tr>
<tr id="S4.T1.4.11" class="ltx_tr">
<td id="S4.T1.4.11.1" class="ltx_td ltx_align_center ltx_border_r">RFM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>
</td>
<td id="S4.T1.4.11.2" class="ltx_td ltx_align_center">83.85</td>
<td id="S4.T1.4.11.3" class="ltx_td ltx_align_center">92.73</td>
</tr>
<tr id="S4.T1.3.3" class="ltx_tr">
<td id="S4.T1.3.3.2" class="ltx_td ltx_align_center ltx_border_r">DCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.3.1" class="ltx_text ltx_framed ltx_framed_underline">86.82</span></td>
<td id="S4.T1.3.3.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">94.48</span></td>
</tr>
<tr id="S4.T1.4.4" class="ltx_tr">
<td id="S4.T1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">FedForgery* (Ours)</td>
<td id="S4.T1.4.4.1" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">87.36</span></td>
<td id="S4.T1.4.4.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.1" class="ltx_text ltx_framed ltx_framed_underline">93.23</span></td>
</tr>
<tr id="S4.T1.4.12" class="ltx_tr">
<td id="S4.T1.4.12.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T1.4.12.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T1.4.12.2.1" class="ltx_text ltx_font_bold">Considering Privacy Issue</span></td>
</tr>
<tr id="S4.T1.4.13" class="ltx_tr">
<td id="S4.T1.4.13.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedForgery (Ours)</td>
<td id="S4.T1.4.13.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">85.55</td>
<td id="S4.T1.4.13.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">91.12</td>
</tr>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Evaluation accuracy rate (in %) and area under the receiver operating characteristic curve (in %) of forgery detection performance on constructed generalized-domain forgery dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T2.52" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.52.53" class="ltx_tr">
<td id="S4.T2.52.53.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T2.52.53.2" class="ltx_td ltx_align_center ltx_border_t">WildDeepfake</td>
<td id="S4.T2.52.53.3" class="ltx_td ltx_align_center ltx_border_t">DeepFakes</td>
<td id="S4.T2.52.53.4" class="ltx_td ltx_align_center ltx_border_t">Face2Face</td>
<td id="S4.T2.52.53.5" class="ltx_td ltx_align_center ltx_border_t">FaceSwap</td>
<td id="S4.T2.52.53.6" class="ltx_td ltx_align_center ltx_border_t">NeuralTextures</td>
</tr>
<tr id="S4.T2.52.54" class="ltx_tr">
<td id="S4.T2.52.54.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T2.52.54.2" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S4.T2.52.54.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy Issue</span></td>
</tr>
<tr id="S4.T2.6.6" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CNNDetection<sub id="S4.T2.1.1.1.1" class="ltx_sub">1</sub> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>
</td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">50.44<math id="S4.T2.2.2.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.2.2.2.m1.1a"><mo id="S4.T2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">\backslash</annotation></semantics></math>58.34</td>
<td id="S4.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_t">58.68<math id="S4.T2.3.3.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.3.3.3.m1.1a"><mo id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">\backslash</annotation></semantics></math>66.54</td>
<td id="S4.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_t">49.64<math id="S4.T2.4.4.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.4.4.4.m1.1a"><mo id="S4.T2.4.4.4.m1.1.1" xref="S4.T2.4.4.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><ci id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">\backslash</annotation></semantics></math>52.43</td>
<td id="S4.T2.5.5.5" class="ltx_td ltx_align_center ltx_border_t">55.30<math id="S4.T2.5.5.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.5.5.5.m1.1a"><mo id="S4.T2.5.5.5.m1.1.1" xref="S4.T2.5.5.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.m1.1b"><ci id="S4.T2.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.m1.1c">\backslash</annotation></semantics></math>61.22</td>
<td id="S4.T2.6.6.6" class="ltx_td ltx_align_center ltx_border_t">51.07<math id="S4.T2.6.6.6.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.6.6.6.m1.1a"><mo id="S4.T2.6.6.6.m1.1.1" xref="S4.T2.6.6.6.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.m1.1b"><ci id="S4.T2.6.6.6.m1.1.1.cmml" xref="S4.T2.6.6.6.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.m1.1c">\backslash</annotation></semantics></math>53.99</td>
</tr>
<tr id="S4.T2.11.11" class="ltx_tr">
<td id="S4.T2.11.11.6" class="ltx_td ltx_align_center ltx_border_r">KNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>
</td>
<td id="S4.T2.7.7.1" class="ltx_td ltx_align_center">51.10<math id="S4.T2.7.7.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.7.7.1.m1.1a"><mo id="S4.T2.7.7.1.m1.1.1" xref="S4.T2.7.7.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.1.m1.1b"><ci id="S4.T2.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.1.m1.1c">\backslash</annotation></semantics></math>51.55</td>
<td id="S4.T2.8.8.2" class="ltx_td ltx_align_center">50.57<math id="S4.T2.8.8.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.8.8.2.m1.1a"><mo id="S4.T2.8.8.2.m1.1.1" xref="S4.T2.8.8.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.2.m1.1b"><ci id="S4.T2.8.8.2.m1.1.1.cmml" xref="S4.T2.8.8.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.2.m1.1c">\backslash</annotation></semantics></math>51.03</td>
<td id="S4.T2.9.9.3" class="ltx_td ltx_align_center">51.31<math id="S4.T2.9.9.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.9.9.3.m1.1a"><mo id="S4.T2.9.9.3.m1.1.1" xref="S4.T2.9.9.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.3.m1.1b"><ci id="S4.T2.9.9.3.m1.1.1.cmml" xref="S4.T2.9.9.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.3.m1.1c">\backslash</annotation></semantics></math>52.02</td>
<td id="S4.T2.10.10.4" class="ltx_td ltx_align_center">52.18<math id="S4.T2.10.10.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.10.10.4.m1.1a"><mo id="S4.T2.10.10.4.m1.1.1" xref="S4.T2.10.10.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.4.m1.1b"><ci id="S4.T2.10.10.4.m1.1.1.cmml" xref="S4.T2.10.10.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.4.m1.1c">\backslash</annotation></semantics></math>52.99</td>
<td id="S4.T2.11.11.5" class="ltx_td ltx_align_center">50.70<math id="S4.T2.11.11.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.11.11.5.m1.1a"><mo id="S4.T2.11.11.5.m1.1.1" xref="S4.T2.11.11.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.5.m1.1b"><ci id="S4.T2.11.11.5.m1.1.1.cmml" xref="S4.T2.11.11.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.5.m1.1c">\backslash</annotation></semantics></math>51.01</td>
</tr>
<tr id="S4.T2.16.16" class="ltx_tr">
<td id="S4.T2.16.16.6" class="ltx_td ltx_align_center ltx_border_r">Xception <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>
</td>
<td id="S4.T2.12.12.1" class="ltx_td ltx_align_center">60.83<math id="S4.T2.12.12.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.12.12.1.m1.1a"><mo id="S4.T2.12.12.1.m1.1.1" xref="S4.T2.12.12.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.1.m1.1b"><ci id="S4.T2.12.12.1.m1.1.1.cmml" xref="S4.T2.12.12.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.1.m1.1c">\backslash</annotation></semantics></math>66.81</td>
<td id="S4.T2.13.13.2" class="ltx_td ltx_align_center">65.18<math id="S4.T2.13.13.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.13.13.2.m1.1a"><mo id="S4.T2.13.13.2.m1.1.1" xref="S4.T2.13.13.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.2.m1.1b"><ci id="S4.T2.13.13.2.m1.1.1.cmml" xref="S4.T2.13.13.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.2.m1.1c">\backslash</annotation></semantics></math>72.14</td>
<td id="S4.T2.14.14.3" class="ltx_td ltx_align_center">46.54<math id="S4.T2.14.14.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.14.14.3.m1.1a"><mo id="S4.T2.14.14.3.m1.1.1" xref="S4.T2.14.14.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.3.m1.1b"><ci id="S4.T2.14.14.3.m1.1.1.cmml" xref="S4.T2.14.14.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.3.m1.1c">\backslash</annotation></semantics></math>50.57</td>
<td id="S4.T2.15.15.4" class="ltx_td ltx_align_center">55.95<math id="S4.T2.15.15.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.15.15.4.m1.1a"><mo id="S4.T2.15.15.4.m1.1.1" xref="S4.T2.15.15.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.4.m1.1b"><ci id="S4.T2.15.15.4.m1.1.1.cmml" xref="S4.T2.15.15.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.4.m1.1c">\backslash</annotation></semantics></math>62.60</td>
<td id="S4.T2.16.16.5" class="ltx_td ltx_align_center">50.05<math id="S4.T2.16.16.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.16.16.5.m1.1a"><mo id="S4.T2.16.16.5.m1.1.1" xref="S4.T2.16.16.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.5.m1.1b"><ci id="S4.T2.16.16.5.m1.1.1.cmml" xref="S4.T2.16.16.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.5.m1.1c">\backslash</annotation></semantics></math>55.12</td>
</tr>
<tr id="S4.T2.22.22" class="ltx_tr">
<td id="S4.T2.17.17.1" class="ltx_td ltx_align_center ltx_border_r">CNNDetection<sub id="S4.T2.17.17.1.1" class="ltx_sub">2</sub><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>
</td>
<td id="S4.T2.18.18.2" class="ltx_td ltx_align_center">62.54<math id="S4.T2.18.18.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.18.18.2.m1.1a"><mo id="S4.T2.18.18.2.m1.1.1" xref="S4.T2.18.18.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.18.18.2.m1.1b"><ci id="S4.T2.18.18.2.m1.1.1.cmml" xref="S4.T2.18.18.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.18.2.m1.1c">\backslash</annotation></semantics></math>70.86</td>
<td id="S4.T2.19.19.3" class="ltx_td ltx_align_center">63.19<math id="S4.T2.19.19.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.19.19.3.m1.1a"><mo id="S4.T2.19.19.3.m1.1.1" xref="S4.T2.19.19.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.3.m1.1b"><ci id="S4.T2.19.19.3.m1.1.1.cmml" xref="S4.T2.19.19.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.3.m1.1c">\backslash</annotation></semantics></math>69.44</td>
<td id="S4.T2.20.20.4" class="ltx_td ltx_align_center">51.53<math id="S4.T2.20.20.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.20.20.4.m1.1a"><mo id="S4.T2.20.20.4.m1.1.1" xref="S4.T2.20.20.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.4.m1.1b"><ci id="S4.T2.20.20.4.m1.1.1.cmml" xref="S4.T2.20.20.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.4.m1.1c">\backslash</annotation></semantics></math>57.36</td>
<td id="S4.T2.21.21.5" class="ltx_td ltx_align_center">59.59<math id="S4.T2.21.21.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.21.21.5.m1.1a"><mo id="S4.T2.21.21.5.m1.1.1" xref="S4.T2.21.21.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.21.21.5.m1.1b"><ci id="S4.T2.21.21.5.m1.1.1.cmml" xref="S4.T2.21.21.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.21.21.5.m1.1c">\backslash</annotation></semantics></math>71.05</td>
<td id="S4.T2.22.22.6" class="ltx_td ltx_align_center">54.02<math id="S4.T2.22.22.6.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.22.22.6.m1.1a"><mo id="S4.T2.22.22.6.m1.1.1" xref="S4.T2.22.22.6.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.22.22.6.m1.1b"><ci id="S4.T2.22.22.6.m1.1.1.cmml" xref="S4.T2.22.22.6.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.22.22.6.m1.1c">\backslash</annotation></semantics></math>58.59</td>
</tr>
<tr id="S4.T2.27.27" class="ltx_tr">
<td id="S4.T2.27.27.6" class="ltx_td ltx_align_center ltx_border_r">RECCE<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S4.T2.23.23.1" class="ltx_td ltx_align_center">65.70<math id="S4.T2.23.23.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.23.23.1.m1.1a"><mo id="S4.T2.23.23.1.m1.1.1" xref="S4.T2.23.23.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.23.23.1.m1.1b"><ci id="S4.T2.23.23.1.m1.1.1.cmml" xref="S4.T2.23.23.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.23.23.1.m1.1c">\backslash</annotation></semantics></math>68.75</td>
<td id="S4.T2.24.24.2" class="ltx_td ltx_align_center">69.54<math id="S4.T2.24.24.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.24.24.2.m1.1a"><mo id="S4.T2.24.24.2.m1.1.1" xref="S4.T2.24.24.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.24.24.2.m1.1b"><ci id="S4.T2.24.24.2.m1.1.1.cmml" xref="S4.T2.24.24.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.24.24.2.m1.1c">\backslash</annotation></semantics></math>77.08</td>
<td id="S4.T2.25.25.3" class="ltx_td ltx_align_center">53.93<math id="S4.T2.25.25.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.25.25.3.m1.1a"><mo id="S4.T2.25.25.3.m1.1.1" xref="S4.T2.25.25.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.25.25.3.m1.1b"><ci id="S4.T2.25.25.3.m1.1.1.cmml" xref="S4.T2.25.25.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.25.25.3.m1.1c">\backslash</annotation></semantics></math>57.01</td>
<td id="S4.T2.26.26.4" class="ltx_td ltx_align_center">68.46<math id="S4.T2.26.26.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.26.26.4.m1.1a"><mo id="S4.T2.26.26.4.m1.1.1" xref="S4.T2.26.26.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.26.26.4.m1.1b"><ci id="S4.T2.26.26.4.m1.1.1.cmml" xref="S4.T2.26.26.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.26.26.4.m1.1c">\backslash</annotation></semantics></math>71.69</td>
<td id="S4.T2.27.27.5" class="ltx_td ltx_align_center">59.39<math id="S4.T2.27.27.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.27.27.5.m1.1a"><mo id="S4.T2.27.27.5.m1.1.1" xref="S4.T2.27.27.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.27.27.5.m1.1b"><ci id="S4.T2.27.27.5.m1.1.1.cmml" xref="S4.T2.27.27.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.27.27.5.m1.1c">\backslash</annotation></semantics></math>70.83</td>
</tr>
<tr id="S4.T2.32.32" class="ltx_tr">
<td id="S4.T2.32.32.6" class="ltx_td ltx_align_center ltx_border_r">GFFD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="S4.T2.28.28.1" class="ltx_td ltx_align_center">64.42<math id="S4.T2.28.28.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.28.28.1.m1.1a"><mo id="S4.T2.28.28.1.m1.1.1" xref="S4.T2.28.28.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.28.28.1.m1.1b"><ci id="S4.T2.28.28.1.m1.1.1.cmml" xref="S4.T2.28.28.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.28.28.1.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.28.28.1.1" class="ltx_text ltx_font_bold">80.93</span>
</td>
<td id="S4.T2.29.29.2" class="ltx_td ltx_align_center">63.84<math id="S4.T2.29.29.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.29.29.2.m1.1a"><mo id="S4.T2.29.29.2.m1.1.1" xref="S4.T2.29.29.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.29.29.2.m1.1b"><ci id="S4.T2.29.29.2.m1.1.1.cmml" xref="S4.T2.29.29.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.29.29.2.m1.1c">\backslash</annotation></semantics></math>63.89</td>
<td id="S4.T2.30.30.3" class="ltx_td ltx_align_center">52.30<math id="S4.T2.30.30.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.30.30.3.m1.1a"><mo id="S4.T2.30.30.3.m1.1.1" xref="S4.T2.30.30.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.30.30.3.m1.1b"><ci id="S4.T2.30.30.3.m1.1.1.cmml" xref="S4.T2.30.30.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.30.30.3.m1.1c">\backslash</annotation></semantics></math>64.75</td>
<td id="S4.T2.31.31.4" class="ltx_td ltx_align_center">68.63<math id="S4.T2.31.31.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.31.31.4.m1.1a"><mo id="S4.T2.31.31.4.m1.1.1" xref="S4.T2.31.31.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.31.31.4.m1.1b"><ci id="S4.T2.31.31.4.m1.1.1.cmml" xref="S4.T2.31.31.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.31.31.4.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.31.31.4.1" class="ltx_text ltx_framed ltx_framed_underline">83.30</span>
</td>
<td id="S4.T2.32.32.5" class="ltx_td ltx_align_center">57.75<math id="S4.T2.32.32.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.32.32.5.m1.1a"><mo id="S4.T2.32.32.5.m1.1.1" xref="S4.T2.32.32.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.32.32.5.m1.1b"><ci id="S4.T2.32.32.5.m1.1.1.cmml" xref="S4.T2.32.32.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.32.32.5.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.32.32.5.1" class="ltx_text ltx_framed ltx_framed_underline">77.17</span>
</td>
</tr>
<tr id="S4.T2.37.37" class="ltx_tr">
<td id="S4.T2.37.37.6" class="ltx_td ltx_align_center ltx_border_r">RFM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>
</td>
<td id="S4.T2.33.33.1" class="ltx_td ltx_align_center">59.98<math id="S4.T2.33.33.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.33.33.1.m1.1a"><mo id="S4.T2.33.33.1.m1.1.1" xref="S4.T2.33.33.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.33.33.1.m1.1b"><ci id="S4.T2.33.33.1.m1.1.1.cmml" xref="S4.T2.33.33.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.33.33.1.m1.1c">\backslash</annotation></semantics></math>73.79</td>
<td id="S4.T2.34.34.2" class="ltx_td ltx_align_center">67.51<math id="S4.T2.34.34.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.34.34.2.m1.1a"><mo id="S4.T2.34.34.2.m1.1.1" xref="S4.T2.34.34.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.34.34.2.m1.1b"><ci id="S4.T2.34.34.2.m1.1.1.cmml" xref="S4.T2.34.34.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.34.34.2.m1.1c">\backslash</annotation></semantics></math>75.12</td>
<td id="S4.T2.35.35.3" class="ltx_td ltx_align_center">
<span id="S4.T2.35.35.3.1" class="ltx_text ltx_font_bold">60.98<math id="S4.T2.35.35.3.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.35.35.3.1.m1.1a"><mo id="S4.T2.35.35.3.1.m1.1.1" xref="S4.T2.35.35.3.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.35.35.3.1.m1.1b"><ci id="S4.T2.35.35.3.1.m1.1.1.cmml" xref="S4.T2.35.35.3.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.35.35.3.1.m1.1c">\backslash</annotation></semantics></math></span>67.51</td>
<td id="S4.T2.36.36.4" class="ltx_td ltx_align_center">70.23<math id="S4.T2.36.36.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.36.36.4.m1.1a"><mo id="S4.T2.36.36.4.m1.1.1" xref="S4.T2.36.36.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.36.36.4.m1.1b"><ci id="S4.T2.36.36.4.m1.1.1.cmml" xref="S4.T2.36.36.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.36.36.4.m1.1c">\backslash</annotation></semantics></math>76.39</td>
<td id="S4.T2.37.37.5" class="ltx_td ltx_align_center">59.55<math id="S4.T2.37.37.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.37.37.5.m1.1a"><mo id="S4.T2.37.37.5.m1.1.1" xref="S4.T2.37.37.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.37.37.5.m1.1b"><ci id="S4.T2.37.37.5.m1.1.1.cmml" xref="S4.T2.37.37.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.37.37.5.m1.1c">\backslash</annotation></semantics></math>64.40</td>
</tr>
<tr id="S4.T2.42.42" class="ltx_tr">
<td id="S4.T2.42.42.6" class="ltx_td ltx_align_center ltx_border_r">DCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</td>
<td id="S4.T2.38.38.1" class="ltx_td ltx_align_center">64.20<math id="S4.T2.38.38.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.38.38.1.m1.1a"><mo id="S4.T2.38.38.1.m1.1.1" xref="S4.T2.38.38.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.38.38.1.m1.1b"><ci id="S4.T2.38.38.1.m1.1.1.cmml" xref="S4.T2.38.38.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.38.38.1.m1.1c">\backslash</annotation></semantics></math>75.40</td>
<td id="S4.T2.39.39.2" class="ltx_td ltx_align_center">71.14<math id="S4.T2.39.39.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.39.39.2.m1.1a"><mo id="S4.T2.39.39.2.m1.1.1" xref="S4.T2.39.39.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.39.39.2.m1.1b"><ci id="S4.T2.39.39.2.m1.1.1.cmml" xref="S4.T2.39.39.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.39.39.2.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.39.39.2.1" class="ltx_text ltx_framed ltx_framed_underline">81.93</span>
</td>
<td id="S4.T2.40.40.3" class="ltx_td ltx_align_center">52.91<math id="S4.T2.40.40.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.40.40.3.m1.1a"><mo id="S4.T2.40.40.3.m1.1.1" xref="S4.T2.40.40.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.40.40.3.m1.1b"><ci id="S4.T2.40.40.3.m1.1.1.cmml" xref="S4.T2.40.40.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.40.40.3.m1.1c">\backslash</annotation></semantics></math>61.19</td>
<td id="S4.T2.41.41.4" class="ltx_td ltx_align_center">67.83<math id="S4.T2.41.41.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.41.41.4.m1.1a"><mo id="S4.T2.41.41.4.m1.1.1" xref="S4.T2.41.41.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.41.41.4.m1.1b"><ci id="S4.T2.41.41.4.m1.1.1.cmml" xref="S4.T2.41.41.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.41.41.4.m1.1c">\backslash</annotation></semantics></math>79.46</td>
<td id="S4.T2.42.42.5" class="ltx_td ltx_align_center">55.33<math id="S4.T2.42.42.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.42.42.5.m1.1a"><mo id="S4.T2.42.42.5.m1.1.1" xref="S4.T2.42.42.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.42.42.5.m1.1b"><ci id="S4.T2.42.42.5.m1.1.1.cmml" xref="S4.T2.42.42.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.42.42.5.m1.1c">\backslash</annotation></semantics></math>70.77</td>
</tr>
<tr id="S4.T2.47.47" class="ltx_tr">
<td id="S4.T2.47.47.6" class="ltx_td ltx_align_center ltx_border_r">FedForgery* (Ours)</td>
<td id="S4.T2.43.43.1" class="ltx_td ltx_align_center">
<span id="S4.T2.43.43.1.1" class="ltx_text ltx_framed ltx_framed_underline">67.75</span><math id="S4.T2.43.43.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.43.43.1.m1.1a"><mo id="S4.T2.43.43.1.m1.1.1" xref="S4.T2.43.43.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.43.43.1.m1.1b"><ci id="S4.T2.43.43.1.m1.1.1.cmml" xref="S4.T2.43.43.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.43.43.1.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.43.43.1.2" class="ltx_text ltx_framed ltx_framed_underline">75.45</span>
</td>
<td id="S4.T2.44.44.2" class="ltx_td ltx_align_center"><span id="S4.T2.44.44.2.1" class="ltx_text ltx_font_bold">73.47<math id="S4.T2.44.44.2.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.44.44.2.1.m1.1a"><mo id="S4.T2.44.44.2.1.m1.1.1" xref="S4.T2.44.44.2.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.44.44.2.1.m1.1b"><ci id="S4.T2.44.44.2.1.m1.1.1.cmml" xref="S4.T2.44.44.2.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.44.44.2.1.m1.1c">\backslash</annotation></semantics></math>82.08</span></td>
<td id="S4.T2.45.45.3" class="ltx_td ltx_align_center">53.77<math id="S4.T2.45.45.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.45.45.3.m1.1a"><mo id="S4.T2.45.45.3.m1.1.1" xref="S4.T2.45.45.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.45.45.3.m1.1b"><ci id="S4.T2.45.45.3.m1.1.1.cmml" xref="S4.T2.45.45.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.45.45.3.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.45.45.3.1" class="ltx_text ltx_framed ltx_framed_underline">68.41</span>
</td>
<td id="S4.T2.46.46.4" class="ltx_td ltx_align_center">
<span id="S4.T2.46.46.4.1" class="ltx_text ltx_font_bold">71.13<math id="S4.T2.46.46.4.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.46.46.4.1.m1.1a"><mo id="S4.T2.46.46.4.1.m1.1.1" xref="S4.T2.46.46.4.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.46.46.4.1.m1.1b"><ci id="S4.T2.46.46.4.1.m1.1.1.cmml" xref="S4.T2.46.46.4.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.46.46.4.1.m1.1c">\backslash</annotation></semantics></math></span>82.21</td>
<td id="S4.T2.47.47.5" class="ltx_td ltx_align_center"><span id="S4.T2.47.47.5.1" class="ltx_text ltx_font_bold">60.95<math id="S4.T2.47.47.5.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.47.47.5.1.m1.1a"><mo id="S4.T2.47.47.5.1.m1.1.1" xref="S4.T2.47.47.5.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.47.47.5.1.m1.1b"><ci id="S4.T2.47.47.5.1.m1.1.1.cmml" xref="S4.T2.47.47.5.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.47.47.5.1.m1.1c">\backslash</annotation></semantics></math>80.32</span></td>
</tr>
<tr id="S4.T2.52.55" class="ltx_tr">
<td id="S4.T2.52.55.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T2.52.55.2" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S4.T2.52.55.2.1" class="ltx_text ltx_font_bold">Considering Privacy Issue</span></td>
</tr>
<tr id="S4.T2.52.52" class="ltx_tr">
<td id="S4.T2.52.52.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedForgery (Ours)</td>
<td id="S4.T2.48.48.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="S4.T2.48.48.1.1" class="ltx_text ltx_font_bold">68.03<math id="S4.T2.48.48.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.48.48.1.1.m1.1a"><mo id="S4.T2.48.48.1.1.m1.1.1" xref="S4.T2.48.48.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.48.48.1.1.m1.1b"><ci id="S4.T2.48.48.1.1.m1.1.1.cmml" xref="S4.T2.48.48.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.48.48.1.1.m1.1c">\backslash</annotation></semantics></math></span>74.59</td>
<td id="S4.T2.49.49.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="S4.T2.49.49.2.1" class="ltx_text ltx_framed ltx_framed_underline">72.24</span><math id="S4.T2.49.49.2.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.49.49.2.m1.1a"><mo id="S4.T2.49.49.2.m1.1.1" xref="S4.T2.49.49.2.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.49.49.2.m1.1b"><ci id="S4.T2.49.49.2.m1.1.1.cmml" xref="S4.T2.49.49.2.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.49.49.2.m1.1c">\backslash</annotation></semantics></math>79.26</td>
<td id="S4.T2.50.50.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="S4.T2.50.50.3.1" class="ltx_text ltx_framed ltx_framed_underline">54.74</span><math id="S4.T2.50.50.3.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.50.50.3.m1.1a"><mo id="S4.T2.50.50.3.m1.1.1" xref="S4.T2.50.50.3.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.50.50.3.m1.1b"><ci id="S4.T2.50.50.3.m1.1.1.cmml" xref="S4.T2.50.50.3.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.50.50.3.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.50.50.3.2" class="ltx_text ltx_font_bold">69.66</span>
</td>
<td id="S4.T2.51.51.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="S4.T2.51.51.4.1" class="ltx_text ltx_framed ltx_framed_underline">70.36</span><math id="S4.T2.51.51.4.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.51.51.4.m1.1a"><mo id="S4.T2.51.51.4.m1.1.1" xref="S4.T2.51.51.4.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.51.51.4.m1.1b"><ci id="S4.T2.51.51.4.m1.1.1.cmml" xref="S4.T2.51.51.4.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.51.51.4.m1.1c">\backslash</annotation></semantics></math><span id="S4.T2.51.51.4.2" class="ltx_text ltx_font_bold">83.79</span>
</td>
<td id="S4.T2.52.52.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="S4.T2.52.52.5.1" class="ltx_text ltx_framed ltx_framed_underline">60.58</span><math id="S4.T2.52.52.5.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S4.T2.52.52.5.m1.1a"><mo id="S4.T2.52.52.5.m1.1.1" xref="S4.T2.52.52.5.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S4.T2.52.52.5.m1.1b"><ci id="S4.T2.52.52.5.m1.1.1.cmml" xref="S4.T2.52.52.5.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.52.52.5.m1.1c">\backslash</annotation></semantics></math>76.64</td>
</tr>
</table>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Results on Hybrid-domain forgery dataset</span>
As shown in Table I, we reimplemented several representative face forgery methods on the Hybrid-domain forgery dataset.
CNNDetection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> aims to design a simple convolutional neural network to detect forgery clues.
Related works<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> found that CNN detectors are prone to overfitting the texture patterns of specific generation methods.
Thus, two different data augmentation methods were designed to boost performance.
KNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> uses the frequency domain information of pictures to detect forgery. This method may be misled by some noise signals, especially when encountering complex datasets, and its detection performance will be greatly affected.
RECCE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> enables the classifier to learn a more general representation by learning from real images, but its defect is that it cannot protect the privacy of training data in the face forgery detection task.
GFFD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> utilized high-frequency noise and the correlation between complementary modalities to facilitate feature learning. RFM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> explored sensitive local regions and specific data augmentation strategies to boost performance. DCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> designed the inter-instance contrastive learning and local content inconsistencies to detect clues.
But the defect is that it cannot protect the privacy of training data in the face forgery detection task.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Noting that the proposed FedForgery belongs to distributed training method, enables sensitive personal information to be stored on the local clients, different from these traditional centralized training methods without considering privacy issues.
Related research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> states that the efficiency and accuracy of advanced federated learning models are getting closer and closer to centralized training models, but still slightly inferior to that of centralized training. For a fair comparison, we add the proposed methods with the centralized training strategy, denoted as FedForgery* in the following experiments.
As shown in Table I, benefiting from the designed generalized contractive feature learning, DCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> achieves the best AUC performance. However, our proposed method is slightly below 1.25% at AUC performance, but achieves better accuracy at 87.36% compared with DCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, GFFD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> and RFM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. It is because the designed robust residual features learning could effectively capture domain-invariant discrepancy information between real and fake images.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">Results on Generalized forgery dataset</span>
To further verify the generalization of the proposed FedForgery, we conduct new experiments on the Generalized forgery dataset.
The aim is to distinguish the authenticity of input faces even with unknown artifact types.
Similarly, we reimplement representative face forgery detection methods for fair comparisons.
The experimental results are shown in Table II.
For convenience, we set the testing set only contains one artifact type, and the training set contains the rest four types.
For example, when the testing set is chosen from DeepFakes dataset, the training set contains artifact types from WildDeepfake, Face2Face, FaceSwap, NeuralTextures datasets.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">As shown in Table II, we construct the generalized forgery dataset to evaluate the ability of methods to explore forgery clues in unknown patterns. It is obvious that our proposed method achieves better performance than DCL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> in all scenarios, and also better than GFFD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> and RFM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> in most scenarios with accuracy and AUC metrics.
It is encouraging that when considering privacy issue, our method FedForgery not only maintain similar performance with centralized training FedForgery*, but also achieve better performance in WildDeepface, Face2Face and FaceSwap testing sets.
<em id="S4.SS3.p5.1.1" class="ltx_emph ltx_font_italic">It proves the proposed residual federated learning strategy could aggregate diverse discrepancy information in local clients and help learn more essential discrepancies to boost the generalization ability.
</em>
We believe it will inspire researchers to explore distributed learning and generalization analysis in the community.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Evaluation accuracy rate (in %) of forgery detection performance on the Deeperforensics-1.0 dataset by several state-of-the-art technologies. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.1.1.2.1" class="ltx_text"></span> <span id="S4.T3.1.1.2.2" class="ltx_text">
<span id="S4.T3.1.1.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.1.1.2.2.1.1" class="ltx_tr">
<span id="S4.T3.1.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">std</span></span>
<span id="S4.T3.1.1.2.2.1.2" class="ltx_tr">
<span id="S4.T3.1.1.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">std</span></span>
</span></span><span id="S4.T3.1.1.2.3" class="ltx_text"></span></td>
<td id="S4.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.1.1.3.1" class="ltx_text"></span> <span id="S4.T3.1.1.3.2" class="ltx_text">
<span id="S4.T3.1.1.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.1.1.3.2.1.1" class="ltx_tr">
<span id="S4.T3.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">std</span></span>
<span id="S4.T3.1.1.3.2.1.2" class="ltx_tr">
<span id="S4.T3.1.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">std/sing</span></span>
</span></span><span id="S4.T3.1.1.3.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T3.1.2" class="ltx_tr">
<td id="S4.T3.1.2.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T3.1.2.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T3.1.2.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy Issue</span></td>
</tr>
<tr id="S4.T3.1.3" class="ltx_tr">
<td id="S4.T3.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">C3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>
</td>
<td id="S4.T3.1.3.2" class="ltx_td ltx_align_center ltx_border_t">98.50</td>
<td id="S4.T3.1.3.3" class="ltx_td ltx_align_center ltx_border_t">87.63</td>
</tr>
<tr id="S4.T3.1.4" class="ltx_tr">
<td id="S4.T3.1.4.1" class="ltx_td ltx_align_center ltx_border_r">TSN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>
</td>
<td id="S4.T3.1.4.2" class="ltx_td ltx_align_center">99.25</td>
<td id="S4.T3.1.4.3" class="ltx_td ltx_align_center"><span id="S4.T3.1.4.3.1" class="ltx_text ltx_framed ltx_framed_underline">91.50</span></td>
</tr>
<tr id="S4.T3.1.5" class="ltx_tr">
<td id="S4.T3.1.5.1" class="ltx_td ltx_align_center ltx_border_r">I3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>
</td>
<td id="S4.T3.1.5.2" class="ltx_td ltx_align_center"><span id="S4.T3.1.5.2.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S4.T3.1.5.3" class="ltx_td ltx_align_center">90.75</td>
</tr>
<tr id="S4.T3.1.6" class="ltx_tr">
<td id="S4.T3.1.6.1" class="ltx_td ltx_align_center ltx_border_r">Resnet+LSTM<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</td>
<td id="S4.T3.1.6.2" class="ltx_td ltx_align_center"><span id="S4.T3.1.6.2.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S4.T3.1.6.3" class="ltx_td ltx_align_center">90.63</td>
</tr>
<tr id="S4.T3.1.7" class="ltx_tr">
<td id="S4.T3.1.7.1" class="ltx_td ltx_align_center ltx_border_r">XceptionNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>
</td>
<td id="S4.T3.1.7.2" class="ltx_td ltx_align_center"><span id="S4.T3.1.7.2.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S4.T3.1.7.3" class="ltx_td ltx_align_center">88.38</td>
</tr>
<tr id="S4.T3.1.8" class="ltx_tr">
<td id="S4.T3.1.8.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T3.1.8.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T3.1.8.2.1" class="ltx_text ltx_font_bold">Considering Privacy Issue</span></td>
</tr>
<tr id="S4.T3.1.9" class="ltx_tr">
<td id="S4.T3.1.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedForgery (Ours)</td>
<td id="S4.T3.1.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.1.9.2.1" class="ltx_text ltx_framed ltx_framed_underline">99.75</span></td>
<td id="S4.T3.1.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.1.9.3.1" class="ltx_text ltx_font_bold">95.21</span></td>
</tr>
</table>
</figure>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.1" class="ltx_p"><span id="S4.SS3.p6.1.1" class="ltx_text ltx_font_bold">Results on large-scale Deepforensics-1.0 dataset</span>
As shown in Table III, we compare our proposed algorithm with other representative face forgery detection methods with a similar protocol in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. To prove the strong generalization ability, we evaluate comparison methods with dataset perturbations. Here we select 1000 manipulated videos in the standard set (std), and 1000 manipulated videos with single-level distortions (std/sing).
When the training set is the standard set and the testing set is also the standard set, all these comparison methods could achieve high accuracies (<math id="S4.SS3.p6.1.m1.1" class="ltx_Math" alttext="\textgreater 98\%" display="inline"><semantics id="S4.SS3.p6.1.m1.1a"><mrow id="S4.SS3.p6.1.m1.1.1" xref="S4.SS3.p6.1.m1.1.1.cmml"><mi id="S4.SS3.p6.1.m1.1.1.2" xref="S4.SS3.p6.1.m1.1.1.2.cmml"></mi><mo id="S4.SS3.p6.1.m1.1.1.1" xref="S4.SS3.p6.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S4.SS3.p6.1.m1.1.1.3" xref="S4.SS3.p6.1.m1.1.1.3.cmml"><mn id="S4.SS3.p6.1.m1.1.1.3.2" xref="S4.SS3.p6.1.m1.1.1.3.2.cmml">98</mn><mo id="S4.SS3.p6.1.m1.1.1.3.1" xref="S4.SS3.p6.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.1.m1.1b"><apply id="S4.SS3.p6.1.m1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1"><gt id="S4.SS3.p6.1.m1.1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S4.SS3.p6.1.m1.1.1.2.cmml" xref="S4.SS3.p6.1.m1.1.1.2">absent</csymbol><apply id="S4.SS3.p6.1.m1.1.1.3.cmml" xref="S4.SS3.p6.1.m1.1.1.3"><csymbol cd="latexml" id="S4.SS3.p6.1.m1.1.1.3.1.cmml" xref="S4.SS3.p6.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS3.p6.1.m1.1.1.3.2.cmml" xref="S4.SS3.p6.1.m1.1.1.3.2">98</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.1.m1.1c">\textgreater 98\%</annotation></semantics></math>), which may benefit from these similar distributions.
The proposed FedForgery not only considers the privacy issue through distributed training, but also achieves accuracy at 99.75%, which is already close to the ultimate accuracy. Thus, the first protocol is not a reasonable experimental setting to distinguish the pros and cons of these comparison methods.
To further evaluate the generalization ability, we utilized the dataset perturbations to mimic real-world scenarios. When the training set is the standard set and the testing set is with single-level distortions (std/sing), the proposed FedForgery can achieve the SOTA accuracy and even exceed Resnet+LSTM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> by 4.58%, XceptionNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> by 6.83% and I3D<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> by 4.46%. We think these accuracy improvements in the large-scale dataset are benefitted from the proposed residual federated learning that could boost the representation generalization ability.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Discussion</span>
</h2>

<section id="S5.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Ablation study</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To verify the effectiveness residual federated learning framework for face forgery detection, we conducted the following experiments as shown in Figure 5.
For the convenience of analysis, we sampled 10% images from the WildDeepfake Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> in the following experiments.
We set eight diverse data centers as local clients, and allocate the same number of datasets to each data center. The eight data centers would evaluate forgery detection performance after the local client training.
And the global server could evaluate performance after each round of global communication.
As shown in Figure 5, the pink line indicates the detection performance of the global server model, and the blue line indicates the average detection accuracies of eight data centers.
Here we find the performance of the global server is significantly higher than the results of data centers in local clients.
The forgery accuracy improves from about 1.34% to 6.35% after applying the proposed residual federated learning strategy.
The curve clearly proves that the proposed FedForgery can improve the forgery detection performance by aggregating the model parameters, and meanwhile protect the privacy of training data in local data centers.
Within a certain number of communication times, with the increase in global communication times, the detection performance of the proposed FedFogery is also improved.
When the global communication times reached about ten times, the forgery detection performance of the global server reaches the best point, with an accuracy rate of 79.21%. It proves the proposed residual federated learning strategy could help the forgery detection model not only train weights collaboratively for data security, but also would maintain strong performance in forgery detection tasks.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2210.09563/assets/x5.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="211" height="130" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The face forgery detection evaluation accuracies of federated learning framework on WildDeepfake dataset.</figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">To further evaluate the performance of the residual feature learning strategy of the proposed algorithm, we design the ablation study experiments on Hybrid-domain face forgery dataset. For the convenience of comparison, the same parameters setting is utilized as elaborated in Section IV-B. The accuracy and AUC separately degrade at 83.36% and 91.02% when directly removing the residual feature instead of the raw images. It is because exploring the specific characteristics of reconstruction residual is easier than inputting raw images in the multiple domain forgery scenarios. The proposed residual feature learning strategy could avoid overfitting and effectively capture domain-invariant discrepancy information between real and fake images, which decreases the accuracy by 2.19% on the Hybrid-domain face forgery dataset.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Analysis of residual feature</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The designed discriminative residual feature learning goals to extract discriminative forgery clues even for unknown artifact types. Existing traditional forgery detection methods generally directly input the raw image into an end-to-end network for binary classification. However, when processing data from complex unknown artifact patterns, the forgery detection performance is not encouraging. Different from direct feeding raw images into the network, we utilized a variational autoencoder framework to reconstruct the image and extract the residual feature to explore forgery clues.
In order to verify the effectiveness of the proposed residual learning strategy, we utilize the t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> to visualize the feature distribution when inputting original images and residual images separately in the data center.
For the fairness of the comparison, we extract features in the layer before the fully connected layer in the ResNet50 network for original images.
The results are shown in Figure 6.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">We select 1500 authentic images and 1500 fake images from the Hybrid-domain forgery dataset here.
It can be observed that the feature distribution of the fake images represented by the green part (in the left subfigure of Figure 6) is scattered and overlap with the red part.
It is because the classifier has a poorer ability to discriminate the forged type when inputting original images.
As shown in the right subfigure of Figure 6, the feature distribution of fake images represented by the green part is more concentrated, indicating that fake images are embedded into a relatively compact feature space. This also demonstrates that our proposed method could capture more discriminative common representations for forgery detection.
Thus, the proposed residual learning strategy can effectively improve the generalization ability of forgery detection.</p>
</div>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.09563/assets/x6.png" id="S5.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="92" height="68" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.09563/assets/x7.png" id="S5.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The left subfigure shows the feature distribution learned by the data center directly using ResNet50 on the original images; The right subfigure presents the feature distribution of our method on the reconstructed residual images.</figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Failure cases</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">As shown in Figure 7, we utilized the Grad-CAM algorithm as the visualization tool to analyze failure cases.
For example, the left two samples show that the detection model pays much attention to the margin region, which would make wrong judgments.
The right two samples show the detection model is affected by the complex background.
Thus, face forgery detection in the wild is still a challenging problem.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2210.09563/assets/x8.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="138" height="68" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Grad-CAM activation map for failure cases on WildDeepfake dataset.</figcaption>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">Visualization Results</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">As shown in Figure 8, in order to analyze the visualization results of each data center and global server focusing on different regions, we utilized the gradient-based visualization tool to generate a Grad-CAM based attention map <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. It reveals the differences in the range of regions that data centers and the global server rely on for forgery detection.
As shown in subfigures (a)-(d), each data center and global server network focuses on the local facial semantic regions, which would be helpful for authenticity identification.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">In Figure 8 (a), the first eight columns represent the visualization effect when the data center model determines that the real face image is true. The attention map area of the real face has a small region range, while the last column shows that the data center model mistakenly classifies the real face with a different attention map.
<em id="S5.SS4.p2.1.1" class="ltx_emph ltx_font_italic">We find that when the forgery detection model makes the wrong decision, the attention map would not focus on suitable local face regions</em>;
In Figure 8 (b) the first eight columns represent the visualization results when the data center model identifies the input fake face image as false.
The attention map area of these inputs almost focuses on artifact regions (like mouth, eyes and nose).
However, the last column shows the attention map when the data center model mistakenly identifies the fake face as true.
It can be found that these attention maps don‚Äôt focus on the semantic regions, but instead on backgrounds;
In Figure 8 (c), the first eight columns represent the visualization results when the global server model identifies the real face image as true.
Similarly in Figure 8 (a), the proposed model mainly focuses on the local semantic regions.
For the wrong identification as shown in the last column, the results show the model pays much attention on redundant face regions but not local regions;
In Figure 8 (d), the first eight columns represent the visualization results when the global server model identifies the forged face image as fake.
Similarly in Figure 8 (b), the model also extracts discriminative forgery representation in local semantic artifact regions.
The wrong results as shown in the last column show the model is mistaken by the disturbance of complex backgrounds.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">Overall, these visualization results clearly prove our proposed FedFogery could extract discriminative forgery representation to focus on local semantic face regions to improve interpretability.
Additionally, it is interesting to find that the visualization attention map could help to directly identify the artifact regions to expand the forgery detection field in the future.</p>
</div>
<figure id="S5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.09563/assets/x9.png" id="S5.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="257" height="58" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Data Center (Real)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.09563/assets/x10.png" id="S5.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="257" height="57" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Data Center (Fake)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.09563/assets/x11.png" id="S5.F8.sf3.g1" class="ltx_graphics ltx_img_landscape" width="257" height="57" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Global Server (Real)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F8.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.09563/assets/x12.png" id="S5.F8.sf4.g1" class="ltx_graphics ltx_img_landscape" width="257" height="57" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Global Server (Fake)</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="S5.F8.2.1" class="ltx_text ltx_font_bold">Grad-CAM attention map</span>. The first eight columns show the designed model identifies the input authenticity correctly; the last column shows the designed model makes wrong decisions.</figcaption>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.5.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.6.2" class="ltx_text ltx_font_italic">Future Directions</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">Although data-driven forgery detection methods have achieved great progress in recent years, which benefit from the contraption of deep network architecture and large-scale labeled data. To further mimic real-world scenarios, more and more researchers focus on the generalization ability in face forgery detection tasks. Thus, we construct the novel hybrid-dataset and generalized-dataset forgery detection task to focus on detecting forgery clues in cross-domain even unknown artifact types. In this section, we discuss several unsolved problems and future potential directions to inspire researches in the community.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p"><span id="S5.SS5.p2.1.1" class="ltx_text ltx_font_bold">Unsupervised/Weakly Supervised Forgery Detection</span>: Nowadays, most existing face forgery detection models are trained with fully supervised training data. However, more and more unknown artifact patterns would be created with the development of the deep generative model. And it is not impossible to label every artifact type accurately on the Internet. Thus, the key solution is to learn the general forgery clues to boost the forgery detection model performance. Unsupervised or weakly supervised learning(e.g. self-attention mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, dynamic convolution<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, meta-learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>) provides a possible solution to learn the essential discrepancy between real and fake images, which can strengthen the usability and scalability.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para">
<p id="S5.SS5.p3.1" class="ltx_p"><span id="S5.SS5.p3.1.1" class="ltx_text ltx_font_bold">Robust Forgery Detection Representation</span>: In real-world scenarios, these forgery detection models will be applied in complex scenarios, which results in image changes in illumination, occlusion, perturbation, etc. Meanwhile, malicious attack algorithms would possibly force the detection model to make the wrong decision. Thus, learning a robust detection representation to defend adversarial examples and noises is an important goal in security and privacy protection fields.</p>
</div>
<div id="S5.SS5.p4" class="ltx_para">
<p id="S5.SS5.p4.1" class="ltx_p"><span id="S5.SS5.p4.1.1" class="ltx_text ltx_font_bold">Interpretable Forgery Detection</span>: Most existing deep learning-based model is still a ‚Äúblack box‚Äù, which lacks theoretical explanation. It is necessary and important to explore interpretability, not only high accuracy. The interpretable forgery detection could help expand more real application scenarios. Meta-learning and hybrid knowledge models may provide a feasible way to solve the interpretability problem in the future.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we propose a novel generalized residual Federated learning method for face Forgery detection (FedForgery).
To improve the forgery detection generalization, we design a variational autoencoder to learn robust discriminative residual feature maps to detect forgery clues.
Additionally, the residual federated learning framework is introduced to train the forgery detection model collaboratively with multiple local data centers, which is essential to protect data privacy.
We conduct several experiments for face forgery detection tasks in complex real-world scenarios.
The experimental results demonstrate that the proposed FedForgery could effectively improve the ability of model generalization and privacy protection.
In the future, we will focus on exploring robust and interpretable face forgery detection methods to mimic more real-world scenarios.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S.¬†Chen, T.¬†Yao, Y.¬†Chen, S.¬†Ding, J.¬†Li, and R.¬†Ji, ‚ÄúLocal relation learning
for face forgery detection,‚Äù in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em>, vol.¬†35, no.¬†2, 2021, pp. 1081‚Äì1088.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Y.¬†Qian, G.¬†Yin, L.¬†Sheng, Z.¬†Chen, and J.¬†Shao, ‚ÄúThinking in frequency: Face
forgery detection by mining frequency-aware clues,‚Äù in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">European
conference on computer vision</em>.¬†¬†¬†Springer, 2020, pp. 86‚Äì103.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
L.¬†Li, J.¬†Bao, T.¬†Zhang, H.¬†Yang, D.¬†Chen, F.¬†Wen, and B.¬†Guo, ‚ÄúFace x-ray for
more general face forgery detection,‚Äù in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition</em>, 2020, pp. 5001‚Äì5010.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
X.¬†Yang, Y.¬†Li, and S.¬†Lyu, ‚ÄúExposing deep fakes using inconsistent head
poses,‚Äù in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019-2019 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP)</em>.¬†¬†¬†IEEE, 2019, pp. 8261‚Äì8265.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X.¬†Li, Y.¬†Lang, Y.¬†Chen, X.¬†Mao, Y.¬†He, S.¬†Wang, H.¬†Xue, and Q.¬†Lu, ‚ÄúSharp
multiple instance learning for deepfake video detection,‚Äù in
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM international conference on multimedia</em>,
2020, pp. 1864‚Äì1872.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
E.¬†Sabir, J.¬†Cheng, A.¬†Jaiswal, W.¬†AbdAlmageed, I.¬†Masi, and P.¬†Natarajan,
‚ÄúRecurrent convolutional strategies for face manipulation detection in
videos,‚Äù <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Interfaces (GUI)</em>, vol.¬†3, no.¬†1, pp. 80‚Äì87, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
B.¬†McMahan, E.¬†Moore, D.¬†Ramage, S.¬†Hampson, and B.¬†A. y¬†Arcas,
‚ÄúCommunication-efficient learning of deep networks from decentralized
data,‚Äù in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.¬†¬†¬†PMLR, 2017, pp. 1273‚Äì1282.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y.¬†Nirkin, L.¬†Wolf, Y.¬†Keller, and T.¬†Hassner, ‚ÄúDeepfake detection based on
discrepancies between faces and their context,‚Äù <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Pattern Analysis and Machine Intelligence</em>, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
P.¬†Zhou, X.¬†Han, V.¬†I. Morariu, and L.¬†S. Davis, ‚ÄúTwo-stream neural networks
for tampered face detection,‚Äù in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">2017 IEEE conference on computer
vision and pattern recognition workshops (CVPRW)</em>.¬†¬†¬†IEEE, 2017, pp. 1831‚Äì1839.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.¬†Li and S.¬†Lyu, ‚ÄúExposing deepfake videos by detecting face warping
artifacts,‚Äù <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.00656</em>, 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
P.¬†Yu, J.¬†Fei, Z.¬†Xia, Z.¬†Zhou, and J.¬†Weng, ‚ÄúImproving generalization by
commonality learning in face forgery detection,‚Äù <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Information Forensics and Security</em>, vol.¬†17, pp. 547‚Äì558, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
U.¬†Scherhag, C.¬†Rathgeb, J.¬†Merkle, and C.¬†Busch, ‚ÄúDeep face representations
for differential morphing attack detection,‚Äù <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Information Forensics and Security</em>, vol.¬†15, pp. 3625‚Äì3639, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J.¬†Yang, A.¬†Li, S.¬†Xiao, W.¬†Lu, and X.¬†Gao, ‚ÄúMtd-net: Learning to detect
deepfakes images by multi-scale texture difference,‚Äù <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Information Forensics and Security</em>, vol.¬†16, pp. 4234‚Äì4245, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Z.¬†Jian, J.¬†Li, Z.¬†Fang, S.¬†Yan, and J.¬†Feng, ‚ÄúMarginalized cnn: Learning deep
invariant representations,‚Äù in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">28th British Machine Vision Conference,
2017</em>, 2017.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
C.¬†Miao, Z.¬†Tan, Q.¬†Chu, N.¬†Yu, and G.¬†Guo, ‚ÄúHierarchical frequency-assisted
interactive networks for face manipulation detection,‚Äù <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Information Forensics and Security</em>, vol.¬†17, pp. 3008‚Äì3021,
2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J.¬†Wang, Y.¬†Sun, and J.¬†Tang, ‚ÄúLisiam: Localization invariance siamese network
for deepfake detection,‚Äù <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em>, vol.¬†17, pp. 2425‚Äì2436, 2022.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J.¬†Wang, Y.¬†Qi, J.¬†Hu, and J.¬†Hu, ‚ÄúFace forgery detection with a fused
attention mechanism,‚Äù in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">2022 3rd International Conference on Computer
Vision, Image and Deep Learning &amp; International Conference on Computer
Engineering and Applications (CVIDL &amp; ICCEA)</em>, 2022, pp. 722‚Äì725.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
R.¬†Durall, M.¬†Keuper, F.-J. Pfreundt, and J.¬†Keuper, ‚ÄúUnmasking deepfakes with
simple features,‚Äù <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.00686</em>, 2019.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
X.¬†Dong, J.¬†Bao, D.¬†Chen, T.¬†Zhang, W.¬†Zhang, N.¬†Yu, D.¬†Chen, F.¬†Wen, and
B.¬†Guo, ‚ÄúProtecting celebrities from deepfake with identity consistency
transformer,‚Äù in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition</em>, 2022, pp. 9458‚Äì9468.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
X.¬†Zhu, H.¬†Fei, B.¬†Zhang, T.¬†Zhang, X.¬†Zhang, S.¬†Z. Li, and Z.¬†Lei, ‚ÄúFace
forgery detection by 3d decomposition and composition search,‚Äù <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Pattern Analysis and Machine Intelligence</em>, vol.¬†45, no.¬†7,
pp. 8342‚Äì8357, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
H.¬†Zhao, W.¬†Zhou, D.¬†Chen, T.¬†Wei, W.¬†Zhang, and N.¬†Yu, ‚ÄúMulti-attentional
deepfake detection,‚Äù in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition</em>, 2021, pp. 2185‚Äì2194.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J.¬†Cao, C.¬†Ma, T.¬†Yao, S.¬†Chen, S.¬†Ding, and X.¬†Yang, ‚ÄúEnd-to-end
reconstruction-classification learning for face forgery detection,‚Äù in
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2022, pp. 4113‚Äì4122.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D.¬†CIFTCIUA and Y.¬†Fakecatcher, ‚ÄúDetection of synthetic portrait videos using
biological signals,‚Äù <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE Transactionson PatternAnalysis and Machine
Intelligence</em>, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
P.¬†Saikia, D.¬†Dholaria, P.¬†Yadav, V.¬†Patel, and M.¬†Roy, ‚ÄúA hybrid cnn-lstm
model for video deepfake detection by leveraging optical flow features,‚Äù in
<em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">2022 International Joint Conference on Neural Networks (IJCNN)</em>.¬†¬†¬†IEEE, 2022, pp. 1‚Äì7.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
I.¬†Masi, A.¬†Killekar, R.¬†M. Mascarenhas, S.¬†P. Gurudatt, and W.¬†AbdAlmageed,
‚ÄúTwo-branch recurrent network for isolating deepfakes in videos,‚Äù in
<em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European conference on computer vision (ECCV)</em>,
2020, pp. 667‚Äì684.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
I.¬†Ganiyusufoglu, L.¬†M. Ng√¥, N.¬†Savov, S.¬†Karaoglu, and T.¬†Gevers,
‚ÄúSpatio-temporal features for generalized detection of deepfake videos,‚Äù
<em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11844</em>, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
L.¬†Trinh, M.¬†Tsang, S.¬†Rambhatla, and Y.¬†Liu, ‚ÄúInterpretable and trustworthy
deepfake detection via dynamic prototypes,‚Äù in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
IEEE/CVF winter conference on applications of computer vision</em>, 2021, pp.
1973‚Äì1983.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
D.¬†G√ºera and E.¬†J. Delp, ‚ÄúDeepfake video detection using recurrent neural
networks,‚Äù in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">2018 15th IEEE international conference on advanced
video and signal based surveillance (AVSS)</em>.¬†¬†¬†IEEE, 2018, pp. 1‚Äì6.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Z.¬†Gu, Y.¬†Chen, T.¬†Yao, S.¬†Ding, J.¬†Li, F.¬†Huang, and L.¬†Ma, ‚ÄúSpatiotemporal
inconsistency learning for deepfake video detection,‚Äù in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 29th ACM International Conference on Multimedia</em>, 2021, pp.
3473‚Äì3481.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Y.¬†Li, M.-C. Chang, and S.¬†Lyu, ‚ÄúIn ictu oculi: Exposing ai created fake
videos by detecting eye blinking,‚Äù in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International workshop
on information forensics and security (WIFS)</em>.¬†¬†¬†IEEE, 2018, pp. 1‚Äì7.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
O.¬†de¬†Lima, S.¬†Franklin, S.¬†Basu, B.¬†Karwoski, and A.¬†George, ‚ÄúDeepfake
detection using spatiotemporal convolutional networks,‚Äù <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2006.14749</em>, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
T.¬†Li, A.¬†K. Sahu, M.¬†Zaheer, M.¬†Sanjabi, A.¬†Talwalkar, and V.¬†Smith,
‚ÄúFederated optimization in heterogeneous networks,‚Äù <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of
Machine Learning and Systems</em>, vol.¬†2, pp. 429‚Äì450, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
W.¬†Zhuang, Y.¬†Wen, and S.¬†Zhang, ‚ÄúJoint optimization in edge-cloud continuum
for federated unsupervised person re-identification,‚Äù in <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 29th ACM International Conference on Multimedia</em>, 2021, pp. 433‚Äì441.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
C.-H. Yao, B.¬†Gong, H.¬†Qi, Y.¬†Cui, Y.¬†Zhu, and M.-H. Yang, ‚ÄúFederated
multi-target domain adaptation,‚Äù in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition</em>, 2022, pp. 1424‚Äì1433.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
R.¬†Shao, P.¬†Perera, P.¬†C. Yuen, and V.¬†M. Patel, ‚ÄúFederated generalized face
presentation attack detection,‚Äù <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks
and Learning Systems</em>, 2022.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
H.¬†Zhou, G.¬†Yang, H.¬†Dai, and G.¬†Liu, ‚ÄúPflf: Privacy-preserving federated
learning framework for edge computing,‚Äù <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Information Forensics and Security</em>, vol.¬†17, pp. 1905‚Äì1918, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
X.¬†Liu, H.¬†Li, G.¬†Xu, Z.¬†Chen, X.¬†Huang, and R.¬†Lu, ‚ÄúPrivacy-enhanced
federated learning against poisoning adversaries,‚Äù <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Information Forensics and Security</em>, vol.¬†16, pp. 4574‚Äì4588, 2021.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Y.¬†Niu and W.¬†Deng, ‚ÄúFederated learning for face recognition with gradient
correction,‚Äù in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, vol.¬†36, no.¬†2, 2022, pp. 1999‚Äì2007.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
W.¬†Zhuang, X.¬†Gan, Y.¬†Wen, X.¬†Zhang, S.¬†Zhang, and S.¬†Yi, ‚ÄúFederated
unsupervised domain adaptation for face recognition,‚Äù <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2204.04382</em>, 2022.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
L.¬†Jiang, R.¬†Li, W.¬†Wu, C.¬†Qian, and C.¬†C. Loy, ‚ÄúDeeperforensics-1.0: A
large-scale dataset for real-world face forgery detection,‚Äù in
<em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2020, pp. 2889‚Äì2898.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
A.¬†Van Den¬†Oord, O.¬†Vinyals <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúNeural discrete representation
learning,‚Äù <em id="bib.bib41.2.2" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
vol.¬†30, 2017.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
A.¬†Rossler, D.¬†Cozzolino, L.¬†Verdoliva, C.¬†Riess, J.¬†Thies, and M.¬†Nie√üner,
‚ÄúFaceforensics++: Learning to detect manipulated facial images,‚Äù in
<em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2019, pp. 1‚Äì11.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
J.¬†Thies, M.¬†Zollhofer, M.¬†Stamminger, C.¬†Theobalt, and M.¬†Nie√üner,
‚ÄúFace2face: Real-time face capture and reenactment of rgb videos,‚Äù in
<em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2016, pp. 2387‚Äì2395.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
J.¬†Thies, M.¬†Zollh√∂fer, and M.¬†Nie√üner, ‚ÄúDeferred neural rendering:
Image synthesis using neural textures,‚Äù <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics
(TOG)</em>, vol.¬†38, no.¬†4, pp. 1‚Äì12, 2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
B.¬†Zi, M.¬†Chang, J.¬†Chen, X.¬†Ma, and Y.-G. Jiang, ‚ÄúWilddeepfake: A challenging
real-world dataset for deepfake detection,‚Äù in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th
ACM international conference on multimedia</em>, 2020, pp. 2382‚Äì2390.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
C.¬†JEONG and T.¬†KIM, ‚ÄúEye blink detection using algorithm based on dlib and
opencv library for game players in competitive environments,‚Äù <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Journal
of International Research in Medical and Pharmaceutical Sciences</em>, pp.
33‚Äì45, 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
A.¬†Paszke, S.¬†Gross, F.¬†Massa, A.¬†Lerer, J.¬†Bradbury, G.¬†Chanan, T.¬†Killeen,
Z.¬†Lin, N.¬†Gimelshein, L.¬†Antiga <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúPytorch: An imperative
style, high-performance deep learning library,‚Äù <em id="bib.bib47.2.2" class="ltx_emph ltx_font_italic">Advances in neural
information processing systems</em>, vol.¬†32, 2019.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
J.¬†Walker, C.¬†Doersch, A.¬†Gupta, and M.¬†Hebert, ‚ÄúAn uncertain future:
Forecasting from static images using variational autoencoders,‚Äù in
<em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European conference on computer vision (ECCV)</em>,
2016, pp. 835‚Äì851.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Q.¬†A. Al-Haija and A.¬†Adebanjo, ‚ÄúBreast cancer diagnosis in histopathological
images using resnet-50 convolutional neural network,‚Äù in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">2020 IEEE
International IOT, Electronics and Mechatronics Conference
(IEMTRONICS)</em>.¬†¬†¬†IEEE, 2020, pp. 1‚Äì7.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
T.¬†Dzanic, K.¬†Shah, and F.¬†Witherden, ‚ÄúFourier spectrum discrepancies in deep
network generated images,‚Äù <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em>, vol.¬†33, pp. 3022‚Äì3032, 2020.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
S.-Y. Wang, O.¬†Wang, R.¬†Zhang, A.¬†Owens, and A.¬†A. Efros, ‚ÄúCnn-generated
images are surprisingly easy to spot‚Ä¶ for now,‚Äù in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2020, pp.
8695‚Äì8704.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
F.¬†Chollet, ‚ÄúXception: Deep learning with depthwise separable convolutions,‚Äù
in <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2017, pp. 1251‚Äì1258.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Y.¬†Luo, Y.¬†Zhang, J.¬†Yan, and W.¬†Liu, ‚ÄúGeneralizing face forgery detection
with high-frequency features,‚Äù in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition</em>, 2021, pp. 16‚Äâ317‚Äì16‚Äâ326.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
C.¬†Wang and W.¬†Deng, ‚ÄúRepresentative forgery mining for fake face detection,‚Äù
in <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2021, pp. 14‚Äâ923‚Äì14‚Äâ932.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
K.¬†Sun, T.¬†Yao, S.¬†Chen, S.¬†Ding, J.¬†Li, and R.¬†Ji, ‚ÄúDual contrastive learning
for general face forgery detection,‚Äù in <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI
Conference on Artificial Intelligence</em>, vol.¬†36, no.¬†2, 2022, pp. 2316‚Äì2324.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
C.¬†Zhang, Y.¬†Xie, H.¬†Bai, B.¬†Yu, W.¬†Li, and Y.¬†Gao, ‚ÄúA survey on federated
learning,‚Äù <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 216, p. 106775, 2021.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
W.¬†Zhuang, Y.¬†Wen, X.¬†Zhang, X.¬†Gan, D.¬†Yin, D.¬†Zhou, S.¬†Zhang, and S.¬†Yi,
‚ÄúPerformance optimization of federated person re-identification via
benchmark analysis,‚Äù in <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM International
Conference on Multimedia</em>, 2020, pp. 955‚Äì963.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
D.¬†Tran, L.¬†Bourdev, R.¬†Fergus, L.¬†Torresani, and M.¬†Paluri, ‚ÄúLearning
spatiotemporal features with 3d convolutional networks,‚Äù in
<em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2015, pp. 4489‚Äì4497.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
L.¬†Wang, Y.¬†Xiong, Z.¬†Wang, Y.¬†Qiao, D.¬†Lin, X.¬†Tang, and L.¬†Van¬†Gool,
‚ÄúTemporal segment networks: Towards good practices for deep action
recognition,‚Äù in <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European conference on computer
vision (ECCV)</em>.¬†¬†¬†Springer, 2016, pp.
20‚Äì36.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
J.¬†Carreira and A.¬†Zisserman, ‚ÄúQuo vadis, action recognition? a new model and
the kinetics dataset,‚Äù in <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition</em>, 2017, pp. 6299‚Äì6308.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
K.¬†He, X.¬†Zhang, S.¬†Ren, and J.¬†Sun, ‚ÄúDeep residual learning for image
recognition,‚Äù in <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition</em>, 2016, pp. 770‚Äì778.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
S.¬†Hochreiter and J.¬†Schmidhuber, ‚ÄúLong short-term memory,‚Äù <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Neural
computation</em>, vol.¬†9, no.¬†8, pp. 1735‚Äì1780, 1997.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
L.¬†Van¬†der Maaten and G.¬†Hinton, ‚ÄúVisualizing data using t-sne.‚Äù
<em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Journal of machine learning research</em>, vol.¬†9, no.¬†11, 2008.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
R.¬†R. Selvaraju, M.¬†Cogswell, A.¬†Das, R.¬†Vedantam, D.¬†Parikh, and D.¬†Batra,
‚ÄúGrad-cam: Visual explanations from deep networks via gradient-based
localization,‚Äù in <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition</em>, 2017, pp. 618‚Äì626.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
W.¬†Zhuang, Q.¬†Chu, Z.¬†Tan, Q.¬†Liu, H.¬†Yuan, C.¬†Miao, Z.¬†Luo, and N.¬†Yu,
‚ÄúUia-vit: Unsupervised inconsistency-aware method based on vision
transformer for face forgery detection,‚Äù in <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
European conference on computer vision (ECCV)</em>, 2022, pp. 391‚Äì407.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
F.¬†Zhao, J.¬†Zhao, S.¬†Yan, and J.¬†Feng, ‚ÄúDynamic conditional networks for
few-shot learning,‚Äù in <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European conference on
computer vision (ECCV)</em>, 2018, pp. 19‚Äì35.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
J.¬†Zhao, J.¬†Xing, L.¬†Xiong, S.¬†Yan, and J.¬†Feng, ‚ÄúRecognizing profile faces by
imagining frontal view,‚Äù <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>,
vol. 128, pp. 460‚Äì478, 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2210.09562" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2210.09563" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2210.09563">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2210.09563" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2210.09564" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 03:48:37 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
