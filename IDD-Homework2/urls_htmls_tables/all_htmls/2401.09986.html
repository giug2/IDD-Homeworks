<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2401.09986] FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling</title><meta property="og:description" content="Federated learning are inherently hampered by data heterogeneity: non-iid distributed training data over local clients. We propose a novel model training approach for federated learning, FLexChill, which exploits the Lâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2401.09986">

<!--Generated on Tue Feb 27 09:05:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Anonymous Submission
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Kichang Lee

</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Songkuk Kim
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">JeongGil Ko
Yonsei University
<br class="ltx_break">{kichang.lee, songkuk.kim, jeonggil.ko}@yonsei.ac.kr
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.2" class="ltx_p">Federated learning are inherently hampered by data heterogeneity: non-iid distributed training data over local clients. We propose a novel model training approach for federated learning, <span id="id1.1.1" class="ltx_text ltx_font_italic">FLex<math id="id1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="id1.1.1.m1.1a"><mo id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><and id="id1.1.1.m1.1.1.cmml" xref="id1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span>, which exploits the <span id="id2.2.2" class="ltx_text ltx_font_italic">Logit Chilling</span> method. Through extensive evaluations, we demonstrate that, in the presence of non-iid data characteristics inherent in federated learning systems, this approach can expedite model convergence and improve inference accuracy. Quantitatively, from our experiments, we observe up to 6<math id="id2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="id2.2.m1.1a"><mo id="id2.2.m1.1.1" xref="id2.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="id2.2.m1.1b"><times id="id2.2.m1.1.1.cmml" xref="id2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m1.1c">\times</annotation></semantics></math> improvement in the global federated learning model convergence time, and up to 3.37% improvement in inference accuracy.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning represents a paradigm enabling the training of effective models within distributed environments without explicitly exposing local dataÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2017</a>)</cite>. This approach provides opportunities for communication and computation efficiency during training by sharing model parameters/gradients learned independently from local leaning processes while suppressing raw data transmissions. Furthermore, since training operations take place in a de-centralized manner, federated learning opens the possibility to parallelize the model training process via the assistance of local client devices. It presents an attractive solution for handling and exploiting the vast amounts of data generated by many mobile and Internet of Things (IoT) device entities consisting the overall systemÂ <cite class="ltx_cite ltx_citemacro_cite">Park <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2023a</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In contrast to conventional centralized training methods, federated learning faces challenges associated with delayed model convergence and limited performance. A fundamental challenge of federated learning arises from the disparity of training data used at each client device. Federated stochastic optimization encounters difficulties in determining optimal parameters, leading to increased communication overhead between local devices and the central server, as well as the need for additional training on (typically resource limited) local devicesÂ <cite class="ltx_cite ltx_citemacro_cite">Zhao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib27" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To address these challenges, a number of prior research have focused on optimizing the local training operations on federated learning clients or on refining the server-side aggregation process. For instance, FedProxÂ <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> controls the number of iterations for each local device, aiming to train models resilient to challenges posed by non-independent and non-iid data environments. SCAFFOLDÂ <cite class="ltx_cite ltx_citemacro_cite">Karimireddy <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> achieves expedited convergence and improved model accuracyÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2017</a>)</cite> by introducing a correction term during the model aggregation phase to balance the influence of each client. These operations alleviate the problems posed by the non-iid environment, a common dataset configuration for federated learning clients.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.5" class="ltx_p">This paper proposes a novel model training approach for federated learning, <span id="S1.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FLex<math id="S1.p4.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S1.p4.1.1.m1.1a"><mo id="S1.p4.1.1.m1.1.1" xref="S1.p4.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S1.p4.1.1.m1.1b"><and id="S1.p4.1.1.m1.1.1.cmml" xref="S1.p4.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span> (<span id="S1.p4.5.2" class="ltx_text ltx_font_bold">F</span>ederated <span id="S1.p4.5.3" class="ltx_text ltx_font_bold">L</span>earning <span id="S1.p4.5.4" class="ltx_text ltx_font_bold">EX</span>ploiting logit <span id="S1.p4.5.5" class="ltx_text ltx_font_bold">Chill</span>ing), that targets to boost the convergence and model performance via temperature scaling, namely <span id="S1.p4.5.6" class="ltx_text ltx_font_italic">logit chilling</span>, during the local model training operations. Note that a typical neural network generates a probability (<math id="S1.p4.2.m1.1" class="ltx_Math" alttext="q_{i}" display="inline"><semantics id="S1.p4.2.m1.1a"><msub id="S1.p4.2.m1.1.1" xref="S1.p4.2.m1.1.1.cmml"><mi id="S1.p4.2.m1.1.1.2" xref="S1.p4.2.m1.1.1.2.cmml">q</mi><mi id="S1.p4.2.m1.1.1.3" xref="S1.p4.2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.2.m1.1b"><apply id="S1.p4.2.m1.1.1.cmml" xref="S1.p4.2.m1.1.1"><csymbol cd="ambiguous" id="S1.p4.2.m1.1.1.1.cmml" xref="S1.p4.2.m1.1.1">subscript</csymbol><ci id="S1.p4.2.m1.1.1.2.cmml" xref="S1.p4.2.m1.1.1.2">ğ‘</ci><ci id="S1.p4.2.m1.1.1.3.cmml" xref="S1.p4.2.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m1.1c">q_{i}</annotation></semantics></math>) for each class from its neural network logits (<math id="S1.p4.3.m2.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S1.p4.3.m2.1a"><msub id="S1.p4.3.m2.1.1" xref="S1.p4.3.m2.1.1.cmml"><mi id="S1.p4.3.m2.1.1.2" xref="S1.p4.3.m2.1.1.2.cmml">z</mi><mi id="S1.p4.3.m2.1.1.3" xref="S1.p4.3.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.3.m2.1b"><apply id="S1.p4.3.m2.1.1.cmml" xref="S1.p4.3.m2.1.1"><csymbol cd="ambiguous" id="S1.p4.3.m2.1.1.1.cmml" xref="S1.p4.3.m2.1.1">subscript</csymbol><ci id="S1.p4.3.m2.1.1.2.cmml" xref="S1.p4.3.m2.1.1.2">ğ‘§</ci><ci id="S1.p4.3.m2.1.1.3.cmml" xref="S1.p4.3.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m2.1c">z_{i}</annotation></semantics></math>) by applying a softmax operation (Eq.Â <a href="#S1.E1" title="In 1 Introduction â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) with the temperature <math id="S1.p4.4.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p4.4.m3.1a"><mi id="S1.p4.4.m3.1.1" xref="S1.p4.4.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p4.4.m3.1b"><ci id="S1.p4.4.m3.1.1.cmml" xref="S1.p4.4.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m3.1c">T</annotation></semantics></math> conventionally set to 1. However, it is not uncommon in other application scenarios to exploit even higher temperature values (i.e., <math id="S1.p4.5.m4.2" class="ltx_Math" alttext="T\in(1,\infty)" display="inline"><semantics id="S1.p4.5.m4.2a"><mrow id="S1.p4.5.m4.2.3" xref="S1.p4.5.m4.2.3.cmml"><mi id="S1.p4.5.m4.2.3.2" xref="S1.p4.5.m4.2.3.2.cmml">T</mi><mo id="S1.p4.5.m4.2.3.1" xref="S1.p4.5.m4.2.3.1.cmml">âˆˆ</mo><mrow id="S1.p4.5.m4.2.3.3.2" xref="S1.p4.5.m4.2.3.3.1.cmml"><mo stretchy="false" id="S1.p4.5.m4.2.3.3.2.1" xref="S1.p4.5.m4.2.3.3.1.cmml">(</mo><mn id="S1.p4.5.m4.1.1" xref="S1.p4.5.m4.1.1.cmml">1</mn><mo id="S1.p4.5.m4.2.3.3.2.2" xref="S1.p4.5.m4.2.3.3.1.cmml">,</mo><mi mathvariant="normal" id="S1.p4.5.m4.2.2" xref="S1.p4.5.m4.2.2.cmml">âˆ</mi><mo stretchy="false" id="S1.p4.5.m4.2.3.3.2.3" xref="S1.p4.5.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.5.m4.2b"><apply id="S1.p4.5.m4.2.3.cmml" xref="S1.p4.5.m4.2.3"><in id="S1.p4.5.m4.2.3.1.cmml" xref="S1.p4.5.m4.2.3.1"></in><ci id="S1.p4.5.m4.2.3.2.cmml" xref="S1.p4.5.m4.2.3.2">ğ‘‡</ci><interval closure="open" id="S1.p4.5.m4.2.3.3.1.cmml" xref="S1.p4.5.m4.2.3.3.2"><cn type="integer" id="S1.p4.5.m4.1.1.cmml" xref="S1.p4.5.m4.1.1">1</cn><infinity id="S1.p4.5.m4.2.2.cmml" xref="S1.p4.5.m4.2.2"></infinity></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.5.m4.2c">T\in(1,\infty)</annotation></semantics></math>), for example, in knowledge distillationÂ <cite class="ltx_cite ltx_citemacro_cite">Hinton <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2015</a>); Touvron <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> or neural network calibrationÂ <cite class="ltx_cite ltx_citemacro_cite">Guo <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<table id="S1.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S1.E1.m1.5" class="ltx_Math" alttext="\xi(z,i,T)=q_{i}=\frac{exp(z_{i}/T)}{\sum_{j}exp(z_{j}/T)}" display="block"><semantics id="S1.E1.m1.5a"><mrow id="S1.E1.m1.5.6" xref="S1.E1.m1.5.6.cmml"><mrow id="S1.E1.m1.5.6.2" xref="S1.E1.m1.5.6.2.cmml"><mi id="S1.E1.m1.5.6.2.2" xref="S1.E1.m1.5.6.2.2.cmml">Î¾</mi><mo lspace="0em" rspace="0em" id="S1.E1.m1.5.6.2.1" xref="S1.E1.m1.5.6.2.1.cmml">â€‹</mo><mrow id="S1.E1.m1.5.6.2.3.2" xref="S1.E1.m1.5.6.2.3.1.cmml"><mo stretchy="false" id="S1.E1.m1.5.6.2.3.2.1" xref="S1.E1.m1.5.6.2.3.1.cmml">(</mo><mi id="S1.E1.m1.3.3" xref="S1.E1.m1.3.3.cmml">z</mi><mo id="S1.E1.m1.5.6.2.3.2.2" xref="S1.E1.m1.5.6.2.3.1.cmml">,</mo><mi id="S1.E1.m1.4.4" xref="S1.E1.m1.4.4.cmml">i</mi><mo id="S1.E1.m1.5.6.2.3.2.3" xref="S1.E1.m1.5.6.2.3.1.cmml">,</mo><mi id="S1.E1.m1.5.5" xref="S1.E1.m1.5.5.cmml">T</mi><mo stretchy="false" id="S1.E1.m1.5.6.2.3.2.4" xref="S1.E1.m1.5.6.2.3.1.cmml">)</mo></mrow></mrow><mo id="S1.E1.m1.5.6.3" xref="S1.E1.m1.5.6.3.cmml">=</mo><msub id="S1.E1.m1.5.6.4" xref="S1.E1.m1.5.6.4.cmml"><mi id="S1.E1.m1.5.6.4.2" xref="S1.E1.m1.5.6.4.2.cmml">q</mi><mi id="S1.E1.m1.5.6.4.3" xref="S1.E1.m1.5.6.4.3.cmml">i</mi></msub><mo id="S1.E1.m1.5.6.5" xref="S1.E1.m1.5.6.5.cmml">=</mo><mfrac id="S1.E1.m1.2.2" xref="S1.E1.m1.2.2.cmml"><mrow id="S1.E1.m1.1.1.1" xref="S1.E1.m1.1.1.1.cmml"><mi id="S1.E1.m1.1.1.1.3" xref="S1.E1.m1.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S1.E1.m1.1.1.1.2" xref="S1.E1.m1.1.1.1.2.cmml">â€‹</mo><mi id="S1.E1.m1.1.1.1.4" xref="S1.E1.m1.1.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S1.E1.m1.1.1.1.2a" xref="S1.E1.m1.1.1.1.2.cmml">â€‹</mo><mi id="S1.E1.m1.1.1.1.5" xref="S1.E1.m1.1.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S1.E1.m1.1.1.1.2b" xref="S1.E1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S1.E1.m1.1.1.1.1.1" xref="S1.E1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S1.E1.m1.1.1.1.1.1.2" xref="S1.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S1.E1.m1.1.1.1.1.1.1" xref="S1.E1.m1.1.1.1.1.1.1.cmml"><msub id="S1.E1.m1.1.1.1.1.1.1.2" xref="S1.E1.m1.1.1.1.1.1.1.2.cmml"><mi id="S1.E1.m1.1.1.1.1.1.1.2.2" xref="S1.E1.m1.1.1.1.1.1.1.2.2.cmml">z</mi><mi id="S1.E1.m1.1.1.1.1.1.1.2.3" xref="S1.E1.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S1.E1.m1.1.1.1.1.1.1.1" xref="S1.E1.m1.1.1.1.1.1.1.1.cmml">/</mo><mi id="S1.E1.m1.1.1.1.1.1.1.3" xref="S1.E1.m1.1.1.1.1.1.1.3.cmml">T</mi></mrow><mo stretchy="false" id="S1.E1.m1.1.1.1.1.1.3" xref="S1.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S1.E1.m1.2.2.2" xref="S1.E1.m1.2.2.2.cmml"><msub id="S1.E1.m1.2.2.2.2" xref="S1.E1.m1.2.2.2.2.cmml"><mo id="S1.E1.m1.2.2.2.2.2" xref="S1.E1.m1.2.2.2.2.2.cmml">âˆ‘</mo><mi id="S1.E1.m1.2.2.2.2.3" xref="S1.E1.m1.2.2.2.2.3.cmml">j</mi></msub><mrow id="S1.E1.m1.2.2.2.1" xref="S1.E1.m1.2.2.2.1.cmml"><mi id="S1.E1.m1.2.2.2.1.3" xref="S1.E1.m1.2.2.2.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S1.E1.m1.2.2.2.1.2" xref="S1.E1.m1.2.2.2.1.2.cmml">â€‹</mo><mi id="S1.E1.m1.2.2.2.1.4" xref="S1.E1.m1.2.2.2.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S1.E1.m1.2.2.2.1.2a" xref="S1.E1.m1.2.2.2.1.2.cmml">â€‹</mo><mi id="S1.E1.m1.2.2.2.1.5" xref="S1.E1.m1.2.2.2.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S1.E1.m1.2.2.2.1.2b" xref="S1.E1.m1.2.2.2.1.2.cmml">â€‹</mo><mrow id="S1.E1.m1.2.2.2.1.1.1" xref="S1.E1.m1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S1.E1.m1.2.2.2.1.1.1.2" xref="S1.E1.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S1.E1.m1.2.2.2.1.1.1.1" xref="S1.E1.m1.2.2.2.1.1.1.1.cmml"><msub id="S1.E1.m1.2.2.2.1.1.1.1.2" xref="S1.E1.m1.2.2.2.1.1.1.1.2.cmml"><mi id="S1.E1.m1.2.2.2.1.1.1.1.2.2" xref="S1.E1.m1.2.2.2.1.1.1.1.2.2.cmml">z</mi><mi id="S1.E1.m1.2.2.2.1.1.1.1.2.3" xref="S1.E1.m1.2.2.2.1.1.1.1.2.3.cmml">j</mi></msub><mo id="S1.E1.m1.2.2.2.1.1.1.1.1" xref="S1.E1.m1.2.2.2.1.1.1.1.1.cmml">/</mo><mi id="S1.E1.m1.2.2.2.1.1.1.1.3" xref="S1.E1.m1.2.2.2.1.1.1.1.3.cmml">T</mi></mrow><mo stretchy="false" id="S1.E1.m1.2.2.2.1.1.1.3" xref="S1.E1.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S1.E1.m1.5b"><apply id="S1.E1.m1.5.6.cmml" xref="S1.E1.m1.5.6"><and id="S1.E1.m1.5.6a.cmml" xref="S1.E1.m1.5.6"></and><apply id="S1.E1.m1.5.6b.cmml" xref="S1.E1.m1.5.6"><eq id="S1.E1.m1.5.6.3.cmml" xref="S1.E1.m1.5.6.3"></eq><apply id="S1.E1.m1.5.6.2.cmml" xref="S1.E1.m1.5.6.2"><times id="S1.E1.m1.5.6.2.1.cmml" xref="S1.E1.m1.5.6.2.1"></times><ci id="S1.E1.m1.5.6.2.2.cmml" xref="S1.E1.m1.5.6.2.2">ğœ‰</ci><vector id="S1.E1.m1.5.6.2.3.1.cmml" xref="S1.E1.m1.5.6.2.3.2"><ci id="S1.E1.m1.3.3.cmml" xref="S1.E1.m1.3.3">ğ‘§</ci><ci id="S1.E1.m1.4.4.cmml" xref="S1.E1.m1.4.4">ğ‘–</ci><ci id="S1.E1.m1.5.5.cmml" xref="S1.E1.m1.5.5">ğ‘‡</ci></vector></apply><apply id="S1.E1.m1.5.6.4.cmml" xref="S1.E1.m1.5.6.4"><csymbol cd="ambiguous" id="S1.E1.m1.5.6.4.1.cmml" xref="S1.E1.m1.5.6.4">subscript</csymbol><ci id="S1.E1.m1.5.6.4.2.cmml" xref="S1.E1.m1.5.6.4.2">ğ‘</ci><ci id="S1.E1.m1.5.6.4.3.cmml" xref="S1.E1.m1.5.6.4.3">ğ‘–</ci></apply></apply><apply id="S1.E1.m1.5.6c.cmml" xref="S1.E1.m1.5.6"><eq id="S1.E1.m1.5.6.5.cmml" xref="S1.E1.m1.5.6.5"></eq><share href="#S1.E1.m1.5.6.4.cmml" id="S1.E1.m1.5.6d.cmml" xref="S1.E1.m1.5.6"></share><apply id="S1.E1.m1.2.2.cmml" xref="S1.E1.m1.2.2"><divide id="S1.E1.m1.2.2.3.cmml" xref="S1.E1.m1.2.2"></divide><apply id="S1.E1.m1.1.1.1.cmml" xref="S1.E1.m1.1.1.1"><times id="S1.E1.m1.1.1.1.2.cmml" xref="S1.E1.m1.1.1.1.2"></times><ci id="S1.E1.m1.1.1.1.3.cmml" xref="S1.E1.m1.1.1.1.3">ğ‘’</ci><ci id="S1.E1.m1.1.1.1.4.cmml" xref="S1.E1.m1.1.1.1.4">ğ‘¥</ci><ci id="S1.E1.m1.1.1.1.5.cmml" xref="S1.E1.m1.1.1.1.5">ğ‘</ci><apply id="S1.E1.m1.1.1.1.1.1.1.cmml" xref="S1.E1.m1.1.1.1.1.1"><divide id="S1.E1.m1.1.1.1.1.1.1.1.cmml" xref="S1.E1.m1.1.1.1.1.1.1.1"></divide><apply id="S1.E1.m1.1.1.1.1.1.1.2.cmml" xref="S1.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S1.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S1.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S1.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S1.E1.m1.1.1.1.1.1.1.2.2">ğ‘§</ci><ci id="S1.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S1.E1.m1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S1.E1.m1.1.1.1.1.1.1.3.cmml" xref="S1.E1.m1.1.1.1.1.1.1.3">ğ‘‡</ci></apply></apply><apply id="S1.E1.m1.2.2.2.cmml" xref="S1.E1.m1.2.2.2"><apply id="S1.E1.m1.2.2.2.2.cmml" xref="S1.E1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S1.E1.m1.2.2.2.2.1.cmml" xref="S1.E1.m1.2.2.2.2">subscript</csymbol><sum id="S1.E1.m1.2.2.2.2.2.cmml" xref="S1.E1.m1.2.2.2.2.2"></sum><ci id="S1.E1.m1.2.2.2.2.3.cmml" xref="S1.E1.m1.2.2.2.2.3">ğ‘—</ci></apply><apply id="S1.E1.m1.2.2.2.1.cmml" xref="S1.E1.m1.2.2.2.1"><times id="S1.E1.m1.2.2.2.1.2.cmml" xref="S1.E1.m1.2.2.2.1.2"></times><ci id="S1.E1.m1.2.2.2.1.3.cmml" xref="S1.E1.m1.2.2.2.1.3">ğ‘’</ci><ci id="S1.E1.m1.2.2.2.1.4.cmml" xref="S1.E1.m1.2.2.2.1.4">ğ‘¥</ci><ci id="S1.E1.m1.2.2.2.1.5.cmml" xref="S1.E1.m1.2.2.2.1.5">ğ‘</ci><apply id="S1.E1.m1.2.2.2.1.1.1.1.cmml" xref="S1.E1.m1.2.2.2.1.1.1"><divide id="S1.E1.m1.2.2.2.1.1.1.1.1.cmml" xref="S1.E1.m1.2.2.2.1.1.1.1.1"></divide><apply id="S1.E1.m1.2.2.2.1.1.1.1.2.cmml" xref="S1.E1.m1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S1.E1.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S1.E1.m1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S1.E1.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S1.E1.m1.2.2.2.1.1.1.1.2.2">ğ‘§</ci><ci id="S1.E1.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S1.E1.m1.2.2.2.1.1.1.1.2.3">ğ‘—</ci></apply><ci id="S1.E1.m1.2.2.2.1.1.1.1.3.cmml" xref="S1.E1.m1.2.2.2.1.1.1.1.3">ğ‘‡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.E1.m1.5c">\xi(z,i,T)=q_{i}=\frac{exp(z_{i}/T)}{\sum_{j}exp(z_{j}/T)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.3" class="ltx_p">When employing a temperature <math id="S1.p6.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p6.1.m1.1a"><mi id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><ci id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">T</annotation></semantics></math> higher than 1, the probability distribution across classes naturally undergoes smoothing due to the narrowed interval between the logitsÂ <cite class="ltx_cite ltx_citemacro_cite">Guo <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite>, making such an approach suitable for applications such as knowledge distillation. Notably, despite altering the probabilities, the order of labelsâ€™ probability remains unaffected with respect to changes in <math id="S1.p6.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p6.2.m2.1a"><mi id="S1.p6.2.m2.1.1" xref="S1.p6.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p6.2.m2.1b"><ci id="S1.p6.2.m2.1.1.cmml" xref="S1.p6.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.2.m2.1c">T</annotation></semantics></math>. While these works successfully explore the impact of varying temperatures for neural network operations, they have mainly focused on applying high temperatures <span id="S1.p6.3.1" class="ltx_text ltx_font_italic">after</span> the model training process, mostly for the inference operations.
Raising <math id="S1.p6.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p6.3.m3.1a"><mi id="S1.p6.3.m3.1.1" xref="S1.p6.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p6.3.m3.1b"><ci id="S1.p6.3.m3.1.1.cmml" xref="S1.p6.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.3.m3.1c">T</annotation></semantics></math> to a higher value reduces the confidence of the training operations. This is especially useful to tame DNNs which are typically overconfident.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">On the other hand, in federated learning, where disparate training data is common, <span id="S1.p7.1.1" class="ltx_text ltx_font_italic">increasing the model confidence</span> of each individually trained client model (using a lower <math id="S1.p7.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p7.1.m1.1a"><mi id="S1.p7.1.m1.1.1" xref="S1.p7.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p7.1.m1.1b"><ci id="S1.p7.1.m1.1.1.cmml" xref="S1.p7.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.1.m1.1c">T</annotation></semantics></math>) prior to their parameter aggregation can be a more effective approach.
Our investigation involves measuring both the gradient flow and the data position shift within the representation space to provide guidelines in this unexplored territory.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.3" class="ltx_p">Specifically, this work targets to show that utilizing fractional temperature values (i.e., <math id="S1.p8.1.m1.2" class="ltx_Math" alttext="T\in(0,1)" display="inline"><semantics id="S1.p8.1.m1.2a"><mrow id="S1.p8.1.m1.2.3" xref="S1.p8.1.m1.2.3.cmml"><mi id="S1.p8.1.m1.2.3.2" xref="S1.p8.1.m1.2.3.2.cmml">T</mi><mo id="S1.p8.1.m1.2.3.1" xref="S1.p8.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S1.p8.1.m1.2.3.3.2" xref="S1.p8.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S1.p8.1.m1.2.3.3.2.1" xref="S1.p8.1.m1.2.3.3.1.cmml">(</mo><mn id="S1.p8.1.m1.1.1" xref="S1.p8.1.m1.1.1.cmml">0</mn><mo id="S1.p8.1.m1.2.3.3.2.2" xref="S1.p8.1.m1.2.3.3.1.cmml">,</mo><mn id="S1.p8.1.m1.2.2" xref="S1.p8.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S1.p8.1.m1.2.3.3.2.3" xref="S1.p8.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p8.1.m1.2b"><apply id="S1.p8.1.m1.2.3.cmml" xref="S1.p8.1.m1.2.3"><in id="S1.p8.1.m1.2.3.1.cmml" xref="S1.p8.1.m1.2.3.1"></in><ci id="S1.p8.1.m1.2.3.2.cmml" xref="S1.p8.1.m1.2.3.2">ğ‘‡</ci><interval closure="open" id="S1.p8.1.m1.2.3.3.1.cmml" xref="S1.p8.1.m1.2.3.3.2"><cn type="integer" id="S1.p8.1.m1.1.1.cmml" xref="S1.p8.1.m1.1.1">0</cn><cn type="integer" id="S1.p8.1.m1.2.2.cmml" xref="S1.p8.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.1.m1.2c">T\in(0,1)</annotation></semantics></math>) during the training process enables effective gradient propagation towards the input layer when applied to federated learning data distribution scenarios. Consequently, we observed that lower temperatures facilitate more efficient data updates within the representation space when dealing with non-iid datasets, a common characteristic of federated learning systems. From our evaluations with three datasets and three baseline federated learning models, we show that these effects accelerate the federated learning model convergence time by up to <math id="S1.p8.2.m2.1" class="ltx_math_unparsed" alttext="\mathbf{6.00\times}" display="inline"><semantics id="S1.p8.2.m2.1a"><mrow id="S1.p8.2.m2.1b"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S1.p8.2.m2.1.1">6.00</mn><mo lspace="0.222em" id="S1.p8.2.m2.1.2">Ã—</mo></mrow><annotation encoding="application/x-tex" id="S1.p8.2.m2.1c">\mathbf{6.00\times}</annotation></semantics></math> and improves the inference accuracy by up to <math id="S1.p8.3.m3.1" class="ltx_Math" alttext="\mathbf{3.37\%}" display="inline"><semantics id="S1.p8.3.m3.1a"><mrow id="S1.p8.3.m3.1.1" xref="S1.p8.3.m3.1.1.cmml"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S1.p8.3.m3.1.1.2" xref="S1.p8.3.m3.1.1.2.cmml">3.37</mn><mo id="S1.p8.3.m3.1.1.1" xref="S1.p8.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p8.3.m3.1b"><apply id="S1.p8.3.m3.1.1.cmml" xref="S1.p8.3.m3.1.1"><csymbol cd="latexml" id="S1.p8.3.m3.1.1.1.cmml" xref="S1.p8.3.m3.1.1.1">percent</csymbol><cn type="float" id="S1.p8.3.m3.1.1.2.cmml" xref="S1.p8.3.m3.1.1.2">3.37</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.3.m3.1c">\mathbf{3.37\%}</annotation></semantics></math>, despite potential concerns on model instability when training with with low temperatures. We summarize the contributions of this work in three-fold as the following:</p>
</div>
<div id="S1.p9" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">To the best of our knowledge, this is the first work that explores the impact of integrating temperature scaling during the training process in a federated learning scenario.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We offer empirical evidence that demonstrates the performance enhancements of exploiting <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">logit chilling</span> in federated learning scenarios, by examining the gradient flow and data position shifts within the representation space.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We introduce a novel federated learning model training approach, <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">FLex<math id="S1.I1.i3.p1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S1.I1.i3.p1.1.1.m1.1a"><mo id="S1.I1.i3.p1.1.1.m1.1.1" xref="S1.I1.i3.p1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i3.p1.1.1.m1.1b"><and id="S1.I1.i3.p1.1.1.m1.1.1.cmml" xref="S1.I1.i3.p1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.p1.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span>, showcasing the application of low temperature usage during the training process.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<section id="S2.SS0.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.1 </span>Temperature scaling</h4>

<div id="S2.SS0.SSS1.p1" class="ltx_para">
<p id="S2.SS0.SSS1.p1.1" class="ltx_p">In machine learning, the output probability distribution generated by a model serves diverse purposes. Primarily, classification models offer probabilities for each class, showcasing the modelâ€™s confidence in its predictions. This aids in assessing how certain the model is in its predictions (i.e., classification outputs) and allows consideration of the likelihood of each class prior to making a final classification decision. Moreover, this distribution offered by the model helps in understanding the uncertainty of a model on its decisionsÂ <cite class="ltx_cite ltx_citemacro_cite">Pearce <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>); Park <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2023b</a>)</cite>.</p>
</div>
<div id="S2.SS0.SSS1.p2" class="ltx_para">
<p id="S2.SS0.SSS1.p2.4" class="ltx_p">In neural networks, computing probabilities from logits often involves employing softmax operations, as shown in Eq.Â <a href="#S1.E1" title="In 1 Introduction â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Here, the temperature parameter (<math id="S2.SS0.SSS1.p2.1.m1.1" class="ltx_Math" alttext="T&gt;0" display="inline"><semantics id="S2.SS0.SSS1.p2.1.m1.1a"><mrow id="S2.SS0.SSS1.p2.1.m1.1.1" xref="S2.SS0.SSS1.p2.1.m1.1.1.cmml"><mi id="S2.SS0.SSS1.p2.1.m1.1.1.2" xref="S2.SS0.SSS1.p2.1.m1.1.1.2.cmml">T</mi><mo id="S2.SS0.SSS1.p2.1.m1.1.1.1" xref="S2.SS0.SSS1.p2.1.m1.1.1.1.cmml">&gt;</mo><mn id="S2.SS0.SSS1.p2.1.m1.1.1.3" xref="S2.SS0.SSS1.p2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS1.p2.1.m1.1b"><apply id="S2.SS0.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS0.SSS1.p2.1.m1.1.1"><gt id="S2.SS0.SSS1.p2.1.m1.1.1.1.cmml" xref="S2.SS0.SSS1.p2.1.m1.1.1.1"></gt><ci id="S2.SS0.SSS1.p2.1.m1.1.1.2.cmml" xref="S2.SS0.SSS1.p2.1.m1.1.1.2">ğ‘‡</ci><cn type="integer" id="S2.SS0.SSS1.p2.1.m1.1.1.3.cmml" xref="S2.SS0.SSS1.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS1.p2.1.m1.1c">T&gt;0</annotation></semantics></math>) controls the probability distributionâ€™s concentration towards one class, and is used to manage how the categorical probability is dispersed over the possible classesÂ <cite class="ltx_cite ltx_citemacro_cite">Jang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2016</a>)</cite>. Notably, this categorical probability aligns with the concept of entropy in information theory, offering a perspective where the temperature parameter governs the level of disorder or uncertainty within the distribution. Specifically, when <math id="S2.SS0.SSS1.p2.2.m2.2" class="ltx_Math" alttext="T\in(1,\infty)" display="inline"><semantics id="S2.SS0.SSS1.p2.2.m2.2a"><mrow id="S2.SS0.SSS1.p2.2.m2.2.3" xref="S2.SS0.SSS1.p2.2.m2.2.3.cmml"><mi id="S2.SS0.SSS1.p2.2.m2.2.3.2" xref="S2.SS0.SSS1.p2.2.m2.2.3.2.cmml">T</mi><mo id="S2.SS0.SSS1.p2.2.m2.2.3.1" xref="S2.SS0.SSS1.p2.2.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S2.SS0.SSS1.p2.2.m2.2.3.3.2" xref="S2.SS0.SSS1.p2.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS0.SSS1.p2.2.m2.2.3.3.2.1" xref="S2.SS0.SSS1.p2.2.m2.2.3.3.1.cmml">(</mo><mn id="S2.SS0.SSS1.p2.2.m2.1.1" xref="S2.SS0.SSS1.p2.2.m2.1.1.cmml">1</mn><mo id="S2.SS0.SSS1.p2.2.m2.2.3.3.2.2" xref="S2.SS0.SSS1.p2.2.m2.2.3.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS0.SSS1.p2.2.m2.2.2" xref="S2.SS0.SSS1.p2.2.m2.2.2.cmml">âˆ</mi><mo stretchy="false" id="S2.SS0.SSS1.p2.2.m2.2.3.3.2.3" xref="S2.SS0.SSS1.p2.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS1.p2.2.m2.2b"><apply id="S2.SS0.SSS1.p2.2.m2.2.3.cmml" xref="S2.SS0.SSS1.p2.2.m2.2.3"><in id="S2.SS0.SSS1.p2.2.m2.2.3.1.cmml" xref="S2.SS0.SSS1.p2.2.m2.2.3.1"></in><ci id="S2.SS0.SSS1.p2.2.m2.2.3.2.cmml" xref="S2.SS0.SSS1.p2.2.m2.2.3.2">ğ‘‡</ci><interval closure="open" id="S2.SS0.SSS1.p2.2.m2.2.3.3.1.cmml" xref="S2.SS0.SSS1.p2.2.m2.2.3.3.2"><cn type="integer" id="S2.SS0.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS0.SSS1.p2.2.m2.1.1">1</cn><infinity id="S2.SS0.SSS1.p2.2.m2.2.2.cmml" xref="S2.SS0.SSS1.p2.2.m2.2.2"></infinity></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS1.p2.2.m2.2c">T\in(1,\infty)</annotation></semantics></math> is applied, the probability distribution tends to be smoother due to increased <math id="S2.SS0.SSS1.p2.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS0.SSS1.p2.3.m3.1a"><mi id="S2.SS0.SSS1.p2.3.m3.1.1" xref="S2.SS0.SSS1.p2.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS1.p2.3.m3.1b"><ci id="S2.SS0.SSS1.p2.3.m3.1.1.cmml" xref="S2.SS0.SSS1.p2.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS1.p2.3.m3.1c">T</annotation></semantics></math>. This arises from the diminished differences between logit values, enhancing the distributionâ€™s entropy. In contrast, with <math id="S2.SS0.SSS1.p2.4.m4.2" class="ltx_Math" alttext="T\in(0,1)" display="inline"><semantics id="S2.SS0.SSS1.p2.4.m4.2a"><mrow id="S2.SS0.SSS1.p2.4.m4.2.3" xref="S2.SS0.SSS1.p2.4.m4.2.3.cmml"><mi id="S2.SS0.SSS1.p2.4.m4.2.3.2" xref="S2.SS0.SSS1.p2.4.m4.2.3.2.cmml">T</mi><mo id="S2.SS0.SSS1.p2.4.m4.2.3.1" xref="S2.SS0.SSS1.p2.4.m4.2.3.1.cmml">âˆˆ</mo><mrow id="S2.SS0.SSS1.p2.4.m4.2.3.3.2" xref="S2.SS0.SSS1.p2.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS0.SSS1.p2.4.m4.2.3.3.2.1" xref="S2.SS0.SSS1.p2.4.m4.2.3.3.1.cmml">(</mo><mn id="S2.SS0.SSS1.p2.4.m4.1.1" xref="S2.SS0.SSS1.p2.4.m4.1.1.cmml">0</mn><mo id="S2.SS0.SSS1.p2.4.m4.2.3.3.2.2" xref="S2.SS0.SSS1.p2.4.m4.2.3.3.1.cmml">,</mo><mn id="S2.SS0.SSS1.p2.4.m4.2.2" xref="S2.SS0.SSS1.p2.4.m4.2.2.cmml">1</mn><mo stretchy="false" id="S2.SS0.SSS1.p2.4.m4.2.3.3.2.3" xref="S2.SS0.SSS1.p2.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS1.p2.4.m4.2b"><apply id="S2.SS0.SSS1.p2.4.m4.2.3.cmml" xref="S2.SS0.SSS1.p2.4.m4.2.3"><in id="S2.SS0.SSS1.p2.4.m4.2.3.1.cmml" xref="S2.SS0.SSS1.p2.4.m4.2.3.1"></in><ci id="S2.SS0.SSS1.p2.4.m4.2.3.2.cmml" xref="S2.SS0.SSS1.p2.4.m4.2.3.2">ğ‘‡</ci><interval closure="open" id="S2.SS0.SSS1.p2.4.m4.2.3.3.1.cmml" xref="S2.SS0.SSS1.p2.4.m4.2.3.3.2"><cn type="integer" id="S2.SS0.SSS1.p2.4.m4.1.1.cmml" xref="S2.SS0.SSS1.p2.4.m4.1.1">0</cn><cn type="integer" id="S2.SS0.SSS1.p2.4.m4.2.2.cmml" xref="S2.SS0.SSS1.p2.4.m4.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS1.p2.4.m4.2c">T\in(0,1)</annotation></semantics></math> within the softmax function, the probability distribution becomes sharper, since lower temperatures amplify the differences between logits, effectively polarizing the distribution and concentrating probabilities closer to the maximum logit value. Consequently, the model becomes more confident in its predictions, as it allocates higher probabilities to fewer classes, thereby reducing uncertainty in the distribution.</p>
</div>
<div id="S2.SS0.SSS1.p3" class="ltx_para">
<p id="S2.SS0.SSS1.p3.2" class="ltx_p">Therefore, temperature scaling operates as a means to adjust the probability distribution within a neural network-based system. Previous work in Knowledge DistillationÂ <cite class="ltx_cite ltx_citemacro_cite">Hinton <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2015</a>); Touvron <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> exploit the temperature value by applying a high temperature <math id="S2.SS0.SSS1.p3.1.m1.2" class="ltx_Math" alttext="T\in(1,\infty)" display="inline"><semantics id="S2.SS0.SSS1.p3.1.m1.2a"><mrow id="S2.SS0.SSS1.p3.1.m1.2.3" xref="S2.SS0.SSS1.p3.1.m1.2.3.cmml"><mi id="S2.SS0.SSS1.p3.1.m1.2.3.2" xref="S2.SS0.SSS1.p3.1.m1.2.3.2.cmml">T</mi><mo id="S2.SS0.SSS1.p3.1.m1.2.3.1" xref="S2.SS0.SSS1.p3.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S2.SS0.SSS1.p3.1.m1.2.3.3.2" xref="S2.SS0.SSS1.p3.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS0.SSS1.p3.1.m1.2.3.3.2.1" xref="S2.SS0.SSS1.p3.1.m1.2.3.3.1.cmml">(</mo><mn id="S2.SS0.SSS1.p3.1.m1.1.1" xref="S2.SS0.SSS1.p3.1.m1.1.1.cmml">1</mn><mo id="S2.SS0.SSS1.p3.1.m1.2.3.3.2.2" xref="S2.SS0.SSS1.p3.1.m1.2.3.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS0.SSS1.p3.1.m1.2.2" xref="S2.SS0.SSS1.p3.1.m1.2.2.cmml">âˆ</mi><mo stretchy="false" id="S2.SS0.SSS1.p3.1.m1.2.3.3.2.3" xref="S2.SS0.SSS1.p3.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS1.p3.1.m1.2b"><apply id="S2.SS0.SSS1.p3.1.m1.2.3.cmml" xref="S2.SS0.SSS1.p3.1.m1.2.3"><in id="S2.SS0.SSS1.p3.1.m1.2.3.1.cmml" xref="S2.SS0.SSS1.p3.1.m1.2.3.1"></in><ci id="S2.SS0.SSS1.p3.1.m1.2.3.2.cmml" xref="S2.SS0.SSS1.p3.1.m1.2.3.2">ğ‘‡</ci><interval closure="open" id="S2.SS0.SSS1.p3.1.m1.2.3.3.1.cmml" xref="S2.SS0.SSS1.p3.1.m1.2.3.3.2"><cn type="integer" id="S2.SS0.SSS1.p3.1.m1.1.1.cmml" xref="S2.SS0.SSS1.p3.1.m1.1.1">1</cn><infinity id="S2.SS0.SSS1.p3.1.m1.2.2.cmml" xref="S2.SS0.SSS1.p3.1.m1.2.2"></infinity></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS1.p3.1.m1.2c">T\in(1,\infty)</annotation></semantics></math> to achieve a smoothed probability distribution. This manipulation aims to magnify small values within the distribution, often representing hidden information encapsulated within the model. Additionally, in generative modelsÂ <cite class="ltx_cite ltx_citemacro_cite">Shih <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2023</a>); Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>, temperature scaling regulates the randomness inherent in model outputs. This technique allows for the control of variability levels in generated samples, enabling adjustments to generated output diversity. Temperature scaling is also used in in model calibrationÂ <cite class="ltx_cite ltx_citemacro_cite">Guo <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite>. Applying temperature adjustments to the modelâ€™s output probabilities, typically through a scaling factor <math id="S2.SS0.SSS1.p3.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS0.SSS1.p3.2.m2.1a"><mi id="S2.SS0.SSS1.p3.2.m2.1.1" xref="S2.SS0.SSS1.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS1.p3.2.m2.1b"><ci id="S2.SS0.SSS1.p3.2.m2.1.1.cmml" xref="S2.SS0.SSS1.p3.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS1.p3.2.m2.1c">T</annotation></semantics></math>, aids in aligning these probabilities more accurately with the true likelihoods or uncertainties present in the data. Likewise, previous work have focused on applying high temperature values for various purposes, mostly for the purpose of conservatively better-understanding the full dataset without bias.</p>
</div>
</section>
<section id="S2.SS0.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.2 </span>Federated learning</h4>

<div id="S2.SS0.SSS2.p1" class="ltx_para">
<p id="S2.SS0.SSS2.p1.1" class="ltx_p">In recent years, federated learning has emerged as a promising paradigm in machine learning, particularly in scenarios where data privacy, security, and the decentralization of model training are core concerns. Unlike traditional centralized training approaches, federated learning enables model training across distributed devices or servers while keeping the data localized; thus, addressing privacy challenges associated with centralized data aggregation. This decentralized learning paradigm involves iterative model training where local updates occur on individual devices, and only aggregated model updates are shared with the central server.</p>
</div>
<div id="S2.SS0.SSS2.p2" class="ltx_para">
<p id="S2.SS0.SSS2.p2.1" class="ltx_p">Despite its benefits, federated learning poses several challenges. A body of work have tackled the issue of communication overhead stemming from the exchange of frequent model parameter updates. A number of previously proposed work have proposed schemes to effectively abstract the model parameters in various forms to relieve the communication and networking overheadÂ <cite class="ltx_cite ltx_citemacro_cite">Park <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2023a</a>)</cite>. Furthermore, federated learning systems are prone to facing issues rising from data heterogeneity caused from the diversity or differences in the characteristics, distributions, or formats of data across federated learning clients. Previous work have attempted to address this challenge by addressing relevant issues such as variations in feature/input variationsÂ <cite class="ltx_cite ltx_citemacro_cite">Yu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite> and spatio-temporal variationsÂ <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2401.09986/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Distribution of gradient norm observed at the input layer for correctly and incorrectly inferenced samples with varying temperature values. We observe noticeable improvements in gradient flow to the when training with lower temperatures.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Design of FLex&amp;Chill</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We initiate our discussions by exploring the impact of logit scaling, also known as temperature scaling, providing empirical evidence on the rationale behind our proposed system.
Furthermore, in this section, we introduce our system, referred to as <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">FLex<math id="S3.p1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.p1.1.1.m1.1a"><mo id="S3.p1.1.1.m1.1.1" xref="S3.p1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.p1.1.1.m1.1b"><and id="S3.p1.1.1.m1.1.1.cmml" xref="S3.p1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span>, a novel local training approach designed for efficiently training a federated learning framework.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Impact of Training with Lower Temperatures</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">As aforementioned, conventionally, temperature scaling has primarily been focused on calibrating the probability distribution of a modelâ€™s output <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">after</span> the model training phase, with limited exploration into its application <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">during</span> the training process itself. In this section, we present empirical results on three initial experiments specifically crafted to showcase the implications of employing temperature scaling throughout the training phase operations in different dimensions. Through these investigations, our aim is to establish a foundation for comprehending the potential implications and advantages associated with the utilization of temperature scaling techniques in neural network training. We conduct our experiments with the CIFAR10 datasetÂ <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2009</a>)</cite> and use a 2-layered CNN architectureÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2017</a>)</cite> as the baseline neural network architecture.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Gradient flow patterns</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Our first experiment focuses on assessing the norm of computed gradients within the input layer for various temperature values (<math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mi id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><ci id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">T</annotation></semantics></math>), and we present sample distribution plot of how the gradients flow for 50K training samples in FigureÂ <a href="#S2.F1" title="Figure 1 â€£ 2.0.2 Federated learning â€£ 2 Background and Related Work â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Note that here we separate the plots for the correctly inferenced samples (in the foward pass) and the incorrect ones to observe their differences. The propagation of gradients to the input layer serves as an indicative metric for the modelâ€™s learning efficacy. Successful gradient propagation to the input layer implies that the model effectively utilizes and comprehends information from diverse features within the input data during the training phaseÂ <cite class="ltx_cite ltx_citemacro_cite">Evci <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.3" class="ltx_p">As shown in FigureÂ <a href="#S2.F1" title="Figure 1 â€£ 2.0.2 Federated learning â€£ 2 Background and Related Work â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the mode of distribution shifts to larger values with decreasing temperatures for both correct and incorrect predictions. One reason behind this mode shift stems from the gradient function characteristics of softmax. Eq.Â <a href="#S3.E2" title="In 3.1.1 Gradient flow patterns â€£ 3.1 Impact of Training with Lower Temperatures â€£ 3 Design of FLex&amp;Chill â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the gradient of cross-entropy for the softmax activation with varying temperature <math id="S3.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><mi id="S3.SS1.SSS1.p2.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.m1.1b"><ci id="S3.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.m1.1c">T</annotation></semantics></math> and hard target, one-hot encoded labels. For brevity, we present the final derivation result and leave details in the Appendix. Since the gradient is multiplied by <math id="S3.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\frac{1}{T}&gt;1" display="inline"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><mrow id="S3.SS1.SSS1.p2.2.m2.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.cmml"><mfrac id="S3.SS1.SSS1.p2.2.m2.1.1.2" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml"><mn id="S3.SS1.SSS1.p2.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.2.cmml">1</mn><mi id="S3.SS1.SSS1.p2.2.m2.1.1.2.3" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.3.cmml">T</mi></mfrac><mo id="S3.SS1.SSS1.p2.2.m2.1.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.1.cmml">&gt;</mo><mn id="S3.SS1.SSS1.p2.2.m2.1.1.3" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.2.m2.1b"><apply id="S3.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1"><gt id="S3.SS1.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.1"></gt><apply id="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2"><divide id="S3.SS1.SSS1.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2"></divide><cn type="integer" id="S3.SS1.SSS1.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.2">1</cn><ci id="S3.SS1.SSS1.p2.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.3">ğ‘‡</ci></apply><cn type="integer" id="S3.SS1.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.2.m2.1c">\frac{1}{T}&gt;1</annotation></semantics></math>, for low temperatures <math id="S3.SS1.SSS1.p2.3.m3.1" class="ltx_Math" alttext="T&lt;1" display="inline"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><mrow id="S3.SS1.SSS1.p2.3.m3.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.SSS1.p2.3.m3.1.1.2" xref="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml">T</mi><mo id="S3.SS1.SSS1.p2.3.m3.1.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.1.cmml">&lt;</mo><mn id="S3.SS1.SSS1.p2.3.m3.1.1.3" xref="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.3.m3.1b"><apply id="S3.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1"><lt id="S3.SS1.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.1"></lt><ci id="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.2">ğ‘‡</ci><cn type="integer" id="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.3.m3.1c">T&lt;1</annotation></semantics></math>, we can expect a gradient boost.</p>
</div>
<div id="S3.SS1.SSS1.p3" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\frac{\partial\xi}{\partial{z_{i}}}=\frac{1}{T}(p_{i}-y_{i})=\frac{1}{T}(\frac{e^{z_{i}/T}}{\sum_{j}e^{z_{j}/T}}-y_{i})" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mfrac id="S3.E2.m1.2.2.4" xref="S3.E2.m1.2.2.4.cmml"><mrow id="S3.E2.m1.2.2.4.2" xref="S3.E2.m1.2.2.4.2.cmml"><mo rspace="0em" id="S3.E2.m1.2.2.4.2.1" xref="S3.E2.m1.2.2.4.2.1.cmml">âˆ‚</mo><mi id="S3.E2.m1.2.2.4.2.2" xref="S3.E2.m1.2.2.4.2.2.cmml">Î¾</mi></mrow><mrow id="S3.E2.m1.2.2.4.3" xref="S3.E2.m1.2.2.4.3.cmml"><mo rspace="0em" id="S3.E2.m1.2.2.4.3.1" xref="S3.E2.m1.2.2.4.3.1.cmml">âˆ‚</mo><msub id="S3.E2.m1.2.2.4.3.2" xref="S3.E2.m1.2.2.4.3.2.cmml"><mi id="S3.E2.m1.2.2.4.3.2.2" xref="S3.E2.m1.2.2.4.3.2.2.cmml">z</mi><mi id="S3.E2.m1.2.2.4.3.2.3" xref="S3.E2.m1.2.2.4.3.2.3.cmml">i</mi></msub></mrow></mfrac><mo id="S3.E2.m1.2.2.5" xref="S3.E2.m1.2.2.5.cmml">=</mo><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mfrac id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml"><mn id="S3.E2.m1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.3.2.cmml">1</mn><mi id="S3.E2.m1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.3.3.cmml">T</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.6" xref="S3.E2.m1.2.2.6.cmml">=</mo><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mfrac id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml"><mn id="S3.E2.m1.2.2.2.3.2" xref="S3.E2.m1.2.2.2.3.2.cmml">1</mn><mi id="S3.E2.m1.2.2.2.3.3" xref="S3.E2.m1.2.2.2.3.3.cmml">T</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.2.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><mfrac id="S3.E2.m1.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.2.cmml"><msup id="S3.E2.m1.2.2.2.1.1.1.2.2" xref="S3.E2.m1.2.2.2.1.1.1.2.2.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.2.2.2" xref="S3.E2.m1.2.2.2.1.1.1.2.2.2.cmml">e</mi><mrow id="S3.E2.m1.2.2.2.1.1.1.2.2.3" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.cmml"><msub id="S3.E2.m1.2.2.2.1.1.1.2.2.3.2" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.2" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.2.cmml">z</mi><mi id="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.3" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.2.1.1.1.2.2.3.1" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.1.cmml">/</mo><mi id="S3.E2.m1.2.2.2.1.1.1.2.2.3.3" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.3.cmml">T</mi></mrow></msup><mrow id="S3.E2.m1.2.2.2.1.1.1.2.3" xref="S3.E2.m1.2.2.2.1.1.1.2.3.cmml"><msub id="S3.E2.m1.2.2.2.1.1.1.2.3.1" xref="S3.E2.m1.2.2.2.1.1.1.2.3.1.cmml"><mo id="S3.E2.m1.2.2.2.1.1.1.2.3.1.2" xref="S3.E2.m1.2.2.2.1.1.1.2.3.1.2.cmml">âˆ‘</mo><mi id="S3.E2.m1.2.2.2.1.1.1.2.3.1.3" xref="S3.E2.m1.2.2.2.1.1.1.2.3.1.3.cmml">j</mi></msub><msup id="S3.E2.m1.2.2.2.1.1.1.2.3.2" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.2.3.2.2" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.2.cmml">e</mi><mrow id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.cmml"><msub id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.2" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.2.cmml">z</mi><mi id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.3" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.3.cmml">j</mi></msub><mo id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.1" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.1.cmml">/</mo><mi id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.3" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.3.cmml">T</mi></mrow></msup></mrow></mfrac><mo id="S3.E2.m1.2.2.2.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E2.m1.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.3.2" xref="S3.E2.m1.2.2.2.1.1.1.3.2.cmml">y</mi><mi id="S3.E2.m1.2.2.2.1.1.1.3.3" xref="S3.E2.m1.2.2.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><and id="S3.E2.m1.2.2a.cmml" xref="S3.E2.m1.2.2"></and><apply id="S3.E2.m1.2.2b.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.5.cmml" xref="S3.E2.m1.2.2.5"></eq><apply id="S3.E2.m1.2.2.4.cmml" xref="S3.E2.m1.2.2.4"><divide id="S3.E2.m1.2.2.4.1.cmml" xref="S3.E2.m1.2.2.4"></divide><apply id="S3.E2.m1.2.2.4.2.cmml" xref="S3.E2.m1.2.2.4.2"><partialdiff id="S3.E2.m1.2.2.4.2.1.cmml" xref="S3.E2.m1.2.2.4.2.1"></partialdiff><ci id="S3.E2.m1.2.2.4.2.2.cmml" xref="S3.E2.m1.2.2.4.2.2">ğœ‰</ci></apply><apply id="S3.E2.m1.2.2.4.3.cmml" xref="S3.E2.m1.2.2.4.3"><partialdiff id="S3.E2.m1.2.2.4.3.1.cmml" xref="S3.E2.m1.2.2.4.3.1"></partialdiff><apply id="S3.E2.m1.2.2.4.3.2.cmml" xref="S3.E2.m1.2.2.4.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.4.3.2.1.cmml" xref="S3.E2.m1.2.2.4.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.4.3.2.2.cmml" xref="S3.E2.m1.2.2.4.3.2.2">ğ‘§</ci><ci id="S3.E2.m1.2.2.4.3.2.3.cmml" xref="S3.E2.m1.2.2.4.3.2.3">ğ‘–</ci></apply></apply></apply><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3"><divide id="S3.E2.m1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.3"></divide><cn type="integer" id="S3.E2.m1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.3.2">1</cn><ci id="S3.E2.m1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.3.3">ğ‘‡</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><minus id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"></minus><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply><apply id="S3.E2.m1.2.2c.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.6.cmml" xref="S3.E2.m1.2.2.6"></eq><share href="#S3.E2.m1.1.1.1.cmml" id="S3.E2.m1.2.2d.cmml" xref="S3.E2.m1.2.2"></share><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><times id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"></times><apply id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"><divide id="S3.E2.m1.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.3"></divide><cn type="integer" id="S3.E2.m1.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.3.2">1</cn><ci id="S3.E2.m1.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.2.3.3">ğ‘‡</ci></apply><apply id="S3.E2.m1.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1"><minus id="S3.E2.m1.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1"></minus><apply id="S3.E2.m1.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2"><divide id="S3.E2.m1.2.2.2.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2"></divide><apply id="S3.E2.m1.2.2.2.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2">superscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.2">ğ‘’</ci><apply id="S3.E2.m1.2.2.2.1.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3"><divide id="S3.E2.m1.2.2.2.1.1.1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.1"></divide><apply id="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.2">ğ‘§</ci><ci id="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.2.3">ğ‘–</ci></apply><ci id="S3.E2.m1.2.2.2.1.1.1.2.2.3.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2.3.3">ğ‘‡</ci></apply></apply><apply id="S3.E2.m1.2.2.2.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3"><apply id="S3.E2.m1.2.2.2.1.1.1.2.3.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.2.3.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.1">subscript</csymbol><sum id="S3.E2.m1.2.2.2.1.1.1.2.3.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.1.2"></sum><ci id="S3.E2.m1.2.2.2.1.1.1.2.3.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.1.3">ğ‘—</ci></apply><apply id="S3.E2.m1.2.2.2.1.1.1.2.3.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.2.3.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2">superscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.2.3.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.2">ğ‘’</ci><apply id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3"><divide id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.1"></divide><apply id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.2">ğ‘§</ci><ci id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.2.3">ğ‘—</ci></apply><ci id="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3.2.3.3">ğ‘‡</ci></apply></apply></apply></apply><apply id="S3.E2.m1.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.2">ğ‘¦</ci><ci id="S3.E2.m1.2.2.2.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\frac{\partial\xi}{\partial{z_{i}}}=\frac{1}{T}(p_{i}-y_{i})=\frac{1}{T}(\frac{e^{z_{i}/T}}{\sum_{j}e^{z_{j}/T}}-y_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.SSS1.p4" class="ltx_para">
<p id="S3.SS1.SSS1.p4.2" class="ltx_p">Furthermore, from the perspective of the loss term <math id="S3.SS1.SSS1.p4.1.m1.1" class="ltx_Math" alttext="(p_{i}-y_{i})" display="inline"><semantics id="S3.SS1.SSS1.p4.1.m1.1a"><mrow id="S3.SS1.SSS1.p4.1.m1.1.1.1" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.SSS1.p4.1.m1.1.1.1.2" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS1.p4.1.m1.1.1.1.1" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.cmml"><msub id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.cmml"><mi id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.2" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.3" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.1" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.2" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.3" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.SS1.SSS1.p4.1.m1.1.1.1.3" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.1.m1.1b"><apply id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1"><minus id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.1"></minus><apply id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.1.m1.1c">(p_{i}-y_{i})</annotation></semantics></math>, when the model yields an incorrect decision for a given sample, the loss term significantly increases as <math id="S3.SS1.SSS1.p4.2.m2.1" class="ltx_Math" alttext="p_{i}\xrightarrow{}0" display="inline"><semantics id="S3.SS1.SSS1.p4.2.m2.1a"><mrow id="S3.SS1.SSS1.p4.2.m2.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.cmml"><msub id="S3.SS1.SSS1.p4.2.m2.1.1.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS1.p4.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.2.cmml">p</mi><mi id="S3.SS1.SSS1.p4.2.m2.1.1.2.3" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.3.cmml">i</mi></msub><mover accent="true" id="S3.SS1.SSS1.p4.2.m2.1.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.SSS1.p4.2.m2.1.1.1.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.2.cmml">â†’</mo><mi id="S3.SS1.SSS1.p4.2.m2.1.1.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1.cmml"></mi></mover><mn id="S3.SS1.SSS1.p4.2.m2.1.1.3" xref="S3.SS1.SSS1.p4.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.2.m2.1b"><apply id="S3.SS1.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1"><apply id="S3.SS1.SSS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1"><csymbol cd="latexml" id="S3.SS1.SSS1.p4.2.m2.1.1.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1">absent</csymbol><ci id="S3.SS1.SSS1.p4.2.m2.1.1.1.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.2">â†’</ci></apply><apply id="S3.SS1.SSS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p4.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.2">ğ‘</ci><ci id="S3.SS1.SSS1.p4.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S3.SS1.SSS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.2.m2.1c">p_{i}\xrightarrow{}0</annotation></semantics></math> (more details later in this section). The double-folded effect accounts for substantial mode shift with thick and long tails in the gradient distribution for lower training temperatures.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Data position shift in the representation space</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">To better understand the impact of temperature scaling on the training process, we conducted a study into the shift of a dataâ€™s position in the representation space (i.e., the distance to the decision boundary). Drawing inspiration from the concept of â€˜travel to decision boundaryâ€™ as proposed by Kim et al.Â <cite class="ltx_cite ltx_citemacro_cite">Kim <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>, we quantified the distance of a data pointâ€™s inference result to the decision boundary by determining the magnitude of epsilon (<math id="S3.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><mi id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><ci id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">\epsilon</annotation></semantics></math>) value multiplied by the adversarial perturbationÂ <cite class="ltx_cite ltx_citemacro_cite">Goodfellow <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2014</a>)</cite> needed to alter the modelâ€™s decision.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p">For this experiment, we configure an initial neural network and perform inference for 1,000 samples to identify the resultsâ€™ positions on the representation space. Among the 1,000, we select the ones that were misclassified, and recompute their positions after performing one training operation using that specific data point and compute the difference in positions on the representation space with respect to the decision boundary. By doing so, we can observe how drastically one training operation affects the next inference output with respect to different temperatures used in the training phase.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2401.09986/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="207" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distributions depicting differences between distances to the decision boundary before and after model updates for varying training temperatures. Notice that lower temperatures show noticeable shift in estimationsâ€™ positions on the representation space, suggesting their aggressiveness in modifying the model even with a small number of training samples.</figcaption>
</figure>
<div id="S3.SS1.SSS2.p3" class="ltx_para">
<p id="S3.SS1.SSS2.p3.3" class="ltx_p">FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.1.2 Data position shift in the representation space â€£ 3.1 Impact of Training with Lower Temperatures â€£ 3 Design of FLex&amp;Chill â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> plots our results in the form of distributions depicting differences between distances to the decision boundary before and after model updates. When higher temperatures (<math id="S3.SS1.SSS2.p3.1.m1.2" class="ltx_Math" alttext="T={2,4}" display="inline"><semantics id="S3.SS1.SSS2.p3.1.m1.2a"><mrow id="S3.SS1.SSS2.p3.1.m1.2.3" xref="S3.SS1.SSS2.p3.1.m1.2.3.cmml"><mi id="S3.SS1.SSS2.p3.1.m1.2.3.2" xref="S3.SS1.SSS2.p3.1.m1.2.3.2.cmml">T</mi><mo id="S3.SS1.SSS2.p3.1.m1.2.3.1" xref="S3.SS1.SSS2.p3.1.m1.2.3.1.cmml">=</mo><mrow id="S3.SS1.SSS2.p3.1.m1.2.3.3.2" xref="S3.SS1.SSS2.p3.1.m1.2.3.3.1.cmml"><mn id="S3.SS1.SSS2.p3.1.m1.1.1" xref="S3.SS1.SSS2.p3.1.m1.1.1.cmml">2</mn><mo id="S3.SS1.SSS2.p3.1.m1.2.3.3.2.1" xref="S3.SS1.SSS2.p3.1.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS1.SSS2.p3.1.m1.2.2" xref="S3.SS1.SSS2.p3.1.m1.2.2.cmml">4</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.1.m1.2b"><apply id="S3.SS1.SSS2.p3.1.m1.2.3.cmml" xref="S3.SS1.SSS2.p3.1.m1.2.3"><eq id="S3.SS1.SSS2.p3.1.m1.2.3.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.2.3.1"></eq><ci id="S3.SS1.SSS2.p3.1.m1.2.3.2.cmml" xref="S3.SS1.SSS2.p3.1.m1.2.3.2">ğ‘‡</ci><list id="S3.SS1.SSS2.p3.1.m1.2.3.3.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.2.3.3.2"><cn type="integer" id="S3.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1">2</cn><cn type="integer" id="S3.SS1.SSS2.p3.1.m1.2.2.cmml" xref="S3.SS1.SSS2.p3.1.m1.2.2">4</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.1.m1.2c">T={2,4}</annotation></semantics></math>) are applied, we can notice that the changes in inference resultsâ€™ positions are not significant (i.e., plots skewed towards 0). Whereas, with a small <math id="S3.SS1.SSS2.p3.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS2.p3.2.m2.1a"><mi id="S3.SS1.SSS2.p3.2.m2.1.1" xref="S3.SS1.SSS2.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.2.m2.1b"><ci id="S3.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.2.m2.1c">T</annotation></semantics></math>, we can notice more pronounced shifts in data positions within the representation space. This suggests that using a small <math id="S3.SS1.SSS2.p3.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS2.p3.3.m3.1a"><mi id="S3.SS1.SSS2.p3.3.m3.1.1" xref="S3.SS1.SSS2.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.3.m3.1b"><ci id="S3.SS1.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.3.m3.1c">T</annotation></semantics></math> at the softmax operations can actively steer the model towards (potentially) substantial optimization to better align with the training data.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Impact of temperature on individual samples</h4>

<figure id="S3.F3" class="ltx_figure"><img src="/html/2401.09986/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Probability distribution for single training sample (class index 4) with different training temperatures. A low <math id="S3.F3.2.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.F3.2.m1.1b"><mi id="S3.F3.2.m1.1.1" xref="S3.F3.2.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.F3.2.m1.1c"><ci id="S3.F3.2.m1.1.1.cmml" xref="S3.F3.2.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.2.m1.1d">T</annotation></semantics></math> hallucinates the modelâ€™s probability distribution, causing the neural network to be trained more aggressively even with a small number of samples.</figcaption>
</figure>
<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">We now examine the impact of different degrees of temperatures on a single sample prediction. Specifically, we take a look at the probability distribution of prediction for a single sample with varying temperature during training process. In FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.1.3 Impact of temperature on individual samples â€£ 3.1 Impact of Training with Lower Temperatures â€£ 3 Design of FLex&amp;Chill â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> we present the the resulting probability distribution for a single training sample (with ground truth index of 4). As the plots show, a higher temperature, <math id="S3.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><mi id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><ci id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">T</annotation></semantics></math>=4 in this case, leads to a widely spread probability distribution, and the neural network tends to less confident in prediction. On the other hand, with lower temperatures the information embedded in the data sample becomes more concentrated to the predicted label. If the prediction is incorrect, this increased prediction on the wrong label results in reduced probability on the correct label and increases the loss. This leads to more aggressive changes despite training from a single sample.</p>
</div>
<div id="S3.SS1.SSS3.p2" class="ltx_para">
<p id="S3.SS1.SSS3.p2.1" class="ltx_p">In federated learning, clients will train themselves with a small amount of local data (much smaller than typical centralized training). For the models trained at the clients to hold value at the server during the aggregation process, it is important that the local data characteristics are effectively embedded in its model parameters despite the small local dataset size. The aggressive behavior when applying low training temperatures that we see in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.1.3 Impact of temperature on individual samples â€£ 3.1 Impact of Training with Lower Temperatures â€£ 3 Design of FLex&amp;Chill â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and throughout our initial experimental results serve as evidence that the core information from each training element can be effectively extracted and learned at the neural network when low temperatures are applied in the federated learning training process.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_italic">FLex<math id="S3.SS2.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.SS2.1.1.m1.1b"><mo id="S3.SS2.1.1.m1.1.1" xref="S3.SS2.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.1.1.m1.1c"><and id="S3.SS2.1.1.m1.1.1.cmml" xref="S3.SS2.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.1.1.m1.1d">\&amp;</annotation></semantics></math>Chill</span> and Logit Chilling</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">Based on such empirical observations, we hypothesise that training neural networks with lower temperatures can benefit the model convergence and performance for systems exploiting with non-iid data, which is common for federated learning scenarios. In <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">FLex<math id="S3.SS2.p1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.SS2.p1.1.1.m1.1a"><mo id="S3.SS2.p1.1.1.m1.1.1" xref="S3.SS2.p1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.1.m1.1b"><and id="S3.SS2.p1.1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span> we term this as <span id="S3.SS2.p1.2.3" class="ltx_text ltx_font_italic">logit chilling</span>, as a we â€˜chill downâ€™ the temperature at the softmax operations, thereby altering the logit computation derived from the neural network during the training process. The focus of a <span id="S3.SS2.p1.2.2" class="ltx_text ltx_font_italic">FLex<math id="S3.SS2.p1.2.2.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.SS2.p1.2.2.m1.1a"><mo id="S3.SS2.p1.2.2.m1.1.1" xref="S3.SS2.p1.2.2.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.2.m1.1b"><and id="S3.SS2.p1.2.2.m1.1.1.cmml" xref="S3.SS2.p1.2.2.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.2.m1.1c">\&amp;</annotation></semantics></math>Chill</span>-based federated learning system is to exploit logit chilling to train a client-side model with low temperature values. As we observed through the studies above and as our evaluations will show, this has an effect of effectively exploiting crucial information from the training samples to actively alter the model towards the new knowledge.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.2" class="ltx_p">The lower temperatures used by Logit Chilling directly influences the local training process on each federated learning client. Notably, the seamless integration of Logit Chilling and <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_italic">FLex<math id="S3.SS2.p2.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.SS2.p2.1.1.m1.1a"><mo id="S3.SS2.p2.1.1.m1.1.1" xref="S3.SS2.p2.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.1.m1.1b"><and id="S3.SS2.p2.1.1.m1.1.1.cmml" xref="S3.SS2.p2.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span> with existing federated learning frameworks is a distinct advantage, allowing for a straightforward implementation within already deployed frameworks. Furthermore, we note that <span id="S3.SS2.p2.2.2" class="ltx_text ltx_font_italic">FLex<math id="S3.SS2.p2.2.2.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.SS2.p2.2.2.m1.1a"><mo id="S3.SS2.p2.2.2.m1.1.1" xref="S3.SS2.p2.2.2.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.2.m1.1b"><and id="S3.SS2.p2.2.2.m1.1.1.cmml" xref="S3.SS2.p2.2.2.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.2.m1.1c">\&amp;</annotation></semantics></math>Chill</span> can be used orthogonality with other efforts that accelerate federated learning training operations such as FedProx and SCAFFOLD.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.3" class="ltx_p">We formulate the operations of <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_italic">FLex<math id="S3.SS2.p3.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.SS2.p3.1.1.m1.1a"><mo id="S3.SS2.p3.1.1.m1.1.1" xref="S3.SS2.p3.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.1.m1.1b"><and id="S3.SS2.p3.1.1.m1.1.1.cmml" xref="S3.SS2.p3.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span> using AlgorithmÂ <a href="#alg1" title="Algorithm 1 â€£ 3.2 FLex&amp;Chill and Logit Chilling â€£ 3 Design of FLex&amp;Chill â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Here, typical federated learning operations take place at both the server and clients except for the fact that the server determines a target <math id="S3.SS2.p3.2.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p3.2.m1.1a"><mi id="S3.SS2.p3.2.m1.1.1" xref="S3.SS2.p3.2.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m1.1b"><ci id="S3.SS2.p3.2.m1.1.1.cmml" xref="S3.SS2.p3.2.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m1.1c">T</annotation></semantics></math> at each round and local model training operations are performed with <math id="S3.SS2.p3.3.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p3.3.m2.1a"><mi id="S3.SS2.p3.3.m2.1.1" xref="S3.SS2.p3.3.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m2.1b"><ci id="S3.SS2.p3.3.m2.1.1.cmml" xref="S3.SS2.p3.3.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m2.1c">T</annotation></semantics></math>.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">

<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span id="alg1.13.2.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> <span id="alg1.2.1" class="ltx_text ltx_font_italic">FLex<math id="alg1.2.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="alg1.2.1.m1.1b"><mo id="alg1.2.1.m1.1.1" xref="alg1.2.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="alg1.2.1.m1.1c"><and id="alg1.2.1.m1.1.1.cmml" xref="alg1.2.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.1.m1.1d">\&amp;</annotation></semantics></math>Chill</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.10" class="ltx_p ltx_figure_panel"><span id="alg1.10.8" class="ltx_text ltx_font_bold" style="font-size:90%;">Data<span id="alg1.5.3.3" class="ltx_text ltx_font_medium"> (<math id="alg1.3.1.1.m1.4" class="ltx_Math" alttext="D_{1},D_{2},...,D_{N}" display="inline"><semantics id="alg1.3.1.1.m1.4a"><mrow id="alg1.3.1.1.m1.4.4.3" xref="alg1.3.1.1.m1.4.4.4.cmml"><msub id="alg1.3.1.1.m1.2.2.1.1" xref="alg1.3.1.1.m1.2.2.1.1.cmml"><mi id="alg1.3.1.1.m1.2.2.1.1.2" xref="alg1.3.1.1.m1.2.2.1.1.2.cmml">D</mi><mn id="alg1.3.1.1.m1.2.2.1.1.3" xref="alg1.3.1.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="alg1.3.1.1.m1.4.4.3.4" xref="alg1.3.1.1.m1.4.4.4.cmml">,</mo><msub id="alg1.3.1.1.m1.3.3.2.2" xref="alg1.3.1.1.m1.3.3.2.2.cmml"><mi id="alg1.3.1.1.m1.3.3.2.2.2" xref="alg1.3.1.1.m1.3.3.2.2.2.cmml">D</mi><mn id="alg1.3.1.1.m1.3.3.2.2.3" xref="alg1.3.1.1.m1.3.3.2.2.3.cmml">2</mn></msub><mo id="alg1.3.1.1.m1.4.4.3.5" xref="alg1.3.1.1.m1.4.4.4.cmml">,</mo><mi mathvariant="normal" id="alg1.3.1.1.m1.1.1" xref="alg1.3.1.1.m1.1.1.cmml">â€¦</mi><mo id="alg1.3.1.1.m1.4.4.3.6" xref="alg1.3.1.1.m1.4.4.4.cmml">,</mo><msub id="alg1.3.1.1.m1.4.4.3.3" xref="alg1.3.1.1.m1.4.4.3.3.cmml"><mi id="alg1.3.1.1.m1.4.4.3.3.2" xref="alg1.3.1.1.m1.4.4.3.3.2.cmml">D</mi><mi id="alg1.3.1.1.m1.4.4.3.3.3" xref="alg1.3.1.1.m1.4.4.3.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.3.1.1.m1.4b"><list id="alg1.3.1.1.m1.4.4.4.cmml" xref="alg1.3.1.1.m1.4.4.3"><apply id="alg1.3.1.1.m1.2.2.1.1.cmml" xref="alg1.3.1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="alg1.3.1.1.m1.2.2.1.1.1.cmml" xref="alg1.3.1.1.m1.2.2.1.1">subscript</csymbol><ci id="alg1.3.1.1.m1.2.2.1.1.2.cmml" xref="alg1.3.1.1.m1.2.2.1.1.2">ğ·</ci><cn type="integer" id="alg1.3.1.1.m1.2.2.1.1.3.cmml" xref="alg1.3.1.1.m1.2.2.1.1.3">1</cn></apply><apply id="alg1.3.1.1.m1.3.3.2.2.cmml" xref="alg1.3.1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="alg1.3.1.1.m1.3.3.2.2.1.cmml" xref="alg1.3.1.1.m1.3.3.2.2">subscript</csymbol><ci id="alg1.3.1.1.m1.3.3.2.2.2.cmml" xref="alg1.3.1.1.m1.3.3.2.2.2">ğ·</ci><cn type="integer" id="alg1.3.1.1.m1.3.3.2.2.3.cmml" xref="alg1.3.1.1.m1.3.3.2.2.3">2</cn></apply><ci id="alg1.3.1.1.m1.1.1.cmml" xref="alg1.3.1.1.m1.1.1">â€¦</ci><apply id="alg1.3.1.1.m1.4.4.3.3.cmml" xref="alg1.3.1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="alg1.3.1.1.m1.4.4.3.3.1.cmml" xref="alg1.3.1.1.m1.4.4.3.3">subscript</csymbol><ci id="alg1.3.1.1.m1.4.4.3.3.2.cmml" xref="alg1.3.1.1.m1.4.4.3.3.2">ğ·</ci><ci id="alg1.3.1.1.m1.4.4.3.3.3.cmml" xref="alg1.3.1.1.m1.4.4.3.3.3">ğ‘</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.1.1.m1.4c">D_{1},D_{2},...,D_{N}</annotation></semantics></math>) where <math id="alg1.4.2.2.m2.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="alg1.4.2.2.m2.1a"><msub id="alg1.4.2.2.m2.1.1" xref="alg1.4.2.2.m2.1.1.cmml"><mi id="alg1.4.2.2.m2.1.1.2" xref="alg1.4.2.2.m2.1.1.2.cmml">D</mi><mi id="alg1.4.2.2.m2.1.1.3" xref="alg1.4.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.4.2.2.m2.1b"><apply id="alg1.4.2.2.m2.1.1.cmml" xref="alg1.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="alg1.4.2.2.m2.1.1.1.cmml" xref="alg1.4.2.2.m2.1.1">subscript</csymbol><ci id="alg1.4.2.2.m2.1.1.2.cmml" xref="alg1.4.2.2.m2.1.1.2">ğ·</ci><ci id="alg1.4.2.2.m2.1.1.3.cmml" xref="alg1.4.2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.2.2.m2.1c">D_{i}</annotation></semantics></math> is the user <math id="alg1.5.3.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="alg1.5.3.3.m3.1a"><mi id="alg1.5.3.3.m3.1.1" xref="alg1.5.3.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.5.3.3.m3.1b"><ci id="alg1.5.3.3.m3.1.1.cmml" xref="alg1.5.3.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.3.3.m3.1c">i</annotation></semantics></math>â€™s local data.
<br class="ltx_break"></span>Model<span id="alg1.9.7.7" class="ltx_text ltx_font_medium"> (<math id="alg1.6.4.4.m1.4" class="ltx_Math" alttext="w^{1}_{t},w^{2}_{t},...,w^{N}_{t}" display="inline"><semantics id="alg1.6.4.4.m1.4a"><mrow id="alg1.6.4.4.m1.4.4.3" xref="alg1.6.4.4.m1.4.4.4.cmml"><msubsup id="alg1.6.4.4.m1.2.2.1.1" xref="alg1.6.4.4.m1.2.2.1.1.cmml"><mi id="alg1.6.4.4.m1.2.2.1.1.2.2" xref="alg1.6.4.4.m1.2.2.1.1.2.2.cmml">w</mi><mi id="alg1.6.4.4.m1.2.2.1.1.3" xref="alg1.6.4.4.m1.2.2.1.1.3.cmml">t</mi><mn id="alg1.6.4.4.m1.2.2.1.1.2.3" xref="alg1.6.4.4.m1.2.2.1.1.2.3.cmml">1</mn></msubsup><mo id="alg1.6.4.4.m1.4.4.3.4" xref="alg1.6.4.4.m1.4.4.4.cmml">,</mo><msubsup id="alg1.6.4.4.m1.3.3.2.2" xref="alg1.6.4.4.m1.3.3.2.2.cmml"><mi id="alg1.6.4.4.m1.3.3.2.2.2.2" xref="alg1.6.4.4.m1.3.3.2.2.2.2.cmml">w</mi><mi id="alg1.6.4.4.m1.3.3.2.2.3" xref="alg1.6.4.4.m1.3.3.2.2.3.cmml">t</mi><mn id="alg1.6.4.4.m1.3.3.2.2.2.3" xref="alg1.6.4.4.m1.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="alg1.6.4.4.m1.4.4.3.5" xref="alg1.6.4.4.m1.4.4.4.cmml">,</mo><mi mathvariant="normal" id="alg1.6.4.4.m1.1.1" xref="alg1.6.4.4.m1.1.1.cmml">â€¦</mi><mo id="alg1.6.4.4.m1.4.4.3.6" xref="alg1.6.4.4.m1.4.4.4.cmml">,</mo><msubsup id="alg1.6.4.4.m1.4.4.3.3" xref="alg1.6.4.4.m1.4.4.3.3.cmml"><mi id="alg1.6.4.4.m1.4.4.3.3.2.2" xref="alg1.6.4.4.m1.4.4.3.3.2.2.cmml">w</mi><mi id="alg1.6.4.4.m1.4.4.3.3.3" xref="alg1.6.4.4.m1.4.4.3.3.3.cmml">t</mi><mi id="alg1.6.4.4.m1.4.4.3.3.2.3" xref="alg1.6.4.4.m1.4.4.3.3.2.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.6.4.4.m1.4b"><list id="alg1.6.4.4.m1.4.4.4.cmml" xref="alg1.6.4.4.m1.4.4.3"><apply id="alg1.6.4.4.m1.2.2.1.1.cmml" xref="alg1.6.4.4.m1.2.2.1.1"><csymbol cd="ambiguous" id="alg1.6.4.4.m1.2.2.1.1.1.cmml" xref="alg1.6.4.4.m1.2.2.1.1">subscript</csymbol><apply id="alg1.6.4.4.m1.2.2.1.1.2.cmml" xref="alg1.6.4.4.m1.2.2.1.1"><csymbol cd="ambiguous" id="alg1.6.4.4.m1.2.2.1.1.2.1.cmml" xref="alg1.6.4.4.m1.2.2.1.1">superscript</csymbol><ci id="alg1.6.4.4.m1.2.2.1.1.2.2.cmml" xref="alg1.6.4.4.m1.2.2.1.1.2.2">ğ‘¤</ci><cn type="integer" id="alg1.6.4.4.m1.2.2.1.1.2.3.cmml" xref="alg1.6.4.4.m1.2.2.1.1.2.3">1</cn></apply><ci id="alg1.6.4.4.m1.2.2.1.1.3.cmml" xref="alg1.6.4.4.m1.2.2.1.1.3">ğ‘¡</ci></apply><apply id="alg1.6.4.4.m1.3.3.2.2.cmml" xref="alg1.6.4.4.m1.3.3.2.2"><csymbol cd="ambiguous" id="alg1.6.4.4.m1.3.3.2.2.1.cmml" xref="alg1.6.4.4.m1.3.3.2.2">subscript</csymbol><apply id="alg1.6.4.4.m1.3.3.2.2.2.cmml" xref="alg1.6.4.4.m1.3.3.2.2"><csymbol cd="ambiguous" id="alg1.6.4.4.m1.3.3.2.2.2.1.cmml" xref="alg1.6.4.4.m1.3.3.2.2">superscript</csymbol><ci id="alg1.6.4.4.m1.3.3.2.2.2.2.cmml" xref="alg1.6.4.4.m1.3.3.2.2.2.2">ğ‘¤</ci><cn type="integer" id="alg1.6.4.4.m1.3.3.2.2.2.3.cmml" xref="alg1.6.4.4.m1.3.3.2.2.2.3">2</cn></apply><ci id="alg1.6.4.4.m1.3.3.2.2.3.cmml" xref="alg1.6.4.4.m1.3.3.2.2.3">ğ‘¡</ci></apply><ci id="alg1.6.4.4.m1.1.1.cmml" xref="alg1.6.4.4.m1.1.1">â€¦</ci><apply id="alg1.6.4.4.m1.4.4.3.3.cmml" xref="alg1.6.4.4.m1.4.4.3.3"><csymbol cd="ambiguous" id="alg1.6.4.4.m1.4.4.3.3.1.cmml" xref="alg1.6.4.4.m1.4.4.3.3">subscript</csymbol><apply id="alg1.6.4.4.m1.4.4.3.3.2.cmml" xref="alg1.6.4.4.m1.4.4.3.3"><csymbol cd="ambiguous" id="alg1.6.4.4.m1.4.4.3.3.2.1.cmml" xref="alg1.6.4.4.m1.4.4.3.3">superscript</csymbol><ci id="alg1.6.4.4.m1.4.4.3.3.2.2.cmml" xref="alg1.6.4.4.m1.4.4.3.3.2.2">ğ‘¤</ci><ci id="alg1.6.4.4.m1.4.4.3.3.2.3.cmml" xref="alg1.6.4.4.m1.4.4.3.3.2.3">ğ‘</ci></apply><ci id="alg1.6.4.4.m1.4.4.3.3.3.cmml" xref="alg1.6.4.4.m1.4.4.3.3.3">ğ‘¡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.4.4.m1.4c">w^{1}_{t},w^{2}_{t},...,w^{N}_{t}</annotation></semantics></math>) where <math id="alg1.7.5.5.m2.1" class="ltx_Math" alttext="w_{t}^{i}" display="inline"><semantics id="alg1.7.5.5.m2.1a"><msubsup id="alg1.7.5.5.m2.1.1" xref="alg1.7.5.5.m2.1.1.cmml"><mi id="alg1.7.5.5.m2.1.1.2.2" xref="alg1.7.5.5.m2.1.1.2.2.cmml">w</mi><mi id="alg1.7.5.5.m2.1.1.2.3" xref="alg1.7.5.5.m2.1.1.2.3.cmml">t</mi><mi id="alg1.7.5.5.m2.1.1.3" xref="alg1.7.5.5.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.7.5.5.m2.1b"><apply id="alg1.7.5.5.m2.1.1.cmml" xref="alg1.7.5.5.m2.1.1"><csymbol cd="ambiguous" id="alg1.7.5.5.m2.1.1.1.cmml" xref="alg1.7.5.5.m2.1.1">superscript</csymbol><apply id="alg1.7.5.5.m2.1.1.2.cmml" xref="alg1.7.5.5.m2.1.1"><csymbol cd="ambiguous" id="alg1.7.5.5.m2.1.1.2.1.cmml" xref="alg1.7.5.5.m2.1.1">subscript</csymbol><ci id="alg1.7.5.5.m2.1.1.2.2.cmml" xref="alg1.7.5.5.m2.1.1.2.2">ğ‘¤</ci><ci id="alg1.7.5.5.m2.1.1.2.3.cmml" xref="alg1.7.5.5.m2.1.1.2.3">ğ‘¡</ci></apply><ci id="alg1.7.5.5.m2.1.1.3.cmml" xref="alg1.7.5.5.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.5.5.m2.1c">w_{t}^{i}</annotation></semantics></math> is the user <math id="alg1.8.6.6.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="alg1.8.6.6.m3.1a"><mi id="alg1.8.6.6.m3.1.1" xref="alg1.8.6.6.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.8.6.6.m3.1b"><ci id="alg1.8.6.6.m3.1.1.cmml" xref="alg1.8.6.6.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.6.6.m3.1c">i</annotation></semantics></math>â€™s model in <math id="alg1.9.7.7.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="alg1.9.7.7.m4.1a"><mi id="alg1.9.7.7.m4.1.1" xref="alg1.9.7.7.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="alg1.9.7.7.m4.1b"><ci id="alg1.9.7.7.m4.1.1.cmml" xref="alg1.9.7.7.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.7.7.m4.1c">t</annotation></semantics></math>-th federated round.
<br class="ltx_break"></span>Parameter<span id="alg1.10.8.8" class="ltx_text ltx_font_medium">: Temperature <math id="alg1.10.8.8.m1.2" class="ltx_Math" alttext="T\in(0,1)" display="inline"><semantics id="alg1.10.8.8.m1.2a"><mrow id="alg1.10.8.8.m1.2.3" xref="alg1.10.8.8.m1.2.3.cmml"><mi id="alg1.10.8.8.m1.2.3.2" xref="alg1.10.8.8.m1.2.3.2.cmml">T</mi><mo id="alg1.10.8.8.m1.2.3.1" xref="alg1.10.8.8.m1.2.3.1.cmml">âˆˆ</mo><mrow id="alg1.10.8.8.m1.2.3.3.2" xref="alg1.10.8.8.m1.2.3.3.1.cmml"><mo stretchy="false" id="alg1.10.8.8.m1.2.3.3.2.1" xref="alg1.10.8.8.m1.2.3.3.1.cmml">(</mo><mn id="alg1.10.8.8.m1.1.1" xref="alg1.10.8.8.m1.1.1.cmml">0</mn><mo id="alg1.10.8.8.m1.2.3.3.2.2" xref="alg1.10.8.8.m1.2.3.3.1.cmml">,</mo><mn id="alg1.10.8.8.m1.2.2" xref="alg1.10.8.8.m1.2.2.cmml">1</mn><mo stretchy="false" id="alg1.10.8.8.m1.2.3.3.2.3" xref="alg1.10.8.8.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.10.8.8.m1.2b"><apply id="alg1.10.8.8.m1.2.3.cmml" xref="alg1.10.8.8.m1.2.3"><in id="alg1.10.8.8.m1.2.3.1.cmml" xref="alg1.10.8.8.m1.2.3.1"></in><ci id="alg1.10.8.8.m1.2.3.2.cmml" xref="alg1.10.8.8.m1.2.3.2">ğ‘‡</ci><interval closure="open" id="alg1.10.8.8.m1.2.3.3.1.cmml" xref="alg1.10.8.8.m1.2.3.3.2"><cn type="integer" id="alg1.10.8.8.m1.1.1.cmml" xref="alg1.10.8.8.m1.1.1">0</cn><cn type="integer" id="alg1.10.8.8.m1.2.2.cmml" xref="alg1.10.8.8.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.8.8.m1.2c">T\in(0,1)</annotation></semantics></math></span></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.14" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span><span id="alg1.l1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Server executes</span><span id="alg1.l1.3" class="ltx_text" style="font-size:90%;">:
</span>
</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span><span id="alg1.l2.2" class="ltx_text" style="font-size:90%;">Initialize </span><math id="alg1.l2.m1.1" class="ltx_Math" alttext="w_{0}" display="inline"><semantics id="alg1.l2.m1.1a"><msub id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">w</mi><mn mathsize="90%" id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">ğ‘¤</ci><cn type="integer" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">w_{0}</annotation></semantics></math><span id="alg1.l2.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span><span id="alg1.l3.2" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="alg1.l3.3" class="ltx_text" style="font-size:90%;">Â each round </span><math id="alg1.l3.m1.4" class="ltx_Math" alttext="t=1,2,...,R" display="inline"><semantics id="alg1.l3.m1.4a"><mrow id="alg1.l3.m1.4.5" xref="alg1.l3.m1.4.5.cmml"><mi mathsize="90%" id="alg1.l3.m1.4.5.2" xref="alg1.l3.m1.4.5.2.cmml">t</mi><mo mathsize="90%" id="alg1.l3.m1.4.5.1" xref="alg1.l3.m1.4.5.1.cmml">=</mo><mrow id="alg1.l3.m1.4.5.3.2" xref="alg1.l3.m1.4.5.3.1.cmml"><mn mathsize="90%" id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">1</mn><mo mathsize="90%" id="alg1.l3.m1.4.5.3.2.1" xref="alg1.l3.m1.4.5.3.1.cmml">,</mo><mn mathsize="90%" id="alg1.l3.m1.2.2" xref="alg1.l3.m1.2.2.cmml">2</mn><mo mathsize="90%" id="alg1.l3.m1.4.5.3.2.2" xref="alg1.l3.m1.4.5.3.1.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="alg1.l3.m1.3.3" xref="alg1.l3.m1.3.3.cmml">â€¦</mi><mo mathsize="90%" id="alg1.l3.m1.4.5.3.2.3" xref="alg1.l3.m1.4.5.3.1.cmml">,</mo><mi mathsize="90%" id="alg1.l3.m1.4.4" xref="alg1.l3.m1.4.4.cmml">R</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.4b"><apply id="alg1.l3.m1.4.5.cmml" xref="alg1.l3.m1.4.5"><eq id="alg1.l3.m1.4.5.1.cmml" xref="alg1.l3.m1.4.5.1"></eq><ci id="alg1.l3.m1.4.5.2.cmml" xref="alg1.l3.m1.4.5.2">ğ‘¡</ci><list id="alg1.l3.m1.4.5.3.1.cmml" xref="alg1.l3.m1.4.5.3.2"><cn type="integer" id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">1</cn><cn type="integer" id="alg1.l3.m1.2.2.cmml" xref="alg1.l3.m1.2.2">2</cn><ci id="alg1.l3.m1.3.3.cmml" xref="alg1.l3.m1.3.3">â€¦</ci><ci id="alg1.l3.m1.4.4.cmml" xref="alg1.l3.m1.4.4">ğ‘…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.4c">t=1,2,...,R</annotation></semantics></math><span id="alg1.l3.4" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l3.5" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l3.6" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span><span id="alg1.l4.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l4.m1.1" class="ltx_Math" alttext="S_{t}\xleftarrow{}" display="inline"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><msub id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml"><mi mathsize="90%" id="alg1.l4.m1.1.1.2.2" xref="alg1.l4.m1.1.1.2.2.cmml">S</mi><mi mathsize="90%" id="alg1.l4.m1.1.1.2.3" xref="alg1.l4.m1.1.1.2.3.cmml">t</mi></msub><mover accent="true" id="alg1.l4.m1.1.1.1" xref="alg1.l4.m1.1.1.1.cmml"><mo mathsize="90%" stretchy="false" id="alg1.l4.m1.1.1.1.2" xref="alg1.l4.m1.1.1.1.2.cmml">â†</mo><mi id="alg1.l4.m1.1.1.1.1" xref="alg1.l4.m1.1.1.1.1.cmml"></mi></mover><mi id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><apply id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1"><csymbol cd="latexml" id="alg1.l4.m1.1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1.1">absent</csymbol><ci id="alg1.l4.m1.1.1.1.2.cmml" xref="alg1.l4.m1.1.1.1.2">â†</ci></apply><apply id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.2.1.cmml" xref="alg1.l4.m1.1.1.2">subscript</csymbol><ci id="alg1.l4.m1.1.1.2.2.cmml" xref="alg1.l4.m1.1.1.2.2">ğ‘†</ci><ci id="alg1.l4.m1.1.1.2.3.cmml" xref="alg1.l4.m1.1.1.2.3">ğ‘¡</ci></apply><csymbol cd="latexml" id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">S_{t}\xleftarrow{}</annotation></semantics></math><span id="alg1.l4.3" class="ltx_text" style="font-size:90%;"> (random set of </span><math id="alg1.l4.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="alg1.l4.m2.1a"><mi mathsize="90%" id="alg1.l4.m2.1.1" xref="alg1.l4.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b"><ci id="alg1.l4.m2.1.1.cmml" xref="alg1.l4.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m2.1c">m</annotation></semantics></math><span id="alg1.l4.4" class="ltx_text" style="font-size:90%;"> clients)
</span>
</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span><span id="alg1.l5.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><span id="alg1.l5.3" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="alg1.l5.4" class="ltx_text" style="font-size:90%;">Â </span><math id="alg1.l5.m1.1" class="ltx_Math" alttext="k\in S_{t}" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml">k</mi><mo mathsize="90%" id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml">âˆˆ</mo><msub id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l5.m1.1.1.3.2" xref="alg1.l5.m1.1.1.3.2.cmml">S</mi><mi mathsize="90%" id="alg1.l5.m1.1.1.3.3" xref="alg1.l5.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><in id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"></in><ci id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2">ğ‘˜</ci><apply id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.3.1.cmml" xref="alg1.l5.m1.1.1.3">subscript</csymbol><ci id="alg1.l5.m1.1.1.3.2.cmml" xref="alg1.l5.m1.1.1.3.2">ğ‘†</ci><ci id="alg1.l5.m1.1.1.3.3.cmml" xref="alg1.l5.m1.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">k\in S_{t}</annotation></semantics></math><span id="alg1.l5.5" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l5.6" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l5.7" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span><span id="alg1.l6.2" class="ltx_text" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><math id="alg1.l6.m1.1" class="ltx_Math" alttext="w_{t}^{k}\xleftarrow{}" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><msubsup id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mi mathsize="90%" id="alg1.l6.m1.1.1.2.2.2" xref="alg1.l6.m1.1.1.2.2.2.cmml">w</mi><mi mathsize="90%" id="alg1.l6.m1.1.1.2.2.3" xref="alg1.l6.m1.1.1.2.2.3.cmml">t</mi><mi mathsize="90%" id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml">k</mi></msubsup><mover accent="true" id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml"><mo mathsize="90%" stretchy="false" id="alg1.l6.m1.1.1.1.2" xref="alg1.l6.m1.1.1.1.2.cmml">â†</mo><mi id="alg1.l6.m1.1.1.1.1" xref="alg1.l6.m1.1.1.1.1.cmml"></mi></mover><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><apply id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"><csymbol cd="latexml" id="alg1.l6.m1.1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1.1">absent</csymbol><ci id="alg1.l6.m1.1.1.1.2.cmml" xref="alg1.l6.m1.1.1.1.2">â†</ci></apply><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2">superscript</csymbol><apply id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.2.1.cmml" xref="alg1.l6.m1.1.1.2">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.2.2.cmml" xref="alg1.l6.m1.1.1.2.2.2">ğ‘¤</ci><ci id="alg1.l6.m1.1.1.2.2.3.cmml" xref="alg1.l6.m1.1.1.2.2.3">ğ‘¡</ci></apply><ci id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3">ğ‘˜</ci></apply><csymbol cd="latexml" id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">w_{t}^{k}\xleftarrow{}</annotation></semantics></math><span id="alg1.l6.3" class="ltx_text" style="font-size:90%;"> ClientUpdate(</span><math id="alg1.l6.m2.2" class="ltx_Math" alttext="w_{t},T" display="inline"><semantics id="alg1.l6.m2.2a"><mrow id="alg1.l6.m2.2.2.1" xref="alg1.l6.m2.2.2.2.cmml"><msub id="alg1.l6.m2.2.2.1.1" xref="alg1.l6.m2.2.2.1.1.cmml"><mi mathsize="90%" id="alg1.l6.m2.2.2.1.1.2" xref="alg1.l6.m2.2.2.1.1.2.cmml">w</mi><mi mathsize="90%" id="alg1.l6.m2.2.2.1.1.3" xref="alg1.l6.m2.2.2.1.1.3.cmml">t</mi></msub><mo mathsize="90%" id="alg1.l6.m2.2.2.1.2" xref="alg1.l6.m2.2.2.2.cmml">,</mo><mi mathsize="90%" id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.2b"><list id="alg1.l6.m2.2.2.2.cmml" xref="alg1.l6.m2.2.2.1"><apply id="alg1.l6.m2.2.2.1.1.cmml" xref="alg1.l6.m2.2.2.1.1"><csymbol cd="ambiguous" id="alg1.l6.m2.2.2.1.1.1.cmml" xref="alg1.l6.m2.2.2.1.1">subscript</csymbol><ci id="alg1.l6.m2.2.2.1.1.2.cmml" xref="alg1.l6.m2.2.2.1.1.2">ğ‘¤</ci><ci id="alg1.l6.m2.2.2.1.1.3.cmml" xref="alg1.l6.m2.2.2.1.1.3">ğ‘¡</ci></apply><ci id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1">ğ‘‡</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.2c">w_{t},T</annotation></semantics></math><span id="alg1.l6.4" class="ltx_text" style="font-size:90%;">)
</span>
</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span><span id="alg1.l7.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><span id="alg1.l7.3" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l7.4" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l7.5" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span><span id="alg1.l8.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><span id="alg1.l8.3" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="alg1.l8.4" class="ltx_text" style="font-size:90%;">Â </span><math id="alg1.l8.m1.1" class="ltx_Math" alttext="k\in S_{t}" display="inline"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml">k</mi><mo mathsize="90%" id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml">âˆˆ</mo><msub id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l8.m1.1.1.3.2" xref="alg1.l8.m1.1.1.3.2.cmml">S</mi><mi mathsize="90%" id="alg1.l8.m1.1.1.3.3" xref="alg1.l8.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><in id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1"></in><ci id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2">ğ‘˜</ci><apply id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.1.cmml" xref="alg1.l8.m1.1.1.3">subscript</csymbol><ci id="alg1.l8.m1.1.1.3.2.cmml" xref="alg1.l8.m1.1.1.3.2">ğ‘†</ci><ci id="alg1.l8.m1.1.1.3.3.cmml" xref="alg1.l8.m1.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">k\in S_{t}</annotation></semantics></math><span id="alg1.l8.5" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l8.6" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l8.7" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span><span id="alg1.l9.2" class="ltx_text" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><math id="alg1.l9.m1.1" class="ltx_Math" alttext="w_{t+1}\xleftarrow{}" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><msub id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml"><mi mathsize="90%" id="alg1.l9.m1.1.1.2.2" xref="alg1.l9.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l9.m1.1.1.2.3" xref="alg1.l9.m1.1.1.2.3.cmml"><mi mathsize="90%" id="alg1.l9.m1.1.1.2.3.2" xref="alg1.l9.m1.1.1.2.3.2.cmml">t</mi><mo mathsize="90%" id="alg1.l9.m1.1.1.2.3.1" xref="alg1.l9.m1.1.1.2.3.1.cmml">+</mo><mn mathsize="90%" id="alg1.l9.m1.1.1.2.3.3" xref="alg1.l9.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mover accent="true" id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml"><mo mathsize="90%" stretchy="false" id="alg1.l9.m1.1.1.1.2" xref="alg1.l9.m1.1.1.1.2.cmml">â†</mo><mi id="alg1.l9.m1.1.1.1.1" xref="alg1.l9.m1.1.1.1.1.cmml"></mi></mover><mi id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><apply id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1"><csymbol cd="latexml" id="alg1.l9.m1.1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1.1">absent</csymbol><ci id="alg1.l9.m1.1.1.1.2.cmml" xref="alg1.l9.m1.1.1.1.2">â†</ci></apply><apply id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.2.1.cmml" xref="alg1.l9.m1.1.1.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.2.2.cmml" xref="alg1.l9.m1.1.1.2.2">ğ‘¤</ci><apply id="alg1.l9.m1.1.1.2.3.cmml" xref="alg1.l9.m1.1.1.2.3"><plus id="alg1.l9.m1.1.1.2.3.1.cmml" xref="alg1.l9.m1.1.1.2.3.1"></plus><ci id="alg1.l9.m1.1.1.2.3.2.cmml" xref="alg1.l9.m1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l9.m1.1.1.2.3.3.cmml" xref="alg1.l9.m1.1.1.2.3.3">1</cn></apply></apply><csymbol cd="latexml" id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">w_{t+1}\xleftarrow{}</annotation></semantics></math><span id="alg1.l9.3" class="ltx_text" style="font-size:90%;"> Aggregation(</span><math id="alg1.l9.m2.1" class="ltx_Math" alttext="w_{t}^{k}" display="inline"><semantics id="alg1.l9.m2.1a"><msubsup id="alg1.l9.m2.1.1" xref="alg1.l9.m2.1.1.cmml"><mi mathsize="90%" id="alg1.l9.m2.1.1.2.2" xref="alg1.l9.m2.1.1.2.2.cmml">w</mi><mi mathsize="90%" id="alg1.l9.m2.1.1.2.3" xref="alg1.l9.m2.1.1.2.3.cmml">t</mi><mi mathsize="90%" id="alg1.l9.m2.1.1.3" xref="alg1.l9.m2.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l9.m2.1b"><apply id="alg1.l9.m2.1.1.cmml" xref="alg1.l9.m2.1.1"><csymbol cd="ambiguous" id="alg1.l9.m2.1.1.1.cmml" xref="alg1.l9.m2.1.1">superscript</csymbol><apply id="alg1.l9.m2.1.1.2.cmml" xref="alg1.l9.m2.1.1"><csymbol cd="ambiguous" id="alg1.l9.m2.1.1.2.1.cmml" xref="alg1.l9.m2.1.1">subscript</csymbol><ci id="alg1.l9.m2.1.1.2.2.cmml" xref="alg1.l9.m2.1.1.2.2">ğ‘¤</ci><ci id="alg1.l9.m2.1.1.2.3.cmml" xref="alg1.l9.m2.1.1.2.3">ğ‘¡</ci></apply><ci id="alg1.l9.m2.1.1.3.cmml" xref="alg1.l9.m2.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m2.1c">w_{t}^{k}</annotation></semantics></math><span id="alg1.l9.4" class="ltx_text" style="font-size:90%;">)
</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span><span id="alg1.l10.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><span id="alg1.l10.3" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l10.4" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l10.5" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span><span id="alg1.l11.2" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l11.3" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l11.4" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span><span id="alg1.l12.2" class="ltx_text ltx_font_bold" style="font-size:90%;">ClientUpdate</span><span id="alg1.l12.3" class="ltx_text" style="font-size:90%;">(</span><math id="alg1.l12.m1.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="alg1.l12.m1.1a"><msub id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l12.m1.1.1.2" xref="alg1.l12.m1.1.1.2.cmml">w</mi><mi mathsize="90%" id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1.2">ğ‘¤</ci><ci id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">w_{t}</annotation></semantics></math><span id="alg1.l12.4" class="ltx_text" style="font-size:90%;">, </span><math id="alg1.l12.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="alg1.l12.m2.1a"><mi mathsize="90%" id="alg1.l12.m2.1.1" xref="alg1.l12.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.l12.m2.1b"><ci id="alg1.l12.m2.1.1.cmml" xref="alg1.l12.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m2.1c">T</annotation></semantics></math><span id="alg1.l12.5" class="ltx_text" style="font-size:90%;">):
</span>
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span><math id="alg1.l13.m1.1" class="ltx_Math" alttext="w_{t}^{k}\xleftarrow{}w_{t}" display="inline"><semantics id="alg1.l13.m1.1a"><mrow id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml"><msubsup id="alg1.l13.m1.1.1.2" xref="alg1.l13.m1.1.1.2.cmml"><mi mathsize="90%" id="alg1.l13.m1.1.1.2.2.2" xref="alg1.l13.m1.1.1.2.2.2.cmml">w</mi><mi mathsize="90%" id="alg1.l13.m1.1.1.2.2.3" xref="alg1.l13.m1.1.1.2.2.3.cmml">t</mi><mi mathsize="90%" id="alg1.l13.m1.1.1.2.3" xref="alg1.l13.m1.1.1.2.3.cmml">k</mi></msubsup><mover accent="true" id="alg1.l13.m1.1.1.1" xref="alg1.l13.m1.1.1.1.cmml"><mo mathsize="90%" stretchy="false" id="alg1.l13.m1.1.1.1.2" xref="alg1.l13.m1.1.1.1.2.cmml">â†</mo><mi id="alg1.l13.m1.1.1.1.1" xref="alg1.l13.m1.1.1.1.1.cmml"></mi></mover><msub id="alg1.l13.m1.1.1.3" xref="alg1.l13.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l13.m1.1.1.3.2" xref="alg1.l13.m1.1.1.3.2.cmml">w</mi><mi mathsize="90%" id="alg1.l13.m1.1.1.3.3" xref="alg1.l13.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b"><apply id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1"><apply id="alg1.l13.m1.1.1.1.cmml" xref="alg1.l13.m1.1.1.1"><csymbol cd="latexml" id="alg1.l13.m1.1.1.1.1.cmml" xref="alg1.l13.m1.1.1.1.1">absent</csymbol><ci id="alg1.l13.m1.1.1.1.2.cmml" xref="alg1.l13.m1.1.1.1.2">â†</ci></apply><apply id="alg1.l13.m1.1.1.2.cmml" xref="alg1.l13.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l13.m1.1.1.2.1.cmml" xref="alg1.l13.m1.1.1.2">superscript</csymbol><apply id="alg1.l13.m1.1.1.2.2.cmml" xref="alg1.l13.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l13.m1.1.1.2.2.1.cmml" xref="alg1.l13.m1.1.1.2">subscript</csymbol><ci id="alg1.l13.m1.1.1.2.2.2.cmml" xref="alg1.l13.m1.1.1.2.2.2">ğ‘¤</ci><ci id="alg1.l13.m1.1.1.2.2.3.cmml" xref="alg1.l13.m1.1.1.2.2.3">ğ‘¡</ci></apply><ci id="alg1.l13.m1.1.1.2.3.cmml" xref="alg1.l13.m1.1.1.2.3">ğ‘˜</ci></apply><apply id="alg1.l13.m1.1.1.3.cmml" xref="alg1.l13.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l13.m1.1.1.3.1.cmml" xref="alg1.l13.m1.1.1.3">subscript</csymbol><ci id="alg1.l13.m1.1.1.3.2.cmml" xref="alg1.l13.m1.1.1.3.2">ğ‘¤</ci><ci id="alg1.l13.m1.1.1.3.3.cmml" xref="alg1.l13.m1.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.1c">w_{t}^{k}\xleftarrow{}w_{t}</annotation></semantics></math><span id="alg1.l13.2" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span><span id="alg1.l14.2" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="alg1.l14.3" class="ltx_text" style="font-size:90%;">Â data, label </span><math id="alg1.l14.m1.1" class="ltx_Math" alttext="\in D_{k}" display="inline"><semantics id="alg1.l14.m1.1a"><mrow id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml"><mi id="alg1.l14.m1.1.1.2" xref="alg1.l14.m1.1.1.2.cmml"></mi><mo mathsize="90%" id="alg1.l14.m1.1.1.1" xref="alg1.l14.m1.1.1.1.cmml">âˆˆ</mo><msub id="alg1.l14.m1.1.1.3" xref="alg1.l14.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l14.m1.1.1.3.2" xref="alg1.l14.m1.1.1.3.2.cmml">D</mi><mi mathsize="90%" id="alg1.l14.m1.1.1.3.3" xref="alg1.l14.m1.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><apply id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1"><in id="alg1.l14.m1.1.1.1.cmml" xref="alg1.l14.m1.1.1.1"></in><csymbol cd="latexml" id="alg1.l14.m1.1.1.2.cmml" xref="alg1.l14.m1.1.1.2">absent</csymbol><apply id="alg1.l14.m1.1.1.3.cmml" xref="alg1.l14.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l14.m1.1.1.3.1.cmml" xref="alg1.l14.m1.1.1.3">subscript</csymbol><ci id="alg1.l14.m1.1.1.3.2.cmml" xref="alg1.l14.m1.1.1.3.2">ğ·</ci><ci id="alg1.l14.m1.1.1.3.3.cmml" xref="alg1.l14.m1.1.1.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">\in D_{k}</annotation></semantics></math><span id="alg1.l14.4" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l14.5" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l14.6" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.1.1.1" class="ltx_text" style="font-size:80%;">15:</span></span><span id="alg1.l15.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l15.m1.1" class="ltx_Math" alttext="\mathbf{z}=w_{t}^{k}(data)/T" display="inline"><semantics id="alg1.l15.m1.1a"><mrow id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l15.m1.1.1.3" xref="alg1.l15.m1.1.1.3.cmml">ğ³</mi><mo mathsize="90%" id="alg1.l15.m1.1.1.2" xref="alg1.l15.m1.1.1.2.cmml">=</mo><mrow id="alg1.l15.m1.1.1.1" xref="alg1.l15.m1.1.1.1.cmml"><mrow id="alg1.l15.m1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.cmml"><msubsup id="alg1.l15.m1.1.1.1.1.3" xref="alg1.l15.m1.1.1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l15.m1.1.1.1.1.3.2.2" xref="alg1.l15.m1.1.1.1.1.3.2.2.cmml">w</mi><mi mathsize="90%" id="alg1.l15.m1.1.1.1.1.3.2.3" xref="alg1.l15.m1.1.1.1.1.3.2.3.cmml">t</mi><mi mathsize="90%" id="alg1.l15.m1.1.1.1.1.3.3" xref="alg1.l15.m1.1.1.1.1.3.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="alg1.l15.m1.1.1.1.1.2" xref="alg1.l15.m1.1.1.1.1.2.cmml">â€‹</mo><mrow id="alg1.l15.m1.1.1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l15.m1.1.1.1.1.1.1.2" xref="alg1.l15.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="alg1.l15.m1.1.1.1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="alg1.l15.m1.1.1.1.1.1.1.1.2" xref="alg1.l15.m1.1.1.1.1.1.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="alg1.l15.m1.1.1.1.1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l15.m1.1.1.1.1.1.1.1.3" xref="alg1.l15.m1.1.1.1.1.1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l15.m1.1.1.1.1.1.1.1.1a" xref="alg1.l15.m1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l15.m1.1.1.1.1.1.1.1.4" xref="alg1.l15.m1.1.1.1.1.1.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.l15.m1.1.1.1.1.1.1.1.1b" xref="alg1.l15.m1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l15.m1.1.1.1.1.1.1.1.5" xref="alg1.l15.m1.1.1.1.1.1.1.1.5.cmml">a</mi></mrow><mo maxsize="90%" minsize="90%" id="alg1.l15.m1.1.1.1.1.1.1.3" xref="alg1.l15.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="alg1.l15.m1.1.1.1.2" xref="alg1.l15.m1.1.1.1.2.cmml">/</mo><mi mathsize="90%" id="alg1.l15.m1.1.1.1.3" xref="alg1.l15.m1.1.1.1.3.cmml">T</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><apply id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1"><eq id="alg1.l15.m1.1.1.2.cmml" xref="alg1.l15.m1.1.1.2"></eq><ci id="alg1.l15.m1.1.1.3.cmml" xref="alg1.l15.m1.1.1.3">ğ³</ci><apply id="alg1.l15.m1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1"><divide id="alg1.l15.m1.1.1.1.2.cmml" xref="alg1.l15.m1.1.1.1.2"></divide><apply id="alg1.l15.m1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1"><times id="alg1.l15.m1.1.1.1.1.2.cmml" xref="alg1.l15.m1.1.1.1.1.2"></times><apply id="alg1.l15.m1.1.1.1.1.3.cmml" xref="alg1.l15.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l15.m1.1.1.1.1.3.1.cmml" xref="alg1.l15.m1.1.1.1.1.3">superscript</csymbol><apply id="alg1.l15.m1.1.1.1.1.3.2.cmml" xref="alg1.l15.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l15.m1.1.1.1.1.3.2.1.cmml" xref="alg1.l15.m1.1.1.1.1.3">subscript</csymbol><ci id="alg1.l15.m1.1.1.1.1.3.2.2.cmml" xref="alg1.l15.m1.1.1.1.1.3.2.2">ğ‘¤</ci><ci id="alg1.l15.m1.1.1.1.1.3.2.3.cmml" xref="alg1.l15.m1.1.1.1.1.3.2.3">ğ‘¡</ci></apply><ci id="alg1.l15.m1.1.1.1.1.3.3.cmml" xref="alg1.l15.m1.1.1.1.1.3.3">ğ‘˜</ci></apply><apply id="alg1.l15.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1.1"><times id="alg1.l15.m1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1.1"></times><ci id="alg1.l15.m1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1.2">ğ‘‘</ci><ci id="alg1.l15.m1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1.3">ğ‘</ci><ci id="alg1.l15.m1.1.1.1.1.1.1.1.4.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1.4">ğ‘¡</ci><ci id="alg1.l15.m1.1.1.1.1.1.1.1.5.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1.5">ğ‘</ci></apply></apply><ci id="alg1.l15.m1.1.1.1.3.cmml" xref="alg1.l15.m1.1.1.1.3">ğ‘‡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">\mathbf{z}=w_{t}^{k}(data)/T</annotation></semantics></math><span id="alg1.l15.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span><span id="alg1.l16.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l16.m1.3" class="ltx_Math" alttext="l(\mathbf{z})=loss(\mathbf{z};label)" display="inline"><semantics id="alg1.l16.m1.3a"><mrow id="alg1.l16.m1.3.3" xref="alg1.l16.m1.3.3.cmml"><mrow id="alg1.l16.m1.3.3.3" xref="alg1.l16.m1.3.3.3.cmml"><mi mathsize="90%" id="alg1.l16.m1.3.3.3.2" xref="alg1.l16.m1.3.3.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.3.1" xref="alg1.l16.m1.3.3.3.1.cmml">â€‹</mo><mrow id="alg1.l16.m1.3.3.3.3.2" xref="alg1.l16.m1.3.3.3.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l16.m1.3.3.3.3.2.1" xref="alg1.l16.m1.3.3.3.cmml">(</mo><mi mathsize="90%" id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml">ğ³</mi><mo maxsize="90%" minsize="90%" id="alg1.l16.m1.3.3.3.3.2.2" xref="alg1.l16.m1.3.3.3.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="alg1.l16.m1.3.3.2" xref="alg1.l16.m1.3.3.2.cmml">=</mo><mrow id="alg1.l16.m1.3.3.1" xref="alg1.l16.m1.3.3.1.cmml"><mi mathsize="90%" id="alg1.l16.m1.3.3.1.3" xref="alg1.l16.m1.3.3.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.2" xref="alg1.l16.m1.3.3.1.2.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l16.m1.3.3.1.4" xref="alg1.l16.m1.3.3.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.2a" xref="alg1.l16.m1.3.3.1.2.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l16.m1.3.3.1.5" xref="alg1.l16.m1.3.3.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.2b" xref="alg1.l16.m1.3.3.1.2.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l16.m1.3.3.1.6" xref="alg1.l16.m1.3.3.1.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.2c" xref="alg1.l16.m1.3.3.1.2.cmml">â€‹</mo><mrow id="alg1.l16.m1.3.3.1.1.1" xref="alg1.l16.m1.3.3.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l16.m1.3.3.1.1.1.2" xref="alg1.l16.m1.3.3.1.1.2.cmml">(</mo><mi mathsize="90%" id="alg1.l16.m1.2.2" xref="alg1.l16.m1.2.2.cmml">ğ³</mi><mo mathsize="90%" id="alg1.l16.m1.3.3.1.1.1.3" xref="alg1.l16.m1.3.3.1.1.2.cmml">;</mo><mrow id="alg1.l16.m1.3.3.1.1.1.1" xref="alg1.l16.m1.3.3.1.1.1.1.cmml"><mi mathsize="90%" id="alg1.l16.m1.3.3.1.1.1.1.2" xref="alg1.l16.m1.3.3.1.1.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.1.1.1.1" xref="alg1.l16.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l16.m1.3.3.1.1.1.1.3" xref="alg1.l16.m1.3.3.1.1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.1.1.1.1a" xref="alg1.l16.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l16.m1.3.3.1.1.1.1.4" xref="alg1.l16.m1.3.3.1.1.1.1.4.cmml">b</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.1.1.1.1b" xref="alg1.l16.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l16.m1.3.3.1.1.1.1.5" xref="alg1.l16.m1.3.3.1.1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.3.3.1.1.1.1.1c" xref="alg1.l16.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="alg1.l16.m1.3.3.1.1.1.1.6" xref="alg1.l16.m1.3.3.1.1.1.1.6.cmml">l</mi></mrow><mo maxsize="90%" minsize="90%" id="alg1.l16.m1.3.3.1.1.1.4" xref="alg1.l16.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.3b"><apply id="alg1.l16.m1.3.3.cmml" xref="alg1.l16.m1.3.3"><eq id="alg1.l16.m1.3.3.2.cmml" xref="alg1.l16.m1.3.3.2"></eq><apply id="alg1.l16.m1.3.3.3.cmml" xref="alg1.l16.m1.3.3.3"><times id="alg1.l16.m1.3.3.3.1.cmml" xref="alg1.l16.m1.3.3.3.1"></times><ci id="alg1.l16.m1.3.3.3.2.cmml" xref="alg1.l16.m1.3.3.3.2">ğ‘™</ci><ci id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1">ğ³</ci></apply><apply id="alg1.l16.m1.3.3.1.cmml" xref="alg1.l16.m1.3.3.1"><times id="alg1.l16.m1.3.3.1.2.cmml" xref="alg1.l16.m1.3.3.1.2"></times><ci id="alg1.l16.m1.3.3.1.3.cmml" xref="alg1.l16.m1.3.3.1.3">ğ‘™</ci><ci id="alg1.l16.m1.3.3.1.4.cmml" xref="alg1.l16.m1.3.3.1.4">ğ‘œ</ci><ci id="alg1.l16.m1.3.3.1.5.cmml" xref="alg1.l16.m1.3.3.1.5">ğ‘ </ci><ci id="alg1.l16.m1.3.3.1.6.cmml" xref="alg1.l16.m1.3.3.1.6">ğ‘ </ci><list id="alg1.l16.m1.3.3.1.1.2.cmml" xref="alg1.l16.m1.3.3.1.1.1"><ci id="alg1.l16.m1.2.2.cmml" xref="alg1.l16.m1.2.2">ğ³</ci><apply id="alg1.l16.m1.3.3.1.1.1.1.cmml" xref="alg1.l16.m1.3.3.1.1.1.1"><times id="alg1.l16.m1.3.3.1.1.1.1.1.cmml" xref="alg1.l16.m1.3.3.1.1.1.1.1"></times><ci id="alg1.l16.m1.3.3.1.1.1.1.2.cmml" xref="alg1.l16.m1.3.3.1.1.1.1.2">ğ‘™</ci><ci id="alg1.l16.m1.3.3.1.1.1.1.3.cmml" xref="alg1.l16.m1.3.3.1.1.1.1.3">ğ‘</ci><ci id="alg1.l16.m1.3.3.1.1.1.1.4.cmml" xref="alg1.l16.m1.3.3.1.1.1.1.4">ğ‘</ci><ci id="alg1.l16.m1.3.3.1.1.1.1.5.cmml" xref="alg1.l16.m1.3.3.1.1.1.1.5">ğ‘’</ci><ci id="alg1.l16.m1.3.3.1.1.1.1.6.cmml" xref="alg1.l16.m1.3.3.1.1.1.1.6">ğ‘™</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.3c">l(\mathbf{z})=loss(\mathbf{z};label)</annotation></semantics></math><span id="alg1.l16.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l17.1.1.1" class="ltx_text" style="font-size:80%;">17:</span></span><span id="alg1.l17.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l17.m1.1" class="ltx_Math" alttext="w_{t}^{k}\xleftarrow{}w_{t}^{k}-\eta\nabla l(\mathbf{z})" display="inline"><semantics id="alg1.l17.m1.1a"><mrow id="alg1.l17.m1.1.2" xref="alg1.l17.m1.1.2.cmml"><msubsup id="alg1.l17.m1.1.2.2" xref="alg1.l17.m1.1.2.2.cmml"><mi mathsize="90%" id="alg1.l17.m1.1.2.2.2.2" xref="alg1.l17.m1.1.2.2.2.2.cmml">w</mi><mi mathsize="90%" id="alg1.l17.m1.1.2.2.2.3" xref="alg1.l17.m1.1.2.2.2.3.cmml">t</mi><mi mathsize="90%" id="alg1.l17.m1.1.2.2.3" xref="alg1.l17.m1.1.2.2.3.cmml">k</mi></msubsup><mover accent="true" id="alg1.l17.m1.1.2.1" xref="alg1.l17.m1.1.2.1.cmml"><mo mathsize="90%" stretchy="false" id="alg1.l17.m1.1.2.1.2" xref="alg1.l17.m1.1.2.1.2.cmml">â†</mo><mi id="alg1.l17.m1.1.2.1.1" xref="alg1.l17.m1.1.2.1.1.cmml"></mi></mover><mrow id="alg1.l17.m1.1.2.3" xref="alg1.l17.m1.1.2.3.cmml"><msubsup id="alg1.l17.m1.1.2.3.2" xref="alg1.l17.m1.1.2.3.2.cmml"><mi mathsize="90%" id="alg1.l17.m1.1.2.3.2.2.2" xref="alg1.l17.m1.1.2.3.2.2.2.cmml">w</mi><mi mathsize="90%" id="alg1.l17.m1.1.2.3.2.2.3" xref="alg1.l17.m1.1.2.3.2.2.3.cmml">t</mi><mi mathsize="90%" id="alg1.l17.m1.1.2.3.2.3" xref="alg1.l17.m1.1.2.3.2.3.cmml">k</mi></msubsup><mo mathsize="90%" id="alg1.l17.m1.1.2.3.1" xref="alg1.l17.m1.1.2.3.1.cmml">âˆ’</mo><mrow id="alg1.l17.m1.1.2.3.3" xref="alg1.l17.m1.1.2.3.3.cmml"><mi mathsize="90%" id="alg1.l17.m1.1.2.3.3.2" xref="alg1.l17.m1.1.2.3.3.2.cmml">Î·</mi><mo lspace="0.167em" rspace="0em" id="alg1.l17.m1.1.2.3.3.1" xref="alg1.l17.m1.1.2.3.3.1.cmml">â€‹</mo><mrow id="alg1.l17.m1.1.2.3.3.3" xref="alg1.l17.m1.1.2.3.3.3.cmml"><mo mathsize="90%" rspace="0.167em" id="alg1.l17.m1.1.2.3.3.3.1" xref="alg1.l17.m1.1.2.3.3.3.1.cmml">âˆ‡</mo><mi mathsize="90%" id="alg1.l17.m1.1.2.3.3.3.2" xref="alg1.l17.m1.1.2.3.3.3.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.l17.m1.1.2.3.3.1a" xref="alg1.l17.m1.1.2.3.3.1.cmml">â€‹</mo><mrow id="alg1.l17.m1.1.2.3.3.4.2" xref="alg1.l17.m1.1.2.3.3.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l17.m1.1.2.3.3.4.2.1" xref="alg1.l17.m1.1.2.3.3.cmml">(</mo><mi mathsize="90%" id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml">ğ³</mi><mo maxsize="90%" minsize="90%" id="alg1.l17.m1.1.2.3.3.4.2.2" xref="alg1.l17.m1.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><apply id="alg1.l17.m1.1.2.cmml" xref="alg1.l17.m1.1.2"><apply id="alg1.l17.m1.1.2.1.cmml" xref="alg1.l17.m1.1.2.1"><csymbol cd="latexml" id="alg1.l17.m1.1.2.1.1.cmml" xref="alg1.l17.m1.1.2.1.1">absent</csymbol><ci id="alg1.l17.m1.1.2.1.2.cmml" xref="alg1.l17.m1.1.2.1.2">â†</ci></apply><apply id="alg1.l17.m1.1.2.2.cmml" xref="alg1.l17.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l17.m1.1.2.2.1.cmml" xref="alg1.l17.m1.1.2.2">superscript</csymbol><apply id="alg1.l17.m1.1.2.2.2.cmml" xref="alg1.l17.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l17.m1.1.2.2.2.1.cmml" xref="alg1.l17.m1.1.2.2">subscript</csymbol><ci id="alg1.l17.m1.1.2.2.2.2.cmml" xref="alg1.l17.m1.1.2.2.2.2">ğ‘¤</ci><ci id="alg1.l17.m1.1.2.2.2.3.cmml" xref="alg1.l17.m1.1.2.2.2.3">ğ‘¡</ci></apply><ci id="alg1.l17.m1.1.2.2.3.cmml" xref="alg1.l17.m1.1.2.2.3">ğ‘˜</ci></apply><apply id="alg1.l17.m1.1.2.3.cmml" xref="alg1.l17.m1.1.2.3"><minus id="alg1.l17.m1.1.2.3.1.cmml" xref="alg1.l17.m1.1.2.3.1"></minus><apply id="alg1.l17.m1.1.2.3.2.cmml" xref="alg1.l17.m1.1.2.3.2"><csymbol cd="ambiguous" id="alg1.l17.m1.1.2.3.2.1.cmml" xref="alg1.l17.m1.1.2.3.2">superscript</csymbol><apply id="alg1.l17.m1.1.2.3.2.2.cmml" xref="alg1.l17.m1.1.2.3.2"><csymbol cd="ambiguous" id="alg1.l17.m1.1.2.3.2.2.1.cmml" xref="alg1.l17.m1.1.2.3.2">subscript</csymbol><ci id="alg1.l17.m1.1.2.3.2.2.2.cmml" xref="alg1.l17.m1.1.2.3.2.2.2">ğ‘¤</ci><ci id="alg1.l17.m1.1.2.3.2.2.3.cmml" xref="alg1.l17.m1.1.2.3.2.2.3">ğ‘¡</ci></apply><ci id="alg1.l17.m1.1.2.3.2.3.cmml" xref="alg1.l17.m1.1.2.3.2.3">ğ‘˜</ci></apply><apply id="alg1.l17.m1.1.2.3.3.cmml" xref="alg1.l17.m1.1.2.3.3"><times id="alg1.l17.m1.1.2.3.3.1.cmml" xref="alg1.l17.m1.1.2.3.3.1"></times><ci id="alg1.l17.m1.1.2.3.3.2.cmml" xref="alg1.l17.m1.1.2.3.3.2">ğœ‚</ci><apply id="alg1.l17.m1.1.2.3.3.3.cmml" xref="alg1.l17.m1.1.2.3.3.3"><ci id="alg1.l17.m1.1.2.3.3.3.1.cmml" xref="alg1.l17.m1.1.2.3.3.3.1">âˆ‡</ci><ci id="alg1.l17.m1.1.2.3.3.3.2.cmml" xref="alg1.l17.m1.1.2.3.3.3.2">ğ‘™</ci></apply><ci id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1">ğ³</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">w_{t}^{k}\xleftarrow{}w_{t}^{k}-\eta\nabla l(\mathbf{z})</annotation></semantics></math><span id="alg1.l17.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l18.1.1.1" class="ltx_text" style="font-size:80%;">18:</span></span><span id="alg1.l18.2" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l18.3" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l18.4" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l19.1.1.1" class="ltx_text" style="font-size:80%;">19:</span></span><span id="alg1.l19.2" class="ltx_text" style="font-size:90%;">Return </span><math id="alg1.l19.m1.1" class="ltx_Math" alttext="w_{t}^{k}" display="inline"><semantics id="alg1.l19.m1.1a"><msubsup id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l19.m1.1.1.2.2" xref="alg1.l19.m1.1.1.2.2.cmml">w</mi><mi mathsize="90%" id="alg1.l19.m1.1.1.2.3" xref="alg1.l19.m1.1.1.2.3.cmml">t</mi><mi mathsize="90%" id="alg1.l19.m1.1.1.3" xref="alg1.l19.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><apply id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.1.cmml" xref="alg1.l19.m1.1.1">superscript</csymbol><apply id="alg1.l19.m1.1.1.2.cmml" xref="alg1.l19.m1.1.1"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.2.1.cmml" xref="alg1.l19.m1.1.1">subscript</csymbol><ci id="alg1.l19.m1.1.1.2.2.cmml" xref="alg1.l19.m1.1.1.2.2">ğ‘¤</ci><ci id="alg1.l19.m1.1.1.2.3.cmml" xref="alg1.l19.m1.1.1.2.3">ğ‘¡</ci></apply><ci id="alg1.l19.m1.1.1.3.cmml" xref="alg1.l19.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">w_{t}^{k}</annotation></semantics></math><span id="alg1.l19.3" class="ltx_text" style="font-size:90%;"> to server
</span>
</div>
</div>
</div>
</div>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">We evaluate the performance of <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">FLex<math id="S4.p1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.p1.1.1.m1.1a"><mo id="S4.p1.1.1.m1.1.1" xref="S4.p1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.1.m1.1b"><and id="S4.p1.1.1.m1.1.1.cmml" xref="S4.p1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span> using three datasets: (i) FEMNIST from the LEAF databaseÂ <cite class="ltx_cite ltx_citemacro_cite">Caldas <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2018b</a>)</cite>, including the Extended MNIST handwriting dataÂ <cite class="ltx_cite ltx_citemacro_cite">Cohen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite> , (ii) the CIFAR10 dataset, and (iii) the CIFAR100 datasetÂ <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2009</a>)</cite>. As metrics, we use the average accuracy and training loss observed at the clients, selected to observe both the performance gain and the effectiveness of <span id="S4.p1.2.2" class="ltx_text ltx_font_italic">FLex<math id="S4.p1.2.2.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.p1.2.2.m1.1a"><mo id="S4.p1.2.2.m1.1.1" xref="S4.p1.2.2.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.2.m1.1b"><and id="S4.p1.2.2.m1.1.1.cmml" xref="S4.p1.2.2.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.2.m1.1c">\&amp;</annotation></semantics></math>Chill</span> in its training operations. Furthermore, we also present the number of federated learning rounds needed to achieve a pre-defined target accuracy.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.09986/assets/x4.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="138" height="86" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F4.sf1.3.2" class="ltx_text" style="font-size:80%;">FEMNIST-DNN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.09986/assets/x5.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="138" height="86" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F4.sf2.3.2" class="ltx_text" style="font-size:80%;">CIFAR10-CNN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.09986/assets/x6.png" id="S4.F4.sf3.g1" class="ltx_graphics ltx_img_landscape" width="138" height="86" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F4.sf3.3.2" class="ltx_text" style="font-size:80%;">CIFAR100-ResNet18</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Average federated learning client-side model accuracy for different temperatures used in training. Overall, lower temperatures show higher average model accuracy for federated learning systems.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiment Setup</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Dataset.</span> We detail the datasets used in our work as follows.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">FEMNIST dataset:</span> Sourced from the LEAF dataset, the FEMNIST dataset comprises of 10 handwritten digits (0-9) and 52 characters (26 lowercase and 26 upper case) images contributed by 712 users, totaling 157,132 samples. We selected a subset of 36 users, each with diverse amounts of local data to account for the non-iid environment. We followed the implementations provided by the original workÂ <cite class="ltx_cite ltx_citemacro_cite">Caldas <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib1" title="" class="ltx_ref">2018a</a>)</cite>.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">CIFAR10 and CIFAR100 dataset:</span> We use the baseline CIFAR10 and CIFAR100 datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2009</a>)</cite> and manually partition the data over 50 federated learning users, with each user holding 1,000 samples.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Model.</span> For each dataset, we utilized distinct model architectures, taking into account the specific challenges and characteristics inherent to each dataset. For FEMNIST, an MLP model featuring four linear layers was employed. We term this combination as â€œFEMNIST-DNNâ€ in the rest of our evaluations. In the case of the CIFAR10 and CIFAR100 datasets, experiments were conducted using a two-layer CNN modelÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2017</a>)</cite> and a ResNet18Â <cite class="ltx_cite ltx_citemacro_cite">He <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2016</a>)</cite>, respectively. These two cases are denoted as â€œCIFAR10-CNNâ€ and â€œCIFAR100-ResNet18.â€</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Experiment Details.</span> Each case underwent local training for 300 federated training rounds, utilizing FedAvgÂ <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2017</a>)</cite> as the baseline federated learning framework. FedAvg is a widely used framework for federated learning. In each round, the server selects 10 participating clients, employing Stochastic Gradient Descent (SGD) as the optimizer with a learning rate of 0.001Â <cite class="ltx_cite ltx_citemacro_cite">Ruder (<a href="#bib.bib20" title="" class="ltx_ref">2016</a>)</cite>. Each client trained its model for 10 local epochs, employing a batch size of 16, and utilized cross-entropy loss as the loss function.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Average Client-side Accuracy</h3>

<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.09986/assets/x7.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_img_landscape" width="138" height="86" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F5.sf1.3.2" class="ltx_text" style="font-size:80%;">FEMNIST-DNN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.09986/assets/x8.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="138" height="86" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F5.sf2.3.2" class="ltx_text" style="font-size:80%;">CIFAR10-CNN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.09986/assets/x9.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_img_landscape" width="138" height="86" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F5.sf3.3.2" class="ltx_text" style="font-size:80%;">CIFAR100-ResNet18</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Federated learning client-side model training loss observed for different training temperature values. We can notice that overall a lower training loss is observed when lower temperature values are used for model training.</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.4" class="ltx_p">We report the average client-side model accuracy results obtained for models trained with different temperatures in FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. For all three datasets (and the three respective models used for each test case) we see an increasing accuracy trend observed for lower temperatures. Note that for the FEMNIST-DNN case with <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">T</annotation></semantics></math>=0.05, we noticed that the accuracy converges after 120 rounds; thus, perform an early exit for this case. One interesting aspect we can notice is that the accuracy for the <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">T</annotation></semantics></math>=0.05 case, which is the lowest temperature we test for, does not show the best performance for the CIFAR100-ResNet18 experiment. While the <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">T</annotation></semantics></math>=0.05 case shows the best performance of FEMNIST-DNN and CIFAR10-CNN, for CIFAR100-ResNet18, we see a accuracy worse than the <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mi id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><ci id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">T</annotation></semantics></math>=0.5 case. This suggests that training with the lowest possible temperature value is not always ideal, rather this result highlights the importance of identifying a proper training temperature as we will further discuss in SectionÂ <a href="#S5" title="5 Discussion â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. A closer zoom into the plots suggest that the best performing configuration can change over the training round and can vary for different datasets, but overall, we can notice that exploiting a temperature value lower than â€œ1â€ in the training process can help improve the classification accuracy.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">The average accuracy for all federated learning clients after 300 training rounds presented in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.4 Federated Learning Convergence Analysis â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> confirm our observations, indicating that with <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">T</annotation></semantics></math>=0.05 the CIFAR10 case shows a 3.37% improvement in accuracy compared to the <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">T</annotation></semantics></math>=1 case. Even for other cases, the use of a low temperature value show promising results in terms of accuracy. We emphasize once more that this does not mean that the accuracy will always perform better at the lowest temperature. Rather, our results suggest the need to carefully explore the fractional temperature space in the federated learning training process.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Training Loss</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.2" class="ltx_p">Next we compare the training loss observed at the clients. In FigureÂ <a href="#S4.F5" title="Figure 5 â€£ 4.2 Average Client-side Accuracy â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we present the average the loss observed at each federated learning training round. Again, we note that we perform early exit for the FEMNIST-DNN case at 120 rounds when <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">T</annotation></semantics></math>=0.05 due to quick model convergence. We can notice there that the use of lower temperatures in the training phase generally helps quickly lower the training loss during the local training phase for federated learning clients. At the same time, when observing the CIFAR100-ResNet18 plots, we can see that the loss for <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">T</annotation></semantics></math>=0.05 does not converge well. In fact, this serves as a reason behind the lower accuracy reported for CIFAR100-ResNet18.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.3" class="ltx_p">From the quantitative values in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.4 Federated Learning Convergence Analysis â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> where we plot the average loss observed at all federated learning clients after 300 training rounds (120 for the FEMNIST-DNN @ <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">T</annotation></semantics></math>=0.05), we can make similar observations. Especially, for FEMNIST-DNN, we see a six-fold improvement in loss values compared to <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">T</annotation></semantics></math>=1. For the CIFAR100-ResNet18 case, however, we notice that the lowest loss convergence is in fact the <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mi id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><ci id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">T</annotation></semantics></math>=0.25 case rather than 0.05. This observation confirms the need to properly consider and explore fractional temperature values for client-side model training.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Federated Learning Convergence Analysis</h3>

<figure id="S4.T1" class="ltx_table">
<p id="S4.T1.7" class="ltx_p"><span id="S4.T1.7.7" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S4.T1.7.7.7.7" class="ltx_inline-block ltx_transformed_outer" style="width:646.7pt;height:145pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S4.T1.7.7.7.7.7" class="ltx_p"><span id="S4.T1.7.7.7.7.7.7" class="ltx_text">
<span id="S4.T1.7.7.7.7.7.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T1.7.7.7.7.7.7.7.8.1" class="ltx_tr">
<span id="S4.T1.7.7.7.7.7.7.7.8.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></span>
<span id="S4.T1.7.7.7.7.7.7.7.8.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3">FEMNIST-DNN</span>
<span id="S4.T1.7.7.7.7.7.7.7.8.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3">CIFAR10-CNN</span>
<span id="S4.T1.7.7.7.7.7.7.7.8.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3">CIFAR100-ResNet18</span></span>
<span id="S4.T1.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.T1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Temperature (<math id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1c">T</annotation></semantics></math>)</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy (%)</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Loss</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Num. of Round</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy (%)</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Loss</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Num. of Round</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy (%)</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Loss</span>
<span id="S4.T1.1.1.1.1.1.1.1.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Num. of Round</span></span>
<span id="S4.T1.2.2.2.2.2.2.2.2" class="ltx_tr">
<span id="S4.T1.2.2.2.2.2.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="T=4.0" display="inline"><semantics id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1a"><mrow id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.cmml"><mi id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.2" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.2.cmml">T</mi><mo id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.1" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.3" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1b"><apply id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1"><eq id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.1"></eq><ci id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.2.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.2">ğ‘‡</ci><cn type="float" id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.3.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1c">T=4.0</annotation></semantics></math></span>
<span id="S4.T1.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.60 (-5.06)</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.893</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">299 (0.44Ã—)</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">37.58 (-3.76)</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.724</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">299 (0.84Ã—)</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.05 (-0.20)</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.984</span>
<span id="S4.T1.2.2.2.2.2.2.2.2.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">288 (0.69Ã—)</span></span>
<span id="S4.T1.3.3.3.3.3.3.3.3" class="ltx_tr">
<span id="S4.T1.3.3.3.3.3.3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="T=2.0" display="inline"><semantics id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1a"><mrow id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.cmml"><mi id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.2" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.2.cmml">T</mi><mo id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.1" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.3" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1b"><apply id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1"><eq id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.1.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.1"></eq><ci id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.2.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.2">ğ‘‡</ci><cn type="float" id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.3.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1c">T=2.0</annotation></semantics></math></span>
<span id="S4.T1.3.3.3.3.3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.20 (-1.46)</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.749</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">205 (0.64Ã—)</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.35 (-0.99)</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.638</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">270 (0.93Ã—)</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.89 (-0.36)</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.918</span>
<span id="S4.T1.3.3.3.3.3.3.3.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">288 (0.69Ã—)</span></span>
<span id="S4.T1.4.4.4.4.4.4.4.4" class="ltx_tr">
<span id="S4.T1.4.4.4.4.4.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="T=1.0" display="inline"><semantics id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1a"><mrow id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.cmml"><mi id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.2" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.2.cmml">T</mi><mo id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.1" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.3" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1b"><apply id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1"><eq id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.1.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.1"></eq><ci id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.2.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.2">ğ‘‡</ci><cn type="float" id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.3.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1c">T=1.0</annotation></semantics></math></span>
<span id="S4.T1.4.4.4.4.4.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78.66 (0.00)</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.684</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">132 (1.00Ã—)</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.34 (0.00)</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.594</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">251 (1.00Ã—)</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.25 (0.00)</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.918</span>
<span id="S4.T1.4.4.4.4.4.4.4.4.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">200 (1Ã—)</span></span>
<span id="S4.T1.5.5.5.5.5.5.5.5" class="ltx_tr">
<span id="S4.T1.5.5.5.5.5.5.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="T=0.5" display="inline"><semantics id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1a"><mrow id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.cmml"><mi id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.2" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.2.cmml">T</mi><mo id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.1" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.3" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1b"><apply id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1"><eq id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.1.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.1"></eq><ci id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.2.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.2">ğ‘‡</ci><cn type="float" id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.3.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1c">T=0.5</annotation></semantics></math></span>
<span id="S4.T1.5.5.5.5.5.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79.78 (+1.13)</span>
<span id="S4.T1.5.5.5.5.5.5.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.654</span>
<span id="S4.T1.5.5.5.5.5.5.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88 (1.50Ã—)</span>
<span id="S4.T1.5.5.5.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.52 (+0.18)</span>
<span id="S4.T1.5.5.5.5.5.5.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.551</span>
<span id="S4.T1.5.5.5.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">161 (1.56Ã—)</span>
<span id="S4.T1.5.5.5.5.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">29.77 (+1.52)</span>
<span id="S4.T1.5.5.5.5.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.5.5.5.5.5.5.5.9.1" class="ltx_text ltx_font_bold">2.875</span></span>
<span id="S4.T1.5.5.5.5.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">178 (1.12Ã—)</span></span>
<span id="S4.T1.6.6.6.6.6.6.6.6" class="ltx_tr">
<span id="S4.T1.6.6.6.6.6.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="T=0.25" display="inline"><semantics id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1a"><mrow id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.cmml"><mi id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.2" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.2.cmml">T</mi><mo id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.1" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.3" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1b"><apply id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1"><eq id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.1.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.1"></eq><ci id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.2.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.2">ğ‘‡</ci><cn type="float" id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.3.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1c">T=0.25</annotation></semantics></math></span>
<span id="S4.T1.6.6.6.6.6.6.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79.50 (+0.85)</span>
<span id="S4.T1.6.6.6.6.6.6.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.650</span>
<span id="S4.T1.6.6.6.6.6.6.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57 (2.32Ã—)</span>
<span id="S4.T1.6.6.6.6.6.6.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.41 (+2.07)</span>
<span id="S4.T1.6.6.6.6.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.532</span>
<span id="S4.T1.6.6.6.6.6.6.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">132 (1.90Ã—)</span>
<span id="S4.T1.6.6.6.6.6.6.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.6.6.6.6.6.6.6.8.1" class="ltx_text ltx_font_bold">30.63 (+2.38)</span></span>
<span id="S4.T1.6.6.6.6.6.6.6.6.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.997</span>
<span id="S4.T1.6.6.6.6.6.6.6.6.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.6.6.6.6.6.6.6.10.1" class="ltx_text ltx_font_bold">152 (1.32Ã—)</span></span></span>
<span id="S4.T1.7.7.7.7.7.7.7.7" class="ltx_tr">
<span id="S4.T1.7.7.7.7.7.7.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="T=0.05" display="inline"><semantics id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1a"><mrow id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.cmml"><mi id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.2" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.2.cmml">T</mi><mo id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.1" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.3" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1b"><apply id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1"><eq id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.1.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.1"></eq><ci id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.2.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.2">ğ‘‡</ci><cn type="float" id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.3.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1c">T=0.05</annotation></semantics></math></span>
<span id="S4.T1.7.7.7.7.7.7.7.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.7.7.7.7.7.7.7.7.2.1" class="ltx_text ltx_font_bold">80.86 (+2.20)</span></span>
<span id="S4.T1.7.7.7.7.7.7.7.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.7.7.7.7.7.7.7.7.3.1" class="ltx_text ltx_font_bold">0.643</span></span>
<span id="S4.T1.7.7.7.7.7.7.7.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.7.7.7.7.7.7.7.7.4.1" class="ltx_text ltx_font_bold">22 (6.00Ã—)</span></span>
<span id="S4.T1.7.7.7.7.7.7.7.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.7.7.7.7.7.7.7.7.5.1" class="ltx_text ltx_font_bold">44.71 (+3.37)</span></span>
<span id="S4.T1.7.7.7.7.7.7.7.7.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.7.7.7.7.7.7.7.7.6.1" class="ltx_text ltx_font_bold">1.528</span></span>
<span id="S4.T1.7.7.7.7.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.7.7.7.7.7.7.7.7.7.1" class="ltx_text ltx_font_bold">106 (2.37Ã—)</span></span>
<span id="S4.T1.7.7.7.7.7.7.7.7.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">27.05 (-2.72)</span>
<span id="S4.T1.7.7.7.7.7.7.7.7.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">4.228</span>
<span id="S4.T1.7.7.7.7.7.7.7.7.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">239 (0.74Ã—)</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Average classification accuracy, model training loss, and number of federated learning training rounds needed to achieve the maximum accuracy of the <math id="S4.T1.9.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.T1.9.m1.1b"><mi id="S4.T1.9.m1.1.1" xref="S4.T1.9.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.T1.9.m1.1c"><ci id="S4.T1.9.m1.1.1.cmml" xref="S4.T1.9.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.m1.1d">T</annotation></semantics></math>=4 case for each dataset-model combination. Quantitative results suggest the effectiveness of exploiting low temperatures for model training in federated learning both in terms of model accuracy and training efficiency.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<p id="S4.T2.1" class="ltx_p"><span id="S4.T2.1.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S4.T2.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:289.3pt;height:144pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S4.T2.1.1.1.1.1" class="ltx_p"><span id="S4.T2.1.1.1.1.1.1" class="ltx_text">
<span id="S4.T2.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T2.1.1.1.1.1.1.1.2.1" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.2.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></span>
<span id="S4.T2.1.1.1.1.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">Centralized - iid</span>
<span id="S4.T2.1.1.1.1.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">Federated - iid</span>
<span id="S4.T2.1.1.1.1.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">Federated - non-iid</span></span>
<span id="S4.T2.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.T2.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S4.T2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.1.1.1.1.m1.1c">T</annotation></semantics></math></span>
<span id="S4.T2.1.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Acc. (%)</span>
<span id="S4.T2.1.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Loss</span>
<span id="S4.T2.1.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Acc. (%)</span>
<span id="S4.T2.1.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Loss</span>
<span id="S4.T2.1.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Acc. (%)</span>
<span id="S4.T2.1.1.1.1.1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Loss</span></span>
<span id="S4.T2.1.1.1.1.1.1.1.3.2" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">4.0</span>
<span id="S4.T2.1.1.1.1.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58.05</span>
<span id="S4.T2.1.1.1.1.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.152</span>
<span id="S4.T2.1.1.1.1.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.22</span>
<span id="S4.T2.1.1.1.1.1.1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.473</span>
<span id="S4.T2.1.1.1.1.1.1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">37.58</span>
<span id="S4.T2.1.1.1.1.1.1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.724</span></span>
<span id="S4.T2.1.1.1.1.1.1.1.4.3" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">2.0</span>
<span id="S4.T2.1.1.1.1.1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.27</span>
<span id="S4.T2.1.1.1.1.1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.041</span>
<span id="S4.T2.1.1.1.1.1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">51.90</span>
<span id="S4.T2.1.1.1.1.1.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.403</span>
<span id="S4.T2.1.1.1.1.1.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.35</span>
<span id="S4.T2.1.1.1.1.1.1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.638</span></span>
<span id="S4.T2.1.1.1.1.1.1.1.5.4" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">1.0</span>
<span id="S4.T2.1.1.1.1.1.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.18</span>
<span id="S4.T2.1.1.1.1.1.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.044</span>
<span id="S4.T2.1.1.1.1.1.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.66</span>
<span id="S4.T2.1.1.1.1.1.1.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.325</span>
<span id="S4.T2.1.1.1.1.1.1.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.34</span>
<span id="S4.T2.1.1.1.1.1.1.1.5.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.594</span></span>
<span id="S4.T2.1.1.1.1.1.1.1.6.5" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">0.5</span>
<span id="S4.T2.1.1.1.1.1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.19</span>
<span id="S4.T2.1.1.1.1.1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.030</span>
<span id="S4.T2.1.1.1.1.1.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">53.19</span>
<span id="S4.T2.1.1.1.1.1.1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.320</span>
<span id="S4.T2.1.1.1.1.1.1.1.6.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.52</span>
<span id="S4.T2.1.1.1.1.1.1.1.6.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.551</span></span>
<span id="S4.T2.1.1.1.1.1.1.1.7.6" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">0.25</span>
<span id="S4.T2.1.1.1.1.1.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.88</span>
<span id="S4.T2.1.1.1.1.1.1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.092</span>
<span id="S4.T2.1.1.1.1.1.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.64</span>
<span id="S4.T2.1.1.1.1.1.1.1.7.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.265</span>
<span id="S4.T2.1.1.1.1.1.1.1.7.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.41</span>
<span id="S4.T2.1.1.1.1.1.1.1.7.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.532</span></span>
<span id="S4.T2.1.1.1.1.1.1.1.8.7" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">0.05</span>
<span id="S4.T2.1.1.1.1.1.1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">60.98</span>
<span id="S4.T2.1.1.1.1.1.1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.227</span>
<span id="S4.T2.1.1.1.1.1.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">47.60</span>
<span id="S4.T2.1.1.1.1.1.1.1.8.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.701</span>
<span id="S4.T2.1.1.1.1.1.1.1.8.7.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">44.71</span>
<span id="S4.T2.1.1.1.1.1.1.1.8.7.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.528</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Average inference accuracy and model training loss for CIFAR10-CNN with different configurations. The impact of <span id="S4.T2.3.1" class="ltx_text ltx_font_italic">FLex<math id="S4.T2.3.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.T2.3.1.m1.1b"><mo id="S4.T2.3.1.m1.1.1" xref="S4.T2.3.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.1.m1.1c"><and id="S4.T2.3.1.m1.1.1.cmml" xref="S4.T2.3.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.1.m1.1d">\&amp;</annotation></semantics></math>Chill</span> is prominent for federated learning scenarios with non-iid datasets, whereas its impact is less when elsewise.</figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Finally, the last columns for each test case in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.4 Federated Learning Convergence Analysis â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> we present the number of federated learning training rounds needed to achieve a preset target accuracy for different temperature values using for model training. This number provides an understanding of how efficient the local training processes are when different temperature values are applied. S</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.3" class="ltx_p">Specifically, in this experiment, we configure the target accuracy to be the maximum accuracy achieved within 300 training rounds with <math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mi id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><ci id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">T</annotation></semantics></math>=4. For example, for the FEMNIST-DNN and CIFAR10-CNN cases, the maximum accuracy for <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mi id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><ci id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">T</annotation></semantics></math>=4 was achieved at the 299<sup id="S4.SS4.p2.3.1" class="ltx_sup"><span id="S4.SS4.p2.3.1.1" class="ltx_text ltx_font_italic">th</span></sup> round, while CIFAR100-ResNet18 achieved such accuracy after 288 rounds.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.2" class="ltx_p">From the results in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.4 Federated Learning Convergence Analysis â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> we can notice that with <math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><mi id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><ci id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">T</annotation></semantics></math>=0.05 the FEMNIST-DNN case achieves the target accuracy after only 22 training rounds. We see similar trends of low temperatures positively affecting the training efficiency throughout our results. This is from the generally aggressiveness of training behaviors when applying lower temperature training. Given a single training sample, while high temperature-based training conservatively absorbs the available information, lower temperatures are more progressive in making model changes. Given the small datasets used for local training and the need to effectively deliver its knowledge to the server for aggregation, we see <span id="S4.SS4.p3.2.1" class="ltx_text ltx_font_italic">FLex<math id="S4.SS4.p3.2.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.SS4.p3.2.1.m1.1a"><mo id="S4.SS4.p3.2.1.m1.1.1" xref="S4.SS4.p3.2.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.1.m1.1b"><and id="S4.SS4.p3.2.1.m1.1.1.cmml" xref="S4.SS4.p3.2.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span>
as an effective way to train client-side models in the federated learning process.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Impact of Dataset Dispersion and Federated Learning on <span id="S4.SS5.1.1" class="ltx_text ltx_font_italic">FLex<math id="S4.SS5.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.SS5.1.1.m1.1b"><mo id="S4.SS5.1.1.m1.1.1" xref="S4.SS5.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.SS5.1.1.m1.1c"><and id="S4.SS5.1.1.m1.1.1.cmml" xref="S4.SS5.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.1.1.m1.1d">\&amp;</annotation></semantics></math>Chill</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.2" class="ltx_p">We now examine the impact of <span id="S4.SS5.p1.1.1" class="ltx_text ltx_font_italic">FLex<math id="S4.SS5.p1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.SS5.p1.1.1.m1.1a"><mo id="S4.SS5.p1.1.1.m1.1.1" xref="S4.SS5.p1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.1.m1.1b"><and id="S4.SS5.p1.1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span> on different model training configurations. Specifically, using the CIFAR10-CNN test case, we examine two additional configurations: (i) centralized learning with iid data and (ii) federated learning with iid data. Note that the federated learning network is identical to our previous experiments except for the dataset distribution and was tested for 300 rounds. By comparing these results with the non-iid federated learning results, we target to understand the impact of <span id="S4.SS5.p1.2.2" class="ltx_text ltx_font_italic">FLex<math id="S4.SS5.p1.2.2.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.SS5.p1.2.2.m1.1a"><mo id="S4.SS5.p1.2.2.m1.1.1" xref="S4.SS5.p1.2.2.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.2.m1.1b"><and id="S4.SS5.p1.2.2.m1.1.1.cmml" xref="S4.SS5.p1.2.2.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.2.m1.1c">\&amp;</annotation></semantics></math>Chill</span> on federated learning and dataset disparity in greater detail.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.4" class="ltx_p">As TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.4 Federated Learning Convergence Analysis â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows, applying <span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_italic">FLex<math id="S4.SS5.p2.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.SS5.p2.1.1.m1.1a"><mo id="S4.SS5.p2.1.1.m1.1.1" xref="S4.SS5.p2.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.1.m1.1b"><and id="S4.SS5.p2.1.1.m1.1.1.cmml" xref="S4.SS5.p2.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span>, thus a lower <math id="S4.SS5.p2.2.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS5.p2.2.m1.1a"><mi id="S4.SS5.p2.2.m1.1.1" xref="S4.SS5.p2.2.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m1.1b"><ci id="S4.SS5.p2.2.m1.1.1.cmml" xref="S4.SS5.p2.2.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.2.m1.1c">T</annotation></semantics></math> does not induce a positive impact on the performance of centralized learning scenarios. In fact, for centralized learning, controlling <math id="S4.SS5.p2.3.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS5.p2.3.m2.1a"><mi id="S4.SS5.p2.3.m2.1.1" xref="S4.SS5.p2.3.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.3.m2.1b"><ci id="S4.SS5.p2.3.m2.1.1.cmml" xref="S4.SS5.p2.3.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.3.m2.1c">T</annotation></semantics></math> for the training process does not show a noticeable impact. We see the same phenomena for the federated learning system with iid samples as well, suggesting that the performance enhancements we see in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.4 Federated Learning Convergence Analysis â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> is not an effect of the federated learning process itself. We do point out that holding iid datasets in federated learning will show overall higher performance compared to non-iid configurations (regardless from <math id="S4.SS5.p2.4.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS5.p2.4.m3.1a"><mi id="S4.SS5.p2.4.m3.1.1" xref="S4.SS5.p2.4.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.4.m3.1b"><ci id="S4.SS5.p2.4.m3.1.1.cmml" xref="S4.SS5.p2.4.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.4.m3.1c">T</annotation></semantics></math>), but is not a practical case to assume when deploying federated learning systems. Rather, as we discussed, the impact of exploiting low training temperatures is beneficial when dealing with non-iid datasets.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2401.09986/assets/x10.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="215" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Accuracy drop observed before and after server-side model aggregation. The aggregation process of client models trained with lower temperatures better retain the individual knowledge.</figcaption>
</figure>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Model stability of low temperature training during federated learning aggregation</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">As discussed in SectionÂ <a href="#S3" title="3 Design of FLex&amp;Chill â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, low temperatures can expedite local training even when dealing with a small amount of training data. Nevertheless, the effect of low temperature training on the model generalization and aggregation stability of federated learning has not yet been thoroughly studied. To inspect the stability of federated learning aggregation for models trained with low temperatures, we measured the the performance change of each client-side model before and after the server-side aggregation round.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">FigureÂ <a href="#S4.F6" title="Figure 6 â€£ 4.5 Impact of Dataset Dispersion and Federated Learning on FLex&amp;Chill â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> plots the changes in accuracy observed for both participating and non-participating clients at each federated learning round. Specifically, once the model is aggregated, each client computes its accuracy with both the pre-update and the post-update model and computes their difference. Note that pre-update models for clients participating in the round would have updated their local models (very recently) with their own data. Thus, the pre-model performance will be high. However, since each model is trained aggressively over heterogeneous data, the aggregation process could puddle up this knowledge and the aggregated model may lose information. Ideally, with their local information properly aggregated, the performance drop will be minimal. Non-participating clients on the other hand, would hope to have an improved updated model the federated learning process.</p>
</div>
<div id="S4.SS6.p3" class="ltx_para">
<p id="S4.SS6.p3.1" class="ltx_p">As FigureÂ <a href="#S4.F6" title="Figure 6 â€£ 4.5 Impact of Dataset Dispersion and Federated Learning on FLex&amp;Chill â€£ 4 Experiment â€£ FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the models trained with low temperatures retain the knowledge better than the medium and hot models for participating clients (solid plots groups at bottom). At the early rounds, the models with high temperature show less performance drop, but the fast learning speed of low temperature model amortizes the performance drop, which results in faster learning of the aggregated model. Furthermore, we can also notice that the aggregation process does not interfere with the performance of non-participating clients (grouped on top), implying that federated learning with low temperature training preserves the generalization power.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p"><math id="S5.p1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S5.p1.1.m1.1a"><mo id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\bullet</annotation></semantics></math><span id="S5.p1.1.1" class="ltx_text ltx_font_bold"> Identifying the optimal temperature.</span> Our study shows the effectiveness of exploiting lower temperatures as a way to enhance federated learning performance. However, an important relevant question remains unanswered: <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">â€œHow do we determine the appropriate or optimal temperature for different applications?â€</span> With varying dataset and models that different federated learning application use, the ideal temperature value will also differ. The scope of this work is on identifying and quantifying the potential benefits of lower temperature-based local training in federated learning and we leave the task of identifying per-purpose optimal temperatures to individual system designers and future research.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><math id="S5.p2.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S5.p2.1.m1.1a"><mo id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\bullet</annotation></semantics></math><span id="S5.p2.1.1" class="ltx_text ltx_font_bold"> Dynamic per-sample temperature scaling.</span> While our paper focuses on understanding the advantages of maintaining a <span id="S5.p2.1.2" class="ltx_text ltx_font_italic">constant low temperature</span> for the training process, this may not be the ideal approach when targeting maximum performance. In reality, varying temperatures can be applied in the training process with respect to their significanceÂ <cite class="ltx_cite ltx_citemacro_cite">Shin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2022</a>); Zeng <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite>. That would mean that the training process can exploit lower temperatures for the samples that is â€œharderâ€ to learn, while higher temperatures are used for those easier to understand. Alternatively, a more course-grain approach of dynamically adjusting the temperature on a per-federated learning round-basis can be another meaningful approach to adapt towards changing local data characteristics.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p"><math id="S5.p3.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S5.p3.1.m1.1a"><mo id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><ci id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">\bullet</annotation></semantics></math><span id="S5.p3.1.1" class="ltx_text ltx_font_bold"> Supporting heterogeneous federated learning.</span> While many federated learning frameworks assume homogeneous devices, recent work have pointed out that this is not always the caseÂ <cite class="ltx_cite ltx_citemacro_cite">Park and Ko (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>. In a federated learning network consisting of devices with heterogeneous computing/network capabilities, the issue of â€œstragglersâ€, which are devices that take longer to complete local training, becomes important to address.
Leveraging insights gleaned from our empirical observations, applying lower temperatures for potential stranglers can be an interesting way of uniforming the local training duration. This would require a prior analysis on the conditions expected at each device and a global consensus on the temperature configuration. We find this as an interesting topic that requires further investigation.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.4" class="ltx_p">This research introduces a novel training approach for federated learning systems, <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">FLex<math id="S6.p1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S6.p1.1.1.m1.1a"><mo id="S6.p1.1.1.m1.1.1" xref="S6.p1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S6.p1.1.1.m1.1b"><and id="S6.p1.1.1.m1.1.1.cmml" xref="S6.p1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.1.m1.1c">\&amp;</annotation></semantics></math>Chill</span>, aimed at enhancing convergence and improving model performance by exploiting a temperature scaling method termed <span id="S6.p1.4.3" class="ltx_text ltx_font_italic">logit chilling</span> in federated learning local model training operations. Specifically, our work revolves around the implications of employing fractional temperature values (<math id="S6.p1.2.m1.1" class="ltx_Math" alttext="0&lt;T&lt;1" display="inline"><semantics id="S6.p1.2.m1.1a"><mrow id="S6.p1.2.m1.1.1" xref="S6.p1.2.m1.1.1.cmml"><mn id="S6.p1.2.m1.1.1.2" xref="S6.p1.2.m1.1.1.2.cmml">0</mn><mo id="S6.p1.2.m1.1.1.3" xref="S6.p1.2.m1.1.1.3.cmml">&lt;</mo><mi id="S6.p1.2.m1.1.1.4" xref="S6.p1.2.m1.1.1.4.cmml">T</mi><mo id="S6.p1.2.m1.1.1.5" xref="S6.p1.2.m1.1.1.5.cmml">&lt;</mo><mn id="S6.p1.2.m1.1.1.6" xref="S6.p1.2.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.2.m1.1b"><apply id="S6.p1.2.m1.1.1.cmml" xref="S6.p1.2.m1.1.1"><and id="S6.p1.2.m1.1.1a.cmml" xref="S6.p1.2.m1.1.1"></and><apply id="S6.p1.2.m1.1.1b.cmml" xref="S6.p1.2.m1.1.1"><lt id="S6.p1.2.m1.1.1.3.cmml" xref="S6.p1.2.m1.1.1.3"></lt><cn type="integer" id="S6.p1.2.m1.1.1.2.cmml" xref="S6.p1.2.m1.1.1.2">0</cn><ci id="S6.p1.2.m1.1.1.4.cmml" xref="S6.p1.2.m1.1.1.4">ğ‘‡</ci></apply><apply id="S6.p1.2.m1.1.1c.cmml" xref="S6.p1.2.m1.1.1"><lt id="S6.p1.2.m1.1.1.5.cmml" xref="S6.p1.2.m1.1.1.5"></lt><share href="#S6.p1.2.m1.1.1.4.cmml" id="S6.p1.2.m1.1.1d.cmml" xref="S6.p1.2.m1.1.1"></share><cn type="integer" id="S6.p1.2.m1.1.1.6.cmml" xref="S6.p1.2.m1.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m1.1c">0&lt;T&lt;1</annotation></semantics></math>) <span id="S6.p1.4.4" class="ltx_text ltx_font_italic">during</span> the model training process. Our findings, derived from an extensive set of evaluations using three datasets and three widely applied neural networks for federated learning, demonstrate that exploiting the <span id="S6.p1.3.2" class="ltx_text ltx_font_italic">FLex<math id="S6.p1.3.2.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S6.p1.3.2.m1.1a"><mo id="S6.p1.3.2.m1.1.1" xref="S6.p1.3.2.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S6.p1.3.2.m1.1b"><and id="S6.p1.3.2.m1.1.1.cmml" xref="S6.p1.3.2.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.3.2.m1.1c">\&amp;</annotation></semantics></math>Chill</span> approach in the client-side model training process holds the potential to expedite model convergence by inducing more pronounced changes despite a limited number of local samples. Consequently, we show that by doing so, we can also achieve an overall higher inference accuracy. While the impact of lower temperature vary with respect to the neural network architecture and dataset, our evaluations reveal up to 6.00<math id="S6.p1.4.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.p1.4.m2.1a"><mo id="S6.p1.4.m2.1.1" xref="S6.p1.4.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.p1.4.m2.1b"><times id="S6.p1.4.m2.1.1.cmml" xref="S6.p1.4.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.4.m2.1c">\times</annotation></semantics></math> improvement in federated learning model convergence speed and 3.37% improvement in inference accuracy.
We see this work as a first step into devising a more fine-tuned (and optimal) training mechanism for federated learning systems.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas <span id="bib.bib1.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018a]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai MeherÂ Karthik Duddu, Peter Wu, Tian Li, Jakub KoneÄná»³, HÂ Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">GitHub - TalwalkarLab/leaf: Leaf: A Benchmark for Federated Settings â€” github.com.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/TalwalkarLab/leaf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/TalwalkarLab/leaf</a>, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas <span id="bib.bib2.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018b]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai MeherÂ Karthik Duddu, Peter Wu, Tian Li, Jakub KoneÄná»³, HÂ Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.01097</span>, 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen <span id="bib.bib3.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre VanÂ Schaik.

</span>
<span class="ltx_bibblock">Emnist: Extending mnist to handwritten letters.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.3.1" class="ltx_text ltx_font_italic">2017 international joint conference on neural networks (IJCNN)</span>, pages 2921â€“2926. IEEE, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Evci <span id="bib.bib4.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Utku Evci, Yani Ioannou, Cem Keskin, and Yann Dauphin.

</span>
<span class="ltx_bibblock">Gradient flow in sparse neural networks and how lottery tickets win.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.3.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</span>, volumeÂ 36, pages 6577â€“6586, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow <span id="bib.bib5.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2014]</span>
<span class="ltx_bibblock">
IanÂ J Goodfellow, Jonathon Shlens, and Christian Szegedy.

</span>
<span class="ltx_bibblock">Explaining and harnessing adversarial examples.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1412.6572</span>, 2014.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo <span id="bib.bib6.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Chuan Guo, Geoff Pleiss, YuÂ Sun, and KilianÂ Q Weinberger.

</span>
<span class="ltx_bibblock">On calibration of modern neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.3.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages 1321â€“1330. PMLR, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He <span id="bib.bib7.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2016]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.3.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</span>, pages 770â€“778, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton <span id="bib.bib8.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2015]</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1503.02531</span>, 2015.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang <span id="bib.bib9.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2016]</span>
<span class="ltx_bibblock">
Eric Jang, Shixiang Gu, and Ben Poole.

</span>
<span class="ltx_bibblock">Categorical reparameterization with gumbel-softmax.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1611.01144</span>, 2016.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy <span id="bib.bib10.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
SaiÂ Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and AnandaÂ Theertha Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.3.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages 5132â€“5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim <span id="bib.bib11.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Juyeop Kim, Junha Park, Songkuk Kim, and Jong-Seok Lee.

</span>
<span class="ltx_bibblock">Curved representation space of vision transformers.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.05742</span>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky <span id="bib.bib12.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2009]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, etÂ al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib13.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Tian Li, AnitÂ Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic">Proceedings of Machine learning and systems</span>, 2:429â€“450, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu <span id="bib.bib14.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Lumin Liu, Jun Zhang, SHÂ Song, and KhaledÂ B Letaief.

</span>
<span class="ltx_bibblock">Client-edge-cloud hierarchical federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.3.1" class="ltx_text ltx_font_italic">ICC 2020-2020 IEEE International Conference on Communications (ICC)</span>, pages 1â€“6. IEEE, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan <span id="bib.bib15.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ Aguera yÂ Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.3.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pages 1273â€“1282. PMLR, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park and Ko [2023]</span>
<span class="ltx_bibblock">
JaeYeon Park and JeongGil Ko.

</span>
<span class="ltx_bibblock">Fedhm: Practical federated learning for heterogeneous model deployments.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">ICT Express</span>, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park <span id="bib.bib17.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023a]</span>
<span class="ltx_bibblock">
JaeYeon Park, Kichang Lee, Sungmin Lee, MiÂ Zhang, and JeongGil Ko.

</span>
<span class="ltx_bibblock">Attfl: A personalized federated learning framework for time-series mobile and embedded sensor data processing.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</span>, 7(3):1â€“31, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park <span id="bib.bib18.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023b]</span>
<span class="ltx_bibblock">
JaeYeon Park, Kichang Lee, Noseong Park, SengÂ Chan You, and JeongGil Ko.

</span>
<span class="ltx_bibblock">Self-attention lstm-fcn model for arrhythmia classification and uncertainty assessment.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic">Artificial Intelligence in Medicine</span>, 142:102570, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pearce <span id="bib.bib19.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Tim Pearce, Alexandra Brintrup, and Jun Zhu.

</span>
<span class="ltx_bibblock">Understanding softmax confidence and uncertainty.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.04972</span>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruder [2016]</span>
<span class="ltx_bibblock">
Sebastian Ruder.

</span>
<span class="ltx_bibblock">An overview of gradient descent optimization algorithms.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1609.04747</span>, 2016.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shih <span id="bib.bib21.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023]</span>
<span class="ltx_bibblock">
Andy Shih, Dorsa Sadigh, and Stefano Ermon.

</span>
<span class="ltx_bibblock">Long horizon temperature scaling.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.03686</span>, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shin <span id="bib.bib22.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Jaemin Shin, Yuanchun Li, Yunxin Liu, and Sung-Ju Lee.

</span>
<span class="ltx_bibblock">Fedbalancer: data and pace control for efficient federated learning on heterogeneous clients.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.3.1" class="ltx_text ltx_font_italic">Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services</span>, pages 436â€“449, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron <span id="bib.bib23.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and HervÃ© JÃ©gou.

</span>
<span class="ltx_bibblock">Training data-efficient image transformers &amp; distillation through attention.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.3.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages 10347â€“10357. PMLR, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang <span id="bib.bib24.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Pei-Hsin Wang, Sheng-Iou Hsieh, Shih-Chieh Chang, Yu-Ting Chen, Jia-Yu Pan, Wei Wei, and Da-Chang Juan.

</span>
<span class="ltx_bibblock">Contextual temperature for language modeling.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.13575</span>, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu <span id="bib.bib25.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Fuxun Yu, Weishan Zhang, Zhuwei Qin, Zirui Xu, DiÂ Wang, Chenchen Liu, Zhi Tian, and Xiang Chen.

</span>
<span class="ltx_bibblock">Fed2: Feature-aligned federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.3.1" class="ltx_text ltx_font_italic">Proceedings of the 27th ACM SIGKDD conference on knowledge discovery &amp; data mining</span>, pages 2066â€“2074, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng <span id="bib.bib26.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Xiao Zeng, Ming Yan, and MiÂ Zhang.

</span>
<span class="ltx_bibblock">Mercury: Efficient on-device distributed dnn training via stochastic importance sampling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.3.1" class="ltx_text ltx_font_italic">Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems</span>, pages 29â€“41, 2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao <span id="bib.bib27.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1806.00582</span>, 2018.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2401.09985" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2401.09986" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2401.09986">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2401.09986" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2401.09987" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 09:05:01 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
