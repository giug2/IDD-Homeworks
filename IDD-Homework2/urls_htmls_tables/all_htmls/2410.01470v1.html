<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders</title>
<!--Generated on Wed Oct  2 12:15:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="neural news recommendation,  evaluation,  representational similarity,  news encoder,  user encoder,  retrieval similarity" lang="en" name="keywords"/>
<base href="/html/2410.01470v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S1" title="In Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S2" title="In Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S3" title="In Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S3.SS1" title="In 3. Methodology â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Encoders of Neural News Recommenders</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S3.SS2" title="In 3. Methodology â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Similarity Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S4" title="In Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5" title="In Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.SS1" title="In 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>News Encoder Architectures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.SS2" title="In 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>User Encoder Architectures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.SS3" title="In 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Key Takeaways</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S6" title="In Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">
Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andreea Iana
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">University of Mannheim</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Mannheim</span><span class="ltx_text ltx_affiliation_country" id="id3.3.id3">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:andreea.iana@uni-mannheim.de">andreea.iana@uni-mannheim.de</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Goran GlavaÅ¡
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">University of WÃ¼rzburg</span><span class="ltx_text ltx_affiliation_city" id="id5.2.id2">WÃ¼rzburg</span><span class="ltx_text ltx_affiliation_country" id="id6.3.id3">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:goran.glavas@uni-wuerzburg.de">goran.glavas@uni-wuerzburg.de</a>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Heiko Paulheim
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">University of Mannheim</span><span class="ltx_text ltx_affiliation_city" id="id8.2.id2">Mannheim</span><span class="ltx_text ltx_affiliation_country" id="id9.3.id3">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:heiko.paulheim@uni-mannheim.de">heiko.paulheim@uni-mannheim.de</a>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id10.id1">Encoder architectures play a pivotal role in neural news recommenders by embedding the semantic and contextual information of news and users. Thus, research has heavily focused on enhancing the representational capabilities of news and user encoders to improve recommender performance. Despite the significant impact of encoder architectures on the quality of news and user representations, existing analyses of encoder designs focus only on the overall downstream recommendation performance. This offers a one-sided assessment of the encodersâ€™ similarity, ignoring more nuanced differences in their behavior, and potentially resulting in sub-optimal model selection.
In this work, we perform a comprehensive analysis of encoder architectures in neural news recommender systems. We systematically evaluate the most prominent news and user encoder architectures, focusing on their (i) representational similarity, measured with the Central Kernel Alignment, (ii) overlap of generated recommendation lists, quantified with the Jaccard similarity, and (iii) the overall recommendation performance. Our analysis reveals that the complexity of certain encoding techniques is often empirically unjustified, highlighting the potential for simpler, more efficient architectures. By isolating the effects of individual components, we provide valuable insights for researchers and practitioners to make better informed decisions about encoder selection and avoid unnecessary complexity in the design of news recommenders.</p>
</div>
<div class="ltx_keywords">neural news recommendation, evaluation, representational similarity, news encoder, user encoder, retrieval similarity
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>INRA 2024: 12th International Workshop on News Recommendation; October 14â€“18, 2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id5"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Recommender systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Similarity measures</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Language models</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Content-based neural models have become the state of the art in news recommendation. Neural news recommenders (NNRs) typically comprise a news encoder and a user encoder. The news encoder learns semantically meaningful representations of news articles, whereas the user encoder embeds the preferences of users based on their click history <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib52" title="">2023</a>)</cite>. NNRs take the candidate news articles and a userâ€™s reading history as input. The relevance of the candidate to the user is determined by comparing, with a scoring function, the latent representations of the two inputs, generated with the corresponding encoders.
Given the key role of encoders in NNRs, a significant body of research has focused on improving the quality of news encoding and user modeling to improve recommendation performance <cite class="ltx_cite ltx_citemacro_citep">(Karimi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib18" title="">2018</a>; Raza and Ding, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib35" title="">2022</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib52" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">On the one hand, ablation studies of recommenders typically analyze individual model components in isolation, neglecting other architecturally comparable model designs <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib48" title="">d</a>; An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>)</cite>. At the same time, we see emerging evidence that widely used NNRs exhibit similar performance despite varying model complexities, and that the overall complexity of the recommendersâ€™ architecture could be reduced <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>; MÃ¶ller and PadÃ³, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib29" title="">2024</a>)</cite>. This highlights the need for a more granular comparison of the individual building blocks to understand their behavior and impact on the overall system. While <cite class="ltx_cite ltx_citemacro_citet">MÃ¶ller and PadÃ³ (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib28" title="">2022</a>)</cite> or <cite class="ltx_cite ltx_citemacro_citet">Iana etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite> evaluated NNR components such as scoring functions and training objectives, a systematic analysis of encoder architectures is still lacking. Such insights would enable researchers and practitioners alike to make more informed choices about encoder selection in NNR design.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">On the other hand, progress in the architectural design of news and user encoders is generally measured in terms of the recommenderâ€™s overall classification and ranking capability <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>; An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib32" title="">2022</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib55" title="">2021b</a>; Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite>. Nonetheless, the quality of the embeddings produced by the news and user encoders is equally crucial, given the reliance of the recommender on the dense retrieval paradigm.
Therefore, evaluating NNRs and their components solely in terms of downstream recommendation performance provides a simplified perspective, potentially overlooking subtle differences in the encodersâ€™ behavior. We thus argue that investigating the similarity of embeddings generated by various news and user encoders would offer a more nuanced understanding of their behavior, in turn benefiting the model selection process.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we perform a systematic analysis of the encoder architectures of NNRs. Unlike conventional evaluation studies, we isolate the effects of each core component to the largest possible extent.
Concretely, we analyze the most prominent news and user encoder architectures in terms of (i) the similarity of learned news, and respectively, user representations, using the Central Kernel Alignment <cite class="ltx_cite ltx_citemacro_citep">(Kornblith etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib23" title="">2019</a>)</cite> metric, (ii) the similarity of the generated recommendation lists, quantified by means of the Jaccard coefficient, and (iii) the impact on the overall recommendation performance.
Our findings provide a better understanding of news recommenders encoder architectures, not only from a recommendation performance perspective, but also in terms of their representational similarity. We demonstrate that the complexity of some encoding techniques is often empirically unjustified, emphasizing the potential benefits of simpler, more efficient architectures.
These results fundamentally challenge the common practice of over-engineering NNR encoders. Consequently, we derive three key takeaways, arguing that (1) the semantic richness of news encoders is crucial for effective recommendation, that (2) user encoders can be significantly simplified without sacrificing performance, and lastly, (3) we advocate for more rigorous evaluation to guide better informed model selection.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Neural news recommenders have significantly advanced in recent years, with encoder architectures playing a key role in capturing the semantic and contextual information of news articles and user profiles. Consequently, a large strand of work has focused on improving the representational capabilities of recommenders by developing ever more accurate, and often complex, news encoding and user modeling architectures. As such, these works have analyzed individual aspects of the NNR components, such as the use of different attention mechanisms in the news or user encoder <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib48" title="">d</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib33" title="">2020</a>)</cite>, the impact of various user modeling <cite class="ltx_cite ltx_citemacro_citep">(An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib32" title="">2022</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib43" title="">2022</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib33" title="">2020</a>; Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite> or news embedding <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib42" title="">2018</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib48" title="">d</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib33" title="">2020</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib55" title="">2021b</a>; Li etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib24" title="">2022</a>; Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib16" title="">2024</a>)</cite> techniques, or the importance of modeling different news features <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib42" title="">2018</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib46" title="">a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib53" title="">2020d</a>; Xun etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib63" title="">2021</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib31" title="">2021</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib56" title="">2021c</a>)</cite> and user characteristics <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib48" title="">2019d</a>; An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib47" title="">2019c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib59" title="">2022d</a>)</cite>. Ablation studies in these cases are usually conducted in isolation for the component under consideration, without taking into account the broader architectural context.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In contrast, another strand of work has started evaluating the impact of NNR components or training strategies across an array of recommendation approaches. For example, <cite class="ltx_cite ltx_citemacro_citet">Wu etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib55" title="">2021b</a>)</cite> have investigated the usage of various pretrained language models as the backbone of widely used NNRs. <cite class="ltx_cite ltx_citemacro_citet">MÃ¶ller and PadÃ³ (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib28" title="">2022</a>)</cite> have evaluated the impact of scoring functions, whereas <cite class="ltx_cite ltx_citemacro_citet">Iana etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite> have analyzed different user modeling techniques and training objectives. The latter have highlighted the similar recommendation performance achieved by certain models despite differences in architectures and complexity, emphasizing the potential to simplify the design of news recommender systems. While these works shed new light on core components of the recommendation model, their evaluation is most often solely based on the downstream recommendation performance.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">The similarity of encoders in NNRs can additionally be measured in terms of their generated representations. More generally, there exist numerous methods for quantifying the similarity of neural networks. Two main categories include (i) representational similarity, which assesses differences in the activations of intermediate layers of neural networks, and (ii) functional similarity, which compares the networksâ€™ outputs in relation to their task <cite class="ltx_cite ltx_citemacro_citep">(Klabunde etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib22" title="">2023b</a>)</cite>. Several works have focused on evaluating the representational similarity of (large) language models <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib62" title="">2020a</a>; Klabunde etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib21" title="">2023a</a>; Brown etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib4" title="">2023</a>; Freestone and Santu, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib7" title="">2024</a>)</cite> or of embedding models in Retrieval Augmented Generation systems <cite class="ltx_cite ltx_citemacro_citep">(Caspari etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib5" title="">2024</a>)</cite>, which are often employed as the news encoding component of NNRs.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Nevertheless, to the best of our knowledge, no work so far compares neither user encoders nor news encoders with respect to representational and functional similarity.
In this work, we fill this gap by comprehensively analyzing the primary components of NNR encoder architectures for both news and user inputs.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.2.1.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text" id="S2.T1.3.2" style="font-size:90%;">Abbreviations and their description.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.4" style="width:433.6pt;height:186.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-75.6pt,32.6pt) scale(0.74151101383543,0.74151101383543) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T1.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.4.1.1.1.1.1">Abbreviation</span></th>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T1.4.1.1.1.2.1">Description</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.4.1.2.2.1">CNN</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.4.1.2.2.2">convolutional neural network <cite class="ltx_cite ltx_citemacro_citep">(Kim, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib19" title="">2014</a>)</cite>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.3.3.1">Att</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.3.3.2">attention network</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.4.4.1">AddAtt</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.4.4.2">additive attention <cite class="ltx_cite ltx_citemacro_citep">(Bahdanau etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib3" title="">2014</a>)</cite>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.5.5.1">MHSA</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.5.5.2">multi-head self-attention <cite class="ltx_cite ltx_citemacro_citep">(Vaswani etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib41" title="">2017</a>)</cite>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.6.6.1">PLM</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.6.6.2">pre-trained language model</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.7.7.1">PLM<sub class="ltx_sub" id="S2.T1.4.1.7.7.1.1">[CLS]</sub>
</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.7.7.2">the PLMâ€™s output <span class="ltx_text ltx_font_typewriter" id="S2.T1.4.1.7.7.2.1">[CLS]</span> token representation</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.8.8.1">PLM<sub class="ltx_sub" id="S2.T1.4.1.8.8.1.1">tokenemb+Att</sub>
</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.8.8.2">PLMâ€™s token embeddings pooled with an attention network <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib55" title="">2021b</a>)</cite>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.9.9.1">SE</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.9.9.2">sentence encoder</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.10.10.1">
<span class="ltx_ERROR undefined" id="S2.T1.4.1.10.10.1.1">\hdashline</span>Con</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.10.10.2">concatenation</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.11.11.1">Linear</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.11.11.2">linear layer</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.12.12.1">
<span class="ltx_ERROR undefined" id="S2.T1.4.1.12.12.1.1">\hdashline</span>LF</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.12.12.2">late fusion <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.4.1.13.13.1">GRU</th>
<td class="ltx_td ltx_align_left" id="S2.T1.4.1.13.13.2">gated recurrent unit <cite class="ltx_cite ltx_citemacro_citep">(Cho etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib6" title="">2014</a>)</cite>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S2.T1.4.1.14.14.1">CandAware</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.4.1.14.14.2">candidate-aware user encoder <cite class="ltx_cite ltx_citemacro_citep">(Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib32" title="">2022</a>)</cite>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We firstly introduce the building blocks of personalized NNRs. Afterwards, we discuss metrics to evaluate both the recommendation performance, as well as the representational similarity of the news and user encoders.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Encoders of Neural News Recommenders</h3>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.2.1.1" style="font-size:90%;">Table 2</span>. </span><span class="ltx_text" id="S3.T2.3.2" style="font-size:90%;">Text encoder architectures.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.1">Text Embedding Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.2.1">Text Encoder</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.3.1">References</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.4.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.4.2.1.1" rowspan="3"><span class="ltx_text" id="S3.T2.4.2.1.1.1">word embeddings</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.4.2.1.2"><span class="ltx_text ltx_font_typewriter" id="S3.T2.4.2.1.2.1">CNN + AddAtt</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.4.2.1.3"><cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>; An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib46" title="">2019a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib47" title="">c</a>; Sheu and Li, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib37" title="">2020</a>; Santosh etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib36" title="">2020</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.3.2">
<td class="ltx_td ltx_align_left" id="S3.T2.4.3.2.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.4.3.2.1.1">MHSA + AddAtt</span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.4.3.2.2"><cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib8" title="">2018</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib48" title="">2019d</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib53" title="">2020d</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib54" title="">2020e</a>; Ge etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib9" title="">2020</a>; Tran etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib40" title="">2021</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib31" title="">2021</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib57" title="">2022b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib51" title="">2021a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib60" title="">2021d</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib32" title="">2022</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib43" title="">2022</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.3">
<td class="ltx_td ltx_align_left" id="S3.T2.4.4.3.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.4.4.3.1.1">CNN + MHSA + AddAtt</span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.4.4.3.2"><cite class="ltx_cite ltx_citemacro_citep">(Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib33" title="">2020</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.5.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.4.5.4.1" rowspan="3">
<span class="ltx_ERROR undefined" id="S3.T2.4.5.4.1.1">\hdashline</span><span class="ltx_text" id="S3.T2.4.5.4.1.2">language model</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T2.4.5.4.2"><span class="ltx_text ltx_font_typewriter" id="S3.T2.4.5.4.2.1">PLM<sub class="ltx_sub" id="S3.T2.4.5.4.2.1.1"><span class="ltx_text" id="S3.T2.4.5.4.2.1.1.1">tokenemb+Att</span></sub></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.4.5.4.3"><cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib50" title="">2020c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib55" title="">2021b</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib64" title="">2021a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib65" title="">b</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.6.5">
<td class="ltx_td ltx_align_left" id="S3.T2.4.6.5.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.4.6.5.1.1">PLM<sub class="ltx_sub" id="S3.T2.4.6.5.1.1.1"><span class="ltx_text ltx_font_serif" id="S3.T2.4.6.5.1.1.1.1">[CLS]</span></sub></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.4.6.5.2"><cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib17" title="">2021</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib58" title="">2022c</a>; Li etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib24" title="">2022</a>; Shivaram etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib38" title="">2022</a>; Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib15" title="">2023c</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.7.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.4.7.6.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.4.7.6.1.1">SE</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.4.7.6.2"><cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib16" title="">2024</a>)</cite></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.10">Content-based neural news recommenders consists of a dedicated <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.10.1">(i) news encoder (NE)</span> and a <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.10.2">(ii) user encoder (UE)</span> <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib52" title="">2023</a>)</cite>. The NE transforms different input features (e.g., title, abstract, categories, named entities, images) of a news article <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_n</annotation></semantics></math> into a latent news representation <math alttext="\mathbf{n}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">ğ§</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbf{n}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">bold_n</annotation></semantics></math>. The UE aggregates the embeddings of the clicked news <math alttext="\mathbf{n}^{u}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msubsup id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2.2" xref="S3.SS1.p1.3.m3.1.1.2.2.cmml">ğ§</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">i</mi><mi id="S3.SS1.p1.3.m3.1.1.2.3" xref="S3.SS1.p1.3.m3.1.1.2.3.cmml">u</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2.2">ğ§</ci><ci id="S3.SS1.p1.3.m3.1.1.2.3.cmml" xref="S3.SS1.p1.3.m3.1.1.2.3">ğ‘¢</ci></apply><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathbf{n}^{u}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">bold_n start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> from a userâ€™s <math alttext="u" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_u</annotation></semantics></math> history into a user-level representation <math alttext="\mathbf{u}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">ğ®</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">ğ®</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\mathbf{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">bold_u</annotation></semantics></math>.
Finally, the embedding of a candidate news <math alttext="\mathbf{n}^{c}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><msup id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">ğ§</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">ğ§</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\mathbf{n}^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">bold_n start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math>, outputted by the NE, is scored against the user representation <math alttext="\mathbf{u}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">ğ®</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">ğ®</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">\mathbf{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">bold_u</annotation></semantics></math> produced by the UE, to determine the relevance of the candidate to the user <math alttext="s(\mathbf{n}^{c},\mathbf{u})" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.2"><semantics id="S3.SS1.p1.8.m8.2a"><mrow id="S3.SS1.p1.8.m8.2.2" xref="S3.SS1.p1.8.m8.2.2.cmml"><mi id="S3.SS1.p1.8.m8.2.2.3" xref="S3.SS1.p1.8.m8.2.2.3.cmml">s</mi><mo id="S3.SS1.p1.8.m8.2.2.2" xref="S3.SS1.p1.8.m8.2.2.2.cmml">â¢</mo><mrow id="S3.SS1.p1.8.m8.2.2.1.1" xref="S3.SS1.p1.8.m8.2.2.1.2.cmml"><mo id="S3.SS1.p1.8.m8.2.2.1.1.2" stretchy="false" xref="S3.SS1.p1.8.m8.2.2.1.2.cmml">(</mo><msup id="S3.SS1.p1.8.m8.2.2.1.1.1" xref="S3.SS1.p1.8.m8.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.8.m8.2.2.1.1.1.2" xref="S3.SS1.p1.8.m8.2.2.1.1.1.2.cmml">ğ§</mi><mi id="S3.SS1.p1.8.m8.2.2.1.1.1.3" xref="S3.SS1.p1.8.m8.2.2.1.1.1.3.cmml">c</mi></msup><mo id="S3.SS1.p1.8.m8.2.2.1.1.3" xref="S3.SS1.p1.8.m8.2.2.1.2.cmml">,</mo><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">ğ®</mi><mo id="S3.SS1.p1.8.m8.2.2.1.1.4" stretchy="false" xref="S3.SS1.p1.8.m8.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.2b"><apply id="S3.SS1.p1.8.m8.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2"><times id="S3.SS1.p1.8.m8.2.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2.2"></times><ci id="S3.SS1.p1.8.m8.2.2.3.cmml" xref="S3.SS1.p1.8.m8.2.2.3">ğ‘ </ci><interval closure="open" id="S3.SS1.p1.8.m8.2.2.1.2.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1"><apply id="S3.SS1.p1.8.m8.2.2.1.1.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1">superscript</csymbol><ci id="S3.SS1.p1.8.m8.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1.2">ğ§</ci><ci id="S3.SS1.p1.8.m8.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1.3">ğ‘</ci></apply><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">ğ®</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.2c">s(\mathbf{n}^{c},\mathbf{u})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m8.2d">italic_s ( bold_n start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT , bold_u )</annotation></semantics></math>. The dot product of the two embeddings <math alttext="\mathbf{n}^{c}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1"><semantics id="S3.SS1.p1.9.m9.1a"><msup id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">ğ§</mi><mi id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">superscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">ğ§</ci><ci id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">\mathbf{n}^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m9.1d">bold_n start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\mathbf{u}" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">ğ®</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">ğ®</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">\mathbf{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m10.1d">bold_u</annotation></semantics></math> is the most common scoring function <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>)</cite>. NNRs are trained via conventional classification objectives <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib12" title="">2013</a>)</cite> with negative sampling <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib49" title="">2022a</a>)</cite>, or contrastive objectives <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib15" title="">2023c</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib26" title="">2023</a>)</cite>.
The building blocks of NNRs (i.e., NE, UE, scoring function, training objective) altogether drive the overall performance of the recommender.
Since the NE and UE determine what information of the documents and users is embedded by the model, and ultimately, propagated through the recommendation pipeline, both types of encoders play a similarly important role in model selection.
We introduce the abbreviations used for the remainder of the paper in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S2.T1" title="Table 1 â€£ 2. Related Work â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">News Encoder Architectures.</span>
The NE can generally be decomposed into a <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.2">text encoder</span>, which embeds the textual content of a news article, and several <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.3">feature-specific encoders</span> (e.g., category, sentiment, entity encoder), which learn to represent further input features different from text chunks. While the former represents a key component of all NNRs, the latter types of encoders are optional and only utilized whenever the textual content is enriched with additional features which might capture or emphasize other aspects of a news article. Lastly, the NE combines the intermediate embeddings produced by the text and feature-specific encoders into a news-level representation by means of a <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.4">multi-feature aggregation strategy</span>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We list the most used types of text encoders that we consider in our analysis in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S3.T2" title="Table 2 â€£ 3.1. Encoders of Neural News Recommenders â€£ 3. Methodology â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">2</span></a>, alongside examples of NNRs using them. We distinguish between text encoders that rely on pretrained word embeddings, contextualized by means of convolutional or self-attention networks, and the more recent architectures that employ pretrained language models.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Note that in this work we do not evaluate encoders which rely on news or user graphs, as such graphs are heavily dataset-dependent. We instead focus on the most used core components of encoders, and leave the analysis of graph-based techniques for future work.</span></span></span>
We additionally consider the most common multi-feature aggregation approaches used to integrate text and other content feature (e.g., category) embeddings into the unified news representation, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S3.T3" title="Table 3 â€£ 3.1. Encoders of Neural News Recommenders â€£ 3. Methodology â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T3.2.1.1" style="font-size:90%;">Table 3</span>. </span><span class="ltx_text" id="S3.T3.3.2" style="font-size:90%;">Multi-feature aggregation strategies for combining textual and categorical representations of news.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.1.1">Multi-feature aggregation</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T3.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.2.1">References</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.4.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.4.2.1.1"><span class="ltx_text ltx_font_typewriter" id="S3.T3.4.2.1.1.1">AddAtt</span></th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.4.2.1.2"><cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>; Santosh etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib36" title="">2020</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib51" title="">2021a</a>; Sun etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib39" title="">2021</a>; Raza and Ding, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib34" title="">2021</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib43" title="">2022</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.4.3.2.1"><span class="ltx_text ltx_font_typewriter" id="S3.T3.4.3.2.1.1">Linear</span></th>
<td class="ltx_td ltx_align_left" id="S3.T3.4.3.2.2"><cite class="ltx_cite ltx_citemacro_citep">(Tran etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib40" title="">2021</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib32" title="">2022</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T3.4.4.3.1"><span class="ltx_text ltx_font_typewriter" id="S3.T3.4.4.3.1.1">Con</span></th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.4.4.3.2"><cite class="ltx_cite ltx_citemacro_citep">(An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Ge etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib9" title="">2020</a>; Han etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib11" title="">2021</a>)</cite></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.4"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.4.1">User Encoder Architectures.</span>
Parameterized UEs represent the most popular user modeling technique. They learn user representations by means of sequential or attentive networks that contextualize the embeddings of clicked news based on patterns in the userâ€™s click behavior. UEs can be further differentiated into candidate-agnostic (i.e., users are encoded separately from candidate news) and candidate-aware (i.e., the user-level aggregation contextualizes the embeddings of clicked news against the embedding of each candidate) encoders <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite>.
More recently, <cite class="ltx_cite ltx_citemacro_citet">Iana etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite> proposed the parameter-free late fusion (<span class="ltx_text ltx_font_typewriter" id="S3.SS1.p4.4.2">LF</span>) approach. <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p4.4.3">LF</span> first averages the clicked news embeddings <math alttext="\mathbf{n}_{i}^{u}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><msubsup id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2.2" xref="S3.SS1.p4.1.m1.1.1.2.2.cmml">ğ§</mi><mi id="S3.SS1.p4.1.m1.1.1.2.3" xref="S3.SS1.p4.1.m1.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">u</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">superscript</csymbol><apply id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.2.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2.2">ğ§</ci><ci id="S3.SS1.p4.1.m1.1.1.2.3.cmml" xref="S3.SS1.p4.1.m1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\mathbf{n}_{i}^{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">bold_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT</annotation></semantics></math> to a user embedding <math alttext="\frac{1}{N}{\sum^{N}_{i=1}\mathbf{n}_{i}^{u}}=\mathbf{u}" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mrow id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml"><mfrac id="S3.SS1.p4.2.m2.1.1.2.2" xref="S3.SS1.p4.2.m2.1.1.2.2.cmml"><mn id="S3.SS1.p4.2.m2.1.1.2.2.2" xref="S3.SS1.p4.2.m2.1.1.2.2.2.cmml">1</mn><mi id="S3.SS1.p4.2.m2.1.1.2.2.3" xref="S3.SS1.p4.2.m2.1.1.2.2.3.cmml">N</mi></mfrac><mo id="S3.SS1.p4.2.m2.1.1.2.1" xref="S3.SS1.p4.2.m2.1.1.2.1.cmml">â¢</mo><mrow id="S3.SS1.p4.2.m2.1.1.2.3" xref="S3.SS1.p4.2.m2.1.1.2.3.cmml"><msubsup id="S3.SS1.p4.2.m2.1.1.2.3.1" xref="S3.SS1.p4.2.m2.1.1.2.3.1.cmml"><mo id="S3.SS1.p4.2.m2.1.1.2.3.1.2.2" xref="S3.SS1.p4.2.m2.1.1.2.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.SS1.p4.2.m2.1.1.2.3.1.3" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2.3.1.3.2" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3.2.cmml">i</mi><mo id="S3.SS1.p4.2.m2.1.1.2.3.1.3.1" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3.1.cmml">=</mo><mn id="S3.SS1.p4.2.m2.1.1.2.3.1.3.3" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.p4.2.m2.1.1.2.3.1.2.3" xref="S3.SS1.p4.2.m2.1.1.2.3.1.2.3.cmml">N</mi></msubsup><msubsup id="S3.SS1.p4.2.m2.1.1.2.3.2" xref="S3.SS1.p4.2.m2.1.1.2.3.2.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2.3.2.2.2" xref="S3.SS1.p4.2.m2.1.1.2.3.2.2.2.cmml">ğ§</mi><mi id="S3.SS1.p4.2.m2.1.1.2.3.2.2.3" xref="S3.SS1.p4.2.m2.1.1.2.3.2.2.3.cmml">i</mi><mi id="S3.SS1.p4.2.m2.1.1.2.3.2.3" xref="S3.SS1.p4.2.m2.1.1.2.3.2.3.cmml">u</mi></msubsup></mrow></mrow><mo id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.cmml">=</mo><mi id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml">ğ®</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><eq id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"></eq><apply id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2"><times id="S3.SS1.p4.2.m2.1.1.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.1"></times><apply id="S3.SS1.p4.2.m2.1.1.2.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.2"><divide id="S3.SS1.p4.2.m2.1.1.2.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.2"></divide><cn id="S3.SS1.p4.2.m2.1.1.2.2.2.cmml" type="integer" xref="S3.SS1.p4.2.m2.1.1.2.2.2">1</cn><ci id="S3.SS1.p4.2.m2.1.1.2.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.2.3">ğ‘</ci></apply><apply id="S3.SS1.p4.2.m2.1.1.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3"><apply id="S3.SS1.p4.2.m2.1.1.2.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.2.3.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1">subscript</csymbol><apply id="S3.SS1.p4.2.m2.1.1.2.3.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.2.3.1.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1">superscript</csymbol><sum id="S3.SS1.p4.2.m2.1.1.2.3.1.2.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1.2.2"></sum><ci id="S3.SS1.p4.2.m2.1.1.2.3.1.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1.2.3">ğ‘</ci></apply><apply id="S3.SS1.p4.2.m2.1.1.2.3.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3"><eq id="S3.SS1.p4.2.m2.1.1.2.3.1.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3.1"></eq><ci id="S3.SS1.p4.2.m2.1.1.2.3.1.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3.2">ğ‘–</ci><cn id="S3.SS1.p4.2.m2.1.1.2.3.1.3.3.cmml" type="integer" xref="S3.SS1.p4.2.m2.1.1.2.3.1.3.3">1</cn></apply></apply><apply id="S3.SS1.p4.2.m2.1.1.2.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.2.3.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2">superscript</csymbol><apply id="S3.SS1.p4.2.m2.1.1.2.3.2.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.2.3.2.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.3.2.2.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2.2.2">ğ§</ci><ci id="S3.SS1.p4.2.m2.1.1.2.3.2.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p4.2.m2.1.1.2.3.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2.3">ğ‘¢</ci></apply></apply></apply><ci id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3">ğ®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\frac{1}{N}{\sum^{N}_{i=1}\mathbf{n}_{i}^{u}}=\mathbf{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">divide start_ARG 1 end_ARG start_ARG italic_N end_ARG âˆ‘ start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT bold_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT = bold_u</annotation></semantics></math>. The inner product of the embedding of the candidate news <math alttext="\mathbf{n}^{c}" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><msup id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml">ğ§</mi><mi id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2">ğ§</ci><ci id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">\mathbf{n}^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">bold_n start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math> and the user embedding <math alttext="\mathbf{u}" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m4.1"><semantics id="S3.SS1.p4.4.m4.1a"><mi id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">ğ®</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><ci id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">ğ®</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\mathbf{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m4.1d">bold_u</annotation></semantics></math> then represents the relevancy score. Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S3.T4" title="Table 4 â€£ 3.1. Encoders of Neural News Recommenders â€£ 3. Methodology â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">4</span></a> lists the main user encoder architectures that we evaluate in this work, together with examples of models using them.</p>
</div>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T4.2.1.1" style="font-size:90%;">Table 4</span>. </span><span class="ltx_text" id="S3.T4.3.2" style="font-size:90%;">User encoder architectures.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T4.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T4.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T4.4.1.1.1.1">User Encoder</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T4.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T4.4.1.1.2.1">References</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T4.4.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T4.4.2.1.1"><span class="ltx_text ltx_font_typewriter" id="S3.T4.4.2.1.1.1">LF</span></th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T4.4.2.1.2"><cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib15" title="">2023c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib16" title="">2024</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.4.3.2.1"><span class="ltx_text ltx_font_typewriter" id="S3.T4.4.3.2.1.1">AddAtt</span></th>
<td class="ltx_td ltx_align_left" id="S3.T4.4.3.2.2"><cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib8" title="">2018</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib47" title="">c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib46" title="">a</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib25" title="">2020</a>; Santosh etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib36" title="">2020</a>; Han etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib11" title="">2021</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib66" title="">2021c</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.4.4.3.1"><span class="ltx_text ltx_font_typewriter" id="S3.T4.4.4.3.1.1">MHSA+AddAtt</span></th>
<td class="ltx_td ltx_align_left" id="S3.T4.4.4.3.2"><cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib48" title="">2019d</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib53" title="">2020d</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib50" title="">2020c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib57" title="">2022b</a>; Xun etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib63" title="">2021</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib60" title="">2021d</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.4.5.4.1">
<span class="ltx_ERROR undefined" id="S3.T4.4.5.4.1.1">\hdashline</span><span class="ltx_text ltx_font_typewriter" id="S3.T4.4.5.4.1.2">GRU<sub class="ltx_sub" id="S3.T4.4.5.4.1.2.1"><span class="ltx_text" id="S3.T4.4.5.4.1.2.1.1">ini</span></sub></span>
</th>
<td class="ltx_td ltx_align_left" id="S3.T4.4.5.4.2"><cite class="ltx_cite ltx_citemacro_citep">(An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Sun etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib39" title="">2021</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.4.6.5.1"><span class="ltx_text ltx_font_typewriter" id="S3.T4.4.6.5.1.1">GRU<sub class="ltx_sub" id="S3.T4.4.6.5.1.1.1"><span class="ltx_text" id="S3.T4.4.6.5.1.1.1.1">con</span></sub></span></th>
<td class="ltx_td ltx_align_left" id="S3.T4.4.6.5.2"><cite class="ltx_cite ltx_citemacro_citep">(An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Tran etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib40" title="">2021</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.4.7.6.1"><span class="ltx_text ltx_font_typewriter" id="S3.T4.4.7.6.1.1">GRU+MHSA+AddAtt</span></th>
<td class="ltx_td ltx_align_left" id="S3.T4.4.7.6.2"><cite class="ltx_cite ltx_citemacro_citep">(Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib33" title="">2020</a>)</cite></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T4.4.8.7.1">
<span class="ltx_ERROR undefined" id="S3.T4.4.8.7.1.1">\hdashline</span><span class="ltx_text ltx_font_typewriter" id="S3.T4.4.8.7.1.2">CandAware</span> (<span class="ltx_text ltx_font_typewriter" id="S3.T4.4.8.7.1.3">CNN+MHSA+AddAtt</span>)</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.4.8.7.2"><cite class="ltx_cite ltx_citemacro_citep">(Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib32" title="">2022</a>)</cite></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Similarity Evaluation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We evaluate NEs and UEs on three dimensions: (i) downstream recommendation performance, (ii) similarity of generated recommendations, and (iii) similarity of learned news or user representations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Downstream Recommendation Performance.</span>
NNRs are usually evaluated with regards to classification (e.g., AUC) and ranking (e.g., MRR, nDCG) performance. In this work, we focus on the ranking performance, which we quantify using nDCG<math alttext="@k" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" mathvariant="normal" xref="S3.SS2.p2.1.m1.1.1.2.cmml">@</mi><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><times id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></times><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">@</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">@k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">@ italic_k</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.5"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.5.1">Similarity of Generated Recommendations.</span>
We analyze the retrieval similarity of recommenders that use different news or user encoder architectures by the similarity of their top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_k</annotation></semantics></math> recommended articles. Specifically, for the same set of users, we firstly generate the corresponding recommendation lists <math alttext="R" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_R</annotation></semantics></math> and <math alttext="R^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msup id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">R</mi><mo id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">ğ‘…</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">R^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math> with models <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_M</annotation></semantics></math> and <math alttext="M^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><msup id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">ğ‘€</ci><ci id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">M^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_M start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>, respectively. We then measure the similarity of retrieved results with the Jaccard similarity coefficient:</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Jaccard(R,R^{\prime})=\frac{|R\bigcap R^{\prime}|}{|R\bigcup R^{\prime}|}" class="ltx_Math" display="block" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.cmml"><mi id="S3.E1.m1.4.4.1.3" xref="S3.E1.m1.4.4.1.3.cmml">J</mi><mo id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.2.cmml">â¢</mo><mi id="S3.E1.m1.4.4.1.4" xref="S3.E1.m1.4.4.1.4.cmml">a</mi><mo id="S3.E1.m1.4.4.1.2a" xref="S3.E1.m1.4.4.1.2.cmml">â¢</mo><mi id="S3.E1.m1.4.4.1.5" xref="S3.E1.m1.4.4.1.5.cmml">c</mi><mo id="S3.E1.m1.4.4.1.2b" xref="S3.E1.m1.4.4.1.2.cmml">â¢</mo><mi id="S3.E1.m1.4.4.1.6" xref="S3.E1.m1.4.4.1.6.cmml">c</mi><mo id="S3.E1.m1.4.4.1.2c" xref="S3.E1.m1.4.4.1.2.cmml">â¢</mo><mi id="S3.E1.m1.4.4.1.7" xref="S3.E1.m1.4.4.1.7.cmml">a</mi><mo id="S3.E1.m1.4.4.1.2d" xref="S3.E1.m1.4.4.1.2.cmml">â¢</mo><mi id="S3.E1.m1.4.4.1.8" xref="S3.E1.m1.4.4.1.8.cmml">r</mi><mo id="S3.E1.m1.4.4.1.2e" xref="S3.E1.m1.4.4.1.2.cmml">â¢</mo><mi id="S3.E1.m1.4.4.1.9" xref="S3.E1.m1.4.4.1.9.cmml">d</mi><mo id="S3.E1.m1.4.4.1.2f" xref="S3.E1.m1.4.4.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.4.4.1.1.1" xref="S3.E1.m1.4.4.1.1.2.cmml"><mo id="S3.E1.m1.4.4.1.1.1.2" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">R</mi><mo id="S3.E1.m1.4.4.1.1.1.3" xref="S3.E1.m1.4.4.1.1.2.cmml">,</mo><msup id="S3.E1.m1.4.4.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.2.cmml">R</mi><mo id="S3.E1.m1.4.4.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.3.cmml">â€²</mo></msup><mo id="S3.E1.m1.4.4.1.1.1.4" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.2" xref="S3.E1.m1.4.4.2.cmml">=</mo><mfrac id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.2.cmml"><mo id="S3.E1.m1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">R</mi><mo id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml"><mo id="S3.E1.m1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.3.1.cmml">â‹‚</mo><msup id="S3.E1.m1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.3.2.2.cmml">R</mi><mo id="S3.E1.m1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.1.3.2.3.cmml">â€²</mo></msup></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="S3.E1.m1.2.2.2.1" xref="S3.E1.m1.2.2.2.2.cmml"><mo id="S3.E1.m1.2.2.2.1.2" stretchy="false" xref="S3.E1.m1.2.2.2.2.1.cmml">|</mo><mrow id="S3.E1.m1.2.2.2.1.1" xref="S3.E1.m1.2.2.2.1.1.cmml"><mi id="S3.E1.m1.2.2.2.1.1.2" xref="S3.E1.m1.2.2.2.1.1.2.cmml">R</mi><mo id="S3.E1.m1.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.cmml">â¢</mo><mrow id="S3.E1.m1.2.2.2.1.1.3" xref="S3.E1.m1.2.2.2.1.1.3.cmml"><mo id="S3.E1.m1.2.2.2.1.1.3.1" xref="S3.E1.m1.2.2.2.1.1.3.1.cmml">â‹ƒ</mo><msup id="S3.E1.m1.2.2.2.1.1.3.2" xref="S3.E1.m1.2.2.2.1.1.3.2.cmml"><mi id="S3.E1.m1.2.2.2.1.1.3.2.2" xref="S3.E1.m1.2.2.2.1.1.3.2.2.cmml">R</mi><mo id="S3.E1.m1.2.2.2.1.1.3.2.3" xref="S3.E1.m1.2.2.2.1.1.3.2.3.cmml">â€²</mo></msup></mrow></mrow><mo id="S3.E1.m1.2.2.2.1.3" stretchy="false" xref="S3.E1.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><eq id="S3.E1.m1.4.4.2.cmml" xref="S3.E1.m1.4.4.2"></eq><apply id="S3.E1.m1.4.4.1.cmml" xref="S3.E1.m1.4.4.1"><times id="S3.E1.m1.4.4.1.2.cmml" xref="S3.E1.m1.4.4.1.2"></times><ci id="S3.E1.m1.4.4.1.3.cmml" xref="S3.E1.m1.4.4.1.3">ğ½</ci><ci id="S3.E1.m1.4.4.1.4.cmml" xref="S3.E1.m1.4.4.1.4">ğ‘</ci><ci id="S3.E1.m1.4.4.1.5.cmml" xref="S3.E1.m1.4.4.1.5">ğ‘</ci><ci id="S3.E1.m1.4.4.1.6.cmml" xref="S3.E1.m1.4.4.1.6">ğ‘</ci><ci id="S3.E1.m1.4.4.1.7.cmml" xref="S3.E1.m1.4.4.1.7">ğ‘</ci><ci id="S3.E1.m1.4.4.1.8.cmml" xref="S3.E1.m1.4.4.1.8">ğ‘Ÿ</ci><ci id="S3.E1.m1.4.4.1.9.cmml" xref="S3.E1.m1.4.4.1.9">ğ‘‘</ci><interval closure="open" id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1"><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">ğ‘…</ci><apply id="S3.E1.m1.4.4.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.2">ğ‘…</ci><ci id="S3.E1.m1.4.4.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.3">â€²</ci></apply></interval></apply><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><divide id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2"></divide><apply id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1"><abs id="S3.E1.m1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2"></abs><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"></times><ci id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2">ğ‘…</ci><apply id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3"><intersect id="S3.E1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3.1"></intersect><apply id="S3.E1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2.2">ğ‘…</ci><ci id="S3.E1.m1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2.3">â€²</ci></apply></apply></apply></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.1"><abs id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.1.2"></abs><apply id="S3.E1.m1.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1"><times id="S3.E1.m1.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1"></times><ci id="S3.E1.m1.2.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.2">ğ‘…</ci><apply id="S3.E1.m1.2.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.3"><union id="S3.E1.m1.2.2.2.1.1.3.1.cmml" xref="S3.E1.m1.2.2.2.1.1.3.1"></union><apply id="S3.E1.m1.2.2.2.1.1.3.2.cmml" xref="S3.E1.m1.2.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.3.2.1.cmml" xref="S3.E1.m1.2.2.2.1.1.3.2">superscript</csymbol><ci id="S3.E1.m1.2.2.2.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.2.1.1.3.2.2">ğ‘…</ci><ci id="S3.E1.m1.2.2.2.1.1.3.2.3.cmml" xref="S3.E1.m1.2.2.2.1.1.3.2.3">â€²</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">Jaccard(R,R^{\prime})=\frac{|R\bigcap R^{\prime}|}{|R\bigcup R^{\prime}|}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">italic_J italic_a italic_c italic_c italic_a italic_r italic_d ( italic_R , italic_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) = divide start_ARG | italic_R â‹‚ italic_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT | end_ARG start_ARG | italic_R â‹ƒ italic_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.8">where <math alttext="|R\bigcap R^{\prime}|" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mrow id="S3.SS2.p5.1.m1.1.1.1" xref="S3.SS2.p5.1.m1.1.1.2.cmml"><mo id="S3.SS2.p5.1.m1.1.1.1.2" stretchy="false" xref="S3.SS2.p5.1.m1.1.1.2.1.cmml">|</mo><mrow id="S3.SS2.p5.1.m1.1.1.1.1" xref="S3.SS2.p5.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p5.1.m1.1.1.1.1.2" xref="S3.SS2.p5.1.m1.1.1.1.1.2.cmml">R</mi><mo id="S3.SS2.p5.1.m1.1.1.1.1.1" xref="S3.SS2.p5.1.m1.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.SS2.p5.1.m1.1.1.1.1.3" xref="S3.SS2.p5.1.m1.1.1.1.1.3.cmml"><mo id="S3.SS2.p5.1.m1.1.1.1.1.3.1" xref="S3.SS2.p5.1.m1.1.1.1.1.3.1.cmml">â‹‚</mo><msup id="S3.SS2.p5.1.m1.1.1.1.1.3.2" xref="S3.SS2.p5.1.m1.1.1.1.1.3.2.cmml"><mi id="S3.SS2.p5.1.m1.1.1.1.1.3.2.2" xref="S3.SS2.p5.1.m1.1.1.1.1.3.2.2.cmml">R</mi><mo id="S3.SS2.p5.1.m1.1.1.1.1.3.2.3" xref="S3.SS2.p5.1.m1.1.1.1.1.3.2.3.cmml">â€²</mo></msup></mrow></mrow><mo id="S3.SS2.p5.1.m1.1.1.1.3" stretchy="false" xref="S3.SS2.p5.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.1"><abs id="S3.SS2.p5.1.m1.1.1.2.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1.2"></abs><apply id="S3.SS2.p5.1.m1.1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1"><times id="S3.SS2.p5.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.1"></times><ci id="S3.SS2.p5.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.2">ğ‘…</ci><apply id="S3.SS2.p5.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.3"><intersect id="S3.SS2.p5.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.3.1"></intersect><apply id="S3.SS2.p5.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p5.1.m1.1.1.1.1.3.2.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.3.2">superscript</csymbol><ci id="S3.SS2.p5.1.m1.1.1.1.1.3.2.2.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.3.2.2">ğ‘…</ci><ci id="S3.SS2.p5.1.m1.1.1.1.1.3.2.3.cmml" xref="S3.SS2.p5.1.m1.1.1.1.1.3.2.3">â€²</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">|R\bigcap R^{\prime}|</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">| italic_R â‹‚ italic_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT |</annotation></semantics></math> denotes the set of articles recommended by both models, and <math alttext="|R\bigcup R^{\prime}|" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><mrow id="S3.SS2.p5.2.m2.1.1.1" xref="S3.SS2.p5.2.m2.1.1.2.cmml"><mo id="S3.SS2.p5.2.m2.1.1.1.2" stretchy="false" xref="S3.SS2.p5.2.m2.1.1.2.1.cmml">|</mo><mrow id="S3.SS2.p5.2.m2.1.1.1.1" xref="S3.SS2.p5.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.1.1.2" xref="S3.SS2.p5.2.m2.1.1.1.1.2.cmml">R</mi><mo id="S3.SS2.p5.2.m2.1.1.1.1.1" xref="S3.SS2.p5.2.m2.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.SS2.p5.2.m2.1.1.1.1.3" xref="S3.SS2.p5.2.m2.1.1.1.1.3.cmml"><mo id="S3.SS2.p5.2.m2.1.1.1.1.3.1" xref="S3.SS2.p5.2.m2.1.1.1.1.3.1.cmml">â‹ƒ</mo><msup id="S3.SS2.p5.2.m2.1.1.1.1.3.2" xref="S3.SS2.p5.2.m2.1.1.1.1.3.2.cmml"><mi id="S3.SS2.p5.2.m2.1.1.1.1.3.2.2" xref="S3.SS2.p5.2.m2.1.1.1.1.3.2.2.cmml">R</mi><mo id="S3.SS2.p5.2.m2.1.1.1.1.3.2.3" xref="S3.SS2.p5.2.m2.1.1.1.1.3.2.3.cmml">â€²</mo></msup></mrow></mrow><mo id="S3.SS2.p5.2.m2.1.1.1.3" stretchy="false" xref="S3.SS2.p5.2.m2.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.1"><abs id="S3.SS2.p5.2.m2.1.1.2.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.2"></abs><apply id="S3.SS2.p5.2.m2.1.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1"><times id="S3.SS2.p5.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.1"></times><ci id="S3.SS2.p5.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.2">ğ‘…</ci><apply id="S3.SS2.p5.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.3"><union id="S3.SS2.p5.2.m2.1.1.1.1.3.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.3.1"></union><apply id="S3.SS2.p5.2.m2.1.1.1.1.3.2.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.1.1.1.1.3.2.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.3.2">superscript</csymbol><ci id="S3.SS2.p5.2.m2.1.1.1.1.3.2.2.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.3.2.2">ğ‘…</ci><ci id="S3.SS2.p5.2.m2.1.1.1.1.3.2.3.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.3.2.3">â€²</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">|R\bigcup R^{\prime}|</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">| italic_R â‹ƒ italic_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT |</annotation></semantics></math> the union of all unique news recommended by the two models. The Jaccard similarity score is bounded in the <math alttext="[0,1]" class="ltx_Math" display="inline" id="S3.SS2.p5.3.m3.2"><semantics id="S3.SS2.p5.3.m3.2a"><mrow id="S3.SS2.p5.3.m3.2.3.2" xref="S3.SS2.p5.3.m3.2.3.1.cmml"><mo id="S3.SS2.p5.3.m3.2.3.2.1" stretchy="false" xref="S3.SS2.p5.3.m3.2.3.1.cmml">[</mo><mn id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml">0</mn><mo id="S3.SS2.p5.3.m3.2.3.2.2" xref="S3.SS2.p5.3.m3.2.3.1.cmml">,</mo><mn id="S3.SS2.p5.3.m3.2.2" xref="S3.SS2.p5.3.m3.2.2.cmml">1</mn><mo id="S3.SS2.p5.3.m3.2.3.2.3" stretchy="false" xref="S3.SS2.p5.3.m3.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.2b"><interval closure="closed" id="S3.SS2.p5.3.m3.2.3.1.cmml" xref="S3.SS2.p5.3.m3.2.3.2"><cn id="S3.SS2.p5.3.m3.1.1.cmml" type="integer" xref="S3.SS2.p5.3.m3.1.1">0</cn><cn id="S3.SS2.p5.3.m3.2.2.cmml" type="integer" xref="S3.SS2.p5.3.m3.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.2c">[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.3.m3.2d">[ 0 , 1 ]</annotation></semantics></math> interval, with 1 indicating that both models recommend an identical set of news. Note that the lengths of both recommendation lists will be equal to the full set of candidate news <math alttext="N^{c}_{u}" class="ltx_Math" display="inline" id="S3.SS2.p5.4.m4.1"><semantics id="S3.SS2.p5.4.m4.1a"><msubsup id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml"><mi id="S3.SS2.p5.4.m4.1.1.2.2" xref="S3.SS2.p5.4.m4.1.1.2.2.cmml">N</mi><mi id="S3.SS2.p5.4.m4.1.1.3" xref="S3.SS2.p5.4.m4.1.1.3.cmml">u</mi><mi id="S3.SS2.p5.4.m4.1.1.2.3" xref="S3.SS2.p5.4.m4.1.1.2.3.cmml">c</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><apply id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.1.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1">subscript</csymbol><apply id="S3.SS2.p5.4.m4.1.1.2.cmml" xref="S3.SS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.1.1.2.1.cmml" xref="S3.SS2.p5.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p5.4.m4.1.1.2.2.cmml" xref="S3.SS2.p5.4.m4.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p5.4.m4.1.1.2.3.cmml" xref="S3.SS2.p5.4.m4.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS2.p5.4.m4.1.1.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">N^{c}_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.4.m4.1d">italic_N start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> for a given user <math alttext="u" class="ltx_Math" display="inline" id="S3.SS2.p5.5.m5.1"><semantics id="S3.SS2.p5.5.m5.1a"><mi id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><ci id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.5.m5.1d">italic_u</annotation></semantics></math>, namely <math alttext="|R|=|R^{\prime}|=|N^{c}_{u}|" class="ltx_Math" display="inline" id="S3.SS2.p5.6.m6.3"><semantics id="S3.SS2.p5.6.m6.3a"><mrow id="S3.SS2.p5.6.m6.3.3" xref="S3.SS2.p5.6.m6.3.3.cmml"><mrow id="S3.SS2.p5.6.m6.3.3.4.2" xref="S3.SS2.p5.6.m6.3.3.4.1.cmml"><mo id="S3.SS2.p5.6.m6.3.3.4.2.1" stretchy="false" xref="S3.SS2.p5.6.m6.3.3.4.1.1.cmml">|</mo><mi id="S3.SS2.p5.6.m6.1.1" xref="S3.SS2.p5.6.m6.1.1.cmml">R</mi><mo id="S3.SS2.p5.6.m6.3.3.4.2.2" stretchy="false" xref="S3.SS2.p5.6.m6.3.3.4.1.1.cmml">|</mo></mrow><mo id="S3.SS2.p5.6.m6.3.3.5" xref="S3.SS2.p5.6.m6.3.3.5.cmml">=</mo><mrow id="S3.SS2.p5.6.m6.2.2.1.1" xref="S3.SS2.p5.6.m6.2.2.1.2.cmml"><mo id="S3.SS2.p5.6.m6.2.2.1.1.2" stretchy="false" xref="S3.SS2.p5.6.m6.2.2.1.2.1.cmml">|</mo><msup id="S3.SS2.p5.6.m6.2.2.1.1.1" xref="S3.SS2.p5.6.m6.2.2.1.1.1.cmml"><mi id="S3.SS2.p5.6.m6.2.2.1.1.1.2" xref="S3.SS2.p5.6.m6.2.2.1.1.1.2.cmml">R</mi><mo id="S3.SS2.p5.6.m6.2.2.1.1.1.3" xref="S3.SS2.p5.6.m6.2.2.1.1.1.3.cmml">â€²</mo></msup><mo id="S3.SS2.p5.6.m6.2.2.1.1.3" stretchy="false" xref="S3.SS2.p5.6.m6.2.2.1.2.1.cmml">|</mo></mrow><mo id="S3.SS2.p5.6.m6.3.3.6" xref="S3.SS2.p5.6.m6.3.3.6.cmml">=</mo><mrow id="S3.SS2.p5.6.m6.3.3.2.1" xref="S3.SS2.p5.6.m6.3.3.2.2.cmml"><mo id="S3.SS2.p5.6.m6.3.3.2.1.2" stretchy="false" xref="S3.SS2.p5.6.m6.3.3.2.2.1.cmml">|</mo><msubsup id="S3.SS2.p5.6.m6.3.3.2.1.1" xref="S3.SS2.p5.6.m6.3.3.2.1.1.cmml"><mi id="S3.SS2.p5.6.m6.3.3.2.1.1.2.2" xref="S3.SS2.p5.6.m6.3.3.2.1.1.2.2.cmml">N</mi><mi id="S3.SS2.p5.6.m6.3.3.2.1.1.3" xref="S3.SS2.p5.6.m6.3.3.2.1.1.3.cmml">u</mi><mi id="S3.SS2.p5.6.m6.3.3.2.1.1.2.3" xref="S3.SS2.p5.6.m6.3.3.2.1.1.2.3.cmml">c</mi></msubsup><mo id="S3.SS2.p5.6.m6.3.3.2.1.3" stretchy="false" xref="S3.SS2.p5.6.m6.3.3.2.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.6.m6.3b"><apply id="S3.SS2.p5.6.m6.3.3.cmml" xref="S3.SS2.p5.6.m6.3.3"><and id="S3.SS2.p5.6.m6.3.3a.cmml" xref="S3.SS2.p5.6.m6.3.3"></and><apply id="S3.SS2.p5.6.m6.3.3b.cmml" xref="S3.SS2.p5.6.m6.3.3"><eq id="S3.SS2.p5.6.m6.3.3.5.cmml" xref="S3.SS2.p5.6.m6.3.3.5"></eq><apply id="S3.SS2.p5.6.m6.3.3.4.1.cmml" xref="S3.SS2.p5.6.m6.3.3.4.2"><abs id="S3.SS2.p5.6.m6.3.3.4.1.1.cmml" xref="S3.SS2.p5.6.m6.3.3.4.2.1"></abs><ci id="S3.SS2.p5.6.m6.1.1.cmml" xref="S3.SS2.p5.6.m6.1.1">ğ‘…</ci></apply><apply id="S3.SS2.p5.6.m6.2.2.1.2.cmml" xref="S3.SS2.p5.6.m6.2.2.1.1"><abs id="S3.SS2.p5.6.m6.2.2.1.2.1.cmml" xref="S3.SS2.p5.6.m6.2.2.1.1.2"></abs><apply id="S3.SS2.p5.6.m6.2.2.1.1.1.cmml" xref="S3.SS2.p5.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.6.m6.2.2.1.1.1.1.cmml" xref="S3.SS2.p5.6.m6.2.2.1.1.1">superscript</csymbol><ci id="S3.SS2.p5.6.m6.2.2.1.1.1.2.cmml" xref="S3.SS2.p5.6.m6.2.2.1.1.1.2">ğ‘…</ci><ci id="S3.SS2.p5.6.m6.2.2.1.1.1.3.cmml" xref="S3.SS2.p5.6.m6.2.2.1.1.1.3">â€²</ci></apply></apply></apply><apply id="S3.SS2.p5.6.m6.3.3c.cmml" xref="S3.SS2.p5.6.m6.3.3"><eq id="S3.SS2.p5.6.m6.3.3.6.cmml" xref="S3.SS2.p5.6.m6.3.3.6"></eq><share href="https://arxiv.org/html/2410.01470v1#S3.SS2.p5.6.m6.2.2.1.cmml" id="S3.SS2.p5.6.m6.3.3d.cmml" xref="S3.SS2.p5.6.m6.3.3"></share><apply id="S3.SS2.p5.6.m6.3.3.2.2.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1"><abs id="S3.SS2.p5.6.m6.3.3.2.2.1.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.2"></abs><apply id="S3.SS2.p5.6.m6.3.3.2.1.1.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.6.m6.3.3.2.1.1.1.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.1">subscript</csymbol><apply id="S3.SS2.p5.6.m6.3.3.2.1.1.2.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.6.m6.3.3.2.1.1.2.1.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.1">superscript</csymbol><ci id="S3.SS2.p5.6.m6.3.3.2.1.1.2.2.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p5.6.m6.3.3.2.1.1.2.3.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS2.p5.6.m6.3.3.2.1.1.3.cmml" xref="S3.SS2.p5.6.m6.3.3.2.1.1.3">ğ‘¢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.6.m6.3c">|R|=|R^{\prime}|=|N^{c}_{u}|</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.6.m6.3d">| italic_R | = | italic_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT | = | italic_N start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT |</annotation></semantics></math>, regardless of the recommendation model used. Thus, to differentiate the retrieval performance of two models, we compute the Jaccard similarity only for the top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p5.7.m7.1"><semantics id="S3.SS2.p5.7.m7.1a"><mi id="S3.SS2.p5.7.m7.1.1" xref="S3.SS2.p5.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.7.m7.1b"><ci id="S3.SS2.p5.7.m7.1.1.cmml" xref="S3.SS2.p5.7.m7.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.7.m7.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.7.m7.1d">italic_k</annotation></semantics></math> recommendations, ordered descendingly by the recommendation scores. Note that in comparison to nDCG<math alttext="@k" class="ltx_Math" display="inline" id="S3.SS2.p5.8.m8.1"><semantics id="S3.SS2.p5.8.m8.1a"><mrow id="S3.SS2.p5.8.m8.1.1" xref="S3.SS2.p5.8.m8.1.1.cmml"><mi id="S3.SS2.p5.8.m8.1.1.2" mathvariant="normal" xref="S3.SS2.p5.8.m8.1.1.2.cmml">@</mi><mo id="S3.SS2.p5.8.m8.1.1.1" xref="S3.SS2.p5.8.m8.1.1.1.cmml">â¢</mo><mi id="S3.SS2.p5.8.m8.1.1.3" xref="S3.SS2.p5.8.m8.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.8.m8.1b"><apply id="S3.SS2.p5.8.m8.1.1.cmml" xref="S3.SS2.p5.8.m8.1.1"><times id="S3.SS2.p5.8.m8.1.1.1.cmml" xref="S3.SS2.p5.8.m8.1.1.1"></times><ci id="S3.SS2.p5.8.m8.1.1.2.cmml" xref="S3.SS2.p5.8.m8.1.1.2">@</ci><ci id="S3.SS2.p5.8.m8.1.1.3.cmml" xref="S3.SS2.p5.8.m8.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.8.m8.1c">@k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.8.m8.1d">@ italic_k</annotation></semantics></math>, the Jaccard similarity measures the overlap of the recommended news between two models without considering the order of the articles in the recommendation set.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.10"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.10.1">Embedding Similarity.</span>
Numerous measures quantify the representational similarity of neural networks <cite class="ltx_cite ltx_citemacro_citep">(Klabunde etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib22" title="">2023b</a>)</cite>. Many of these methods require an identical dimensionality of the compared embeddings or an alignment of the latent representation spaces across models. Since these constraints are not straightforwardly met by the embeddings produced with different news and user encoder architectures, we choose to measure the similarity of embeddings using the Centered Kernel Alignment (CKA) with a linear kernel <cite class="ltx_cite ltx_citemacro_citep">(Kornblith etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib23" title="">2019</a>)</cite>.
Concretely, for a given representation <math alttext="\mathbf{E}" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.1"><semantics id="S3.SS2.p6.1.m1.1a"><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">ğ„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">ğ„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">\mathbf{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.1d">bold_E</annotation></semantics></math>, we firstly mean-center it column-wise. Afterwards, we compute the pair-wise similarity of the representation of each instance <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">italic_i</annotation></semantics></math> to all other instances in <math alttext="\mathbf{E}" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.1"><semantics id="S3.SS2.p6.3.m3.1a"><mi id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml">ğ„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><ci id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1">ğ„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">\mathbf{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.1d">bold_E</annotation></semantics></math>. Each row <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p6.4.m4.1"><semantics id="S3.SS2.p6.4.m4.1a"><mi id="S3.SS2.p6.4.m4.1.1" xref="S3.SS2.p6.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.1b"><ci id="S3.SS2.p6.4.m4.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.4.m4.1d">italic_i</annotation></semantics></math> in the resulting similarity matrix <math alttext="\mathbf{S}" class="ltx_Math" display="inline" id="S3.SS2.p6.5.m5.1"><semantics id="S3.SS2.p6.5.m5.1a"><mi id="S3.SS2.p6.5.m5.1.1" xref="S3.SS2.p6.5.m5.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m5.1b"><ci id="S3.SS2.p6.5.m5.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m5.1c">\mathbf{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.5.m5.1d">bold_S</annotation></semantics></math> thus comprises the similarity between instanceâ€™s <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p6.6.m6.1"><semantics id="S3.SS2.p6.6.m6.1a"><mi id="S3.SS2.p6.6.m6.1.1" xref="S3.SS2.p6.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.6.m6.1b"><ci id="S3.SS2.p6.6.m6.1.1.cmml" xref="S3.SS2.p6.6.m6.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.6.m6.1d">italic_i</annotation></semantics></math> embedding and all other embeddings, including itself. For two different models with the same number of embeddings <math alttext="\mathbf{E}" class="ltx_Math" display="inline" id="S3.SS2.p6.7.m7.1"><semantics id="S3.SS2.p6.7.m7.1a"><mi id="S3.SS2.p6.7.m7.1.1" xref="S3.SS2.p6.7.m7.1.1.cmml">ğ„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.7.m7.1b"><ci id="S3.SS2.p6.7.m7.1.1.cmml" xref="S3.SS2.p6.7.m7.1.1">ğ„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.7.m7.1c">\mathbf{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.7.m7.1d">bold_E</annotation></semantics></math> and <math alttext="\mathbf{E^{\prime}}" class="ltx_Math" display="inline" id="S3.SS2.p6.8.m8.1"><semantics id="S3.SS2.p6.8.m8.1a"><msup id="S3.SS2.p6.8.m8.1.1" xref="S3.SS2.p6.8.m8.1.1.cmml"><mi id="S3.SS2.p6.8.m8.1.1.2" xref="S3.SS2.p6.8.m8.1.1.2.cmml">ğ„</mi><mo id="S3.SS2.p6.8.m8.1.1.3" xref="S3.SS2.p6.8.m8.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.8.m8.1b"><apply id="S3.SS2.p6.8.m8.1.1.cmml" xref="S3.SS2.p6.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.8.m8.1.1.1.cmml" xref="S3.SS2.p6.8.m8.1.1">superscript</csymbol><ci id="S3.SS2.p6.8.m8.1.1.2.cmml" xref="S3.SS2.p6.8.m8.1.1.2">ğ„</ci><ci id="S3.SS2.p6.8.m8.1.1.3.cmml" xref="S3.SS2.p6.8.m8.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.8.m8.1c">\mathbf{E^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.8.m8.1d">bold_E start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>, the resulting representational similarity matrices <math alttext="\mathbf{S}" class="ltx_Math" display="inline" id="S3.SS2.p6.9.m9.1"><semantics id="S3.SS2.p6.9.m9.1a"><mi id="S3.SS2.p6.9.m9.1.1" xref="S3.SS2.p6.9.m9.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.9.m9.1b"><ci id="S3.SS2.p6.9.m9.1.1.cmml" xref="S3.SS2.p6.9.m9.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.9.m9.1c">\mathbf{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.9.m9.1d">bold_S</annotation></semantics></math> and <math alttext="\mathbf{S^{\prime}}" class="ltx_Math" display="inline" id="S3.SS2.p6.10.m10.1"><semantics id="S3.SS2.p6.10.m10.1a"><msup id="S3.SS2.p6.10.m10.1.1" xref="S3.SS2.p6.10.m10.1.1.cmml"><mi id="S3.SS2.p6.10.m10.1.1.2" xref="S3.SS2.p6.10.m10.1.1.2.cmml">ğ’</mi><mo id="S3.SS2.p6.10.m10.1.1.3" xref="S3.SS2.p6.10.m10.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.10.m10.1b"><apply id="S3.SS2.p6.10.m10.1.1.cmml" xref="S3.SS2.p6.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.10.m10.1.1.1.cmml" xref="S3.SS2.p6.10.m10.1.1">superscript</csymbol><ci id="S3.SS2.p6.10.m10.1.1.2.cmml" xref="S3.SS2.p6.10.m10.1.1.2">ğ’</ci><ci id="S3.SS2.p6.10.m10.1.1.3.cmml" xref="S3.SS2.p6.10.m10.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.10.m10.1c">\mathbf{S^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.10.m10.1d">bold_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>, respectively, can be directly compared using the Hilbert-Schmidt Independence Criterion (HSIC) <cite class="ltx_cite ltx_citemacro_citep">(Gretton etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib10" title="">2005</a>)</cite> as follows:</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="CKA(\mathbf{E},\mathbf{E^{\prime}})=\frac{HSIC(\mathbf{S},\mathbf{S^{\prime}})%
}{\sqrt{HSIC(\mathbf{S},\mathbf{S})HSIC(\mathbf{S^{\prime}},\mathbf{S^{\prime}%
})}}" class="ltx_Math" display="block" id="S3.E2.m1.8"><semantics id="S3.E2.m1.8a"><mrow id="S3.E2.m1.8.8" xref="S3.E2.m1.8.8.cmml"><mrow id="S3.E2.m1.8.8.1" xref="S3.E2.m1.8.8.1.cmml"><mi id="S3.E2.m1.8.8.1.3" xref="S3.E2.m1.8.8.1.3.cmml">C</mi><mo id="S3.E2.m1.8.8.1.2" xref="S3.E2.m1.8.8.1.2.cmml">â¢</mo><mi id="S3.E2.m1.8.8.1.4" xref="S3.E2.m1.8.8.1.4.cmml">K</mi><mo id="S3.E2.m1.8.8.1.2a" xref="S3.E2.m1.8.8.1.2.cmml">â¢</mo><mi id="S3.E2.m1.8.8.1.5" xref="S3.E2.m1.8.8.1.5.cmml">A</mi><mo id="S3.E2.m1.8.8.1.2b" xref="S3.E2.m1.8.8.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.8.8.1.1.1" xref="S3.E2.m1.8.8.1.1.2.cmml"><mo id="S3.E2.m1.8.8.1.1.1.2" stretchy="false" xref="S3.E2.m1.8.8.1.1.2.cmml">(</mo><mi id="S3.E2.m1.7.7" xref="S3.E2.m1.7.7.cmml">ğ„</mi><mo id="S3.E2.m1.8.8.1.1.1.3" xref="S3.E2.m1.8.8.1.1.2.cmml">,</mo><msup id="S3.E2.m1.8.8.1.1.1.1" xref="S3.E2.m1.8.8.1.1.1.1.cmml"><mi id="S3.E2.m1.8.8.1.1.1.1.2" xref="S3.E2.m1.8.8.1.1.1.1.2.cmml">ğ„</mi><mo id="S3.E2.m1.8.8.1.1.1.1.3" xref="S3.E2.m1.8.8.1.1.1.1.3.cmml">â€²</mo></msup><mo id="S3.E2.m1.8.8.1.1.1.4" stretchy="false" xref="S3.E2.m1.8.8.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.8.8.2" xref="S3.E2.m1.8.8.2.cmml">=</mo><mfrac id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml"><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.4.cmml">H</mi><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.5" xref="S3.E2.m1.2.2.2.5.cmml">S</mi><mo id="S3.E2.m1.2.2.2.3a" xref="S3.E2.m1.2.2.2.3.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.6" xref="S3.E2.m1.2.2.2.6.cmml">I</mi><mo id="S3.E2.m1.2.2.2.3b" xref="S3.E2.m1.2.2.2.3.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.7" xref="S3.E2.m1.2.2.2.7.cmml">C</mi><mo id="S3.E2.m1.2.2.2.3c" xref="S3.E2.m1.2.2.2.3.cmml">â¢</mo><mrow id="S3.E2.m1.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.2.cmml"><mo id="S3.E2.m1.2.2.2.2.1.2" stretchy="false" xref="S3.E2.m1.2.2.2.2.2.cmml">(</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">ğ’</mi><mo id="S3.E2.m1.2.2.2.2.1.3" xref="S3.E2.m1.2.2.2.2.2.cmml">,</mo><msup id="S3.E2.m1.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.1.1.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.2.1.1.2.cmml">ğ’</mi><mo id="S3.E2.m1.2.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.2.1.1.3.cmml">â€²</mo></msup><mo id="S3.E2.m1.2.2.2.2.1.4" stretchy="false" xref="S3.E2.m1.2.2.2.2.2.cmml">)</mo></mrow></mrow><msqrt id="S3.E2.m1.6.6.6" xref="S3.E2.m1.6.6.6.cmml"><mrow id="S3.E2.m1.6.6.6.4.4" xref="S3.E2.m1.6.6.6.4.4.cmml"><mi id="S3.E2.m1.6.6.6.4.4.6" xref="S3.E2.m1.6.6.6.4.4.6.cmml">H</mi><mo id="S3.E2.m1.6.6.6.4.4.5" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mi id="S3.E2.m1.6.6.6.4.4.7" xref="S3.E2.m1.6.6.6.4.4.7.cmml">S</mi><mo id="S3.E2.m1.6.6.6.4.4.5a" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mi id="S3.E2.m1.6.6.6.4.4.8" xref="S3.E2.m1.6.6.6.4.4.8.cmml">I</mi><mo id="S3.E2.m1.6.6.6.4.4.5b" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mi id="S3.E2.m1.6.6.6.4.4.9" xref="S3.E2.m1.6.6.6.4.4.9.cmml">C</mi><mo id="S3.E2.m1.6.6.6.4.4.5c" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mrow id="S3.E2.m1.6.6.6.4.4.10.2" xref="S3.E2.m1.6.6.6.4.4.10.1.cmml"><mo id="S3.E2.m1.6.6.6.4.4.10.2.1" stretchy="false" xref="S3.E2.m1.6.6.6.4.4.10.1.cmml">(</mo><mi id="S3.E2.m1.3.3.3.1.1.1" xref="S3.E2.m1.3.3.3.1.1.1.cmml">ğ’</mi><mo id="S3.E2.m1.6.6.6.4.4.10.2.2" xref="S3.E2.m1.6.6.6.4.4.10.1.cmml">,</mo><mi id="S3.E2.m1.4.4.4.2.2.2" xref="S3.E2.m1.4.4.4.2.2.2.cmml">ğ’</mi><mo id="S3.E2.m1.6.6.6.4.4.10.2.3" stretchy="false" xref="S3.E2.m1.6.6.6.4.4.10.1.cmml">)</mo></mrow><mo id="S3.E2.m1.6.6.6.4.4.5d" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mi id="S3.E2.m1.6.6.6.4.4.11" xref="S3.E2.m1.6.6.6.4.4.11.cmml">H</mi><mo id="S3.E2.m1.6.6.6.4.4.5e" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mi id="S3.E2.m1.6.6.6.4.4.12" xref="S3.E2.m1.6.6.6.4.4.12.cmml">S</mi><mo id="S3.E2.m1.6.6.6.4.4.5f" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mi id="S3.E2.m1.6.6.6.4.4.13" xref="S3.E2.m1.6.6.6.4.4.13.cmml">I</mi><mo id="S3.E2.m1.6.6.6.4.4.5g" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mi id="S3.E2.m1.6.6.6.4.4.14" xref="S3.E2.m1.6.6.6.4.4.14.cmml">C</mi><mo id="S3.E2.m1.6.6.6.4.4.5h" xref="S3.E2.m1.6.6.6.4.4.5.cmml">â¢</mo><mrow id="S3.E2.m1.6.6.6.4.4.4.2" xref="S3.E2.m1.6.6.6.4.4.4.3.cmml"><mo id="S3.E2.m1.6.6.6.4.4.4.2.3" stretchy="false" xref="S3.E2.m1.6.6.6.4.4.4.3.cmml">(</mo><msup id="S3.E2.m1.5.5.5.3.3.3.1.1" xref="S3.E2.m1.5.5.5.3.3.3.1.1.cmml"><mi id="S3.E2.m1.5.5.5.3.3.3.1.1.2" xref="S3.E2.m1.5.5.5.3.3.3.1.1.2.cmml">ğ’</mi><mo id="S3.E2.m1.5.5.5.3.3.3.1.1.3" xref="S3.E2.m1.5.5.5.3.3.3.1.1.3.cmml">â€²</mo></msup><mo id="S3.E2.m1.6.6.6.4.4.4.2.4" xref="S3.E2.m1.6.6.6.4.4.4.3.cmml">,</mo><msup id="S3.E2.m1.6.6.6.4.4.4.2.2" xref="S3.E2.m1.6.6.6.4.4.4.2.2.cmml"><mi id="S3.E2.m1.6.6.6.4.4.4.2.2.2" xref="S3.E2.m1.6.6.6.4.4.4.2.2.2.cmml">ğ’</mi><mo id="S3.E2.m1.6.6.6.4.4.4.2.2.3" xref="S3.E2.m1.6.6.6.4.4.4.2.2.3.cmml">â€²</mo></msup><mo id="S3.E2.m1.6.6.6.4.4.4.2.5" stretchy="false" xref="S3.E2.m1.6.6.6.4.4.4.3.cmml">)</mo></mrow></mrow></msqrt></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.8b"><apply id="S3.E2.m1.8.8.cmml" xref="S3.E2.m1.8.8"><eq id="S3.E2.m1.8.8.2.cmml" xref="S3.E2.m1.8.8.2"></eq><apply id="S3.E2.m1.8.8.1.cmml" xref="S3.E2.m1.8.8.1"><times id="S3.E2.m1.8.8.1.2.cmml" xref="S3.E2.m1.8.8.1.2"></times><ci id="S3.E2.m1.8.8.1.3.cmml" xref="S3.E2.m1.8.8.1.3">ğ¶</ci><ci id="S3.E2.m1.8.8.1.4.cmml" xref="S3.E2.m1.8.8.1.4">ğ¾</ci><ci id="S3.E2.m1.8.8.1.5.cmml" xref="S3.E2.m1.8.8.1.5">ğ´</ci><interval closure="open" id="S3.E2.m1.8.8.1.1.2.cmml" xref="S3.E2.m1.8.8.1.1.1"><ci id="S3.E2.m1.7.7.cmml" xref="S3.E2.m1.7.7">ğ„</ci><apply id="S3.E2.m1.8.8.1.1.1.1.cmml" xref="S3.E2.m1.8.8.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.1.1.1.1.1.cmml" xref="S3.E2.m1.8.8.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.8.8.1.1.1.1.2.cmml" xref="S3.E2.m1.8.8.1.1.1.1.2">ğ„</ci><ci id="S3.E2.m1.8.8.1.1.1.1.3.cmml" xref="S3.E2.m1.8.8.1.1.1.1.3">â€²</ci></apply></interval></apply><apply id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6"><divide id="S3.E2.m1.6.6.7.cmml" xref="S3.E2.m1.6.6"></divide><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><times id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"></times><ci id="S3.E2.m1.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.4">ğ»</ci><ci id="S3.E2.m1.2.2.2.5.cmml" xref="S3.E2.m1.2.2.2.5">ğ‘†</ci><ci id="S3.E2.m1.2.2.2.6.cmml" xref="S3.E2.m1.2.2.2.6">ğ¼</ci><ci id="S3.E2.m1.2.2.2.7.cmml" xref="S3.E2.m1.2.2.2.7">ğ¶</ci><interval closure="open" id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.1"><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">ğ’</ci><apply id="S3.E2.m1.2.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.2">ğ’</ci><ci id="S3.E2.m1.2.2.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3">â€²</ci></apply></interval></apply><apply id="S3.E2.m1.6.6.6.cmml" xref="S3.E2.m1.6.6.6"><root id="S3.E2.m1.6.6.6a.cmml" xref="S3.E2.m1.6.6.6"></root><apply id="S3.E2.m1.6.6.6.4.4.cmml" xref="S3.E2.m1.6.6.6.4.4"><times id="S3.E2.m1.6.6.6.4.4.5.cmml" xref="S3.E2.m1.6.6.6.4.4.5"></times><ci id="S3.E2.m1.6.6.6.4.4.6.cmml" xref="S3.E2.m1.6.6.6.4.4.6">ğ»</ci><ci id="S3.E2.m1.6.6.6.4.4.7.cmml" xref="S3.E2.m1.6.6.6.4.4.7">ğ‘†</ci><ci id="S3.E2.m1.6.6.6.4.4.8.cmml" xref="S3.E2.m1.6.6.6.4.4.8">ğ¼</ci><ci id="S3.E2.m1.6.6.6.4.4.9.cmml" xref="S3.E2.m1.6.6.6.4.4.9">ğ¶</ci><interval closure="open" id="S3.E2.m1.6.6.6.4.4.10.1.cmml" xref="S3.E2.m1.6.6.6.4.4.10.2"><ci id="S3.E2.m1.3.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.3.1.1.1">ğ’</ci><ci id="S3.E2.m1.4.4.4.2.2.2.cmml" xref="S3.E2.m1.4.4.4.2.2.2">ğ’</ci></interval><ci id="S3.E2.m1.6.6.6.4.4.11.cmml" xref="S3.E2.m1.6.6.6.4.4.11">ğ»</ci><ci id="S3.E2.m1.6.6.6.4.4.12.cmml" xref="S3.E2.m1.6.6.6.4.4.12">ğ‘†</ci><ci id="S3.E2.m1.6.6.6.4.4.13.cmml" xref="S3.E2.m1.6.6.6.4.4.13">ğ¼</ci><ci id="S3.E2.m1.6.6.6.4.4.14.cmml" xref="S3.E2.m1.6.6.6.4.4.14">ğ¶</ci><interval closure="open" id="S3.E2.m1.6.6.6.4.4.4.3.cmml" xref="S3.E2.m1.6.6.6.4.4.4.2"><apply id="S3.E2.m1.5.5.5.3.3.3.1.1.cmml" xref="S3.E2.m1.5.5.5.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.5.3.3.3.1.1.1.cmml" xref="S3.E2.m1.5.5.5.3.3.3.1.1">superscript</csymbol><ci id="S3.E2.m1.5.5.5.3.3.3.1.1.2.cmml" xref="S3.E2.m1.5.5.5.3.3.3.1.1.2">ğ’</ci><ci id="S3.E2.m1.5.5.5.3.3.3.1.1.3.cmml" xref="S3.E2.m1.5.5.5.3.3.3.1.1.3">â€²</ci></apply><apply id="S3.E2.m1.6.6.6.4.4.4.2.2.cmml" xref="S3.E2.m1.6.6.6.4.4.4.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.4.4.4.2.2.1.cmml" xref="S3.E2.m1.6.6.6.4.4.4.2.2">superscript</csymbol><ci id="S3.E2.m1.6.6.6.4.4.4.2.2.2.cmml" xref="S3.E2.m1.6.6.6.4.4.4.2.2.2">ğ’</ci><ci id="S3.E2.m1.6.6.6.4.4.4.2.2.3.cmml" xref="S3.E2.m1.6.6.6.4.4.4.2.2.3">â€²</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.8c">CKA(\mathbf{E},\mathbf{E^{\prime}})=\frac{HSIC(\mathbf{S},\mathbf{S^{\prime}})%
}{\sqrt{HSIC(\mathbf{S},\mathbf{S})HSIC(\mathbf{S^{\prime}},\mathbf{S^{\prime}%
})}}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.8d">italic_C italic_K italic_A ( bold_E , bold_E start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) = divide start_ARG italic_H italic_S italic_I italic_C ( bold_S , bold_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) end_ARG start_ARG square-root start_ARG italic_H italic_S italic_I italic_C ( bold_S , bold_S ) italic_H italic_S italic_I italic_C ( bold_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , bold_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) end_ARG end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.1">The CKA similarity scores are bounded to the interval <math alttext="[0,1]" class="ltx_Math" display="inline" id="S3.SS2.p8.1.m1.2"><semantics id="S3.SS2.p8.1.m1.2a"><mrow id="S3.SS2.p8.1.m1.2.3.2" xref="S3.SS2.p8.1.m1.2.3.1.cmml"><mo id="S3.SS2.p8.1.m1.2.3.2.1" stretchy="false" xref="S3.SS2.p8.1.m1.2.3.1.cmml">[</mo><mn id="S3.SS2.p8.1.m1.1.1" xref="S3.SS2.p8.1.m1.1.1.cmml">0</mn><mo id="S3.SS2.p8.1.m1.2.3.2.2" xref="S3.SS2.p8.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS2.p8.1.m1.2.2" xref="S3.SS2.p8.1.m1.2.2.cmml">1</mn><mo id="S3.SS2.p8.1.m1.2.3.2.3" stretchy="false" xref="S3.SS2.p8.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.1.m1.2b"><interval closure="closed" id="S3.SS2.p8.1.m1.2.3.1.cmml" xref="S3.SS2.p8.1.m1.2.3.2"><cn id="S3.SS2.p8.1.m1.1.1.cmml" type="integer" xref="S3.SS2.p8.1.m1.1.1">0</cn><cn id="S3.SS2.p8.1.m1.2.2.cmml" type="integer" xref="S3.SS2.p8.1.m1.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.1.m1.2c">[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.1.m1.2d">[ 0 , 1 ]</annotation></semantics></math>, with a score of 1 denoting equivalent representations.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="257" id="S3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.2.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S3.F1.3.2" style="font-size:90%;">Ranking performance (nDCG@10) of recommenders depending on the news encoder architecture and input features.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experimental Setup</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">Data.</span>
We conduct experiments on the MINDsmall <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib61" title="">2020b</a>)</cite> dataset. Since <cite class="ltx_cite ltx_citemacro_citet">Wu etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib61" title="">2020b</a>)</cite> do not release the test set labels, we use the validation portion for testing, and split the respective training set into temporarily disjoint training (the first four days of data) and validation (the last day of data) subsets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Evaluation Setup.</span>
We separately evaluate the encoder architectures of NNRs. In all experiments, we consider both mono-feature (e.g., title) and multi-feature (e.g., title and categories) inputs for the NE. In the latter case, we learn category representations by means of a linear encoder that combines a category ID embedding layer with a dense layer <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib45" title="">2019b</a>; An etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib2" title="">2019</a>; Qi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib32" title="">2022</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib43" title="">2022</a>)</cite>. Moreover, in our analysis of NE architectures, we adopt the <span class="ltx_text ltx_font_italic" id="S4.p2.1.2">late fusion</span> approach <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite> instead of the traditional parameterized UEs. This evaluation setup allows us to isolate the effects of NEs and to avoid additional confounding factors stemming from the UE, which also influence the output of the NNR. Similarly, when evaluating the similarity of UE architectures, we keep the underlying NE of the recommender fixed, i.e., we analyze different UEs for the same base NE.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.3"><span class="ltx_text ltx_font_bold" id="S4.p3.3.1">Implementation and Optimization Details.</span>
We train all models with the standard cross-entropy loss, using dot product as the scoring function. We use 300-dimensional pretrained Glove embeddings <cite class="ltx_cite ltx_citemacro_citep">(Pennington etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib30" title="">2014</a>)</cite> to initialize the word embeddings of the word embedding-based text encoders. Additionally, we use RoBERTa-base <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib27" title="">2019</a>)</cite> and the news-specialized multilingual sentence encoder NaSE <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib16" title="">2024</a>)</cite> for the PLM-based and SE-based text encoders, respectively. We fine-tune only the last four layers of the language models.
Following prior work <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib49" title="">2022a</a>)</cite>, we sample four negatives per positive example during training. We set the maximum history length to 50 and train all models with mixed precision, the Adam optimizer <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Ba, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib20" title="">2014</a>)</cite>, and a batch size of 8. We train all NNRs with word embedding-based NEs for 20 epochs, and those with language model-based NEs for 10 epochs.
We tune the main hyperparameters of all NNRs using grid search. Concretely, we search for the optimal learning rate in <math alttext="\{1e{-3},1e{-4},1e{-5}\}" class="ltx_Math" display="inline" id="S4.p3.1.m1.3"><semantics id="S4.p3.1.m1.3a"><mrow id="S4.p3.1.m1.3.3.3" xref="S4.p3.1.m1.3.3.4.cmml"><mo id="S4.p3.1.m1.3.3.3.4" stretchy="false" xref="S4.p3.1.m1.3.3.4.cmml">{</mo><mrow id="S4.p3.1.m1.1.1.1.1" xref="S4.p3.1.m1.1.1.1.1.cmml"><mrow id="S4.p3.1.m1.1.1.1.1.2" xref="S4.p3.1.m1.1.1.1.1.2.cmml"><mn id="S4.p3.1.m1.1.1.1.1.2.2" xref="S4.p3.1.m1.1.1.1.1.2.2.cmml">1</mn><mo id="S4.p3.1.m1.1.1.1.1.2.1" xref="S4.p3.1.m1.1.1.1.1.2.1.cmml">â¢</mo><mi id="S4.p3.1.m1.1.1.1.1.2.3" xref="S4.p3.1.m1.1.1.1.1.2.3.cmml">e</mi></mrow><mo id="S4.p3.1.m1.1.1.1.1.1" xref="S4.p3.1.m1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S4.p3.1.m1.1.1.1.1.3" xref="S4.p3.1.m1.1.1.1.1.3.cmml">3</mn></mrow><mo id="S4.p3.1.m1.3.3.3.5" xref="S4.p3.1.m1.3.3.4.cmml">,</mo><mrow id="S4.p3.1.m1.2.2.2.2" xref="S4.p3.1.m1.2.2.2.2.cmml"><mrow id="S4.p3.1.m1.2.2.2.2.2" xref="S4.p3.1.m1.2.2.2.2.2.cmml"><mn id="S4.p3.1.m1.2.2.2.2.2.2" xref="S4.p3.1.m1.2.2.2.2.2.2.cmml">1</mn><mo id="S4.p3.1.m1.2.2.2.2.2.1" xref="S4.p3.1.m1.2.2.2.2.2.1.cmml">â¢</mo><mi id="S4.p3.1.m1.2.2.2.2.2.3" xref="S4.p3.1.m1.2.2.2.2.2.3.cmml">e</mi></mrow><mo id="S4.p3.1.m1.2.2.2.2.1" xref="S4.p3.1.m1.2.2.2.2.1.cmml">âˆ’</mo><mn id="S4.p3.1.m1.2.2.2.2.3" xref="S4.p3.1.m1.2.2.2.2.3.cmml">4</mn></mrow><mo id="S4.p3.1.m1.3.3.3.6" xref="S4.p3.1.m1.3.3.4.cmml">,</mo><mrow id="S4.p3.1.m1.3.3.3.3" xref="S4.p3.1.m1.3.3.3.3.cmml"><mrow id="S4.p3.1.m1.3.3.3.3.2" xref="S4.p3.1.m1.3.3.3.3.2.cmml"><mn id="S4.p3.1.m1.3.3.3.3.2.2" xref="S4.p3.1.m1.3.3.3.3.2.2.cmml">1</mn><mo id="S4.p3.1.m1.3.3.3.3.2.1" xref="S4.p3.1.m1.3.3.3.3.2.1.cmml">â¢</mo><mi id="S4.p3.1.m1.3.3.3.3.2.3" xref="S4.p3.1.m1.3.3.3.3.2.3.cmml">e</mi></mrow><mo id="S4.p3.1.m1.3.3.3.3.1" xref="S4.p3.1.m1.3.3.3.3.1.cmml">âˆ’</mo><mn id="S4.p3.1.m1.3.3.3.3.3" xref="S4.p3.1.m1.3.3.3.3.3.cmml">5</mn></mrow><mo id="S4.p3.1.m1.3.3.3.7" stretchy="false" xref="S4.p3.1.m1.3.3.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.3b"><set id="S4.p3.1.m1.3.3.4.cmml" xref="S4.p3.1.m1.3.3.3"><apply id="S4.p3.1.m1.1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1.1"><minus id="S4.p3.1.m1.1.1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1.1.1"></minus><apply id="S4.p3.1.m1.1.1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.1.1.2"><times id="S4.p3.1.m1.1.1.1.1.2.1.cmml" xref="S4.p3.1.m1.1.1.1.1.2.1"></times><cn id="S4.p3.1.m1.1.1.1.1.2.2.cmml" type="integer" xref="S4.p3.1.m1.1.1.1.1.2.2">1</cn><ci id="S4.p3.1.m1.1.1.1.1.2.3.cmml" xref="S4.p3.1.m1.1.1.1.1.2.3">ğ‘’</ci></apply><cn id="S4.p3.1.m1.1.1.1.1.3.cmml" type="integer" xref="S4.p3.1.m1.1.1.1.1.3">3</cn></apply><apply id="S4.p3.1.m1.2.2.2.2.cmml" xref="S4.p3.1.m1.2.2.2.2"><minus id="S4.p3.1.m1.2.2.2.2.1.cmml" xref="S4.p3.1.m1.2.2.2.2.1"></minus><apply id="S4.p3.1.m1.2.2.2.2.2.cmml" xref="S4.p3.1.m1.2.2.2.2.2"><times id="S4.p3.1.m1.2.2.2.2.2.1.cmml" xref="S4.p3.1.m1.2.2.2.2.2.1"></times><cn id="S4.p3.1.m1.2.2.2.2.2.2.cmml" type="integer" xref="S4.p3.1.m1.2.2.2.2.2.2">1</cn><ci id="S4.p3.1.m1.2.2.2.2.2.3.cmml" xref="S4.p3.1.m1.2.2.2.2.2.3">ğ‘’</ci></apply><cn id="S4.p3.1.m1.2.2.2.2.3.cmml" type="integer" xref="S4.p3.1.m1.2.2.2.2.3">4</cn></apply><apply id="S4.p3.1.m1.3.3.3.3.cmml" xref="S4.p3.1.m1.3.3.3.3"><minus id="S4.p3.1.m1.3.3.3.3.1.cmml" xref="S4.p3.1.m1.3.3.3.3.1"></minus><apply id="S4.p3.1.m1.3.3.3.3.2.cmml" xref="S4.p3.1.m1.3.3.3.3.2"><times id="S4.p3.1.m1.3.3.3.3.2.1.cmml" xref="S4.p3.1.m1.3.3.3.3.2.1"></times><cn id="S4.p3.1.m1.3.3.3.3.2.2.cmml" type="integer" xref="S4.p3.1.m1.3.3.3.3.2.2">1</cn><ci id="S4.p3.1.m1.3.3.3.3.2.3.cmml" xref="S4.p3.1.m1.3.3.3.3.2.3">ğ‘’</ci></apply><cn id="S4.p3.1.m1.3.3.3.3.3.cmml" type="integer" xref="S4.p3.1.m1.3.3.3.3.3">5</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.3c">\{1e{-3},1e{-4},1e{-5}\}</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.3d">{ 1 italic_e - 3 , 1 italic_e - 4 , 1 italic_e - 5 }</annotation></semantics></math>. We optimize the number of heads in the multi-head self-attention networks in <math alttext="[8,12,16,20,24,32]" class="ltx_Math" display="inline" id="S4.p3.2.m2.6"><semantics id="S4.p3.2.m2.6a"><mrow id="S4.p3.2.m2.6.7.2" xref="S4.p3.2.m2.6.7.1.cmml"><mo id="S4.p3.2.m2.6.7.2.1" stretchy="false" xref="S4.p3.2.m2.6.7.1.cmml">[</mo><mn id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">8</mn><mo id="S4.p3.2.m2.6.7.2.2" xref="S4.p3.2.m2.6.7.1.cmml">,</mo><mn id="S4.p3.2.m2.2.2" xref="S4.p3.2.m2.2.2.cmml">12</mn><mo id="S4.p3.2.m2.6.7.2.3" xref="S4.p3.2.m2.6.7.1.cmml">,</mo><mn id="S4.p3.2.m2.3.3" xref="S4.p3.2.m2.3.3.cmml">16</mn><mo id="S4.p3.2.m2.6.7.2.4" xref="S4.p3.2.m2.6.7.1.cmml">,</mo><mn id="S4.p3.2.m2.4.4" xref="S4.p3.2.m2.4.4.cmml">20</mn><mo id="S4.p3.2.m2.6.7.2.5" xref="S4.p3.2.m2.6.7.1.cmml">,</mo><mn id="S4.p3.2.m2.5.5" xref="S4.p3.2.m2.5.5.cmml">24</mn><mo id="S4.p3.2.m2.6.7.2.6" xref="S4.p3.2.m2.6.7.1.cmml">,</mo><mn id="S4.p3.2.m2.6.6" xref="S4.p3.2.m2.6.6.cmml">32</mn><mo id="S4.p3.2.m2.6.7.2.7" stretchy="false" xref="S4.p3.2.m2.6.7.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.6b"><list id="S4.p3.2.m2.6.7.1.cmml" xref="S4.p3.2.m2.6.7.2"><cn id="S4.p3.2.m2.1.1.cmml" type="integer" xref="S4.p3.2.m2.1.1">8</cn><cn id="S4.p3.2.m2.2.2.cmml" type="integer" xref="S4.p3.2.m2.2.2">12</cn><cn id="S4.p3.2.m2.3.3.cmml" type="integer" xref="S4.p3.2.m2.3.3">16</cn><cn id="S4.p3.2.m2.4.4.cmml" type="integer" xref="S4.p3.2.m2.4.4">20</cn><cn id="S4.p3.2.m2.5.5.cmml" type="integer" xref="S4.p3.2.m2.5.5">24</cn><cn id="S4.p3.2.m2.6.6.cmml" type="integer" xref="S4.p3.2.m2.6.6">32</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.6c">[8,12,16,20,24,32]</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.6d">[ 8 , 12 , 16 , 20 , 24 , 32 ]</annotation></semantics></math>, and the query vector dimensionality by sweeping the interval <math alttext="[50,200]" class="ltx_Math" display="inline" id="S4.p3.3.m3.2"><semantics id="S4.p3.3.m3.2a"><mrow id="S4.p3.3.m3.2.3.2" xref="S4.p3.3.m3.2.3.1.cmml"><mo id="S4.p3.3.m3.2.3.2.1" stretchy="false" xref="S4.p3.3.m3.2.3.1.cmml">[</mo><mn id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml">50</mn><mo id="S4.p3.3.m3.2.3.2.2" xref="S4.p3.3.m3.2.3.1.cmml">,</mo><mn id="S4.p3.3.m3.2.2" xref="S4.p3.3.m3.2.2.cmml">200</mn><mo id="S4.p3.3.m3.2.3.2.3" stretchy="false" xref="S4.p3.3.m3.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.2b"><interval closure="closed" id="S4.p3.3.m3.2.3.1.cmml" xref="S4.p3.3.m3.2.3.2"><cn id="S4.p3.3.m3.1.1.cmml" type="integer" xref="S4.p3.3.m3.1.1">50</cn><cn id="S4.p3.3.m3.2.2.cmml" type="integer" xref="S4.p3.3.m3.2.2">200</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.2c">[50,200]</annotation><annotation encoding="application/x-llamapun" id="S4.p3.3.m3.2d">[ 50 , 200 ]</annotation></semantics></math> with a step of 50.
We run all experiments using the implementations available in the NewsRecLib library <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib13" title="">2023a</a>)</cite>, on a cluster with virtual machines, training each model on a single NVIDIA A100 40GB GPU.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/andreeaiana/newsreclib</span></span></span></p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Results and Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We begin by analyzing the similarity of core NE architectures, followed by an evaluation of UE similarity using the same base news encoding approach. In both cases, we first compare the architectures in terms of ranking performance and retrieval similarity, as these are standard evaluation approaches in the recommender systems field. We then assess the architectures from the perspective of pair-wise embedding similarity.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>News Encoder Architectures</h3>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="858" id="S5.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F2.2.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="S5.F2.3.2" style="font-size:90%;">Jaccard similarity for the top-10 recommended news for models with different news encoder architectures and input features. Each modelâ€™s subscript indicates the type of input, and the multi-feature aggregation strategy, if used.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="858" id="S5.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.2.1.1" style="font-size:90%;">Figure 3</span>. </span><span class="ltx_text" id="S5.F3.3.2" style="font-size:90%;">CKA similarity of news embeddings produced with different news encoder architectures and input features. Each modelâ€™s subscript indicates the type of input, and the multi-feature aggregation strategy, if used.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S3.F1" title="Figure 1 â€£ 3.2. Similarity Evaluation â€£ 3. Methodology â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">1</span></a> shows the ranking performance, in terms of nDCG@10, of NNRs for different news encoders and input features. For the same input type, e.g. mono-feature, we find a high similarity between the performance of recommenders based on the same family of text encoders. Specifically, text encoders using pretrained static word embeddings are outperformed by those based on PLMs.
Moreover, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.1">MHSA+AddAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.2">CNN+MHSA+AddAtt</span> appear to have nearly identical performance, despite the increased complexity of the latter architecture. Similarly, simply using the <math alttext="[CLS]" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.2.cmml"><mo id="S5.SS1.p1.1.m1.1.1.1.2" stretchy="false" xref="S5.SS1.p1.1.m1.1.1.2.1.cmml">[</mo><mrow id="S5.SS1.p1.1.m1.1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S5.SS1.p1.1.m1.1.1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.1.1.2.cmml">C</mi><mo id="S5.SS1.p1.1.m1.1.1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.1.1.cmml">â¢</mo><mi id="S5.SS1.p1.1.m1.1.1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.1.1.3.cmml">L</mi><mo id="S5.SS1.p1.1.m1.1.1.1.1.1a" xref="S5.SS1.p1.1.m1.1.1.1.1.1.cmml">â¢</mo><mi id="S5.SS1.p1.1.m1.1.1.1.1.4" xref="S5.SS1.p1.1.m1.1.1.1.1.4.cmml">S</mi></mrow><mo id="S5.SS1.p1.1.m1.1.1.1.3" stretchy="false" xref="S5.SS1.p1.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.1"><csymbol cd="latexml" id="S5.SS1.p1.1.m1.1.1.2.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="S5.SS1.p1.1.m1.1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1"><times id="S5.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1.1"></times><ci id="S5.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1.2">ğ¶</ci><ci id="S5.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1.3">ğ¿</ci><ci id="S5.SS1.p1.1.m1.1.1.1.1.4.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1.4">ğ‘†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">[CLS]</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">[ italic_C italic_L italic_S ]</annotation></semantics></math> token representation produced by the PLM instead of pooling tokens with an attention network as proposed by <cite class="ltx_cite ltx_citemacro_citet">Wu etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib55" title="">2021b</a>)</cite> leads to slightly better performance while maintaining a lighter text encoder.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Our findings show that among the three multi-feature aggregation strategies, the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.1">Linear</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.2">AddAtt</span> approaches always outperform the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.3">Con</span> technique. This is intuitive, as the concatenation of vectors with varying dimensionality from non-aligned representation spaces will be sub-optimal. In contrast, both other aggregation strategies project the intermediate text and category embeddings in the same latent representation space. Most importantly, we find that leveraging categories in addition to textual news content as input features is most beneficial for word embedding-based text encoders, and becomes irrelevant or slightly detrimental for the domain-adapted sentence encoder. This can be explained, on the one hand, by the better representational capabilities of the much larger language models which acquire contextual understanding during pretraining compared to static word embeddings. On the other hand, sentence encoders, especially domain-specialized models such as NaSE <cite class="ltx_cite ltx_citemacro_citep">(Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib16" title="">2024</a>)</cite>, better capture nuances and topics from text due to their pretraining objectives that focus on the overall sentence-level semantics.</p>
</div>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="444" id="S5.F4.sf1.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.sf1.3.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text ltx_font_typewriter" id="S5.F4.sf1.4.2" style="font-size:90%;">SE<sub class="ltx_sub" id="S5.F4.sf1.4.2.1"><span class="ltx_text ltx_font_serif" id="S5.F4.sf1.4.2.1.1">Monofeat</span></sub><span class="ltx_text ltx_font_serif" id="S5.F4.sf1.4.2.2"> against the best performing architectures from the other news encoder families evaluated.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="444" id="S5.F4.sf2.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.sf2.3.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S5.F4.sf2.4.2" style="font-size:90%;">LF against other user encoder architectures evaluated, with <span class="ltx_text ltx_font_typewriter" id="S5.F4.sf2.4.2.1">CNN+AddAtt</span> as the base news encoder.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.4.2.1" style="font-size:90%;">Figure 4</span>. </span><span class="ltx_text" id="S5.F4.2.1" style="font-size:90%;">Evolution of Jaccard similarity for different values of <math alttext="k" class="ltx_Math" display="inline" id="S5.F4.2.1.m1.1"><semantics id="S5.F4.2.1.m1.1b"><mi id="S5.F4.2.1.m1.1.1" xref="S5.F4.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F4.2.1.m1.1c"><ci id="S5.F4.2.1.m1.1.1.cmml" xref="S5.F4.2.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.2.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.F4.2.1.m1.1e">italic_k</annotation></semantics></math>.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">We find these similarities in ranking performance between the various news encoding architectures to be reflected in the similarity of retrieved articles. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F2" title="Figure 2 â€£ 5.1. News Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the pair-wise Jaccard similarity scores between the top-10 recommended news per model. Note that we exclude <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p3.1.1">PLM<sub class="ltx_sub" id="S5.SS1.p3.1.1.1"><span class="ltx_text ltx_font_serif" id="S5.SS1.p3.1.1.1.1">tokenemb+Att</span></sub></span>, as well as the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p3.1.2">Con</span> multi-feature aggregation strategy from further analysis for the sake of brevity and due to their poorer performance.
As expected, models from the same family of text encoders show higher similarity scores. The lower Jaccard similarities across word embedding and PLM-based intra-family models using mono-feature versus multi-feature input supports our previous observation regarding the low relevance of categorical input for the domain-adapted SE.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">The overall pair-wise Jaccard similarities could initially suggest that most NEs result in little overlap in their recommendation lists. However, a Jaccard similarity score of 0.54 between two models for a list of <math alttext="k=10" class="ltx_Math" display="inline" id="S5.SS1.p4.1.m1.1"><semantics id="S5.SS1.p4.1.m1.1a"><mrow id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml"><mi id="S5.SS1.p4.1.m1.1.1.2" xref="S5.SS1.p4.1.m1.1.1.2.cmml">k</mi><mo id="S5.SS1.p4.1.m1.1.1.1" xref="S5.SS1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.p4.1.m1.1.1.3" xref="S5.SS1.p4.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><apply id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1"><eq id="S5.SS1.p4.1.m1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1.1"></eq><ci id="S5.SS1.p4.1.m1.1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.1.2">ğ‘˜</ci><cn id="S5.SS1.p4.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p4.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">k=10</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p4.1.m1.1d">italic_k = 10</annotation></semantics></math> recommended items means that, in practice, the two models output 7 identical articles. Analogously, a score of 0.66 indicates an overlap of 8 out of 10 recommendations. As Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F2" title="Figure 2 â€£ 5.1. News Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">2</span></a> shows, the recommendations generated by the various NE architectures differ by more than 3 articles in a list of length 10 only in rare cases. In other words, regardless of the architectural differences and complexities, the encoders retrieve, on average, the same articles in over 70% of the time.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1">Taking a look at the CKA similarity of the test set news embeddings produced with the different NEs, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F3" title="Figure 3 â€£ 5.1. News Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">3</span></a>, corroborates our hypothesis: intra-family NEs tend to produce similar embeddings when using the same type of input features. The news-adapted SE constitutes the only exception, as its embeddings are not significantly influenced by leveraging categories as additional input features. Additionally, we observe a higher representational similarity between the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.1">CNN+AddAtt</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.2">MHSA+AddAtt</span>, and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.3">CNN+MHSA+AddAtt</span> models with multi-feature input, and a slightly lower similarity between <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.4">PLM<sub class="ltx_sub" id="S5.SS1.p5.1.4.1"><span class="ltx_text ltx_font_serif" id="S5.SS1.p5.1.4.1.1">[CLS]</span></sub></span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.5">SE</span>-based models. Overall, the high similarity of representations, of recommendation performance, and the large overlap of generated recommendations by the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.6">CNN+AddAtt</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.7">MHSA+AddAtt</span>, and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p5.1.8">CNN+MHSA+AddAtt</span> multi-feature NEs contest the empirical contribution of incremental architectural changes in the NE architecture of some NNRs.</p>
</div>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.8">Lastly, we contrast the representational similarity of models against their retrieval similarity. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F4.sf1" title="In Figure 4 â€£ 5.1. News Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">4(a)</span></a> illustrates the evolution of Jaccard similarity scores between the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p6.8.1">SE<sub class="ltx_sub" id="S5.SS1.p6.8.1.1"><span class="ltx_text ltx_font_serif" id="S5.SS1.p6.8.1.1.1">Monofeat</span></sub></span> encoder and the best performing architecture from each remaining NE family for different values of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.p6.1.m1.1"><semantics id="S5.SS1.p6.1.m1.1a"><mi id="S5.SS1.p6.1.m1.1.1" xref="S5.SS1.p6.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.1.m1.1b"><ci id="S5.SS1.p6.1.m1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.1.m1.1d">italic_k</annotation></semantics></math>. For low values of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.p6.2.m2.1"><semantics id="S5.SS1.p6.2.m2.1a"><mi id="S5.SS1.p6.2.m2.1.1" xref="S5.SS1.p6.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.2.m2.1b"><ci id="S5.SS1.p6.2.m2.1.1.cmml" xref="S5.SS1.p6.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.2.m2.1d">italic_k</annotation></semantics></math>, we observe a lower similarity of retrieved news for inter-family text encoders, with scores converging toward 1 for larger <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.p6.3.m3.1"><semantics id="S5.SS1.p6.3.m3.1a"><mi id="S5.SS1.p6.3.m3.1.1" xref="S5.SS1.p6.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.3.m3.1b"><ci id="S5.SS1.p6.3.m3.1.1.cmml" xref="S5.SS1.p6.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.3.m3.1d">italic_k</annotation></semantics></math>. An important insight here is that for low values of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.p6.4.m4.1"><semantics id="S5.SS1.p6.4.m4.1a"><mi id="S5.SS1.p6.4.m4.1.1" xref="S5.SS1.p6.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.4.m4.1b"><ci id="S5.SS1.p6.4.m4.1.1.cmml" xref="S5.SS1.p6.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.4.m4.1d">italic_k</annotation></semantics></math> (e.g., <math alttext="k&lt;10" class="ltx_Math" display="inline" id="S5.SS1.p6.5.m5.1"><semantics id="S5.SS1.p6.5.m5.1a"><mrow id="S5.SS1.p6.5.m5.1.1" xref="S5.SS1.p6.5.m5.1.1.cmml"><mi id="S5.SS1.p6.5.m5.1.1.2" xref="S5.SS1.p6.5.m5.1.1.2.cmml">k</mi><mo id="S5.SS1.p6.5.m5.1.1.1" xref="S5.SS1.p6.5.m5.1.1.1.cmml">&lt;</mo><mn id="S5.SS1.p6.5.m5.1.1.3" xref="S5.SS1.p6.5.m5.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.5.m5.1b"><apply id="S5.SS1.p6.5.m5.1.1.cmml" xref="S5.SS1.p6.5.m5.1.1"><lt id="S5.SS1.p6.5.m5.1.1.1.cmml" xref="S5.SS1.p6.5.m5.1.1.1"></lt><ci id="S5.SS1.p6.5.m5.1.1.2.cmml" xref="S5.SS1.p6.5.m5.1.1.2">ğ‘˜</ci><cn id="S5.SS1.p6.5.m5.1.1.3.cmml" type="integer" xref="S5.SS1.p6.5.m5.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.5.m5.1c">k&lt;10</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.5.m5.1d">italic_k &lt; 10</annotation></semantics></math>), the news articles retrieved by different NEs tend to be identical, on average, in more than half of the recommended items (e.g., a Jaccard of 0.42 for <math alttext="k=5" class="ltx_Math" display="inline" id="S5.SS1.p6.6.m6.1"><semantics id="S5.SS1.p6.6.m6.1a"><mrow id="S5.SS1.p6.6.m6.1.1" xref="S5.SS1.p6.6.m6.1.1.cmml"><mi id="S5.SS1.p6.6.m6.1.1.2" xref="S5.SS1.p6.6.m6.1.1.2.cmml">k</mi><mo id="S5.SS1.p6.6.m6.1.1.1" xref="S5.SS1.p6.6.m6.1.1.1.cmml">=</mo><mn id="S5.SS1.p6.6.m6.1.1.3" xref="S5.SS1.p6.6.m6.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.6.m6.1b"><apply id="S5.SS1.p6.6.m6.1.1.cmml" xref="S5.SS1.p6.6.m6.1.1"><eq id="S5.SS1.p6.6.m6.1.1.1.cmml" xref="S5.SS1.p6.6.m6.1.1.1"></eq><ci id="S5.SS1.p6.6.m6.1.1.2.cmml" xref="S5.SS1.p6.6.m6.1.1.2">ğ‘˜</ci><cn id="S5.SS1.p6.6.m6.1.1.3.cmml" type="integer" xref="S5.SS1.p6.6.m6.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.6.m6.1c">k=5</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.6.m6.1d">italic_k = 5</annotation></semantics></math> translates into an overlap of 3 out of 5 items). We observe this behavior even for models with lower representational similarity scores, e.g., word embedding-based NEs versus language model-based NEs. This is relevant from a practical perspective, where retrieval similarity is of most interest for small values of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.p6.7.m7.1"><semantics id="S5.SS1.p6.7.m7.1a"><mi id="S5.SS1.p6.7.m7.1.1" xref="S5.SS1.p6.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.7.m7.1b"><ci id="S5.SS1.p6.7.m7.1.1.cmml" xref="S5.SS1.p6.7.m7.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.7.m7.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.7.m7.1d">italic_k</annotation></semantics></math>. It would imply, on the one hand, that the representational similarity of NEs might not directly correlate with the retrieval performance for small <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.p6.8.m8.1"><semantics id="S5.SS1.p6.8.m8.1a"><mi id="S5.SS1.p6.8.m8.1.1" xref="S5.SS1.p6.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.8.m8.1b"><ci id="S5.SS1.p6.8.m8.1.1.cmml" xref="S5.SS1.p6.8.m8.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.8.m8.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.8.m8.1d">italic_k</annotation></semantics></math>. On the other hand, this evidence re-affirms our earlier hypothesis that small differences in the architecture and complexity of news encoders do not result in large differences in the actual recommended items.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>User Encoder Architectures</h3>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="201" id="S5.F5.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.2.1.1" style="font-size:90%;">Figure 5</span>. </span><span class="ltx_text" id="S5.F5.3.2" style="font-size:90%;">Ranking performance of different recommenders (nDCG@10) depending on the user encoder architecture, for different base news encoder families. The dark bars denote the ranking obtained when using a mono-feature input (i.e., title) in the news encoder, whereas the lighter bars indicate the (generally higher) scores gained with a multi-feature input (i.e., title and category), and the best multi-feature aggregation strategy per news encoder family.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="879" id="S5.F6.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.2.1.1" style="font-size:90%;">Figure 6</span>. </span><span class="ltx_text" id="S5.F6.3.2" style="font-size:90%;">Jaccard similarity for the top-10 recommended news for models with different user encoder architectures. Each model name denotes the base news encoder, with the user encoder architecture indicated by the subscript.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="830" id="S5.F7.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F7.2.1.1" style="font-size:90%;">Figure 7</span>. </span><span class="ltx_text" id="S5.F7.3.2" style="font-size:90%;">CKA similarity of user embeddings produced with different user encoders, for different families of base news encoders. Each model name denotes the base news encoder, with the user encoder architecture indicated by the subscript.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We next investigate the ranking performance, with regards to nDCG@10, for different UE architectures for the same base NE. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F5" title="Figure 5 â€£ 5.2. User Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">5</span></a> displays the corresponding results, for both mono-feature, and well as multi-feature input. We find that the <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.1">LF</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.2">AddAtt</span>, and <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.3">CandAware</span> encoders perform the best across all families of NEs. More specifically, the much simpler <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.4">LF</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.5">AddAtt</span> encoders outperform the complex <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.6">CandAware</span> modeling technique in the case of language model-based NEs, and perform similarly with <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.7">CandAware</span> for word embedding-based NEs, as previously suggested by <cite class="ltx_cite ltx_citemacro_citet">Iana etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite>.
Surprisingly, these two approaches also consistently achieve better ranking than sequential-based UEs (i.e., <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.8">GRU+MHSA+AddAtt</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.9">GRU<sub class="ltx_sub" id="S5.SS2.p1.1.9.1"><span class="ltx_text ltx_font_serif" id="S5.SS2.p1.1.9.1.1">ini</span></sub></span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.10">GRU<sub class="ltx_sub" id="S5.SS2.p1.1.10.1"><span class="ltx_text ltx_font_serif" id="S5.SS2.p1.1.10.1.1">con</span></sub></span>). Once again, we see that using categorical information alongside the textual content as input to the NE benefits all recommenders regardless of the UE family. The only exception, as previously discussed, are SE-based NNRs. Interestingly, we see that multi-feature inputs close the gap (i) in between inter-family UEs for the same base NE, and (ii) across intra-family UEs for different underlying NEs.
Most importantly, our findings corroborate earlier results from <cite class="ltx_cite ltx_citemacro_citet">Iana etÂ al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">MÃ¶ller and PadÃ³ (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib29" title="">2024</a>)</cite> that the complexity of user encoders can be simplified, particularly when the bi-encoder NNR leverages language models pretrained, or even domain-specialized, on large-scale corpora, to obtain news representations.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The heatmap in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F6" title="Figure 6 â€£ 5.2. User Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">6</span></a> shows the Jaccard similarity scores for the top-10 recommendations, for the different UE families, when using only the title as input to the NE.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The results with multi-feature input are similar, and we omit them for the sake of brevity.</span></span></span> We exclude <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.1.1">GRU<sub class="ltx_sub" id="S5.SS2.p2.1.1.1"><span class="ltx_text ltx_font_serif" id="S5.SS2.p2.1.1.1.1">con</span></sub></span> from further analysis as it underperforms the counterpart variant <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.1.2">GRU<sub class="ltx_sub" id="S5.SS2.p2.1.2.1"><span class="ltx_text ltx_font_serif" id="S5.SS2.p2.1.2.1.1">ini</span></sub></span>.
We observe that in terms of retrieval similarity, the NNRs are clustered based on the underlying NE family, regardless of the UE used. Once again, the results indicate a large overlap of recommended news (i.e., on average, of at least 7 out of 10 recommendations) for the UEs within these clusters. Moreover, we observe comparable similarity patterns across inter-family UEs for the same NE family; different NEs change only the absolute magnitude of the Jaccard similarity scores. Within intra-family clusters of NEs, the findings re-affirm that <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.1.3">LF</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.1.4">AddAtt</span> have the highest overlap in terms of the top-10 recommended articles; their generated recommendations usually differ in at most 2 or 3 items, on average. This is intuitive, as <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.1.5">LF</span> represents a special case of <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.1.6">AddAtt</span>, where the attention weights are all equal, and set to the inverse of the userâ€™s history length.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.3">We delve deeper into the retrieval similarity of UE architectures. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F4.sf2" title="In Figure 4 â€£ 5.1. News Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">4(b)</span></a> shows the Jaccard similarity of <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.1">LF</span> against the other user modeling approaches for a recommender with a <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.2">CNN+AddAtt</span>-based NE, for different values of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.p3.1.m1.1"><semantics id="S5.SS2.p3.1.m1.1a"><mi id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><ci id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.1.m1.1d">italic_k</annotation></semantics></math>. As in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.SS1" title="5.1. News Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">5.1</span></a>, the Jaccard similarity of recommended news is sensitive to the value of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.p3.2.m2.1"><semantics id="S5.SS2.p3.2.m2.1a"><mi id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><ci id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.2.m2.1d">italic_k</annotation></semantics></math>, with scores converging toward 1 for larger values of <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.p3.3.m3.1"><semantics id="S5.SS2.p3.3.m3.1a"><mi id="S5.SS2.p3.3.m3.1.1" xref="S5.SS2.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.3.m3.1b"><ci id="S5.SS2.p3.3.m3.1.1.cmml" xref="S5.SS2.p3.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.3.m3.1d">italic_k</annotation></semantics></math>. On the one hand, the scores of sequential UEs (<span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.3">GRU<sub class="ltx_sub" id="S5.SS2.p3.3.3.1"><span class="ltx_text ltx_font_serif" id="S5.SS2.p3.3.3.1.1">ini</span></sub></span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.4">GRU+MHSA+AddAtt</span>) are clustered closely together, which can be explained by their shared sequential component. However, the retrieved articles appear to be more similar between sequential and non-sequential UEs (e.g., higher Jaccard similarity between <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.5">GRU+MHSA+AddAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.6">MHSA+AddAtt</span>) across intra-family NEs, than between sequential UEs. This could be attributed to the architectural differences of the two models, among which <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.7">GRU+MHSA+AddAtt</span> employs an attention network similar to that of <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.3.8">MHSA+AddAtt</span>. These mixed results, combined with the better performing non-sequential UEs, call into question the efficiency of modeling the news recommendation task as a sequential recommendation problem <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib58" title="">2022c</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">We shift our attention to the pair-wise similarity of user embeddings generated by the different types of UEs for the users in the test set, illustrated in the heatmap of Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#S5.F7" title="Figure 7 â€£ 5.2. User Encoder Architectures â€£ 5. Results and Discussion â€£ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders"><span class="ltx_text ltx_ref_tag">7</span></a>. We additionally perform a hierarchical clustering on the heatmap to identify clusters of similar UEs <cite class="ltx_cite ltx_citemacro_citep">(Waskom, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib44" title="">2021</a>)</cite>. In contrast to retrieval results, we find that the architecturally comparable families of UEs dictate the similarity of embeddings, regardless of the underlying NE used. Most surprisingly, we find that although the top-recommended news by <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.1">GRU<sub class="ltx_sub" id="S5.SS2.p4.1.1.1"><span class="ltx_text ltx_font_serif" id="S5.SS2.p4.1.1.1.1">ini</span></sub></span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.2">GRU+MHSA+AddAtt</span> moderately overlap, their user representations are highly dissimilar. Moreover, the latent representations of <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.3">AddAtt</span> appear more similar to other attention-based UEs than with <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.4">LF</span>. This could be explained by the fact that as a particular case of <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.5">AddAtt</span>, the parameterless <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.6">LF</span> does not reshape the embedding space, as it simply computes an average of the userâ€™s clicked news. Nonetheless, these differences in the representational similarities of UEs also do not appear to directly correlate with more dissimilar retrieval performance. This suggests that in real-world applications, the lightweight and conceptually simple <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.7">LF</span> constitutes an equally effective and more efficient alternative to <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.8">AddAtt</span>, and especially, to more complex architectures.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Key Takeaways</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Following the results of our in-depth analysis of the embedding and retrieval similarity of the most prominent news and user encoder architectures, we highlight several key takeaways.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">Semantic Richness is Key.</span>
Our analysis demonstrates that the semantic richness of news encoders, achieved either through multi-feature input or contextualized language models, significantly outweighs the impact of UEs. This is particularly the case when initializing news representations with large-scale PLMs. Additionally, contextualized language models can effectively capture semantic nuances, such as topical information, without heavily relying on categorical annotations. From a practical standpoint, this reduces the need for manual or automatic feature engineering, streamlining the NNR design process. We hence argue that research on news encoding should focus more on leveraging and adapting existing semantically informed, contextualized language models for the task of news recommendation, rather than on incrementally modifying existing architectures.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p3.1.1">User Encoders Can be Considerably Simplified.</span>
Our findings show that retrieval similarity is primarily influenced by the underlying NE family, rather than the specific UE used. At the same time, simpler approaches such as <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p3.1.2">LF</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p3.1.3">AddAtt</span> not only result in significantly better ranked results, but their retrieved items largely overlap with those recommended by more complex UE architectures. These findings thus render simpler architectures as better and more lightweight user modeling alternatives. Additionally, the high retrieval similarity between parameter-free (i.e., <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p3.1.4">LF</span>) and parameterized (e.g., <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p3.1.5">AddAtt</span>) encoders heavily indicates that, in practice, there is little empirical justification for an additional parameterized component in the news recommender system. Furthermore, the similarity of sequential and non-sequential encoders indicates that treating news recommendation as a sequential problem might be sub-optimal. We speculate that the high item churn characteristic of news, combined with short user histories, limit the benefits of differentiating between long and short-term user preferences, in contrast to other domains, such as movie or book recommendation. In conclusion, in line with <cite class="ltx_cite ltx_citemacro_citet">MÃ¶ller and PadÃ³ (<a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib29" title="">2024</a>)</cite>, we posit that user modeling should not focus exclusively on the architectural component, but instead, should pay closer attention to the usersâ€™ motivations to consume certain news, on the one hand, and to collecting richer and more accurate user (relevance) feedback, on the other hand.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p4.1.1">More Rigorous Evaluation is Needed for Better Model Selection.</span>
Our findings, along with recent research <cite class="ltx_cite ltx_citemacro_citep">(MÃ¶ller and PadÃ³, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib28" title="">2022</a>; Iana etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib14" title="">2023b</a>; MÃ¶ller and PadÃ³, <a class="ltx_ref" href="https://arxiv.org/html/2410.01470v1#bib.bib29" title="">2024</a>)</cite>, highlight the limitations of current evaluation practices in news recommendation. By focusing solely on performance metrics, we risk overlooking critical aspects of model behavior, leading to sub-optimal component selection and incremental model advancement. Therefore, we advocate for a more comprehensive and rigorous evaluation approach. Ablation studies should consider the broader architectural context, and together with model comparisons, should extend beyond performance-based evaluation to include a more granular behavioral and representational analysis. This would provide a more nuanced understanding of model similarities and differences, guiding researchers and practitioners toward better informed model selection decisions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Despite the central role played by encoder architectures in neural news recommenders, their advancement and understanding is generally limited to one-sided evaluation in terms of recommendation performance.
In this work, we conducted a comprehensive evaluation of encoder architectures in neural news recommenders, by systematically analyzing their (i) representation similarity, (ii) overlap of generated recommendations, and (iii) overall recommendation performance.
Evaluations of recommenders on standard benchmarks often reveal insignificant performance differences between compared models or among their ablated components. Consequently, our analysis of differences in representational similarity and retrieval overlap of neural news recommenders serves as a complementary evaluation tool for understanding the relationship between the architectural design, behavior, and downstream performance of models.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Our findings offer more nuanced insights into the interplay of news and user encoders, and challenge the assumption that complex encoding techniques are essential for accurate news recommendation. We demonstrate that simpler, yet equally effective architectures can yield comparable results. This underscores the importance of understanding recommendersâ€™ behavior from multiple perspectives, and of balancing model complexity with performance.
Specifically, we emphasize three key takeaways: (1) the crucial role of semantic richness in news encoders, (2) the potential for simplifying user encoders without sacrificing accuracy, and (3) the need for more rigorous evaluation and ablation studies to inform architectural design choices.
By fostering a more transparent and nuanced understanding of encoder architectures in neural news recommenders, we hope to guide researchers and practitioners toward more efficient and effective model designs.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
The authors acknowledge support by the state of Baden-WÃ¼rttemberg through bwHPC and the German Research Foundation (DFG) through grant INST 35/1597-1 FUGG. We also thank Fabian David Schmidt for proof-reading.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">An etÂ al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu, and Xing Xie. 2019.

</span>
<span class="ltx_bibblock">Neural news recommendation with long-and short-term user representations. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>. 336â€“345.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/P19-1033" title="">https://doi.org/10.18653/v1/P19-1033</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau etÂ al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014.

</span>
<span class="ltx_bibblock">Neural machine translation by jointly learning to align and translate.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">ICLR</em> (2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Davis Brown, Charles Godfrey, Nicholas Konz, Jonathan Tu, and Henry Kvinge. 2023.

</span>
<span class="ltx_bibblock">Understanding the Inner-workings of Language Models Through Representation Dissimilarity. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>. 6543â€“6558.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-main.403" title="">https://doi.org/10.18653/v1/2023.emnlp-main.403</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caspari etÂ al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Laura Caspari, KanishkaÂ Ghosh Dastidar, Saber Zerhoudi, Jelena Mitrovic, and Michael Granitzer. 2024.

</span>
<span class="ltx_bibblock">Beyond Benchmarks: Evaluating Embedding Model Similarity for Retrieval Augmented Generation Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">arXiv preprint arXiv:2407.08275</em> (2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2407.08275" title="">https://doi.org/10.48550/arXiv.2407.08275</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho etÂ al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart van MerriÃ«nboer, Ã‡aÄŸlar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014.

</span>
<span class="ltx_bibblock">Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>. 1724â€“1734.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3115/v1/D14-1179" title="">https://doi.org/10.3115/v1/D14-1179</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freestone and Santu (2024)</span>
<span class="ltx_bibblock">
Matthew Freestone and Shubhra KantiÂ Karmaker Santu. 2024.

</span>
<span class="ltx_bibblock">Word Embeddings Revisited: Do LLMs Offer Something New?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2402.11094</em> (2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2402.11094" title="">https://doi.org/10.48550/arXiv.2402.11094</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Jie Gao, Xin Xin, Junshuai Liu, Rui Wang, Jing Lu, Biao Li, Xin Fan, and Ping Guo. 2018.

</span>
<span class="ltx_bibblock">Fine-grained deep knowledge-aware network for news recommendation with self-attention. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)</em>. IEEE, 81â€“88.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/WI.2018.0-104" title="">https://doi.org/10.1109/WI.2018.0-104</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ge etÂ al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Suyu Ge, Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2020.

</span>
<span class="ltx_bibblock">Graph enhanced representation learning for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the web conference 2020</em>. 2863â€“2869.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3366423.3380050" title="">https://doi.org/10.1145/3366423.3380050</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gretton etÂ al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard SchÃ¶lkopf. 2005.

</span>
<span class="ltx_bibblock">Measuring statistical dependence with Hilbert-Schmidt norms. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">International conference on algorithmic learning theory</em>. Springer, 63â€“77.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han etÂ al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Songqiao Han, Hailiang Huang, and Jiangwei Liu. 2021.

</span>
<span class="ltx_bibblock">Neural news recommendation with event extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">arXiv preprint arXiv:2111.05068</em> (2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2111.05068" title="">https://doi.org/10.48550/arXiv.2111.05068</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013.

</span>
<span class="ltx_bibblock">Learning deep structured semantic models for web search using clickthrough data. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management</em>. 2333â€“2338.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2505515.2505665" title="">https://doi.org/10.1145/2505515.2505665</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iana etÂ al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Andreea Iana, Goran GlavaÅ¡, and Heiko Paulheim. 2023a.

</span>
<span class="ltx_bibblock">NewsRecLib: A PyTorch-Lightning Library for Neural News Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>. 296â€“310.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-demo.26" title="">https://doi.org/10.18653/v1/2023.emnlp-demo.26</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iana etÂ al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Andreea Iana, Goran Glavas, and Heiko Paulheim. 2023b.

</span>
<span class="ltx_bibblock">Simplifying content-based neural news recommendation: On user modeling and training objectives. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 2384â€“2388.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3592062" title="">https://doi.org/10.1145/3539618.3592062</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iana etÂ al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2023c)</span>
<span class="ltx_bibblock">
Andreea Iana, Goran GlavaÅ¡, and Heiko Paulheim. 2023c.

</span>
<span class="ltx_bibblock">Train once, use flexibly: A modular framework for multi-aspect neural news recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">arXiv preprint arXiv:2307.16089</em> (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2307.16089" title="">https://doi.org/10.48550/arXiv.2307.16089</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iana etÂ al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Andreea Iana, FabianÂ David Schmidt, Goran GlavaÅ¡, and Heiko Paulheim. 2024.

</span>
<span class="ltx_bibblock">News Without Borders: Domain Adaptation of Multilingual Sentence Embeddings for Cross-lingual News Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">arXiv preprint arXiv:2406.12634</em> (2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2406.12634" title="">https://doi.org/10.48550/arXiv.2406.12634</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia etÂ al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Qinglin Jia, Jingjie Li, Qi Zhang, Xiuqiang He, and Jieming Zhu. 2021.

</span>
<span class="ltx_bibblock">RMBERT: News recommendation via recurrent reasoning memory network over BERT. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval</em>. 1773â€“1777.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3404835.3463234" title="">https://doi.org/10.1145/3404835.3463234</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimi etÂ al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Mozhgan Karimi, Dietmar Jannach, and Michael Jugovac. 2018.

</span>
<span class="ltx_bibblock">News recommender systemsâ€“Survey and roads ahead.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Information Processing &amp; Management</em> 54, 6 (2018), 1203â€“1227.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.ipm.2018.04.008" title="">https://doi.org/10.1016/j.ipm.2018.04.008</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim (2014)</span>
<span class="ltx_bibblock">
Yoon Kim. 2014.

</span>
<span class="ltx_bibblock">Convolutional Neural Networks for Sentence Classification. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>. Association for Computational Linguistics, Doha, Qatar, 1746â€“1751.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3115/v1/D14-1181" title="">https://doi.org/10.3115/v1/D14-1181</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2014)</span>
<span class="ltx_bibblock">
DiederikÂ P Kingma and Jimmy Ba. 2014.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">ICLR</em> (2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klabunde etÂ al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Max Klabunde, MehdiÂ Ben Amor, Michael Granitzer, and Florian Lemmerich. 2023a.

</span>
<span class="ltx_bibblock">Towards Measuring Representational Similarity of Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">UniReps: the First Workshop on Unifying Representations in Neural Models</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klabunde etÂ al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Max Klabunde, Tobias Schumacher, Markus Strohmaier, and Florian Lemmerich. 2023b.

</span>
<span class="ltx_bibblock">Similarity of neural network models: A survey of functional and representational measures.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">arXiv preprint arXiv:2305.06329</em> (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.06329" title="">https://doi.org/10.48550/arXiv.2305.06329</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kornblith etÂ al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton. 2019.

</span>
<span class="ltx_bibblock">Similarity of neural network representations revisited. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">International conference on machine learning</em>. PMLR, 3519â€“3529.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jian Li, Jieming Zhu, Qiwei Bi, Guohao Cai, Lifeng Shang, Zhenhua Dong, Xin Jiang, and Qun Liu. 2022.

</span>
<span class="ltx_bibblock">MINER: Multi-interest matching network for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">Findings of the Association for Computational Linguistics: ACL 2022</em>. 343â€“352.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.findings-acl.29" title="">https://doi.org/10.18653/v1/2022.findings-acl.29</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Danyang Liu, Jianxun Lian, Shiyin Wang, Ying Qiao, Jiun-Hung Chen, Guangzhong Sun, and Xing Xie. 2020.

</span>
<span class="ltx_bibblock">KRED: Knowledge-aware document representation for news recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Proceedings of the 14th ACM Conference on Recommender Systems</em>. 200â€“209.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3383313.3412237" title="">https://doi.org/10.1145/3383313.3412237</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Rui Liu, Bin Yin, Ziyi Cao, Qianchen Xia, Yong Chen, and Dell Zhang. 2023.

</span>
<span class="ltx_bibblock">Perconet: News recommendation with explicit persona and contrastive learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">arXiv preprint arXiv:2304.07923</em> (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2304.07923" title="">https://doi.org/10.48550/arXiv.2304.07923</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">RoBERTa: A Robustly Optimized BERT Pretraining Approach.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1907.11692Â [cs.CL]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1907.11692" title="">https://arxiv.org/abs/1907.11692</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MÃ¶ller and PadÃ³ (2022)</span>
<span class="ltx_bibblock">
Lucas MÃ¶ller and Sebastian PadÃ³. 2022.

</span>
<span class="ltx_bibblock">Understanding the Relation of User and News Representations in Content-Based Neural News Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Joint Proceedings of 10th International Workshop on News Recommendation and Analytics (INRAâ€™22) and the Third International Workshop on Investigating Learning During Web Search (IWILDSâ€˜22) co-located with the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIRâ€™22)</em> (2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ceur-ws.org/Vol-3411/INRA-paper2.pdf" title="">https://ceur-ws.org/Vol-3411/INRA-paper2.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MÃ¶ller and PadÃ³ (2024)</span>
<span class="ltx_bibblock">
Lucas MÃ¶ller and Sebastian PadÃ³. 2024.

</span>
<span class="ltx_bibblock">Explaining Neural News Recommendation with Attributions onto Reading Histories.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">ACM Transactions on Intelligent Systems and Technology</em> (2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3673233" title="">https://doi.org/10.1145/3673233</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pennington etÂ al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Jeffrey Pennington, Richard Socher, and ChristopherÂ D Manning. 2014.

</span>
<span class="ltx_bibblock">Glove: Global vectors for word representation. In <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</em>. 1532â€“1543.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3115/v1/D14-1162" title="">https://doi.org/10.3115/v1/D14-1162</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi etÂ al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Tao Qi, Fangzhao Wu, Chuhan Wu, and Yongfeng Huang. 2021.

</span>
<span class="ltx_bibblock">PP-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>. 5457â€“5467.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2021.acl-long.424" title="">https://doi.org/10.18653/v1/2021.acl-long.424</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi etÂ al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Tao Qi, Fangzhao Wu, Chuhan Wu, and Yongfeng Huang. 2022.

</span>
<span class="ltx_bibblock">News recommendation with candidate-aware user modeling. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 1917â€“1921.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3477495.3531778" title="">https://doi.org/10.1145/3477495.3531778</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi etÂ al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang, and Xing Xie. 2020.

</span>
<span class="ltx_bibblock">Privacy-Preserving News Recommendation Model Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Findings of the Association for Computational Linguistics: EMNLP 2020</em>. 1423â€“1432.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.findings-emnlp.128" title="">https://doi.org/10.18653/v1/2020.findings-emnlp.128</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raza and Ding (2021)</span>
<span class="ltx_bibblock">
Shaina Raza and Chen Ding. 2021.

</span>
<span class="ltx_bibblock">Deep dynamic neural network to trade-off between accuracy and diversity in a news recommender system.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2103.08458</em> (2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2103.08458" title="">https://doi.org/10.48550/arXiv.2103.08458</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raza and Ding (2022)</span>
<span class="ltx_bibblock">
Shaina Raza and Chen Ding. 2022.

</span>
<span class="ltx_bibblock">News recommender system: a review of recent progress, challenges, and opportunities.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Artificial Intelligence Review</em> (2022), 1â€“52.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10462-021-10043-x" title="">https://doi.org/10.1007/s10462-021-10043-x</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Santosh etÂ al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
TYSS Santosh, Avirup Saha, and Niloy Ganguly. 2020.

</span>
<span class="ltx_bibblock">MVL: Multi-view learning for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 1873â€“1876.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401294" title="">https://doi.org/10.1145/3397271.3401294</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheu and Li (2020)</span>
<span class="ltx_bibblock">
Heng-Shiou Sheu and Sheng Li. 2020.

</span>
<span class="ltx_bibblock">Context-aware graph embedding for session-based news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 14th ACM Conference on Recommender Systems</em>. 657â€“662.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3383313.3418477" title="">https://doi.org/10.1145/3383313.3418477</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shivaram etÂ al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Karthik Shivaram, Ping Liu, Matthew Shapiro, Mustafa Bilgic, and Aron Culotta. 2022.

</span>
<span class="ltx_bibblock">Reducing cross-topic political homogenization in content-based news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Proceedings of the 16th ACM conference on Recommender Systems</em>. 220â€“228.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3546782" title="">https://doi.org/10.1145/3523227.3546782</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Yumin Sun, Fangzhou Yi, Cheng Zeng, Bing Li, Peng He, Jinxia Qiao, and Yinghui Zhou. 2021.

</span>
<span class="ltx_bibblock">A hybrid approach to news recommendation based on knowledge graph and long short-term user preferences. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">2021 IEEE International Conference on Services Computing (SCC)</em>. IEEE, 165â€“173.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/SCC53864.2021.00029" title="">https://doi.org/10.1109/SCC53864.2021.00029</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tran etÂ al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
DaiÂ Hoang Tran, Salma Hamad, Munazza Zaib, Abdulwahab Aljubairy, QuanÂ Z Sheng, WeiÂ Emma Zhang, NguyenÂ H Tran, and Nguyen LuÂ Dang Khoa. 2021.

</span>
<span class="ltx_bibblock">Deep news recommendation with contextual user profiling and multifaceted article representation. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Web Information Systems Engineeringâ€“WISE 2021: 22nd International Conference on Web Information Systems Engineering, WISE 2021, Melbourne, VIC, Australia, October 26â€“29, 2021, Proceedings, Part II 22</em>. Springer, 237â€“251.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-030-91560-5_17" title="">https://doi.org/10.1007/978-3-030-91560-5_17</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Proceedings of the 31st International Conference on Neural Information Processing Systems</em>. 6000â€“6010.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/abs/10.5555/3295222.3295349" title="">https://dl.acm.org/doi/abs/10.5555/3295222.3295349</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Hongwei Wang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018.

</span>
<span class="ltx_bibblock">DKN: Deep knowledge-aware network for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 2018 world wide web conference</em>. 1835â€“1844.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3178876.3186175" title="">https://doi.org/10.1145/3178876.3186175</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Rongyao Wang, Shoujin Wang, Wenpeng Lu, and Xueping Peng. 2022.

</span>
<span class="ltx_bibblock">News recommendation via multi-interest news sequence modelling. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 7942â€“7946.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICASSP43922.2022.9747149" title="">https://doi.org/10.1109/ICASSP43922.2022.9747149</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waskom (2021)</span>
<span class="ltx_bibblock">
MichaelÂ L Waskom. 2021.

</span>
<span class="ltx_bibblock">Seaborn: statistical data visualization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Journal of Open Source Software</em> 6, 60 (2021), 3021.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.21105/joss.03021" title="">https://doi.org/10.21105/joss.03021</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2019b)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang, and Xing Xie. 2019b.

</span>
<span class="ltx_bibblock">Neural news recommendation with attentive multi-view learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">Proceedings of the 28th International Joint Conference on Artificial Intelligence</em>. 3863â€“3869.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.24963/ijcai.2019/536" title="">https://doi.org/10.24963/ijcai.2019/536</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2019a)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Mingxiao An, Yongfeng Huang, and Xing Xie. 2019a.

</span>
<span class="ltx_bibblock">Neural news recommendation with topic-aware news representation. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">Proceedings of the 57th Annual meeting of the association for computational linguistics</em>. 1154â€“1159.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/P19-1110" title="">https://doi.org/10.18653/v1/P19-1110</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2019c)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Mingxiao An, Tao Qi, Jianqiang Huang, Yongfeng Huang, and Xing Xie. 2019c.

</span>
<span class="ltx_bibblock">Neural news recommendation with heterogeneous user behavior. In <em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)</em>. 4874â€“4883.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/D19-1493" title="">https://doi.org/10.18653/v1/D19-1493</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2019d)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Suyu Ge, Tao Qi, Yongfeng Huang, and Xing Xie. 2019d.

</span>
<span class="ltx_bibblock">Neural news recommendation with multi-head self-attention. In <em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)</em>. 6389â€“6394.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/D19-1671" title="">https://doi.org/10.18653/v1/D19-1671</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, and Yongfeng Huang. 2022a.

</span>
<span class="ltx_bibblock">Rethinking InfoNCE: How Many Negative Samples Do You Need?. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22</em>, LudÂ De Raedt (Ed.). International Joint Conferences on Artificial Intelligence Organization, 2509â€“2515.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.24963/ijcai.2022/348" title="">https://doi.org/10.24963/ijcai.2022/348</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2020c)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Yongfeng Huang, and Xing Xie. 2020c.

</span>
<span class="ltx_bibblock">Neural news recommendation with negative feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">CCF Transactions on Pervasive Computing and Interaction</em> 2 (2020), 178â€“188.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s42486-020-00044-0" title="">https://doi.org/10.1007/s42486-020-00044-0</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2021a)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Yongfeng Huang, and Xing Xie. 2021a.

</span>
<span class="ltx_bibblock">User-as-graph: User modeling with heterogeneous graph pooling for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">IJCAI</em>. 1624â€“1630.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.24963/ijcai.2021/224" title="">https://doi.org/10.24963/ijcai.2021/224</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Yongfeng Huang, and Xing Xie. 2023.

</span>
<span class="ltx_bibblock">Personalized news recommendation: Methods and challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">ACM Transactions on Information Systems</em> 41, 1 (2023), 1â€“50.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3530257" title="">https://doi.org/10.1145/3530257</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2020d)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2020d.

</span>
<span class="ltx_bibblock">SentiRec: Sentiment diversity-aware neural news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib53.3.1">Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</em>. 44â€“53.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.aacl-main.6" title="">https://aclanthology.org/2020.aacl-main.6</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2020e)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2020e.

</span>
<span class="ltx_bibblock">User Modeling with Click Preference and Reading Satisfaction for News Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">IJCAI</em>. 3023â€“3029.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.24963/ijcai.2020/418" title="">https://doi.org/10.24963/ijcai.2020/418</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2021b)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2021b.

</span>
<span class="ltx_bibblock">Empowering news recommendation with pre-trained language models. In <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 1652â€“1656.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3404835.3463069" title="">https://doi.org/10.1145/3404835.3463069</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2021c)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2021c.

</span>
<span class="ltx_bibblock">Mm-rec: multimodal news recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">arXiv preprint arXiv:2104.07407</em> (2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2104.07407" title="">https://doi.org/10.48550/arXiv.2104.07407</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2022b.

</span>
<span class="ltx_bibblock">Two Birds with One Stone: Unified Model Learning for Both Recall and Ranking in News Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">Findings of the Association for Computational Linguistics: ACL 2022</em>. 3474â€“3480.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.findings-acl.274" title="">https://doi.org/10.18653/v1/2022.findings-acl.274</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2022c)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, Chenliang Li, and Yongfeng Huang. 2022c.

</span>
<span class="ltx_bibblock">Is news recommendation a sequential recommendation task?. In <em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval</em>. 2382â€“2386.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3477495.3531862" title="">https://doi.org/10.1145/3477495.3531862</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib59.2.2.1">.</span> (2022d)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, Qi Liu, Xuan Tian, Jie Li, Wei He, Yongfeng Huang, and Xing Xie. 2022d.

</span>
<span class="ltx_bibblock">Feedrec: News feed recommendation with various user feedbacks. In <em class="ltx_emph ltx_font_italic" id="bib.bib59.3.1">Proceedings of the ACM Web Conference 2022</em>. 2088â€“2097.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3485447.3512082" title="">https://doi.org/10.1145/3485447.3512082</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib60.2.2.1">.</span> (2021d)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Xiting Wang, Yongfeng Huang, and Xing Xie. 2021d.

</span>
<span class="ltx_bibblock">Fairness-aware news recommendation with decomposed adversarial learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">Proceedings of the AAAI conference on artificial intelligence</em>, Vol.Â 35. 4462â€“4469.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/aaai.v35i5.16573" title="">https://doi.org/10.1609/aaai.v35i5.16573</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu, etÂ al<span class="ltx_text" id="bib.bib61.3.1">.</span> 2020b.

</span>
<span class="ltx_bibblock">Mind: A large-scale dataset for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib61.4.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. 3597â€“3606.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.acl-main.331" title="">https://doi.org/10.18653/v1/2020.acl-main.331</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
John Wu, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and James Glass. 2020a.

</span>
<span class="ltx_bibblock">Similarity Analysis of Contextual Word Representation Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. 4638â€“4655.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.acl-main.422" title="">https://doi.org/10.18653/v1/2020.acl-main.422</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xun etÂ al<span class="ltx_text" id="bib.bib63.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiahao Xun, Shengyu Zhang, Zhou Zhao, Jieming Zhu, Qi Zhang, Jingjie Li, Xiuqiang He, Xiaofei He, Tat-Seng Chua, and Fei Wu. 2021.

</span>
<span class="ltx_bibblock">Why do we click: visual impression-aware news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib63.3.1">Proceedings of the 29th ACM international conference on multimedia</em>. 3881â€“3890.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3474085.3475514" title="">https://doi.org/10.1145/3474085.3475514</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span class="ltx_text" id="bib.bib64.2.2.1">.</span> (2021a)</span>
<span class="ltx_bibblock">
Qi Zhang, Qinglin Jia, Chuyuan Wang, Jingjie Li, Zhaowei Wang, and Xiuqiang He. 2021a.

</span>
<span class="ltx_bibblock">AMM: Attentive multi-field matching for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib64.3.1">Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval</em>. 1588â€“1592.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3404835.3463232" title="">https://doi.org/10.1145/3404835.3463232</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span class="ltx_text" id="bib.bib65.2.2.1">.</span> (2021b)</span>
<span class="ltx_bibblock">
Qi Zhang, Jingjie Li, Qinglin Jia, Chuyuan Wang, Jieming Zhu, Zhaowei Wang, and Xiuqiang He. 2021b.

</span>
<span class="ltx_bibblock">UNBERT: User-News Matching BERT for News Recommendation.. In <em class="ltx_emph ltx_font_italic" id="bib.bib65.3.1">IJCAI</em>, Vol.Â 21. 3356â€“3362.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.24963/ijcai.2021/462" title="">https://doi.org/10.24963/ijcai.2021/462</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span class="ltx_text" id="bib.bib66.2.2.1">.</span> (2021c)</span>
<span class="ltx_bibblock">
Xuanyu Zhang, Qing Yang, and Dongliang Xu. 2021c.

</span>
<span class="ltx_bibblock">Combining explicit entity graph with implicit text information for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib66.3.1">Companion Proceedings of the Web Conference 2021</em>. 412â€“416.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3442442.3452329" title="">https://doi.org/10.1145/3442442.3452329</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 12:15:03 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
