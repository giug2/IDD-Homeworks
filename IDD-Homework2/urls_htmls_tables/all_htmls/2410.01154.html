<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting</title>
<!--Generated on Wed Oct  2 01:08:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.01154v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S1" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.SS1" title="In 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Relation Synonyms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.SS2" title="In 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Synthetic Sample Generation with Entity Filtering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.SS3" title="In 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Sentence Rephrase</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.SS4" title="In 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Self-Prompting Inference</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.SS5" title="In 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Addressing the Error Propagation Problem</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S3" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S3.SS1" title="In 3 Experimental Setup ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S3.SS2" title="In 3 Experimental Setup ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S3.SS3" title="In 3 Experimental Setup ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Baselines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S4" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results and Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S4.SS1" title="In 4 Results and Analysis ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Main Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S4.SS2" title="In 4 Results and Analysis ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Ablation Study on Different Diversity Strategies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S5" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A1" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A1.SS1" title="In Appendix A Related Works ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Zero-shot Relation Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A1.SS2" title="In Appendix A Related Works ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>LLMs for Zero-shot Relation Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A1.SS3" title="In Appendix A Related Works ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Synthetic Data Generation via LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A2" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Datasets information</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A3" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Hyperparameter Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A4" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Influence of Demonstration Quantity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A5" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Influence of Generated Data Size</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A6" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Data Generation Quality Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A7" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Comparing among Different Demonstration Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A8" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Cost of Synthetic Data Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A9" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span>General Effectiveness with LLMs of Different Sizes</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A10" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">J </span>Case Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A11" title="In Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">K </span>Prompts for LLMs</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Siyi Liu<sup class="ltx_sup" id="id10.10.id1"><span class="ltx_text ltx_font_italic" id="id10.10.id1.1">1†</span></sup>       Yang Li<sup class="ltx_sup" id="id11.11.id2"><span class="ltx_text ltx_font_italic" id="id11.11.id2.1">2</span></sup>       Jiang Li<sup class="ltx_sup" id="id12.12.id3"><span class="ltx_text ltx_font_italic" id="id12.12.id3.1">2</span></sup>      
<span class="ltx_text ltx_font_bold" id="id4.4.1">Shan Yang<sup class="ltx_sup" id="id4.4.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id4.4.1.1.1">3</span></sup></span>       <span class="ltx_text ltx_font_bold" id="id5.5.2">Yunshi Lan<sup class="ltx_sup" id="id5.5.2.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id5.5.2.1.1">4</span></sup></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id13.13.id4">1</sup>EPFL, Lausanne, Switzerland 
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id5">2</sup>MYBank, Ant Group, Beijing, China 
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.id6">3</sup>Beihang University, Beijing, China 
<br class="ltx_break"/><sup class="ltx_sup" id="id16.16.id7">4</sup>East China Normal University, Beijing, China 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id17.17.id8">ssui.liu1022@gmail.com</span>       <span class="ltx_text ltx_font_typewriter" id="id18.18.id9">ly200170@alibaba-inc.com</span>       <span class="ltx_text ltx_font_typewriter" id="id19.19.id10">lj311207@mybank.cn</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id20.20.id11">shanyang@buaa.edu.cn</span>       <span class="ltx_text ltx_font_typewriter" id="id21.21.id12">yslan@dase.ecnu.cn
<br class="ltx_break"/></span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id22.id1">Recent research in zero-shot Relation Extraction (RE) has focused on using Large Language Models (LLMs) due to their impressive zero-shot capabilities. However, current methods often perform suboptimally, mainly due to a lack of detailed, context-specific prompts needed for understanding various sentences and relations. To address this, we introduce the Self-Prompting framework, a novel method designed to fully harness the embedded RE knowledge within LLMs. Specifically, our framework employs a three-stage diversity approach to prompt LLMs, generating multiple synthetic samples that encapsulate specific relations from scratch. These generated samples act as in-context learning samples, offering explicit and context-specific guidance to efficiently prompt LLMs for RE. Experimental evaluations on benchmark datasets show our approach outperforms existing LLM-based zero-shot RE methods. Additionally, our experiments confirm the effectiveness of our generation pipeline in producing high-quality synthetic data that enhances performance.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="384" id="S1.F1.g1" src="x1.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Depiction of the three-stage synthetic sample generation pipeline, where <span class="ltx_text" id="S1.F1.4.1" style="color:#00FFFF;">blue</span> indicates candidate relations, <span class="ltx_text" id="S1.F1.5.2" style="color:#BFFF00;">green</span> signifies synonym relations, and <span class="ltx_text" id="S1.F1.6.3" style="color:#FF8000;">orange</span> highlights entities within sentences.</figcaption>
</figure><span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span><sup class="ltx_sup" id="footnotex1.1"><span class="ltx_text ltx_font_italic" id="footnotex1.1.1">†</span></sup>The work is performed when Siyi Liu is an intern in MYBank, Ant Group.</span></span></span>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent advances in Large Language Models (LLMs) have significantly progressed Natural Language Processing (NLP). Leveraging LLMs’ potential in zero-shot learning, there is growing interest in applying their capabilities to zero-shot Relation Extraction (RE) <cite class="ltx_cite ltx_citemacro_cite">Han et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib7" title="">2018</a>); Chen and Li (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib3" title="">2021</a>)</cite>, which identifies relationships between entities in text without extensive data annotation. Specifically, current methods convert the RE task into a Question Answering (QA) task by reformulating sentences as questions and candidate relations as options <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib37" title="">2023b</a>)</cite>. Further advancements integrate a self-consistency approach <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib27" title="">2022b</a>)</cite> within QA to reduce uncertainty through majority voting <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib13" title="">2023a</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, current methods frequently demonstrate suboptimal performance, mainly because of insufficient guidance for RE. The intricate demands of RE necessitate more detailed and context-specific prompts to effectively comprehend the diverse and complex nature of sentences and relations <cite class="ltx_cite ltx_citemacro_cite">Bassignana and Plank (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib2" title="">2022</a>); Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib40" title="">2023b</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Inspired by recent studies on <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Self-Prompting</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib14" title="">2022</a>); Wan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib24" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib25" title="">b</a>)</cite>—that is, <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">employing the outputs generated by LLMs themselves as prompts</span>—our research introduces a novel prompting paradigm for RE. This paradigm leverages LLMs’ inherent capabilities to create synthetic RE data tailored to specific relations. When using LLMs for RE from specific sentences, these synthetic samples, enriched with essential relational knowledge, serve as effective in-context demonstrations.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To be specific, for each distinct relation, we initially prompt LLMs to generate a corresponding sample comprising a sentence and its related relation triple. However, directly prompting LLMs to generate samples may result in a lack of <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">diversity</span> and <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">coverage</span> <cite class="ltx_cite ltx_citemacro_cite">Chung et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib6" title="">2023</a>); Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib34" title="">2024</a>)</cite>, which are crucial for in-context learning <cite class="ltx_cite ltx_citemacro_cite">Levy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib11" title="">2022</a>); Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib15" title="">2023</a>)</cite>. Consequently, to guarantee the quality and comprehensive coverage of these synthetic samples, we implement a three-stage diversification strategy:
<span class="ltx_text ltx_font_bold" id="S1.p4.1.3">1. Relation Synonyms</span>: Utilizing LLMs, we generate synonyms for each relation, broadening semantic understanding and data variability. <span class="ltx_text ltx_font_bold" id="S1.p4.1.4">2. Entity Filtering</span>: We filter out generated samples containing high-frequency entities to prevent repetitions, thereby ensuring the uniqueness of each data point. <span class="ltx_text ltx_font_bold" id="S1.p4.1.5">3. Sentence Rephrase</span>: By rephrasing generated sentences, we introduce structural variation and enhance the linguistic complexity of our dataset. The integration of these diversification methods results in a robust and varied set of synthetic data for RE. During inference, we select salient examples from this synthetic dataset as in-context demonstrations for each test sample, concatenating them with the test question to form the final input sequence for the LLM to generate the final answer.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To verify our method’s effectiveness, we evaluated it across multiple zero-shot RE datasets. Compared to previous prompting strategies for LLM-based zero-shot RE SoTA, our method significantly outperforms them. Furthermore, extensive experiments have shown that our three-stage diversification strategy substantially enhances the diversity and coverage of in-context samples, thereby boosting model performance.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Relation Synonyms</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Our methodology’s initial phase generates relation synonyms to broaden relation synonym coverage. This strategy recognizes that a dataset’s relation often represents a broad concept, covering various synonymous or semantically related terms. As detailed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">1</span></a>, Step 1, we utilize LLMs to generate <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">italic_k</annotation></semantics></math> synonyms for each targeted relation. To ensure the generated synonyms align with the relation’s meaning, we provide the description of the relation to the LLMs. We then integrate the original relation with these synonyms to form a comprehensive semantic group. This process ensures the group encompasses the original relation alongside its synonyms, enhancing the relation’s contextual comprehension.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Synthetic Sample Generation with Entity Filtering</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">After establishing semantic groups for each relation, we then prompt LLMs to create synthetic samples (as shown in Step 2 of Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">1</span></a>). However, these directly generated samples often lack sufficient entity coverage, reflecting the real world’s complexity and variability in sentence structures. Such reliance on LLMs may result in a skewed distribution of entities, favoring those frequently found in pretraining and Supervised Fine-Tuning (SFT) data <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib16" title="">2023b</a>); Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib31" title="">2023</a>)</cite>. This issue is not unique to our approach but has also been observed in other LLM-based domain-specific data generation efforts (e.g., <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib16" title="">2023b</a>); Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib31" title="">2023</a>)</cite>).</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">To ensure comprehensive entity coverage, we implement a filtration mechanism for generated samples. This method discards samples with entities appearing more than <math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">italic_n</annotation></semantics></math> times, preventing overrepresentation. Conversely, samples with less frequent entities are retained, and their occurrence counts are updated. This strategy mitigates bias towards prevalent entities, promoting a diverse and balanced entity representation in our synthetic sample collection.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Sentence Rephrase</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">In our Self-Prompting framework, semantic coverage is crucial for sample diversity. The placement of subject and object entities in sentences can vary widely, and relations may be expressed implicitly or explicitly. Thus, incorporating diverse linguistic forms in synthetic data is essential.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">To address this, we use LLMs to rephrase each sentence in the synthetic samples, creating <math alttext="r" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mi id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">italic_r</annotation></semantics></math> variants with similar meanings (as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">1</span></a>, Step 4). These rephrased versions differ in structure but maintain the original relation, whether explicit or implicit. This method enhances the range of linguistic expressions in our dataset while ensuring consistent portrayal of the relationship across different semantic representations.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Self-Prompting Inference</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">In the inference phase for a given test sentence, we retrieve <math alttext="d" class="ltx_Math" display="inline" id="S2.SS4.p1.1.m1.1"><semantics id="S2.SS4.p1.1.m1.1a"><mi id="S2.SS4.p1.1.m1.1.1" xref="S2.SS4.p1.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.1b"><ci id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.1.m1.1d">italic_d</annotation></semantics></math> semantically similar samples as in-context demonstrations. This involves encoding the test sentence with the sentence embedding model and selecting the most similar examples from our sample set using cosine similarity.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">To organize the retrieved samples effectively, we implement a ranking strategy based on similarity scores <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib17" title="">2022a</a>)</cite>, arranging samples from the lowest to the highest score. This method positions the most relevant sample nearest to the test sentence, optimizing the impact of contextually appropriate samples on the LLM’s inference process.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Addressing the Error Propagation Problem</h3>
<div class="ltx_para" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.1">Error propagation is a critical concern in complex pipelines like ours, where early inaccuracies can accumulate and adversely impact downstream tasks. For instance, if incorrect or imprecise synonyms are generated during the Relation Synonyms Generation step, these errors may cascade through subsequent stages, resulting in further inaccuracies in relation extraction and other tasks that rely on these synonyms. To mitigate this risk, we incorporate relation descriptions (as detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.SS1" title="2.1 Relation Synonyms ‣ 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">2.1</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A11.T14" title="Table 14 ‣ Appendix K Prompts for LLMs ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">14</span></a> in the appendix). This enables the language model to better grasp the context of the relations, thereby enhancing the accuracy of synonym generation, as demonstrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S4.T4" title="Table 4 ‣ 4.2 Ablation Study on Different Diversity Strategies ‣ 4 Results and Analysis ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.3" style="width:346.9pt;height:158.8pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-63.5pt,29.0pt) scale(0.731870981781986,0.731870981781986) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T1.3.3.3.4" rowspan="2"><span class="ltx_text" id="S2.T1.3.3.3.4.1">Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T1.3.3.3.5" rowspan="2"><span class="ltx_text" id="S2.T1.3.3.3.5.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S2.T1.1.1.1.1"><math alttext="m=5" class="ltx_Math" display="inline" id="S2.T1.1.1.1.1.m1.1"><semantics id="S2.T1.1.1.1.1.m1.1a"><mrow id="S2.T1.1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T1.1.1.1.1.m1.1.1.2" xref="S2.T1.1.1.1.1.m1.1.1.2.cmml">m</mi><mo id="S2.T1.1.1.1.1.m1.1.1.1" xref="S2.T1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S2.T1.1.1.1.1.m1.1.1.3" xref="S2.T1.1.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.m1.1b"><apply id="S2.T1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.m1.1.1"><eq id="S2.T1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T1.1.1.1.1.m1.1.1.1"></eq><ci id="S2.T1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.1.1.1.1.m1.1.1.2">𝑚</ci><cn id="S2.T1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S2.T1.1.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.m1.1c">m=5</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.1.m1.1d">italic_m = 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S2.T1.2.2.2.2"><math alttext="m=10" class="ltx_Math" display="inline" id="S2.T1.2.2.2.2.m1.1"><semantics id="S2.T1.2.2.2.2.m1.1a"><mrow id="S2.T1.2.2.2.2.m1.1.1" xref="S2.T1.2.2.2.2.m1.1.1.cmml"><mi id="S2.T1.2.2.2.2.m1.1.1.2" xref="S2.T1.2.2.2.2.m1.1.1.2.cmml">m</mi><mo id="S2.T1.2.2.2.2.m1.1.1.1" xref="S2.T1.2.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S2.T1.2.2.2.2.m1.1.1.3" xref="S2.T1.2.2.2.2.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.2.m1.1b"><apply id="S2.T1.2.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.2.m1.1.1"><eq id="S2.T1.2.2.2.2.m1.1.1.1.cmml" xref="S2.T1.2.2.2.2.m1.1.1.1"></eq><ci id="S2.T1.2.2.2.2.m1.1.1.2.cmml" xref="S2.T1.2.2.2.2.m1.1.1.2">𝑚</ci><cn id="S2.T1.2.2.2.2.m1.1.1.3.cmml" type="integer" xref="S2.T1.2.2.2.2.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.2.m1.1c">m=10</annotation><annotation encoding="application/x-llamapun" id="S2.T1.2.2.2.2.m1.1d">italic_m = 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S2.T1.3.3.3.3"><math alttext="m=15" class="ltx_Math" display="inline" id="S2.T1.3.3.3.3.m1.1"><semantics id="S2.T1.3.3.3.3.m1.1a"><mrow id="S2.T1.3.3.3.3.m1.1.1" xref="S2.T1.3.3.3.3.m1.1.1.cmml"><mi id="S2.T1.3.3.3.3.m1.1.1.2" xref="S2.T1.3.3.3.3.m1.1.1.2.cmml">m</mi><mo id="S2.T1.3.3.3.3.m1.1.1.1" xref="S2.T1.3.3.3.3.m1.1.1.1.cmml">=</mo><mn id="S2.T1.3.3.3.3.m1.1.1.3" xref="S2.T1.3.3.3.3.m1.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.3.3.m1.1b"><apply id="S2.T1.3.3.3.3.m1.1.1.cmml" xref="S2.T1.3.3.3.3.m1.1.1"><eq id="S2.T1.3.3.3.3.m1.1.1.1.cmml" xref="S2.T1.3.3.3.3.m1.1.1.1"></eq><ci id="S2.T1.3.3.3.3.m1.1.1.2.cmml" xref="S2.T1.3.3.3.3.m1.1.1.2">𝑚</ci><cn id="S2.T1.3.3.3.3.m1.1.1.3.cmml" type="integer" xref="S2.T1.3.3.3.3.m1.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.3.3.m1.1c">m=15</annotation><annotation encoding="application/x-llamapun" id="S2.T1.3.3.3.3.m1.1d">italic_m = 15</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.4.1">
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.4.1.1">Prec.</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.4.1.2">Rec.</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.4.1.3">F1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.4.1.4">Prec.</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.4.1.5">Rec.</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.4.1.6">F1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.4.1.7">Prec.</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.4.1.8">Rec.</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.4.1.9">F1</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.3.3.5.2.1" rowspan="7"><span class="ltx_text" id="S2.T1.3.3.5.2.1.1">Zero-shot</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.3.3.5.2.2">R-BERT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.5.2.3">39.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.5.2.4">43.27</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T1.3.3.5.2.5">41.15</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.5.2.6">26.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.5.2.7">29.69</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T1.3.3.5.2.8">27.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.5.2.9">17.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.5.2.10">18.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.5.2.11">18.03</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.3.3.6.3.1">ESIM</th>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.6.3.2">48.58</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.6.3.3">47.74</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.6.3.4">48.16</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.6.3.5">44.12</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.6.3.6">45.46</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.6.3.7">44.78</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.6.3.8">27.31</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.6.3.9">29.62</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.6.3.10">28.42</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.3.3.7.4.1">CIM</th>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.7.4.2">49.63</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.7.4.3">48.81</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.7.4.4">49.22</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.7.4.5">46.54</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.7.4.6">47.90</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.7.4.7">45.57</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.7.4.8">29.17</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.7.4.9">30.58</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.7.4.10">29.86</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.3.3.8.5.1">ZS-BERT</th>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.8.5.2">71.54</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.8.5.3">72.39</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.8.5.4">71.96</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.8.5.5">60.51</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.8.5.6">60.98</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.8.5.7">60.74</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.8.5.8">34.12</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.8.5.9">34.38</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.8.5.10">34.25</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.3.3.9.6.1">RE-Prompt (NoGen)</th>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.9.6.2">51.78</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.9.6.3">46.76</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.9.6.4">48.93</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.9.6.5">54.87</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.9.6.6">36.52</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.9.6.7">43.80</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.9.6.8">54.45</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.9.6.9">29.43</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.9.6.10">37.45</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.3.3.10.7.1">RE-Prompt</th>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.10.7.2">70.66</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.10.7.3"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.10.7.3.1">83.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.10.7.4">76.63</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.10.7.5">68.51</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.10.7.6"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.10.7.6.1">74.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.10.7.7">71.50</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.10.7.8">63.69</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.10.7.9"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.10.7.9.1">67.93</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.10.7.10">65.74</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.3.3.11.8.1">RE-Matching</th>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.11.8.2"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.11.8.2.1">78.19</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.11.8.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.11.8.3.1">78.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.11.8.4"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.11.8.4.1">78.30</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.11.8.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.11.8.5.1">74.39</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.11.8.6">73.54</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.11.8.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.11.8.7.1">73.96</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.11.8.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.11.8.8.1">67.31</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.11.8.9">67.33</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.11.8.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.11.8.10.1">67.32</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T1.3.3.12.9.1" rowspan="3"><span class="ltx_text" id="S2.T1.3.3.12.9.1.1">LLMs</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.3.3.12.9.2">Vanilla</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.12.9.3">74.45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.12.9.4">59.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T1.3.3.12.9.5">65.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.12.9.6">61.15</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.12.9.7">57.68</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T1.3.3.12.9.8">59.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.12.9.9">57.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.12.9.10">61.27</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.3.12.9.11">59.01</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.3.3.13.10.1">SumAsk</th>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.13.10.2">75.64</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.13.10.3">70.96</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.13.10.4">73.32</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.13.10.5">62.31</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.13.10.6">61.08</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T1.3.3.13.10.7">61.69</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.13.10.8">43.55</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.13.10.9">40.27</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.3.13.10.10">41.85</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3.14.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S2.T1.3.3.14.11.1">Self-Prompting</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.3.14.11.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.14.11.2.1">78.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.3.14.11.3">77.01</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T1.3.3.14.11.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.14.11.4.1">77.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.3.14.11.5"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.14.11.5.1">75.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.3.14.11.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.14.11.6.1">74.43</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T1.3.3.14.11.7"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.14.11.7.1">74.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.3.14.11.8"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.14.11.8.1">69.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.3.14.11.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.3.3.14.11.9.1">67.50</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.3.14.11.10"><span class="ltx_text ltx_font_bold" id="S2.T1.3.3.14.11.10.1">68.70</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Main results on Wiki-ZSL. We mark the best results in <span class="ltx_text ltx_font_bold" id="S2.T1.6.1">bold</span>, the second-best <span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T1.7.2">underlined</span>. The results of the baselines are retrieved from <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib13" title="">2023a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib39" title="">2023a</a>)</cite>.</figcaption>
</figure>
<figure class="ltx_table" id="S2.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T2.3" style="width:346.9pt;height:158.8pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-63.5pt,29.0pt) scale(0.731870981781986,0.731870981781986) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T2.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T2.3.3.3.4" rowspan="2"><span class="ltx_text" id="S2.T2.3.3.3.4.1">Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T2.3.3.3.5" rowspan="2"><span class="ltx_text" id="S2.T2.3.3.3.5.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S2.T2.1.1.1.1"><math alttext="m=5" class="ltx_Math" display="inline" id="S2.T2.1.1.1.1.m1.1"><semantics id="S2.T2.1.1.1.1.m1.1a"><mrow id="S2.T2.1.1.1.1.m1.1.1" xref="S2.T2.1.1.1.1.m1.1.1.cmml"><mi id="S2.T2.1.1.1.1.m1.1.1.2" xref="S2.T2.1.1.1.1.m1.1.1.2.cmml">m</mi><mo id="S2.T2.1.1.1.1.m1.1.1.1" xref="S2.T2.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S2.T2.1.1.1.1.m1.1.1.3" xref="S2.T2.1.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.1.m1.1b"><apply id="S2.T2.1.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.1.m1.1.1"><eq id="S2.T2.1.1.1.1.m1.1.1.1.cmml" xref="S2.T2.1.1.1.1.m1.1.1.1"></eq><ci id="S2.T2.1.1.1.1.m1.1.1.2.cmml" xref="S2.T2.1.1.1.1.m1.1.1.2">𝑚</ci><cn id="S2.T2.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S2.T2.1.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.1.m1.1c">m=5</annotation><annotation encoding="application/x-llamapun" id="S2.T2.1.1.1.1.m1.1d">italic_m = 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S2.T2.2.2.2.2"><math alttext="m=10" class="ltx_Math" display="inline" id="S2.T2.2.2.2.2.m1.1"><semantics id="S2.T2.2.2.2.2.m1.1a"><mrow id="S2.T2.2.2.2.2.m1.1.1" xref="S2.T2.2.2.2.2.m1.1.1.cmml"><mi id="S2.T2.2.2.2.2.m1.1.1.2" xref="S2.T2.2.2.2.2.m1.1.1.2.cmml">m</mi><mo id="S2.T2.2.2.2.2.m1.1.1.1" xref="S2.T2.2.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S2.T2.2.2.2.2.m1.1.1.3" xref="S2.T2.2.2.2.2.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.2.2.m1.1b"><apply id="S2.T2.2.2.2.2.m1.1.1.cmml" xref="S2.T2.2.2.2.2.m1.1.1"><eq id="S2.T2.2.2.2.2.m1.1.1.1.cmml" xref="S2.T2.2.2.2.2.m1.1.1.1"></eq><ci id="S2.T2.2.2.2.2.m1.1.1.2.cmml" xref="S2.T2.2.2.2.2.m1.1.1.2">𝑚</ci><cn id="S2.T2.2.2.2.2.m1.1.1.3.cmml" type="integer" xref="S2.T2.2.2.2.2.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.2.2.m1.1c">m=10</annotation><annotation encoding="application/x-llamapun" id="S2.T2.2.2.2.2.m1.1d">italic_m = 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S2.T2.3.3.3.3"><math alttext="m=15" class="ltx_Math" display="inline" id="S2.T2.3.3.3.3.m1.1"><semantics id="S2.T2.3.3.3.3.m1.1a"><mrow id="S2.T2.3.3.3.3.m1.1.1" xref="S2.T2.3.3.3.3.m1.1.1.cmml"><mi id="S2.T2.3.3.3.3.m1.1.1.2" xref="S2.T2.3.3.3.3.m1.1.1.2.cmml">m</mi><mo id="S2.T2.3.3.3.3.m1.1.1.1" xref="S2.T2.3.3.3.3.m1.1.1.1.cmml">=</mo><mn id="S2.T2.3.3.3.3.m1.1.1.3" xref="S2.T2.3.3.3.3.m1.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.3.3.m1.1b"><apply id="S2.T2.3.3.3.3.m1.1.1.cmml" xref="S2.T2.3.3.3.3.m1.1.1"><eq id="S2.T2.3.3.3.3.m1.1.1.1.cmml" xref="S2.T2.3.3.3.3.m1.1.1.1"></eq><ci id="S2.T2.3.3.3.3.m1.1.1.2.cmml" xref="S2.T2.3.3.3.3.m1.1.1.2">𝑚</ci><cn id="S2.T2.3.3.3.3.m1.1.1.3.cmml" type="integer" xref="S2.T2.3.3.3.3.m1.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.3.3.m1.1c">m=15</annotation><annotation encoding="application/x-llamapun" id="S2.T2.3.3.3.3.m1.1d">italic_m = 15</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.4.1">
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.4.1.1">Prec.</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.4.1.2">Rec.</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.4.1.3">F1</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.4.1.4">Prec.</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.4.1.5">Rec.</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.4.1.6">F1</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.4.1.7">Prec.</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.4.1.8">Rec.</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.4.1.9">F1</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.3.3.5.2.1" rowspan="7"><span class="ltx_text" id="S2.T2.3.3.5.2.1.1">Zero-shot</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.3.3.5.2.2">R-BERT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.5.2.3">42.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.5.2.4">48.61</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T2.3.3.5.2.5">45.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.5.2.6">25.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.5.2.7">33.02</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T2.3.3.5.2.8">28.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.5.2.9">16.95</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.5.2.10">19.37</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.5.2.11">18.08</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.6.3.1">ESIM</th>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.6.3.2">56.27</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.6.3.3">58.44</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.6.3.4">57.33</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.6.3.5">42.89</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.6.3.6">44.17</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.6.3.7">43.52</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.6.3.8">29.15</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.6.3.9">31.59</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.6.3.10">30.32</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.7.4.1">CIM</th>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.7.4.2">58.05</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.7.4.3">61.92</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.7.4.4">59.92</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.7.4.5">47.39</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.7.4.6">49.11</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.7.4.7">48.23</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.7.4.8">31.83</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.7.4.9">33.06</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.7.4.10">32.43</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.8.5.1">ZS-BERT</th>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.8.5.2">76.96</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.8.5.3">78.86</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.8.5.4">77.90</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.8.5.5">56.92</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.8.5.6">57.59</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.8.5.7">57.25</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.8.5.8">35.54</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.8.5.9">38.19</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.8.5.10">36.82</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.9.6.1">RE-Prompt (NoGen)</th>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.9.6.2">72.36</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.9.6.3">58.61</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.9.6.4">64.57</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.9.6.5">66.47</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.9.6.6">48.28</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.9.6.7">55.61</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.9.6.8">66.49</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.9.6.9">40.05</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.9.6.10">49.38</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.10.7.1">RE-Prompt</th>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.10.7.2">90.15</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.10.7.3">88.50</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.10.7.4">89.30</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.10.7.5">80.33</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.10.7.6">79.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.10.7.7">79.96</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.10.7.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.10.7.8.1">74.33</span></td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.10.7.9">72.51</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.10.7.10">73.40</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.11.8.1">RE-Matching</th>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.11.8.2"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.11.8.2.1">92.82</span></td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.11.8.3"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.11.8.3.1">92.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.11.8.4"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.11.8.4.1">92.58</span></td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.11.8.5"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.11.8.5.1">83.21</span></td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.11.8.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.11.8.6.1">82.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.11.8.7"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.11.8.7.1">82.93</span></td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.11.8.8">73.80</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.11.8.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.11.8.9.1">73.52</span></td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.11.8.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.11.8.10.1">73.66</span></td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T2.3.3.12.9.1" rowspan="3"><span class="ltx_text" id="S2.T2.3.3.12.9.1.1">LLMs</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.3.3.12.9.2">Vanilla</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.12.9.3">91.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.12.9.4">88.87</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T2.3.3.12.9.5">90.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.12.9.6">72.64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.12.9.7">76.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T2.3.3.12.9.8">74.34</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.12.9.9">65.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.12.9.10">65.50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.3.3.12.9.11">65.48</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.13.10.1">SumAsk</th>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.13.10.2">78.27</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.13.10.3">72.55</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.13.10.4">75.30</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.13.10.5">64.77</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.13.10.6">60.94</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.3.3.13.10.7">62.80</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.13.10.8">44.76</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.13.10.9">41.13</td>
<td class="ltx_td ltx_align_center" id="S2.T2.3.3.13.10.10">42.87</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3.14.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S2.T2.3.3.14.11.1">Self-Prompting</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T2.3.3.14.11.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.14.11.2.1">90.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T2.3.3.14.11.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.14.11.3.1">89.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T2.3.3.14.11.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.14.11.4.1">90.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T2.3.3.14.11.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.14.11.5.1">81.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T2.3.3.14.11.6"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.14.11.6.1">83.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T2.3.3.14.11.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.3.3.14.11.7.1">82.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T2.3.3.14.11.8"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.14.11.8.1">75.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T2.3.3.14.11.9"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.14.11.9.1">78.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T2.3.3.14.11.10"><span class="ltx_text ltx_font_bold" id="S2.T2.3.3.14.11.10.1">76.76</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Main results on FewRel. We mark the best results in <span class="ltx_text ltx_font_bold" id="S2.T2.6.1">bold</span>, the second-best <span class="ltx_text ltx_framed ltx_framed_underline" id="S2.T2.7.2">underlined</span>. The results of the baselines are retrieved from <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib13" title="">2023a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib39" title="">2023a</a>)</cite>.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setup</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We evaluate our methods on four RE datasets:
(1) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">FewRel</span> <cite class="ltx_cite ltx_citemacro_cite">Han et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib7" title="">2018</a>)</cite>, (2) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.2">Wiki-ZSL</span> <cite class="ltx_cite ltx_citemacro_cite">Sorokin and Gurevych (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib23" title="">2017</a>)</cite>, (3) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.3">TACRED.</span> <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib38" title="">2017</a>)</cite>, (4) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.4">SemEval</span> <cite class="ltx_cite ltx_citemacro_cite">Hendrickx et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib9" title="">2009</a>)</cite>. Further details about the dataset preprocessing and data statistics are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A2" title="Appendix B Datasets information ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Implementation Details</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In our study, we employed ChatGPT with the API version <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">gpt-3.5-turbo-0301</span>, in line with previous research <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib37" title="">2023b</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib13" title="">2023a</a>)</cite>. The text embedding model utilized was <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.2">text-embedding-ada-002</span>, accessed via the OpenAI API. For more details about hyperparameter setting on API usage and synthetic sample generation, please refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A3" title="Appendix C Hyperparameter Settings ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Baselines</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">Zero-shot Baselines</span>:
For the FewRel and WikiZSL datasets, our baseline models include R-BERT <cite class="ltx_cite ltx_citemacro_cite">Wu and He (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib30" title="">2019</a>)</cite>, ESIM <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib4" title="">2017</a>)</cite>, CIM <cite class="ltx_cite ltx_citemacro_cite">Rocktaschel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib21" title="">2016</a>)</cite>, ZS-BERT <cite class="ltx_cite ltx_citemacro_cite">Chen and Li (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib3" title="">2021</a>)</cite>, RE-Prompt <cite class="ltx_cite ltx_citemacro_cite">Chia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib5" title="">2022</a>)</cite> and RE-Matching <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib39" title="">2023a</a>)</cite>. For RE-Prompt, the NoGen variant represents outcomes without data generation. Regarding TACRED and SemEval, our baseline comparisons involve NLI <cite class="ltx_cite ltx_citemacro_cite">Sainz et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib22" title="">2021</a>)</cite> and SuRE <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib19" title="">2022</a>)</cite>. Here, the underlying base models are DeBERTa-XLarge <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib8" title="">2020</a>)</cite> for NLI and PEGASUS-Large <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib35" title="">2020</a>)</cite> for SuRE. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.2">LLMs Baselines</span>:
In evaluating prompt-based LLM baselines, we selected SumAsk <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib13" title="">2023a</a>)</cite> and QA4RE <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib37" title="">2023b</a>)</cite> for comparison. We also present the performance using a vanilla prompt strategy (denoted as <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.3">Vanilla</span>). This approach involves directly prompting LLMs to deduce the relation within a sentence, absent any in-context demonstrations (<math alttext="d=0" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">d</mi><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><eq id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></eq><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑑</ci><cn id="S3.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">d=0</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_d = 0</annotation></semantics></math>).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results and Analysis</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Main Results</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Our evaluation of zero-shot prompting in LLMs, conducted on the FewRel and Wiki-ZSL datasets (as detailed in Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.T1" title="Table 1 ‣ 2.5 Addressing the Error Propagation Problem ‣ 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S2.T2" title="Table 2 ‣ 2.5 Addressing the Error Propagation Problem ‣ 2 Methodology ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">2</span></a>), shows competitive performance against existing zero-shot RE methods. Notably, our Self-Prompting technique significantly enhances ChatGPT’s performance over Vanilla prompting, outperforming the RE-Prompt method in most scenarios and markedly surpassing the SumAsk prompt strategy.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">As the number of unseen relations (<math alttext="m" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_m</annotation></semantics></math>) increases, predicting the correct relation becomes more challenging due to a broader range of choices. However, the benefits of Self-Prompting become more apparent, while Vanilla and SumAsk approaches show significant performance declines. This is likely because in-context demonstrations effectively narrow down potential relations. As a result, Self-Prompting better guides LLMs in inferring correct relations and demonstrates greater resilience with increasing relations.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Further validation is demonstrated through the application of our method on the TACRED and SemEval datasets. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S4.T3" title="Table 3 ‣ 4.1 Main Results ‣ 4 Results and Analysis ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">3</span></a>, our Self-Prompting technique achieved the highest F1 score on the SemEval dataset and the second-highest on TACRED, outperforming other zero-shot methods and significantly exceeding the performance of the QA4RE prompt strategy. This highlights the effectiveness of our approach, particularly given QA4RE’s established performance.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.2" style="width:173.4pt;height:90.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-50.8pt,26.6pt) scale(0.630582174266228,0.630582174266228) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T3.2.2.3.1.1">Datasets</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T3.2.2.3.1.2">TACRED</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T3.2.2.3.1.3">SemEval</th>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.4.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T3.2.2.4.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.4.2.2">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.4.2.3">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.4.2.4">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.4.2.5">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.4.2.6">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.4.2.7">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.1.1">NLI<sub class="ltx_sub" id="S4.T3.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.1.1.1.1.1">DeBERTa</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.1.1.1.2.1">42.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.3.1">76.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.1.1.1.4.1">55.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.5">22.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.6">25.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1.7">23.7</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.2.1">SuRE<sub class="ltx_sub" id="S4.T3.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.1.1.1">PEGASUS</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.2">13.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.3">51.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.4">21.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.5">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.6">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.7">0.0</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.5.1.1">Vanilla</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.5.1.2">32.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.5.1.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.2.2.5.1.3.1">74.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.5.1.4">44.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.5.1.5">18.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.5.1.6">20.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.5.1.7">19.4</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.6.2.1">SumAsk</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.6.2.2.1">62.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.3">53.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.4"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.6.2.4.1">57.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.7">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.7.3.1">QA4RE</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.2">32.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.3">68.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.4">44.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.2.2.7.3.5.1">29.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.2.2.7.3.6.1">35.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.2.2.7.3.7.1">32.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" id="S4.T3.2.2.8.4.1">Self-Prompting</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.2.2.8.4.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.2.2.8.4.2.1">56.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.2.2.8.4.3">57.5</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.2.2.8.4.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.2.2.8.4.4.1">57.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.2.2.8.4.5"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.8.4.5.1">55.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.2.2.8.4.6"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.8.4.6.1">50.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.2.2.8.4.7"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.8.4.7.1">52.7</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Main results on TACRED and SemEval. We mark the best results in <span class="ltx_text ltx_font_bold" id="S4.T3.5.1">bold</span>, the second-best <span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.6.2">underlined</span>. The results of the baselines are retrieved from <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib37" title="">2023b</a>)</cite></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation Study on Different Diversity Strategies</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In our ablation study, we systematically examine the impact of different components of our synthetic data generation method on the FewRel and Wiki-ZSL datasets. The absence of each component is denoted by a specific condition in our experiments: <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.1">w/o Rephrasing</span> (omission of sentence rephrasing), <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.2">w/o Synonyms</span> (exclusion of relation synonyms generation), <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.3">w/o Entity Filtering</span> (absence of entity frequency filtering), <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.4">w/o All</span> (direct generation without any enhancements), <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.5">Vanilla</span> (zero-shot learning without any generated samples, serving as a baseline), and <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.6">Complete</span> (all diversification strategies are included).</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">As we can see in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#S4.T4" title="Table 4 ‣ 4.2 Ablation Study on Different Diversity Strategies ‣ 4 Results and Analysis ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">4</span></a>, the findings emphasize the importance of each component. Removing sentence rephrasing slightly decreases Precision and F1 scores. Excluding relation synonym generation results in a more substantial drop across all metrics, highlighting the importance of synonyms for capturing semantic breadth. Omitting entity frequency filtering significantly impacts Recall, indicating that entity variety is crucial for comprehensive relation extraction.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.3" style="width:195.1pt;height:94.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-51.6pt,24.9pt) scale(0.654241175851841,0.654241175851841) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T4.3.1.1.1.1">Strategy</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T4.3.1.1.1.2">Wiki-ZSL</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T4.3.1.1.1.3">FewRel</th>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T4.3.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.3.1.2.2.2">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.3.1.2.2.3">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.3.1.2.2.4">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.3.1.2.2.5">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.3.1.2.2.6">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.3.1.2.2.7">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.3.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.3.1.3.1.1">Vanilla</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.3.1.2">70.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.3.1.3">72.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.3.1.4">71.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.3.1.5">81.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.3.1.6">78.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.3.1.7">80.1</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.3.1.4.2.1">w/o Synonyms</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.4.2.2">73.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.4.2.3">73.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.4.2.4">73.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.4.2.5">82.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.4.2.6">80.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.4.2.7">81.3</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.3.1.5.3.1">w/o Entity Filtering</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.3.2">74.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.3.3">75.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.3.4">75.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.3.5">82.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.3.6">80.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.3.7">81.7</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.3.1.6.4.1">w/o Rephrase</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.4.2">77.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.4.3">75.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.4.4">76.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.4.5">84.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.4.6">81.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.4.7">83.2</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.3.1.7.5.1">w/o All</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.7.5.2">65.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.7.5.3">67.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.7.5.4">66.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.7.5.5">78.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.7.5.6">81.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.7.5.7">80.0</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T4.3.1.8.6.1">Complete</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.8.6.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.8.6.2.1">82.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.8.6.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.8.6.3.1">77.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.8.6.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.8.6.4.1">80.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.8.6.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.8.6.5.1">85.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.8.6.6"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.8.6.6.1">83.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.8.6.7"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.8.6.7.1">84.3</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance comparison of different strategies on FewRel and Wiki-ZSL datasets (<math alttext="m=10" class="ltx_Math" display="inline" id="S4.T4.2.m1.1"><semantics id="S4.T4.2.m1.1b"><mrow id="S4.T4.2.m1.1.1" xref="S4.T4.2.m1.1.1.cmml"><mi id="S4.T4.2.m1.1.1.2" xref="S4.T4.2.m1.1.1.2.cmml">m</mi><mo id="S4.T4.2.m1.1.1.1" xref="S4.T4.2.m1.1.1.1.cmml">=</mo><mn id="S4.T4.2.m1.1.1.3" xref="S4.T4.2.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.2.m1.1c"><apply id="S4.T4.2.m1.1.1.cmml" xref="S4.T4.2.m1.1.1"><eq id="S4.T4.2.m1.1.1.1.cmml" xref="S4.T4.2.m1.1.1.1"></eq><ci id="S4.T4.2.m1.1.1.2.cmml" xref="S4.T4.2.m1.1.1.2">𝑚</ci><cn id="S4.T4.2.m1.1.1.3.cmml" type="integer" xref="S4.T4.2.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.m1.1d">m=10</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.m1.1e">italic_m = 10</annotation></semantics></math>).</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Moreover, directly prompting LLMs to generate samples and using them for inference impairs the model’s performance, as evidenced by the w/o All condition, which underperforms compared to the Vanilla baseline. This suggests that unrefined sample generation can adversely affect the quality of RE. In contrast, our method (Complete), which incorporates all techniques, consistently outperforms the other conditions. It notably secures the highest Precision, Recall, and F1 scores across both datasets, confirming our comprehensive approach’s effectiveness.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this study, we introduced the Self-Prompting framework to optimize zero-shot RE in LLMs. Our three-stage diversification strategy generates synthetic samples, enhancing LLMs’ accuracy and efficiency in RE. Experimental results on benchmark datasets demonstrate our method’s effectiveness, surpassing existing LLM-based zero-shot RE techniques. Further experiments confirm that our strategy successfully addresses the challenges of diversity and coverage in synthetic sample generation, thereby improving model performance.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">While our Self-Prompting method demonstrates promising outcomes in zero-shot RE, it also presents certain limitations. Firstly, the selection of appropriate in-context demonstrations from synthetic datasets requires further exploration, as improper samples may introduce noise, adversely affecting LLM performance in zero-shot RE. Additionally, the performance of our Self-Prompting method on domain-specific data remains uncertain, given that domain-specific data generation poses an ongoing challenge. We acknowledge these issues and leave them for future work to address.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This work employs text generated by Large Language Models (LLMs), which may inadvertently produce content with ethical or safety concerns. However, given that ChatGPT, the LLM utilized in our experiments, is rigorously designed to minimize the generation of untrustworthy and harmful information, and considering the specific context of zero-shot relation extraction, we contend that the ethical considerations related to this research are limited. Consequently, a detailed discussion of these issues is deemed unnecessary.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.16609" title="">Qwen technical report</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bassignana and Plank (2022)</span>
<span class="ltx_bibblock">
Elisa Bassignana and Barbara Plank. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-srw.7" title="">What do you mean by relation extraction? a survey on datasets and study on scientific relation classification</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</em>, pages 67–83, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Li (2021)</span>
<span class="ltx_bibblock">
Chih-Yao Chen and Cheng-Te Li. 2021.

</span>
<span class="ltx_bibblock">Zs-bert: Towards zero-shot relation extraction with attribute representation learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 3470–3479.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2017)</span>
<span class="ltx_bibblock">
Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, and Diana Inkpen. 2017.

</span>
<span class="ltx_bibblock">Enhanced lstm for natural language inference.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1657–1668.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chia et al. (2022)</span>
<span class="ltx_bibblock">
Yew Ken Chia, Lidong Bing, Soujanya Poria, and Luo Si. 2022.

</span>
<span class="ltx_bibblock">Relationprompt: Leveraging prompts to generate synthetic data for zero-shot relation triplet extraction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Findings of the Association for Computational Linguistics: ACL 2022</em>, pages 45–57.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. (2023)</span>
<span class="ltx_bibblock">
John Chung, Ece Kamar, and Saleema Amershi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.34" title="">Increasing diversity while maintaining accuracy: Text data generation with large language models and human interventions</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 575–593, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2018)</span>
<span class="ltx_bibblock">
Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong Sun. 2018.

</span>
<span class="ltx_bibblock">Fewrel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020.

</span>
<span class="ltx_bibblock">Deberta: Decoding-enhanced bert with disentangled attention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrickx et al. (2009)</span>
<span class="ltx_bibblock">
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid Ó Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano, and Stan Szpakowicz. 2009.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W09-2415" title="">SemEval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-2009)</em>, pages 94–99, Boulder, Colorado. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al. (2022)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in neural information processing systems</em>, 35:22199–22213.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levy et al. (2022)</span>
<span class="ltx_bibblock">
Itay Levy, Ben Bogin, and Jonathan Berant. 2022.

</span>
<span class="ltx_bibblock">Diverse demonstrations improve in-context compositional generalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2212.06800</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levy et al. (2017)</span>
<span class="ltx_bibblock">
Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer. 2017.

</span>
<span class="ltx_bibblock">Zero-shot relation extraction via reading comprehension.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</em>, pages 333–342.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
Guozheng Li, Peng Wang, and Wenjun Ke. 2023a.

</span>
<span class="ltx_bibblock">Revisiting large language models as zero-shot relation extractors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2310.05028</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Junlong Li, Zhuosheng Zhang, and Hai Zhao. 2022.

</span>
<span class="ltx_bibblock">Self-prompting large language models for open-domain qa.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2212.08635</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Qiu (2023)</span>
<span class="ltx_bibblock">
Xiaonan Li and Xipeng Qiu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-emnlp.411" title="">Finding support examples for in-context learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 6219–6235, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming Yin. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.647" title="">Synthetic data generation with large language models for text classification: Potential and limitations</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 10443–10461, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022a)</span>
<span class="ltx_bibblock">
Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2022a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.deelio-1.10" title="">What makes good in-context examples for GPT-3?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</em>, pages 100–114, Dublin, Ireland and Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022b)</span>
<span class="ltx_bibblock">
Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le Bras, Yejin Choi, and Hannaneh Hajishirzi. 2022b.

</span>
<span class="ltx_bibblock">Generated knowledge prompting for commonsense reasoning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3154–3169.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2022)</span>
<span class="ltx_bibblock">
Keming Lu, I-Hung Hsu, Wenxuan Zhou, Mingyu Derek Ma, and Muhao Chen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-emnlp.490" title="">Summarization as indirect supervision for relation extraction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 6575–6594, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neubig and He (2023)</span>
<span class="ltx_bibblock">
Graham Neubig and Zhiwei He. 2023.

</span>
<span class="ltx_bibblock">Zeno GPT Machine Translation Report.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rocktaschel et al. (2016)</span>
<span class="ltx_bibblock">
Tim Rocktaschel, Edward Grefenstette, Karl Moritz Hermann, Tomas Kocisky, and Phil Blunsom. 2016.

</span>
<span class="ltx_bibblock">Reasoning about entailment with neural attention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sainz et al. (2021)</span>
<span class="ltx_bibblock">
Oscar Sainz, Oier Lopez de Lacalle, Gorka Labaka, Ander Barrena, and Eneko Agirre. 2021.

</span>
<span class="ltx_bibblock">Label verbalization and entailment for effective zero and few-shot relation extraction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 1199–1212.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sorokin and Gurevych (2017)</span>
<span class="ltx_bibblock">
Daniil Sorokin and Iryna Gurevych. 2017.

</span>
<span class="ltx_bibblock">Context-aware representations for knowledge base relation extraction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, pages 1784–1789.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2023a)</span>
<span class="ltx_bibblock">
Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan Arik, and Tomas Pfister. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.216" title="">Better zero-shot reasoning with self-adaptive prompting</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 3493–3514, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2023b)</span>
<span class="ltx_bibblock">
Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Hanjun Dai, Julian Martin Eisenschlos, Sercan O Arik, and Tomas Pfister. 2023b.

</span>
<span class="ltx_bibblock">Universal self-adaptive prompting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2305.14926</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022a)</span>
<span class="ltx_bibblock">
Wenya Wang, Vivek Srikumar, Hanna Hajishirzi, and Noah A Smith. 2022a.

</span>
<span class="ltx_bibblock">Elaboration-generating commonsense question answering at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2209.01232</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022b)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022b.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Advances in Neural Information Processing Systems</em>, 35:24824–24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, et al. 2023.

</span>
<span class="ltx_bibblock">Zero-shot information extraction via chatting with chatgpt.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2302.10205</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and He (2019)</span>
<span class="ltx_bibblock">
Shanchan Wu and Yifan He. 2019.

</span>
<span class="ltx_bibblock">Enriching pre-trained language model with entity information for relation classification.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 28th ACM international conference on information and knowledge management</em>, pages 2361–2364.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
Ran Xu, Hejie Cui, Yue Yu, Xuan Kan, Wenqi Shi, Yuchen Zhuang, Wei Jin, Joyce Ho, and Carl Yang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2311.00287" title="">Knowledge-infused prompting: Assessing and advancing clinical text data generation with large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2022)</span>
<span class="ltx_bibblock">
Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong. 2022.

</span>
<span class="ltx_bibblock">Zerogen: Efficient zero-shot learning via dataset generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 11653–11669.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, and Meng Jiang. 2022.

</span>
<span class="ltx_bibblock">Generate rather than retrieve: Large language models are strong context generators.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2024)</span>
<span class="ltx_bibblock">
Zhaojian Yu, Xin Zhang, Ning Shang, Yangyu Huang, Can Xu, Yishujie Zhao, Wenxiang Hu, and Qiufeng Yin. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2312.14187" title="">Wavecoder: Widespread and versatile enhanced instruction tuning with refined data generation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. 2020.

</span>
<span class="ltx_bibblock">Pegasus: Pre-training with extracted gap-sentences for abstractive summarization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">International Conference on Machine Learning</em>, pages 11328–11339. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023a)</span>
<span class="ltx_bibblock">
Junlei Zhang, Zhenzhong Lan, and Junxian He. 2023a.

</span>
<span class="ltx_bibblock">Contrastive learning of sentence embeddings from scratch.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2305.15077</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023b)</span>
<span class="ltx_bibblock">
Kai Zhang, Bernal Jimenez Gutierrez, and Yu Su. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.50" title="">Aligning instruction tasks unlocks large language models as zero-shot relation extractors</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 794–812, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2017)</span>
<span class="ltx_bibblock">
Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, and Christopher D Manning. 2017.

</span>
<span class="ltx_bibblock">Position-aware attention and supervised data improve slot filling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Conference on Empirical Methods in Natural Language Processing</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023a)</span>
<span class="ltx_bibblock">
Jun Zhao, Wenyu Zhan, Wayne Xin Zhao, Qi Zhang, Tao Gui, Zhongyu Wei, Junzhe Wang, Minlong Peng, and Mingming Sun. 2023a.

</span>
<span class="ltx_bibblock">Re-matching: A fine-grained semantic matching method for zero-shot relation extraction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 6680–6691.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023b)</span>
<span class="ltx_bibblock">
Xiaoyan Zhao, Yang Deng, Min Yang, Lingzhi Wang, Rui Zhang, Hong Cheng, Wai Lam, Ying Shen, and Ruifeng Xu. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.02051" title="">A comprehensive survey on deep learning for relation extraction: Recent advances and new frontiers</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Related Works</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Zero-shot Relation Extraction</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Zero-shot RE has recently become a crucial focus in advancing predictive model capabilities. <cite class="ltx_cite ltx_citemacro_citet">Levy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib12" title="">2017</a>)</cite> pioneered zero-shot RE, developing models capable of identifying novel relations beyond predefined types. Furthering this field, <cite class="ltx_cite ltx_citemacro_citet">Sainz et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib22" title="">2021</a>)</cite> explored the use of smaller Language Models (LMs) fine-tuned on Natural Language Inference (NLI) datasets. Their approach employs an entity-filled relation template matching the test sentence, utilizing inference for relation prediction. <cite class="ltx_cite ltx_citemacro_citet">Chen and Li (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib3" title="">2021</a>)</cite> incorporate text descriptions of both seen and unseen relations. It employs nearest neighbor search for predicting unseen relations, using embeddings of these relations and new sentences. <cite class="ltx_cite ltx_citemacro_citet">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib19" title="">2022</a>)</cite> framed RE as a summarization task, applying generative models to concisely express the relationships between target entities. However, a persistent challenge with existing zero-shot methods is their heavy reliance on extensive labeled data. Our research focuses on conducting zero-shot RE without any labeled data.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>LLMs for Zero-shot Relation Extraction</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">In the exploration of Zero-shot RE using LLMs, most existing research has concentrated on designing effective prompts to enhance LLMs’ extraction performance. For instance, ChatIE <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib29" title="">2023</a>)</cite> employs ChatGPT for zero-shot RE, utilizing a two-stage prompting strategy to refine the LLMs’ search scope. QA4RE <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib37" title="">2023b</a>)</cite> adopts a multiple-choice question-answering format, representing relations through manually crafted templates and assigning LLMs the task of predicting a single character. In a different approach, SumAsk <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib13" title="">2023a</a>)</cite> deconstructs the LLMs’ reasoning into three distinct stages, thereby aiding them in understanding and interpreting the relationships between subjects and objects. This method is further enriched by the use of self-consistency <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib27" title="">2022b</a>)</cite> to reduce response uncertainty. However, these methods do not fully harness the LLMs’ inherent RE capabilities, primarily because of insufficient context-specific prompting. Our work aims to explore the LLMs’ RE potential by utilizing Self-Prompting, which focuses on generating context-specific prompts from synthetic samples.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Synthetic Data Generation via LLMs</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">Recent research has been focused on leveraging the content generated by LLMs to enhance the training of smaller models in various domains. For instance, <cite class="ltx_cite ltx_citemacro_citet">Ye et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib32" title="">2022</a>)</cite> applied this technique in classification tasks, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib26" title="">2022a</a>)</cite> in commonsense question-answering, <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib36" title="">2023a</a>)</cite> in contrastive learning, and <cite class="ltx_cite ltx_citemacro_citet">Chia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib5" title="">2022</a>)</cite> in RE. Additionally, another strand of research directly utilizes the outputs from LLMs. Some studies have employed LLMs to generate relevant contexts or background documents as supplementary inputs for QA tasks <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib33" title="">2022</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib18" title="">2022b</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib14" title="">2022</a>)</cite>. Others have focused on eliciting detailed reasoning steps, termed chain-of-thought, particularly for solving arithmetic problems <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib28" title="">2022</a>); Wan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib24" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib25" title="">b</a>)</cite>. In this work, we capitalize on synthetic RE samples generated by LLMs to bolster their capabilities in RE, exploring a novel approach to enhance the effectiveness of these models in this specific task.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Datasets information</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.2">The statistics of the datasets are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A2.T5" title="Table 5 ‣ Appendix B Datasets information ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">5</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A2.T6" title="Table 6 ‣ Appendix B Datasets information ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">6</span></a>. Following previous works <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib37" title="">2023b</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib13" title="">2023a</a>)</cite>, for the FewRel and Wiki-ZSL datasets, we randomly selected 5 relations for validation and selected a varying number of unseen relations (<math alttext="m" class="ltx_Math" display="inline" id="A2.p1.1.m1.1"><semantics id="A2.p1.1.m1.1a"><mi id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><ci id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="A2.p1.1.m1.1d">italic_m</annotation></semantics></math>) for testing, where <math alttext="m" class="ltx_Math" display="inline" id="A2.p1.2.m2.1"><semantics id="A2.p1.2.m2.1a"><mi id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><ci id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="A2.p1.2.m2.1d">italic_m</annotation></semantics></math> could be 5, 10, or 15. To ascertain the robustness of our results, this classification process was repeated five times, and we report the average macro-F1 scores from these iterations. For TACRED and SemEval, we conduct experiments using only the test samples and present the micro-averaged F1 scores. All relations are included except for <span class="ltx_text ltx_font_italic" id="A2.p1.2.1">none-of-the-above</span>.</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">To effectively manage OpenAI API usage and associated costs, we randomly selected 1,000 samples from the test set of each dataset. We ensured that these samples proportionally represented each relation class.</p>
</div>
<figure class="ltx_table" id="A2.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T5.1" style="width:208.1pt;height:48.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.7pt,2.7pt) scale(0.899288994931093,0.899288994931093) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T5.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A2.T5.1.1.1.1.1">Dataset</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T5.1.1.1.1.2"># samples</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T5.1.1.1.1.3"># entities</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T5.1.1.1.1.4"># relations</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T5.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.2.1.1">FewRel</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.2.1.2">56,000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.2.1.3">72,954</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.2.1.4">80</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.1.3.2.1">Wiki-ZSL</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T5.1.1.3.2.2">94,383</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T5.1.1.3.2.3">77,623</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T5.1.1.3.2.4">113</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Statistics of FewRel and Wiki-ZSL</figcaption>
</figure>
<figure class="ltx_table" id="A2.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T6.1" style="width:212.5pt;height:47.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.4pt,3.4pt) scale(0.873088838026562,0.873088838026562) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T6.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A2.T6.1.1.1.1.1">Dataset</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T6.1.1.1.1.2"># train</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T6.1.1.1.1.3"># dev</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T6.1.1.1.1.4"># test</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T6.1.1.1.1.5"># relations</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T6.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T6.1.1.2.1.1">TACRED</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.2.1.2">68,124</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.2.1.3">22,631</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.2.1.4">15,509</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.2.1.5">42</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T6.1.1.3.2.1">SemEval</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T6.1.1.3.2.2">6,507</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T6.1.1.3.2.3">1,493</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T6.1.1.3.2.4">2,717</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T6.1.1.3.2.5">9</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Statistics of TACRED and SemEval </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A2.F3.1" style="width:240.7pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="419" id="A2.F3.1.g1" src="x2.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Average F1 when using different numbers of 
<br class="ltx_break"/>demonstrations in Self-Prompting.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A2.F3.2" style="width:193.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="534" id="A2.F3.2.g1" src="x3.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Average F1 when using different sizes of synthetic samples in Self-Prompting.</figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Hyperparameter Settings</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">During the synthetic sample generation phase, the temperature setting was adjusted to 1.2 to enhance sample diversity. Conversely, for inference, we set the temperature to 0, ensuring reproducibility, with other hyperparameters maintained at default settings.</p>
</div>
<div class="ltx_para" id="A3.p2">
<p class="ltx_p" id="A3.p2.4">For generating relation synonyms, we produced 10 synonyms per relation (<math alttext="k=10" class="ltx_Math" display="inline" id="A3.p2.1.m1.1"><semantics id="A3.p2.1.m1.1a"><mrow id="A3.p2.1.m1.1.1" xref="A3.p2.1.m1.1.1.cmml"><mi id="A3.p2.1.m1.1.1.2" xref="A3.p2.1.m1.1.1.2.cmml">k</mi><mo id="A3.p2.1.m1.1.1.1" xref="A3.p2.1.m1.1.1.1.cmml">=</mo><mn id="A3.p2.1.m1.1.1.3" xref="A3.p2.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p2.1.m1.1b"><apply id="A3.p2.1.m1.1.1.cmml" xref="A3.p2.1.m1.1.1"><eq id="A3.p2.1.m1.1.1.1.cmml" xref="A3.p2.1.m1.1.1.1"></eq><ci id="A3.p2.1.m1.1.1.2.cmml" xref="A3.p2.1.m1.1.1.2">𝑘</ci><cn id="A3.p2.1.m1.1.1.3.cmml" type="integer" xref="A3.p2.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.1.m1.1c">k=10</annotation><annotation encoding="application/x-llamapun" id="A3.p2.1.m1.1d">italic_k = 10</annotation></semantics></math>). In the synthetic sample generation and filtering process, the LLMs were prompted to generate 10 samples at a time, excluding those with entities occurring more than three times (<math alttext="n=3" class="ltx_Math" display="inline" id="A3.p2.2.m2.1"><semantics id="A3.p2.2.m2.1a"><mrow id="A3.p2.2.m2.1.1" xref="A3.p2.2.m2.1.1.cmml"><mi id="A3.p2.2.m2.1.1.2" xref="A3.p2.2.m2.1.1.2.cmml">n</mi><mo id="A3.p2.2.m2.1.1.1" xref="A3.p2.2.m2.1.1.1.cmml">=</mo><mn id="A3.p2.2.m2.1.1.3" xref="A3.p2.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p2.2.m2.1b"><apply id="A3.p2.2.m2.1.1.cmml" xref="A3.p2.2.m2.1.1"><eq id="A3.p2.2.m2.1.1.1.cmml" xref="A3.p2.2.m2.1.1.1"></eq><ci id="A3.p2.2.m2.1.1.2.cmml" xref="A3.p2.2.m2.1.1.2">𝑛</ci><cn id="A3.p2.2.m2.1.1.3.cmml" type="integer" xref="A3.p2.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.2.m2.1c">n=3</annotation><annotation encoding="application/x-llamapun" id="A3.p2.2.m2.1d">italic_n = 3</annotation></semantics></math>). The generation process ceased either upon reaching 200 samples or when no new samples contained unique entities after three iterations for each relation. Each sample underwent sentence rephrasing to generate three variants (<math alttext="r=3" class="ltx_Math" display="inline" id="A3.p2.3.m3.1"><semantics id="A3.p2.3.m3.1a"><mrow id="A3.p2.3.m3.1.1" xref="A3.p2.3.m3.1.1.cmml"><mi id="A3.p2.3.m3.1.1.2" xref="A3.p2.3.m3.1.1.2.cmml">r</mi><mo id="A3.p2.3.m3.1.1.1" xref="A3.p2.3.m3.1.1.1.cmml">=</mo><mn id="A3.p2.3.m3.1.1.3" xref="A3.p2.3.m3.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p2.3.m3.1b"><apply id="A3.p2.3.m3.1.1.cmml" xref="A3.p2.3.m3.1.1"><eq id="A3.p2.3.m3.1.1.1.cmml" xref="A3.p2.3.m3.1.1.1"></eq><ci id="A3.p2.3.m3.1.1.2.cmml" xref="A3.p2.3.m3.1.1.2">𝑟</ci><cn id="A3.p2.3.m3.1.1.3.cmml" type="integer" xref="A3.p2.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.3.m3.1c">r=3</annotation><annotation encoding="application/x-llamapun" id="A3.p2.3.m3.1d">italic_r = 3</annotation></semantics></math>). A detailed cost analysis is provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A8" title="Appendix H Cost of Synthetic Data Generation ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">H</span></a>. Regarding the selection of demonstration samples at inference, we fixed <math alttext="d" class="ltx_Math" display="inline" id="A3.p2.4.m4.1"><semantics id="A3.p2.4.m4.1a"><mi id="A3.p2.4.m4.1.1" xref="A3.p2.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="A3.p2.4.m4.1b"><ci id="A3.p2.4.m4.1.1.cmml" xref="A3.p2.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.4.m4.1c">d</annotation><annotation encoding="application/x-llamapun" id="A3.p2.4.m4.1d">italic_d</annotation></semantics></math> at 10. Following <cite class="ltx_cite ltx_citemacro_citet">Kojima et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib10" title="">2022</a>)</cite>, our approach only retains the first part of the model’s output that conforms to the specified answer format.</p>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Influence of Demonstration Quantity</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.3">To identify the optimal number of in-context samples <math alttext="d" class="ltx_Math" display="inline" id="A4.p1.1.m1.1"><semantics id="A4.p1.1.m1.1a"><mi id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><ci id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="A4.p1.1.m1.1d">italic_d</annotation></semantics></math>, we analyzed how varying the number of examples in the input affects performance, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A2.F3" title="Figure 3 ‣ Appendix B Datasets information ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">3</span></a>. These experiments, aimed at assessing cost-effectiveness, were limited to a single subset of relations with <math alttext="m=10" class="ltx_Math" display="inline" id="A4.p1.2.m2.1"><semantics id="A4.p1.2.m2.1a"><mrow id="A4.p1.2.m2.1.1" xref="A4.p1.2.m2.1.1.cmml"><mi id="A4.p1.2.m2.1.1.2" xref="A4.p1.2.m2.1.1.2.cmml">m</mi><mo id="A4.p1.2.m2.1.1.1" xref="A4.p1.2.m2.1.1.1.cmml">=</mo><mn id="A4.p1.2.m2.1.1.3" xref="A4.p1.2.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.2.m2.1b"><apply id="A4.p1.2.m2.1.1.cmml" xref="A4.p1.2.m2.1.1"><eq id="A4.p1.2.m2.1.1.1.cmml" xref="A4.p1.2.m2.1.1.1"></eq><ci id="A4.p1.2.m2.1.1.2.cmml" xref="A4.p1.2.m2.1.1.2">𝑚</ci><cn id="A4.p1.2.m2.1.1.3.cmml" type="integer" xref="A4.p1.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.2.m2.1c">m=10</annotation><annotation encoding="application/x-llamapun" id="A4.p1.2.m2.1d">italic_m = 10</annotation></semantics></math>. Analyzing F1 scores across two datasets revealed a pattern of performance improvement as the number of examples increased from 1 to 12. Yet, we found that utilizing more than 10 examples did not offer substantial benefits and, notably for Wiki-ZSL, resulted in diminished performance. Therefore, balancing performance efficiency with cost considerations, we determined that 10 demonstrations (<math alttext="d=10" class="ltx_Math" display="inline" id="A4.p1.3.m3.1"><semantics id="A4.p1.3.m3.1a"><mrow id="A4.p1.3.m3.1.1" xref="A4.p1.3.m3.1.1.cmml"><mi id="A4.p1.3.m3.1.1.2" xref="A4.p1.3.m3.1.1.2.cmml">d</mi><mo id="A4.p1.3.m3.1.1.1" xref="A4.p1.3.m3.1.1.1.cmml">=</mo><mn id="A4.p1.3.m3.1.1.3" xref="A4.p1.3.m3.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.3.m3.1b"><apply id="A4.p1.3.m3.1.1.cmml" xref="A4.p1.3.m3.1.1"><eq id="A4.p1.3.m3.1.1.1.cmml" xref="A4.p1.3.m3.1.1.1"></eq><ci id="A4.p1.3.m3.1.1.2.cmml" xref="A4.p1.3.m3.1.1.2">𝑑</ci><cn id="A4.p1.3.m3.1.1.3.cmml" type="integer" xref="A4.p1.3.m3.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.3.m3.1c">d=10</annotation><annotation encoding="application/x-llamapun" id="A4.p1.3.m3.1d">italic_d = 10</annotation></semantics></math>) were optimal for our experiments.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Influence of Generated Data Size</h2>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">Evaluating the impact of synthetic sample size on experimental outcomes, our comprehensive analysis, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A2.F3" title="Figure 3 ‣ Appendix B Datasets information ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">3</span></a>, focuses on a relation subset with <math alttext="m=10" class="ltx_Math" display="inline" id="A5.p1.1.m1.1"><semantics id="A5.p1.1.m1.1a"><mrow id="A5.p1.1.m1.1.1" xref="A5.p1.1.m1.1.1.cmml"><mi id="A5.p1.1.m1.1.1.2" xref="A5.p1.1.m1.1.1.2.cmml">m</mi><mo id="A5.p1.1.m1.1.1.1" xref="A5.p1.1.m1.1.1.1.cmml">=</mo><mn id="A5.p1.1.m1.1.1.3" xref="A5.p1.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.p1.1.m1.1b"><apply id="A5.p1.1.m1.1.1.cmml" xref="A5.p1.1.m1.1.1"><eq id="A5.p1.1.m1.1.1.1.cmml" xref="A5.p1.1.m1.1.1.1"></eq><ci id="A5.p1.1.m1.1.1.2.cmml" xref="A5.p1.1.m1.1.1.2">𝑚</ci><cn id="A5.p1.1.m1.1.1.3.cmml" type="integer" xref="A5.p1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.1.m1.1c">m=10</annotation><annotation encoding="application/x-llamapun" id="A5.p1.1.m1.1d">italic_m = 10</annotation></semantics></math>, exploring synthetic sample sizes from 100 to approximately 6,000.</p>
</div>
<div class="ltx_para" id="A5.p2">
<p class="ltx_p" id="A5.p2.1">The analysis reveals a clear trend: an increase in synthetic sample size generally boosts the F1 score across both FewRel and Wiki-ZSL datasets. Specifically, the FewRel dataset shows a steady increase in performance, reaching its peak with the full dataset utilized. In contrast, the Wiki-ZSL dataset experiences a marked improvement in F1 scores from 100 to 1,000 samples, after which the gains taper off, with scores stabilizing at 2,500 samples and beyond. This indicates that while enlarging the synthetic sample pool enhances model performance, a saturation point exists beyond which no significant benefits are observed.</p>
</div>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Data Generation Quality Analysis</h2>
<figure class="ltx_figure" id="A6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="435" id="A6.F4.g1" src="x4.png" width="665"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Percentage of correct samples in FewRel and Wiki-ZSL</figcaption>
</figure>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">We employed GPT-4 to determine the presence of specified relations within various datasets to evaluate the quality of generated samples. We randomly selected 10 relations from each dataset, generating 10 samples for each, thereby creating a set of 100 samples per dataset. This analysis encompassed three datasets: the original real data, our generated data, and data generated using the RE-Prompt method. GPT-4 was tasked with verifying the specified relations in these samples. A sample was deemed correct if the head and tail entities exhibited the relation as labeled.</p>
</div>
<div class="ltx_para" id="A6.p2">
<p class="ltx_p" id="A6.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A6.F4" title="Figure 4 ‣ Appendix F Data Generation Quality Analysis ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">4</span></a> shows that our generated samples more accurately encapsulate the targeted relations compared to those generated by the RE-Prompt method. This close alignment with real data benchmarks demonstrates the effectiveness of our generation methodology, validating our samples’ utility for in-context learning in RE tasks.</p>
</div>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Comparing among Different Demonstration Data</h2>
<div class="ltx_para" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">To further compare the quality of synthetic data from our method against RE-Prompt, we utilized RE-Prompt’s synthetic data as demonstration samples in our inference framework. We documented the experimental outcomes on the FewRel and Wiki-ZSL datasets, with <math alttext="m=10" class="ltx_Math" display="inline" id="A7.p1.1.m1.1"><semantics id="A7.p1.1.m1.1a"><mrow id="A7.p1.1.m1.1.1" xref="A7.p1.1.m1.1.1.cmml"><mi id="A7.p1.1.m1.1.1.2" xref="A7.p1.1.m1.1.1.2.cmml">m</mi><mo id="A7.p1.1.m1.1.1.1" xref="A7.p1.1.m1.1.1.1.cmml">=</mo><mn id="A7.p1.1.m1.1.1.3" xref="A7.p1.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.p1.1.m1.1b"><apply id="A7.p1.1.m1.1.1.cmml" xref="A7.p1.1.m1.1.1"><eq id="A7.p1.1.m1.1.1.1.cmml" xref="A7.p1.1.m1.1.1.1"></eq><ci id="A7.p1.1.m1.1.1.2.cmml" xref="A7.p1.1.m1.1.1.2">𝑚</ci><cn id="A7.p1.1.m1.1.1.3.cmml" type="integer" xref="A7.p1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p1.1.m1.1c">m=10</annotation><annotation encoding="application/x-llamapun" id="A7.p1.1.m1.1d">italic_m = 10</annotation></semantics></math>, in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A7.T7" title="Table 7 ‣ Appendix G Comparing among Different Demonstration Data ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">7</span></a>. These outcomes uniformly demonstrate that our method surpasses RE-Prompt in all instances, highlighting the superior data quality generated by our approach. This advantage is attained without task-specific fine-tuning, showcasing our data generation process’s ability to produce high-quality synthetic samples for RE tasks effectively.</p>
</div>
<figure class="ltx_table" id="A7.T7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T7.3" style="width:216.8pt;height:67.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.6pt,11.4pt) scale(0.747619186426145,0.747619186426145) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.T7.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.T7.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A7.T7.3.1.1.1.1">Datasets</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="A7.T7.3.1.1.1.2">FewRel</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="A7.T7.3.1.1.1.3">Wiki-ZSL</th>
</tr>
<tr class="ltx_tr" id="A7.T7.3.1.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row" id="A7.T7.3.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T7.3.1.2.2.2">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T7.3.1.2.2.3">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A7.T7.3.1.2.2.4">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T7.3.1.2.2.5">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T7.3.1.2.2.6">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T7.3.1.2.2.7">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.T7.3.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T7.3.1.3.1.1">Vanilla</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T7.3.1.3.1.2">82.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T7.3.1.3.1.3">78.32</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T7.3.1.3.1.4">80.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T7.3.1.3.1.5">68.50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T7.3.1.3.1.6">72.23</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T7.3.1.3.1.7">70.31</td>
</tr>
<tr class="ltx_tr" id="A7.T7.3.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A7.T7.3.1.4.2.1">RE-Prompt</th>
<td class="ltx_td ltx_align_center" id="A7.T7.3.1.4.2.2">83.73</td>
<td class="ltx_td ltx_align_center" id="A7.T7.3.1.4.2.3">81.30</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T7.3.1.4.2.4">82.50</td>
<td class="ltx_td ltx_align_center" id="A7.T7.3.1.4.2.5">73.33</td>
<td class="ltx_td ltx_align_center" id="A7.T7.3.1.4.2.6">72.14</td>
<td class="ltx_td ltx_align_center" id="A7.T7.3.1.4.2.7">72.73</td>
</tr>
<tr class="ltx_tr" id="A7.T7.3.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A7.T7.3.1.5.3.1">Self-Prompting</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T7.3.1.5.3.2"><span class="ltx_text ltx_font_bold" id="A7.T7.3.1.5.3.2.1">85.47</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T7.3.1.5.3.3"><span class="ltx_text ltx_font_bold" id="A7.T7.3.1.5.3.3.1">83.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A7.T7.3.1.5.3.4"><span class="ltx_text ltx_font_bold" id="A7.T7.3.1.5.3.4.1">84.28</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T7.3.1.5.3.5"><span class="ltx_text ltx_font_bold" id="A7.T7.3.1.5.3.5.1">83.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T7.3.1.5.3.6"><span class="ltx_text ltx_font_bold" id="A7.T7.3.1.5.3.6.1">76.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T7.3.1.5.3.7"><span class="ltx_text ltx_font_bold" id="A7.T7.3.1.5.3.7.1">79.93</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance on FewRel and Wiki-ZSL datasets using varied synthetic demonstrations with <math alttext="m=10" class="ltx_Math" display="inline" id="A7.T7.2.m1.1"><semantics id="A7.T7.2.m1.1b"><mrow id="A7.T7.2.m1.1.1" xref="A7.T7.2.m1.1.1.cmml"><mi id="A7.T7.2.m1.1.1.2" xref="A7.T7.2.m1.1.1.2.cmml">m</mi><mo id="A7.T7.2.m1.1.1.1" xref="A7.T7.2.m1.1.1.1.cmml">=</mo><mn id="A7.T7.2.m1.1.1.3" xref="A7.T7.2.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.T7.2.m1.1c"><apply id="A7.T7.2.m1.1.1.cmml" xref="A7.T7.2.m1.1.1"><eq id="A7.T7.2.m1.1.1.1.cmml" xref="A7.T7.2.m1.1.1.1"></eq><ci id="A7.T7.2.m1.1.1.2.cmml" xref="A7.T7.2.m1.1.1.2">𝑚</ci><cn id="A7.T7.2.m1.1.1.3.cmml" type="integer" xref="A7.T7.2.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T7.2.m1.1d">m=10</annotation><annotation encoding="application/x-llamapun" id="A7.T7.2.m1.1e">italic_m = 10</annotation></semantics></math> unseen relations</figcaption>
</figure>
<figure class="ltx_table" id="A7.T8">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T8.3" style="width:411.9pt;height:142.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-56.2pt,19.3pt) scale(0.785639268910077,0.785639268910077) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.T8.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.T8.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A7.T8.3.3.3.4" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.3.4.1">Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A7.T8.3.3.3.5" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.3.5.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="A7.T8.1.1.1.1"><math alttext="m=5" class="ltx_Math" display="inline" id="A7.T8.1.1.1.1.m1.1"><semantics id="A7.T8.1.1.1.1.m1.1a"><mrow id="A7.T8.1.1.1.1.m1.1.1" xref="A7.T8.1.1.1.1.m1.1.1.cmml"><mi id="A7.T8.1.1.1.1.m1.1.1.2" xref="A7.T8.1.1.1.1.m1.1.1.2.cmml">m</mi><mo id="A7.T8.1.1.1.1.m1.1.1.1" xref="A7.T8.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A7.T8.1.1.1.1.m1.1.1.3" xref="A7.T8.1.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.T8.1.1.1.1.m1.1b"><apply id="A7.T8.1.1.1.1.m1.1.1.cmml" xref="A7.T8.1.1.1.1.m1.1.1"><eq id="A7.T8.1.1.1.1.m1.1.1.1.cmml" xref="A7.T8.1.1.1.1.m1.1.1.1"></eq><ci id="A7.T8.1.1.1.1.m1.1.1.2.cmml" xref="A7.T8.1.1.1.1.m1.1.1.2">𝑚</ci><cn id="A7.T8.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="A7.T8.1.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T8.1.1.1.1.m1.1c">m=5</annotation><annotation encoding="application/x-llamapun" id="A7.T8.1.1.1.1.m1.1d">italic_m = 5</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="A7.T8.2.2.2.2"><math alttext="m=10" class="ltx_Math" display="inline" id="A7.T8.2.2.2.2.m1.1"><semantics id="A7.T8.2.2.2.2.m1.1a"><mrow id="A7.T8.2.2.2.2.m1.1.1" xref="A7.T8.2.2.2.2.m1.1.1.cmml"><mi id="A7.T8.2.2.2.2.m1.1.1.2" xref="A7.T8.2.2.2.2.m1.1.1.2.cmml">m</mi><mo id="A7.T8.2.2.2.2.m1.1.1.1" xref="A7.T8.2.2.2.2.m1.1.1.1.cmml">=</mo><mn id="A7.T8.2.2.2.2.m1.1.1.3" xref="A7.T8.2.2.2.2.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.T8.2.2.2.2.m1.1b"><apply id="A7.T8.2.2.2.2.m1.1.1.cmml" xref="A7.T8.2.2.2.2.m1.1.1"><eq id="A7.T8.2.2.2.2.m1.1.1.1.cmml" xref="A7.T8.2.2.2.2.m1.1.1.1"></eq><ci id="A7.T8.2.2.2.2.m1.1.1.2.cmml" xref="A7.T8.2.2.2.2.m1.1.1.2">𝑚</ci><cn id="A7.T8.2.2.2.2.m1.1.1.3.cmml" type="integer" xref="A7.T8.2.2.2.2.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T8.2.2.2.2.m1.1c">m=10</annotation><annotation encoding="application/x-llamapun" id="A7.T8.2.2.2.2.m1.1d">italic_m = 10</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="A7.T8.3.3.3.3"><math alttext="m=15" class="ltx_Math" display="inline" id="A7.T8.3.3.3.3.m1.1"><semantics id="A7.T8.3.3.3.3.m1.1a"><mrow id="A7.T8.3.3.3.3.m1.1.1" xref="A7.T8.3.3.3.3.m1.1.1.cmml"><mi id="A7.T8.3.3.3.3.m1.1.1.2" xref="A7.T8.3.3.3.3.m1.1.1.2.cmml">m</mi><mo id="A7.T8.3.3.3.3.m1.1.1.1" xref="A7.T8.3.3.3.3.m1.1.1.1.cmml">=</mo><mn id="A7.T8.3.3.3.3.m1.1.1.3" xref="A7.T8.3.3.3.3.m1.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.T8.3.3.3.3.m1.1b"><apply id="A7.T8.3.3.3.3.m1.1.1.cmml" xref="A7.T8.3.3.3.3.m1.1.1"><eq id="A7.T8.3.3.3.3.m1.1.1.1.cmml" xref="A7.T8.3.3.3.3.m1.1.1.1"></eq><ci id="A7.T8.3.3.3.3.m1.1.1.2.cmml" xref="A7.T8.3.3.3.3.m1.1.1.2">𝑚</ci><cn id="A7.T8.3.3.3.3.m1.1.1.3.cmml" type="integer" xref="A7.T8.3.3.3.3.m1.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T8.3.3.3.3.m1.1c">m=15</annotation><annotation encoding="application/x-llamapun" id="A7.T8.3.3.3.3.m1.1d">italic_m = 15</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T8.3.3.3.6" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.3.6.1">Avg. Improv.</span></th>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T8.3.3.4.1.1">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T8.3.3.4.1.2">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A7.T8.3.3.4.1.3">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T8.3.3.4.1.4">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T8.3.3.4.1.5">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A7.T8.3.3.4.1.6">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T8.3.3.4.1.7">Prec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A7.T8.3.3.4.1.8">Rec.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A7.T8.3.3.4.1.9">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.T8.3.3.5.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T8.3.3.5.1.1" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.5.1.1.1">Qwen-1.8B</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T8.3.3.5.1.2">Vanilla</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.5.1.3">51.23</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.5.1.4">47.47</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.5.1.5">49.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.5.1.6">22.81</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.5.1.7">27.36</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.5.1.8">24.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.5.1.9">20.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.5.1.10">24.42</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.5.1.11">22.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.5.1.12" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.5.1.12.1">14.57%</span></td>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.6.2">
<td class="ltx_td ltx_align_left" id="A7.T8.3.3.6.2.1">Self-Prompting</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.6.2.2">59.30</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.6.2.3">59.28</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.6.2.4">59.29</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.6.2.5">47.31</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.6.2.6">46.80</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.6.2.7">47.05</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.6.2.8">33.66</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.6.2.9">34.43</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.6.2.10">34.04</td>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.7.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T8.3.3.7.3.1" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.7.3.1.1">Qwen-7B</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T8.3.3.7.3.2">Vanilla</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.7.3.3">64.85</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.7.3.4">62.60</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.7.3.5">63.69</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.7.3.6">37.80</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.7.3.7">40.24</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.7.3.8">38.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.7.3.9">27.71</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.7.3.10">30.05</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.7.3.11">28.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.7.3.12" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.7.3.12.1">10.07%</span></td>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.8.4">
<td class="ltx_td ltx_align_left" id="A7.T8.3.3.8.4.1">Self-Prompting</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.8.4.2">64.09</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.8.4.3">65.49</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.8.4.4">64.78</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.8.4.5">54.85</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.8.4.6">55.85</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.8.4.7">55.35</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.8.4.8">41.97</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.8.4.9">41.20</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.8.4.10">41.58</td>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.9.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T8.3.3.9.5.1" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.9.5.1.1">Qwen-14B</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T8.3.3.9.5.2">Vanilla</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.9.5.3">66.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.9.5.4">65.20</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.9.5.5">65.66</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.9.5.6">53.03</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.9.5.7">52.31</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.9.5.8">52.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.9.5.9">47.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.9.5.10">45.60</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.9.5.11">46.64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.9.5.12" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.9.5.12.1">6.63%</span></td>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.10.6">
<td class="ltx_td ltx_align_left" id="A7.T8.3.3.10.6.1">Self-Prompting</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.10.6.2">75.00</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.10.6.3">69.86</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.10.6.4">72.33</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.10.6.5">63.17</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.10.6.6">60.05</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.10.6.7">61.67</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.10.6.8">51.70</td>
<td class="ltx_td ltx_align_center" id="A7.T8.3.3.10.6.9">50.03</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A7.T8.3.3.10.6.10">50.85</td>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.11.7">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A7.T8.3.3.11.7.1" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.11.7.1.1">ChatGPT</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T8.3.3.11.7.2">Vanilla</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.11.7.3">91.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.11.7.4">88.87</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.11.7.5">90.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.11.7.6">72.64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.11.7.7">76.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.11.7.8">74.34</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.11.7.9">65.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T8.3.3.11.7.10">65.50</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A7.T8.3.3.11.7.11">65.48</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A7.T8.3.3.11.7.12" rowspan="2"><span class="ltx_text" id="A7.T8.3.3.11.7.12.1">5.24%</span></td>
</tr>
<tr class="ltx_tr" id="A7.T8.3.3.12.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A7.T8.3.3.12.8.1">Self-Prompting</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T8.3.3.12.8.2">88.47</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T8.3.3.12.8.3">88.92</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A7.T8.3.3.12.8.4">88.70</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T8.3.3.12.8.5">80.27</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T8.3.3.12.8.6">82.08</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A7.T8.3.3.12.8.7">81.17</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T8.3.3.12.8.8">74.82</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T8.3.3.12.8.9">77.05</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A7.T8.3.3.12.8.10">75.92</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Performance of our method for LLMs with different size</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Cost of Synthetic Data Generation</h2>
<div class="ltx_para" id="A8.p1">
<p class="ltx_p" id="A8.p1.1">For synthetic data generation, we employed <span class="ltx_text ltx_font_typewriter" id="A8.p1.1.1">gpt-3.5-turbo</span>, an economical choice at $0.001 per 1K tokens for prompts and $0.002 per 1K tokens for completions<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/pricing" title="">https://openai.com/pricing</a></span></span></span>. The synthesis involves three phases: generating relation synonyms, creating samples, and rephrasing sentences. The costs for each relation’s data generation are itemized in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A8.T9" title="Table 9 ‣ Appendix H Cost of Synthetic Data Generation ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">9</span></a>, totaling approximately $0.264 for around 600 samples per relation. Considering the Wiki-ZSL dataset includes up to 113 relations, the full data generation cost is estimated at $30. This is cost-effective compared to manual annotation expenses, such as in machine translation tasks, which can reach around $0.1 per word <cite class="ltx_cite ltx_citemacro_cite">Neubig and He (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib20" title="">2023</a>)</cite>. Thus, using <span class="ltx_text ltx_font_typewriter" id="A8.p1.1.2">gpt-3.5-turbo</span> for synthetic data generation in RE tasks is validated as an economically viable method.</p>
</div>
<figure class="ltx_table" id="A8.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A8.T9.1" style="width:216.8pt;height:59.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-54.6pt,15.1pt) scale(0.665116818582299,0.665116818582299) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A8.T9.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A8.T9.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A8.T9.1.1.1.1.1">Stage</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T9.1.1.1.1.2"># Prompt</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T9.1.1.1.1.3"># Completion</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T9.1.1.1.1.4"># Total</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T9.1.1.1.1.5">Cost ($)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A8.T9.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T9.1.1.2.1.1">Relation Synonyms</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.2.1.2">0.132</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.2.1.3">0.077</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.2.1.4">0.209</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.2.1.5">0.00029</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A8.T9.1.1.3.2.1">Sample Generation</th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.3.2.2">38.18</td>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.3.2.3">23.14</td>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.3.2.4">61.33</td>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.3.2.5">0.08447</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A8.T9.1.1.4.3.1">Sentence Rephrase</th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.4.3.2">112.58</td>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.4.3.3">33.55</td>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.4.3.4">146.12</td>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.4.3.5">0.17967</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="A8.T9.1.1.5.4.1">Total</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.1.1.5.4.2">150.89</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.1.1.5.4.3">56.77</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.1.1.5.4.4">207.66</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.1.1.5.4.5">0.26443</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Average number of token usage (k) and cost ($) for a single relation samples generation</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A9">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix I </span>General Effectiveness with LLMs of Different Sizes</h2>
<div class="ltx_para" id="A9.p1">
<p class="ltx_p" id="A9.p1.1">To examine the impact of LLM size, we also employed the Qwen <cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#bib.bib1" title="">2023</a>)</cite> series LLMs (1.8B, 7B, 14B) as alternative base models for evaluating our Self-Prompting methods. Our research explored Self-Prompting’s efficacy across LLMs of various sizes, with the findings detailed in the accompanying table. This analysis covered models ranging from Qwen-1.8B to ChatGPT, applying both Vanilla and Self-Prompting methods to different sets of unseen relations (<math alttext="m=5,10,15" class="ltx_Math" display="inline" id="A9.p1.1.m1.3"><semantics id="A9.p1.1.m1.3a"><mrow id="A9.p1.1.m1.3.4" xref="A9.p1.1.m1.3.4.cmml"><mi id="A9.p1.1.m1.3.4.2" xref="A9.p1.1.m1.3.4.2.cmml">m</mi><mo id="A9.p1.1.m1.3.4.1" xref="A9.p1.1.m1.3.4.1.cmml">=</mo><mrow id="A9.p1.1.m1.3.4.3.2" xref="A9.p1.1.m1.3.4.3.1.cmml"><mn id="A9.p1.1.m1.1.1" xref="A9.p1.1.m1.1.1.cmml">5</mn><mo id="A9.p1.1.m1.3.4.3.2.1" xref="A9.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="A9.p1.1.m1.2.2" xref="A9.p1.1.m1.2.2.cmml">10</mn><mo id="A9.p1.1.m1.3.4.3.2.2" xref="A9.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="A9.p1.1.m1.3.3" xref="A9.p1.1.m1.3.3.cmml">15</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A9.p1.1.m1.3b"><apply id="A9.p1.1.m1.3.4.cmml" xref="A9.p1.1.m1.3.4"><eq id="A9.p1.1.m1.3.4.1.cmml" xref="A9.p1.1.m1.3.4.1"></eq><ci id="A9.p1.1.m1.3.4.2.cmml" xref="A9.p1.1.m1.3.4.2">𝑚</ci><list id="A9.p1.1.m1.3.4.3.1.cmml" xref="A9.p1.1.m1.3.4.3.2"><cn id="A9.p1.1.m1.1.1.cmml" type="integer" xref="A9.p1.1.m1.1.1">5</cn><cn id="A9.p1.1.m1.2.2.cmml" type="integer" xref="A9.p1.1.m1.2.2">10</cn><cn id="A9.p1.1.m1.3.3.cmml" type="integer" xref="A9.p1.1.m1.3.3">15</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.1.m1.3c">m=5,10,15</annotation><annotation encoding="application/x-llamapun" id="A9.p1.1.m1.3d">italic_m = 5 , 10 , 15</annotation></semantics></math>) in the FewRel dataset.</p>
</div>
<div class="ltx_para" id="A9.p2">
<p class="ltx_p" id="A9.p2.1">The Qwen series models (1.8B, 7B, and 14B parameters) demonstrated clear enhancements using Self-Prompting compared to the Vanilla approach. For the smallest model, Qwen-1.8B, Self-Prompting achieved a 14.57% average increase in F1 scores, highlighting its significant benefit for smaller-scale models. With larger models, the average improvement lessened but remained impactful: 10.07% for Qwen-7B and 6.63% for Qwen-14B.</p>
</div>
</section>
<section class="ltx_appendix" id="A10">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix J </span>Case Study</h2>
<div class="ltx_para" id="A10.p1">
<p class="ltx_p" id="A10.p1.1"><span class="ltx_text ltx_font_bold" id="A10.p1.1.1">Generation:</span>
Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A10.T10" title="Table 10 ‣ Appendix J Case Study ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A10.T11" title="Table 11 ‣ Appendix J Case Study ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">11</span></a> showcase examples of the generation process for the <span class="ltx_text ltx_font_italic" id="A10.p1.1.2">location</span> and <span class="ltx_text ltx_font_italic" id="A10.p1.1.3">operator</span> relations, respectively. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A10.p1.1.4">Inference:</span> Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A10.T12" title="Table 12 ‣ Appendix J Case Study ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">12</span></a> presents a successful instance of Self-Prompting, while Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A10.T13" title="Table 13 ‣ Appendix J Case Study ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">13</span></a> illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between <span class="ltx_text ltx_font_italic" id="A10.p1.1.5">location</span> and <span class="ltx_text ltx_font_italic" id="A10.p1.1.6">located on terrain feature</span>. Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference.</p>
</div>
<figure class="ltx_table" id="A10.T10">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A10.T10.1" style="width:433.6pt;height:292.5pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.8pt,1.9pt) scale(0.987120654475293,0.987120654475293) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A10.T10.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A10.T10.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A10.T10.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.1.1.1.1">
<span class="ltx_p" id="A10.T10.1.1.1.1.1.1.1" style="width:43.4pt;">Stage</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A10.T10.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.1.1.2.1">
<span class="ltx_p" id="A10.T10.1.1.1.1.2.1.1" style="width:368.6pt;">Examples</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A10.T10.1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T10.1.1.2.1.1" rowspan="3">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.2.1.1.1">
<span class="ltx_p" id="A10.T10.1.1.2.1.1.1.1" style="width:43.4pt;"><span class="ltx_text" id="A10.T10.1.1.2.1.1.1.1.1">Relation Synonyms</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T10.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.2.1.2.1">
<span class="ltx_p" id="A10.T10.1.1.2.1.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T10.1.1.2.1.2.1.1.1">Relation</span>: <span class="ltx_text" id="A10.T10.1.1.2.1.2.1.1.2" style="color:#00FFFF;">Location</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.3.2.1.1">
<span class="ltx_p" id="A10.T10.1.1.3.2.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T10.1.1.3.2.1.1.1.1">Description</span>: location of the item, physical object, or event is within.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.4.3.1.1">
<span class="ltx_p" id="A10.T10.1.1.4.3.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T10.1.1.4.3.1.1.1.1">Synonyms</span>: [situated at, found within, positioned in, nestled amongst, geographically placed, lying in, set within, residing at, located near, anchored in]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T10.1.1.5.4.1" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.5.4.1.1">
<span class="ltx_p" id="A10.T10.1.1.5.4.1.1.1" style="width:43.4pt;"><span class="ltx_text" id="A10.T10.1.1.5.4.1.1.1.1">Sample Generation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T10.1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.5.4.2.1">
<span class="ltx_p" id="A10.T10.1.1.5.4.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T10.1.1.5.4.2.1.1.1">Relation</span>: <span class="ltx_text" id="A10.T10.1.1.5.4.2.1.1.2" style="color:#00FFFF;">Location</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.6.5.1.1">
<span class="ltx_p" id="A10.T10.1.1.6.5.1.1.1" style="width:368.6pt;">1. The <span class="ltx_text" id="A10.T10.1.1.6.5.1.1.1.1" style="color:#FF8000;">grocery store</span> in my <span class="ltx_text" id="A10.T10.1.1.6.5.1.1.1.2" style="color:#FF8000;">neighborhood</span> has a wide variety of organic produce.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.7.6.1.1">
<span class="ltx_p" id="A10.T10.1.1.7.6.1.1.1" style="width:368.6pt;">2. The <span class="ltx_text" id="A10.T10.1.1.7.6.1.1.1.1" style="color:#FF8000;">rainforest</span>, filled with exotic wildlife, is set within the <span class="ltx_text" id="A10.T10.1.1.7.6.1.1.1.2" style="color:#FF8000;">Amazon River basin</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.8.7.1.1">
<span class="ltx_p" id="A10.T10.1.1.8.7.1.1.1" style="width:368.6pt;">3. The <span class="ltx_text" id="A10.T10.1.1.8.7.1.1.1.1" style="color:#FF8000;">Louvre Museum</span>, one of the world’s largest art museums, sits within the city of <span class="ltx_text" id="A10.T10.1.1.8.7.1.1.1.2" style="color:#FF8000;">Paris</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A10.T10.1.1.9.8.1" rowspan="9">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.9.8.1.1">
<span class="ltx_p" id="A10.T10.1.1.9.8.1.1.1" style="width:43.4pt;"><span class="ltx_text" id="A10.T10.1.1.9.8.1.1.1.1">Rephrase Sentence</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T10.1.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.9.8.2.1">
<span class="ltx_p" id="A10.T10.1.1.9.8.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T10.1.1.9.8.2.1.1.1">Relation</span>: <span class="ltx_text" id="A10.T10.1.1.9.8.2.1.1.2" style="color:#00FFFF;">Location</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.10.9.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.10.9.1.1">
<span class="ltx_p" id="A10.T10.1.1.10.9.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T10.1.1.10.9.1.1.1.1">Sentence</span>: The historic <span class="ltx_text" id="A10.T10.1.1.10.9.1.1.1.2" style="color:#FF8000;">Colosseum</span> is set within the heart of <span class="ltx_text" id="A10.T10.1.1.10.9.1.1.1.3" style="color:#FF8000;">Rome</span>, surrounded by ancient ruins and archaeological sites.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.11.10.1.1">
<span class="ltx_p" id="A10.T10.1.1.11.10.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T10.1.1.11.10.1.1.1.1">Rephrased Sentence:</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.12.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.12.11.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.12.11.1.1">
<span class="ltx_p" id="A10.T10.1.1.12.11.1.1.1" style="width:368.6pt;">1. At the core of <span class="ltx_text" id="A10.T10.1.1.12.11.1.1.1.1" style="color:#FF8000;">Rome</span>, the <span class="ltx_text" id="A10.T10.1.1.12.11.1.1.1.2" style="color:#FF8000;">Colosseum</span> stands amidst ancient ruins and archaeological wonders.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.13.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T10.1.1.13.12.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.13.12.1.1">
<span class="ltx_p" id="A10.T10.1.1.13.12.1.1.1" style="width:368.6pt;">2. Surrounded by relics of the past, the <span class="ltx_text" id="A10.T10.1.1.13.12.1.1.1.1" style="color:#FF8000;">Colosseum</span> exists at the center of <span class="ltx_text" id="A10.T10.1.1.13.12.1.1.1.2" style="color:#FF8000;">Rome</span>, a city with a rich history.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T10.1.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A10.T10.1.1.14.13.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T10.1.1.14.13.1.1">
<span class="ltx_p" id="A10.T10.1.1.14.13.1.1.1" style="width:368.6pt;">3. <span class="ltx_text" id="A10.T10.1.1.14.13.1.1.1.1" style="color:#FF8000;">Rome’s</span> heart holds the majestic <span class="ltx_text" id="A10.T10.1.1.14.13.1.1.1.2" style="color:#FF8000;">Colosseum</span>, encircled by remnants of the ancient era.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Case of sample generation for relation <span class="ltx_text ltx_font_bold" id="A10.T10.3.1">Location</span></figcaption>
</figure>
<figure class="ltx_table" id="A10.T11">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A10.T11.1" style="width:433.6pt;height:283.5pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.8pt,1.8pt) scale(0.987120654475293,0.987120654475293) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A10.T11.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A10.T11.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A10.T11.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.1.1.1.1">
<span class="ltx_p" id="A10.T11.1.1.1.1.1.1.1" style="width:43.4pt;">Stage</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A10.T11.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.1.1.2.1">
<span class="ltx_p" id="A10.T11.1.1.1.1.2.1.1" style="width:368.6pt;">Examples</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A10.T11.1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T11.1.1.2.1.1" rowspan="3">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.2.1.1.1">
<span class="ltx_p" id="A10.T11.1.1.2.1.1.1.1" style="width:43.4pt;"><span class="ltx_text" id="A10.T11.1.1.2.1.1.1.1.1">Relation Synonyms</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T11.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.2.1.2.1">
<span class="ltx_p" id="A10.T11.1.1.2.1.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T11.1.1.2.1.2.1.1.1">Relation</span>: <span class="ltx_text" id="A10.T11.1.1.2.1.2.1.1.2" style="color:#00FFFF;">Operator</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.3.2.1.1">
<span class="ltx_p" id="A10.T11.1.1.3.2.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T11.1.1.3.2.1.1.1.1">Description</span>: person, profession, or organization that operates the equipment, facility, or service.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.4.3.1.1">
<span class="ltx_p" id="A10.T11.1.1.4.3.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T11.1.1.4.3.1.1.1.1">Synonyms</span>: [controller, manager, handler, technician, operator, administrator, machinist, supervisor, system operator, service provider]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T11.1.1.5.4.1" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.5.4.1.1">
<span class="ltx_p" id="A10.T11.1.1.5.4.1.1.1" style="width:43.4pt;"><span class="ltx_text" id="A10.T11.1.1.5.4.1.1.1.1">Sample Generation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T11.1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.5.4.2.1">
<span class="ltx_p" id="A10.T11.1.1.5.4.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T11.1.1.5.4.2.1.1.1">Relation</span>: <span class="ltx_text" id="A10.T11.1.1.5.4.2.1.1.2" style="color:#00FFFF;">Operator</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.6.5.1.1">
<span class="ltx_p" id="A10.T11.1.1.6.5.1.1.1" style="width:368.6pt;">1. The <span class="ltx_text" id="A10.T11.1.1.6.5.1.1.1.1" style="color:#FF8000;">doctor</span>, who works at the hospital, is responsible for overseeing the <span class="ltx_text" id="A10.T11.1.1.6.5.1.1.1.2" style="color:#FF8000;">medical equipment</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.7.6.1.1">
<span class="ltx_p" id="A10.T11.1.1.7.6.1.1.1" style="width:368.6pt;">2. The <span class="ltx_text" id="A10.T11.1.1.7.6.1.1.1.1" style="color:#FF8000;">IT technician</span> is in charge of maintaining and operating the <span class="ltx_text" id="A10.T11.1.1.7.6.1.1.1.2" style="color:#FF8000;">computer server</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.8.7.1.1">
<span class="ltx_p" id="A10.T11.1.1.8.7.1.1.1" style="width:368.6pt;">3. The <span class="ltx_text" id="A10.T11.1.1.8.7.1.1.1.1" style="color:#FF8000;">internet connection</span> provided by the <span class="ltx_text" id="A10.T11.1.1.8.7.1.1.1.2" style="color:#FF8000;">telecommunications company</span> has been unreliable lately.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A10.T11.1.1.9.8.1" rowspan="6">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.9.8.1.1">
<span class="ltx_p" id="A10.T11.1.1.9.8.1.1.1" style="width:43.4pt;"><span class="ltx_text" id="A10.T11.1.1.9.8.1.1.1.1">Rephrase Sentence</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T11.1.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.9.8.2.1">
<span class="ltx_p" id="A10.T11.1.1.9.8.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T11.1.1.9.8.2.1.1.1">Relation</span>: <span class="ltx_text" id="A10.T11.1.1.9.8.2.1.1.2" style="color:#00FFFF;">Operator</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.10.9.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.10.9.1.1">
<span class="ltx_p" id="A10.T11.1.1.10.9.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T11.1.1.10.9.1.1.1.1">Sentence</span>: The <span class="ltx_text" id="A10.T11.1.1.10.9.1.1.1.2" style="color:#FF8000;">train station</span> is operated by the <span class="ltx_text" id="A10.T11.1.1.10.9.1.1.1.3" style="color:#FF8000;">city transportation authority</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.11.10.1.1">
<span class="ltx_p" id="A10.T11.1.1.11.10.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T11.1.1.11.10.1.1.1.1">Rephrased Sentence:</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.12.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.12.11.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.12.11.1.1">
<span class="ltx_p" id="A10.T11.1.1.12.11.1.1.1" style="width:368.6pt;">1. The <span class="ltx_text" id="A10.T11.1.1.12.11.1.1.1.1" style="color:#FF8000;">train station</span> falls under the jurisdiction of the <span class="ltx_text" id="A10.T11.1.1.12.11.1.1.1.2" style="color:#FF8000;">city transportation authority</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.13.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T11.1.1.13.12.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.13.12.1.1">
<span class="ltx_p" id="A10.T11.1.1.13.12.1.1.1" style="width:368.6pt;">2. The <span class="ltx_text" id="A10.T11.1.1.13.12.1.1.1.1" style="color:#FF8000;">city transportation authority</span> oversees the operations of the <span class="ltx_text" id="A10.T11.1.1.13.12.1.1.1.2" style="color:#FF8000;">train station</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T11.1.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A10.T11.1.1.14.13.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T11.1.1.14.13.1.1">
<span class="ltx_p" id="A10.T11.1.1.14.13.1.1.1" style="width:368.6pt;">3. The <span class="ltx_text" id="A10.T11.1.1.14.13.1.1.1.1" style="color:#FF8000;">city transportation authority</span> is in charge of managing the <span class="ltx_text" id="A10.T11.1.1.14.13.1.1.1.2" style="color:#FF8000;">train station</span>.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Case of sample generation for relation <span class="ltx_text ltx_font_bold" id="A10.T11.3.1">Operator</span></figcaption>
</figure>
<figure class="ltx_table" id="A10.T12">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A10.T12.1" style="width:433.6pt;height:417.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.2pt,6.9pt) scale(0.968020106184861,0.968020106184861) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A10.T12.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A10.T12.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A10.T12.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.1.1.1.1">
<span class="ltx_p" id="A10.T12.1.1.1.1.1.1.1" style="width:52.0pt;">Stage</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A10.T12.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.1.1.2.1">
<span class="ltx_p" id="A10.T12.1.1.1.1.2.1.1" style="width:368.6pt;">Examples</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A10.T12.1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T12.1.1.2.1.1" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.2.1.1.1">
<span class="ltx_p" id="A10.T12.1.1.2.1.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T12.1.1.2.1.1.1.1.1">Background Prompts</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T12.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.2.1.2.1">
<span class="ltx_p" id="A10.T12.1.1.2.1.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.2.1.2.1.1.1">Relation</span>: You are a helpful information extractor that can conduct relation extraction task. In detail, you final goal is to extract the relation between two entities in a sentence. The relation candidate is a list of relations that you can choose from:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.3.2.1.1">
<span class="ltx_p" id="A10.T12.1.1.3.2.1.1.1" style="width:368.6pt;">[’religion’, ’location’, ’competition class’, ’operating system’, ’owned by’, ’contains administrative territorial entity’, ’field of work’, ’spouse’, ’located on terrain feature’, ’distributed by’]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T12.1.1.4.3.1" rowspan="10">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.4.3.1.1">
<span class="ltx_p" id="A10.T12.1.1.4.3.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T12.1.1.4.3.1.1.1.1">Synthetic In-Context Prompts</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T12.1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.4.3.2.1">
<span class="ltx_p" id="A10.T12.1.1.4.3.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.4.3.2.1.1.1">Sentence</span>: The <span class="ltx_text" id="A10.T12.1.1.4.3.2.1.1.2" style="color:#FF8000;">ski resort town</span>, nestled against the natural feature of <span class="ltx_text" id="A10.T12.1.1.4.3.2.1.1.3" style="color:#FF8000;">snow-capped mountains</span>, is a popular destination for winter sports enthusiasts.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.5.4.1.1">
<span class="ltx_p" id="A10.T12.1.1.5.4.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T12.1.1.5.4.1.1.1.1" style="color:#FF8000;">town</span> and <span class="ltx_text" id="A10.T12.1.1.5.4.1.1.1.2" style="color:#FF8000;">snow-capped mountains</span> is: <span class="ltx_text" id="A10.T12.1.1.5.4.1.1.1.3" style="color:#00FFFF;">located on terrain feature</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.6.5.1.1">
<span class="ltx_p" id="A10.T12.1.1.6.5.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.6.5.1.1.1.1">Sentence</span>: The <span class="ltx_text" id="A10.T12.1.1.6.5.1.1.1.2" style="color:#FF8000;">village</span>, with its enchanting <span class="ltx_text" id="A10.T12.1.1.6.5.1.1.1.3" style="color:#FF8000;">vineyards</span> and stunning vistas, finds itself nestled in the picturesque <span class="ltx_text" id="A10.T12.1.1.6.5.1.1.1.4" style="color:#FF8000;">valley</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.7.6.1.1">
<span class="ltx_p" id="A10.T12.1.1.7.6.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T12.1.1.7.6.1.1.1.1" style="color:#FF8000;">village</span> and <span class="ltx_text" id="A10.T12.1.1.7.6.1.1.1.2" style="color:#FF8000;">valley</span> is: <span class="ltx_text" id="A10.T12.1.1.7.6.1.1.1.3" style="color:#00FFFF;">location</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.8.7.1.1">
<span class="ltx_p" id="A10.T12.1.1.8.7.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.8.7.1.1.1.1">Sentence</span>: The beautiful <span class="ltx_text" id="A10.T12.1.1.8.7.1.1.1.2" style="color:#FF8000;">vineyard</span>, with rolling hills as its backdrop, is situated near the quaint <span class="ltx_text" id="A10.T12.1.1.8.7.1.1.1.3" style="color:#FF8000;">village</span> and nearby tourist destinations.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.9.8.1.1">
<span class="ltx_p" id="A10.T12.1.1.9.8.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T12.1.1.9.8.1.1.1.1" style="color:#FF8000;">vineyard</span> and <span class="ltx_text" id="A10.T12.1.1.9.8.1.1.1.2" style="color:#FF8000;">village</span> is: <span class="ltx_text" id="A10.T12.1.1.9.8.1.1.1.3" style="color:#00FFFF;">location</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.10.9.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.10.9.1.1">
<span class="ltx_p" id="A10.T12.1.1.10.9.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.10.9.1.1.1.1">Sentence</span>: Perched on the <span class="ltx_text" id="A10.T12.1.1.10.9.1.1.1.2" style="color:#FF8000;">hill</span>, the <span class="ltx_text" id="A10.T12.1.1.10.9.1.1.1.3" style="color:#FF8000;">building</span> provides a stunning vista of the <span class="ltx_text" id="A10.T12.1.1.10.9.1.1.1.4" style="color:#FF8000;">valley</span> beneath.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.11.10.1.1">
<span class="ltx_p" id="A10.T12.1.1.11.10.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T12.1.1.11.10.1.1.1.1" style="color:#FF8000;">building</span> and <span class="ltx_text" id="A10.T12.1.1.11.10.1.1.1.2" style="color:#FF8000;">hill</span> is: <span class="ltx_text" id="A10.T12.1.1.11.10.1.1.1.3" style="color:#00FFFF;">located on terrain feature</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.12.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.12.11.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.12.11.1.1">
<span class="ltx_p" id="A10.T12.1.1.12.11.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.12.11.1.1.1.1">Sentence</span>: Renowned for its geysers and hot springs, <span class="ltx_text" id="A10.T12.1.1.12.11.1.1.1.2" style="color:#FF8000;">Yellowstone National Park</span> is situated in the <span class="ltx_text" id="A10.T12.1.1.12.11.1.1.1.3" style="color:#FF8000;">western United States</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.13.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.13.12.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.13.12.1.1">
<span class="ltx_p" id="A10.T12.1.1.13.12.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T12.1.1.13.12.1.1.1.1" style="color:#FF8000;">Yellowstone National Park</span> and <span class="ltx_text" id="A10.T12.1.1.13.12.1.1.1.2" style="color:#FF8000;">western United States</span> is: <span class="ltx_text" id="A10.T12.1.1.13.12.1.1.1.3" style="color:#00FFFF;">located on terrain feature</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T12.1.1.14.13.1" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.14.13.1.1">
<span class="ltx_p" id="A10.T12.1.1.14.13.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T12.1.1.14.13.1.1.1.1">Test Sample Prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T12.1.1.14.13.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.14.13.2.1">
<span class="ltx_p" id="A10.T12.1.1.14.13.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.14.13.2.1.1.1">Sentence</span>: It is located west of, and adjacent to <span class="ltx_text" id="A10.T12.1.1.14.13.2.1.1.2" style="color:#FF8000;">Bridalveil Fall</span>, on the south side of the Merced River in <span class="ltx_text" id="A10.T12.1.1.14.13.2.1.1.3" style="color:#FF8000;">Yosemite Valley</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.15.14">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.15.14.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.15.14.1.1">
<span class="ltx_p" id="A10.T12.1.1.15.14.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T12.1.1.15.14.1.1.1.1" style="color:#FF8000;">Bridalveil Fall</span> and <span class="ltx_text" id="A10.T12.1.1.15.14.1.1.1.2" style="color:#FF8000;">Yosemite Valley</span> is:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.16.15">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A10.T12.1.1.16.15.1" rowspan="3">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.16.15.1.1">
<span class="ltx_p" id="A10.T12.1.1.16.15.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T12.1.1.16.15.1.1.1.1">Output</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T12.1.1.16.15.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.16.15.2.1">
<span class="ltx_p" id="A10.T12.1.1.16.15.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.16.15.2.1.1.1">Ground truth</span>: located on terrain feature</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.17.16">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T12.1.1.17.16.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.17.16.1.1">
<span class="ltx_p" id="A10.T12.1.1.17.16.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.17.16.1.1.1.1">Vanilla</span>: location <span class="ltx_text" id="A10.T12.1.1.17.16.1.1.1.2" style="color:#E60000;">✗</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T12.1.1.18.17">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A10.T12.1.1.18.17.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T12.1.1.18.17.1.1">
<span class="ltx_p" id="A10.T12.1.1.18.17.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T12.1.1.18.17.1.1.1.1">Self-Prompting</span>: located on terrain feature <span class="ltx_text" id="A10.T12.1.1.18.17.1.1.1.2" style="color:#009900;">✓</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Case of successful test sample inference</figcaption>
</figure>
<figure class="ltx_table" id="A10.T13">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A10.T13.1" style="width:433.6pt;height:436.3pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.2pt,7.2pt) scale(0.968020106184861,0.968020106184861) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A10.T13.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A10.T13.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A10.T13.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.1.1.1.1">
<span class="ltx_p" id="A10.T13.1.1.1.1.1.1.1" style="width:52.0pt;">Stage</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A10.T13.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.1.1.2.1">
<span class="ltx_p" id="A10.T13.1.1.1.1.2.1.1" style="width:368.6pt;">Examples</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A10.T13.1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T13.1.1.2.1.1" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.2.1.1.1">
<span class="ltx_p" id="A10.T13.1.1.2.1.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T13.1.1.2.1.1.1.1.1">Background Prompts</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T13.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.2.1.2.1">
<span class="ltx_p" id="A10.T13.1.1.2.1.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.2.1.2.1.1.1">Relation</span>: You are a helpful information extractor that can conduct relation extraction task. In detail, you final goal is to extract the relation between two entities in a sentence. The relation candidate is a list of relations that you can choose from:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.3.2.1.1">
<span class="ltx_p" id="A10.T13.1.1.3.2.1.1.1" style="width:368.6pt;">[’religion’, ’location’, ’competition class’, ’operating system’, ’owned by’, ’contains administrative territorial entity’, ’field of work’, ’spouse’, ’located on terrain feature’, ’distributed by’]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T13.1.1.4.3.1" rowspan="10">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.4.3.1.1">
<span class="ltx_p" id="A10.T13.1.1.4.3.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T13.1.1.4.3.1.1.1.1">Synthetic In-Context Prompts</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T13.1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.4.3.2.1">
<span class="ltx_p" id="A10.T13.1.1.4.3.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.4.3.2.1.1.1">Sentence</span>: An operating system known as <span class="ltx_text" id="A10.T13.1.1.4.3.2.1.1.2" style="color:#FF8000;">macOS</span> powers the <span class="ltx_text" id="A10.T13.1.1.4.3.2.1.1.3" style="color:#FF8000;">Mac computers</span>, which are produced by <span class="ltx_text" id="A10.T13.1.1.4.3.2.1.1.4" style="color:#FF8000;">Apple Inc.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.5.4.1.1">
<span class="ltx_p" id="A10.T13.1.1.5.4.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T13.1.1.5.4.1.1.1.1" style="color:#FF8000;">computers</span> and <span class="ltx_text" id="A10.T13.1.1.5.4.1.1.1.2" style="color:#FF8000;">Mac</span> is: <span class="ltx_text" id="A10.T13.1.1.5.4.1.1.1.3" style="color:#00FFFF;">operating system</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.6.5.1.1">
<span class="ltx_p" id="A10.T13.1.1.6.5.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.6.5.1.1.1.1">Sentence</span>: <span class="ltx_text" id="A10.T13.1.1.6.5.1.1.1.2" style="color:#FF8000;">Linux</span>, a widely used <span class="ltx_text" id="A10.T13.1.1.6.5.1.1.1.3" style="color:#FF8000;">open-source</span> operating system, is favored by programmers and developers.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.7.6.1.1">
<span class="ltx_p" id="A10.T13.1.1.7.6.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T13.1.1.7.6.1.1.1.1" style="color:#FF8000;">Linux</span> and <span class="ltx_text" id="A10.T13.1.1.7.6.1.1.1.2" style="color:#FF8000;">open-source</span> is: <span class="ltx_text" id="A10.T13.1.1.7.6.1.1.1.3" style="color:#00FFFF;">operating system</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.8.7.1.1">
<span class="ltx_p" id="A10.T13.1.1.8.7.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.8.7.1.1.1.1">Sentence</span>: The <span class="ltx_text" id="A10.T13.1.1.8.7.1.1.1.2" style="color:#FF8000;">Unix operating system</span>, known for its stability and security, is widely used in <span class="ltx_text" id="A10.T13.1.1.8.7.1.1.1.3" style="color:#FF8000;">enterprise computer systems</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.9.8.1.1">
<span class="ltx_p" id="A10.T13.1.1.9.8.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T13.1.1.9.8.1.1.1.1" style="color:#FF8000;">Unix operating system</span> and <span class="ltx_text" id="A10.T13.1.1.9.8.1.1.1.2" style="color:#FF8000;">computer systems</span> is: <span class="ltx_text" id="A10.T13.1.1.9.8.1.1.1.3" style="color:#00FFFF;">operating system</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.10.9.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.10.9.1.1">
<span class="ltx_p" id="A10.T13.1.1.10.9.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.10.9.1.1.1.1">Sentence</span>: <span class="ltx_text" id="A10.T13.1.1.10.9.1.1.1.2" style="color:#FF8000;">Windows</span>, commonly known as <span class="ltx_text" id="A10.T13.1.1.10.9.1.1.1.3" style="color:#FF8000;">Microsoft Windows</span>, is a group of several proprietary graphical operating system families.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.11.10.1.1">
<span class="ltx_p" id="A10.T13.1.1.11.10.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T13.1.1.11.10.1.1.1.1" style="color:#FF8000;">Windows</span> and <span class="ltx_text" id="A10.T13.1.1.11.10.1.1.1.2" style="color:#FF8000;">Microsoft</span> is: <span class="ltx_text" id="A10.T13.1.1.11.10.1.1.1.3" style="color:#00FFFF;">operating system</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.12.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.12.11.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.12.11.1.1">
<span class="ltx_p" id="A10.T13.1.1.12.11.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.12.11.1.1.1.1">Sentence</span>: The construction and distribution of the iconic <span class="ltx_text" id="A10.T13.1.1.12.11.1.1.1.2" style="color:#FF8000;">Lego sets</span> are handled by <span class="ltx_text" id="A10.T13.1.1.12.11.1.1.1.3" style="color:#FF8000;">The Lego Group</span>, a Danish toy production company.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.13.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.13.12.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.13.12.1.1">
<span class="ltx_p" id="A10.T13.1.1.13.12.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T13.1.1.13.12.1.1.1.1" style="color:#FF8000;">Lego sets</span> and <span class="ltx_text" id="A10.T13.1.1.13.12.1.1.1.2" style="color:#FF8000;">The Lego Group</span> is: <span class="ltx_text" id="A10.T13.1.1.13.12.1.1.1.3" style="color:#00FFFF;">distributed by</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A10.T13.1.1.14.13.1" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.14.13.1.1">
<span class="ltx_p" id="A10.T13.1.1.14.13.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T13.1.1.14.13.1.1.1.1">Test Sample Prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T13.1.1.14.13.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.14.13.2.1">
<span class="ltx_p" id="A10.T13.1.1.14.13.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.14.13.2.1.1.1">Sentence</span>: Sentence: His muscle algorithms for face animation were widely used in the computer film industry, most notably by <span class="ltx_text" id="A10.T13.1.1.14.13.2.1.1.2" style="color:#FF8000;">Pixar</span>, which first used the technique in their animation short <span class="ltx_text" id="A10.T13.1.1.14.13.2.1.1.3" style="color:#FF8000;">Tin Toy</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.15.14">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.15.14.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.15.14.1.1">
<span class="ltx_p" id="A10.T13.1.1.15.14.1.1.1" style="width:368.6pt;">Given the Sentence, the relation between <span class="ltx_text" id="A10.T13.1.1.15.14.1.1.1.1" style="color:#FF8000;">Tin Toy</span> and <span class="ltx_text" id="A10.T13.1.1.15.14.1.1.1.2" style="color:#FF8000;">Pixar</span> is:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.16.15">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A10.T13.1.1.16.15.1" rowspan="3">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.16.15.1.1">
<span class="ltx_p" id="A10.T13.1.1.16.15.1.1.1" style="width:52.0pt;"><span class="ltx_text" id="A10.T13.1.1.16.15.1.1.1.1">Output</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A10.T13.1.1.16.15.2">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.16.15.2.1">
<span class="ltx_p" id="A10.T13.1.1.16.15.2.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.16.15.2.1.1.1">Ground truth</span>: distributed by</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.17.16">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A10.T13.1.1.17.16.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.17.16.1.1">
<span class="ltx_p" id="A10.T13.1.1.17.16.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.17.16.1.1.1.1">Vanilla</span>: distributed by <span class="ltx_text" id="A10.T13.1.1.17.16.1.1.1.2" style="color:#009900;">✓</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A10.T13.1.1.18.17">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A10.T13.1.1.18.17.1">
<span class="ltx_inline-block ltx_align_top" id="A10.T13.1.1.18.17.1.1">
<span class="ltx_p" id="A10.T13.1.1.18.17.1.1.1" style="width:368.6pt;"><span class="ltx_text ltx_font_bold" id="A10.T13.1.1.18.17.1.1.1.1">Self-Prompting</span>: field of work <span class="ltx_text" id="A10.T13.1.1.18.17.1.1.1.2" style="color:#E60000;">✗</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Case of failed test sample inference</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A11">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix K </span>Prompts for LLMs</h2>
<div class="ltx_para" id="A11.p1">
<p class="ltx_p" id="A11.p1.1">We listed each stage’s prompts used in the synthetic data generation process in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01154v1#A11.T14" title="Table 14 ‣ Appendix K Prompts for LLMs ‣ Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"><span class="ltx_text ltx_ref_tag">14</span></a>.</p>
</div>
<figure class="ltx_table" id="A11.T14">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A11.T14.1" style="width:433.6pt;height:779.2pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.8pt,5.1pt) scale(0.987135536003239,0.987135536003239) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A11.T14.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A11.T14.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A11.T14.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.1.1.1.1">
<span class="ltx_p" id="A11.T14.1.1.1.1.1.1.1" style="width:65.0pt;">Stage</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A11.T14.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.1.1.2.1">
<span class="ltx_p" id="A11.T14.1.1.1.1.2.1.1" style="width:346.9pt;">Prompts</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A11.T14.1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A11.T14.1.1.2.1.1" rowspan="8">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.2.1.1.1">
<span class="ltx_p" id="A11.T14.1.1.2.1.1.1.1" style="width:65.0pt;"><span class="ltx_text" id="A11.T14.1.1.2.1.1.1.1.1">Relation Synonyms</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A11.T14.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.2.1.2.1">
<span class="ltx_p" id="A11.T14.1.1.2.1.2.1.1" style="width:346.9pt;">For a giving relation type: {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.2.1.2.1.1.1">relation</span>}, your objective is to create {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.2.1.2.1.1.2">k</span>} synonyms about this relation.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.3.2.1.1">
<span class="ltx_p" id="A11.T14.1.1.3.2.1.1.1" style="width:346.9pt;">The description of this relation is: {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.3.2.1.1.1.1">description</span>}</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.4.3.1.1">
<span class="ltx_p" id="A11.T14.1.1.4.3.1.1.1" style="width:346.9pt;">Ensure that your generated examples adhere to the following guidelines:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.5.4.1.1">
<span class="ltx_p" id="A11.T14.1.1.5.4.1.1.1" style="width:346.9pt;">1. The synonyms should explicitly or implicitly align with the relation {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.5.4.1.1.1.1">relation</span>}.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.6.5.1.1">
<span class="ltx_p" id="A11.T14.1.1.6.5.1.1.1" style="width:346.9pt;">2. Ensure the diversity among different synonyms.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.7.6.1.1">
<span class="ltx_p" id="A11.T14.1.1.7.6.1.1.1" style="width:346.9pt;">3. The synonyms could be a single word or phrase.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.8.7.1.1">
<span class="ltx_p" id="A11.T14.1.1.8.7.1.1.1" style="width:346.9pt;">Please format your output in Python list-style:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.9.8.1.1">
<span class="ltx_p" id="A11.T14.1.1.9.8.1.1.1" style="width:346.9pt;">[synonyms1, synonyms2, …, synonyms{<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.9.8.1.1.1.1">k</span>}]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A11.T14.1.1.10.9.1" rowspan="12">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.10.9.1.1">
<span class="ltx_p" id="A11.T14.1.1.10.9.1.1.1" style="width:65.0pt;"><span class="ltx_text" id="A11.T14.1.1.10.9.1.1.1.1">Sample Generation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A11.T14.1.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.10.9.2.1">
<span class="ltx_p" id="A11.T14.1.1.10.9.2.1.1" style="width:346.9pt;">Imagine you are a sophisticated language model functioning as a textual data generator for a relation extraction task. Your objective is to create {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.10.9.2.1.1.1">k</span>} synthetic sentences, each containing a specific type of relationship denoted as: {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.10.9.2.1.1.2">relation</span>}</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.11.10.1.1">
<span class="ltx_p" id="A11.T14.1.1.11.10.1.1.1" style="width:346.9pt;">The description of this relation is: {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.11.10.1.1.1.1">description</span>}.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.12.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.12.11.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.12.11.1.1">
<span class="ltx_p" id="A11.T14.1.1.12.11.1.1.1" style="width:346.9pt;">These sentences must be informative and clearly demonstrate the intended relation, either explicitly or implicitly. Please format your output as follows:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.13.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.13.12.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.13.12.1.1">
<span class="ltx_p" id="A11.T14.1.1.13.12.1.1.1" style="width:346.9pt;">Sentence: [Your generated sentence here].</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.14.13.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.14.13.1.1">
<span class="ltx_p" id="A11.T14.1.1.14.13.1.1.1" style="width:346.9pt;">Relation: [(entity1, {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.14.13.1.1.1.1">relation</span>}, entity2), (entity3, {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.14.13.1.1.1.2">relation</span>}, entity4), …].</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.15.14">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.15.14.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.15.14.1.1">
<span class="ltx_p" id="A11.T14.1.1.15.14.1.1.1" style="width:346.9pt;">Where the relation list could contain one to three relation tuples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.16.15">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.16.15.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.16.15.1.1">
<span class="ltx_p" id="A11.T14.1.1.16.15.1.1.1" style="width:346.9pt;">Ensure that your generated examples adhere to the following guidelines:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.17.16">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.17.16.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.17.16.1.1">
<span class="ltx_p" id="A11.T14.1.1.17.16.1.1.1" style="width:346.9pt;">1. The relation should be the same as the previously defined relation.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.18.17">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.18.17.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.18.17.1.1">
<span class="ltx_p" id="A11.T14.1.1.18.17.1.1.1" style="width:346.9pt;">2. Head and tail entities must appear in the original sentence.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.19.18">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.19.18.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.19.18.1.1">
<span class="ltx_p" id="A11.T14.1.1.19.18.1.1.1" style="width:346.9pt;">3. Separate the head and tail into several triples that have the same relation.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.20.19">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.20.19.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.20.19.1.1">
<span class="ltx_p" id="A11.T14.1.1.20.19.1.1.1" style="width:346.9pt;">4. Generate sentences with varying lengths and complexities, including simple, compound, and complex sentences.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.21.20">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.21.20.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.21.20.1.1">
<span class="ltx_p" id="A11.T14.1.1.21.20.1.1.1" style="width:346.9pt;">5. Ensure a broad and realistic variety in the types of head and tail entities to reflect real-world contexts.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.22.21">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A11.T14.1.1.22.21.1" rowspan="10">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.22.21.1.1">
<span class="ltx_p" id="A11.T14.1.1.22.21.1.1.1" style="width:65.0pt;"><span class="ltx_text" id="A11.T14.1.1.22.21.1.1.1.1">Rephrase Sentence</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A11.T14.1.1.22.21.2">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.22.21.2.1">
<span class="ltx_p" id="A11.T14.1.1.22.21.2.1.1" style="width:346.9pt;">As a text paraphrasing agent, your task is to paraphrase a given sentence to generate {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.22.21.2.1.1.1">k</span>} new versions. The original sentence includes one or more relationships. Rewrite the sentence to subtly imply the relationships that were originally stated explicitly, while also enhancing the semantic depth and diversifying the grammatical structure.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.23.22">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.23.22.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.23.22.1.1">
<span class="ltx_p" id="A11.T14.1.1.23.22.1.1.1" style="width:346.9pt;">Input format:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.24.23">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.24.23.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.24.23.1.1">
<span class="ltx_p" id="A11.T14.1.1.24.23.1.1.1" style="width:346.9pt;">Sentence: The sentence to be paraphrased.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.25.24">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.25.24.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.25.24.1.1">
<span class="ltx_p" id="A11.T14.1.1.25.24.1.1.1" style="width:346.9pt;">Relation: A list of relation tuples in the format (head, relation, tail).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.26.25">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.26.25.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.26.25.1.1">
<span class="ltx_p" id="A11.T14.1.1.26.25.1.1.1" style="width:346.9pt;">Output Format:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.27.26">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.27.26.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.27.26.1.1">
<span class="ltx_p" id="A11.T14.1.1.27.26.1.1.1" style="width:346.9pt;">Provide {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.27.26.1.1.1.1">k</span>} paraphrased sentences, where the relation list could contain one to three relation tuples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.28.27">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.28.27.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.28.27.1.1">
<span class="ltx_p" id="A11.T14.1.1.28.27.1.1.1" style="width:346.9pt;">Ensure that your generated examples adhere to the following guidelines:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.29.28">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.29.28.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.29.28.1.1">
<span class="ltx_p" id="A11.T14.1.1.29.28.1.1.1" style="width:346.9pt;">1. Preservation of Entities: Ensure that the head and tail entities from the original sentence are present in each paraphrased version.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.30.29">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.30.29.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.30.29.1.1">
<span class="ltx_p" id="A11.T14.1.1.30.29.1.1.1" style="width:346.9pt;">2. Variety and Realism: Aim for a wide range of sentence structures and contexts in your paraphrases, reflecting realistic and diverse scenarios.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.31.30">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.31.30.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.31.30.1.1">
<span class="ltx_p" id="A11.T14.1.1.31.30.1.1.1" style="width:346.9pt;">3. In the generated relation list for each paraphrased sentence, the relation MUST remain consistent with the relation: {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.31.30.1.1.1.1">relation</span>}, while minor modifications to the entities are permissible.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.32.31">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A11.T14.1.1.32.31.1" rowspan="5">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.32.31.1.1">
<span class="ltx_p" id="A11.T14.1.1.32.31.1.1.1" style="width:65.0pt;"><span class="ltx_text" id="A11.T14.1.1.32.31.1.1.1.1">Inference</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A11.T14.1.1.32.31.2">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.32.31.2.1">
<span class="ltx_p" id="A11.T14.1.1.32.31.2.1.1" style="width:346.9pt;">Your goal is to extract the relation between two entities in a sentence. The relation candidate is a list of relations that you can choose from: {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.32.31.2.1.1.1">relation list</span>}</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.33.32">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.33.32.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.33.32.1.1">
<span class="ltx_p" id="A11.T14.1.1.33.32.1.1.1" style="width:346.9pt;">{<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.33.32.1.1.1.1">demonstrations</span>}</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.34.33">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A11.T14.1.1.34.33.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.34.33.1.1">
<span class="ltx_p" id="A11.T14.1.1.34.33.1.1.1" style="width:346.9pt;">Sentence: {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.34.33.1.1.1.1">extract sentence</span>}</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A11.T14.1.1.35.34">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A11.T14.1.1.35.34.1">
<span class="ltx_inline-block ltx_align_top" id="A11.T14.1.1.35.34.1.1">
<span class="ltx_p" id="A11.T14.1.1.35.34.1.1.1" style="width:346.9pt;">Given the Sentence, the relation between {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.35.34.1.1.1.1">head</span>} and {<span class="ltx_text ltx_font_italic" id="A11.T14.1.1.35.34.1.1.1.2">tail</span>} is:</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Prompts used for synthetic data generation and test sample inference</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 01:08:14 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
