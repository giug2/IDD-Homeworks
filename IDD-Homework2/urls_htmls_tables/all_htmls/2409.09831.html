<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling</title>
<!--Generated on Tue Sep 17 11:14:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.09831v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S1" title="In Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S2" title="In Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S3" title="In Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">System Design</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S3.SS1" title="In III System Design ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">The Masker</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S3.SS2" title="In III System Design ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">The Mask-Filling System</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S4" title="In Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Setup</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S4.SS1" title="In IV Experimental Setup ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S4.SS2" title="In IV Experimental Setup ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Hyperparameter tuning and Training</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S4.SS3" title="In IV Experimental Setup ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">System instances</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S4.SS4" title="In IV Experimental Setup ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-D</span> </span><span class="ltx_text ltx_font_italic">Evaluation Metrics</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5" title="In Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results and Discussion</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.SS1" title="In V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Lexical Similarity Evaluation against References</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.SS2" title="In V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Readability Evaluation against References</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.SS3" title="In V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Data Utility Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.SS3.SSS1" title="In V-C Data Utility Evaluation ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span>1 </span>Downstream NER Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.SS3.SSS2" title="In V-C Data Utility Evaluation ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span>2 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.SS4" title="In V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">Data Privacy Evaluation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S6" title="In Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusions and Future Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S6.SS1" title="In VI Conclusions and Future Work ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-A</span> </span><span class="ltx_text ltx_font_italic">Limitations</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S6.SS2" title="In VI Conclusions and Future Work ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-B</span> </span><span class="ltx_text ltx_font_italic">Future works</span></span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Generating Synthetic Free-text Medical
<br class="ltx_break"/>Records with Low Re-identification Risk
<br class="ltx_break"/>using Masked Language Modeling</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Samuel Belkadi<sup class="ltx_sup" id="id9.9.id1"><span class="ltx_text ltx_font_italic" id="id9.9.id1.1">1,2</span></sup>, Libo Ren<sup class="ltx_sup" id="id10.10.id2"><span class="ltx_text ltx_font_italic" id="id10.10.id2.1">2</span></sup>, Nicolo Micheletti<sup class="ltx_sup" id="id11.11.id3"><span class="ltx_text ltx_font_italic" id="id11.11.id3.1">2,3</span></sup>, Lifeng Han<sup class="ltx_sup" id="id12.12.id4"><span class="ltx_text ltx_font_italic" id="id12.12.id4.1">2</span></sup>, Goran Nenadic<sup class="ltx_sup" id="id13.13.id5"><span class="ltx_text ltx_font_italic" id="id13.13.id5.1">2</span></sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id6"><span class="ltx_text ltx_font_italic" id="id14.14.id6.1">1</span></sup>Department of Engineering, University of Cambridge, UK 
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.id7"><span class="ltx_text ltx_font_italic" id="id15.15.id7.1">2</span></sup>Department of Computer Science, The University of Manchester, UK 
<br class="ltx_break"/><sup class="ltx_sup" id="id16.16.id8"><span class="ltx_text ltx_font_italic" id="id16.16.id8.1">3</span></sup>Department of Computer Science and Technology, Tsinghua University, China 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id17.17.id9">sb2764@cam.ac.uk</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id18.18.id10">libo.ren@student.manchester.ac.uk</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id19.19.id11">nkl24@tsinghua.org.cn</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id20.20.id12">{lifeng.han, g.nenadic}@manchester.ac.uk</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id21.id1">In this paper, we present a system that generates synthetic free-text medical records, such as discharge summaries, admission notes and doctor correspondences, using Masked Language Modeling (MLM). Our system is designed to preserve the critical information of the records while introducing significant diversity and minimizing re-identification risk. The system incorporates a de-identification component that uses Philter to mask Protected Health Information (PHI), followed by a Medical Entity Recognition (NER) model to retain key medical information. We explore various masking ratios and mask-filling techniques to balance the trade-off between diversity and fidelity in the synthetic outputs without affecting overall readability. Our results demonstrate that the system can produce high-quality synthetic data with significant diversity while achieving a HIPAA-compliant PHI recall rate of 0.96 and a low re-identification risk of 0.035. Furthermore, downstream evaluations using an NER task reveal that the synthetic data can be effectively used to train models with performance comparable to those trained on real data. The flexibility of the system allows it to be adapted for specific use cases, making it a valuable tool for privacy-preserving data generation in medical research and healthcare applications.</p>
<p class="ltx_p" id="id22.id2"><span class="ltx_text ltx_font_italic" id="id22.id2.1">Index Terms–</span> Masked Language Model, Text Generation, De-identification, Medical Records, Synthetic Data Applications</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The generation of synthetic alternatives to private datasets has gained increasing recognition in both academic and industrial fields as a means to enable large-scale access to data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib1" title="">1</a>]</cite>. When properly produced, synthetic data can replicate the statistical patterns of the original data while disconnecting from actual human individuals <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib2" title="">2</a>]</cite>. This kind of data not only facilitates data sharing with minimal privacy concerns but also supports data augmentation to enhance the performance of machine learning (ML) models. As a result, this capability has significant potential to maximize the value of patient data in advancing biomedicine and healthcare, which are domains where data is hardly accessible due to privacy and scarcity reasons.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The widespread adoption of medical record systems has led to the accumulation of vast amounts of patient data. While this data has the potential to enhance health knowledge and improve care <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib4" title="">4</a>]</cite>, <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">privacy</span> concerns restrict its accessibility <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib5" title="">5</a>]</cite>, hindering the development of translational AI and ML in healthcare. <span class="ltx_text ltx_font_bold" id="S1.p2.1.2">Synthetic data generation</span> provides a solution by creating synthetic records, such as discharge summaries, that minimize privacy risks while remaining useful for tasks such as testing health information systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib6" title="">6</a>]</cite>, medical education <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib7" title="">7</a>]</cite>, hypothesis generation, and developing medical AI systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib9" title="">9</a>]</cite>. As a result, several initiatives have turned to synthetic data generation to broaden public access to their datasets, including the National Institutes of Health’s National COVID Cohort Collaborative and the Clinical Practice Research Datalink by the UK’s National Institute for Health and Care Research.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Because real medical records are difficult to access, the datasets available for biomedical research are often small, lack diversity, miss key features, overrepresent certain subpopulations, have imbalanced labels, and lack sufficient annotations. For these reasons, ML models trained on these data may <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">perform poorly</span>, generalize inadequately, and produce unfair outcomes when disparities occur across patient subgroups <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib10" title="">10</a>]</cite>. In addition, combining synthetic discharge data with real data may potentially improve performance and reduce bias <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib11" title="">11</a>]</cite>. This approach increases the representation of underrepresented classes or patient subpopulations in the data, preventing the model from focusing too heavily on dominant groups. Furthermore, synthetic medical data could be generated in large quantities and at low cost, offering greater diversity than traditional augmentation methods (e.g., over- or under-sampling), thus reducing the risk of overfitting.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Among numerous synthetic data generation techniques, Casual Language Modeling (<span class="ltx_text ltx_font_bold" id="S1.p4.1.1">CLM</span>) is the one currently recognized as the state-of-the-art. Encoder-decoder transformers and GPTs have showcased their capabilities to capture the statistical properties of real discharge summaries with moderate privacy risks. However, to our knowledge, no work has tried to use Masked Language Modeling for this task. In <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">our previous work</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib12" title="">12</a>]</cite>, we introduced the first system to generate synthetic data using Masked Language Modeling (MLM) and compared it to Casual Language Modeling at multiple synthetic generations tasks to conclude that MLM was able to outperform the latter at some synthetic data generation tasks while preserving CLM’s main ability to infer complex knowledge and relations.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The reason for this alternative is that <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">MLM is way more controllable</span>. In fact, we can control the resemblance between the synthetic data and the original data, i.e. control the <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">diversity in generations</span>, with more accuracy than with CLM models by adjusting <span class="ltx_text ltx_font_italic" id="S1.p5.1.3">masking ratios</span>, <span class="ltx_text ltx_font_italic" id="S1.p5.1.4">masked tokens</span> and <span class="ltx_text ltx_font_italic" id="S1.p5.1.5">mask-filling</span> techniques.
As a result, the structure of the letter is kept intact and critical information can be selected to appear in the synthetic data. This solves a major issue of autoregressive models that must generate their letter’s structure from scratch and thus struggle with long letters, often deviating from the original letter’s intention when increasing diversity. In addition, as a bidirectional approach, MLM models can leverage the full context of a text and thus <span class="ltx_text ltx_font_italic" id="S1.p5.1.6">reduce hallucinations</span>.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">This paper aims to introduce a system specifically designed to generate synthetic free-text medical reports, including discharge summaries, admission notes and correspondences between doctors using Masked Language Modeling. This system includes a de-identification phase using a state-of-the-art de-identification tool called <span class="ltx_text ltx_font_bold" id="S1.p6.1.1">Philter</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib13" title="">13</a>]</cite>, which does not rely on deep learning and is specifically designed for the recognition of protected health information (PHI). While most other works ignore de-identification or assume that input data are already manually labeled for de-identification, we aim to include de-identification directly within our system. Additionally, our system includes a Medical Entity Recognition model to select and retain critical medical information from the original medical records.
The final system is capable of taking raw, <span class="ltx_text ltx_font_bold" id="S1.p6.1.2">neither annotated nor de-identified letters</span>, and generates a large amount of unique synthetic letters that retain the critical medical information of the original letter and for which users can control its resemblance/diversity trade-off. Finally, it guarantees the reduction in the number of patient health identifiers to nearly zero at the cost of slightly reduced data fidelity.
<span class="ltx_text ltx_font_bold" id="S1.p6.1.3">The system, training, and evaluation codes</span> are made publicly available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/SamySam0/SynDeidMLM" title="">https://github.com/SamySam0/SynDeidMLM</a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">As, to the best of our knowledge, this work is <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">the first</span> to experiment with MLM for generating synthetic <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">medical records</span>, we present below some that are closely related to our system development.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib14" title="">14</a>]</cite>, authors introduced a method to generate Synthetic Electronic Health Record data using Generative Adversarial Networks (GANs). However, they showed <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">limitations</span> in the ability of their model to control the <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">prevalence/resemblance</span> between the synthetic data and the original data, something that can be improved by using MLM models. They also underline the limitation of their model in <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">complex knowledge</span> and <span class="ltx_text ltx_font_italic" id="S2.p2.1.4">relationships</span> between medical concepts, which <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib12" title="">12</a>]</cite> showed to be improved through extensive pretraining of MLM models.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Using a similar system, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib15" title="">15</a>]</cite> produced synthetic unstructured free-text medical data with low re-identification risk. However, the authors experienced <span class="ltx_text ltx_font_italic" id="S2.p3.1.1">high similarities</span> between generated and original data, leading to reduced diversity in the synthetic data and limiting its potential in large-scale generations for uses such as oversampling. Additionally, they did not focus on <span class="ltx_text ltx_font_italic" id="S2.p3.1.2">de-identification</span> and assumed that synthetic data generation reduces re-identification risk by creating new patient records with different content. As a result, they stated that synthetic data produced must undergo rigorous de-identification of PHI elements before they can be distributed for public use.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Later, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib16" title="">16</a>]</cite> presented a study on using deep-learning with GPT-2 for biomedical data augmentation. The focus was on generating artificial clinical notes in Electronic Health Records (EHRs) to improve the training of machine learning models for predicting patient outcomes, such as readmission rates. In their work, they suggested a novel approach to introduce noise and variability in generations, but to the cost of a decrease in model predictive performance. Indeed, as a unidirectional approach, GPTs inevitably restrict their capacity to leverage the full context of a text and may suffer from <span class="ltx_text ltx_font_italic" id="S2.p4.1.1">hallucinations</span>.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Similarly, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib17" title="">17</a>]</cite> compared vanilla transformer and pre-trained GPT-2 models for generating synthetic medical text to augment datasets. In their work, they evaluate the effectiveness of the generated synthetic data in improving the performance of deep learning models in specific medical tasks. However, they concluded that both models had difficulties generating synthetic data that could translate well on downstream tasks. Most importantly, they show that GPTs sometimes <span class="ltx_text ltx_font_italic" id="S2.p5.1.1">struggle with generating long letters</span> due to their autoregressive nature. That is, they are hardly controllable as they lose the entire structure and main string of the letter. Autoregressive models need to generate a totally new letter word-by-word. Therefore, the longer the letter, the more possibilities it has to deviate away from its original intention.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">In one of the latest works on medical synthetic data generation, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib18" title="">18</a>]</cite> analyzed whether GPT-3.5 could generate high-quality discharge summaries. They observed that GPT-3.5 was likely to reproduce and list all concepts mentioned in the prompt. In addition, GPT-3.5 generated <span class="ltx_text ltx_font_italic" id="S2.p6.1.1">unnatural</span> texts which missed necessary supporting information and tended to introduce <span class="ltx_text ltx_font_italic" id="S2.p6.1.2">spurious</span> information. These are due to the hard controllability of autoregressive CLM models as to how much is kept or how much is removed, resulting in <span class="ltx_text ltx_font_italic" id="S2.p6.1.3">a lack of diversity</span> in the synthetic data. That was indeed validated by clinician-evaluators who noted “the correctness of the generated discharge summaries while suffering in variety, supporting information, and coherence in narratives” (hallucinations).
Moreover, they revealed that GPT-3.5 <span class="ltx_text ltx_font_italic" id="S2.p6.1.4">failed to present diagnoses</span> as interconnected events, which is something that may be improved through the selection of tokens to be masked when using MLM approaches.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Finally, in one of our parallel works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib19" title="">19</a>]</cite>, we presented an alternative approach for generating synthetic de-identified discharge summaries, using a different dataset and system architecture. This alternative system includes rule-based components, offering a complementary perspective to the work described here. We highly recommend readers explore this paper for additional insights into synthetic medical data generation.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">System Design</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section describes the design of our system in detail, following the pipeline displayed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S3.F1" title="Figure 1 ‣ III System Design ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The system takes as input a medical record. This can be a discharge summary, admission note or correspondence between doctors.
The first component of our system is a <span class="ltx_text ltx_font_bold" id="S3.p2.1.1">Masker</span>. It aims to select which entities to mask in the input letter and which to keep for optimal results. As an output, the <span class="ltx_text ltx_font_italic" id="S3.p2.1.2">Masker</span> provides us with the final masked letter.
The second and final component is the <span class="ltx_text ltx_font_bold" id="S3.p2.1.3">Mask-filling System</span> which fills in all masked entities based on the context and remaining information, to generate one or more synthetic letter(s) from the one provided.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="231" id="S3.F1.g1" src="extracted/5860419/Figures/System.jpeg" width="580"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Design of the entire System with Masker and Mask-Filling components.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">The Masker</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">Masker</span> is decomposed into three distinct phases. Each phase iteratively selects a subset of entities to mask or keep in the final masked letter based on certain parameters tuned for the specific use case. We define below each of these phases with details on their implementation. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">De-identification.</span> The first phase in the <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.2">Masker</span> is to detect protected health information (PHI). For this purpose, we use a tool called Philter <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib20" title="">20</a>]</cite> which uses regular expressions as its main building block. Philter can extract 7 categories of PHIs, namely DATE, ID, NAME, CONTACT, AGE&gt;=90, AGE&lt;90, and LOCATION. The authors reported a recall of 99.46% on the 2000 note UCSF test corpus and a recall of 99.92% on the publicly available 514 note 2014 i2b2 test corpus. To the best of our knowledge, Philter is the first certified de-identified redaction pipeline that makes clinical notes available to researchers for nonhuman subjects’ research, without further IRB approval needed, under the period cited in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib13" title="">13</a>]</cite>. We use this tool to tag and mask every entity in our original letter that belongs to any of these PHI categories. Note that precision is less important here as false positive entities contribute to the additional noise in the masked sequences, promoting diversity in the generations.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Medical Entity Recognition.</span> The second phase in the <span class="ltx_text ltx_font_italic" id="S3.SS1.p3.1.2">Masker</span> is to detect medical entities that we believe are critical information which build the core of the letter and should not be masked to preserve the letter’s intention. For this purpose, we leverage a pre-trained Medical Named Entity Recognition (NER) model which was fine-tuned on i2b2-2010 by Stanza<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://stanfordnlp.github.io/stanza/available_biomed_models.html</span></span></span>. This NER extracts 3 categories of medical entities, namely PROBLEM, TEST, and TREATMENT; and reported a micro-averaged F1 score of 88.13% on the same dataset. We use this tool to tag and protect every remaining entity in our original letter that belongs to any of these medical categories, such that they can remain in the structure of the masked letter and guide the synthetic generation. Note that the NER can be replaced at the need to select different types of entities and critical information. Alternatively, a ratio can be set up to control how much of each medical entity’s category should be kept.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Part-of-Speech Tagger.</span> The third and final phase in the <span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.2">Masker</span> is to detect part of speech within the original letter. To this end, we use Stanza’s POS which assigns a part-of-speech to each remaining word based on both its definition and its context. Given the POS of all remaining entities, we select and mask a random subset of tagged entities in order to create diversity in the synthetic generations. To do so, we define a set of ratios, with values between 0 and 1 for each POS category, where values closer to 0 imply less masking and ones closer to 1 have higher masking rates. For example, we could give the set {<span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.3">NOUN: 0.7, VRB: 0.5</span>} to approximately mask 70% of nouns, 50% of verbs and none of the other POS categories.
We leave the choice of masking ratios to the user based on their own use cases. Results of experiments on different presets are given in section <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5" title="V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">The Mask-Filling System</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">Mask-Filling System</span> takes as input the letter previously masked by the <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.2">Masker</span> to generate one (or multiple) synthetic version(s) of the original letter with retained core information. To do so, it is decomposed into two interconnected components, i.e., an MLM model and a Mask-Filling algorithm. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">MLM Model.</span> The MLM model is a deep language model that takes in the masked letter and provides a probability distribution over all possible words to replace the masked entity. As our MLM model, we selected a fine-tuned instance of the famous pre-trained encoder BERT, named Bio_ClinicalBERT<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT</span></span></span>. This model was initialized from BioBERT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib21" title="">21</a>]</cite> and fine-tuned on all notes from MIMIC III <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib22" title="">22</a>]</cite>, a database containing electronic health records from ICU patients at the Beth Israel Hospital in Boston, MA. This makes it an excellent baseline trained on both biomedical and clinical data. We then further trained this model on our specific task using the 790 training letters provided by our dataset to obtain the final version of our MLM model. Please note that we did not try alternative models as a baseline for our system. However, we truly encourage further studies to experiment with different baseline models.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Mask-Filling Algorithm.</span> The other component of the Mask-Filling System is the <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.1.2">Mask-Filling Algorithm</span>. This algorithm prepares the masked letter, cut into chunks, for the MLM model. Then, the latter sends back filling probabilities for each masked entity to the algorithm, which then decides which word to select before sending the next chunk to the MLM model. In our work, we experiment with two distinct mask-filling algorithms. Each of them is described below and results are given and compared in section <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5" title="V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Simultaneous Chunk Filling</span>: The first filling method takes a chunk of the masked letter and passes it to the MLM model. The latter sends back the probabilities for each masked entity. For each masked entity, the Mask-Filling component selects which word to replace it with based on the probability distribution. The user can decide to pick the word with the highest probability deterministically, or, in order to promote diversity, he can choose to select each word stochastically from the probability distribution at the cost of a slightly reduced fidelity. Here, fidelity is affected as we do not select the most probable word anymore, but instead draw from the MLM’s normal distribution.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Iterative Mask Filling</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib23" title="">23</a>]</cite>: In the second filling method, we select a window around each masked entity where each preceding masked words are replaced by their selected counterparts and later masked entities by their value in the original letter. In short, each masked word is replaced iteratively to generate a synthetic letter. This method has the advantage of offering a stronger context as a single entity is masked within the chunk (window) passed to the MLM model. Moreover, as it iteratively generates synthetic entities, it further motivates diversity in the output while allowing more confidence as the MLM model is always presented with a single word to replace. As with the previous approach, each replaced entity may be selected deterministically or stochastically from the MLM’s distribution. We decided to stick with a stochastic approach as recommended in their original paper. In fact, this provides wider possibilities when generating multiple synthetic instances of a given letter.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Setup</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we introduce the dataset used to train and evaluate our system, as well as the training and hyperparameter selection process of our MLM model. Furthermore, we present the different instances of the system we will compare and the evaluation phases with the respective metrics they leverage.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Datasets</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Throughout our work, we used the database released as part of the first track of the UTHealth Challenge (i2b2) 2014 shared task data on protected health information (PHI) de-identification with gold labels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib25" title="">25</a>]</cite>. The dataset is issued by the Research Patient Data Repository of Partners Healthcare and provides 1304 clinical records for 296 diabetic patients, including discharge summaries, admission notes, and correspondences between doctors. Furthermore, it is pre-divided into 790 samples for training and 514 for testing.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We decided to use this dataset as it provides a large number of medical records for various clinical conditions and treatments, enabling our model to generate diverse samples. In addition, all records come with PHI annotations, being realistic surrogates to real information, allowing us to evaluate the rate of successful de-identification by our system. The annotations are HIPAA-PHI compliant and include additional sub-categories to further ensure the patients’ protection. We provide below all the categories of annotations:</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">NAME (types: PATIENT, DOCTOR, USERNAME);</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">PROFESSION;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">LOCATION (types: ROOM, DEPARTMENT, HOSPITAL, ORGANIZATION, STREET, CITY, STATE, COUNTRY, ZIP, OTHER);</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">AGE;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">DATE;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i6.p1">
<p class="ltx_p" id="S4.I1.i6.p1.1">CONTACT (types: PHONE, FAX, EMAIL, URL, IPADDRESS);</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i7.p1">
<p class="ltx_p" id="S4.I1.i7.p1.1">IDs (types: SOCIAL SECURITY NUMBER, MEDICAL RECORD NUMBER, HEALTH PLAN NUMBER, ACCOUNT NUMBER, LICENSE NUMBER, VEHICLE ID, DEVICE ID, BIOMETRIC ID, ID NUMBER).</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">Out of these categories, only the following correspond to the HIPAA-PHI categories: NAME-PATIENT, LOCATION-STREET, LOCATION-CITY, LOCATION-ZIP, LOCATION-ORGANIZATION, AGE, DATE, CONTACT-PHONE, CONTACT-FAX, CONTACT-EMAIL, as well as all ID sub-categories.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Hyperparameter tuning and Training</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.9">During training, we perform a grid search to select the most optimal set of hyperparameters from the following values: <math alttext="\alpha\in\{1\times 10^{-4},5\times 10^{-5},3\times 10^{-5}\}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.3"><semantics id="S4.SS2.p1.1.m1.3a"><mrow id="S4.SS2.p1.1.m1.3.3" xref="S4.SS2.p1.1.m1.3.3.cmml"><mi id="S4.SS2.p1.1.m1.3.3.5" xref="S4.SS2.p1.1.m1.3.3.5.cmml">α</mi><mo id="S4.SS2.p1.1.m1.3.3.4" xref="S4.SS2.p1.1.m1.3.3.4.cmml">∈</mo><mrow id="S4.SS2.p1.1.m1.3.3.3.3" xref="S4.SS2.p1.1.m1.3.3.3.4.cmml"><mo id="S4.SS2.p1.1.m1.3.3.3.3.4" stretchy="false" xref="S4.SS2.p1.1.m1.3.3.3.4.cmml">{</mo><mrow id="S4.SS2.p1.1.m1.1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.SS2.p1.1.m1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.cmml">×</mo><msup id="S4.SS2.p1.1.m1.1.1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.cmml"><mn id="S4.SS2.p1.1.m1.1.1.1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.2.cmml">10</mn><mrow id="S4.SS2.p1.1.m1.1.1.1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.cmml"><mo id="S4.SS2.p1.1.m1.1.1.1.1.1.3.3a" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.cmml">−</mo><mn id="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.2" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="S4.SS2.p1.1.m1.3.3.3.3.5" xref="S4.SS2.p1.1.m1.3.3.3.4.cmml">,</mo><mrow id="S4.SS2.p1.1.m1.2.2.2.2.2" xref="S4.SS2.p1.1.m1.2.2.2.2.2.cmml"><mn id="S4.SS2.p1.1.m1.2.2.2.2.2.2" xref="S4.SS2.p1.1.m1.2.2.2.2.2.2.cmml">5</mn><mo id="S4.SS2.p1.1.m1.2.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.1.m1.2.2.2.2.2.1.cmml">×</mo><msup id="S4.SS2.p1.1.m1.2.2.2.2.2.3" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.cmml"><mn id="S4.SS2.p1.1.m1.2.2.2.2.2.3.2" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.2.cmml">10</mn><mrow id="S4.SS2.p1.1.m1.2.2.2.2.2.3.3" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.cmml"><mo id="S4.SS2.p1.1.m1.2.2.2.2.2.3.3a" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.cmml">−</mo><mn id="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.2" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.2.cmml">5</mn></mrow></msup></mrow><mo id="S4.SS2.p1.1.m1.3.3.3.3.6" xref="S4.SS2.p1.1.m1.3.3.3.4.cmml">,</mo><mrow id="S4.SS2.p1.1.m1.3.3.3.3.3" xref="S4.SS2.p1.1.m1.3.3.3.3.3.cmml"><mn id="S4.SS2.p1.1.m1.3.3.3.3.3.2" xref="S4.SS2.p1.1.m1.3.3.3.3.3.2.cmml">3</mn><mo id="S4.SS2.p1.1.m1.3.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.1.m1.3.3.3.3.3.1.cmml">×</mo><msup id="S4.SS2.p1.1.m1.3.3.3.3.3.3" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.cmml"><mn id="S4.SS2.p1.1.m1.3.3.3.3.3.3.2" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.2.cmml">10</mn><mrow id="S4.SS2.p1.1.m1.3.3.3.3.3.3.3" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.cmml"><mo id="S4.SS2.p1.1.m1.3.3.3.3.3.3.3a" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.cmml">−</mo><mn id="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.2" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.2.cmml">5</mn></mrow></msup></mrow><mo id="S4.SS2.p1.1.m1.3.3.3.3.7" stretchy="false" xref="S4.SS2.p1.1.m1.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.3b"><apply id="S4.SS2.p1.1.m1.3.3.cmml" xref="S4.SS2.p1.1.m1.3.3"><in id="S4.SS2.p1.1.m1.3.3.4.cmml" xref="S4.SS2.p1.1.m1.3.3.4"></in><ci id="S4.SS2.p1.1.m1.3.3.5.cmml" xref="S4.SS2.p1.1.m1.3.3.5">𝛼</ci><set id="S4.SS2.p1.1.m1.3.3.3.4.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3"><apply id="S4.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1"></times><cn id="S4.SS2.p1.1.m1.1.1.1.1.1.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.1.1.1.2">1</cn><apply id="S4.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3">superscript</csymbol><cn id="S4.SS2.p1.1.m1.1.1.1.1.1.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.2">10</cn><apply id="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.3"><minus id="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.3"></minus><cn id="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.1.1.1.3.3.2">4</cn></apply></apply></apply><apply id="S4.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2"><times id="S4.SS2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2.1"></times><cn id="S4.SS2.p1.1.m1.2.2.2.2.2.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.2.2.2.2.2.2">5</cn><apply id="S4.SS2.p1.1.m1.2.2.2.2.2.3.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.2.2.2.2.2.3.1.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3">superscript</csymbol><cn id="S4.SS2.p1.1.m1.2.2.2.2.2.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.2">10</cn><apply id="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.3"><minus id="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.1.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.3"></minus><cn id="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.2.2.2.2.2.3.3.2">5</cn></apply></apply></apply><apply id="S4.SS2.p1.1.m1.3.3.3.3.3.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3"><times id="S4.SS2.p1.1.m1.3.3.3.3.3.1.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3.1"></times><cn id="S4.SS2.p1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.3.3.3.3.3.2">3</cn><apply id="S4.SS2.p1.1.m1.3.3.3.3.3.3.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.3.3.3.3.3.3.1.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3">superscript</csymbol><cn id="S4.SS2.p1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.2">10</cn><apply id="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.3"><minus id="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.1.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.3"></minus><cn id="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.3.3.3.3.3.3.3.2">5</cn></apply></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.3c">\alpha\in\{1\times 10^{-4},5\times 10^{-5},3\times 10^{-5}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.3d">italic_α ∈ { 1 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 5 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT , 3 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT }</annotation></semantics></math>, <math alttext="\beta\in\{8,16\}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.2"><semantics id="S4.SS2.p1.2.m2.2a"><mrow id="S4.SS2.p1.2.m2.2.3" xref="S4.SS2.p1.2.m2.2.3.cmml"><mi id="S4.SS2.p1.2.m2.2.3.2" xref="S4.SS2.p1.2.m2.2.3.2.cmml">β</mi><mo id="S4.SS2.p1.2.m2.2.3.1" xref="S4.SS2.p1.2.m2.2.3.1.cmml">∈</mo><mrow id="S4.SS2.p1.2.m2.2.3.3.2" xref="S4.SS2.p1.2.m2.2.3.3.1.cmml"><mo id="S4.SS2.p1.2.m2.2.3.3.2.1" stretchy="false" xref="S4.SS2.p1.2.m2.2.3.3.1.cmml">{</mo><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">8</mn><mo id="S4.SS2.p1.2.m2.2.3.3.2.2" xref="S4.SS2.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S4.SS2.p1.2.m2.2.2" xref="S4.SS2.p1.2.m2.2.2.cmml">16</mn><mo id="S4.SS2.p1.2.m2.2.3.3.2.3" stretchy="false" xref="S4.SS2.p1.2.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.2b"><apply id="S4.SS2.p1.2.m2.2.3.cmml" xref="S4.SS2.p1.2.m2.2.3"><in id="S4.SS2.p1.2.m2.2.3.1.cmml" xref="S4.SS2.p1.2.m2.2.3.1"></in><ci id="S4.SS2.p1.2.m2.2.3.2.cmml" xref="S4.SS2.p1.2.m2.2.3.2">𝛽</ci><set id="S4.SS2.p1.2.m2.2.3.3.1.cmml" xref="S4.SS2.p1.2.m2.2.3.3.2"><cn id="S4.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1">8</cn><cn id="S4.SS2.p1.2.m2.2.2.cmml" type="integer" xref="S4.SS2.p1.2.m2.2.2">16</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.2c">\beta\in\{8,16\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.2d">italic_β ∈ { 8 , 16 }</annotation></semantics></math>, <math alttext="\phi\in\{0.75,1.0\}" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.2"><semantics id="S4.SS2.p1.3.m3.2a"><mrow id="S4.SS2.p1.3.m3.2.3" xref="S4.SS2.p1.3.m3.2.3.cmml"><mi id="S4.SS2.p1.3.m3.2.3.2" xref="S4.SS2.p1.3.m3.2.3.2.cmml">ϕ</mi><mo id="S4.SS2.p1.3.m3.2.3.1" xref="S4.SS2.p1.3.m3.2.3.1.cmml">∈</mo><mrow id="S4.SS2.p1.3.m3.2.3.3.2" xref="S4.SS2.p1.3.m3.2.3.3.1.cmml"><mo id="S4.SS2.p1.3.m3.2.3.3.2.1" stretchy="false" xref="S4.SS2.p1.3.m3.2.3.3.1.cmml">{</mo><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">0.75</mn><mo id="S4.SS2.p1.3.m3.2.3.3.2.2" xref="S4.SS2.p1.3.m3.2.3.3.1.cmml">,</mo><mn id="S4.SS2.p1.3.m3.2.2" xref="S4.SS2.p1.3.m3.2.2.cmml">1.0</mn><mo id="S4.SS2.p1.3.m3.2.3.3.2.3" stretchy="false" xref="S4.SS2.p1.3.m3.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.2b"><apply id="S4.SS2.p1.3.m3.2.3.cmml" xref="S4.SS2.p1.3.m3.2.3"><in id="S4.SS2.p1.3.m3.2.3.1.cmml" xref="S4.SS2.p1.3.m3.2.3.1"></in><ci id="S4.SS2.p1.3.m3.2.3.2.cmml" xref="S4.SS2.p1.3.m3.2.3.2">italic-ϕ</ci><set id="S4.SS2.p1.3.m3.2.3.3.1.cmml" xref="S4.SS2.p1.3.m3.2.3.3.2"><cn id="S4.SS2.p1.3.m3.1.1.cmml" type="float" xref="S4.SS2.p1.3.m3.1.1">0.75</cn><cn id="S4.SS2.p1.3.m3.2.2.cmml" type="float" xref="S4.SS2.p1.3.m3.2.2">1.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.2c">\phi\in\{0.75,1.0\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.2d">italic_ϕ ∈ { 0.75 , 1.0 }</annotation></semantics></math> and <math alttext="\psi\in\{0.30,0.50\}" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.2"><semantics id="S4.SS2.p1.4.m4.2a"><mrow id="S4.SS2.p1.4.m4.2.3" xref="S4.SS2.p1.4.m4.2.3.cmml"><mi id="S4.SS2.p1.4.m4.2.3.2" xref="S4.SS2.p1.4.m4.2.3.2.cmml">ψ</mi><mo id="S4.SS2.p1.4.m4.2.3.1" xref="S4.SS2.p1.4.m4.2.3.1.cmml">∈</mo><mrow id="S4.SS2.p1.4.m4.2.3.3.2" xref="S4.SS2.p1.4.m4.2.3.3.1.cmml"><mo id="S4.SS2.p1.4.m4.2.3.3.2.1" stretchy="false" xref="S4.SS2.p1.4.m4.2.3.3.1.cmml">{</mo><mn id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">0.30</mn><mo id="S4.SS2.p1.4.m4.2.3.3.2.2" xref="S4.SS2.p1.4.m4.2.3.3.1.cmml">,</mo><mn id="S4.SS2.p1.4.m4.2.2" xref="S4.SS2.p1.4.m4.2.2.cmml">0.50</mn><mo id="S4.SS2.p1.4.m4.2.3.3.2.3" stretchy="false" xref="S4.SS2.p1.4.m4.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.2b"><apply id="S4.SS2.p1.4.m4.2.3.cmml" xref="S4.SS2.p1.4.m4.2.3"><in id="S4.SS2.p1.4.m4.2.3.1.cmml" xref="S4.SS2.p1.4.m4.2.3.1"></in><ci id="S4.SS2.p1.4.m4.2.3.2.cmml" xref="S4.SS2.p1.4.m4.2.3.2">𝜓</ci><set id="S4.SS2.p1.4.m4.2.3.3.1.cmml" xref="S4.SS2.p1.4.m4.2.3.3.2"><cn id="S4.SS2.p1.4.m4.1.1.cmml" type="float" xref="S4.SS2.p1.4.m4.1.1">0.30</cn><cn id="S4.SS2.p1.4.m4.2.2.cmml" type="float" xref="S4.SS2.p1.4.m4.2.2">0.50</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.2c">\psi\in\{0.30,0.50\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.2d">italic_ψ ∈ { 0.30 , 0.50 }</annotation></semantics></math>; where <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.p1.5.m5.1"><semantics id="S4.SS2.p1.5.m5.1a"><mi id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><ci id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.5.m5.1d">italic_α</annotation></semantics></math> is the learning rate of the MLM model, <math alttext="\beta" class="ltx_Math" display="inline" id="S4.SS2.p1.6.m6.1"><semantics id="S4.SS2.p1.6.m6.1a"><mi id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><ci id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.6.m6.1d">italic_β</annotation></semantics></math> is the training batch size, <math alttext="\phi" class="ltx_Math" display="inline" id="S4.SS2.p1.7.m7.1"><semantics id="S4.SS2.p1.7.m7.1a"><mi id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><ci id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.7.m7.1d">italic_ϕ</annotation></semantics></math> is the PHI’s masking proportion and <math alttext="\psi" class="ltx_Math" display="inline" id="S4.SS2.p1.8.m8.1"><semantics id="S4.SS2.p1.8.m8.1a"><mi id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><ci id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.8.m8.1d">italic_ψ</annotation></semantics></math> is the overall masking probability. For convenience, we select the optimal number of training epochs through early stoppage with patience of <math alttext="p=2" class="ltx_Math" display="inline" id="S4.SS2.p1.9.m9.1"><semantics id="S4.SS2.p1.9.m9.1a"><mrow id="S4.SS2.p1.9.m9.1.1" xref="S4.SS2.p1.9.m9.1.1.cmml"><mi id="S4.SS2.p1.9.m9.1.1.2" xref="S4.SS2.p1.9.m9.1.1.2.cmml">p</mi><mo id="S4.SS2.p1.9.m9.1.1.1" xref="S4.SS2.p1.9.m9.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.9.m9.1.1.3" xref="S4.SS2.p1.9.m9.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m9.1b"><apply id="S4.SS2.p1.9.m9.1.1.cmml" xref="S4.SS2.p1.9.m9.1.1"><eq id="S4.SS2.p1.9.m9.1.1.1.cmml" xref="S4.SS2.p1.9.m9.1.1.1"></eq><ci id="S4.SS2.p1.9.m9.1.1.2.cmml" xref="S4.SS2.p1.9.m9.1.1.2">𝑝</ci><cn id="S4.SS2.p1.9.m9.1.1.3.cmml" type="integer" xref="S4.SS2.p1.9.m9.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m9.1c">p=2</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.9.m9.1d">italic_p = 2</annotation></semantics></math>. While we agree that more advanced hyperparameter search methods exist, such as Bayesian Optimization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib26" title="">26</a>]</cite> or Optuna <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib27" title="">27</a>]</cite>, we decided to opt for grid search due to computational limitations.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.2">We split the dataset into 80% training and 20% validation, using a random split. We once again recognize that k-fold cross-validation is usually more accurate, but are constrained by the same computational resources. For each possible set of hyperparameters, a new instance of the system is created. Then, during its training, training samples are re-processed at each epoch with random masking of up to <math alttext="\psi" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_ψ</annotation></semantics></math> percent, including <math alttext="\phi" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">italic_ϕ</annotation></semantics></math> percent of all PHI entities. This is made to allow the model to see varied versions of the same sample, increasing the diversity of cases it can learn from and thus reducing overfitting. In contrast, the validation set is masked consistently across all epochs to ensure fair comparison.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">We evaluate each instance using perplexity as it reflects the MLM model’s confidence. Once the best hyperparameters are identified, we merge the training and validation sets and retrain the best model on the full dataset.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">System instances</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Throughout the evaluation, we compare four distinct system instances, i.e., versions of our system that use different <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.1">Masker</span> ratios and <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.2">Mask-Filling algorithms</span>.</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">System_S_0.5</span>: This instance masks all PHI entities and none of the medical entities captured by the NER. However, it masks 50% of NOUNS, VERBS and ADJECTIVES for moderate diversity. In addition, it uses the Simultaneous Chunk Filling algorithm for mask-filling.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">System_S_0.7</span>: Similarly to <span class="ltx_text ltx_font_italic" id="S4.I2.i2.p1.1.2">System_S_0.5</span>, this instance masks all PHI entities and none of the medical entities captured by the NER. However, it masks 70% of NOUNS, VERBS and ADJECTIVES for increased diversity, and uses the same Simultaneous Chunk-filling algorithm.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">System_I_0.7</span>: This instance masks all PHI entities and none of the medical entities captured by the NER. It uses Iterative Mask Filling and masks 70% of NOUNS, VERBS and ADJECTIVES for moderate diversity. Note that using Iterative Mask Filling increases the standards for the amount of masking. Please refer to their paper for more details on this aspect <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib23" title="">23</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">System_I_0.9</span>: Similarly to <span class="ltx_text ltx_font_italic" id="S4.I2.i4.p1.1.2">System_I_0.7</span>, this instance masks all PHI entities and none of the medical entities captured by the NER. However, it masks 90% of NOUNS, VERBS and ADJECTIVES for increased diversity, and uses the same Iterative Mask-filling technique.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Please note that the masking ratios are inspired by the results obtained in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib12" title="">12</a>]</cite>. Such sets may be modified based on the user’s specific use case, and we encourage future works to experiment with more diverse sets of ratios to increase the quality of generated texts.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS4.5.1.1">IV-D</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS4.6.2">Evaluation Metrics</span>
</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">The quality evaluation of synthetic medical records primarily revolves around three aspects: <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.1">resemblance/similarity to reference (real) data</span>, <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.2">data utility</span> and <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.3">privacy</span>. This process implies comparing the synthetic data generated against the real data using a set of metrics and applied cases. We describe below in detail each of these three aspects.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.1">Lexical similarity to reference</span> evaluates the ability of our synthetic data to resemble the statistical characteristics of real data at both variable and record (or patient) levels. This includes lexical similarities such as "how much information is retained from the original data?", "how much overall meaning is maintained post-synthetisation?" and "how much diversification and deviation (prevalence) was generated?", which are evaluated with ROUGE, BERTScore and ROUGE metrics, respectively. It further includes readability comparisons such as "how easily can the text be read?" and "what academic level do you need to read the document?", which are evaluated with FRE<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Flesh Reading Ease</span></span></span> and the pair FKG<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Flesch-Kincaid Grade</span></span></span>-SMOG, respectively.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p3.1.1">Data utility</span> measures the usefulness and applicability of a dataset for practical purposes. Specifically, it is evaluated by determining how well the generated data captures the critical characteristics present in the real data. To assess this characteristic, we evaluate the extent to which our synthetic records retain the capability of training machine learning models that perform comparably to those trained using real data. This is done through a downstream NER task, similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#bib.bib12" title="">12</a>]</cite> and described in subsection <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.SS3.SSS1" title="V-C1 Downstream NER Task ‣ V-C Data Utility Evaluation ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span>1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS4.p4">
<p class="ltx_p" id="S4.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p4.1.1">Data privacy</span> evaluation is crucial when considering the sharing of synthetic medical data. As our current dataset has been labeled by multiple professionals following the official HIPAA-PHI de-identification rules, we evaluate the privacy level of our model by calculating the F1-score to how much of the PHIs were identified and replaced by our system according to the annotated data, and how much re-identification occurred on average post generation. 
<br class="ltx_break"/></p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results and Discussion</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we present the results of all system instances at the three evaluation phases described in section <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S4" title="IV Experimental Setup ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">IV</span></a>. To read full synthetic samples, please refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#Ax1" title="Examples of generated synthetic letters ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_title">Examples of generated synthetic letters</span></a>. Note that, as there is no existing work on the synthetic generation of de-identified medical records with the same dataset, we are limited to comparing different configurations of our system internally.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.5.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.6.2">Lexical Similarity Evaluation against References</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The ROUGE and BERTScore of all four system instances are displayed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.T1" title="TABLE I ‣ V-A Lexical Similarity Evaluation against References ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr" id="S5.T1.1.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T1.1.1.1.2">ROUGE-1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T1.1.1.1.3">ROUGE-2</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T1.1.1.1.4">ROUGE-L</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T1.1.1.1.5">BERTScore</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T1.1.2.1.1">System_S_0.5</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.2.1.2">0.861</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.2.1.3">0.760</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.2.1.4">0.852</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.2.1.5">0.729</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T1.1.3.2.1">System_S_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.3.2.2">0.828</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.3.2.3">0.703</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.3.2.4">0.815</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.3.2.5">0.674</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T1.1.4.3.1">System_I_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.4.3.2">0.852</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.4.3.3">0.732</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.4.3.4">0.841</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.4.3.5">0.706</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T1.1.5.4.1">System_I_0.9</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.5.4.2">0.826</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.5.4.3">0.686</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.5.4.4">0.811</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.4.5">0.668</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Lexical similarities of the generated synthetic letters against references on the testing dataset.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">As we can observe, the higher the masking ratios are, the more ROUGE and BERTScore values decrease. That is due to the amount of noise increasing with the amount of masking to fill. In addition, we see that as the ROUGE score decreases, the BERTScore follows, confirming the trade-off between generations’ diversity and fidelity described in section <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S3" title="III System Design ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">When looking specifically at the results of the System_S instances, increasing the masking ratios penalizes the similarity more than with the iterative systems. In fact, on the same ratios (0.7), all ROUGE scores are about 3 points lower and the BERTScore 0.32 lower. That showcases one of the advantages of Iterative Mask Filling being that each mask token to fill is surrounded by original or predicted tokens, which adds to the MLM context and reduces overall uncertainty.
On the other hand, when increasing System_Is’ masking ratios from 0.7 to 0.9, the ROUGE scores decrease between 3 and 5 points, while the BERTScore only decreases by less than half a point. This shows that while the generated letter is lexically further away from the original letter, the meaning is mostly preserved.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Finally, Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.T2" title="TABLE II ‣ V-A Lexical Similarity Evaluation against References ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">II</span></a> presents the overlap between the top 5, 10, 20, 50, and 100 features identified across the real and synthetic datasets, without stopwords, to further evaluate the distance of the synthetic data to the original one. The results confirm that increasing the masking ratios and utilizing the iterative filling algorithms further promotes diverse generations while conserving an acceptable amount of core information.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1">Overall, all four instances proved strong performance in maintaining the core meaning of the letter with acceptable BERTScore, while adding a good amount of diversity, reflected by the lower ROUGE scores and feature-overlapping ratios. Most importantly, a trade-off is very clear here, and we showed that the masking ratios and mask-filling techniques could be used to tune it for the needs of specific use cases.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr" id="S5.T2.1.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T2.1.1.1.2">Top 5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T2.1.1.1.3">Top 10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T2.1.1.1.4">Top 20</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T2.1.1.1.5">Top 50</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.1.1.1.6">Top 100</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T2.1.2.1.1">System_S_0.5</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.2.1.2">3.848</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.2.1.3">7.854</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.2.1.4">15.593</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.2.1.5">38.420</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.2.1.6">78.670</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T2.1.3.2.1">System_S_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.3.2.2">3.601</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.3.2.3">7.310</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.3.2.4">14.607</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.3.2.5">35.971</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.3.2.6">73.695</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T2.1.4.3.1">System_I_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.4.3.2">3.712</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.4.3.3">7.510</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.4.3.4">15.095</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.4.3.5">37.233</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.4.3.6">76.093</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T2.1.5.4.1">System_I_0.9</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.5.4.2">3.537</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.5.4.3">7.222</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.5.4.4">14.551</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.5.4.5">35.510</td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.5.4.6">72.298</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Average number of overlap between the top 5, 10, 20, 50 and 100 features identified across the real and synthetic datasets, without stopwords.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.5.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.6.2">Readability Evaluation against References</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">According to the results of the readability evaluation displayed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.T3" title="TABLE III ‣ V-B Readability Evaluation against References ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">III</span></a>, the synthetic data would be slightly easier to read than the original one. In fact, all versions of the system generated synthetic letters that were easier to read on average. Furthermore, the higher the masking ratio, the better the readability scores tend to be. This is attributed to the fact that the MLM model may fill masked tokens with words that are more common than the original ones. That is, when a complicated word is masked, the MLM model tends to replace it with a more common one.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Moreover, if we take a closer look at the systems against each other instead of against the references, it is rather difficult to differentiate a clear winner. This turns out to be very fortunate because, as explained in the previous evaluation phase, we will be able to tune the desired trade-off between diversity and fidelity without being afraid of rendering complicated and less readable letters.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_rr" id="S5.T3.1.1.1.1"></th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.1.1.2">FRE</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.1.1.3">FKG</td>
<td class="ltx_td ltx_align_left" id="S5.T3.1.1.1.4">SMOG</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T3.1.2.2.1">System_S_0.5</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.2.2.2">64.024</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.2.2.3">7.647</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.2.2.4">10.823</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T3.1.3.3.1">System_S_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.3.3.2">65.091</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.3.3.3">7.466</td>
<td class="ltx_td ltx_align_left" id="S5.T3.1.3.3.4">10.696</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T3.1.4.4.1">System_I_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.4.4.2">63.792</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.4.4.3">7.707</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.4.4.4">10.878</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T3.1.5.5.1">System_I_0.9</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.5.5.2">64.294</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.5.5.3">7.636</td>
<td class="ltx_td ltx_align_left" id="S5.T3.1.5.5.4">10.832</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T3.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.6.6.1.1">References (original letters)</span></th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.6.6.2">61.597</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.6.6.3">8.06</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.6.6.4">11.067</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Readability scores of the generated synthetic letters against references on the testing dataset.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">Data Utility Evaluation</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">In this evaluation phase, we determine how well the generated data captures the critical characteristics present in the real data by evaluating the extent to which our synthetic data retains the capability of training machine learning models that perform comparably to those trained using real data. We display the downstream pipeline in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.F2" title="Figure 2 ‣ V-C1 Downstream NER Task ‣ V-C Data Utility Evaluation ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">2</span></a> and describe it below in more detail. Finally, we give the results of the data utility evaluation.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS3.SSS1.5.1.1">V-C</span>1 </span>Downstream NER Task</h4>
<div class="ltx_para" id="S5.SS3.SSS1.p1">
<p class="ltx_p" id="S5.SS3.SSS1.p1.1">Before starting, we split the testing set into training and testing subsets. Then the downstream pipeline is presented as follows. First, the original letters are passed through the system to generate synthetic letters. Then, the original letters and synthetic letters are passed through SciSpacy<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://allenai.github.io/scispacy/</span></span></span> <span class="ltx_text ltx_font_italic" id="S5.SS3.SSS1.p1.1.1">en_ner_bc5cdr_md</span>, a SpaCy<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://spacy.io/</span></span></span> NER model trained on the BC5CDR corpus to recognize DISEASE and CHEMICAL entities, which achieved an F1-score of 0.843 on their dataset. Note that there exist alternative NER models that could be used here, something that could be worth exploring in future works. After extraction, we obtain the detected medical entities from both the original and synthetic letters. These entities are then stored to act as an original and synthetic entities dataset to train a Spacy NER model from scratch. That is, we train a first version of the Spacy NER model on the medical NER data extracted from the original <span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p1.1.2">training subset</span>, and a second version on the ones extracted from the synthetic <span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p1.1.3">training subset</span>. Finally, we evaluate both versions of Spacy on the <span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p1.1.4">testing subset</span> and compare their performance.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p2">
<p class="ltx_p" id="S5.SS3.SSS1.p2.1">Moreover, to see how much improvement can be obtained by further augmenting the synthetic dataset, we repeat this experiment and generate two synthetic letters per original letter.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p3">
<p class="ltx_p" id="S5.SS3.SSS1.p3.1">We acknowledge that errors may be propagated from SciSpacy’s extractions as it has an F1-score of “only” 0.843, but we consider that error rates may be proportional between extractions from the original and synthetic letters. 
<br class="ltx_break"/></p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="213" id="S5.F2.g1" src="extracted/5860419/Figures/Downstream.jpeg" width="568"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Design of the Downstream Task Pipeline for Data Utility Evaluation.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS3.SSS2.5.1.1">V-C</span>2 </span>Results</h4>
<div class="ltx_para" id="S5.SS3.SSS2.p1">
<p class="ltx_p" id="S5.SS3.SSS2.p1.1">The results of the downstream task are given in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S5.T4" title="TABLE IV ‣ V-C2 Results ‣ V-C Data Utility Evaluation ‣ V Results and Discussion ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag">IV</span></a>. As they demonstrate, all systems could achieve scores comparable to those obtained on the original letters. An interesting observation is that the more we increase the masking ratios, the higher the scores tend to be. That is probably due to the increased diversity generated in synthetic samples, allowing to generate more diverse samples for Spacy to train on. Additionally, it is interesting that the iterative mask-filling technique could achieve the highest score by a slight margin, which is in accordance with the lexical results obtained above.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p2">
<p class="ltx_p" id="S5.SS3.SSS2.p2.1">Furthermore, we confirm that augmenting the synthetic to twice the size of the original one slightly increases the F1-score, to achieve scores up to 0.836, i.e., only 0.006 lower than with real data. In addition, we observe that systems using iterative mask filling tend to improve more than the ones using simultaneous mask filling. This may be due to better diversity in the iterative generations, leading to more diversity between two synthetic samples generated from the same original letter.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p3">
<p class="ltx_p" id="S5.SS3.SSS2.p3.1">Overall, the evaluation scores show that our system could successfully train Spacy on this NER task on two labels (DISEASE and CHEMICAL) achieving up to 0.836 F1 scores. Most importantly, it yielded comparable performance to the real data, demonstrating the quality of generated texts and the benefit of using the generated synthetic data as an alternative to real data or to produce oversampling.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.5.1.1">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T4.5.1.1.1"></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_rr" id="S5.T4.5.1.1.2"></th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.1.1.3">Precision</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.1.1.4">Recall</td>
<td class="ltx_td ltx_align_left" id="S5.T4.5.1.1.5">F1-Score</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.2.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S5.T4.5.2.2.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T4.5.2.2.2">System_S_0.5</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.5.2.2.3">0.842</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.5.2.2.4">0.792</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.5.2.2.5">0.816</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.5.3.3.1"><span class="ltx_text ltx_font_bold" id="S5.T4.5.3.3.1.1">Augmented</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T4.5.3.3.2">System_S_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.3.3.3">0.851</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.3.3.4">0.797</td>
<td class="ltx_td ltx_align_left" id="S5.T4.5.3.3.5">0.823</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.5.4.4.1"><span class="ltx_text ltx_font_bold" id="S5.T4.5.4.4.1.1">by x1</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T4.5.4.4.2">System_I_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.4.4.3">0.831</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.4.4.4">0.812</td>
<td class="ltx_td ltx_align_left" id="S5.T4.5.4.4.5">0.821</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.5.5">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T4.5.5.5.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T4.5.5.5.2">System_I_0.9</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.5.5.3">0.846</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.5.5.4">0.810</td>
<td class="ltx_td ltx_align_left" id="S5.T4.5.5.5.5">0.827</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.6.6">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S5.T4.5.6.6.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T4.5.6.6.2">System_S_0.5</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.5.6.6.3">0.844</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.5.6.6.4">0.800</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.5.6.6.5">0.821</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.5.7.7.1"><span class="ltx_text ltx_font_bold" id="S5.T4.5.7.7.1.1">Augmented</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T4.5.7.7.2">System_S_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.7.7.3">0.850</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.7.7.4">0.805</td>
<td class="ltx_td ltx_align_left" id="S5.T4.5.7.7.5">0.828</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.5.8.8.1"><span class="ltx_text ltx_font_bold" id="S5.T4.5.8.8.1.1">by x2</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T4.5.8.8.2">System_I_0.7</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.8.8.3">0.838</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.8.8.4">0.819</td>
<td class="ltx_td ltx_align_left" id="S5.T4.5.8.8.5">0.829</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.9.9">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T4.5.9.9.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T4.5.9.9.2">System_I_0.9</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.9.9.3">0.855</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.5.9.9.4">0.819</td>
<td class="ltx_td ltx_align_left" id="S5.T4.5.9.9.5"><span class="ltx_text ltx_font_bold" id="S5.T4.5.9.9.5.1">0.836</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.10.10">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S5.T4.5.10.10.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T4.5.10.10.2"><span class="ltx_text ltx_font_bold" id="S5.T4.5.10.10.2.1">References</span></th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.5.10.10.3">0.86</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.5.10.10.4">0.824</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.5.10.10.5">0.842</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Average Precision, Recall and F1-score for two labels (DISEASE and CHEMICAL) using Synthetic data <math alttext="\times 1" class="ltx_Math" display="inline" id="S5.T4.3.m1.1"><semantics id="S5.T4.3.m1.1b"><mrow id="S5.T4.3.m1.1.1" xref="S5.T4.3.m1.1.1.cmml"><mi id="S5.T4.3.m1.1.1.2" xref="S5.T4.3.m1.1.1.2.cmml"></mi><mo id="S5.T4.3.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.T4.3.m1.1.1.1.cmml">×</mo><mn id="S5.T4.3.m1.1.1.3" xref="S5.T4.3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.3.m1.1c"><apply id="S5.T4.3.m1.1.1.cmml" xref="S5.T4.3.m1.1.1"><times id="S5.T4.3.m1.1.1.1.cmml" xref="S5.T4.3.m1.1.1.1"></times><csymbol cd="latexml" id="S5.T4.3.m1.1.1.2.cmml" xref="S5.T4.3.m1.1.1.2">absent</csymbol><cn id="S5.T4.3.m1.1.1.3.cmml" type="integer" xref="S5.T4.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.m1.1d">\times 1</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.m1.1e">× 1</annotation></semantics></math>, <math alttext="\times 2" class="ltx_Math" display="inline" id="S5.T4.4.m2.1"><semantics id="S5.T4.4.m2.1b"><mrow id="S5.T4.4.m2.1.1" xref="S5.T4.4.m2.1.1.cmml"><mi id="S5.T4.4.m2.1.1.2" xref="S5.T4.4.m2.1.1.2.cmml"></mi><mo id="S5.T4.4.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.T4.4.m2.1.1.1.cmml">×</mo><mn id="S5.T4.4.m2.1.1.3" xref="S5.T4.4.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.4.m2.1c"><apply id="S5.T4.4.m2.1.1.cmml" xref="S5.T4.4.m2.1.1"><times id="S5.T4.4.m2.1.1.1.cmml" xref="S5.T4.4.m2.1.1.1"></times><csymbol cd="latexml" id="S5.T4.4.m2.1.1.2.cmml" xref="S5.T4.4.m2.1.1.2">absent</csymbol><cn id="S5.T4.4.m2.1.1.3.cmml" type="integer" xref="S5.T4.4.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.m2.1d">\times 2</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.m2.1e">× 2</annotation></semantics></math>, and Real data on the testing dataset.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.5.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.6.2">Data Privacy Evaluation</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">In this final evaluation phase, we assess the privacy and de-identification capabilities of our system.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">First, we calculate the de-identification rate of our system, i.e., the accuracy of the <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.1">Masker</span> in identifying all protected health information in our testing dataset. When considering all PHI categories defined in section <a class="ltx_ref" href="https://arxiv.org/html/2409.09831v2#S4.SS1" title="IV-A Datasets ‣ IV Experimental Setup ‣ Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a> (including additional sub-categories), Philter was able to achieve a recall of 0.92. Furthermore, when only considering HIPAA-PHI categories, it achieved a lower-bound recall of 0.96, excluding POS masked by the <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.2">Masker</span>. Note that only recall is of interest as only the False Negatives, i.e. PHIs that were not detected, can affect patients’ privacy.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">Secondly, we calculated the re-identification risk, i.e. the probability that our MLM model re-introduces a valid protected health information masked by the <span class="ltx_text ltx_font_italic" id="S5.SS4.p3.1.1">Masker</span>. To evaluate the re-identification risk, we leverage the risk of presence disclosure which assesses an attacker’s ability to determine if any real patient records in their possession were used to train the MLM model by comparing these records against the synthetic patient dataset. Assessing the risk of presence disclosure ensures the privacy of individuals whose data was used to train a decision model, as well as the interests of the healthcare entity where the individual received treatment. Thus, presence disclosure is a widely evaluated measure of re-identification risk. As a result, we observed that our MLM model re-identified masked PHI entities of more than two tokens with a probability of only 0.035. To give further insights into the re-identification risk, we calculated the rate of longest common substrings with lengths of 3 or more, 5 or more, and 7 or more, between original and synthetic PHIs. The outcomes showed rates of only 0.098, 0.020 and 0.009, respectively.</p>
</div>
<div class="ltx_para" id="S5.SS4.p4">
<p class="ltx_p" id="S5.SS4.p4.1">These two sets of results further showcase the effectiveness of our system to de-identify HIPAA-PHI entities (and additional categories) while guaranteeing a very low re-identification rate.</p>
</div>
<div class="ltx_para" id="S5.SS4.p5">
<p class="ltx_p" id="S5.SS4.p5.1">As an interesting improvement, we believe that re-identification risk could be further decreased to nearly zero by adding a logic-based component responsible for filling in masked dates. This would also further improve the generation of interconnected events as temporal information could be kept logical and in accordance with the original letter, which is hard to tune in a deep language model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusions and Future Work</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In conclusion, our system successfully generated synthetic medical records, including discharge summaries, admission notes, and doctor correspondences. The results demonstrated that (1) the system maintained the core meaning of the records while introducing significant diversity. Furthermore, we demonstrated the flexibility of our model which allowed us to tune the trade-off between diversity and fidelity, depending on the use case and based on the masking ratios and mask-filling technique, without compromising the readability of the synthetic records. Additionally, (3) the downstream evaluation task showcased the ability of our system to successfully train Spacy on the given NER task, achieving comparable performance to those achieved with real data. This highlights the quality of the generated medical records and underscores the benefit of using our system to generate synthetic data as a viable alternative to real data. Finally, (4) our system demonstrated high effectiveness in de-identifying HIPAA-PHI entities with a recall of 0.96 while guaranteeing a low re-identification risk of 0.035.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS1.5.1.1">VI-A</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS1.6.2">Limitations</span>
</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Upon careful analysis of the generated samples, we observed that consistently filling temporal information throughout the synthetic letter, and aligning it with the original data, presents a significant challenge. Furthermore, other interconnected events such as two names within a discussion may be complicated to assign consistently when one is not present in the context’s window at the moment of generation. This is an issue that our system may encounter and is rather important as medical data inherently consists of time series, where interconnected and temporal information are critical for numerous applications, such as modeling the progression of diseases. As a result, we recommend using our system as a means to generate synthetic data used to enhance machine learning performance, and not as a tool for the training or teaching of humans.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">In addition, although a majority of medical information is kept untouched due to the medical NER model in the <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.1">Masker</span>, some medical entities that are classified as non-critical may be masked and replaced. As a result, and because it is really difficult to automate and expensive to manually evaluate, we are not able to guarantee that all generated records are medically sound. Therefore, we recommend using the synthetic data in cases where medical soundness is not necessary.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS2.5.1.1">VI-B</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS2.6.2">Future works</span>
</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">With regards to the <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.1">Masker</span> component, future work could involve experimenting with alternative medical NER models to extract different types of critical medical information. Our current NER model identifies problems, tests, and treatments, but alternative models such as <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.2">Stanza Radiology</span> or <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.3">Stanza Bionlp13cg</span> could be better suited for specific datasets. Additionally, it would be worth exploring extra masking ratios for the medical NER and POS tagger to understand further its effect on the trade-off between diversity and fidelity in the generated outputs.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">Regarding the Mask-Filling Algorithm, training or fine-tuning additional baseline Masked Language models could significantly influence the quality of the generated data, making further experiments on this matter interesting. Another idea is to investigate whether passing the type of entity to be replaced into the MLM could improve PHI replacement accuracy and generation quality, particularly when less context is available. This approach might also allow to reduce the chunk/window size required, thereby lowering the computational cost of generating synthetic data.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">Moreover, incorporating a logic-based component responsible for filling in masked PHI dates could ensure that all dates are consistently replaced and aligned throughout the synthetic letter. As noted in our results, this would also reduce the re-identification risk.</p>
</div>
<div class="ltx_para" id="S6.SS2.p4">
<p class="ltx_p" id="S6.SS2.p4.1">Finally, expanding the evaluation of the system to a broader set of downstream tasks and datasets would provide a more comprehensive understanding of its potential applications. This includes applying the system to specialized datasets, such as those in radiology or oncology, together with appropriate medical NER models and system configurations.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Gonzales, G. Guruswamy, and S. R. Smith, “Synthetic data in health care: A narrative review,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">PLOS Digital Health</em>, vol. 2, no. 1, p. e0000082, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
R. J. Chen, M. Y. Lu, T. Y. Chen, D. F. Williamson, and F. Mahmood, “Synthetic data in machine learning for medicine and healthcare,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Nature Biomedical Engineering</em>, vol. 5, no. 6, pp. 493–497, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. L. Beam and I. S. Kohane, “Big data and machine learning in health care,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Jama</em>, vol. 319, no. 13, pp. 1317–1318, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
N. D. Shah, E. W. Steyerberg, and D. M. Kent, “Big data and predictive analytics: recalibrating expectations,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Jama</em>, vol. 320, no. 1, pp. 27–28, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
W. N. Price and I. G. Cohen, “Privacy in the age of medical big data,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Nature medicine</em>, vol. 25, no. 1, pp. 37–43, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. Tucker, Z. Wang, Y. Rotalinti, and P. Myles, “Generating high-fidelity synthetic patient data for assessing machine learning healthcare software,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">NPJ digital medicine</em>, vol. 3, no. 1, pp. 1–13, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Z. Li, S. Belkadi, N. Micheletti, L. Han, M. Shardlow, and G. Nenadic, “Large language models and control mechanisms improve text readability of biomedical abstracts,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2309.13202</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S. James, C. Harbron, J. Branson, and M. Sundler, “Synthetic data use: exploring use cases to optimise data utility,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Discover Artificial Intelligence</em>, vol. 1, no. 1, p. 15, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Belkadi, L. Han, Y. Wu, and G. Nenadic, “Exploring the value of pre-trained language models for clinical named entity recognition,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">2023 IEEE International Conference on Big Data (BigData)</em>.   IEEE, 2023, pp. 3660–3669.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
N. Norori, Q. Hu, F. M. Aellen, F. D. Faraci, and A. Tzovara, “Addressing bias in big data and ai for health care: A call for open science,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Patterns</em>, vol. 2, no. 10, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Belkadi, N. Micheletti, L. Han, W. Del-Pinto, and G. Nenadic, “Generating medical prescriptions with conditional transformer,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv e-prints</em>, pp. arXiv–2310, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
N. Micheletti, S. Belkadi, L. Han, and G. Nenadic, “Exploration of masked and causal language modelling for text generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2405.12630</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
L. Radhakrishnan, G. Schenk, K. Muenzen, B. Oskotsky, H. Ashouri Choshali, T. Plunkett, S. Israni, and A. J. Butte, “A certified de-identification system for all clinical text documents for information extraction at scale,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">JAMIA open</em>, vol. 6, no. 3, p. ooad045, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
C. Yan, Z. Zhang, S. Nyemba, and Z. Li, “Generating synthetic electronic health record data using generative adversarial networks: Tutorial,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">JMIR AI</em>, vol. 3, p. e52615, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
S. N. Kasthurirathne, G. Dexter, and S. J. Grannis, “Generative adversarial networks for creating synthetic free-text medical data: a proposal for collaborative research and re-use of machine learning models,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">AMIA Summits on Translational Science Proceedings</em>, vol. 2021, p. 335, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Q. Lu, D. Dou, and T. H. Nguyen, “Textual data augmentation for patient outcomes prediction,” in <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">2021 IEEE international conference on bioinformatics and biomedicine (BIBM)</em>.   IEEE, 2021, pp. 2817–2821.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Amin-Nejad, J. Ive, and S. Velupillai, “Exploring transformer text generation for medical dataset augmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, 2020, pp. 4699–4708.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Falis, A. P. Gema, H. Dong, L. Daines, S. Basetti, M. Holder, R. S. Penfold, A. Birch, and B. Alex, “Can gpt-3.5 generate and code discharge summaries?” <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2401.13512</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
L. Ren, S. Belkadi, L. Han, W. Del-Pinto, and G. Nenadic, “Synthetic4health: Generating annotated synthetic clinical letters,” 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2409.09501" title="">https://arxiv.org/abs/2409.09501</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
B. Norgeot, K. Muenzen, T. A. Peterson, X. Fan, B. S. Glicksberg, G. Schenk, E. Rutenberg, B. Oskotsky, M. Sirota, J. Yazdany <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">et al.</em>, “Protected health information filter (philter): accurately and securely de-identifying free-text clinical notes,” <em class="ltx_emph ltx_font_italic" id="bib.bib20.2.2">NPJ digital medicine</em>, vol. 3, no. 1, p. 57, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Lee, W. Yoon, S. Kim, D. Kim, S. Kim, C. H. So, and J. Kang, “Biobert: a pre-trained biomedical language representation model for biomedical text mining,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Bioinformatics</em>, vol. 36, no. 4, pp. 1234–1240, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. E. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng, M. Ghassemi, B. Moody, P. Szolovits, L. Anthony Celi, and R. G. Mark, “Mimic-iii, a freely accessible critical care database,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Scientific data</em>, vol. 3, no. 1, pp. 1–9, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
H. T. Kesgin and M. F. Amasyali, “Iterative mask filling: An effective text augmentation method using masked language modeling,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">International Conference on Advanced Engineering, Technology and Applications</em>.   Springer, 2023, pp. 450–463.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A. Stubbs and Ö. Uzuner, “Annotating longitudinal clinical narratives for de-identification: The 2014 i2b2/uthealth corpus,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Journal of biomedical informatics</em>, vol. 58, pp. S20–S29, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
A. Stubbs, C. Kotfila, and Ö. Uzuner, “Automated systems for the de-identification of longitudinal clinical narratives: Overview of 2014 i2b2/uthealth shared task track 1,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Journal of biomedical informatics</em>, vol. 58, pp. S11–S19, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
R. Turner, D. Eriksson, M. McCourt, J. Kiili, E. Laaksonen, Z. Xu, and I. Guyon, “Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge 2020,” in <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">NeurIPS 2020 Competition and Demonstration Track</em>.   PMLR, 2021, pp. 3–26.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
T. Akiba, S. Sano, T. Yanase, T. Ohta, and M. Koyama, “Optuna: A next-generation hyperparameter optimization framework,” in <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</em>, 2019, pp. 2623–2631.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Examples of generated synthetic letters</h2>
<figure class="ltx_figure" id="Ax1.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="Ax1.F3.1" style="width:203.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="853" id="Ax1.F3.1.g1" src="extracted/5860419/Figures/I_70_1.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="Ax1.F3.2" style="width:203.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="849" id="Ax1.F3.2.g1" src="extracted/5860419/Figures/I_70_2.png" width="598"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="Ax1.F3.3" style="width:203.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="837" id="Ax1.F3.3.g1" src="extracted/5860419/Figures/S_50_1.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="Ax1.F3.4" style="width:203.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="729" id="Ax1.F3.4.g1" src="extracted/5860419/Figures/S_50_2.png" width="598"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Synthetic letters generated from letter 201-03 using System_I_0.7 (Top) and System_S_0.5 (Bottom).</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 17 11:14:59 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
