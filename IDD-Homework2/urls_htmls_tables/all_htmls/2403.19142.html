<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Tulu Resource for Machine Translation</title>
<!--Generated on Thu May  2 21:47:17 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2403.19142v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S1" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S2" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Linguistic Context</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S2.SS0.SSS0.Px1" title="In 2. Linguistic Context ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title">Kannada</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S2.SS0.SSS0.Px2" title="In 2. Linguistic Context ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title">Tulu</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S3" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S4" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>The 1<sup class="ltx_sup">st</sup> Dataset for Tulu MT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S5" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S5.SS1" title="In 5. Experiments ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S5.SS2" title="In 5. Experiments ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>IndicBARTSS &amp; YANMTT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S5.SS3" title="In 5. Experiments ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>NMT-Adapt</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S5.SS4" title="In 5. Experiments ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Fine-tuning with EN–TCY data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.SS0.SSS0.Px1" title="In 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title">English-Tulu Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.SS0.SSS0.Px2" title="In 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title">Tulu-English Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.SS0.SSS0.Px3" title="In 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title">Further Iterations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.SS0.SSS0.Px4" title="In 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title">Fine-tuning with <span class="ltx_text ltx_font_italic">DravidianLangTech</span> data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.SS0.SSS0.Px5" title="In 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title">Tulu Translation Performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.SS1" title="In 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Qualitative Error Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S7" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S8" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S9" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Ethics Statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S10" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Acknowledgements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S11" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11 </span>Bibliographical References</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S12" title="In A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">12 </span>Language Resource References</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">A Tulu Resource for Machine Translation</h1>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">We present the first parallel dataset for English–Tulu translation. Tulu, classified within the South Dravidian linguistic family branch, is predominantly spoken by approximately 2.5 million individuals in southwestern India. Our dataset is constructed by integrating human translations into the multilingual machine translation resource FLORES-200.
Furthermore, we use this dataset for evaluation purposes in developing our English–Tulu machine translation model. For the model’s training, we leverage resources available for related South Dravidian languages. We adopt a transfer learning approach that exploits similarities between high-resource and low-resource languages. This method enables the training of a machine translation system even in the absence of parallel data between the source and target language, thereby overcoming a significant obstacle in machine translation development for low-resource languages.
Our English–Tulu system, trained without using parallel English–Tulu data, outperforms Google Translate by 19 BLEU points (in September 2023).
The dataset and code are available here: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/manunarayanan/Tulu-NMT" title="">https://github.com/manunarayanan/Tulu-NMT</a>.

<br class="ltx_break"/>
<br class="ltx_break"/>
<span class="ltx_text ltx_font_bold" id="id2.id1.1">Keywords: </span>Dravidian Language Tulu, Low-Resource Languages, Parallel Dataset, Machine Translation</p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\NAT@set@cites</span>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1"><span class="ltx_text" id="p2.1.1"></span></p>
</div>
<div class="ltx_logical-block" id="id1">
<div class="ltx_para" id="id1.p1">
<p class="ltx_p ltx_align_center" id="id1.p1.1"><span class="ltx_text ltx_font_bold" id="id1.p1.1.1" style="font-size:144%;">A Tulu Resource for Machine Translation</span></p>
<br class="ltx_break ltx_centering"/>
<table class="ltx_tabular ltx_centering ltx_align_top" id="id1.p1.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="id1.p1.2.1.1">
<td class="ltx_td ltx_align_center" id="id1.p1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="id1.p1.2.1.1.1.1" style="font-size:120%;">Manu Narayanan, Noëmi Aepli</span></td>
</tr>
<tr class="ltx_tr" id="id1.p1.2.2.2">
<td class="ltx_td ltx_align_center" id="id1.p1.2.2.2.1">University of Zurich</td>
</tr>
<tr class="ltx_tr" id="id1.p1.2.3.3">
<td class="ltx_td ltx_align_center" id="id1.p1.2.3.3.1">{manu.narayanan,noemi.aepli}@uzh.ch</td>
</tr>
</tbody>
</table>
<p class="ltx_p ltx_align_center" id="id1.p1.3"><span class="ltx_text ltx_font_italic" id="id1.p1.3.1">Abstract content</span></p>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">1.   Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Over the past decade, the field of neural machine translation (NMT) has seen significant advances with the advent of sequence-to-sequence models <cite class="ltx_cite ltx_citemacro_citep">(Sutskever et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib33" title="">2014</a>)</cite>, attention mechanisms <cite class="ltx_cite ltx_citemacro_citep">(Bahdanau et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib3" title="">2015</a>)</cite>, and transformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib35" title="">2017</a>)</cite>.
However, these advancements fall short when confronted with languages lacking extensive parallel datasets. Challenges stemming from both the scarcity of abundant parallel data and the absence of domain-diverse data pose significant hurdles in crafting robust NMT models <cite class="ltx_cite ltx_citemacro_citep">(Koehn and Knowles, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib17" title="">2017</a>)</cite>.
Regrettably, a vast majority of the world’s linguistic diversity, spanning over 7,000 languages, faces one or both of these challenges <cite class="ltx_cite ltx_citemacro_citep">(Littauer and Paterson III, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib21" title="">2016</a>; Lakew et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib19" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Among these languages stands Tulu (ISO 639-3 code: TCY), a South-Dravidian language spoken by approximately 2.5 million individuals in India <cite class="ltx_cite ltx_citemacro_citep">(Madasamy et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib2" title="">2022</a>)</cite>, characterized by several dialects <cite class="ltx_cite ltx_citemacro_citep">(Eberhard et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib11" title="">2023</a>)</cite>.
Tulu is not recognized as an official language, neither in India nor in any other country. Hence, it is not used for official purposes and education, where Kannada or Malayalam is used instead.
However, efforts to enhance accessibility to the language have been evident through Unicode proposals for a Tulu script and petitions urging the Indian government to recognize Tulu as an official state language <cite class="ltx_cite ltx_citemacro_citep">(Thadhagath, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib34" title="">2023</a>)</cite>.
Furthermore, Tulu demonstrates a notable online presence and engagement among its speakers through various social media platforms. For instance, <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">Jai Tulunad<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote1.1.1.1">1</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://jaitulunad.in/" title="">https://jaitulunad.in/</a></span></span></span></span>, a volunteer organization established in 2014 in Karnataka, India, maintains active profiles on several social media platforms with over 1,000 engaged subscribers. They launched an online English-Tulu dictionary in 2021 and regularly host cultural and educational events for Tulu speakers.
Furthermore, several groups on social media are exclusively dedicated to Tulu language memes and other content.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.facebook.com/VenurTroll" title="">https://www.facebook.com/VenurTroll</a></span></span></span> Moreover, Tulu features a vibrant film industry, which produced nine movies in 2023.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/List_of_Tulu_films_of_2023" title="">https://en.wikipedia.org/wiki/List_of_Tulu_films_of_2023</a></span></span></span></p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="87" id="S1.F1.g1" src="extracted/2403.19142v1/tulu_example.png" width="252"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A sentence in Tulu taken from our human-translated extension of the FLORES-200 dataset. English: ‘<span class="ltx_text ltx_font_italic" id="S1.F1.2.1">I am happy that there are people willing to support me.</span>’</figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Considering the surge of information driven by the internet and social media, coupled with the increasing importance of language accessibility in contemporary society, it becomes crucial to create resources and methodologies that tackle the translation challenges encountered by low-resource languages. This endeavor plays a crucial role in promoting social equity, economic equality, and political inclusivity.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Transfer learning offers an approach to mitigate the low-resource issue to a certain extent. It aims to use existing knowledge to adapt pre-trained models. Instead of starting from scratch, this technique facilitates the adaptation of already-trained models to new languages, particularly when a related language with such resources is available.
Tulu is fortunate in this regard, as Kannada (ISO 639-3 code: KAN) serves as a closely-related language with some readily available NLP resources.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this study, we present the first parallel dataset for Tulu and use it to evaluate our machine translation system for English–Tulu. Without access to parallel EN–TCY data, we developed this system using a transfer learning <cite class="ltx_cite ltx_citemacro_citep">(Zoph et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib37" title="">2016</a>)</cite> to address translation challenges in this low-resource language.
Our main contributions are:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Introducing a machine translation dataset for Tulu by extending FLORES-200 with human translations into Tulu.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Developing a machine translation system for English–Tulu, leveraging the resources of related Dravidian languages and employing transfer learning.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">2.   Linguistic Context</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Languages spoken in the South Asian region belong to at least four major language families: Dravidian, Austro-Asiatic, Sino-Tibetan, and Indo-European (predominantly from the Indo-Aryan sub-branch). Among these, the Dravidian languages constitute the second-largest group.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>See <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://censusindia.gov.in/nada/index.php/catalog/42561" title="">https://censusindia.gov.in/nada/index.php/catalog/42561</a>, page 14.</span></span></span></p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The Dravidian language family ranks as the fifth largest language family globally, comprising approximately 25 languages primarily spoken in India <cite class="ltx_cite ltx_citemacro_citep">(Subrahmanyam, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib32" title="">2006</a>)</cite>. This family is divided into four subgroups: North Dravidian, South Dravidian, South-Central Dravidian, and Central Dravidian. Tulu, Kannada, and Malayalam belong to the South Dravidian subgroup.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Dravidian languages generally share the following main characteristics:
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Vowels</span> Most of the Dravidian languages have ‘a 10-vowel system, with five short and five long ones’ <cite class="ltx_cite ltx_citemacro_citep">(Subrahmanyam, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib32" title="">2006</a>)</cite>.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p3.1.2">Consonants</span> Retroflex consonants, a distinctive feature rare outside the Indian subcontinent, are prominent in Dravidian languages. However, voiced stops and aspirated stops are notably absent in these languages.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p3.1.3">Cases</span> According to <cite class="ltx_cite ltx_citemacro_citep">(Steever, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib30" title="">2017</a>)</cite>, Dravidian languages typically feature between five and eight cases. These include nominative, accusative, dative, genitive, locative (‘in’), ablative (‘from’), sociative (‘with’), and instrumental (‘by’). Kannada and Tulu exhibit all eight cases, while Malayalam has seven, with the absence of the ablative case.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p3.1.4">Morphology</span> Dravidian languages are characterized as agglutinative, with grammatical relations such as voice or tense typically expressed through suffixation and compounding.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p3.1.5">Syntax</span> Word order is a flexible subject-object-verb, with the verb always in the final position.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p3.1.6">Writing</span> The primary Dravidian scripts in current use include Kannada, Malayalam, Tamil, and Telugu. The Tigalari script, historically used for writing Tulu, has gradually fallen out of use over the past few centuries, leading to the adoption of the Kannada script for writing Tulu <cite class="ltx_cite ltx_citemacro_citep">(Steever, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib31" title="">2019</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Kannada</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">is spoken by approximately 43.7 million people in India, according to <cite class="ltx_cite ltx_citemacro_citet">Office of the Registrar General &amp; Census Commissioner, India (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib25" title="">2022</a>)</cite>, with around 93% of them residing in Karnataka, where it holds the status of the official language.
Kannada shares most of the typical characteristics of the Dravidian languages listed above.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">Tulu and Kannada have co-evolved in close geographical and cultural proximity since at least the 8th century CE. Since 1947, Kannada has served as the official language in the Tulu-speaking region, with the exception of Kasaragod district, where Malayalam holds official status. Consequently, there has been an increasing trend of using Kannada loanwords in contemporary Tulu. Numerous Tulu words exhibit notable similarities to their Kannada equivalents.
Hence, Kannada resources can serve as a starting point for constructing NLP systems tailored to Tulu.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Tulu</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">is spoken by around 2.5 million people <cite class="ltx_cite ltx_citemacro_citep">(Madasamy et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib2" title="">2022</a>)</cite> in the Dakshina Kannada and Udupi districts of Karnataka state and the Kasargod district of the Kerala state, with scattered speakers found in Maharashtra and other regions of India. Malayalam and Kannada share linguistic ties with Tulu, which comprises several dialects <cite class="ltx_cite ltx_citemacro_citep">(Eberhard et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib11" title="">2023</a>)</cite>.
The benchmark dataset introduced in this study is closely aligned with Central Tulu, which is predominantly spoken in the Mangaluru region and serves as the primary city in the Tulu-speaking area. We employ the Kannada script for written communication, reflecting the prevailing practice among Tulu speakers.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">The grammatical aspects of Tulu are similar to other South Dravidian languages <cite class="ltx_cite ltx_citemacro_citep">(Brigel, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib8" title="">1982</a>)</cite>. The majority of Tulu speakers are bilingual, often using Kannada or Malayalam when communicating with individuals outside their community within their respective states. The Tigalari script, traditionally used for writing Tulu, has been gradually replaced by Kannada. A significant contributing factor to this transition is the absence of a Unicode script that supports Tigalari characters. Additionally, the Tulu community has refrained from writing in Tulu for several generations, opting to use Kannada or Malayalam for official purposes and education. Consequently, the Tigalari script has fallen out of use over the generations.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">3.   Related Work</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">Shared Task on Translation of Under-Resourced Dravidian Languages</span> at the <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">DravidianLangTech-2022</span> workshop <cite class="ltx_cite ltx_citemacro_citep">(Madasamy et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib2" title="">2022</a>)</cite> involved Kannada–Tulu as one of the language pairs to be translated. The participants were given a Kannada-Tulu parallel training dataset of 8,300 sentences and development and test sets containing 1,000 sentences each. These datasets were created by collecting monolingual Tulu documents from digitally accessible sources and manually translating them into Kannada. The team that scored the highest BLEU score <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib27" title="">2002</a>)</cite> for Kannada–Tulu translation trained a transformer model provided by OpenNMT <cite class="ltx_cite ltx_citemacro_citep">(Klein et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib15" title="">2017</a>)</cite>
for five different Dravidian languages (Tamil, Malayalam, Telugu, Kannada and Tulu) and got a BLEU score of 61.49 <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib13" title="">2022</a>)</cite>. They trained their model for Tulu using only the 8,300 sentences of the training set. They hypothesize that the BLEU score might be higher because of the similarity of training and test sentences and, thus, high word overlap in the source and target data. A word or even sentence overlap in source and target might occur since Kannada and Tulu are similar with quite some shared vocabulary.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Bala Das et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib4" title="">2023</a>)</cite> focus specifically on translating low-resource Indic languages by developing a multilingual NMT system with a shared encoder-decoder containing 15 language pairs (i.e. English and 14 Indic languages). They utilize the similarity between Indic languages, along with back-translation and domain adaptation, to achieve better results in translating low-resource languages. However, all the language pairs explored in the paper have parallel training data available, and back-translation is used only to create synthetic parallel training data from monolingual sentences.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">The transfer learning approach NMT-Adapt <cite class="ltx_cite ltx_citemacro_citep">(Ko et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite> aims to leverage the lexical and syntactic structure similarities between high-resource languages and low-resource languages and train a translation model without using any parallel data. It combines denoising autoencoding <cite class="ltx_cite ltx_citemacro_citep">(Artetxe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib1" title="">2018</a>)</cite>, back-translation <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib29" title="">2016</a>)</cite>, and adversarial objectives to utilize monolingual data for low-resource adaptation. <cite class="ltx_cite ltx_citemacro_citet">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite> experimented with three groups of languages, namely Iberian languages, Indic languages, and Arabic. Within the Indic languages, they treated Hindi as the high-resource language and Marathi, Nepali, and Urdu as related low-resource languages.
<cite class="ltx_cite ltx_citemacro_citet">Sennrich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib29" title="">2016</a>)</cite> had already shown that pairing monolingual data with automatic back-translation and using that as additional parallel training data can improve the capability of an English–<span class="ltx_text ltx_font_italic" id="S3.p3.1.1">German</span> model to translate <span class="ltx_text ltx_font_italic" id="S3.p3.1.2">Turkish</span>–English. <cite class="ltx_cite ltx_citemacro_citet">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite> added denoising autoencoding to this task, such that the model learns a shared feature space for the high-resource and low-resource languages and enables the encoder and decoder to transform between the features and the sentences. This involves adding noise to datasets in both languages by randomly shuffling words by at most 3-word positions and masking words with a uniform probability of 0.1. A dataset with this ‘noised’ data, along with the original data, is used to do the denoising autoencoding. The denoising autoencoding trains the model to reconstruct the original version of a corrupted input sentence <cite class="ltx_cite ltx_citemacro_citep">(Artetxe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib1" title="">2018</a>)</cite>. According to <cite class="ltx_cite ltx_citemacro_citet">Lample et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib20" title="">2018</a>)</cite>, this enables the feature space to learn high-level semantic knowledge and make it more robust.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">4.   The 1<sup class="ltx_sup ltx_centering" id="S4.1.1">st</sup> Dataset for Tulu MT</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To maximize the potential impact, we opted to extend an already existing and widely adopted benchmark dataset for the creation of a Tulu dataset: <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">FLORES-200</span>, ‘Evaluation Benchmark for Low-Resource and Multilingual Machine Translation’<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>‘The sentences were sampled in equal amounts from Wikinews (an international news source), Wikijunior (a collection of age-appropriate non-fiction books), and Wikivoyage (a travel guide).’ <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/openlanguagedata/flores" title="">https://github.com/openlanguagedata/flores</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib1" title="">2022</a>; NLLB Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib3" title="">2022</a>)</cite>, which contains over 200 language varieties to-date.
The FLORES-200 dataset comprises 2009 sentences for each language.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">To obtain the translations, we collaborated with the organization <span class="ltx_text ltx_font_italic" id="S4.p2.1.1">Jai Tulunad<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote6.1.1.1">6</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://www.jaitulunad.com/about" title="">https://www.jaitulunad.com/about</a></span></span></span></span>, a volunteer organization headquartered in the southern Indian city of Mangaluru.
This collaboration was crucial not only for us to find native Tulu speakers but also because an increasing number of researchers have underscored the significance for NLP researchers to prioritize the needs and preferences of the pertinent speaker community <cite class="ltx_cite ltx_citemacro_citep">(Bird, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib5" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib6" title="">2022</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib23" title="">2022</a>; Mukhija et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib24" title="">2021</a>; Blaschke et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib7" title="">2024</a>)</cite>. The organization and the translators were happy to contribute to our project
which makes us confident that this is in the interest of the Tulu community.
<span class="ltx_text ltx_font_italic" id="S4.p2.1.2">Jai Tulunad</span> is dedicated to preserving and promoting Tulu language and culture. Approximately 15 volunteers from this organization, based in Mangaluru, Karnataka state, India, participated in translating the sentences from the FLORES-200 dataset into Tulu. While the volunteers are not professional translators, they are all native Tulu speakers fluent in English. Furthermore, they all have native proficiency in Kannada since Kannada is the language taught in schools, used for official purposes and for communicating with people in non-Tulu speaking communities in the same region.
Among the translators, two are Tulu language instructors, and one is a distinguished Tulu poet.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">During the translation process, translators referred to both English and Kannada sentences in the dataset and translated them into Tulu. They consulted with literary experts within the translator group to address questions regarding Tulu vocabulary and resolved decisions regarding the utilization of outdated Tulu words, colloquialisms, and loanwords from Kannada in the translation.
Along with the original FLORES-200 dataset, we provided the translators with guidelines, which we adapted from the original guidelines that were published by <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib1" title="">2022</a>; NLLB Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib3" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.p4">
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Translations must be neutral, informative, and clear to native speakers.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">No assistance from any machine translation tools; this was easy since there are no existing machine translation tools for Tulu.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">Proper nouns may be transliterated if no equivalent term exists in Tulu. Similarly, abbreviations must be translated in the manner they usually appear in Tulu.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">Idioms, metaphors, etc. need not be translated word by word. They should be translated as they usually appear in Tulu.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">The most knowledgeable individuals among the team (in this case, the Tulu school teachers and the poet) shall take on the role of experts, who will resolve any queries that the other translators may have. They shall also review all the sentences translated by everyone, including themselves, to eliminate typos, grammatical errors, and any other translation errors.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">Throughout the translation process, we had regular conversations with two members of the team who coordinated the whole process. The major challenges the translators faced during this process are listed below:</p>
</div>
<div class="ltx_para" id="S4.p6">
<ol class="ltx_enumerate" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">While the vocabulary of Tulu historically encompassed a vast array of words, many of them have fallen out of common use today, particularly as they are not taught in schools as part of contemporary Tulu. Additionally, many Tulu words have been replaced by Kannada or Sanskrit<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.ethnologue.com/language/san/" title="">https://www.ethnologue.com/language/san/</a></span></span></span> equivalents, further complicating the preservation of the language. As a result, the team encountered the need for frequent considerations to determine the appropriate word choices in specific instances, given the absence of a widely accepted standard Tulu.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">Passive voice is not commonly used in Tulu, nor in any other modern Dravidian languages according to <cite class="ltx_cite ltx_citemacro_citet">Krishnamurti (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib18" title="">2003</a>)</cite>. Consequently, a literal translation of an English sentence in passive voice may sound unusual in Tulu. Hence, such sentences were translated into the commonly used active voice.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1">Dialectical variations exist within Tulu based on the region of origin of the speaker. Therefore, the team had to pay attention to using a consistent dialect. In this case, all translators adhered to the Mangaluru (Central Tulunad) dialect.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1">There are two variations of the phonetic <span class="ltx_text ltx_font_typewriter" id="S4.I2.i4.p1.1.1">/e/</span>
sound (a close-mid front unrounded vowel) in Tulu, which occur when it is in the word-final position, a unique feature of Tulu <cite class="ltx_cite ltx_citemacro_citep">(Subrahmanyam, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib32" title="">2006</a>)</cite>. However, these distinctions cannot be represented in the English, Kannada, or Malayalam scripts. The proposal for a Unicode Tulu script, that was submitted by members of <span class="ltx_text ltx_font_italic" id="S4.I2.i4.p1.1.2">Jai Tulunad</span> to the Unicode Consortium,<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://unicode.org/consortium/consort.html" title="">https://unicode.org/consortium/consort.html</a></span></span></span> addresses these differences. An example usage of the two <span class="ltx_text ltx_font_typewriter" id="S4.I2.i4.p1.1.3">/e/</span> sounds is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S4.F2" title="Figure 2 ‣ 4. The 1st Dataset for Tulu MT ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>
It displays the Tulu translation of the sentences <span class="ltx_text ltx_font_italic" id="S4.I2.i4.p1.1.4">‘<span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.4.1">He</span> will come’</span> and <span class="ltx_text ltx_font_italic" id="S4.I2.i4.p1.1.5">‘<span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.5.1">I</span> will come’</span> written using Kannada and Malayalam scripts, with an apostrophe (<span class="ltx_text ltx_font_typewriter" id="S4.I2.i4.p1.1.6">’</span>) used to differentiate the two <span class="ltx_text ltx_font_typewriter" id="S4.I2.i4.p1.1.7">/e/</span> sounds.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S4.I2.i5.p1">
<p class="ltx_p" id="S4.I2.i5.p1.1">Another challenge, which is also prevalent in other language pairs, is translating the word <span class="ltx_text ltx_font_italic" id="S4.I2.i5.p1.1.1">you</span> into Tulu. Whereas English has only one <span class="ltx_text ltx_font_italic" id="S4.I2.i5.p1.1.2">you</span> and Kannada has two (singular <span class="ltx_text ltx_font_typewriter" id="S4.I2.i5.p1.1.3">neenu</span> and plural <span class="ltx_text ltx_font_typewriter" id="S4.I2.i5.p1.1.4">neevu</span>), Tulu has three words for <span class="ltx_text ltx_font_italic" id="S4.I2.i5.p1.1.5">you</span>: singular <span class="ltx_text ltx_font_typewriter" id="S4.I2.i5.p1.1.6">ee</span>, plural <span class="ltx_text ltx_font_typewriter" id="S4.I2.i5.p1.1.7">nikulu</span> and formal <span class="ltx_text ltx_font_typewriter" id="S4.I2.i5.p1.1.8">eeru</span>. As a result, there could be some ambiguity regarding the specific Tulu word for <span class="ltx_text ltx_font_italic" id="S4.I2.i5.p1.1.9">you</span> when translating standalone English sentences.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="S4.F2.g1" src="extracted/2403.19142v1/tulu_sample_corrected.png" width="252"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Example sentences showing the two <span class="ltx_text ltx_font_typewriter" id="S4.F2.3.1">/e/</span> sounds in Tulu. Image shared by the translation team of <span class="ltx_text ltx_font_italic" id="S4.F2.4.2">Jai Tulunad</span>.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">5.   Experiments</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">5.1.   Data</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">English–Kannada training set</span>
To train the base model for EN–KN translation, we use the Samanantar dataset <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib4" title="">2022</a>)</cite>, comprising 4 million sentences. This dataset primarily originates from Indian websites, government documents, and sources such as Coursera, Khan Academy, and select science YouTube channels,<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.coursera.org" title="">https://www.coursera.org</a> &amp; <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.khanacademy.org" title="">https://www.khanacademy.org</a> &amp; <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.youtube.com" title="">https://www.youtube.com</a></span></span></span> which offer parallel human-translated subtitles in various Indic languages <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib4" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">English–Kannada test set</span>
To test the EN–KN models, we use the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.2">dev</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.3">dev-test</span> sets of the FLORES-200 <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib1" title="">2022</a>; NLLB Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib3" title="">2022</a>)</cite> dataset, consisting of 997 and 1,012 sentences, respectively.
The domain mainly uses Wikimedia sources such as WikiNews, WikiJunior, and WikiVoyage. This stands in contrast to the training data from Samanantar, which is primarily derived from Indian sources situated within the Indian context.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.1">English–Tulu test set</span>
To evaluate our EN–TCY models, we use our newly developed dataset introduced in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S4" title="4. The 1st Dataset for Tulu MT ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>, which comprises a set of 1,300 human-translated sentences from FLORES-200. We split this dataset into 647 sentences for the development set and 653 for the test set.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>When we conducted the experiments, not all of the 2,009 sentences have been translated.</span></span></span></p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p4.1.1">Monolingual Tulu dataset</span>
The method we apply requires a monolingual dataset in the low-resource language for the back-translation and denoising autoencoding steps. As there is no pre-existing dataset readily accessible for Tulu, we have turned to the Tulu Wikipedia<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>We downloaded the Tulu Wikipedia (<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://tcy.wikipedia.org" title="">https://tcy.wikipedia.org</a>) articles via Wikimedia Downloads (<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dumps.wikimedia.org/" title="">https://dumps.wikimedia.org/</a>) and used the WikiExtractor <cite class="ltx_cite ltx_citemacro_citep">(Attardi, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib2" title="">2015</a>)</cite> to get the text.</span></span></span> containing 1,894 articles <cite class="ltx_cite ltx_citemacro_citep">(Wikipedia, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib36" title="">2023</a>)</cite>.
As a result of processing the articles, we obtained a monolingual Tulu corpus comprising 40,000 sentences.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1.1" style="font-size:90%;">Dataset</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="S5.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.2.1" style="font-size:90%;">Source</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S5.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.3.1" style="font-size:90%;">#sents</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.2.1.1"><span class="ltx_text" id="S5.T1.1.2.1.1.1" style="font-size:90%;">EN–KN training</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.2.1.2"><span class="ltx_text" id="S5.T1.1.2.1.2.1" style="font-size:90%;">Samanantar</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.2.1.3"><span class="ltx_text" id="S5.T1.1.2.1.3.1" style="font-size:90%;">4,093,524</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3.2">
<td class="ltx_td ltx_align_left" id="S5.T1.1.3.2.1"><span class="ltx_text" id="S5.T1.1.3.2.1.1" style="font-size:90%;">EN–KN test</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.3.2.2"><span class="ltx_text" id="S5.T1.1.3.2.2.1" style="font-size:90%;">FLORES-200</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.3.2.3"><span class="ltx_text" id="S5.T1.1.3.2.3.1" style="font-size:90%;">2,009</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4.3">
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.3.1"><span class="ltx_text" id="S5.T1.1.4.3.1.1" style="font-size:90%;">TCY monolingual</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.4.3.2"><span class="ltx_text" id="S5.T1.1.4.3.2.1" style="font-size:90%;">Wikipedia</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.4.3.3"><span class="ltx_text" id="S5.T1.1.4.3.3.1" style="font-size:90%;">40,124</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5.4">
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.4.1"><span class="ltx_text" id="S5.T1.1.5.4.1.1" style="font-size:90%;">EN–TCY test</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.5.4.2"><span class="ltx_text" id="S5.T1.1.5.4.2.1" style="font-size:90%;">Human transl. FLORES</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.5.4.3"><span class="ltx_text" id="S5.T1.1.5.4.3.1" style="font-size:90%;">1,300</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.6.5">
<td class="ltx_td ltx_align_left" id="S5.T1.1.6.5.1"><span class="ltx_text" id="S5.T1.1.6.5.1.1" style="font-size:90%;">EN–TCY training</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.6.5.2"><span class="ltx_text" id="S5.T1.1.6.5.2.1" style="font-size:90%;">DravidianLangTech-22</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.6.5.3"><span class="ltx_text" id="S5.T1.1.6.5.3.1" style="font-size:90%;">8,300</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Datasets used in our experiments.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="479" id="S5.F3.g1" src="extracted/2403.19142v1/method_v4.png" width="252"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Experimental setup illustrating the steps involved in the training.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">5.2.   IndicBARTSS &amp; YANMTT</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The original version of the method we use, NMT-Adapt <cite class="ltx_cite ltx_citemacro_citep">(Ko et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite>, is based on the multilingual BART (mBART) language model <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib22" title="">2020</a>)</cite> to initialize training. However, Kannada is not included neither in mBART nor mBART-50. Consequently, Tulu data would need to be transliterated into one of the languages included in mBART-50, such as Malayalam, which would affect the performance of the model.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Therefore, we opted for IndicBARTSS<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/ai4bharat/IndicBARTSS" title="">https://huggingface.co/ai4bharat/IndicBARTSS</a></span></span></span>, an updated version of IndicBART <cite class="ltx_cite ltx_citemacro_citep">(Dabre et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib10" title="">2022</a>)</cite>.
IndicBARTSS supports eleven Indic languages in their native scripts, including Kannada.
It is a multilingual model trained on the IndicCorp corpus, which was introduced by <cite class="ltx_cite ltx_citemacro_citet">Kakwani et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib14" title="">2020</a>)</cite>.
IndicCorp is a collection of monolingual corpora in eleven Indic languages and English. It contains 452 million sentences (five billion tokens). These texts were crawled from online sources, primarily comprising news articles, magazines, and books.
Additionally, <cite class="ltx_cite ltx_citemacro_citet">Dabre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib9" title="">2023</a>)</cite> developed the YANMTT toolkit, which is independently maintained by some of the researchers associated with IndicBARTSS. We use this toolkit in our experiments for pre-training, fine-tuning, and decoding.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">5.3.   NMT-Adapt</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We adopted a slightly simplified version of the transfer learning approach NMT-Adapt introduced by <cite class="ltx_cite ltx_citemacro_citet">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite> to develop a machine translation system for English–Tulu. This approach combines denoising autoencoding <cite class="ltx_cite ltx_citemacro_citep">(Artetxe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib1" title="">2018</a>)</cite> and back-translation <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib29" title="">2016</a>)</cite> into a multi-step, iterative procedure, as depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S5.F3" title="Figure 3 ‣ 5.1. Data ‣ 5. Experiments ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>. While striving to closely follow the original implementation, we omitted an adversarial step due to limitations of the pre-trained model and training library we utilized (see Section <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S8" title="8. Limitations ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>). Our aim was to replicate and compare the effectiveness of this process for our set of languages wherever possible (see Section <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S8" title="8. Limitations ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>).</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">Task 1: Fine-tuning for back-translation</span>
The initial step involved fine-tuning the IndicBARTSS model to translate from Kannada to English. To achieve this, we used the Samanantar dataset for training and the EN–KN dataset from FLORES-200 for development and testing. Subsequently, we used this model to translate the monolingual Tulu dataset into English. This fine-tuned model serves as the base model for TCY–EN translation.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p3.1.1">Task 2: Training with back-translation</span></p>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">For the training with back-translation, we used a second pre-trained IndicBARTSS model, which served as the base model for EN–TCY translation. We trained this model using the back-translation pairs obtained in Task 1.</p>
</div>
<div class="ltx_para" id="S5.SS3.p5">
<p class="ltx_p" id="S5.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p5.1.1">Task 3: Training with parallel data</span></p>
</div>
<div class="ltx_para" id="S5.SS3.p6">
<p class="ltx_p" id="S5.SS3.p6.1">In the third step, we trained the model from the previous task with the parallel English–Kannada training dataset from Samanantar.</p>
</div>
<div class="ltx_para" id="S5.SS3.p7">
<p class="ltx_p" id="S5.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p7.1.1">Task 4: Denoising autoencoding</span></p>
</div>
<div class="ltx_para" id="S5.SS3.p8">
<p class="ltx_p" id="S5.SS3.p8.1">For the denoising autoencoding, we generated ‘noised’ sentences from the monolingual Tulu and Kannada training datasets by implementing random shuffling and word masking. We followed the method described in <cite class="ltx_cite ltx_citemacro_citet">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite>, where words are randomly shuffled with a maximum shift of three positions, and each word is masked with a uniform probability of 0.1.
Subsequently, we trained the English–Tulu base model using these ‘noised’ Tulu and Kannada sentences as the source data, with the unaltered Tulu and Kannada sentences as the target data.</p>
</div>
<div class="ltx_para" id="S5.SS3.p9">
<p class="ltx_p" id="S5.SS3.p9.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p9.1.1">Task 5: Fine-tuning with back-translation</span></p>
</div>
<div class="ltx_para" id="S5.SS3.p10">
<p class="ltx_p" id="S5.SS3.p10.1">In the final step, we further fine-tuned the EN–TCY model from the preceding step using the back-translated pairs. We used this model to generate the English side of the back-translated pairs again, forming the new back-translation set for the next step.
These newly generated back-translated pairs are used to repeat Tasks 2–5 on the TCY–EN base model obtained in Task 1. This process could then be repeated by each model supplying the back-translation pairs for the other one.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">5.4.   Fine-tuning with EN–TCY data</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Madasamy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib2" title="">2022</a>)</cite> released parallel training data for KN–TCY, comprising 8,300 sentences as part of the <span class="ltx_text ltx_font_italic" id="S5.SS4.p1.1.1">Shared Task on Translation of Under-Resourced Dravidian Languages</span> at the <span class="ltx_text ltx_font_italic" id="S5.SS4.p1.1.2">DravidianLangTech-2022</span> workshop.
We used this data to create a parallel EN–TCY dataset and fine-tuned the models obtained from the modified NMT-Adapt process we followed.
To create the parallel EN–TCY dataset from KN–TCY sentences, we initially translated the Kannada sentences into English. We performed this translation using two methods: first, utilizing the ‘base model TCY–EN’ obtained in Task 1, and second, using Google Translate<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://translate.google.com" title="">https://translate.google.com</a></span></span></span> for comparison.
Note that Google Translate does not currently offer a translation service for Tulu. However, it does support Kannada translation. Given the shared script and substantial linguistic similarity between Tulu and Kannada, as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S2" title="2. Linguistic Context ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, we opted to utilize Google Translate to translate Tulu text as if it were Kannada. Despite the absence of alternative online translation services for Tulu, we believe this approach serves as a meaningful and comprehensible starting point for benchmarking the performance of our model.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">Although the ‘base model TCY–EN’ achieved a BLEU score <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib27" title="">2002</a>)</cite> of 30.65 when evaluated on the FLORES-200 Kannada <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p2.1.1">dev-test</span> split, it showed lower translation quality compared to Google Translate, as it omitted some information from the source sentence during translation.
Therefore, we combined the English sentences translated by Google Translate with the Tulu sentences from the KN–TCY dataset to obtain an EN–TCY parallel dataset comprising 8,300 sentences.
Finally, we fine-tuned the models obtained at the end of Task 5 in both the EN–TCY and TCY–EN directions using this dataset. Our aim was to assess whether we could further enhance the models beyond what NMT-Adapt offers.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">6.   Results</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We evaluated the machine translation model and each task of the process with our new test set as introduced in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S4" title="4. The 1st Dataset for Tulu MT ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>, using SacreBLEU<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/mjpost/sacrebleu" title="">https://github.com/mjpost/sacrebleu</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Post, <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib28" title="">2018</a>)</cite>.
Table <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.T2" title="Table 2 ‣ 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a> presents the BLEU scores for each stage of the training process.
The TCY–EN model, obtained by fine-tuning the pre-trained IndicBARTSS on the Samanantar EN–KN data, achieves a BLEU score of 1.84, suggesting that the model is not capable of translating Tulu.</p>
</div>
<figure class="ltx_table" id="S6.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T2.1.1.1">
<td class="ltx_td ltx_align_left" id="S6.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.1.1">Iteration</span></td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.2.1">Direction</span></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.3.1">Task no.</span></td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.4.1">Task</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.5.1">Lannguages</span></td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.6.1">BLEU</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.2.2.1" rowspan="10"><span class="ltx_text" id="S6.T2.1.2.2.1.1">1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.2.2">TCY–EN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.2.3">1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T2.1.2.2.4">fine-tuning with</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.2.2.5">KN–EN</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T2.1.2.2.6">1.84</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.3.3">
<td class="ltx_td ltx_align_center" id="S6.T2.1.3.3.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.3.3.2">2</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.3.3.3">back-translation with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.3.3.4">EN–TCY</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.3.3.5">12.83</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.4.4">
<td class="ltx_td ltx_align_center" id="S6.T2.1.4.4.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.4.4.2">3</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.4.4.3">training with parallel</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.4.4.4">EN–KN</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.4.4.5">17.27</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.5.5">
<td class="ltx_td ltx_align_center" id="S6.T2.1.5.5.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.5.5.2">4a</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.5.5.3">denoising autoencoding with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.5.5.4">KN</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.5.5.5">3.20</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.6.6">
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.6.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.6.2">4b</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.6.6.3">denoising autoencoding with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.6.6.4">TCY</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.6.6.5">5.92</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.7.7">
<td class="ltx_td ltx_align_center" id="S6.T2.1.7.7.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.7.7.2">5</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.7.7.3">fine-tuning with back-translation data</td>
<td class="ltx_td ltx_border_r" id="S6.T2.1.7.7.4"></td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.7.7.5">11.06</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.8.8">
<td class="ltx_td ltx_align_center" id="S6.T2.1.8.8.1">TCY–EN</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.8.8.2">2</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.8.8.3">back-translation with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.8.8.4">TCY–EN</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.8.8.5">19.53</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.9.9">
<td class="ltx_td ltx_align_center" id="S6.T2.1.9.9.1">TCY–EN</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.9.9.2">4a</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.9.9.3">denoising autoencoding with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.9.9.4">KN</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.9.9.5">7.08</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.10.10">
<td class="ltx_td ltx_align_center" id="S6.T2.1.10.10.1">TCY–EN</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.10.10.2">4b</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.10.10.3">denoising autoencoding with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.10.10.4">TCY</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.10.10.5">7.08</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.11.11">
<td class="ltx_td ltx_align_center" id="S6.T2.1.11.11.1">TCY-EN</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.11.11.2">5</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.11.11.3">fine-tuning with back-translation data</td>
<td class="ltx_td ltx_border_r" id="S6.T2.1.11.11.4"></td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.11.11.5"><span class="ltx_text ltx_font_bold" id="S6.T2.1.11.11.5.1">25.97</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.12.12">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.12.12.1" rowspan="5"><span class="ltx_text" id="S6.T2.1.12.12.1.1">2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.12.12.2">EN–TCY</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.12.12.3">2</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T2.1.12.12.4">back-translation with</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.12.12.5">EN–TCY</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T2.1.12.12.6">12.09</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.13.13">
<td class="ltx_td ltx_align_center" id="S6.T2.1.13.13.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.13.13.2">3</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.13.13.3">training with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.13.13.4">EN–KN</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.13.13.5">9.09</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.14.14">
<td class="ltx_td ltx_align_center" id="S6.T2.1.14.14.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.14.14.2">4a</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.14.14.3">denoising autoencoding with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.14.14.4">KN</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.14.14.5">3.45</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.15.15">
<td class="ltx_td ltx_align_center" id="S6.T2.1.15.15.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.15.15.2">4b</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.15.15.3">denoising autoencoding with</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T2.1.15.15.4">TCY</td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.15.15.5">6.59</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.16.16">
<td class="ltx_td ltx_align_center" id="S6.T2.1.16.16.1">EN–TCY</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.16.16.2">5</td>
<td class="ltx_td ltx_align_left" id="S6.T2.1.16.16.3">fine-tuning with back-translation data</td>
<td class="ltx_td ltx_border_r" id="S6.T2.1.16.16.4"></td>
<td class="ltx_td ltx_align_right" id="S6.T2.1.16.16.5">13.43</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>BLEU scores for each step in the training with 2 iterations.</figcaption>
</figure>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">English-Tulu Translation</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.1">The fine-tuned TCY–EN model from Task 1 was used to translate the monolingual Tulu data into English. Subsequently, the sentence pairs obtained from the EN–TCY translation were used to fine-tune the IndicBARTSS model, which served as the base model for translating from English to Tulu. This resulted in a BLEU score of 12.83 for Tulu. While this score signifies a certain level of learning, the translation cannot be considered useful.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p2.1">Moving on to Task 3, we trained the EN–TCY model using the Samanantar EN–KN data. This task improved the BLEU score for Tulu, reaching 17.27. This enhancement suggests that training the model to translate into Kannada also enhanced its ability to translate into Tulu.
This improvement can be attributed to the high degree of similarity between Tulu and Kannada and the effectiveness of transfer learning.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p3.1">In Task 4a, after conducting denoising autoencoding with Kannada data, the BLEU score decreased to 3.20. However, it then increased slightly to 5.92 upon denoising autoencoding with Tulu in Task 4b.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p4.1">The adversarial training task, a component of the original NMT-Adapt method, was not implemented in this work. The adversarial training task involves blending the latent space of the encoder across English, Tulu, and Kannada, enabling the model to learn language-agnostic features <cite class="ltx_cite ltx_citemacro_citep">(Ko et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite>. Without this task, while denoising autoencoding enhanced the robustness of the model’s learned feature space, its benefits were somewhat compromised.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p5">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p5.1">In the final step, Task 5, of the first iteration for the EN–TCY model, we performed additional fine-tuning using the EN–TCY sentence pairs utilized in Task 2. This process further increased the BLEU score of the model to 11.06 as the decoder adapted more effectively to the target (TCY) side. We used this model to generate Tulu sentences from the English side of the back-translated pairs. Subsequently, these new back-translated TCY-EN sentence pairs were utilized in the first iteration of training the TCY-EN model, the results of which are detailed in the following section.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Tulu-English Translation</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p1.1">In Task 2 of the TCY–EN direction, the base TCY–EN model was trained using the back-translated TCY–EN pairs obtained from the previous step. This training resulted in a BLEU score of 19.53, indicating the effectiveness of transfer learning. The decoder demonstrated proficiency in generating English tokens, likely attributed to the pre-trained IndicBARTSS model’s inherent language modeling capability in English.
Since the model had already been exposed to parallel KN–EN data in Task 1, the subsequent step involved denoising autoencoding with Kannada data (Task 4a). However, this led to a decline in the BLEU score to 7.08. Despite denoising autoencoding with Tulu data afterward, the BLEU score remained unchanged. The absence of the adversarial training task significantly limited the effectiveness of denoising autoencoding, as previously mentioned.
Nevertheless, in the subsequent task (Task 5), which involved fine-tuning with back-translated TCY–EN pairs for a second time, the BLEU score increased to 25.97. This represented the highest score attained by either model thus far.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Further Iterations</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px3.p1.1">We used the final TCY–EN model, which we obtained in Task 5, to subsequently back-translate the Tulu sentences that were used to train it in both Task 2 and Task 5.
This newly generated set of back-translated EN–TCY pairs served to start a second iteration of the entire process.
However, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.T2" title="Table 2 ‣ 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, despite some initial improvement, the BLEU scores for the EN–TCY model kept declining from the starting score of 11.06.</p>
</div>
<figure class="ltx_table" id="S6.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T3.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S6.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.1.1">Iter.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S6.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.2.1">Direction</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r" id="S6.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.3.1">old BLEU</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S6.T3.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.4.1">new BLEU</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T3.1.2.1.1">1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T3.1.2.1.2">EN–TCY</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S6.T3.1.2.1.3">11.06</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T3.1.2.1.4">13.12</td>
</tr>
<tr class="ltx_tr" id="S6.T3.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S6.T3.1.3.2.1">1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S6.T3.1.3.2.2">TCY–EN</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T3.1.3.2.3">25.97</td>
<td class="ltx_td ltx_align_right" id="S6.T3.1.3.2.4">21.85</td>
</tr>
<tr class="ltx_tr" id="S6.T3.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S6.T3.1.4.3.1">2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S6.T3.1.4.3.2">EN–TCY</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T3.1.4.3.3">13.43</td>
<td class="ltx_td ltx_align_right" id="S6.T3.1.4.3.4">35.41</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>BLEU scores after additional fine-tuning using <span class="ltx_text ltx_font_italic" id="S6.T3.3.1">DravidianLangTech-2022</span> data.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Fine-tuning with <span class="ltx_text ltx_font_italic" id="S6.SS0.SSS0.Px4.1.1">DravidianLangTech</span> data</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px4.p1.1">We used the parallel EN–TCY data from <span class="ltx_text ltx_font_italic" id="S6.SS0.SSS0.Px4.p1.1.1">DravidianLangTech-22</span> to further fine-tune the EN–TCY and TCY–EN models obtained at the end of each iteration. Table <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#S6.T3" title="Table 3 ‣ Further Iterations ‣ 6. Results ‣ A Tulu Resource for Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the changes in BLEU scores resulting from this fine-tuning step.
For the EN–TCY model obtained at the end of Iteration 1, fine-tuning improved its BLEU score from 11.06 to 13.12. This moderate increase is not surprising, as the manually translated Tulu data would have further enhanced the decoder’s performance.
Conversely, for the TCY–EN model obtained at the end of Iteration 1, the BLEU score decreased from 25.97 to 21.85. The English sentences in this training data, generated by Google Translate, are not perfect translations and often contain transliterated Kannada words, particularly in the form of names of mythological characters, places, and local flora and fauna. We hypothesize that these aspects contributed to the degradation of the TCY–EN model’s decoder.
Finally, the EN–TCY model obtained at the end of Iteration 2 was also fine-tuned with this data, resulting in a substantial increase in its BLEU score from 13.43 to 35.41.
This dramatic improvement may be attributed to the high-quality Tulu data, which eliminated spurious correlations in the latent space and simultaneously enhanced the decoder’s ability to generate Tulu tokens.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Tulu Translation Performance</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px5.p1.1">The results suggest that the approach outlined by <cite class="ltx_cite ltx_citemacro_citet">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite> effectively achieves reasonable performance in translating from Tulu to English, as evidenced by the model’s BLEU score of 25.97. To provide a point of comparison, we used Google Translate to translate the Tulu test data to English using Google Translate<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://translate.google.com/" title="">https://translate.google.com/</a>, in September 2023</span></span></span>. It automatically detected the sentences as Kannada and produced a translation with a BLEU score of 7.19.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S6.SS0.SSS0.Px5.p2.1">However, the NMT-Adapt approach did not yield the same level of performance in the reverse direction, from English to Tulu. The highest achieved BLEU score, 17.27, was obtained through training with back-translation pairs and parallel English-Kannada data exclusively. However, when we combined the NMT-Adapt pipeline with additional fine-tuning using the <span class="ltx_text ltx_font_italic" id="S6.SS0.SSS0.Px5.p2.1.1">DravidianLangTech-22</span> data, we observed a substantial improvement, resulting in a BLEU score of 35.41.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px5.p3">
<p class="ltx_p" id="S6.SS0.SSS0.Px5.p3.1">The denoising autoencoding step generated good results only when followed by fine-tuning with back-translation data in our setting. However, there are a multitude of factors, including the unique characters of Tulu and Kannada, as well as the constrained size of the monolingual Tulu dataset, consisting of just over 40,000 entries.
In the work by <cite class="ltx_cite ltx_citemacro_citet">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite>, the monolingual datasets for all the ‘low-resource’ languages they examined contained at least one million sentences. This implies that the model’s decoder had a larger number of examples to adapt its feature space and acquire high-level semantic knowledge of the low-resource language.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.1.   Qualitative Error Analysis</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">To gain a qualitative understanding of the translations, we conducted an analysis by randomly selecting sentences from the model-generated translations and then comparing them with the reference translations.
In the TCY–EN model with the highest BLEU score, we identified multiple cases where words were transliterated from Tulu to English rather than accurately translated.
Furthermore, we observed occurrences of Kannada characters appearing in English translations and, conversely, instances of English characters appearing in Kannada translations.
Additionally, there were situations where common Tulu words, which had distinct meanings in Kannada or closely resembled common Kannada words, were translated as Kannada instead of Tulu.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">For instance, the Tulu word <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p2.1.1">uppuna</span>, which should have been translated as <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.2">together</span>, was incorrectly translated to <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.3">salt</span>, which is <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p2.1.4">uppu</span> in Kannada.
Similarly, the phrase <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p2.1.5">tenkāyi amērikā</span>, which means <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.6">South America</span> in Tulu, was translated into English as <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.7">United States</span> by the TCY–EN model, ignoring the first word. However, <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p2.1.8">dakṣiṇa āphrikā</span>, which is the formal name for South Africa in both Tulu and Kannada, was correctly translated as <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.9">South Africa</span>. This discrepancy arises from the fact that <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p2.1.10">dakṣiṇa</span> is a loan word from Sanskrit for <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.11">south</span> used in both Kannada and Tulu, whereas <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p2.1.12">tenkāyi</span> is unique to Tulu.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">Finally, we observed instances of word repetition or recurring sequences of words in the translations known as hallucinations. This phenomenon is a well-documented challenge in text generation tasks, as discussed in <cite class="ltx_cite ltx_citemacro_citep">(Fu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib12" title="">2021</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">7.   Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We introduced the first parallel dataset for English–Tulu by incorporating Tulu translations into the multilingual machine translation resource FLORES-200 <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib1" title="">2022</a>; NLLB Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#biba.bib3" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Furthermore, we developed a machine translation system for English–Tulu by leveraging resources for Kannada, a related South Dravidian language. We employed a transfer learning approach that exploits the similarities between the languages, enabling the training of a machine translation system even in the absence of parallel data between the source and target languages.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">Our system achieved a BLEU score of 25.97 for Tulu–English translation, significantly outperforming Google Translate in September 2023, which reached a BLEU of 7.19.
However, the relatively low BLEU scores indicate that the usefulness of our system’s translations is limited. In English–Tulu translation, the model often retains elements of Kannada in the output. However, in Tulu–English translation, we observe that certain parts of Tulu sentences in the test set are conveyed effectively enough for non-Tulu speakers to understand. Additionally, proper nouns are accurately transliterated into English in the results. However, the translation quality diminishes as sentences become longer, and in some cases, the model simply transliterates complex Tulu words into English.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">8.   Limitations</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib16" title="">2021</a>)</cite> implemented NMT-Adapt using the fairseq toolkit<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/facebookresearch/fairseq" title="">https://github.com/facebookresearch/fairseq</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Ott et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib26" title="">2019</a>)</cite> and mBART <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.19142v1#bib.bib22" title="">2020</a>)</cite> as the pre-trained model. However, since Kannada is not supported in mBART, we worked with the pre-trained IndicBARTSS model and the YANMTT toolkit. Unfortunately, YANMTT does not include the adversarial training with Wasserstein loss, a critical step in NMT-Adapt for achieving the objectives of denoising autoencoding.
In future work, we plan to implement this step and integrate it into the toolkit.</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">Furthermore, to benchmark against NMT-Adapt models, we attempted to train bilingual (EN–KN) and trilingual (EN–KN–ML) transformer models with the intention of subsequently adapting them to translate Tulu.
Nevertheless, due to resource constraints, particularly when initialized with sizes akin to mBART or IndicBARTSS, these models proved too large to train. Smaller models trained with the Samanantar dataset achieved a maximum BLEU score of only 8.60 when translating EN–KN.</p>
</div>
<div class="ltx_para" id="S8.p3">
<p class="ltx_p" id="S8.p3.1">Finally, we used the parallel EN–TCY data adapted from <span class="ltx_text ltx_font_italic" id="S8.p3.1.1">DravidianLangTech-22</span> to independently fine-tune models at the end of each iteration.
To ensure that improvements are consistently incorporated into each subsequent iteration, this step should be incorporated into the NMT-Adapt pipeline.
This would be important to gain a more comprehensive understanding of this step and potentially quantify its effects.</p>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">9.   Ethics Statement</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">This paper introduces a novel dataset for Tulu and presents initial efforts towards developing a machine translation system for English–Tulu.
We collaborated with <span class="ltx_text ltx_font_italic" id="S9.p1.1.1">Jai Tulunad</span>, a volunteer organization based in India, dedicated to preserving Tulu language and culture. Their enthusiastic contribution to our project assures us that our efforts align with the community’s interests and needs.</p>
</div>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">10.   Acknowledgements</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">We thank Chantal Amrhein for her support, Anne Göhring, Amit Moryossef, and the anonymous reviewers for their insightful input. Additionally, we extend our appreciation to the organization <span class="ltx_text ltx_font_italic" id="S10.p1.1.1">Jai Tulunad</span> and the Tulu translators for their invaluable contributions to this study. This work was supported by the Swiss National Science Foundation (project no. 191934) and the Department of Computational Linguistics at the University of Zurich.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="S11">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">11.   Bibliographical References</h2>
<div class="ltx_para" id="S11.p1">
<span class="ltx_ERROR undefined" id="S11.p1.1">\c@NAT@ctr</span>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography"></h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe et al. (2018)</span>
<span class="ltx_bibblock">
Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=Sy2ogebAW" title="">Unsupervised neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Attardi (2015)</span>
<span class="ltx_bibblock">
Giuseppe Attardi. 2015.

</span>
<span class="ltx_bibblock">WikiExtractor.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/attardi/wikiextractor" title="">https://github.com/attardi/wikiextractor</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al. (2015)</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1409.0473" title="">Neural machine translation by jointly learning to align and translate</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bala Das et al. (2023)</span>
<span class="ltx_bibblock">
Sudhansu Bala Das, Atharv Biradar, Tapas Kumar Mishra, and Bidyut Kr. Patra. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3587932" title="">Improving multilingual neural machine translation system for indic languages</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">ACM Trans. Asian Low-Resour. Lang. Inf. Process.</em>, 22(6).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bird (2020)</span>
<span class="ltx_bibblock">
Steven Bird. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.coling-main.313" title="">Decolonising speech and language technology</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 28th International Conference on Computational Linguistics</em>, pages 3504–3519, Barcelona, Spain (Online). International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bird (2022)</span>
<span class="ltx_bibblock">
Steven Bird. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.539" title="">Local languages, third spaces, and other high-resource scenarios</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 7817–7829, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blaschke et al. (2024)</span>
<span class="ltx_bibblock">
Verena Blaschke, Christoph Purschke, Hinrich Schütze, and Barbara Plank. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.11968" title="">What do dialect speakers want? a survey of attitudes towards language technology for german dialects</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brigel (1982)</span>
<span class="ltx_bibblock">
J. Brigel. 1982.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://books.google.ch/books?id=81AgB3u2tcQC" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1.1">A Grammar of the Tulu Language</em></a>.

</span>
<span class="ltx_bibblock">Asian Educational Services.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dabre et al. (2023)</span>
<span class="ltx_bibblock">
Raj Dabre, Diptesh Kanojia, Chinmay Sawant, and Eiichiro Sumita. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-demo.24" title="">YANMTT: Yet another neural machine translation toolkit</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)</em>, pages 257–263, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dabre et al. (2022)</span>
<span class="ltx_bibblock">
Raj Dabre, Himani Shrotriya, Anoop Kunchukuttan, Ratish Puduppully, Mitesh Khapra, and Pratyush Kumar. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-acl.145" title="">IndicBART: A pre-trained model for indic natural language generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Findings of the Association for Computational Linguistics: ACL 2022</em>, pages 1849–1863, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eberhard et al. (2023)</span>
<span class="ltx_bibblock">
David M. Eberhard, Gary F. Simons, and Charles D. Fennig, editors. 2023.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Ethnologue: Languages of the World</em>, twenty-sixth edition.

</span>
<span class="ltx_bibblock">SIL International, Dallas, Texas.

</span>
<span class="ltx_bibblock">Online version: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.ethnologue.com" title="">http://www.ethnologue.com</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2021)</span>
<span class="ltx_bibblock">
Zihao Fu, Wai Lam, Anthony Man-Cho So, and Bei Shi. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1609/aaai.v35i14.17520" title="">A theoretical analysis of the repetition problem in text generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, 35(14):12848–12856.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal et al. (2022)</span>
<span class="ltx_bibblock">
Piyushi Goyal, Musica Supriya, Dinesh U, and Ashalatha Nayak. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.dravidianlangtech-1.19" title="">Translation techies @DravidianLangTech-ACL2022-machine translation in Dravidian languages</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages</em>, pages 120–124, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kakwani et al. (2020)</span>
<span class="ltx_bibblock">
Divyanshu Kakwani, Anoop Kunchukuttan, Satish Golla, Gokul N.C., Avik Bhattacharyya, Mitesh M. Khapra, and Pratyush Kumar. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.findings-emnlp.445" title="">IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian languages</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 4948–4961, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klein et al. (2017)</span>
<span class="ltx_bibblock">
Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, and Alexander Rush. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/P17-4012" title="">OpenNMT: Open-source toolkit for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of ACL 2017, System Demonstrations</em>, pages 67–72, Vancouver, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko et al. (2021)</span>
<span class="ltx_bibblock">
Wei-Jen Ko, Ahmed El-Kishky, Adithya Renduchintala, Vishrav Chaudhary, Naman Goyal, Francisco Guzmán, Pascale Fung, Philipp Koehn, and Mona Diab. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.66" title="">Adapting high-resource NMT models to translate low-resource related languages without parallel data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 802–812, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn and Knowles (2017)</span>
<span class="ltx_bibblock">
Philipp Koehn and Rebecca Knowles. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W17-3204" title="">Six challenges for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the First Workshop on Neural Machine Translation</em>, pages 28–39, Vancouver. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnamurti (2003)</span>
<span class="ltx_bibblock">
Bhadriraju Krishnamurti. 2003.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1017/CBO9780511486876" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1.1">The Dravidian Languages</em></a>.

</span>
<span class="ltx_bibblock">Cambridge Language Surveys. Cambridge University Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lakew et al. (2020)</span>
<span class="ltx_bibblock">
Surafel Melaku Lakew, Matteo Negri, and Marco Turchi. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:214727851" title="">Low resource neural machine translation: A benchmark for five african languages</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">ArXiv</em>, abs/2003.14402.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lample et al. (2018)</span>
<span class="ltx_bibblock">
Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc’Aurelio Ranzato. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=rkYTTf-AZ" title="">Unsupervised machine translation using monolingual corpora only</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Littauer and Paterson III (2016)</span>
<span class="ltx_bibblock">
Richard Littauer and Hugh Paterson III. 2016.

</span>
<span class="ltx_bibblock">Open source code serving endangered languages.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of LREC 2016 Collaboration and Computing for Under-Resourced Languages: Towards an Alliance for Digital Language Diversity (CCURL) Workshop</em>, pages 86–88, Portorož, Slovenia.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020)</span>
<span class="ltx_bibblock">
Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00343" title="">Multilingual denoising pre-training for neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Transactions of the Association for Computational Linguistics</em>, 8:726–742.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Zoey Liu, Crystal Richardson, Richard Hatcher, and Emily Prud’hommeaux. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.272" title="">Not always about you: Prioritizing community needs when developing endangered language technology</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3933–3944, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukhija et al. (2021)</span>
<span class="ltx_bibblock">
Namrata Mukhija, Monojit Choudhury, and Kalika Bali. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2110.07444" title="">Designing language technologies for social good: The road not taken</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Office of the Registrar General &amp; Census Commissioner, India (2022)</span>
<span class="ltx_bibblock">
Office of the Registrar General &amp; Census Commissioner, India. 2022.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Distribution of Kannada Speakers 2011</em>, pages 38–39. Government of India.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ott et al. (2019)</span>
<span class="ltx_bibblock">
Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019.

</span>
<span class="ltx_bibblock">fairseq: A fast, extensible toolkit for sequence modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of NAACL-HLT 2019: Demonstrations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post (2018)</span>
<span class="ltx_bibblock">
Matt Post. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-6319" title="">A call for clarity in reporting BLEU scores</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the Third Conference on Machine Translation: Research Papers</em>, pages 186–191, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al. (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P16-1009" title="">Improving neural machine translation models with monolingual data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 86–96, Berlin, Germany. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steever (2017)</span>
<span class="ltx_bibblock">
Sanford B. Steever. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1017/9781316135716.028" title="">The dravidian language family</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">The Cambridge Handbook of Linguistic Typology</em>, Cambridge Handbooks in Language and Linguistics, page 887–910. Cambridge University Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steever (2019)</span>
<span class="ltx_bibblock">
S.B. Steever, editor. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.4324/9781315722580" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1.1">The Dravidian Languages</em></a>, 2nd edition.

</span>
<span class="ltx_bibblock">Routledge.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subrahmanyam (2006)</span>
<span class="ltx_bibblock">
P.S. Subrahmanyam. 2006.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/B0-08-044854-2/02147-7" title="">Dravidian languages</a>.

</span>
<span class="ltx_bibblock">In Keith Brown, editor, <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Encyclopedia of Language &amp; Linguistics (Second Edition)</em>, second edition edition, pages 785–795. Elsevier, Oxford.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutskever et al. (2014)</span>
<span class="ltx_bibblock">
Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf" title="">Sequence to sequence learning with neural networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Advances in Neural Information Processing Systems</em>, volume 27. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thadhagath (2023)</span>
<span class="ltx_bibblock">
Pathi Venkata Thadhagath. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.hindustantimes.com/cities/bengaluru-news/demand-to-make-tulu-second-official-language-of-karnataka-arises-in-assembly-101689751745948.html" title="">Demand to make tulu second official language of karnataka arises in assembly</a>.

</span>
<span class="ltx_bibblock">Hindustan Times.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="">Attention is all you need</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wikipedia (2023)</span>
<span class="ltx_bibblock">
Wikipedia. 2023.

</span>
<span class="ltx_bibblock">Tulu Wikipedia — Wikipedia, the free encyclopedia.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://en.wikipedia.org/w/index.php?title=Tulu%20Wikipedia&amp;oldid=1157462605" title="">http://en.wikipedia.org/w/index.php?title=Tulu%20Wikipedia&amp;oldid=1157462605</a>.

</span>
<span class="ltx_bibblock">[Online; accessed 29-May-2023].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zoph et al. (2016)</span>
<span class="ltx_bibblock">
Barret Zoph, Deniz Yuret, Jonathan May, and Kevin Knight. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D16-1163" title="">Transfer learning for low-resource neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em>, pages 1568–1575, Austin, Texas. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="S12">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">12.   Language Resource References</h2>
<div class="ltx_para" id="S12.p1">
<span class="ltx_ERROR undefined" id="S12.p1.1">\c@NAT@ctr</span>
</div>
</section>
<section class="ltx_bibliography" id="biba">
<h2 class="ltx_title ltx_title_bibliography"> </h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="biba.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal et al. (2022)</span>
<span class="ltx_bibblock">
Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc’Aurelio Ranzato, Francisco Guzmán, and Angela Fan. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00474" title="">The Flores-101 evaluation benchmark for low-resource and multilingual machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="biba.bib1.1.1">Transactions of the Association for Computational Linguistics</em>, 10:522–538.

</span>
</li>
<li class="ltx_bibitem" id="biba.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madasamy et al. (2022)</span>
<span class="ltx_bibblock">
Anand Kumar Madasamy, Asha Hegde, Shubhanker Banerjee, Bharathi Raja Chakravarthi, Ruba Priyadharshini, Hosahalli Shashirekha, and John McCrae. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.dravidianlangtech-1.41" title="">Overview of the shared task on machine translation in Dravidian languages</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="biba.bib2.1.1">Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages</em>, pages 271–278, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="biba.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NLLB Team et al. (2022)</span>
<span class="ltx_bibblock">
NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2207.04672" title="">No language left behind: Scaling human-centered machine translation</a>.

</span>
</li>
<li class="ltx_bibitem" id="biba.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al. (2022)</span>
<span class="ltx_bibblock">
Gowtham Ramesh, Sumanth Doddapaneni, Aravinth Bheemaraj, Mayank Jobanputra, Raghavan AK, Ajitesh Sharma, Sujit Sahoo, Harshita Diddee, Mahalakshmi J, Divyanshu Kakwani, Navneet Kumar, Aswin Pradeep, Srihari Nagaraj, Kumar Deepak, Vivek Raghavan, Anoop Kunchukuttan, Pratyush Kumar, and Mitesh Shantadevi Khapra. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00452" title="">Samanantar: The largest publicly available parallel corpora collection for 11 Indic languages</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="biba.bib4.1.1">Transactions of the Association for Computational Linguistics</em>, 10:145–162.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu May  2 21:47:17 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
