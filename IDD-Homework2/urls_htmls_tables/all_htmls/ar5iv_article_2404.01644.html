<article class="ltx_document ltx_authors_1line">
 <div class="ltx_para" id="p1">
  <span class="ltx_ERROR undefined" id="p1.1">
   \onlineid
  </span>
  <p class="ltx_p" id="p1.2">
   1174
   <span class="ltx_ERROR undefined" id="p1.2.1">
    \vgtccategory
   </span>
   Research
   <span class="ltx_ERROR undefined" id="p1.2.2">
    \vgtcpapertype
   </span>
   please specify
   <span class="ltx_ERROR undefined" id="p1.2.3">
    \authorfooter
   </span>
   Luoxuan Weng, Junyu Lu, Yingchaojie Feng, Yihan Liu, and Wei Chen are with the State Key Lab of CAD&amp;CG, Zhejiang University. E-mail: {lukeweng, junyulu, fycj, liuyihan1024, chenvis}@zju.edu.cn.
Xingbo Wang is with Weill Cornell Medical College, Cornell University. E-mail: xingbo.wang@med.cornell.edu.
  </p>
 </div>
 <h1 class="ltx_title ltx_title_document">
  <em class="ltx_emph ltx_font_italic" id="1.1">
   InsightLens
  </em>
  : Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Luoxuan Weng
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Xingbo Wang
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Junyu Lu
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yingchaojie Feng
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yihan Liu
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    and
Wei Chen
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="2.1">
   The proliferation of large language models (LLMs) has revolutionized the capabilities of natural language interfaces (NLIs) for data analysis. LLMs can perform multi-step and complex reasoning to generate data insights based on users’ analytic intents. However, these insights often entangle with an abundance of contexts in analytic conversations such as code, visualizations, and natural language explanations. This hinders efficient identification, verification, and interpretation of insights within the current chat-based interfaces of LLMs. In this paper, we first conduct a formative study with eight experienced data analysts to understand their general workflow and pain points during LLM-powered data analysis. Then, we propose an LLM-based multi-agent framework to automatically extract, associate, and organize insights along with the analysis process. Based on this, we introduce
   <span class="ltx_ERROR undefined" id="2.1.1">
    \name
   </span>
   , an interactive system that visualizes the intricate conversational contexts from multiple aspects to facilitate insight discovery and exploration. A user study with twelve data analysts demonstrates the effectiveness of
   <span class="ltx_ERROR undefined" id="2.1.2">
    \name
   </span>
   , showing that it significantly reduces users’ manual and cognitive effort without disrupting their conversational data analysis workflow, leading to a more efficient analysis experience.
  </p>
 </div>
 <div class="ltx_classification">
  <h6 class="ltx_title ltx_title_classification">
   keywords:
  </h6>
  Large language model, interactive data analysis, natural language interface
 </div>
 <div class="ltx_para" id="p2">
  <span class="ltx_ERROR undefined" id="p2.1">
   \teaser
  </span>
  <img alt="[Uncaptioned image]" class="ltx_graphics ltx_centering ltx_img_landscape" height="195" id="p2.g1" src="/html/2404.01644/assets/x1.png" width="461"/>
  <p class="ltx_p ltx_align_center" id="p2.2">
   <span class="ltx_text ltx_caption" id="p2.2.1">
    In a typical workflow of conducting data analysis with large language models, users are required to identify, verify, and interpret insights from lengthy analytic conversations overwhelmed with different contexts. To alleviate the manual and cognitive load during the process, we adopt an LLM-based multi-agent framework that automates the extraction, association, and organization of insights.
   </span>
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Natural language interfaces (NLIs) for data analysis
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib56" title="">
      56
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib53" title="">
      53
     </a>
     ]
    </cite>
    have received much attention in recent years. Users express their analytic intents and data-related questions in natural language (NL), prompting NLIs to generate corresponding results or data visualizations for further analysis. Recently, large language models (LLMs), such as GPT-4
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     ]
    </cite>
    and LLaMA
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib65" title="">
      65
     </a>
     ]
    </cite>
    , have emerged and achieved unprecedented performance in natural language understanding, reasoning, and generation. They have become the backbones for NLIs (
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">
     e.g.
    </span>
    , ChatGPT’s Advanced Data Analysis
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib47" title="">
      47
     </a>
     ]
    </cite>
    ) to enhance conversational data analysis
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib73" title="">
      73
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib20" title="">
      20
     </a>
     ]
    </cite>
    , hereafter referred to as
    <em class="ltx_emph ltx_font_italic" id="S1.p1.1.2">
     LLM-powered data analysis
    </em>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    During LLM-powered data analysis, LLMs can perform multi-step and complex reasoning to derive data insights based on users’ queries about the dataset and the previous conversation history. This process typically generates various intermediate outputs, such as code, visualizations, and NL explanations
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ]
    </cite>
    . After identifying the key insights from LLMs’ responses, users often need to associate them with the corresponding intermediate outputs for verification, since LLMs may sometimes provide unreliable or incorrect responses due to hallucinations
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib77" title="">
      77
     </a>
     ]
    </cite>
    . As the conversations progress, users may navigate back and forth between different parts of the conversation to gather essential information for understanding the current analyses generated by LLMs. Meanwhile, they need to keep track and make sense of the previously discovered insights for making informed decisions and determining future explorations
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib68" title="">
      68
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib59" title="">
      59
     </a>
     ]
    </cite>
    . Finally, users will record, organize, and report valuable insights by exploring the entire conversation history.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    However, this workflow is tedious and inefficient with the current chat-based interfaces of LLMs. As analytic conversations are usually lengthy and overwhelmed with various types of context, it requires significant manual and cognitive effort to frequently navigate in the conversations to extract insights and associate them with the supporting evidence (
    <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">
     i.e.
    </span>
    , intermediate outputs). In contrast, most existing research only tracks the provenance of a single form of analytic context, such as data
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib15" title="">
      15
     </a>
     ]
    </cite>
    , code
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib31" title="">
      31
     </a>
     ]
    </cite>
    , or visualization
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib80" title="">
      80
     </a>
     ]
    </cite>
    , ignoring their combinations, which impedes a comprehensive understanding of the analysis process. Furthermore, users are required to manually maintain the discovered insights either by mental recall or through external note-taking
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ]
    </cite>
    . Given the large numbers of insights quickly generated by LLMs and the expanding conversational contexts, this process often causes a substantial cognitive load. Many interactive systems have been developed to help users explore LLMs’ responses in various scenarios such as creative writing
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib62" title="">
      62
     </a>
     ]
    </cite>
    and information seeking
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib29" title="">
      29
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib63" title="">
      63
     </a>
     ]
    </cite>
    . However, they primarily focus on semantic context (
    <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">
     e.g.
    </span>
    , topic changes
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib34" title="">
      34
     </a>
     ]
    </cite>
    ) of LLMs’ outputs, and fail to facilitate the exploration of data context during analytic conversations
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib59" title="">
      59
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib25" title="">
      25
     </a>
     ]
    </cite>
    . Moreover, most such systems generally lack integrated support for recording and organizing insights.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    To better understand the general workflow, challenges, and design requirements in LLM-powered data analysis, we conducted a formative interview study with eight experienced data analysts. Accordingly, we present
    <span class="ltx_ERROR undefined" id="S1.p4.1.1">
     \name
    </span>
    , an interactive system that facilitates efficient insight discovery and exploration. Going beyond traditional analytical chatbots that are limited to interact with a single intelligent agent
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib54" title="">
      54
     </a>
     ]
    </cite>
    and require users to manually manage the conversational contexts,
    <span class="ltx_ERROR undefined" id="S1.p4.1.2">
     \name
    </span>
    adopts an LLM-based multi-agent framework for automatic extraction, association, and organization of insights during conversational data analysis. Moreover,
    <span class="ltx_ERROR undefined" id="S1.p4.1.3">
     \name
    </span>
    offers multi-level and multi-faceted visualizations to aid in exploring the organized insights. Specifically, it features an
    <em class="ltx_emph ltx_font_italic" id="S1.p4.1.4">
     Insight Minimap
    </em>
    and a
    <em class="ltx_emph ltx_font_italic" id="S1.p4.1.5">
     Topic Canvas
    </em>
    to reveal the temporal shifts of data and semantic context throughout the analysis process. They provide on-the-fly feedback to guide insight discovery and exploration without disrupting the conversational workflow. To evaluate the effectiveness of
    <span class="ltx_ERROR undefined" id="S1.p4.1.6">
     \name
    </span>
    , we conducted a technical evaluation and a user study. The technical evaluation demonstrated a satisfactory performance of our multi-agent framework in accurately extracting, associating, and organizing insights. The user study revealed that
    <span class="ltx_ERROR undefined" id="S1.p4.1.7">
     \name
    </span>
    can significantly reduce the manual and cognitive effort in discovering and exploring insights in LLM-powered data analysis, leading to a more efficient analysis experience.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    In summary, the major contributions of our work are:
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       A formative study that identifies critical challenges and summarizes design requirements for discovering and exploring insights from conversational contexts in LLM-powered data analysis.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <span class="ltx_ERROR undefined" id="S1.I1.i2.p1.1">
       \name
      </span>
      <p class="ltx_p" id="S1.I1.i2.p1.2">
       , an interactive system that facilitates efficient insight discovery and exploration through a novel multi-agent framework and interactive visualizations.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       A technical evaluation and a user study that demonstrate the effectiveness of
       <span class="ltx_ERROR undefined" id="S1.I1.i3.p1.1.1">
        \name
       </span>
       .
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    NLIs for Data Analysis
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     Natural language is an intuitive modality for interacting with data and can significantly lower the barriers of data analysis
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib25" title="">
       25
      </a>
      ]
     </cite>
     . Therefore, NLIs for data analysis have been extensively studied in multiple fields including databases
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib2" title="">
       2
      </a>
      ]
     </cite>
     , natural language processing (NLP)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib36" title="">
       36
      </a>
      ]
     </cite>
     , and visualization
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib56" title="">
       56
      </a>
      ]
     </cite>
     . Chen
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.1.1">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib8" title="">
       8
      </a>
      ]
     </cite>
     divided these systems into two categories: NLIs for data queries and for visualizations. We follow this categorization to review previous work and then discuss about the cutting-edge progress in LLM-powered data analysis.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">
      NLIs for data queries
     </span>
     , or most well known as
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.2">
      semantic parsing
     </em>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib30" title="">
       30
      </a>
      ]
     </cite>
     , transform NL utterances into machine-readable representations like SQL and Python to execute on knowledge bases
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib9" title="">
       9
      </a>
      ]
     </cite>
     . Early systems leveraged pattern-matching
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib78" title="">
       78
      </a>
      ]
     </cite>
     , parsing strategies
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib52" title="">
       52
      </a>
      ]
     </cite>
     , or rule-based methods
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ]
     </cite>
     to understand the semantic structures of the input queries
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib2" title="">
       2
      </a>
      ]
     </cite>
     . Later, neural approaches
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib67" title="">
       67
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      ]
     </cite>
     trained end-to-end neural networks to directly generate executable SQL queries from NL inputs, which overcame previous limitations like ambiguities or fuzzy linguistic coverage
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib28" title="">
       28
      </a>
      ]
     </cite>
     . Recently, researchers developed training-free strategies utilizing LLMs to address issues of end-to-end neural models like low interpretability and large training data need, and achieved state-of-the-art performance
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib79" title="">
       79
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib72" title="">
       72
      </a>
      ]
     </cite>
     . Binder
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib9" title="">
       9
      </a>
      ]
     </cite>
     , for instance, used only a few in-context examples to bind LLMs’ strong reasoning abilities with programming languages to tackle with complex data queries.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p3">
    <p class="ltx_p" id="S2.SS1.p3.1">
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.1">
      NLIs for visualizations (V-NLIs)
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib60" title="">
       60
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib53" title="">
       53
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib58" title="">
       58
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib57" title="">
       57
      </a>
      ]
     </cite>
     take a step further by responding with interactive visualizations based on query results. Initially introduced by Cox
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.2">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib12" title="">
       12
      </a>
      ]
     </cite>
     , these systems allow users to focus more on their data rather than manipulating complex visual interfaces
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib56" title="">
       56
      </a>
      ]
     </cite>
     . Many work aims at resolving the ambiguities or underspecifications in input queries
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib55" title="">
       55
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib18" title="">
       18
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib53" title="">
       53
      </a>
      ]
     </cite>
     . For example, NL4DV
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib45" title="">
       45
      </a>
      ]
     </cite>
     generated analytic specifications for visualizations and explicitly highlighted ambiguities in its responses. Another important line of research in V-NLIs explores analytic context to maintain a conversational flow
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib23" title="">
       23
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib64" title="">
       64
      </a>
      ]
     </cite>
     . Evizeon
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib25" title="">
       25
      </a>
      ]
     </cite>
     applied pragmatics principles for interacting with visualizations and defined three types of context transitions (
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.3">
      i.e.
     </span>
     ,
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.4">
      continue
     </em>
     ,
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.5">
      retain
     </em>
     , and
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.6">
      shift
     </em>
     ). Based on this, Snowy
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib59" title="">
       59
      </a>
      ]
     </cite>
     recommended context-aware utterances to support conversational visual analysis. Similarly, our work also highlights data context transitions during analysis.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p4">
    <p class="ltx_p" id="S2.SS1.p4.1">
     Recently,
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p4.1.1">
      analytical assistants powered by LLMs
     </span>
     have emerged as a prevalent paradigm
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib42" title="">
       42
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib35" title="">
       35
      </a>
      ]
     </cite>
     . Many empirical studies have been conducted to understand the conversational challenges
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib11" title="">
       11
      </a>
      ]
     </cite>
     and user behaviors
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib21" title="">
       21
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib20" title="">
       20
      </a>
      ]
     </cite>
     during LLM-powered data analysis. Moreover, automated tools have also been developed to better leverage LLMs’ potentials. For instance, InsightPilot
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib40" title="">
       40
      </a>
      ]
     </cite>
     simplified data exploration by automatically generating insights, and AI Threads
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib24" title="">
       24
      </a>
      ]
     </cite>
     created and refined visualizations through a multi-threaded analytical chatbot.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p5">
    <p class="ltx_p" id="S2.SS1.p5.1">
     Overall, the large corpus of previous studies in NLIs for data analysis provides a solid foundation for our work. We choose to focus on LLM-powered data analysis for its recent prevalence and rather immature interaction schemes. This new paradigm brings unique challenges that create high manual and cognitive overload on users. Therefore, we concentrate on investigating the pain points during conversational data analysis and enabling users to better discover and explore data insights.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Analytic Provenance in Data Analysis
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Analytic provenance tracks the history and evolution of different analytic context, such as data
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib49" title="">
       49
      </a>
      ]
     </cite>
     , visualizations
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib41" title="">
       41
      </a>
      ]
     </cite>
     , and insights
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib19" title="">
       19
      </a>
      ]
     </cite>
     , which helps users better understand the analysis process. Ragan
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib50" title="">
       50
      </a>
      ]
     </cite>
     introduced an organizational framework to characterize different types and purposes of provenance. Based on this framework, Madanagopal
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.2">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib41" title="">
       41
      </a>
      ]
     </cite>
     further investigated the mapping between tasks and provenance types, such as knowledge transfer, validation, and sensemaking. During these processes, researchers have proposed various techniques for effective provenance management
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib46" title="">
       46
      </a>
      ]
     </cite>
     and presentation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib5" title="">
       5
      </a>
      ]
     </cite>
     . For example, Berant
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.3">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib4" title="">
       4
      </a>
      ]
     </cite>
     presented a cell-based provenance with NL utterances to explain queries over data tables. And DIY
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib44" title="">
       44
      </a>
      ]
     </cite>
     enabled users to evaluate NLIs’ correctness on databases by visualizing representative data subset transformations. Similarly, XNLI
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib16" title="">
       16
      </a>
      ]
     </cite>
     provided interactive widgets to depict visualization provenance in V-NLIs for explanation and diagnosis. Our work builds upon these endeavors by extracting and tracking the insights and other analytic context during LLM-powered data analysis. Moreover, we associate these insights with their relevant evidence (
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.4">
      e.g.
     </span>
     , code, visualizations) to facilitate user comprehension and verification.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Exploration of LLMs’ Responses
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Limitations of the linear conversational structures pose challenges in supporting complex information tasks with LLMs
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib37" title="">
       37
      </a>
      ]
     </cite>
     . Therefore, numerous visual interfaces have been introduced to facilitate LLM response exploration
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib61" title="">
       61
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib26" title="">
       26
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib38" title="">
       38
      </a>
      ]
     </cite>
     . For example, Sensecape
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib63" title="">
       63
      </a>
      ]
     </cite>
     provided multi-level exploration and sensemaking for information-seeking activities, while Graphologue
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib29" title="">
       29
      </a>
      ]
     </cite>
     created an interactive diagram of LLMs’ responses based on named entity recognition. Both of them enhanced users’ understanding of individual responses. To support structured examination of multiple responses, Luminate
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib62" title="">
       62
      </a>
      ]
     </cite>
     systematically generated a multi-dimensional design space for human-AI co-creation processes. Furthermore, other work focuses on better managing LLMs’ conversational contexts. C5
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib34" title="">
       34
      </a>
      ]
     </cite>
     , for example, addressed the human and model contextual forgetting issues by dynamically visualizing the topic transitions during conversations. Similarly, Memory Sandbox
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib27" title="">
       27
      </a>
      ]
     </cite>
     enabled transparent and interactive context management of LLM-powered agents. Nevertheless, these interfaces are not tailored for data analysis scenarios, hence they fall short in supporting effective exploration of analytic context. Our work extends this line of research by providing multi-level and multi-faceted visualizations to facilitate insight discovery and exploration during conversational data analysis.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Formative Study
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    The target users of our system are data analysts who utilize LLMs for analytical tasks. To understand the workflow, pain points, and best practices of LLM-powered data analysis, especially how users discover and explore data insights, we conducted a formative interview study to summarize challenges with traditional chat-based interfaces. Based on our findings, we derive four design requirements to facilitate insight discovery and exploration from LLMs’ conversational contexts.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Participants and Procedure
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     Eight experienced data analysts from various domains, including business intelligence, finance, and e-commerce were interviewed (E1-8, 3 females and 5 males, age from 25 to 32). Each participant had a minimum of 4 years’ experience in data analysis, and all of them had recently used LLMs for their work. We developed a prototype system that served as a localhost analytical chatbot powered by GPT-4. Then, participants were asked to perform open-ended data analysis
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib16" title="">
       16
      </a>
      ]
     </cite>
     with the system to explore the movies dataset from Vega, which consists of 709 rows and 10 columns. We encouraged participants to use think-aloud protocol to raise any questions or concerns. Finally, we collected their feedback on analysis experience, focusing on how they acquired information from the conversation history and organized the obtained data insights for summarization or further data exploration, as well as their encountered challenges and obstacles during the process. The interviews were conducted online and lasted about 60 to 80 minutes.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Findings
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     LLMs were prompted with analytic queries to generate code for data processing and visualization, and then interpret the execution results to provide data insights. We observed three operations that participants commonly performed during LLM-powered data analysis:
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.1">
      identification, verification, and interpretation
     </em>
     of insights. First, they identified the key insights from each response through carefully examining the entire message. Most participants (7/8) temporarily saved the insights through copy-and-paste or screenshots. Then, although they generally found the automatically derived insights relevant and accurate, most participants (7/8) still manually verified each insight by investigating the related code, code outputs, visualizations, or NL explanations. Finally, after collecting enough insights or finishing a specific analytic topic, all participants checked the previous notes or screenshots to recap their findings and determine next-step explorations. However, during the entire process, participants encountered several common challenges that decreased their analysis efficiency, which are summarized below.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     For clarity, we first define the terminologies used in the paper.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p3">
    <ul class="ltx_itemize" id="S3.I1">
     <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i1.p1">
       <p class="ltx_p" id="S3.I1.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">
         Analytic Context:
        </span>
        Properties of the dataset (focused attributes and values), user interactions (analytic intents and data-related questions), intermediate outputs generated by LLMs for analytic purposes (code, code outputs, visualizations, and NL explanations), and data insights derived by either LLMs or users.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i2.p1">
       <p class="ltx_p" id="S3.I1.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">
         Insight Evidence:
        </span>
        <em class="ltx_emph ltx_font_italic" id="S3.I1.i2.p1.1.2">
         Parts
        </em>
        of the intermediate outputs generated by LLMs that
        <em class="ltx_emph ltx_font_italic" id="S3.I1.i2.p1.1.3">
         directly
        </em>
        support each insight, including the
        <em class="ltx_emph ltx_font_italic" id="S3.I1.i2.p1.1.4">
         specific piece
        </em>
        of code, code outputs, visualizations, and NL explanations.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <figure class="ltx_figure" id="S3.F1">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="189" id="S3.F1.g1" src="/html/2404.01644/assets/x2.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F1.6.1.1" style="font-size:90%;">
       Figure 1
      </span>
      :
     </span>
     <span class="ltx_ERROR undefined" id="S3.F1.7.2">
      \name
     </span>
     <span class="ltx_text" id="S3.F1.8.3" style="font-size:90%;">
      consists of (A) a user interface and (B) a multi-agent framework. Users (A1) upload a dataset and specify their analytic intent. The
      <em class="ltx_emph ltx_font_italic" id="S3.F1.8.3.1">
       Data Science (DS) Agent
      </em>
      (B1) interprets the intent, initiating a conversation cycle that is forwarded to the
      <em class="ltx_emph ltx_font_italic" id="S3.F1.8.3.2">
       Insight Extraction (IE) Agent
      </em>
      (B2) for insight extraction and evidence association. Following this, the
      <em class="ltx_emph ltx_font_italic" id="S3.F1.8.3.3">
       Insight Management (IM) Agent
      </em>
      (B3) organizes the insights by identifying their data attributes, analytic topics, and related insights. Users can then (A2) inspect the extracted insights and (A3) explore the structured topics.
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S3.SS2.p4">
    <p class="ltx_p" id="S3.SS2.p4.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">
      C1: Repeated and tedious insight acquisition/verification from LLMs’ responses.
     </span>
     When identifying data insights, participants needed to acquire the relevant analytic context from LLMs’ responses. All participants found the process repetitive and laborious, especially given the lengthy and cumbersome conversation history. They complained that LLMs tended to
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p4.1.2">
      ‘elaborate too much on the potential reasons behind each conclusion’
     </em>
     (E3), which forced them to
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p4.1.3">
      ‘manually locate and summarize the key information instead of gaining intuitive takeaways’
     </em>
     (E1).
The situation was exacerbated when verifying insights, because participants had to locate other context (
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p4.1.4">
      e.g.
     </span>
     , code and visualizations) as insight evidence and associate them with each insight manually.
For example, E5 spent much time in
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p4.1.5">
      ‘scrolling back to find that particular number in code outputs’
     </em>
     to ensure correctness when she saw numerical values. Moreover, when participants iteratively modified their prompts for expected analysis results, the insight evidence would span across multiple responses, leading to extra manual effort for navigation.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p5">
    <p class="ltx_p" id="S3.SS2.p5.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">
      C2: Significant overhead for insight organization.
     </span>
     When interpreting the collected insights, most participants (7/8) managed to organize them into meaningful subgroups either based on data attributes or analytic topics.
E7 explained that
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p5.1.2">
      ‘effective organizations helped him better reuse data findings in presentations and documentations’
     </em>
     . However, this process was described as
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p5.1.3">
      ‘troublesome and painstaking’
     </em>
     (E4), due to the necessity of manually annotating each insight with its characteristics before synthesizing them collectively.
As the linear chat-based interfaces suffered in effective insight management, participants resorted to external tools (
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p5.1.4">
      e.g.
     </span>
     , Typora, Word) to document their acquired insights and other analytic context in notes or screenshots. Nevertheless, as the analysis progressed, the document quickly became overwhelming and was filled with
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p5.1.5">
      ‘too much unordered text and images’
     </em>
     (E5), which posed further challenges to structured organization. Meanwhile, the frequent switching between different applications was highlighted as
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p5.1.6">
      ‘frustrating and time-consuming’
     </em>
     (E3).
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p6">
    <p class="ltx_p" id="S3.SS2.p6.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">
      C3: Inflexible and inefficient insight browsing and revisiting.
     </span>
     Participants commonly expressed the need to revisit and explore previous findings throughout the analysis process. They reported that the lack of a high-level overview, such as a
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.2">
      ‘timeline’
     </em>
     (E4) or
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.3">
      ‘minimap’
     </em>
     (E7), hindered quick navigation and contextual understanding.
The extra cognitive overload for insight exploration mainly reflected in two aspects.
First, it was inconvenient to browse insights. For example, E3 maintained an outline of her discoveries in Word, but the document soon became lengthy and forced her to
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.4">
      ‘repeatedly scroll up and down to browse each section’
     </em>
     , which
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.5">
      ‘somewhat outweighed the advantages of organizing insights’
     </em>
     (E3). Moreover, as the quality of LLM-generated insights may differ, participants desired to prioritize significant insights during exploration instead of
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.6">
      ‘random meandering’
     </em>
     (E4), which was not supported.
Second, it was cumbersome to revisit previous related insights and their supporting evidence (
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.1.7">
      e.g.
     </span>
     , visualizations), a frequent need during analysis for
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.8">
      ‘comparison or reference’
     </em>
     (E6) and
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.9">
      ‘inspiring new discoveries’
     </em>
     (E8), as stated by many participants (5/8).
Besides, many participants (5/8) mentioned that they sometimes unknowingly stuck in certain subsets of data attributes (E2, E5) or analytic topics (E1), leading to potential biases. Such issues could have been mitigated if users were
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.10">
      ‘more aware of the data or semantic changes’
     </em>
     (E1).
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Design Requirements
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     The findings indicate that data analysts struggle with current interfaces when working with LLMs. To this end, we aim to design a novel interactive system for better extraction, association, organization, and exploration of insights to facilitate a more efficient data analysis experience. The design requirements can be summarized as follows.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p2">
    <p class="ltx_p" id="S3.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">
      R1: Support automatic insight extraction and association from LLMs’ responses.
     </span>
     Manual extraction and association of insights with relevant evidence from LLMs’ lengthy responses are tedious and error-prone (
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.2">
      C1
     </span>
     ).
Therefore, the system should constantly monitor the conversations to automatically extract insights and insight evidence, as well as establish and maintain associations between them.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p3">
    <p class="ltx_p" id="S3.SS3.p3.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">
      R2: Facilitate effective and on-the-fly insight organization.
     </span>
     Manual organization of insights based on data attributes or analytic topics is inefficient and troublesome (
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.2">
      C2
     </span>
     ), especially when numerous insights and messy analytic context are involved. Meanwhile, resorting to external tools incurs extra manual effort and cognitive overload.
Hence, the system should organize insights along with the analysis process.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p4">
    <p class="ltx_p" id="S3.SS3.p4.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1">
      R3: Provide multi-level and multi-faceted insight exploration.
     </span>
     Exploring previous insights and other analytic context from multiple aspects or levels of detail were non-intuitive and burdensome (
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.2">
      C3
     </span>
     ). Therefore, the system should allow multi-faceted insight exploration (
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p4.1.3">
      e.g.
     </span>
     , temporal, data attributes, analytic topics). Additionally, insight interestingness
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib81" title="">
       81
      </a>
      ]
     </cite>
     and context transitions
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib59" title="">
       59
      </a>
      ]
     </cite>
     should be highlighted to help users quickly identify important insights and enhance analytic comprehensiveness. To facilitate easier navigation and inspection of insights, an insight-level overview should be offered, with details on demand to reveal the supporting evidence and other related insights.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p5">
    <p class="ltx_p" id="S3.SS3.p5.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p5.1.1">
      R4: Adopt familiar and unobtrusive interactions and visual designs.
     </span>
     Users generally appreciate the conversational manner for its intuitive and user-friendly interaction with LLMs. Therefore, enhancing existing interfaces seamlessly with appropriate visualizations is more favorable than creating complex new tools. To avoid steep learning curves and high switching costs, the system should adopt familiar visual designs and flexible interactions that cater to different user needs, without disrupting the original chat-based workflow.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Framework for LLM-Powered Data Analysis
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    We develop a multi-agent framework (Figure
    <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Findings ‣ 3 Formative Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    B) to automatically extract, associate, and organize insights. Each agent, functioned by an LLM and equipped with specialized tools and in-context memory, plans and executes actionable steps to perform different tasks. Initially, the
    <em class="ltx_emph ltx_font_italic" id="S4.p1.1.1">
     Data Science (DS) Agent
    </em>
    interacts with users to complete their analytic tasks, generating a conversation cycle. This conversation cycle is then passed to the
    <em class="ltx_emph ltx_font_italic" id="S4.p1.1.2">
     Insight Extraction (IE) Agent
    </em>
    , which extracts insights from the conversation and associates them with the relevant insight evidence (
    <span class="ltx_text ltx_font_bold" id="S4.p1.1.3">
     R1
    </span>
    ). Meanwhile, the
    <em class="ltx_emph ltx_font_italic" id="S4.p1.1.4">
     IE Agent
    </em>
    evaluates the extracted insights’ interestingness based on their semantic and statistical significance (
    <span class="ltx_text ltx_font_bold" id="S4.p1.1.5">
     R3
    </span>
    ). Subsequently, the
    <em class="ltx_emph ltx_font_italic" id="S4.p1.1.6">
     Insight Management (IM) Agent
    </em>
    examines the insights’ data and semantic characteristics and dynamically organize them with previous insights (
    <span class="ltx_text ltx_font_bold" id="S4.p1.1.7">
     R2, R3
    </span>
    ).
Throughout the conversation cycles,
    <span class="ltx_ERROR undefined" id="S4.p1.1.8">
     \name
    </span>
    iteratively updates the visualizations (Figure
    <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Findings ‣ 3 Formative Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    A) to facilitate flexible and efficient insight exploration from multiple aspects and levels of detail (
    <span class="ltx_text ltx_font_bold" id="S4.p1.1.9">
     R3
    </span>
    ).
This section describes our prompting techniques, with the next section introducing our user interface.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Intent Interpretation
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     As the entry point of our framework, the
     <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.1">
      DS Agent
     </em>
     writes, executes code, and generates insights along with various intermediate outputs to address users’ analytic intents (Figure
     <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Findings ‣ 3 Formative Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     B1). We utilize Open Interpreter
     <span class="ltx_note ltx_role_footnote" id="footnote1">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         1
        </sup>
        <span class="ltx_tag ltx_tag_note">
         1
        </span>
        https://github.com/KillianLucas/open-interpreter/
       </span>
      </span>
     </span>
     to provide a local code execution environment for the agent. Moreover, we adopt the ReAct (Reasoning and Acting)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib74" title="">
       74
      </a>
      ]
     </cite>
     paradigm for prompting, which requires the agent to think step-by-step and adapt its actions based on prior observations. During each conversation cycle, the agent first formulates a plan with actionable steps tailored to the dataset and analytic intent, and then sequentially executes each step to fulfill the analytic needs. At each step, the agent determines its next action (
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">
      e.g.
     </span>
     , refining code, generating insights) by observing previous code execution results and the current analytic stage. This process concludes when the agent has derived sufficient insights to adequately address the analytic intent. To ensure the validity and reliability of the generated insights, we instruct the agent to provide substantial intermediate outputs in its responses, such as code outputs and visualizations.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Insight Extraction and Association
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     To support automatic insight extraction and association (
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.1">
      R1
     </span>
     ), the
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p1.1.2">
      IE Agent
     </em>
     keeps monitoring the conversation history along with the analysis process (Figure
     <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Findings ‣ 3 Formative Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     B2). The design of its prompt is detailed below.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">
      Providing background knowledge.
     </span>
     Prior to task delineation, we introduce the definitions of some key terminologies in data analysis such as
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.2">
      insight
     </em>
     ,
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.3">
      insight evidence
     </em>
     , and
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.4">
      insight interestingness
     </em>
     , drawing from previous literature
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib69" title="">
       69
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      ]
     </cite>
     and our formative study. This allows the agent to be familiar with the essential domain knowledge, facilitating improved task performance and output quality. Subsequently, we provide a brief description of the dataset currently in play, including its title and attributes. This ensures the agent’s focus of the conversation is confined to the information relevant to the data and analytic context, instead of extracting unrelated insights. Finally, we underscore the task and its objectives with a few demonstration examples to better leverage LLMs’ in-context learning
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib9" title="">
       9
      </a>
      ]
     </cite>
     abilities for desired results.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">
      Identifying/Refining insights.
     </span>
     For each conversation cycle, we instruct the agent to carefully examine it and determine whether it contains insights and/or other analytic context. Meanwhile, we maintain the previously identified insights as the agent’s memory, which not only helps it leverage in-context learning to extract insights in a consistent manner, but also enables the refinement of previous insights. During analytic conversations, users may not always pose a new analytic intent every time; they often adjust their prompts for clarification or enhancement
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib11" title="">
       11
      </a>
      ]
     </cite>
     . For example, users may request an alternative visualization to better illustrate a derived insight. Therefore, by directing the agent to choose between two actions (
     <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.2">
      i.e.
     </span>
     ,
     <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.p3.1.3">
      ‘identify new insight’
     </code>
     or
     <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.p3.1.4">
      ‘refine existing insight’
     </code>
     ), we ensure a comprehensive analysis of each conversation cycle without missing key information. Moreover, rather than replicating LLMs’ lengthy responses, the extracted insights are
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p3.1.5">
      summarized
     </em>
     into concise sentences for intuitive understanding.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p4">
    <p class="ltx_p" id="S4.SS2.p4.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">
      Associating insight evidence.
     </span>
     To automatically bind all relevant insight evidence with each insight, the agent is required to scrutinize the code, code outputs, visualizations, and NL explanations in each conversation cycle, focusing on their data and semantic implications. This allows the agent to locate the
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p4.1.2">
      minimum
     </em>
     but
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p4.1.3">
      critical
     </em>
     parts that directly support each insight, which mitigates users’ cognitive load in understanding and verifying insights without having to examine the entire contexts in LLMs’ responses. Meanwhile, the previous insights are also taken into consideration for potential modifications or additions, in case that new evidence may emerge due to users’ iterative prompting.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p5">
    <p class="ltx_p" id="S4.SS2.p5.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.1">
      Evaluating insight interestingness.
     </span>
     Inspired by QuickInsights
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      ]
     </cite>
     , we judge the interestingness of an insight (
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.2">
      R3
     </span>
     ) by two factors: its
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p5.1.3">
      semantic significance
     </em>
     (
     <span class="ltx_text ltx_font_italic" id="S4.SS2.p5.1.4">
      i.e.
     </span>
     , the subject of it should be important, such as a best-selling product) and its
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p5.1.5">
      statistical significance
     </em>
     (
     <span class="ltx_text ltx_font_italic" id="S4.SS2.p5.1.6">
      i.e.
     </span>
     , the relevant statistical metrics of it should be notable, such as a high standard deviation). To achieve this, the agent first evaluates each insight’s semantic meaning to determine its importance. Then, it categorizes the insights and utilizes function calls to calculate their corresponding statistical metrics. We borrow ideas from previous literature for categorizing insights
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib69" title="">
       69
      </a>
      ]
     </cite>
     and mapping insight categories to appropriate statistical functions
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib59" title="">
       59
      </a>
      ]
     </cite>
     . Accordingly, the agent assigns a numerical interestingness score ranging from 1 to 5. To ensure scoring consistency, previous interestingness scores are also provided for reference.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Insight Organization
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     To organize insights from multiple aspects along with the analysis process (
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">
      R2, R3
     </span>
     ), the
     <em class="ltx_emph ltx_font_italic" id="S4.SS3.p1.1.2">
      IM Agent
     </em>
     receives the extracted insights and examines their data and semantic characteristics to categorize them into subgroups based on data attributes and analytic topics (Figure
     <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Findings ‣ 3 Formative Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     B3).
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p2">
    <p class="ltx_p" id="S4.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">
      Providing overall analysis domain.
     </span>
     To ensure the generation of valid data attributes and relevant analytic topics each time, we provide an automatically identified short summary of the dataset and a list of its attributes beforehand. This enables the agent to gain an overall understanding of the analysis domain to facilitate insight organization.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p3">
    <p class="ltx_p" id="S4.SS3.p3.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p3.1.1">
      Determining data context.
     </span>
     The agent is tasked with identifying the corresponding data attributes associated with each insight. To mitigate the risk of fabricating non-existent attributes, we explicitly instruct the agent to restrict its selection to the given attribute list. Meanwhile, it is required to identify the analytical actions (
     <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.2">
      e.g.
     </span>
     ,
     <em class="ltx_emph ltx_font_italic" id="S4.SS3.p3.1.3">
      filtering
     </em>
     and
     <em class="ltx_emph ltx_font_italic" id="S4.SS3.p3.1.4">
      aggregation
     </em>
     , if any) applied to the data subset pertinent to each insight, based on the insight evidence provided. Consequently, we can obtain the data context of each insight to support users’ detailed inspection needs.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p4">
    <p class="ltx_p" id="S4.SS3.p4.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">
      Classifying into topics/subtopics.
     </span>
     As LLM-powered data analysis is a dynamic process, the complete set of insights cannot be predetermined, making traditional topic modeling techniques (
     <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.2">
      e.g.
     </span>
     , LDA) inapplicable. Therefore, we propose a novel topic classification method to sequentially assign analytic topics for each newly extracted insight.
    </p>
    <ol class="ltx_enumerate" id="S4.I1">
     <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="S4.I1.i1.p1">
       <p class="ltx_p" id="S4.I1.i1.p1.1">
        First, we maintain a list of analytic topics derived from the previous conversation (and insights) as the agent’s memory.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="S4.I1.i2.p1">
       <p class="ltx_p" id="S4.I1.i2.p1.1">
        Then, the agent is instructed to
        <code class="ltx_verbatim ltx_font_typewriter" id="S4.I1.i2.p1.1.1">
         select
        </code>
        a suitable topic from the list that best describes the semantic meaning of the insight. To combine LLMs’ NL understanding abilities with a best practice from prior literature
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib51" title="">
          51
         </a>
         ]
        </cite>
        , we provide cosine similarities between the embeddings of the insight and each existing topic for reference, which enables the agent to make more informed decisions.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="S4.I1.i3.p1">
       <p class="ltx_p" id="S4.I1.i3.p1.1">
        In cases where no existing topics correspond to the insight, or when the topic list is empty at the start of each conversation, the agent is required to
        <code class="ltx_verbatim ltx_font_typewriter" id="S4.I1.i3.p1.1.1">
         generate
        </code>
        an appropriate analytic topic. The new topic should be under the provided analysis domain and be broad enough to encompass potentially similar subsequent insights. To avoid the generation of identical or overlapping topics as much as possible, the agent must utilize function calls to calculate the cosine similarities between the candidate new topic and each existing topic. We empirically set the similarity threshold as 0.55. Once any similarity score exceeds the threshold, the agent has to generate another new candidate topic.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="S4.I1.i4.p1">
       <p class="ltx_p" id="S4.I1.i4.p1.1">
        Finally, the selected or generated analytic topic for the insight is determined. We then recursively execute the above steps to classify subtopics within the assigned main topic.
       </p>
      </div>
     </li>
    </ol>
    <p class="ltx_p" id="S4.SS3.p4.2">
     We employ this method to organize the extracted insights semantically in a reliable and structured way during each conversation cycle.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p5">
    <p class="ltx_p" id="S4.SS3.p5.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p5.1.1">
      Identifying related insights.
     </span>
     After obtaining the corresponding data attributes and analytic topics of the extracted insights, we categorize them into subgroups to enable user exploration from different aspects. Moreover, we determine the related insights across two dimensions. First, we identify
     <em class="ltx_emph ltx_font_italic" id="S4.SS3.p5.1.2">
      data-related
     </em>
     insights by comparing the intersections between their associated data attributes. For example, an insight associated with ‘
     <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS3.p5.1.3">
      [MPG, Year, Origin]
     </code>
     ’ is closely related to another one associated with ‘
     <code class="ltx_verbatim ltx_font_typewriter" id="S4.SS3.p5.1.4">
      [MPG, Year]
     </code>
     ’. Second, we identify
     <em class="ltx_emph ltx_font_italic" id="S4.SS3.p5.1.5">
      semantic-related
     </em>
     insights by comparing the cosine similarities between their embeddings. Consequently, two lists of related insights are derived for each insight. By linking these insights together, we address the common user need for easier reference or comparison of similar data findings.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="S4.F2.g1" src="/html/2404.01644/assets/figs/system.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S4.F2.8.1.1" style="font-size:90%;">
       Figure 2
      </span>
      :
     </span>
     <span class="ltx_text" id="S4.F2.9.2" style="font-size:90%;">
      The user interface of
      <span class="ltx_ERROR undefined" id="S4.F2.9.2.1">
       \name
      </span>
      consists of five views. The
      <em class="ltx_emph ltx_font_italic" id="S4.F2.9.2.2">
       Chat Window
      </em>
      (A) enables conversational interactions between users and LLMs. The
      <em class="ltx_emph ltx_font_italic" id="S4.F2.9.2.3">
       Insight Details
      </em>
      (B) displays the currently focused insight’s summary with its relevant data context and supporting evidence. The
      <em class="ltx_emph ltx_font_italic" id="S4.F2.9.2.4">
       Insight Gallery
      </em>
      (C) presents the corresponding related insights in terms of data and semantics. The
      <em class="ltx_emph ltx_font_italic" id="S4.F2.9.2.5">
       Insight Minimap
      </em>
      (D) visualizes the analysis process chronologically based on each insight. The
      <em class="ltx_emph ltx_font_italic" id="S4.F2.9.2.6">
       Topic Canvas
      </em>
      (E) provides the hierarchical topic structure of all insights throughout the conversation.
     </span>
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   InsightLens
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    We develop
    <span class="ltx_ERROR undefined" id="S5.p1.1.1">
     \name
    </span>
    (Figure
    <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Findings ‣ 3 Formative Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    A), an interactive system that builds upon the multi-agent framework to facilitate efficient insight discovery and exploration during LLM-powered data analysis. In this section, we first present an overview of the user interface, and then describe its core features, visual designs, and interactions in detail, including
    <em class="ltx_emph ltx_font_italic" id="S5.p1.1.2">
     User Input
    </em>
    ,
    <em class="ltx_emph ltx_font_italic" id="S5.p1.1.3">
     Insight Inspection
    </em>
    , and
    <em class="ltx_emph ltx_font_italic" id="S5.p1.1.4">
     Topic Exploration
    </em>
    .
   </p>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    User Interface Overview
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     The user interface of
     <span class="ltx_ERROR undefined" id="S5.SS1.p1.1.1">
      \name
     </span>
     consists of five coordinated views (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     ). It is designed with the core principle of enhancing existing interfaces while maintaining users’ original conversational workflow (
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.2">
      R4
     </span>
     ). Given the unique nature of conversations which display the most amount of information at first glance, we sought advice from the data analysts in our formative study and improved our visual designs iteratively. Consequently, we choose to adopt a
     <em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.3">
      ‘details first, overview last’
     </em>
     strategy
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib39" title="">
       39
      </a>
      ]
     </cite>
     from left to right to make the user interface more applicable to the conversational workflow, while facilitating easy inspection and exploration of insights during the analysis process.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p2">
    <p class="ltx_p" id="S5.SS1.p2.1">
     To achieve this, we keep the
     <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.1">
      Chat Window
     </em>
     (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     A) similar to ChatGPT on the left, where users can input their analytic intents and view LLMs’ responses. Beside it, the
     <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.2">
      Insight Details
     </em>
     (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     B) shows an individual insight with its relevant data context and supporting evidence for thorough inspection, while the
     <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.3">
      Insight Gallery
     </em>
     (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     C) displays its data- and semantic-related insights for convenient comparison. Additionally, we employ a matrix-based design in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.4">
      Insight Minimap
     </em>
     (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     D) to chronologically visualize the analysis process. Each row represents a unique insight, showcasing its data and semantic characteristics. Finally, the
     <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.5">
      Topic Canvas
     </em>
     (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     E) on the right adopts a tree-based design to visualize the hierarchical topic structure, enabling users to explore their findings across different analytic topics.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    User Input &amp; Insight Inspection
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     As the entry point of the user interface, users upload their datasets and interact with the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.1">
      DS Agent
     </em>
     (Section
     <a class="ltx_ref" href="#S4.SS1" title="4.1 Intent Interpretation ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       4.1
      </span>
     </a>
     ) in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.2">
      Chat Window
     </em>
     . We adopt a streaming approach while generating LLMs’ responses to mitigate system latency
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib73" title="">
       73
      </a>
      ]
     </cite>
     . Right beside it lays the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.3">
      Insight Details
     </em>
     and
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.4">
      Insight Gallery
     </em>
     arranged vertically to enable detailed inspection for each insight.
Along with the conversation flow, we provide an overview of the extracted insights in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.5">
      Insight Minimap
     </em>
     , which is constructed by
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.6">
      insight rows
     </em>
     vertically stacked in temporal order. These four views are coordinated to scroll together seamlessly. Additionally, by clicking on each insight row, users can conveniently examine its details and navigate between conversation parts. Collectively, the visual designs and interactions support the following tasks to facilitate multi-level and multi-faceted insight exploration and fulfil various user needs (
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.7">
      R3, R4
     </span>
     ).
    </p>
   </div>
   <div class="ltx_para" id="S5.SS2.p2">
    <p class="ltx_p" id="S5.SS2.p2.2">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.2.1">
      Inspecting insight details.
     </span>
     As the conversation progresses, the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.2">
      Insight Details
     </em>
     updates with the latest extracted insight. It consists of five sections (
     <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.2.3">
      i.e.
     </span>
     ,
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.4">
      Data
     </em>
     ,
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.5">
      Code
     </em>
     ,
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.6">
      Code Output
     </em>
     ,
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.7">
      Vis
     </em>
     , and
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.8">
      Insight
     </em>
     ) to display the insight’s summary along with its associated data context and evidence. These sections are collapsible to satisfy different user background and preferences (
     <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.2.9">
      e.g.
     </span>
     , some analysts might not be familiar with coding and prefer to view data attributes or visualizations for verification and understanding).
Meanwhile, the relevant NL explanations are highlighted in LLMs’ original responses in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.10">
      Chat Window
     </em>
     . All these content are the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.11">
      minimum
     </em>
     but
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.12">
      critical
     </em>
     parts of the intermediate outputs to reduce users’ cognitive overload, enabling quick inspection and verification. To navigate among different insights, users can either 1) scroll in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.13">
      Chat Window
     </em>
     or
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.14">
      Insight Minimap
     </em>
     or 2) click on the dots (
     <span class="ltx_ERROR undefined" id="S5.SS2.p2.2.15">
      \scalerel
     </span>
     *
     <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="31" id="S5.SS2.p2.1.g1" src="/html/2404.01644/assets/x3.png" width="31"/>
     ) below each response. Pinning (
     <span class="ltx_ERROR undefined" id="S5.SS2.p2.2.16">
      \scalerel
     </span>
     *
     <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="18" id="S5.SS2.p2.2.g2" src="/html/2404.01644/assets/x4.png" width="11"/>
     ) is also supported to temporarily disable scrolling coordination for focused examination of a specific insight.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS2.p3">
    <p class="ltx_p" id="S5.SS2.p3.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">
      Comparing related insights.
     </span>
     In accordance with the currently focused insight displayed in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.1.2">
      Insight Details
     </em>
     , we present its related insights in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.1.3">
      Insight Gallery
     </em>
     , ranked by similarity (or by temporal order for ties). For simplicity, only the associated visualization and the insight’s summary are displayed in each
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.1.4">
      insight card
     </em>
     . To enable a clear understanding of the rationales behind each recommendation, we show the relevant data attributes for data-related insights and similarity scores for semantic-related insights. Users can click on each insight card in the gallery to view its details for comparison or reference.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS2.p4">
    <p class="ltx_p" id="S5.SS2.p4.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.1">
      Revealing data coverage.
     </span>
     On top of the minimap, we provide a histogram (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     D1) to visualize the distribution of the associated insight numbers across each data attribute. By observing the histogram, users can intuitively understand which attributes have already been extensively analyzed and which ones remain underexplored. Hovering and sorting are also supported to view detailed information and quickly locate the uncovered attributes. Therefore, users’ awareness of their data coverage during the analysis process can significantly be improved.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS2.p5">
    <p class="ltx_p" id="S5.SS2.p5.3">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p5.3.1">
      Understanding context transitions.
     </span>
     In each insight row of the minimap (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     D2), we represent its associated data attributes with a set of connected points (corresponding to the above histogram). This not only enables a quick review of each insight’s data context, but also showcases context transitions throughout the analysis process. For example, certain visual patterns can represent different types of transitions like
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p5.3.2">
      continue
     </em>
     (
     <span class="ltx_ERROR undefined" id="S5.SS2.p5.3.3">
      \scalerel
     </span>
     *
     <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="56" id="S5.SS2.p5.1.g1" src="/html/2404.01644/assets/x5.png" width="97"/>
     ),
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p5.3.4">
      retain
     </em>
     (
     <span class="ltx_ERROR undefined" id="S5.SS2.p5.3.5">
      \scalerel
     </span>
     *
     <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="56" id="S5.SS2.p5.2.g2" src="/html/2404.01644/assets/x6.png" width="61"/>
     ), and
     <em class="ltx_emph ltx_font_italic" id="S5.SS2.p5.3.6">
      shift
     </em>
     (
     <span class="ltx_ERROR undefined" id="S5.SS2.p5.3.7">
      \scalerel
     </span>
     *
     <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="56" id="S5.SS2.p5.3.g3" src="/html/2404.01644/assets/x7.png" width="97"/>
     )
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib59" title="">
       59
      </a>
      ]
     </cite>
     . In case that users expect to prioritize some attributes of interest,
     <span class="ltx_text ltx_font_italic" id="S5.SS2.p5.3.8">
      e.g.
     </span>
     , always keeping track of ‘
     <code class="ltx_verbatim ltx_font_typewriter" id="S5.SS2.p5.3.9">
      Worwide Gross
     </code>
     ’ for financial analysis, they can drag the bars in the above histogram to adjust column order. Additionally, we colorize each insight row to denote its analytic topic and reveal the topic changes. Overall, this intuitive and effective design can be seamlessly integrated into the conversational workflow and helps users better review their analyses across both data and semantic dimensions.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS2.p6">
    <p class="ltx_p" id="S5.SS2.p6.1">
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p6.1.1">
      Highlighting insight interestingness.
     </span>
     To empower users to easily identify and revisit high-quality or interesting insights, we visualize the interestingness scores of each insight as horizontal bars (Figure
     <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     D3), as well as adding a category tag in each insight row for reference. As the ‘interestingness’ of an insight can be subjective and varies among users
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib57" title="">
       57
      </a>
      ]
     </cite>
     , the scores automatically assigned by LLMs may not accurately reflect user preferences (
     <span class="ltx_text ltx_font_italic" id="S5.SS2.p6.1.2">
      i.e.
     </span>
     , whether they would find the insight significant). To balance this, we provide LLMs’ explanations for the rationales behind each interestingness score on hovering, and also allow users to dynamically adjust the score by resizing the corresponding bar. Therefore, this feature offers an alternative way for users to explore previous insights, either based on automated evaluations or their own judgment, similar to a ‘bookmark’ for insight significance.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Topic Exploration
   </h3>
   <div class="ltx_para" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     As the highest-level overview, the
     <em class="ltx_emph ltx_font_italic" id="S5.SS3.p1.1.1">
      Topic Canvas
     </em>
     visualizes the hierarchical topic structure of all extracted insights. We choose the tree-based design due to its simplicity and intuitiveness for topic organization and exploration (
     <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.2">
      R3, R4
     </span>
     ). The tree (without a root node) is structured into two levels, representing main topics and their subtopics, respectively. Each node indicates a topic/subtopic, differentiated by color and labeled with its title and associated insight number. These nodes are visually linked to their corresponding insight rows in the
     <em class="ltx_emph ltx_font_italic" id="S5.SS3.p1.1.3">
      Insight Minimap
     </em>
     . Additionally, hovering over any node will highlight its related insights (and subtopics, if any) and display a brief description for quick inspection of each topic’s essence. Overall, the
     <em class="ltx_emph ltx_font_italic" id="S5.SS3.p1.1.4">
      Topic Canvas
     </em>
     is automatically updated along with the analysis process and coordinated with other views to facilitate insight exploration across analytic topics.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Technical Evaluation
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    The effectiveness of
    <span class="ltx_ERROR undefined" id="S6.p1.1.1">
     \name
    </span>
    depends on whether our multi-agent framework can successfully extract, associate, and organize the generated insights during LLM-powered data analysis. Therefore, we conducted a technical evaluation focusing on (1) the
    <em class="ltx_emph ltx_font_italic" id="S6.p1.1.2">
     coverage
    </em>
    of insight extraction, (2) the
    <em class="ltx_emph ltx_font_italic" id="S6.p1.1.3">
     accuracy
    </em>
    of insight association, and (3) the
    <em class="ltx_emph ltx_font_italic" id="S6.p1.1.4">
     quality
    </em>
    and
    <em class="ltx_emph ltx_font_italic" id="S6.p1.1.5">
     accuracy
    </em>
    of insight organization.
   </p>
  </div>
  <section class="ltx_subsection" id="S6.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.1
    </span>
    Experiment Settings
   </h3>
   <div class="ltx_para" id="S6.SS1.p1">
    <p class="ltx_p" id="S6.SS1.p1.2">
     <span class="ltx_text ltx_font_bold" id="S6.SS1.p1.2.1">
      Dataset.
     </span>
     We collected 10 datasets from reputable sources (6 from Kaggle and 4 from Vega) with diverse analysis domains (
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p1.2.2">
      e.g.
     </span>
     , education, economics) and number of rows (
     <math alttext="\mu=1058,\sigma=777" class="ltx_Math" display="inline" id="S6.SS1.p1.1.m1.2">
      <semantics id="S6.SS1.p1.1.m1.2a">
       <mrow id="S6.SS1.p1.1.m1.2.2.2" xref="S6.SS1.p1.1.m1.2.2.3.cmml">
        <mrow id="S6.SS1.p1.1.m1.1.1.1.1" xref="S6.SS1.p1.1.m1.1.1.1.1.cmml">
         <mi id="S6.SS1.p1.1.m1.1.1.1.1.2" xref="S6.SS1.p1.1.m1.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S6.SS1.p1.1.m1.1.1.1.1.1" xref="S6.SS1.p1.1.m1.1.1.1.1.1.cmml">
          =
         </mo>
         <mn id="S6.SS1.p1.1.m1.1.1.1.1.3" xref="S6.SS1.p1.1.m1.1.1.1.1.3.cmml">
          1058
         </mn>
        </mrow>
        <mo id="S6.SS1.p1.1.m1.2.2.2.3" xref="S6.SS1.p1.1.m1.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S6.SS1.p1.1.m1.2.2.2.2" xref="S6.SS1.p1.1.m1.2.2.2.2.cmml">
         <mi id="S6.SS1.p1.1.m1.2.2.2.2.2" xref="S6.SS1.p1.1.m1.2.2.2.2.2.cmml">
          σ
         </mi>
         <mo id="S6.SS1.p1.1.m1.2.2.2.2.1" xref="S6.SS1.p1.1.m1.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S6.SS1.p1.1.m1.2.2.2.2.3" xref="S6.SS1.p1.1.m1.2.2.2.2.3.cmml">
          777
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.2b">
        <apply id="S6.SS1.p1.1.m1.2.2.3.cmml" xref="S6.SS1.p1.1.m1.2.2.2">
         <csymbol cd="ambiguous" id="S6.SS1.p1.1.m1.2.2.3a.cmml" xref="S6.SS1.p1.1.m1.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S6.SS1.p1.1.m1.1.1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1.1.1">
          <eq id="S6.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1.1.1.1">
          </eq>
          <ci id="S6.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S6.SS1.p1.1.m1.1.1.1.1.2">
           𝜇
          </ci>
          <cn id="S6.SS1.p1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S6.SS1.p1.1.m1.1.1.1.1.3">
           1058
          </cn>
         </apply>
         <apply id="S6.SS1.p1.1.m1.2.2.2.2.cmml" xref="S6.SS1.p1.1.m1.2.2.2.2">
          <eq id="S6.SS1.p1.1.m1.2.2.2.2.1.cmml" xref="S6.SS1.p1.1.m1.2.2.2.2.1">
          </eq>
          <ci id="S6.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S6.SS1.p1.1.m1.2.2.2.2.2">
           𝜎
          </ci>
          <cn id="S6.SS1.p1.1.m1.2.2.2.2.3.cmml" type="integer" xref="S6.SS1.p1.1.m1.2.2.2.2.3">
           777
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.2c">
        \mu=1058,\sigma=777
       </annotation>
      </semantics>
     </math>
     ) and columns (
     <math alttext="\mu=14,\sigma=5" class="ltx_Math" display="inline" id="S6.SS1.p1.2.m2.2">
      <semantics id="S6.SS1.p1.2.m2.2a">
       <mrow id="S6.SS1.p1.2.m2.2.2.2" xref="S6.SS1.p1.2.m2.2.2.3.cmml">
        <mrow id="S6.SS1.p1.2.m2.1.1.1.1" xref="S6.SS1.p1.2.m2.1.1.1.1.cmml">
         <mi id="S6.SS1.p1.2.m2.1.1.1.1.2" xref="S6.SS1.p1.2.m2.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S6.SS1.p1.2.m2.1.1.1.1.1" xref="S6.SS1.p1.2.m2.1.1.1.1.1.cmml">
          =
         </mo>
         <mn id="S6.SS1.p1.2.m2.1.1.1.1.3" xref="S6.SS1.p1.2.m2.1.1.1.1.3.cmml">
          14
         </mn>
        </mrow>
        <mo id="S6.SS1.p1.2.m2.2.2.2.3" xref="S6.SS1.p1.2.m2.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S6.SS1.p1.2.m2.2.2.2.2" xref="S6.SS1.p1.2.m2.2.2.2.2.cmml">
         <mi id="S6.SS1.p1.2.m2.2.2.2.2.2" xref="S6.SS1.p1.2.m2.2.2.2.2.2.cmml">
          σ
         </mi>
         <mo id="S6.SS1.p1.2.m2.2.2.2.2.1" xref="S6.SS1.p1.2.m2.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S6.SS1.p1.2.m2.2.2.2.2.3" xref="S6.SS1.p1.2.m2.2.2.2.2.3.cmml">
          5
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S6.SS1.p1.2.m2.2b">
        <apply id="S6.SS1.p1.2.m2.2.2.3.cmml" xref="S6.SS1.p1.2.m2.2.2.2">
         <csymbol cd="ambiguous" id="S6.SS1.p1.2.m2.2.2.3a.cmml" xref="S6.SS1.p1.2.m2.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S6.SS1.p1.2.m2.1.1.1.1.cmml" xref="S6.SS1.p1.2.m2.1.1.1.1">
          <eq id="S6.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S6.SS1.p1.2.m2.1.1.1.1.1">
          </eq>
          <ci id="S6.SS1.p1.2.m2.1.1.1.1.2.cmml" xref="S6.SS1.p1.2.m2.1.1.1.1.2">
           𝜇
          </ci>
          <cn id="S6.SS1.p1.2.m2.1.1.1.1.3.cmml" type="integer" xref="S6.SS1.p1.2.m2.1.1.1.1.3">
           14
          </cn>
         </apply>
         <apply id="S6.SS1.p1.2.m2.2.2.2.2.cmml" xref="S6.SS1.p1.2.m2.2.2.2.2">
          <eq id="S6.SS1.p1.2.m2.2.2.2.2.1.cmml" xref="S6.SS1.p1.2.m2.2.2.2.2.1">
          </eq>
          <ci id="S6.SS1.p1.2.m2.2.2.2.2.2.cmml" xref="S6.SS1.p1.2.m2.2.2.2.2.2">
           𝜎
          </ci>
          <cn id="S6.SS1.p1.2.m2.2.2.2.2.3.cmml" type="integer" xref="S6.SS1.p1.2.m2.2.2.2.2.3">
           5
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS1.p1.2.m2.2c">
        \mu=14,\sigma=5
       </annotation>
      </semantics>
     </math>
     ). We manually crafted 10 analytic queries for each dataset, totaling to 100 samples. These queries, together with their corresponding datasets, were input into our system, resulting in 104 extracted insights and 50 generated analytic topics (with 70 subtopics).
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p2">
    <p class="ltx_p" id="S6.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S6.SS1.p2.1.1">
      Methodology.
     </span>
     To evaluate insight extraction, we first manually labeled the key insights from the user perspective in the original responses generated by the
     <em class="ltx_emph ltx_font_italic" id="S6.SS1.p2.1.2">
      DS Agent
     </em>
     , providing a ground truth for the insights extracted by the
     <em class="ltx_emph ltx_font_italic" id="S6.SS1.p2.1.3">
      IE Agent
     </em>
     .
Then, we measured the ratio of covered labeled insights to their total number (
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.4">
      i.e.
     </span>
     , coverage). As the automatically extracted insights were summarized by the
     <em class="ltx_emph ltx_font_italic" id="S6.SS1.p2.1.5">
      IE Agent
     </em>
     for easier understanding, we considered a labeled insight as covered if its semantic meaning was contained in the corresponding extracted insight.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p3">
    <p class="ltx_p" id="S6.SS1.p3.1">
     To evaluate insight association, we measured the ratio of insights with correctly associated evidence to the total number of extracted insights (
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p3.1.1">
      i.e.
     </span>
     , accuracy). If any part of the evidence (
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p3.1.2">
      i.e.
     </span>
     , code, code outputs, visualizations, and NL explanations) was incorrect or irrelevant to its corresponding insight, we considered it as a negative sample.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p4">
    <p class="ltx_p" id="S6.SS1.p4.1">
     To evaluate insight organization, we focused on two aspects: data and semantic characteristics (see Section
     <a class="ltx_ref" href="#S4.SS3" title="4.3 Insight Organization ‣ 4 Framework for LLM-Powered Data Analysis ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       4.3
      </span>
     </a>
     ). For data context, we measured the ratio of insights with correctly identified data attributes (and analytical actions) to the total number of extracted insights (
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p4.1.1">
      i.e.
     </span>
     , accuracy). For analytic topics/subtopics, we utilized GPT-4 to rate their quality, a widely adopted method in the NLP community for assessing machine-generated texts
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib10" title="">
       10
      </a>
      ]
     </cite>
     . Specifically, we instructed GPT-4 to consider multiple aspects of the topics (
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p4.1.2">
      e.g.
     </span>
     , relevance, clarity, adaptability) for a thorough evaluation. The detailed prompts can be found in the supplemental material.
As the assignment of analytic topics is subjective and lacks a definitive ground truth, we compared the rating scores of our dynamically generated topics with a static baseline
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib34" title="">
       34
      </a>
      ]
     </cite>
     (
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p4.1.3">
      i.e.
     </span>
     , feeding all insights to GPT-4 for topic generation). Additionally, we manually labeled each insight with the topic list generated by our system as a ground truth for evaluating topic classification accuracy.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.2
    </span>
    Results
   </h3>
   <div class="ltx_para" id="S6.SS2.p1">
    <p class="ltx_p" id="S6.SS2.p1.1">
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.1">
      Metrics.
     </span>
     For insight extraction, the coverage of the extracted insights was
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.2">
      91.2%
     </span>
     (
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.3">
      i.e.
     </span>
     , covered 176 out of 193 labeled insights). For insight association, the accuracy of the associated insight evidence was
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.4">
      88.5%
     </span>
     (
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.5">
      i.e.
     </span>
     , 92 corrects and 12 errors). For insight organization, the accuracy of the identified data context was
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.6">
      88.5%
     </span>
     (
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.7">
      i.e.
     </span>
     , 92 corrects and 12 errors). Additionally, analytic topics produced by our system received an average quality rating of
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.8">
      7.6
     </span>
     on a 10-point scale, surpassing the static baseline (5.9). The accuracy of topic classification was
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.9">
      91.3%
     </span>
     (
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.10">
      i.e.
     </span>
     , 95 corrects and 9 errors). Overall, these statistical metrics demonstrated the effectiveness and robustness of our multi-agent framework.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p2">
    <p class="ltx_p" id="S6.SS2.p2.1">
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p2.1.1">
      Failure Cases Analysis.
     </span>
     For insight extraction, we categorized the 17 failure cases into two types: (1)
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p2.1.2">
      Missing Insights
     </em>
     (8/17) and (2)
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p2.1.3">
      Missing Details
     </em>
     (9/17). The
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p2.1.4">
      IE Agent
     </em>
     sometimes failed to extract all the key insights; instead, it tended to only focus on the most significant ones. For instance, with the query
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p2.1.5">
      ‘compute the average discount percentage offered by each smartphone brand’
     </em>
     , only the brands with the highest and lowest discounts were highlighted, while the
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p2.1.6">
      DS Agent
     </em>
     actually mentioned numerous intermediate brands in its response. In other cases, the agent over-summarized the information, omitting critical details. An example of this is an extracted insight that merely acknowledged the
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p2.1.7">
      ‘top 10 most profitable movies’
     </em>
     without specifying their titles.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p3">
    <p class="ltx_p" id="S6.SS2.p3.1">
     For insight association, we observed two failure modes: (1)
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p3.1.1">
      No Code/Code Output
     </em>
     (5/12) and (2)
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p3.1.2">
      Incorrect NL Explanations
     </em>
     (7/12). In the former, the
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p3.1.3">
      IE Agent
     </em>
     did not include any associated code or code output in its responses. In the latter, it provided incorrect NL explanations that did not align with the insights, arising from either fabricated sentences or an oversimplification of the original output.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p4">
    <p class="ltx_p" id="S6.SS2.p4.1">
     For insight organization, we evaluated failures in terms of data context accuracy and topic classification accuracy. Data context errors primarily stemmed from
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p4.1.1">
      Fabricating Attributes
     </em>
     (9/12), with the remainder due to
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p4.1.2">
      Missing Attributes
     </em>
     (3/12). The former occurred when the
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p4.1.3">
      DS Agent
     </em>
     created new attributes for specific queries (
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p4.1.4">
      e.g.
     </span>
     , defining a
     <code class="ltx_verbatim ltx_font_typewriter" id="S6.SS2.p4.1.5">
      Decade
     </code>
     attribute from
     <code class="ltx_verbatim ltx_font_typewriter" id="S6.SS2.p4.1.6">
      Year
     </code>
     ), leading to the
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p4.1.7">
      IM Agent
     </em>
     ’s inability to correctly identify the original dataset attributes. In contrast, the latter was due to the agent’s occasional failure to fully deduce the associated attributes. Regarding topic classification, the predominant issue was
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p4.1.8">
      Topic Disagreement
     </em>
     (9/9), where humans and LLMs focused on different aspects. Since insights could span multiple topics, such cases were technically not ‘errors’ but rather outcomes of varying labeling criteria.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p5">
    <p class="ltx_p" id="S6.SS2.p5.1">
     Overall, most failure cases discussed above can be ascribed to LLMs’ hallucinations. Such issues are particularly evident given the intricate nature of our targeted tasks and the complex prompting techniques we employ for our framework, which often lead to LLMs’ generation of unexpected outputs. To mitigate this, we can incorporate more effective instructions to make LLMs’ behavior more reliable and robust
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib77" title="">
       77
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p6">
    <p class="ltx_p" id="S6.SS2.p6.1">
     <span class="ltx_text ltx_font_bold" id="S6.SS2.p6.1.1">
      Summary.
     </span>
     Despite the few failure cases, the results demonstrated our multi-agent framework’s high coverage, accuracy, and quality in automatically extracting, associating, and organizing the generated insights in analytic conversations. This can significantly reduce users’ manual and cognitive effort during LLM-powered data analysis, establishing a solid foundation for the interactive features of
     <span class="ltx_ERROR undefined" id="S6.SS2.p6.1.2">
      \name
     </span>
     .
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   User Study
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    To evaluate the effectiveness of
    <span class="ltx_ERROR undefined" id="S7.p1.1.1">
     \name
    </span>
    in facilitating insight discovery and exploration during LLM-powered data analysis, we conducted a within-subjects user study. Specifically, we aimed to collect users’ feedback on the effectiveness and usability of
    <span class="ltx_ERROR undefined" id="S7.p1.1.2">
     \name
    </span>
    ’s features, as well as its impact on the overall data analysis process.
   </p>
  </div>
  <section class="ltx_subsection" id="S7.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.1
    </span>
    Experiment Design
   </h3>
   <div class="ltx_para" id="S7.SS1.p1">
    <p class="ltx_p" id="S7.SS1.p1.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS1.p1.1.1">
      Participants and Setup.
     </span>
     We recruited 12 data analysts (P1-12, 4 females and 8 males, age from 24 to 29) from the business intelligence department of a local technology company. Each had 4 to 8 years of experience in data analysis. Their daily tasks included analyzing datasets and reporting data findings, with proficiency in various tools like Excel (12/12), Python (10/12), and Microsoft Power BI (8/12). All of them had experience using LLMs (
     <span class="ltx_text ltx_font_italic" id="S7.SS1.p1.1.2">
      e.g.
     </span>
     , ChatGPT, Claude, Qwen) for their work with varying frequencies (6 often, 4 sometimes, 2 rarely). Each participant received $25 as compensation upon completion.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS1.p2">
    <p class="ltx_p" id="S7.SS1.p2.1">
     For our comparative study, we set the
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p2.1.1">
      Baseline
     </em>
     as the
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p2.1.2">
      Chat Window
     </em>
     of
     <span class="ltx_ERROR undefined" id="S7.SS1.p2.1.3">
      \name
     </span>
     , excluding all interactive visualizations for insight inspection and exploration. This ChatGPT-like
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p2.1.4">
      Baseline
     </em>
     mirrored the systems participants currently used when interacting with LLMs. We also provided a document editor for participants to record their findings.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS1.p3">
    <p class="ltx_p" id="S7.SS1.p3.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS1.p3.1.1">
      Tasks and Datasets.
     </span>
     Participants were asked to use both
     <span class="ltx_ERROR undefined" id="S7.SS1.p3.1.2">
      \name
     </span>
     and
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p3.1.3">
      Baseline
     </em>
     to analyze two datasets: (1) a housing dataset (15 columns, 1460 rows) and (2) a colleges dataset (14 columns, 1214 rows). They were instructed to perform open-ended data exploration on each dataset to provide insights into (1) the housing market dynamics for real estate agents, and (2) the various factors of US colleges for student applicants, as if they were to provide a comprehensive data report within a week. To mitigate learning effects while ensuring comparability of collected data across different experiment sessions, we split each dataset into two parts
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib33" title="">
       33
      </a>
      ]
     </cite>
     , each of which was allocated to one of the systems.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS1.p4">
    <p class="ltx_p" id="S7.SS1.p4.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS1.p4.1.1">
      Procedure.
     </span>
     Initially, participants were asked to sign a consent form and fill out a pre-study questionnaire to collect demographic information. After that, we conducted a tutorial using an example dataset to introduce the features of both systems. Participants were then given adequate time to familiarize themselves with each system, during which they were encouraged to raise any questions or concerns.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS1.p5">
    <p class="ltx_p" id="S7.SS1.p5.1">
     Then, participants were requested to use both systems across two datasets (and tasks). We counterbalanced the order of the systems and datasets (4=2x2 sessions in total) to mitigate learning effects. Each session lasted 15 minutes and was screen- and audio-recorded as system logs. Participants were also encouraged to think aloud about their thoughts and findings during the analysis process.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS1.p6">
    <p class="ltx_p" id="S7.SS1.p6.1">
     Finally, participants were required to complete a post-study questionnaire using a 5-point Likert scale, followed by a semi-structured interview to comprehend their ratings and collect qualitative feedback on the effectiveness, usability, and potential impact of the system on their daily workflow. The entire study lasted about 120 minutes.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS1.p7">
    <p class="ltx_p" id="S7.SS1.p7.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS1.p7.1.1">
      Measures.
     </span>
     We collected 48(=12x4) recordings and system logs in the experiments. To complement participants’ qualitative feedback, we employed the following measures: (1)
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p7.1.2">
      number of confirmed insights
     </em>
     , (2)
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p7.1.3">
      number of unique data attributes explored
     </em>
     , and (3)
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p7.1.4">
      number of unique analytic topics explored
     </em>
     . These measures were informed by previous literature
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib43" title="">
       43
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib66" title="">
       66
      </a>
      ]
     </cite>
     and offered quantitative evidence for our analysis. To ensure methodological consistency, we utilized the same prompting techniques of
     <span class="ltx_ERROR undefined" id="S7.SS1.p7.1.5">
      \name
     </span>
     on
     <em class="ltx_emph ltx_font_italic" id="S7.SS1.p7.1.6">
      Baseline
     </em>
     for data processing.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.2
    </span>
    Results
   </h3>
   <figure class="ltx_figure" id="S7.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="282" id="S7.F3.g1" src="/html/2404.01644/assets/x8.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S7.F3.3.1.1" style="font-size:90%;">
       Figure 3
      </span>
      :
     </span>
     <span class="ltx_text" id="S7.F3.4.2" style="font-size:90%;">
      The results of the measures and qualitative ratings regarding
      <span class="ltx_ERROR undefined" id="S7.F3.4.2.1">
       \name
      </span>
      ’s support for insight discovery and exploration.
     </span>
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S7.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="312" id="S7.F4.g1" src="/html/2404.01644/assets/x9.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S7.F4.3.1.1" style="font-size:90%;">
       Figure 4
      </span>
      :
     </span>
     <span class="ltx_text" id="S7.F4.4.2" style="font-size:90%;">
      The results of the questionnaire regarding
      <span class="ltx_ERROR undefined" id="S7.F4.4.2.1">
       \name
      </span>
      ’s effectiveness, usability, and impact on data analysis.
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S7.SS2.p1">
    <p class="ltx_p" id="S7.SS2.p1.1">
     All participants completed four experiment sessions successfully. Based on their qualitative feedback and the collected quantitative measures, we discuss the effectiveness of
     <span class="ltx_ERROR undefined" id="S7.SS2.p1.1.1">
      \name
     </span>
     in facilitating insight discovery and exploration (Figure
     <a class="ltx_ref" href="#S7.F3" title="Figure 3 ‣ 7.2 Results ‣ 7 User Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     ). We then report
     <span class="ltx_ERROR undefined" id="S7.SS2.p1.1.2">
      \name
     </span>
     ’s feature effectiveness, system usability, and impact on data analysis (Figure
     <a class="ltx_ref" href="#S7.F4" title="Figure 4 ‣ 7.2 Results ‣ 7 User Study ‣ InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     ).
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p2">
    <p class="ltx_p" id="S7.SS2.p2.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS2.p2.1.1">
      Support for Insight Discovery.
     </span>
     The effectiveness of
     <span class="ltx_ERROR undefined" id="S7.SS2.p2.1.2">
      \name
     </span>
     in facilitating insight discovery was appreciated by all participants (
     <math alttext="\mu=4.67&gt;2.67,p=.002" class="ltx_Math" display="inline" id="S7.SS2.p2.1.m1.2">
      <semantics id="S7.SS2.p2.1.m1.2a">
       <mrow id="S7.SS2.p2.1.m1.2.2.2" xref="S7.SS2.p2.1.m1.2.2.3.cmml">
        <mrow id="S7.SS2.p2.1.m1.1.1.1.1" xref="S7.SS2.p2.1.m1.1.1.1.1.cmml">
         <mi id="S7.SS2.p2.1.m1.1.1.1.1.2" xref="S7.SS2.p2.1.m1.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p2.1.m1.1.1.1.1.3" xref="S7.SS2.p2.1.m1.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p2.1.m1.1.1.1.1.4" xref="S7.SS2.p2.1.m1.1.1.1.1.4.cmml">
          4.67
         </mn>
         <mo id="S7.SS2.p2.1.m1.1.1.1.1.5" xref="S7.SS2.p2.1.m1.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p2.1.m1.1.1.1.1.6" xref="S7.SS2.p2.1.m1.1.1.1.1.6.cmml">
          2.67
         </mn>
        </mrow>
        <mo id="S7.SS2.p2.1.m1.2.2.2.3" xref="S7.SS2.p2.1.m1.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p2.1.m1.2.2.2.2" xref="S7.SS2.p2.1.m1.2.2.2.2.cmml">
         <mi id="S7.SS2.p2.1.m1.2.2.2.2.2" xref="S7.SS2.p2.1.m1.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p2.1.m1.2.2.2.2.1" xref="S7.SS2.p2.1.m1.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p2.1.m1.2.2.2.2.3" xref="S7.SS2.p2.1.m1.2.2.2.2.3.cmml">
          .002
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p2.1.m1.2b">
        <apply id="S7.SS2.p2.1.m1.2.2.3.cmml" xref="S7.SS2.p2.1.m1.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p2.1.m1.2.2.3a.cmml" xref="S7.SS2.p2.1.m1.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p2.1.m1.1.1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1">
          <and id="S7.SS2.p2.1.m1.1.1.1.1a.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1">
          </and>
          <apply id="S7.SS2.p2.1.m1.1.1.1.1b.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1">
           <eq id="S7.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p2.1.m1.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p2.1.m1.1.1.1.1.4">
            4.67
           </cn>
          </apply>
          <apply id="S7.SS2.p2.1.m1.1.1.1.1c.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1">
           <gt id="S7.SS2.p2.1.m1.1.1.1.1.5.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p2.1.m1.1.1.1.1.4.cmml" id="S7.SS2.p2.1.m1.1.1.1.1d.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1">
           </share>
           <cn id="S7.SS2.p2.1.m1.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p2.1.m1.1.1.1.1.6">
            2.67
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p2.1.m1.2.2.2.2.cmml" xref="S7.SS2.p2.1.m1.2.2.2.2">
          <eq id="S7.SS2.p2.1.m1.2.2.2.2.1.cmml" xref="S7.SS2.p2.1.m1.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S7.SS2.p2.1.m1.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p2.1.m1.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p2.1.m1.2.2.2.2.3">
           .002
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p2.1.m1.2c">
        \mu=4.67&gt;2.67,p=.002
       </annotation>
      </semantics>
     </math>
     ), while
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.3">
      Baseline
     </em>
     forced them to manually scrutinize and summarize insights from LLMs’ lengthy responses. P3 expressed his favor for
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.4">
      ‘the dots below each message’
     </em>
     that
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.5">
      ‘reminded him of missed insights’
     </em>
     . Also, the highlighted NL explanations in each response were reported as
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.6">
      ‘being particularly useful for her to quickly identify key points’
     </em>
     (P11). Moreover,
     <span class="ltx_ERROR undefined" id="S7.SS2.p2.1.7">
      \name
     </span>
     significantly streamlined the verification of insights. We observed that participants constantly referred to the
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.8">
      Insight Details
     </em>
     to review the relevant insight evidence, which allowed them to
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.9">
      ‘easily see the involved attributes and visualizations without scrolling up and down’
     </em>
     (P10).
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p3">
    <p class="ltx_p" id="S7.SS2.p3.2">
     Additionally, one of our measures reinforced
     <span class="ltx_ERROR undefined" id="S7.SS2.p3.2.1">
      \name
     </span>
     ’s support for insight discovery. Specifically, participants confirmed more insights using
     <span class="ltx_ERROR undefined" id="S7.SS2.p3.2.2">
      \name
     </span>
     compared to
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p3.2.3">
      Baseline
     </em>
     (Task 1:
     <math alttext="\mu=10.4&gt;7.4,p=.002" class="ltx_Math" display="inline" id="S7.SS2.p3.1.m1.2">
      <semantics id="S7.SS2.p3.1.m1.2a">
       <mrow id="S7.SS2.p3.1.m1.2.2.2" xref="S7.SS2.p3.1.m1.2.2.3.cmml">
        <mrow id="S7.SS2.p3.1.m1.1.1.1.1" xref="S7.SS2.p3.1.m1.1.1.1.1.cmml">
         <mi id="S7.SS2.p3.1.m1.1.1.1.1.2" xref="S7.SS2.p3.1.m1.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p3.1.m1.1.1.1.1.3" xref="S7.SS2.p3.1.m1.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p3.1.m1.1.1.1.1.4" xref="S7.SS2.p3.1.m1.1.1.1.1.4.cmml">
          10.4
         </mn>
         <mo id="S7.SS2.p3.1.m1.1.1.1.1.5" xref="S7.SS2.p3.1.m1.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p3.1.m1.1.1.1.1.6" xref="S7.SS2.p3.1.m1.1.1.1.1.6.cmml">
          7.4
         </mn>
        </mrow>
        <mo id="S7.SS2.p3.1.m1.2.2.2.3" xref="S7.SS2.p3.1.m1.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p3.1.m1.2.2.2.2" xref="S7.SS2.p3.1.m1.2.2.2.2.cmml">
         <mi id="S7.SS2.p3.1.m1.2.2.2.2.2" xref="S7.SS2.p3.1.m1.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p3.1.m1.2.2.2.2.1" xref="S7.SS2.p3.1.m1.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p3.1.m1.2.2.2.2.3" xref="S7.SS2.p3.1.m1.2.2.2.2.3.cmml">
          .002
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p3.1.m1.2b">
        <apply id="S7.SS2.p3.1.m1.2.2.3.cmml" xref="S7.SS2.p3.1.m1.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p3.1.m1.2.2.3a.cmml" xref="S7.SS2.p3.1.m1.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p3.1.m1.1.1.1.1.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1">
          <and id="S7.SS2.p3.1.m1.1.1.1.1a.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1">
          </and>
          <apply id="S7.SS2.p3.1.m1.1.1.1.1b.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1">
           <eq id="S7.SS2.p3.1.m1.1.1.1.1.3.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p3.1.m1.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p3.1.m1.1.1.1.1.4">
            10.4
           </cn>
          </apply>
          <apply id="S7.SS2.p3.1.m1.1.1.1.1c.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1">
           <gt id="S7.SS2.p3.1.m1.1.1.1.1.5.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p3.1.m1.1.1.1.1.4.cmml" id="S7.SS2.p3.1.m1.1.1.1.1d.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1">
           </share>
           <cn id="S7.SS2.p3.1.m1.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p3.1.m1.1.1.1.1.6">
            7.4
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p3.1.m1.2.2.2.2.cmml" xref="S7.SS2.p3.1.m1.2.2.2.2">
          <eq id="S7.SS2.p3.1.m1.2.2.2.2.1.cmml" xref="S7.SS2.p3.1.m1.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S7.SS2.p3.1.m1.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p3.1.m1.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p3.1.m1.2.2.2.2.3">
           .002
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p3.1.m1.2c">
        \mu=10.4&gt;7.4,p=.002
       </annotation>
      </semantics>
     </math>
     ; Task 2:
     <math alttext="\mu=11.1&gt;7.3,p=.005" class="ltx_Math" display="inline" id="S7.SS2.p3.2.m2.2">
      <semantics id="S7.SS2.p3.2.m2.2a">
       <mrow id="S7.SS2.p3.2.m2.2.2.2" xref="S7.SS2.p3.2.m2.2.2.3.cmml">
        <mrow id="S7.SS2.p3.2.m2.1.1.1.1" xref="S7.SS2.p3.2.m2.1.1.1.1.cmml">
         <mi id="S7.SS2.p3.2.m2.1.1.1.1.2" xref="S7.SS2.p3.2.m2.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p3.2.m2.1.1.1.1.3" xref="S7.SS2.p3.2.m2.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p3.2.m2.1.1.1.1.4" xref="S7.SS2.p3.2.m2.1.1.1.1.4.cmml">
          11.1
         </mn>
         <mo id="S7.SS2.p3.2.m2.1.1.1.1.5" xref="S7.SS2.p3.2.m2.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p3.2.m2.1.1.1.1.6" xref="S7.SS2.p3.2.m2.1.1.1.1.6.cmml">
          7.3
         </mn>
        </mrow>
        <mo id="S7.SS2.p3.2.m2.2.2.2.3" xref="S7.SS2.p3.2.m2.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p3.2.m2.2.2.2.2" xref="S7.SS2.p3.2.m2.2.2.2.2.cmml">
         <mi id="S7.SS2.p3.2.m2.2.2.2.2.2" xref="S7.SS2.p3.2.m2.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p3.2.m2.2.2.2.2.1" xref="S7.SS2.p3.2.m2.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p3.2.m2.2.2.2.2.3" xref="S7.SS2.p3.2.m2.2.2.2.2.3.cmml">
          .005
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p3.2.m2.2b">
        <apply id="S7.SS2.p3.2.m2.2.2.3.cmml" xref="S7.SS2.p3.2.m2.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p3.2.m2.2.2.3a.cmml" xref="S7.SS2.p3.2.m2.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p3.2.m2.1.1.1.1.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1">
          <and id="S7.SS2.p3.2.m2.1.1.1.1a.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1">
          </and>
          <apply id="S7.SS2.p3.2.m2.1.1.1.1b.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1">
           <eq id="S7.SS2.p3.2.m2.1.1.1.1.3.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p3.2.m2.1.1.1.1.2.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p3.2.m2.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p3.2.m2.1.1.1.1.4">
            11.1
           </cn>
          </apply>
          <apply id="S7.SS2.p3.2.m2.1.1.1.1c.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1">
           <gt id="S7.SS2.p3.2.m2.1.1.1.1.5.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p3.2.m2.1.1.1.1.4.cmml" id="S7.SS2.p3.2.m2.1.1.1.1d.cmml" xref="S7.SS2.p3.2.m2.1.1.1.1">
           </share>
           <cn id="S7.SS2.p3.2.m2.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p3.2.m2.1.1.1.1.6">
            7.3
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p3.2.m2.2.2.2.2.cmml" xref="S7.SS2.p3.2.m2.2.2.2.2">
          <eq id="S7.SS2.p3.2.m2.2.2.2.2.1.cmml" xref="S7.SS2.p3.2.m2.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p3.2.m2.2.2.2.2.2.cmml" xref="S7.SS2.p3.2.m2.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p3.2.m2.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p3.2.m2.2.2.2.2.3">
           .005
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p3.2.m2.2c">
        \mu=11.1&gt;7.3,p=.005
       </annotation>
      </semantics>
     </math>
     ). By
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p3.2.4">
      confirming
     </em>
     an insight, they not only identified it, but also thoroughly verified its correctness. Therefore, we ascribed the observed significant difference to
     <span class="ltx_ERROR undefined" id="S7.SS2.p3.2.5">
      \name
     </span>
     ’s support for reducing the time needed for verification, thereby leading to more insights discovered within a limited time frame.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p4">
    <p class="ltx_p" id="S7.SS2.p4.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS2.p4.1.1">
      Support for Insight Exploration.
     </span>
     The effectiveness of
     <span class="ltx_ERROR undefined" id="S7.SS2.p4.1.2">
      \name
     </span>
     in exploring previously discovered insights received significantly higher ratings than
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p4.1.3">
      Baseline
     </em>
     (
     <math alttext="\mu=4.92&gt;2.25,p=.002" class="ltx_Math" display="inline" id="S7.SS2.p4.1.m1.2">
      <semantics id="S7.SS2.p4.1.m1.2a">
       <mrow id="S7.SS2.p4.1.m1.2.2.2" xref="S7.SS2.p4.1.m1.2.2.3.cmml">
        <mrow id="S7.SS2.p4.1.m1.1.1.1.1" xref="S7.SS2.p4.1.m1.1.1.1.1.cmml">
         <mi id="S7.SS2.p4.1.m1.1.1.1.1.2" xref="S7.SS2.p4.1.m1.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p4.1.m1.1.1.1.1.3" xref="S7.SS2.p4.1.m1.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p4.1.m1.1.1.1.1.4" xref="S7.SS2.p4.1.m1.1.1.1.1.4.cmml">
          4.92
         </mn>
         <mo id="S7.SS2.p4.1.m1.1.1.1.1.5" xref="S7.SS2.p4.1.m1.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p4.1.m1.1.1.1.1.6" xref="S7.SS2.p4.1.m1.1.1.1.1.6.cmml">
          2.25
         </mn>
        </mrow>
        <mo id="S7.SS2.p4.1.m1.2.2.2.3" xref="S7.SS2.p4.1.m1.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p4.1.m1.2.2.2.2" xref="S7.SS2.p4.1.m1.2.2.2.2.cmml">
         <mi id="S7.SS2.p4.1.m1.2.2.2.2.2" xref="S7.SS2.p4.1.m1.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p4.1.m1.2.2.2.2.1" xref="S7.SS2.p4.1.m1.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p4.1.m1.2.2.2.2.3" xref="S7.SS2.p4.1.m1.2.2.2.2.3.cmml">
          .002
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p4.1.m1.2b">
        <apply id="S7.SS2.p4.1.m1.2.2.3.cmml" xref="S7.SS2.p4.1.m1.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p4.1.m1.2.2.3a.cmml" xref="S7.SS2.p4.1.m1.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p4.1.m1.1.1.1.1.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1">
          <and id="S7.SS2.p4.1.m1.1.1.1.1a.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1">
          </and>
          <apply id="S7.SS2.p4.1.m1.1.1.1.1b.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1">
           <eq id="S7.SS2.p4.1.m1.1.1.1.1.3.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p4.1.m1.1.1.1.1.2.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p4.1.m1.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p4.1.m1.1.1.1.1.4">
            4.92
           </cn>
          </apply>
          <apply id="S7.SS2.p4.1.m1.1.1.1.1c.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1">
           <gt id="S7.SS2.p4.1.m1.1.1.1.1.5.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p4.1.m1.1.1.1.1.4.cmml" id="S7.SS2.p4.1.m1.1.1.1.1d.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1">
           </share>
           <cn id="S7.SS2.p4.1.m1.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p4.1.m1.1.1.1.1.6">
            2.25
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p4.1.m1.2.2.2.2.cmml" xref="S7.SS2.p4.1.m1.2.2.2.2">
          <eq id="S7.SS2.p4.1.m1.2.2.2.2.1.cmml" xref="S7.SS2.p4.1.m1.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p4.1.m1.2.2.2.2.2.cmml" xref="S7.SS2.p4.1.m1.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p4.1.m1.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p4.1.m1.2.2.2.2.3">
           .002
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p4.1.m1.2c">
        \mu=4.92&gt;2.25,p=.002
       </annotation>
      </semantics>
     </math>
     ). Participants highly appreciated
     <span class="ltx_ERROR undefined" id="S7.SS2.p4.1.4">
      \name
     </span>
     ’s features for exploring insights from different aspects. For example, P4 commented that
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p4.1.5">
      ‘it was nice to track his findings by time order in the minimap’
     </em>
     , while
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p4.1.6">
      ‘using the baseline required him to navigate back and forth to grasp what he explored before’
     </em>
     . During open-ended data exploration, participants acknowledged the importance of keeping them aware of the overall analysis flow, which avoided
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p4.1.7">
      ‘repetitive analyses on a previously explored topic’
     </em>
     (P8).
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p5">
    <p class="ltx_p" id="S7.SS2.p5.4">
     Interestingly, the quantitative measures revealed the potential expansion on participants’ data and analytic coverage due to their improved awareness of the analyses. When using
     <span class="ltx_ERROR undefined" id="S7.SS2.p5.4.1">
      \name
     </span>
     , they explored more data attributes (Task 1:
     <math alttext="\mu=12.4&gt;9.3,p=.006" class="ltx_Math" display="inline" id="S7.SS2.p5.1.m1.2">
      <semantics id="S7.SS2.p5.1.m1.2a">
       <mrow id="S7.SS2.p5.1.m1.2.2.2" xref="S7.SS2.p5.1.m1.2.2.3.cmml">
        <mrow id="S7.SS2.p5.1.m1.1.1.1.1" xref="S7.SS2.p5.1.m1.1.1.1.1.cmml">
         <mi id="S7.SS2.p5.1.m1.1.1.1.1.2" xref="S7.SS2.p5.1.m1.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p5.1.m1.1.1.1.1.3" xref="S7.SS2.p5.1.m1.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.1.m1.1.1.1.1.4" xref="S7.SS2.p5.1.m1.1.1.1.1.4.cmml">
          12.4
         </mn>
         <mo id="S7.SS2.p5.1.m1.1.1.1.1.5" xref="S7.SS2.p5.1.m1.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p5.1.m1.1.1.1.1.6" xref="S7.SS2.p5.1.m1.1.1.1.1.6.cmml">
          9.3
         </mn>
        </mrow>
        <mo id="S7.SS2.p5.1.m1.2.2.2.3" xref="S7.SS2.p5.1.m1.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p5.1.m1.2.2.2.2" xref="S7.SS2.p5.1.m1.2.2.2.2.cmml">
         <mi id="S7.SS2.p5.1.m1.2.2.2.2.2" xref="S7.SS2.p5.1.m1.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p5.1.m1.2.2.2.2.1" xref="S7.SS2.p5.1.m1.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.1.m1.2.2.2.2.3" xref="S7.SS2.p5.1.m1.2.2.2.2.3.cmml">
          .006
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p5.1.m1.2b">
        <apply id="S7.SS2.p5.1.m1.2.2.3.cmml" xref="S7.SS2.p5.1.m1.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p5.1.m1.2.2.3a.cmml" xref="S7.SS2.p5.1.m1.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p5.1.m1.1.1.1.1.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1">
          <and id="S7.SS2.p5.1.m1.1.1.1.1a.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1">
          </and>
          <apply id="S7.SS2.p5.1.m1.1.1.1.1b.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1">
           <eq id="S7.SS2.p5.1.m1.1.1.1.1.3.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p5.1.m1.1.1.1.1.2.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p5.1.m1.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p5.1.m1.1.1.1.1.4">
            12.4
           </cn>
          </apply>
          <apply id="S7.SS2.p5.1.m1.1.1.1.1c.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1">
           <gt id="S7.SS2.p5.1.m1.1.1.1.1.5.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p5.1.m1.1.1.1.1.4.cmml" id="S7.SS2.p5.1.m1.1.1.1.1d.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1">
           </share>
           <cn id="S7.SS2.p5.1.m1.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p5.1.m1.1.1.1.1.6">
            9.3
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p5.1.m1.2.2.2.2.cmml" xref="S7.SS2.p5.1.m1.2.2.2.2">
          <eq id="S7.SS2.p5.1.m1.2.2.2.2.1.cmml" xref="S7.SS2.p5.1.m1.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p5.1.m1.2.2.2.2.2.cmml" xref="S7.SS2.p5.1.m1.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p5.1.m1.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p5.1.m1.2.2.2.2.3">
           .006
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p5.1.m1.2c">
        \mu=12.4&gt;9.3,p=.006
       </annotation>
      </semantics>
     </math>
     ; Task 2:
     <math alttext="\mu=12.3&gt;9.1,p=.012" class="ltx_Math" display="inline" id="S7.SS2.p5.2.m2.2">
      <semantics id="S7.SS2.p5.2.m2.2a">
       <mrow id="S7.SS2.p5.2.m2.2.2.2" xref="S7.SS2.p5.2.m2.2.2.3.cmml">
        <mrow id="S7.SS2.p5.2.m2.1.1.1.1" xref="S7.SS2.p5.2.m2.1.1.1.1.cmml">
         <mi id="S7.SS2.p5.2.m2.1.1.1.1.2" xref="S7.SS2.p5.2.m2.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p5.2.m2.1.1.1.1.3" xref="S7.SS2.p5.2.m2.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.2.m2.1.1.1.1.4" xref="S7.SS2.p5.2.m2.1.1.1.1.4.cmml">
          12.3
         </mn>
         <mo id="S7.SS2.p5.2.m2.1.1.1.1.5" xref="S7.SS2.p5.2.m2.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p5.2.m2.1.1.1.1.6" xref="S7.SS2.p5.2.m2.1.1.1.1.6.cmml">
          9.1
         </mn>
        </mrow>
        <mo id="S7.SS2.p5.2.m2.2.2.2.3" xref="S7.SS2.p5.2.m2.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p5.2.m2.2.2.2.2" xref="S7.SS2.p5.2.m2.2.2.2.2.cmml">
         <mi id="S7.SS2.p5.2.m2.2.2.2.2.2" xref="S7.SS2.p5.2.m2.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p5.2.m2.2.2.2.2.1" xref="S7.SS2.p5.2.m2.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.2.m2.2.2.2.2.3" xref="S7.SS2.p5.2.m2.2.2.2.2.3.cmml">
          .012
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p5.2.m2.2b">
        <apply id="S7.SS2.p5.2.m2.2.2.3.cmml" xref="S7.SS2.p5.2.m2.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p5.2.m2.2.2.3a.cmml" xref="S7.SS2.p5.2.m2.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p5.2.m2.1.1.1.1.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1">
          <and id="S7.SS2.p5.2.m2.1.1.1.1a.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1">
          </and>
          <apply id="S7.SS2.p5.2.m2.1.1.1.1b.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1">
           <eq id="S7.SS2.p5.2.m2.1.1.1.1.3.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p5.2.m2.1.1.1.1.2.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p5.2.m2.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p5.2.m2.1.1.1.1.4">
            12.3
           </cn>
          </apply>
          <apply id="S7.SS2.p5.2.m2.1.1.1.1c.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1">
           <gt id="S7.SS2.p5.2.m2.1.1.1.1.5.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p5.2.m2.1.1.1.1.4.cmml" id="S7.SS2.p5.2.m2.1.1.1.1d.cmml" xref="S7.SS2.p5.2.m2.1.1.1.1">
           </share>
           <cn id="S7.SS2.p5.2.m2.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p5.2.m2.1.1.1.1.6">
            9.1
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p5.2.m2.2.2.2.2.cmml" xref="S7.SS2.p5.2.m2.2.2.2.2">
          <eq id="S7.SS2.p5.2.m2.2.2.2.2.1.cmml" xref="S7.SS2.p5.2.m2.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p5.2.m2.2.2.2.2.2.cmml" xref="S7.SS2.p5.2.m2.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p5.2.m2.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p5.2.m2.2.2.2.2.3">
           .012
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p5.2.m2.2c">
        \mu=12.3&gt;9.1,p=.012
       </annotation>
      </semantics>
     </math>
     ) and analytic topics (Task 1:
     <math alttext="\mu=6.5&gt;5.3,p=.03" class="ltx_Math" display="inline" id="S7.SS2.p5.3.m3.2">
      <semantics id="S7.SS2.p5.3.m3.2a">
       <mrow id="S7.SS2.p5.3.m3.2.2.2" xref="S7.SS2.p5.3.m3.2.2.3.cmml">
        <mrow id="S7.SS2.p5.3.m3.1.1.1.1" xref="S7.SS2.p5.3.m3.1.1.1.1.cmml">
         <mi id="S7.SS2.p5.3.m3.1.1.1.1.2" xref="S7.SS2.p5.3.m3.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p5.3.m3.1.1.1.1.3" xref="S7.SS2.p5.3.m3.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.3.m3.1.1.1.1.4" xref="S7.SS2.p5.3.m3.1.1.1.1.4.cmml">
          6.5
         </mn>
         <mo id="S7.SS2.p5.3.m3.1.1.1.1.5" xref="S7.SS2.p5.3.m3.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p5.3.m3.1.1.1.1.6" xref="S7.SS2.p5.3.m3.1.1.1.1.6.cmml">
          5.3
         </mn>
        </mrow>
        <mo id="S7.SS2.p5.3.m3.2.2.2.3" xref="S7.SS2.p5.3.m3.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p5.3.m3.2.2.2.2" xref="S7.SS2.p5.3.m3.2.2.2.2.cmml">
         <mi id="S7.SS2.p5.3.m3.2.2.2.2.2" xref="S7.SS2.p5.3.m3.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p5.3.m3.2.2.2.2.1" xref="S7.SS2.p5.3.m3.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.3.m3.2.2.2.2.3" xref="S7.SS2.p5.3.m3.2.2.2.2.3.cmml">
          .03
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p5.3.m3.2b">
        <apply id="S7.SS2.p5.3.m3.2.2.3.cmml" xref="S7.SS2.p5.3.m3.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p5.3.m3.2.2.3a.cmml" xref="S7.SS2.p5.3.m3.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p5.3.m3.1.1.1.1.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1">
          <and id="S7.SS2.p5.3.m3.1.1.1.1a.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1">
          </and>
          <apply id="S7.SS2.p5.3.m3.1.1.1.1b.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1">
           <eq id="S7.SS2.p5.3.m3.1.1.1.1.3.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p5.3.m3.1.1.1.1.2.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p5.3.m3.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p5.3.m3.1.1.1.1.4">
            6.5
           </cn>
          </apply>
          <apply id="S7.SS2.p5.3.m3.1.1.1.1c.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1">
           <gt id="S7.SS2.p5.3.m3.1.1.1.1.5.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p5.3.m3.1.1.1.1.4.cmml" id="S7.SS2.p5.3.m3.1.1.1.1d.cmml" xref="S7.SS2.p5.3.m3.1.1.1.1">
           </share>
           <cn id="S7.SS2.p5.3.m3.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p5.3.m3.1.1.1.1.6">
            5.3
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p5.3.m3.2.2.2.2.cmml" xref="S7.SS2.p5.3.m3.2.2.2.2">
          <eq id="S7.SS2.p5.3.m3.2.2.2.2.1.cmml" xref="S7.SS2.p5.3.m3.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p5.3.m3.2.2.2.2.2.cmml" xref="S7.SS2.p5.3.m3.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p5.3.m3.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p5.3.m3.2.2.2.2.3">
           .03
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p5.3.m3.2c">
        \mu=6.5&gt;5.3,p=.03
       </annotation>
      </semantics>
     </math>
     ; Task 2:
     <math alttext="\mu=5.8&gt;4.3,p=.035" class="ltx_Math" display="inline" id="S7.SS2.p5.4.m4.2">
      <semantics id="S7.SS2.p5.4.m4.2a">
       <mrow id="S7.SS2.p5.4.m4.2.2.2" xref="S7.SS2.p5.4.m4.2.2.3.cmml">
        <mrow id="S7.SS2.p5.4.m4.1.1.1.1" xref="S7.SS2.p5.4.m4.1.1.1.1.cmml">
         <mi id="S7.SS2.p5.4.m4.1.1.1.1.2" xref="S7.SS2.p5.4.m4.1.1.1.1.2.cmml">
          μ
         </mi>
         <mo id="S7.SS2.p5.4.m4.1.1.1.1.3" xref="S7.SS2.p5.4.m4.1.1.1.1.3.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.4.m4.1.1.1.1.4" xref="S7.SS2.p5.4.m4.1.1.1.1.4.cmml">
          5.8
         </mn>
         <mo id="S7.SS2.p5.4.m4.1.1.1.1.5" xref="S7.SS2.p5.4.m4.1.1.1.1.5.cmml">
          &gt;
         </mo>
         <mn id="S7.SS2.p5.4.m4.1.1.1.1.6" xref="S7.SS2.p5.4.m4.1.1.1.1.6.cmml">
          4.3
         </mn>
        </mrow>
        <mo id="S7.SS2.p5.4.m4.2.2.2.3" xref="S7.SS2.p5.4.m4.2.2.3a.cmml">
         ,
        </mo>
        <mrow id="S7.SS2.p5.4.m4.2.2.2.2" xref="S7.SS2.p5.4.m4.2.2.2.2.cmml">
         <mi id="S7.SS2.p5.4.m4.2.2.2.2.2" xref="S7.SS2.p5.4.m4.2.2.2.2.2.cmml">
          p
         </mi>
         <mo id="S7.SS2.p5.4.m4.2.2.2.2.1" xref="S7.SS2.p5.4.m4.2.2.2.2.1.cmml">
          =
         </mo>
         <mn id="S7.SS2.p5.4.m4.2.2.2.2.3" xref="S7.SS2.p5.4.m4.2.2.2.2.3.cmml">
          .035
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S7.SS2.p5.4.m4.2b">
        <apply id="S7.SS2.p5.4.m4.2.2.3.cmml" xref="S7.SS2.p5.4.m4.2.2.2">
         <csymbol cd="ambiguous" id="S7.SS2.p5.4.m4.2.2.3a.cmml" xref="S7.SS2.p5.4.m4.2.2.2.3">
          formulae-sequence
         </csymbol>
         <apply id="S7.SS2.p5.4.m4.1.1.1.1.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1">
          <and id="S7.SS2.p5.4.m4.1.1.1.1a.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1">
          </and>
          <apply id="S7.SS2.p5.4.m4.1.1.1.1b.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1">
           <eq id="S7.SS2.p5.4.m4.1.1.1.1.3.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1.3">
           </eq>
           <ci id="S7.SS2.p5.4.m4.1.1.1.1.2.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1.2">
            𝜇
           </ci>
           <cn id="S7.SS2.p5.4.m4.1.1.1.1.4.cmml" type="float" xref="S7.SS2.p5.4.m4.1.1.1.1.4">
            5.8
           </cn>
          </apply>
          <apply id="S7.SS2.p5.4.m4.1.1.1.1c.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1">
           <gt id="S7.SS2.p5.4.m4.1.1.1.1.5.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1.5">
           </gt>
           <share href="#S7.SS2.p5.4.m4.1.1.1.1.4.cmml" id="S7.SS2.p5.4.m4.1.1.1.1d.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1">
           </share>
           <cn id="S7.SS2.p5.4.m4.1.1.1.1.6.cmml" type="float" xref="S7.SS2.p5.4.m4.1.1.1.1.6">
            4.3
           </cn>
          </apply>
         </apply>
         <apply id="S7.SS2.p5.4.m4.2.2.2.2.cmml" xref="S7.SS2.p5.4.m4.2.2.2.2">
          <eq id="S7.SS2.p5.4.m4.2.2.2.2.1.cmml" xref="S7.SS2.p5.4.m4.2.2.2.2.1">
          </eq>
          <ci id="S7.SS2.p5.4.m4.2.2.2.2.2.cmml" xref="S7.SS2.p5.4.m4.2.2.2.2.2">
           𝑝
          </ci>
          <cn id="S7.SS2.p5.4.m4.2.2.2.2.3.cmml" type="float" xref="S7.SS2.p5.4.m4.2.2.2.2.3">
           .035
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S7.SS2.p5.4.m4.2c">
        \mu=5.8&gt;4.3,p=.035
       </annotation>
      </semantics>
     </math>
     ) than
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p5.4.2">
      Baseline
     </em>
     . During the experiments, we constantly noticed that many participants would check the
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p5.4.3">
      Insight Minimap
     </em>
     or
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p5.4.4">
      Topic Canvas
     </em>
     before posing their next analytic intent. Consequently, these observed significant differences implied participants’ tendency to analyze more comprehensively when explicitly presenting the discovered insights organized across data and semantic dimensions.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p6">
    <p class="ltx_p" id="S7.SS2.p6.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS2.p6.1.1">
      Feature Effectiveness.
     </span>
     Overall, the features of
     <span class="ltx_ERROR undefined" id="S7.SS2.p6.1.2">
      \name
     </span>
     received positive feedback from most participants.
Firstly, the
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.3">
      Insight Details
     </em>
     (Q1) was appreciated by participants for allowing them to
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.4">
      ‘quickly obtain an insight summary without manually reading every piece of messages’
     </em>
     (P5, P7). Also, the associated insight evidence such as code snippets eliminated their need to
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.5">
      ‘scroll back to check that specific line of code for data transformation’
     </em>
     (P6) to ensure relevance and correctness.
Secondly, the
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.6">
      Insight Gallery
     </em>
     (Q2) helped participants review related insights conveniently. P8 found it particularly useful for
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.7">
      ‘understanding relationships between attributes when dealing with multiple similar insights’
     </em>
     , while P3 likened it to
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.8">
      ‘a menu tool’
     </em>
     that enabled him to review different visualization types for similar insights. However, some participants found it less beneficial (P2, P4) due to the rather short analysis time.
Thirdly, the
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.9">
      Insight Minimap
     </em>
     (Q3) was constantly praised by most participants (8/12) as
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.10">
      ‘the most useful feature’
     </em>
     (P1).
P9 described it as
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.11">
      ‘being very innovative and reminded him of the minimap in VS Code’
     </em>
     , while others favored its
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.12">
      ‘clear presentation of covered data attributes’
     </em>
     (P2, P4, P7, P12) and
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.13">
      ‘color encodings to reveal topic changes’
     </em>
     (P5). This made the analysis process
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.14">
      ‘more structured and thorough’
     </em>
     (P11). Additionally, the interestingness bars enabled participants to discard trivial insights. For example, P4 identified an insight with an extremely low interestingness score about a negligible attribute relationship
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.15">
      ‘caused by an accidental query’
     </em>
     .
Finally, the
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.16">
      Topic Canvas
     </em>
     (Q4) reduced participants’ manual and cognitive effort to organize insights. The generated topics were reported as
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.17">
      ‘being reasonable and intuitive’
     </em>
     that
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.18">
      ‘decreased the chaos of the overwhelming conversation’
     </em>
     (P10).
Moreover, viewing the tree-based topic structure gave P3 a sense of
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.19">
      ‘solving the open-ended task from various angles’
     </em>
     - aiding comprehensive thinking - though some preferred relying on personal judgment rather than
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p6.1.20">
      ‘being disturbed by the organized topics’
     </em>
     (P5).
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p7">
    <p class="ltx_p" id="S7.SS2.p7.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS2.p7.1.1">
      System Usability.
     </span>
     All participants agreed that
     <span class="ltx_ERROR undefined" id="S7.SS2.p7.1.2">
      \name
     </span>
     was easy to learn (Q5) and use (Q6), and were willing to integrate the system into their daily workflow (Q7). The visual designs and interfaces were described as
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p7.1.3">
      ‘very intuitive and user-friendly’
     </em>
     (P3, P7) without
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p7.1.4">
      ‘causing steep learning curves’
     </em>
     (P1). As stated by P9, the views looked so natural that
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p7.1.5">
      ‘it should be easy for any professionals to understand its main features at first glance’
     </em>
     . Meanwhile, participants also noted some potential improvements for
     <span class="ltx_ERROR undefined" id="S7.SS2.p7.1.6">
      \name
     </span>
     . For example, P4 complained about LLMs’ instability in analyzing complex problems, and P11 expected to
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p7.1.7">
      ‘combine certain insights for more in-depth analysis’
     </em>
     .
    </p>
   </div>
   <div class="ltx_para" id="S7.SS2.p8">
    <p class="ltx_p" id="S7.SS2.p8.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS2.p8.1.1">
      Impact on Data Analysis.
     </span>
     We investigated
     <span class="ltx_ERROR undefined" id="S7.SS2.p8.1.2">
      \name
     </span>
     ’s impact on the overall workflow of LLM-powered data analysis in terms of fluidity, workload, and understanding. Firstly, participants agreed that the system was unobtrusive and did not disrupt the conversational interaction (Q8). P9 commented that
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p8.1.3">
      ‘he just chatted with LLMs as usual, and the views would automatically update without any interference’
     </em>
     , while P7 thought
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p8.1.4">
      ‘the system was like a chat interface augmented with useful plugins’
     </em>
     . Secondly, participants’ manual and cognitive overload could be mitigated by using
     <span class="ltx_ERROR undefined" id="S7.SS2.p8.1.5">
      \name
     </span>
     (Q9). The offered features alleviated the effort for
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p8.1.6">
      ‘excessive scrolling now and then’
     </em>
     (P2) and
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p8.1.7">
      ‘memorizing all insights in mind’
     </em>
     (P12). Moreover, organizing insights on the fly helped participants
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p8.1.8">
      ‘focus more on the analysis itself rather than constant context switching’
     </em>
     (P10). Finally,
     <span class="ltx_ERROR undefined" id="S7.SS2.p8.1.9">
      \name
     </span>
     could improve participants’ understanding of the analyses generated by LLMs (Q10). P6 stated that
     <em class="ltx_emph ltx_font_italic" id="S7.SS2.p8.1.10">
      ‘it felt like she was participating more in the analysis process by inspecting the changes in different views to capture what was going on, instead of merely inputting a query and waiting for LLMs to handle everything’
     </em>
     . In other words,
     <span class="ltx_ERROR undefined" id="S7.SS2.p8.1.11">
      \name
     </span>
     helped strike a balance between automation and human agency, thereby increasing users’ understanding and trust during LLM-powered data analysis.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.3
    </span>
    Observed Behaviors
   </h3>
   <div class="ltx_para" id="S7.SS3.p1">
    <p class="ltx_p" id="S7.SS3.p1.1">
     We observed two prominent workflow patterns adopted by different participants when using
     <span class="ltx_ERROR undefined" id="S7.SS3.p1.1.1">
      \name
     </span>
     for data analysis.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS3.p2">
    <p class="ltx_p" id="S7.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS3.p2.1.1">
      User-Initiated Workflow.
     </span>
     Participants with a clear analysis goal often posed analytic intents sequentially based on their own judgment and preferences, without being excessively intervened by the system. For example, P5 explored the colleges dataset centering around the ownership and its influence on factors such as student quality and financial condition. In such cases, the
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p2.1.2">
      Insight Minimap
     </em>
     and
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p2.1.3">
      Topic Canvas
     </em>
     primarily served as a structured and organized way for reviewing previous insights rather than inspiring new discoveries. Notably, the construction of the topic tree predominantly progressed from
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p2.1.4">
      bottom
     </em>
     (insights) to
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p2.1.5">
      top
     </em>
     (analytic topics) with much more subtopics than main topics, which revealed a depth-oriented exploration pattern.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS3.p3">
    <p class="ltx_p" id="S7.SS3.p3.1">
     <span class="ltx_text ltx_font_bold" id="S7.SS3.p3.1.1">
      System-Initiated Workflow.
     </span>
     Participants without a specific aim (potentially due to their unfamiliarity with the analysis domain), on the other hand, commonly posed multiple random analytic intents at first to
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p3.1.2">
      ‘make a draft’
     </em>
     (P1). Then, they would inspect the
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p3.1.3">
      Insight Minimap
     </em>
     and
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p3.1.4">
      Topic Canvas
     </em>
     to gain an overview of their analyses and observe potential biases (
     <span class="ltx_text ltx_font_italic" id="S7.SS3.p3.1.5">
      e.g.
     </span>
     , certain attributes/topics may have been thoroughly explored while others remain overlooked) to determine their future explorations. Therefore, the construction of the topic tree was now from
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p3.1.6">
      top
     </em>
     to
     <em class="ltx_emph ltx_font_italic" id="S7.SS3.p3.1.7">
      bottom
     </em>
     with many topics scattered around and very few subtopics, which demonstrated a breadth-oriented exploration pattern.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S8">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    8
   </span>
   Discussion
  </h2>
  <div class="ltx_para" id="S8.p1">
   <p class="ltx_p" id="S8.p1.1">
    In this section, we reflect on our work and discuss its implications for designing human-LLM interfaces in data analysis, along with its limitations and potential future research directions.
   </p>
  </div>
  <section class="ltx_subsection" id="S8.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     8.1
    </span>
    Design Implications
   </h3>
   <div class="ltx_para" id="S8.SS1.p1">
    <p class="ltx_p" id="S8.SS1.p1.1">
     <span class="ltx_text ltx_font_bold" id="S8.SS1.p1.1.1">
      Integrate data and semantic context for enhanced understanding.
     </span>
     Given the inherent limitations of the linear chat-based interfaces, managing LLMs’ conversational contexts for complex information tasks has emerged as a popular research topic in both VIS and HCI commnities
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib29" title="">
       29
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib63" title="">
       63
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib34" title="">
       34
      </a>
      ]
     </cite>
     . Going beyond existing work that primarily focuses on extracting the semantic structures of conversational utterances,
     <span class="ltx_ERROR undefined" id="S8.SS1.p1.1.2">
      \name
     </span>
     further integrates data context - an important factor of data analysis - including data attributes and analytical actions. We visualize the ever-changing data and semantic context simultaneously in a minimap, allowing users to quickly gain an overall understanding of the analysis process. Our user study indicates that such integration not only facilitates reviewing and navigation of different data insights, but also potentially expands data analysts’ data and analytic coverage, leading to more comprehensive results during exploratory data analysis.
    </p>
   </div>
   <div class="ltx_para" id="S8.SS1.p2">
    <p class="ltx_p" id="S8.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S8.SS1.p2.1.1">
      Provide follow-up analytic guidance for data exploration.
     </span>
     In our user study, many participants (6/12) suggested incorporating query recommendations during analysis, especially when they faced an unfamiliar dataset (
     <span class="ltx_text ltx_font_italic" id="S8.SS1.p2.1.2">
      i.e.
     </span>
     , the
     <em class="ltx_emph ltx_font_italic" id="S8.SS1.p2.1.3">
      ‘cold start’
     </em>
     issue). Providing analytic guidance has been extensively explored in previous literature
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib68" title="">
       68
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib59" title="">
       59
      </a>
      ]
     </cite>
     , which can further be improved with LLMs’ extraordinary capabilities
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib20" title="">
       20
      </a>
      ]
     </cite>
     . Meanwhile,
     <span class="ltx_ERROR undefined" id="S8.SS1.p2.1.4">
      \name
     </span>
     ’s support for organizing insights on the fly can establish a robust foundation to inform context-aware assistance. For example, we can integrate another LLM-based agent into our framework, which receives analysts’ background and goals as well as their current focused analytic topics and data attributes, and then generates appropriate suggestions to deepen or broaden their analyses.
    </p>
   </div>
   <div class="ltx_para" id="S8.SS1.p3">
    <p class="ltx_p" id="S8.SS1.p3.1">
     <span class="ltx_text ltx_font_bold" id="S8.SS1.p3.1.1">
      Balance between the flexibility and complexity of interaction paradigms.
     </span>
     The fundamental principle guiding our visual and interaction design is to maintain the conversational workflow, where the primary interaction modality is through natural language. Nevertheless, we admit the potential of leveraging other modalities or paradigms for NLI-based data analysis systems (
     <span class="ltx_text ltx_font_italic" id="S8.SS1.p3.1.2">
      e.g.
     </span>
     , direct manipulations
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib60" title="">
       60
      </a>
      ]
     </cite>
     and sticky cells
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib71" title="">
       71
      </a>
      ]
     </cite>
     ). One of the participants in our user study expected to modify the
     <em class="ltx_emph ltx_font_italic" id="S8.SS1.p3.1.3">
      Topic Canvas
     </em>
     by directly adding or editing nodes, similar to the operations in a mind map. Although such features could improve the flexibility of interaction with LLMs (which have been validated in many node-based LLM interfaces
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib63" title="">
       63
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib3" title="">
       3
      </a>
      ]
     </cite>
     ), they may also introduce increased complexity and steep learning curves
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib32" title="">
       32
      </a>
      ]
     </cite>
     . Therefore, we aim to achieve a trade-off between NLIs’ intuitiveness and visualizations’ expressiveness. Future research could further explore how to balance these two aspects in designing interaction paradigms for LLMs.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S8.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     8.2
    </span>
    Limitations and Future Work
   </h3>
   <div class="ltx_para" id="S8.SS2.p1">
    <p class="ltx_p" id="S8.SS2.p1.1">
     <span class="ltx_text ltx_font_bold" id="S8.SS2.p1.1.1">
      Scalability.
     </span>
     Our framework can theoretically support larger and more complex datasets without any limitations. To reduce the potential visual clutter in the
     <em class="ltx_emph ltx_font_italic" id="S8.SS2.p1.1.2">
      Insight Minimap
     </em>
     and
     <em class="ltx_emph ltx_font_italic" id="S8.SS2.p1.1.3">
      Topic Canvas
     </em>
     when very large numbers of data attributes or analytic topics are involved, we can employ graph visualization techniques such as fisheye
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib70" title="">
       70
      </a>
      ]
     </cite>
     , edge bundling
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib48" title="">
       48
      </a>
      ]
     </cite>
     , and semantic zoom
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib62" title="">
       62
      </a>
      ]
     </cite>
     , which we leave for future work.
    </p>
   </div>
   <div class="ltx_para" id="S8.SS2.p2">
    <p class="ltx_p" id="S8.SS2.p2.1">
     <span class="ltx_text ltx_font_bold" id="S8.SS2.p2.1.1">
      Potentiality.
     </span>
     Incorporating LLMs into data analysis is an emerging but promising paradigm. With LLMs’ rapidly growing reasoning capabilities and extended context windows
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib6" title="">
       6
      </a>
      ]
     </cite>
     , data analysts can potentially be able to conduct longer and more in-depth analysis on intricate datasets with the help of intelligent
     <em class="ltx_emph ltx_font_italic" id="S8.SS2.p2.1.2">
      data copilots
     </em>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib76" title="">
       76
      </a>
      ]
     </cite>
     . Such envisions further emphasize the necessity of developing smart strategies to manage the complex conversational contexts during analysis. Therefore, we believe that our work could inspire future research in leveraging visualizations and other enhanced interaction techniques to make LLM-powered data analysis more streamlined, accessible, and productive.
    </p>
   </div>
   <div class="ltx_para" id="S8.SS2.p3">
    <p class="ltx_p" id="S8.SS2.p3.1">
     <span class="ltx_text ltx_font_bold" id="S8.SS2.p3.1.1">
      Generalizability.
     </span>
     While
     <span class="ltx_ERROR undefined" id="S8.SS2.p3.1.2">
      \name
     </span>
     is tailored to conversational data analysis, the design principles can be generalized to other usage scenarios of LLMs. For example, participants in our user study highly appreciated the
     <em class="ltx_emph ltx_font_italic" id="S8.SS2.p3.1.3">
      Insight Minimap
     </em>
     , whose fundamental idea is to chronologically display the entire conversation based on the visual abstraction of some domain-specific atomic units (a
     <em class="ltx_emph ltx_font_italic" id="S8.SS2.p3.1.4">
      data insight
     </em>
     in our case). Future work could adopt this minimap-based design in various applications (
     <span class="ltx_text ltx_font_italic" id="S8.SS2.p3.1.5">
      e.g.
     </span>
     , conversational text-to-image generation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib17" title="">
       17
      </a>
      ]
     </cite>
     ) with pre-defined units of each conversation cycle. Moreover, exploring the linear conversation in a non-linear, tree-based manner similar to the
     <em class="ltx_emph ltx_font_italic" id="S8.SS2.p3.1.6">
      Topic Canvas
     </em>
     is a promising paradigm worthy of further investigation in other creativity-driven processes (
     <span class="ltx_text ltx_font_italic" id="S8.SS2.p3.1.7">
      e.g.
     </span>
     , story writing
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib75" title="">
       75
      </a>
      ]
     </cite>
     ).
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S9">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    9
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S9.p1">
   <p class="ltx_p" id="S9.p1.1">
    This work presents
    <span class="ltx_ERROR undefined" id="S9.p1.1.1">
     \name
    </span>
    , an interactive system that visualizes the complex conversational contexts during LLM-powered data analysis to facilitate efficient insight discovery and exploration. Built upon an LLM-based multi-agent framework that streamlines the process of extracting, associating, and organizing insights in analytic conversations,
    <span class="ltx_ERROR undefined" id="S9.p1.1.2">
     \name
    </span>
    provides a set of interactive visualizations to enable multi-level and multi-faceted exploration. A technical evaluation and a user study demonstrate the effectiveness of our framework and system.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2303.08774" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2303 . 08774
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     K. Affolter, K. Stockinger, and A. Bernstein.
    </span>
    <span class="ltx_bibblock">
     A comparative survey of recent natural language interfaces for databases.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">
      VLDB J.
     </span>
     , 28:793–819, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1007/S00778-019-00567-8" target="_blank" title="">
      doi: 10 . 1007/S00778-019-00567-8
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     T. Angert, M. Suzara, J. Han, C. Pondoc, and H. Subramonyam.
    </span>
    <span class="ltx_bibblock">
     Spellburst: A node-based interface for exploratory creative coding with natural language prompts.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">
      Proc. UIST
     </span>
     . ACM, New York, NY, USA, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3586183.3606719" target="_blank" title="">
      doi: 10 . 1145/3586183 . 3606719
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     J. Berant, D. Deutch, A. Globerson, T. Milo, and T. Wolfson.
    </span>
    <span class="ltx_bibblock">
     Explaining queries over web tables to non-experts.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">
      ICDE
     </span>
     , pp. 1570–1573, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ICDE.2019.00144" target="_blank" title="">
      doi: 10 . 1109/ICDE . 2019 . 00144
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     M. Chakhchoukh, N. Boukhelifa, and A. Bezerianos.
    </span>
    <span class="ltx_bibblock">
     Understanding how in-visualization provenance can support trade-off analysis.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 29(9):3758–3774, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2022.3171074" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2022 . 3171074
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     S. Chen, S. Wong, L. Chen, and Y. Tian.
    </span>
    <span class="ltx_bibblock">
     Extending context window of large language models via positional interpolation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2306.15595" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2306 . 15595
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     Y. Chen, J. Yang, and W. Ribarsky.
    </span>
    <span class="ltx_bibblock">
     Toward effective insight management in visual analytics systems.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">
      PacificVis
     </span>
     , pp. 49–56, 2009.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/PACIFICVIS.2009.4906837" target="_blank" title="">
      doi: 10 . 1109/PACIFICVIS . 2009 . 4906837
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     Z. Chen and H. Xia.
    </span>
    <span class="ltx_bibblock">
     Crossdata: Leveraging text-data connections for authoring data documents.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">
      Proc. CHI
     </span>
     . ACM, New York, NY, USA, 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3491102.3517485" target="_blank" title="">
      doi: 10 . 1145/3491102 . 3517485
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     Z. Cheng, T. Xie, P. Shi, C. Li, R. Nadkarni, Y. Hu, C. Xiong, D. Radev, M. Ostendorf, L. Zettlemoyer, N. A. Smith, and T. Yu.
    </span>
    <span class="ltx_bibblock">
     Binding language models in symbolic languages.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">
      ICLR
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2210.02875" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2210 . 02875
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     C.-H. Chiang and H.-y. Lee.
    </span>
    <span class="ltx_bibblock">
     Can large language models be an alternative to human evaluations?
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">
      Proc. ACL
     </span>
     , pp. 15607–15631. ACL, Toronto, Canada, July 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.870" target="_blank" title="">
      doi: 10 . 18653/v1/2023 . acl-long . 870
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     B. Chopra, A. Singha, A. Fariha, S. Gulwani, C. Parnin, A. Tiwari, and A. Z. Henley.
    </span>
    <span class="ltx_bibblock">
     Conversational challenges in ai-powered data science: Obstacles, needs, and design opportunities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2310.16164" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2310 . 16164
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     K. Cox, R. E. Grinter, S. L. Hibino, L. J. Jagadeesan, and D. Mantilla.
    </span>
    <span class="ltx_bibblock">
     A multi-modal natural language interface to an information visualization environment.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">
      International Journal of Speech Technology
     </span>
     , 4:297–314, 2001.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1023/A%3A1011368926479" target="_blank" title="">
      doi: 10 . 1023/A%3A1011368926479
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     R. Ding, S. Han, Y. Xu, H. Zhang, and D. Zhang.
    </span>
    <span class="ltx_bibblock">
     Quickinsights: Quick and automatic discovery of insights from multi-dimensional data.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">
      Proc. SIGMOD
     </span>
     , p. 317–332. ACM, New York, NY, USA, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3299869.3314037" target="_blank" title="">
      doi: 10 . 1145/3299869 . 3314037
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     M. Dubey, S. Dasgupta, A. Sharma, K. Höffner, and J. Lehmann.
    </span>
    <span class="ltx_bibblock">
     Asknow: A framework for natural language query formalization in sparql.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">
      Proc. International Conference on The Semantic Web
     </span>
     , p. 300–316. Springer, Berlin, Heidelberg, 2016.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1007/978-3-319-34129-3_19" target="_blank" title="">
      doi: 10 . 1007/978-3-319-34129-3_19
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     W. Epperson, V. Gorantla, D. Moritz, and A. Perer.
    </span>
    <span class="ltx_bibblock">
     Dead or alive: Continuous data profiling for interactive data science.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 30(1):197–207, 2024.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2023.3327367" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2023 . 3327367
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     Y. Feng, X. Wang, B. Pan, K. K. Wong, Y. Ren, S. Liu, Z. Yan, Y. Ma, H. Qu, and W. Chen.
    </span>
    <span class="ltx_bibblock">
     Xnli: Explaining and diagnosing nli-based visual data analysis.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , pp. 1–14, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2023.3240003" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2023 . 3240003
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, and W. Chen.
    </span>
    <span class="ltx_bibblock">
     Promptmagician: Interactive prompt engineering for text-to-image creation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 30(1):295–305, 2024.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2023.3327168" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2023 . 3327168
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     T. Gao, M. Dontcheva, E. Adar, Z. Liu, and K. G. Karahalios.
    </span>
    <span class="ltx_bibblock">
     Datatone: Managing ambiguity in natural language interfaces for data visualization.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">
      Proc. UIST
     </span>
     , p. 489–500. ACM, New York, NY, USA, 2015.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2807442.2807478" target="_blank" title="">
      doi: 10 . 1145/2807442 . 2807478
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     D. Gotz and M. X. Zhou.
    </span>
    <span class="ltx_bibblock">
     Characterizing users’ visual analytic activity for insight provenance.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">
      IEEE VAST
     </span>
     , pp. 123–130, 2008.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/VAST.2008.4677365" target="_blank" title="">
      doi: 10 . 1109/VAST . 2008 . 4677365
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     K. Gu, M. Grunde-McLaughlin, A. M. McNutt, J. Heer, and T. Althoff.
    </span>
    <span class="ltx_bibblock">
     How do data analysts respond to ai assistance? a wizard-of-oz study.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.10108" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2309 . 10108
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     K. Gu, R. Shang, T. Althoff, C. Wang, and S. M. Drucker.
    </span>
    <span class="ltx_bibblock">
     How do analysts understand and verify ai-assisted data analyses?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.10947" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2309 . 10947
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     J. Guo, Z. Zhan, Y. Gao, Y. Xiao, J.-G. Lou, T. Liu, and D. Zhang.
    </span>
    <span class="ltx_bibblock">
     Towards complex text-to-SQL in cross-domain database with intermediate representation.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">
      Proc. ACL
     </span>
     , pp. 4524–4535. ACL, Florence, Italy, July 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P19-1444" target="_blank" title="">
      doi: 10 . 18653/v1/P19-1444
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     M. Hearst and M. Tory.
    </span>
    <span class="ltx_bibblock">
     Would you like a chart with that? incorporating visualizations into conversational interfaces.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">
      IEEE VIS
     </span>
     , pp. 1–5, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/VISUAL.2019.8933766" target="_blank" title="">
      doi: 10 . 1109/VISUAL . 2019 . 8933766
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     M.-H. Hong and A. Crisan.
    </span>
    <span class="ltx_bibblock">
     Conversational ai threads for visualizing multidimensional datasets.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2311.05590" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2311 . 05590
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     E. Hoque, V. Setlur, M. Tory, and I. Dykeman.
    </span>
    <span class="ltx_bibblock">
     Applying pragmatics principles for interaction with visual analytics.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 24(1):309–318, 2018.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2017.2744684" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2017 . 2744684
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     M. N. Hoque, T. Mashiat, B. Ghai, C. Shelton, F. Chevalier, K. Kraus, and N. Elmqvist.
    </span>
    <span class="ltx_bibblock">
     The hallmark effect: Supporting provenance and transparent use of large language models in writing with interactive visualization.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">
      arXiv
     </span>
     , 2024.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2311.13057" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2311 . 13057
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     Z. Huang, S. Gutierrez, H. Kamana, and S. Macneil.
    </span>
    <span class="ltx_bibblock">
     Memory sandbox: Transparent and interactive memory management for conversational agents.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">
      Proc. UIST
     </span>
     . ACM, New York, NY, USA, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3586182.3615796" target="_blank" title="">
      doi: 10 . 1145/3586182 . 3615796
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     R. C. A. Iacob, F. Brad, E.-S. Apostol, C.-O. Truică, I. A. Hosu, and T. Rebedea.
    </span>
    <span class="ltx_bibblock">
     Neural approaches for natural language interfaces to databases: A survey.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">
      Proc. COLING
     </span>
     , pp. 381–395. International Committee on Computational Linguistics, Barcelona, Spain (Online), Dec. 2020.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.coling-main.34" target="_blank" title="">
      doi: 10 . 18653/v1/2020 . coling-main . 34
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     P. Jiang, J. Rayan, S. P. Dow, and H. Xia.
    </span>
    <span class="ltx_bibblock">
     Graphologue: Exploring large language model responses with interactive diagrams.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">
      Proc. UIST
     </span>
     . ACM, New York, NY, USA, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3586183.3606737" target="_blank" title="">
      doi: 10 . 1145/3586183 . 3606737
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     A. Kamath and R. Das.
    </span>
    <span class="ltx_bibblock">
     A survey on semantic parsing.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">
      arXiv
     </span>
     , 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.1812.00978" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 1812 . 00978
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     M. B. Kery, B. E. John, P. O’Flaherty, A. Horvath, and B. A. Myers.
    </span>
    <span class="ltx_bibblock">
     Towards effective foraging by data scientists to find past analysis choices.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">
      Proc. CHI
     </span>
     , p. 1–13. ACM, New York, NY, USA, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3290605.3300322" target="_blank" title="">
      doi: 10 . 1145/3290605 . 3300322
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     S. Lallé, D. Toker, C. Conati, and G. Carenini.
    </span>
    <span class="ltx_bibblock">
     Prediction of users’ learning curves for adaptation while using an information visualization.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">
      Proc. IUI
     </span>
     , p. 357–368. ACM, New York, NY, USA, 2015.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2678025.2701376" target="_blank" title="">
      doi: 10 . 1145/2678025 . 2701376
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     Q. Li, H. Lin, C. F. Tang, X. Wei, Z. Peng, X. Ma, and T. Chen.
    </span>
    <span class="ltx_bibblock">
     Exploring the "double-edged sword" effect of auto-insight recommendation in exploratory data analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">
      Proc. IUI Workshop
     </span>
     , CEUR Workshop Proceedings, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     P. Liang, D. Ye, Z. Zhu, Y. Wang, W. Xia, R. Liang, and G. Sun.
    </span>
    <span class="ltx_bibblock">
     C5: Towards better conversation comprehension and contextual continuity for chatgpt.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.10108" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2309 . 10108
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_tag_bibitem">
     [35]
    </span>
    <span class="ltx_bibblock">
     Y. Lin, H. Li, L. Yang, A. Wu, and H. Qu.
    </span>
    <span class="ltx_bibblock">
     Inksight: Leveraging sketch interaction for documenting chart findings in computational notebooks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 30(1):944–954, 2024.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2023.3327170" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2023 . 3327170
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_tag_bibitem">
     [36]
    </span>
    <span class="ltx_bibblock">
     S.-C. Liu, S. Wang, T. Chang, W. Lin, C.-W. Hsiung, Y.-C. Hsieh, Y.-P. Cheng, S.-H. Luo, and J. Zhang.
    </span>
    <span class="ltx_bibblock">
     JarviX: A LLM no code platform for tabular data analysis and optimization.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">
      Proc. EMNLP
     </span>
     , pp. 622–630. ACL, Singapore, Dec. 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-industry.59" target="_blank" title="">
      doi: 10 . 18653/v1/2023 . emnlp-industry . 59
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_tag_bibitem">
     [37]
    </span>
    <span class="ltx_bibblock">
     Y. Liu, Z. Wen, L. Weng, O. Woodman, Y. Yang, and W. Chen.
    </span>
    <span class="ltx_bibblock">
     Sprout: Authoring programming tutorials with interactive visualization of large language model generation process.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2312.01801" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2312 . 01801
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_tag_bibitem">
     [38]
    </span>
    <span class="ltx_bibblock">
     J. Lu, B. Pan, J. Chen, Y. Feng, J. Hu, Y. Peng, and W. Chen.
    </span>
    <span class="ltx_bibblock">
     Agentlens: Visual analysis for agent behaviors in llm-based autonomous systems.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">
      arXiv
     </span>
     , 2024.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2402.08995" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2402 . 08995
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_tag_bibitem">
     [39]
    </span>
    <span class="ltx_bibblock">
     T. Luciani, A. Burks, C. Sugiyama, J. Komperda, and G. E. Marai.
    </span>
    <span class="ltx_bibblock">
     Details-first, show context, overview last: Supporting exploration of viscous fingers in large-scale ensemble simulations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 25(1):1225–1235, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2018.2864849" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2018 . 2864849
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_tag_bibitem">
     [40]
    </span>
    <span class="ltx_bibblock">
     P. Ma, R. Ding, S. Wang, S. Han, and D. Zhang.
    </span>
    <span class="ltx_bibblock">
     InsightPilot: An LLM-empowered automated data exploration system.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">
      Proc. EMNLP
     </span>
     , pp. 346–352. ACL, Singapore, Dec. 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-demo.31" target="_blank" title="">
      doi: 10 . 18653/v1/2023 . emnlp-demo . 31
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_tag_bibitem">
     [41]
    </span>
    <span class="ltx_bibblock">
     K. Madanagopal, E. D. Ragan, and P. Benjamin.
    </span>
    <span class="ltx_bibblock">
     Analytic provenance in practice: The role of provenance in real-world visualization and data analysis environments.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">
      IEEE Computer Graphics and Applications
     </span>
     , 39(6):30–45, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/MCG.2019.2933419" target="_blank" title="">
      doi: 10 . 1109/MCG . 2019 . 2933419
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_tag_bibitem">
     [42]
    </span>
    <span class="ltx_bibblock">
     A. M. Mcnutt, C. Wang, R. A. Deline, and S. M. Drucker.
    </span>
    <span class="ltx_bibblock">
     On the design of ai-powered code assistants for notebooks.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">
      Proc. CHI
     </span>
     . ACM, New York, NY, USA, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3544548.3580940" target="_blank" title="">
      doi: 10 . 1145/3544548 . 3580940
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_tag_bibitem">
     [43]
    </span>
    <span class="ltx_bibblock">
     A. Narechania, A. Coscia, E. Wall, and A. Endert.
    </span>
    <span class="ltx_bibblock">
     Lumos: Increasing awareness of analytic behavior during visual data analysis.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 28(1):1009–1018, 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2021.3114827" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2021 . 3114827
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_tag_bibitem">
     [44]
    </span>
    <span class="ltx_bibblock">
     A. Narechania, A. Fourney, B. Lee, and G. Ramos.
    </span>
    <span class="ltx_bibblock">
     Diy: Assessing the correctness of natural language to sql systems.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">
      Proc. IUI
     </span>
     , p. 597–607. ACM, New York, NY, USA, 2021.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3397481.3450667" target="_blank" title="">
      doi: 10 . 1145/3397481 . 3450667
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_tag_bibitem">
     [45]
    </span>
    <span class="ltx_bibblock">
     A. Narechania, A. Srinivasan, and J. Stasko.
    </span>
    <span class="ltx_bibblock">
     Nl4dv: A toolkit for generating analytic specifications for data visualization from natural language queries.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 27(2):369–379, 2021.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2020.3030378" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2020 . 3030378
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_tag_bibitem">
     [46]
    </span>
    <span class="ltx_bibblock">
     P. H. Nguyen, K. Xu, A. Wheat, B. W. Wong, S. Attfield, and B. Fields.
    </span>
    <span class="ltx_bibblock">
     Sensepath: Understanding the sensemaking process through analytic provenance.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 22(1):41–50, 2016.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2015.2467611" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2015 . 2467611
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_tag_bibitem">
     [47]
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Chatgpt plugins.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/chatgpt-plugins#code-interpreter" target="_blank" title="">
      https://openai.com/blog/chatgpt-plugins#code-interpreter
     </a>
     , 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_tag_bibitem">
     [48]
    </span>
    <span class="ltx_bibblock">
     R. Pan, Z. Wang, Y. Wei, H. Gao, G. Ou, C. C. Cao, J. Xu, T. Xu, and W. Chen.
    </span>
    <span class="ltx_bibblock">
     Towards efficient visual simplification of computational graphs in deep neural networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , pp. 1–14, 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2022.3230832" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2022 . 3230832
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_tag_bibitem">
     [49]
    </span>
    <span class="ltx_bibblock">
     X. Pu, S. Kross, J. M. Hofman, and D. G. Goldstein.
    </span>
    <span class="ltx_bibblock">
     Datamations: Animated explanations of data analysis pipelines.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">
      Proc. CHI
     </span>
     . ACM, New York, NY, USA, 2021.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3411764.3445063" target="_blank" title="">
      doi: 10 . 1145/3411764 . 3445063
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_tag_bibitem">
     [50]
    </span>
    <span class="ltx_bibblock">
     E. D. Ragan, A. Endert, J. Sanyal, and J. Chen.
    </span>
    <span class="ltx_bibblock">
     Characterizing provenance in visualization and data analysis: An organizational framework of provenance types and purposes.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 22(1):31–40, 2016.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2015.2467551" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2015 . 2467551
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_tag_bibitem">
     [51]
    </span>
    <span class="ltx_bibblock">
     N. Reimers and I. Gurevych.
    </span>
    <span class="ltx_bibblock">
     Sentence-BERT: Sentence embeddings using Siamese BERT-networks.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">
      Proc. EMNLP-IJCNLP
     </span>
     , pp. 3982–3992. ACL, Hong Kong, China, Nov. 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-1410" target="_blank" title="">
      doi: 10 . 18653/v1/D19-1410
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_tag_bibitem">
     [52]
    </span>
    <span class="ltx_bibblock">
     D. Saha, A. Floratou, K. Sankaranarayanan, U. F. Minhas, A. R. Mittal, and F. Özcan.
    </span>
    <span class="ltx_bibblock">
     Athena: an ontology-driven system for natural language querying over relational data stores.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">
      Proc. VLDB Endow.
     </span>
     , 9(12):1209–1220, aug 2016.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.14778/2994509.2994536" target="_blank" title="">
      doi: 10 . 14778/2994509 . 2994536
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_tag_bibitem">
     [53]
    </span>
    <span class="ltx_bibblock">
     V. Setlur, S. E. Battersby, M. Tory, R. Gossweiler, and A. X. Chang.
    </span>
    <span class="ltx_bibblock">
     Eviza: A natural language interface for visual analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">
      Proc. UIST
     </span>
     , p. 365–377. ACM, New York, NY, USA, 2016.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2984511.2984588" target="_blank" title="">
      doi: 10 . 1145/2984511 . 2984588
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_tag_bibitem">
     [54]
    </span>
    <span class="ltx_bibblock">
     V. Setlur and M. Tory.
    </span>
    <span class="ltx_bibblock">
     How do you converse with an analytical chatbot? revisiting gricean maxims for designing analytical conversational behavior.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">
      Proc. CHI
     </span>
     . ACM, New York, NY, USA, 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3491102.3501972" target="_blank" title="">
      doi: 10 . 1145/3491102 . 3501972
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_tag_bibitem">
     [55]
    </span>
    <span class="ltx_bibblock">
     V. Setlur, M. Tory, and A. Djalali.
    </span>
    <span class="ltx_bibblock">
     Inferencing underspecified natural language utterances in visual analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">
      Proc. IUI
     </span>
     , p. 40–51. ACM, New York, NY, USA, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3301275.3302270" target="_blank" title="">
      doi: 10 . 1145/3301275 . 3302270
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_tag_bibitem">
     [56]
    </span>
    <span class="ltx_bibblock">
     L. Shen, E. Shen, Y. Luo, X. Yang, X. Hu, X. Zhang, Z. Tai, and J. Wang.
    </span>
    <span class="ltx_bibblock">
     Towards natural language interfaces for data visualization: A survey.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 29(6):3121–3144, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2022.3148007" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2022 . 3148007
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_tag_bibitem">
     [57]
    </span>
    <span class="ltx_bibblock">
     A. Srinivasan, S. M. Drucker, A. Endert, and J. Stasko.
    </span>
    <span class="ltx_bibblock">
     Augmenting visualizations with interactive data facts to facilitate interpretation and communication.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 25(1):672–681, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2018.2865145" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2018 . 2865145
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_tag_bibitem">
     [58]
    </span>
    <span class="ltx_bibblock">
     A. Srinivasan, N. Nyapathy, B. Lee, S. M. Drucker, and J. Stasko.
    </span>
    <span class="ltx_bibblock">
     Collecting and characterizing natural language utterances for specifying data visualizations.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">
      Proc. CHI
     </span>
     . ACM, New York, NY, USA, 2021.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3411764.3445400" target="_blank" title="">
      doi: 10 . 1145/3411764 . 3445400
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_tag_bibitem">
     [59]
    </span>
    <span class="ltx_bibblock">
     A. Srinivasan and V. Setlur.
    </span>
    <span class="ltx_bibblock">
     Snowy: Recommending utterances for conversational visual analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib59.1.1">
      Proc. UIST
     </span>
     , p. 864–880. ACM, New York, NY, USA, 2021.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3472749.3474792" target="_blank" title="">
      doi: 10 . 1145/3472749 . 3474792
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_tag_bibitem">
     [60]
    </span>
    <span class="ltx_bibblock">
     A. Srinivasan and J. Stasko.
    </span>
    <span class="ltx_bibblock">
     Orko: Facilitating multimodal interaction for visual exploration and analysis of networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib60.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 24(1):511–521, 2018.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2017.2745219" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2017 . 2745219
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_tag_bibitem">
     [61]
    </span>
    <span class="ltx_bibblock">
     H. Subramonyam, C. L. Pondoc, C. Seifert, M. Agrawala, and R. Pea.
    </span>
    <span class="ltx_bibblock">
     Bridging the gulf of envisioning: Cognitive design challenges in llm interfaces.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib61.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.14459" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2309 . 14459
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_tag_bibitem">
     [62]
    </span>
    <span class="ltx_bibblock">
     S. Suh, M. Chen, B. Min, T. J.-J. Li, and H. Xia.
    </span>
    <span class="ltx_bibblock">
     Structured generation and exploration of design space with large language models for human-ai co-creation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib62.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2310.12953" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2310 . 12953
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_tag_bibitem">
     [63]
    </span>
    <span class="ltx_bibblock">
     S. Suh, B. Min, S. Palani, and H. Xia.
    </span>
    <span class="ltx_bibblock">
     Sensecape: Enabling multilevel exploration and sensemaking with large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib63.1.1">
      Proc. UIST
     </span>
     . ACM, New York, NY, USA, 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3586183.3606756" target="_blank" title="">
      doi: 10 . 1145/3586183 . 3606756
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_tag_bibitem">
     [64]
    </span>
    <span class="ltx_bibblock">
     M. Tory and V. Setlur.
    </span>
    <span class="ltx_bibblock">
     Do what i mean, not what i say! design considerations for supporting intent and context in analytical conversation.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib64.1.1">
      IEEE VAST
     </span>
     , pp. 93–103, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/VAST47406.2019.8986918" target="_blank" title="">
      doi: 10 . 1109/VAST47406 . 2019 . 8986918
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_tag_bibitem">
     [65]
    </span>
    <span class="ltx_bibblock">
     H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al.
    </span>
    <span class="ltx_bibblock">
     Llama: Open and efficient foundation language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib65.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2302.13971" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2302 . 13971
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_tag_bibitem">
     [66]
    </span>
    <span class="ltx_bibblock">
     K. Urgo and J. Arguello.
    </span>
    <span class="ltx_bibblock">
     Learning assessments in search-as-learning: A survey of prior work and opportunities for future research.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib66.1.1">
      Information Processing &amp; Management
     </span>
     , 59(2):102821, 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.ipm.2021.102821" target="_blank" title="">
      doi: 10 . 1016/j . ipm . 2021 . 102821
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_tag_bibitem">
     [67]
    </span>
    <span class="ltx_bibblock">
     B. Wang, R. Shin, X. Liu, O. Polozov, and M. Richardson.
    </span>
    <span class="ltx_bibblock">
     RAT-SQL: Relation-aware schema encoding and linking for text-to-SQL parsers.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib67.1.1">
      Proc. ACL
     </span>
     , pp. 7567–7578. ACL, Online, July 2020.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.677" target="_blank" title="">
      doi: 10 . 18653/v1/2020 . acl-main . 677
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_tag_bibitem">
     [68]
    </span>
    <span class="ltx_bibblock">
     X. Wang, F. Cheng, Y. Wang, K. Xu, J. Long, H. Lu, and H. Qu.
    </span>
    <span class="ltx_bibblock">
     Interactive data analysis with next-step natural language query recommendation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib68.1.1">
      arXiv
     </span>
     , 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2201.04868" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2201 . 04868
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_tag_bibitem">
     [69]
    </span>
    <span class="ltx_bibblock">
     Y. Wang, Z. Sun, H. Zhang, W. Cui, K. Xu, X. Ma, and D. Zhang.
    </span>
    <span class="ltx_bibblock">
     Datashot: Automatic generation of fact sheets from tabular data.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib69.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 26(1):895–905, 2020.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2019.2934398" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2019 . 2934398
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_tag_bibitem">
     [70]
    </span>
    <span class="ltx_bibblock">
     Y. Wang, Y. Wang, H. Zhang, Y. Sun, C.-W. Fu, M. Sedlmair, B. Chen, and O. Deussen.
    </span>
    <span class="ltx_bibblock">
     Structure-aware fisheye views for efficient large graph exploration.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib70.1.1">
      IEEE Trans. Vis. Comput. Graph.
     </span>
     , 25(1):566–575, 2019.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TVCG.2018.2864911" target="_blank" title="">
      doi: 10 . 1109/TVCG . 2018 . 2864911
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_tag_bibitem">
     [71]
    </span>
    <span class="ltx_bibblock">
     Z. J. Wang, K. Dai, and W. K. Edwards.
    </span>
    <span class="ltx_bibblock">
     StickyLand: Breaking the Linear Presentation of Computational Notebooks.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib71.1.1">
      Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems
     </span>
     . ACM, 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3491101.3519653" target="_blank" title="">
      doi: 10 . 1145/3491101 . 3519653
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_tag_bibitem">
     [72]
    </span>
    <span class="ltx_bibblock">
     T. Xie, C. H. Wu, P. Shi, R. Zhong, T. Scholak, M. Yasunaga, C.-S. Wu, M. Zhong, P. Yin, S. I. Wang, V. Zhong, B. Wang, C. Li, C. Boyle, A. Ni, Z. Yao, D. Radev, C. Xiong, L. Kong, R. Zhang, N. A. Smith, L. Zettlemoyer, and T. Yu.
    </span>
    <span class="ltx_bibblock">
     UnifiedSKG: Unifying and multi-tasking structured knowledge grounding with text-to-text language models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">
      Proc. EMNLP
     </span>
     , pp. 602–631. ACL, Abu Dhabi, United Arab Emirates, Dec. 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.39" target="_blank" title="">
      doi: 10 . 18653/v1/2022 . emnlp-main . 39
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_tag_bibitem">
     [73]
    </span>
    <span class="ltx_bibblock">
     T. Xie, F. Zhou, Z. Cheng, P. Shi, L. Weng, Y. Liu, T. J. Hua, J. Zhao, Q. Liu, C. Liu, L. Z. Liu, Y. Xu, H. Su, D. Shin, C. Xiong, and T. Yu.
    </span>
    <span class="ltx_bibblock">
     Openagents: An open platform for language agents in the wild.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib73.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2310.10634" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2310 . 10634
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_tag_bibitem">
     [74]
    </span>
    <span class="ltx_bibblock">
     S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao.
    </span>
    <span class="ltx_bibblock">
     React: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib74.1.1">
      ICLR
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2210.03629" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2210 . 03629
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_tag_bibitem">
     [75]
    </span>
    <span class="ltx_bibblock">
     A. Yuan, A. Coenen, E. Reif, and D. Ippolito.
    </span>
    <span class="ltx_bibblock">
     Wordcraft: Story writing with large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib75.1.1">
      Proc. IUI
     </span>
     , p. 841–852. ACM, New York, NY, USA, 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3490099.3511105" target="_blank" title="">
      doi: 10 . 1145/3490099 . 3511105
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_tag_bibitem">
     [76]
    </span>
    <span class="ltx_bibblock">
     W. Zhang, Y. Shen, W. Lu, and Y. Zhuang.
    </span>
    <span class="ltx_bibblock">
     Data-copilot: Bridging billions of data and humans with autonomous workflow.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib76.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2306.07209" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2306 . 07209
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_tag_bibitem">
     [77]
    </span>
    <span class="ltx_bibblock">
     Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao, Y. Zhang, Y. Chen, L. Wang, A. T. Luu, W. Bi, F. Shi, and S. Shi.
    </span>
    <span class="ltx_bibblock">
     Siren’s song in the ai ocean: A survey on hallucination in large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib77.1.1">
      arXiv
     </span>
     , 2023.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.01219" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 2309 . 01219
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_tag_bibitem">
     [78]
    </span>
    <span class="ltx_bibblock">
     W. Zheng, H. Cheng, L. Zou, J. X. Yu, and K. Zhao.
    </span>
    <span class="ltx_bibblock">
     Natural language question/answering: Let users talk with the knowledge graph.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib78.1.1">
      Proc. CIKM
     </span>
     , p. 217–226. ACM, New York, NY, USA, 2017.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3132847.3132977" target="_blank" title="">
      doi: 10 . 1145/3132847 . 3132977
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_tag_bibitem">
     [79]
    </span>
    <span class="ltx_bibblock">
     F. Zhou, M. Hu, H. Dong, Z. Cheng, F. Cheng, S. Han, and D. Zhang.
    </span>
    <span class="ltx_bibblock">
     TaCube: Pre-computing data cubes for answering numerical-reasoning questions over tabular data.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib79.1.1">
      Proc. EMNLP
     </span>
     , pp. 2278–2291. ACL, Abu Dhabi, United Arab Emirates, Dec. 2022.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.145" target="_blank" title="">
      doi: 10 . 18653/v1/2022 . emnlp-main . 145
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_tag_bibitem">
     [80]
    </span>
    <span class="ltx_bibblock">
     Z. Zhou, X. Wen, Y. Wang, and D. Gotz.
    </span>
    <span class="ltx_bibblock">
     Modeling and leveraging analytic focus during exploratory visual analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib80.1.1">
      Proc. CHI
     </span>
     . ACM, New York, NY, USA, 2021.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3411764.3445674" target="_blank" title="">
      doi: 10 . 1145/3411764 . 3445674
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_tag_bibitem">
     [81]
    </span>
    <span class="ltx_bibblock">
     Çağatay Demiralp, P. J. Haas, S. Parthasarathy, and T. Pedapati.
    </span>
    <span class="ltx_bibblock">
     Foresight: Rapid data exploration through guideposts.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib81.1.1">
      arXiv
     </span>
     , 2017.
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.1709.10513" target="_blank" title="">
      doi: 10 . 48550/ARXIV . 1709 . 10513
     </a>
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
