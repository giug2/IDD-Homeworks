<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.01342] Covert Communication Based on the Poisoning Attack in Federated Learning</title><meta property="og:description" content="Covert communication has become an important area of research in computer security. It involves hiding specific information on a carrier for message transmission and is often used to transmit private data, military sec…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Covert Communication Based on the Poisoning Attack in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Covert Communication Based on the Poisoning Attack in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.01342">

<!--Generated on Thu Feb 29 02:15:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="covert communication,  federated learning,  information coding,  poisoning attack">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Covert Communication Based on the Poisoning Attack in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Junchuan Liang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:liangjunchuan@stu.sicnu.edu.cn">liangjunchuan@stu.sicnu.edu.cn</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rong Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:rwang@sicnu.edu.cn">rwang@sicnu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">School of Computer Science, Sichuan Normal University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_streetaddress">Chenlong Street 1819</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_city">Chengdu</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_state">China</span><span id="id5.5.id5" class="ltx_text ltx_affiliation_postcode">610101</span>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id6.id1" class="ltx_p">Covert communication has become an important area of research in computer security. It involves hiding specific information on a carrier for message transmission and is often used to transmit private data, military secrets, and even malware. In deep learning, many methods have been developed for hiding information in models to achieve covert communication. However, these methods are not applicable to federated learning, where model aggregation invalidates the exact information embedded in the model by the client. To address this problem, we propose a novel method for covert communication in federated learning based on the poisoning attack. Our approach achieves 100% accuracy in covert message transmission between two clients and is shown to be both stealthy and robust through extensive experiments. However, existing defense methods are limited in their effectiveness against our attack scheme, highlighting the urgent need for new protection methods to be developed. Our study emphasizes the necessity of research in covert communication and serves as a foundation for future research in federated learning attacks and defenses.</p>
</div>
<div class="ltx_keywords">covert communication, federated learning, information coding, poisoning attack
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>xxxx xxxx xxxx; xxxx xxxx, 2023; xxxx, xxxx</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>xxxx xxxx xxxx xxxx ,xxxx, 2023, xxxx, xxxx</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer security Federated learning systems</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Communication Security Covert communication</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Covert communication design</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Covert communication <cite class="ltx_cite ltx_citemacro_citep">(Mirzargar and
Stojilović, <a href="#bib.bib32" title="" class="ltx_ref">2019</a>; Chandra
et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2015</a>; Li and
Epliremides, <a href="#bib.bib25" title="" class="ltx_ref">2004</a>)</cite> is a method of transmitting secret information has been receiving a lot of attention. Pony <cite class="ltx_cite ltx_citemacro_citep">(Eisenkraft and
Olshtein., <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite> and Glupteba <cite class="ltx_cite ltx_citemacro_citep">(Horejsi and Chen, <a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite> have been observed to use bitcoin transactions for transmitting messages. And StegoNet <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite> successfully embeds malware into the artificial intelligence (AI) model. Numerous studies <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2021</a>)</cite> have been made about using models as carriers in deep learning. However, there are few studies on covert communication in federated learning.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Federated learning <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2017</a>)</cite> is a decentralized machine learning that allows models to be trained data across multiple clients without the need to share the raw data. This technique has been applied in various fields (such as finance <cite class="ltx_cite ltx_citemacro_citep">(Long
et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2020</a>)</cite>, healthcare <cite class="ltx_cite ltx_citemacro_citep">(Brisimi et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2018</a>; Silva et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite>, and the Internet of Things (IoT) <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite>) and has the potential to shape the future of artificial intelligence in a privacy-obsessed world <cite class="ltx_cite ltx_citemacro_citep">(Kairouz
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>. The process of federated learning involves initializing a global model, local training of the model on each client’s data, aggregation of the updated model parameters, and evaluation of the model’s performance. This process is repeated for multiple iterations to improve the model’s performance.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The focus of this paper is on achieving covert communication between two clients in federated learning using only model aggregation. Federated learning is a preferred choice in institutions such as hospitals and banks that prioritize privacy protection to obtain better models. In such settings, models are only transmitted to a fully trusted server, which carefully reviews them before performing model aggregation and distributing the aggregated models to clients. In this hypothetical scenario, we assume that an attacker is a compromised software whose goal is to leak important data with 100% accuracy from a client to a receiver posing as a benign participant. However, this process will face three main problems.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Issue 1:</span> The first issue an attacker needs to consider is that the client’s important data is physically isolated, except for the model that will be sent to a fully trusted server. Therefore, the attacker needs to find a way to hide the information into the model.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">Issue 2:</span> The second issue is that the server performs a rigorous review of the models submitted by the client, including model similarity comparison, accuracy detection, differential privacy, etc. The attacker needs to hide the information while ensuring that the model appears normal to pass the review process.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">Issue 3:</span> The third issue that the attacker needs to consider is that the server performs federated aggregation after receiving the client’s model, such as FedAvg. This means that the attacker needs to ensure the accuracy of the hidden information in the model after recalculation, to prevent distortion or loss of the covert communication.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Previous methods proposed in <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite> have demonstrated the ability to hide information within a model while maintaining its functionality. However, these methods are not suitable for federated learning scenarios due to the server’s model aggregation process, which invalidates the embedded information. The backdoor-based approach proposed by <cite class="ltx_cite ltx_citemacro_citep">(Costa
et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite> enables information transfer between federated learning clients but is limited to transferring only 1 bit of data, making it unsuitable for our scenario.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">To address the limitations of existing methods, we propose a novel approach to federated learning covert communication (Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) based on poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>; Fung
et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2018</a>; Tolpegin
et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>)</cite>. This approach is motivated by two factors. Firstly, the invisibility of client training data and processes in federated learning makes it vulnerable to poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>, making our proposed technique highly relevant. Second, our repeated poisoning technique significantly increases communication capacity, achieving 10,000-bit data transfer compared to the 1-bit capacity of backdoor-based approaches <cite class="ltx_cite ltx_citemacro_citep">(Costa
et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">Our approach not only enables the accurate transmission of large amounts of information but also circumvents the careful scrutiny of the server. We evaluated the latest approaches to the federated learning of poisoning attack defense in recent years, such as differential privacy <cite class="ltx_cite ltx_citemacro_citep">(Du et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>; Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2016</a>)</cite>, FLAME <cite class="ltx_cite ltx_citemacro_citep">(Nguyen
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>, and GAA <cite class="ltx_cite ltx_citemacro_citep">(Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>)</cite>. Even if the central server uses a validation dataset to detect the clients’ updates <cite class="ltx_cite ltx_citemacro_citep">(Fang
et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>. We found that these methods do not prevent covert communication. This suggests that research into relevant defense options is imminent.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">The paper contributes to a better understanding of the security implications of covert communication in federated learning and paves the way for further research in this area. The contributions of this paper are three-fold.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="296" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Federated learning covert communication (The red arrows represent the message that the sender wants to transmit.)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S1.F1.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S1.F1.2" class="ltx_p ltx_figure_panel ltx_align_center">Federated learning covert communication.</p>
</div>
</div>
</figure>
<div id="S1.p11" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">we propose a novel approach to achieve federated learning covert communication using the poisoning attack. Our method can successfully achieve <math id="S1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S1.I1.i1.p1.1.m1.1a"><mrow id="S1.I1.i1.p1.1.m1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.cmml"><mn id="S1.I1.i1.p1.1.m1.1.1.2" xref="S1.I1.i1.p1.1.m1.1.1.2.cmml">100</mn><mo id="S1.I1.i1.p1.1.m1.1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.1.m1.1b"><apply id="S1.I1.i1.p1.1.m1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i1.p1.1.m1.1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.I1.i1.p1.1.m1.1.1.2.cmml" xref="S1.I1.i1.p1.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.1.m1.1c">100\%</annotation></semantics></math> accurate transmission of information between two federated learning clients only through the federated learning aggregation process.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">we propose an optimization method for our covert communication scheme, which enables more covert and larger capacity information transmission. The communication capacity of our scheme is also evaluated theoretically.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Experiments demonstrate the accuracy, stealthiness, and robustness of our approach. We analyze the effectiveness of current defense methods against our attack and point out new possible defense schemes.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Federated Learning and Poisoning attack</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Federated learning is a decentralized machine learning technique that allows multiple clients to train a global model without the need for data sharing. The key idea is to update the global model by aggregating the local updates from each client, which preserves the privacy of client data. The implementation process of federated learning typically involves the following steps.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Step 1. A central server distributes the initial global model to a set of clients.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Step 2. Each client device trains the model on its local data and sends the updated model back to the central server.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Step 3. The central server aggregates the model updates from all clients to create a new global model.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">Step 4. Steps 2 and 3 are repeated for a certain number of rounds until a predetermined stopping criterion is reached.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.1" class="ltx_p">However, federated learning can be vulnerable to various security threats, such as the poisoning attack. Poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>; Fung
et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2018</a>; Tolpegin
et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>)</cite> in federated learning involve a malicious client intentionally sending malicious data to the server. Such malicious data can lead to inaccurate or biased results.</p>
</div>
<div id="S2.SS1.p7" class="ltx_para">
<p id="S2.SS1.p7.1" class="ltx_p">In recent years, a variety of poisoning attacks in federated learning have been proposed, including data poisoning <cite class="ltx_cite ltx_citemacro_citep">(Tolpegin
et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>)</cite>, and model poisoning <cite class="ltx_cite ltx_citemacro_citep">(Fang
et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>. And it is pointed out that poisoning attacks are inevitable due to the invisibility of the client training process and data in <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Covert Communication Attack</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Covert communication attacks in <cite class="ltx_cite ltx_citemacro_citep">(Mirzargar and
Stojilović, <a href="#bib.bib32" title="" class="ltx_ref">2019</a>; Chandra
et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2015</a>; Li and
Epliremides, <a href="#bib.bib25" title="" class="ltx_ref">2004</a>)</cite> involve using a communication channel to transmit information. Covert communication attacks are also known as covert channel attacks in <cite class="ltx_cite ltx_citemacro_citep">(Li and
Epliremides, <a href="#bib.bib25" title="" class="ltx_ref">2004</a>; Luo
et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2007</a>; Roberts, <a href="#bib.bib38" title="" class="ltx_ref">2000</a>; Giffin et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2003</a>; Tuptuk and Hailes, <a href="#bib.bib46" title="" class="ltx_ref">2015</a>)</cite>. It is a major concern in the security of various systems, including cloud computing and pervasive computing systems. There are two main classes of covert channels, i.e., timing channels in <cite class="ltx_cite ltx_citemacro_citep">(Tuptuk and Hailes, <a href="#bib.bib46" title="" class="ltx_ref">2015</a>)</cite> and storage channels in <cite class="ltx_cite ltx_citemacro_citep">(Li and
Epliremides, <a href="#bib.bib25" title="" class="ltx_ref">2004</a>; Luo
et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2007</a>)</cite>. Timing channels rely on modulating resources to convey covert messages, while storage channels transfer information by storing values of inaccessible objects. Both types of attacks aim to make covert messages indistinguishable from legitimate traffic to avoid detection. Covert channels have been proposed in various communication protocols, including IP and TCP in <cite class="ltx_cite ltx_citemacro_citep">(Roberts, <a href="#bib.bib38" title="" class="ltx_ref">2000</a>)</cite>. In wireless networks, timing channels are particularly challenging to implement due to the regularity of sampling and predictable processing. Overall, covert channel attacks can be powerful tools for industrial espionage and sabotage in <cite class="ltx_cite ltx_citemacro_citep">(Chandra
et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">In this paper, we focus on the use of the poisoning attack to achieve covert communication between clients. This involves embedding covert messages within the model that can be decoded by the special client.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Proposed Attack Method</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Challenges</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To achieve covert communication between two clients in federated learning, we propose a poisoning attack-based strategy that embeds messages into the local model updates. Specifically, we first select a malicious client who participates in the training process, and we carefully craft their model updates to encode the covert messages. Then, we let these malicious clients send the poisoned model updates to the server, which will in turn distribute them to all other clients. In this process, we will face the following challenges.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Challenge 1: How to send a message to the receiver?</span> One of the main challenges in covert communication is how to send a message from the sender to the receiver. In federated learning, all information embedded in the model by the message sender is recalculated by the server, which can result in the sender not being able to send the exact value to the receiver. Moreover, it is also challenging for the receiver to accurately distinguish the bits of information sent by the sender from the model updates.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Challenge 2: How to ensure communication covertly?</span> Another main challenge in covert communication is how to ensure that the hidden message is not detectable or distinguishable from normal model updates. To send information to the receiver, in the case of joint learning, the information can only be carried through the model. Therefore, the challenge is how to ensure that the model that hides the information looks the same as the normal model.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Challenge 3: How to ensure the accuracy of the global model and local model?</span> The third critical challenge in covert communication is to prevent any disruption or compromise to the federated learning process. Since our hidden communication relies on the federated learning process, it is essential to ensure that the process is executed correctly as a prerequisite for the existence of covert communication. At the same time, ensuring the accuracy of the local model can reduce the possibility of the sender being detected by the server.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Attacker Model</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We define the following attacker’s scenario and the attacker’s knowledge, as well as the target of the attack.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Attack scenario.</span> Our attack scenario is designed for a horizontal federated learning setting. In this setting, the central server collects models from clients and computing updates. Meanwhile, the clients train their respective models. In this scenario, the attacker participates in the federated learning process by disguising themselves as benign client.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Attackers.</span> To make the covert communication process more intuitive, we divide the attacker into two roles, i.e., the message sender and the message receiver. Both of them join the federated learning system disguised as benign clients. The sender is responsible for encoding a message into the model weights at a pre-agreed position, while the receiver is tasked with decoding the information from the global model based on the recorded and averaged weights over several rounds. The success of the task is determined by the accurate matching of the decoded information to the sent information.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Attackers’ knowledge.</span> The sender and receiver can agree in advance on the position of the weights used to send messages in the model, based on their knowledge of the model architecture. The sender and the receiver can agree in advance on the way of encoding the content of the communication, based on their shared knowledge of the encoding scheme and the decoding algorithm.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Attack Method</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In federated learning, clients send their model updates to the server for aggregation and obtain the updated global model. In a poisoning attack, the attacker aims to inject malicious model updates that will manipulate the global model in a specific way. However, due to server model aggregation, it is difficult for the sender to send the exact values to the receiver.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">To overcome this challenge, the sender can control the weight of the model update and make it closer to the desired direction. For example, if the sender wants to send a message that corresponds to the binary value of 0, the sender can adjust the weights of its model updates to be closer to the negative side of the scale; if the sender wants to send a message that corresponds to the binary value of 1, the sender can adjust the weights to be closer to the positive side of the scale. The proposed attack method is presented in Algorithm 1 and further explained as follows.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Covert communication in federated learning</figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>The agreed position <math id="alg1.l1.m1.1" class="ltx_Math" alttext="w_{p}" display="inline"><semantics id="alg1.l1.m1.1a"><msub id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2.cmml">w</mi><mi id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">𝑤</ci><ci id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">w_{p}</annotation></semantics></math> for encoding the message, total cycle <math id="alg1.l1.m2.1" class="ltx_Math" alttext="S_{N}" display="inline"><semantics id="alg1.l1.m2.1a"><msub id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><mi id="alg1.l1.m2.1.1.2" xref="alg1.l1.m2.1.1.2.cmml">S</mi><mi id="alg1.l1.m2.1.1.3" xref="alg1.l1.m2.1.1.3.cmml">N</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1">subscript</csymbol><ci id="alg1.l1.m2.1.1.2.cmml" xref="alg1.l1.m2.1.1.2">𝑆</ci><ci id="alg1.l1.m2.1.1.3.cmml" xref="alg1.l1.m2.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">S_{N}</annotation></semantics></math> and which one has <math id="alg1.l1.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="alg1.l1.m3.1a"><mi id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><ci id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">n</annotation></semantics></math> rounds, and the Information encoded as binary <math id="alg1.l1.m4.4" class="ltx_Math" alttext="B=b_{1},b_{2},...,b_{S_{N}}" display="inline"><semantics id="alg1.l1.m4.4a"><mrow id="alg1.l1.m4.4.4" xref="alg1.l1.m4.4.4.cmml"><mi id="alg1.l1.m4.4.4.5" xref="alg1.l1.m4.4.4.5.cmml">B</mi><mo id="alg1.l1.m4.4.4.4" xref="alg1.l1.m4.4.4.4.cmml">=</mo><mrow id="alg1.l1.m4.4.4.3.3" xref="alg1.l1.m4.4.4.3.4.cmml"><msub id="alg1.l1.m4.2.2.1.1.1" xref="alg1.l1.m4.2.2.1.1.1.cmml"><mi id="alg1.l1.m4.2.2.1.1.1.2" xref="alg1.l1.m4.2.2.1.1.1.2.cmml">b</mi><mn id="alg1.l1.m4.2.2.1.1.1.3" xref="alg1.l1.m4.2.2.1.1.1.3.cmml">1</mn></msub><mo id="alg1.l1.m4.4.4.3.3.4" xref="alg1.l1.m4.4.4.3.4.cmml">,</mo><msub id="alg1.l1.m4.3.3.2.2.2" xref="alg1.l1.m4.3.3.2.2.2.cmml"><mi id="alg1.l1.m4.3.3.2.2.2.2" xref="alg1.l1.m4.3.3.2.2.2.2.cmml">b</mi><mn id="alg1.l1.m4.3.3.2.2.2.3" xref="alg1.l1.m4.3.3.2.2.2.3.cmml">2</mn></msub><mo id="alg1.l1.m4.4.4.3.3.5" xref="alg1.l1.m4.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="alg1.l1.m4.1.1" xref="alg1.l1.m4.1.1.cmml">…</mi><mo id="alg1.l1.m4.4.4.3.3.6" xref="alg1.l1.m4.4.4.3.4.cmml">,</mo><msub id="alg1.l1.m4.4.4.3.3.3" xref="alg1.l1.m4.4.4.3.3.3.cmml"><mi id="alg1.l1.m4.4.4.3.3.3.2" xref="alg1.l1.m4.4.4.3.3.3.2.cmml">b</mi><msub id="alg1.l1.m4.4.4.3.3.3.3" xref="alg1.l1.m4.4.4.3.3.3.3.cmml"><mi id="alg1.l1.m4.4.4.3.3.3.3.2" xref="alg1.l1.m4.4.4.3.3.3.3.2.cmml">S</mi><mi id="alg1.l1.m4.4.4.3.3.3.3.3" xref="alg1.l1.m4.4.4.3.3.3.3.3.cmml">N</mi></msub></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.4b"><apply id="alg1.l1.m4.4.4.cmml" xref="alg1.l1.m4.4.4"><eq id="alg1.l1.m4.4.4.4.cmml" xref="alg1.l1.m4.4.4.4"></eq><ci id="alg1.l1.m4.4.4.5.cmml" xref="alg1.l1.m4.4.4.5">𝐵</ci><list id="alg1.l1.m4.4.4.3.4.cmml" xref="alg1.l1.m4.4.4.3.3"><apply id="alg1.l1.m4.2.2.1.1.1.cmml" xref="alg1.l1.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m4.2.2.1.1.1.1.cmml" xref="alg1.l1.m4.2.2.1.1.1">subscript</csymbol><ci id="alg1.l1.m4.2.2.1.1.1.2.cmml" xref="alg1.l1.m4.2.2.1.1.1.2">𝑏</ci><cn type="integer" id="alg1.l1.m4.2.2.1.1.1.3.cmml" xref="alg1.l1.m4.2.2.1.1.1.3">1</cn></apply><apply id="alg1.l1.m4.3.3.2.2.2.cmml" xref="alg1.l1.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l1.m4.3.3.2.2.2.1.cmml" xref="alg1.l1.m4.3.3.2.2.2">subscript</csymbol><ci id="alg1.l1.m4.3.3.2.2.2.2.cmml" xref="alg1.l1.m4.3.3.2.2.2.2">𝑏</ci><cn type="integer" id="alg1.l1.m4.3.3.2.2.2.3.cmml" xref="alg1.l1.m4.3.3.2.2.2.3">2</cn></apply><ci id="alg1.l1.m4.1.1.cmml" xref="alg1.l1.m4.1.1">…</ci><apply id="alg1.l1.m4.4.4.3.3.3.cmml" xref="alg1.l1.m4.4.4.3.3.3"><csymbol cd="ambiguous" id="alg1.l1.m4.4.4.3.3.3.1.cmml" xref="alg1.l1.m4.4.4.3.3.3">subscript</csymbol><ci id="alg1.l1.m4.4.4.3.3.3.2.cmml" xref="alg1.l1.m4.4.4.3.3.3.2">𝑏</ci><apply id="alg1.l1.m4.4.4.3.3.3.3.cmml" xref="alg1.l1.m4.4.4.3.3.3.3"><csymbol cd="ambiguous" id="alg1.l1.m4.4.4.3.3.3.3.1.cmml" xref="alg1.l1.m4.4.4.3.3.3.3">subscript</csymbol><ci id="alg1.l1.m4.4.4.3.3.3.3.2.cmml" xref="alg1.l1.m4.4.4.3.3.3.3.2">𝑆</ci><ci id="alg1.l1.m4.4.4.3.3.3.3.3.cmml" xref="alg1.l1.m4.4.4.3.3.3.3.3">𝑁</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.4c">B=b_{1},b_{2},...,b_{S_{N}}</annotation></semantics></math> to be encoded.

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>The received message <math id="alg1.l2.m1.1" class="ltx_Math" alttext="R_{B}" display="inline"><semantics id="alg1.l2.m1.1a"><msub id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">R</mi><mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">𝑅</ci><ci id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">R_{B}</annotation></semantics></math> after decoding.

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span><span id="alg1.l3.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l3.m1.1" class="ltx_Math" alttext="S_{0}\to S_{N}" display="inline"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><msub id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml"><mi id="alg1.l3.m1.1.1.2.2" xref="alg1.l3.m1.1.1.2.2.cmml">S</mi><mn id="alg1.l3.m1.1.1.2.3" xref="alg1.l3.m1.1.1.2.3.cmml">0</mn></msub><mo stretchy="false" id="alg1.l3.m1.1.1.1" xref="alg1.l3.m1.1.1.1.cmml">→</mo><msub id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml"><mi id="alg1.l3.m1.1.1.3.2" xref="alg1.l3.m1.1.1.3.2.cmml">S</mi><mi id="alg1.l3.m1.1.1.3.3" xref="alg1.l3.m1.1.1.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><ci id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1">→</ci><apply id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.2.1.cmml" xref="alg1.l3.m1.1.1.2">subscript</csymbol><ci id="alg1.l3.m1.1.1.2.2.cmml" xref="alg1.l3.m1.1.1.2.2">𝑆</ci><cn type="integer" id="alg1.l3.m1.1.1.2.3.cmml" xref="alg1.l3.m1.1.1.2.3">0</cn></apply><apply id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.3.1.cmml" xref="alg1.l3.m1.1.1.3">subscript</csymbol><ci id="alg1.l3.m1.1.1.3.2.cmml" xref="alg1.l3.m1.1.1.3.2">𝑆</ci><ci id="alg1.l3.m1.1.1.3.3.cmml" xref="alg1.l3.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">S_{0}\to S_{N}</annotation></semantics></math> <span id="alg1.l3.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>     <span id="alg1.l4.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l4.m1.4" class="ltx_Math" alttext="S_{i}=1,2,...,n" display="inline"><semantics id="alg1.l4.m1.4a"><mrow id="alg1.l4.m1.4.5" xref="alg1.l4.m1.4.5.cmml"><msub id="alg1.l4.m1.4.5.2" xref="alg1.l4.m1.4.5.2.cmml"><mi id="alg1.l4.m1.4.5.2.2" xref="alg1.l4.m1.4.5.2.2.cmml">S</mi><mi id="alg1.l4.m1.4.5.2.3" xref="alg1.l4.m1.4.5.2.3.cmml">i</mi></msub><mo id="alg1.l4.m1.4.5.1" xref="alg1.l4.m1.4.5.1.cmml">=</mo><mrow id="alg1.l4.m1.4.5.3.2" xref="alg1.l4.m1.4.5.3.1.cmml"><mn id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">1</mn><mo id="alg1.l4.m1.4.5.3.2.1" xref="alg1.l4.m1.4.5.3.1.cmml">,</mo><mn id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml">2</mn><mo id="alg1.l4.m1.4.5.3.2.2" xref="alg1.l4.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l4.m1.3.3" xref="alg1.l4.m1.3.3.cmml">…</mi><mo id="alg1.l4.m1.4.5.3.2.3" xref="alg1.l4.m1.4.5.3.1.cmml">,</mo><mi id="alg1.l4.m1.4.4" xref="alg1.l4.m1.4.4.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.4b"><apply id="alg1.l4.m1.4.5.cmml" xref="alg1.l4.m1.4.5"><eq id="alg1.l4.m1.4.5.1.cmml" xref="alg1.l4.m1.4.5.1"></eq><apply id="alg1.l4.m1.4.5.2.cmml" xref="alg1.l4.m1.4.5.2"><csymbol cd="ambiguous" id="alg1.l4.m1.4.5.2.1.cmml" xref="alg1.l4.m1.4.5.2">subscript</csymbol><ci id="alg1.l4.m1.4.5.2.2.cmml" xref="alg1.l4.m1.4.5.2.2">𝑆</ci><ci id="alg1.l4.m1.4.5.2.3.cmml" xref="alg1.l4.m1.4.5.2.3">𝑖</ci></apply><list id="alg1.l4.m1.4.5.3.1.cmml" xref="alg1.l4.m1.4.5.3.2"><cn type="integer" id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">1</cn><cn type="integer" id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2">2</cn><ci id="alg1.l4.m1.3.3.cmml" xref="alg1.l4.m1.3.3">…</ci><ci id="alg1.l4.m1.4.4.cmml" xref="alg1.l4.m1.4.4">𝑛</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.4c">S_{i}=1,2,...,n</annotation></semantics></math> <span id="alg1.l4.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>         <span id="alg1.l5.2" class="ltx_text ltx_font_bold">if</span> <math id="alg1.l5.m1.1" class="ltx_Math" alttext="sender" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mi id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml">​</mo><mi id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1a" xref="alg1.l5.m1.1.1.1.cmml">​</mo><mi id="alg1.l5.m1.1.1.4" xref="alg1.l5.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1b" xref="alg1.l5.m1.1.1.1.cmml">​</mo><mi id="alg1.l5.m1.1.1.5" xref="alg1.l5.m1.1.1.5.cmml">d</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1c" xref="alg1.l5.m1.1.1.1.cmml">​</mo><mi id="alg1.l5.m1.1.1.6" xref="alg1.l5.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1d" xref="alg1.l5.m1.1.1.1.cmml">​</mo><mi id="alg1.l5.m1.1.1.7" xref="alg1.l5.m1.1.1.7.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><times id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"></times><ci id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2">𝑠</ci><ci id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3">𝑒</ci><ci id="alg1.l5.m1.1.1.4.cmml" xref="alg1.l5.m1.1.1.4">𝑛</ci><ci id="alg1.l5.m1.1.1.5.cmml" xref="alg1.l5.m1.1.1.5">𝑑</ci><ci id="alg1.l5.m1.1.1.6.cmml" xref="alg1.l5.m1.1.1.6">𝑒</ci><ci id="alg1.l5.m1.1.1.7.cmml" xref="alg1.l5.m1.1.1.7">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">sender</annotation></semantics></math> <span id="alg1.l5.3" class="ltx_text ltx_font_bold">then</span>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.2.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>              <math id="alg1.l6.m1.1" class="ltx_Math" alttext="w_{pl}=b_{i}" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><msub id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mi id="alg1.l6.m1.1.1.2.2" xref="alg1.l6.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml"><mi id="alg1.l6.m1.1.1.2.3.2" xref="alg1.l6.m1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.1.1.2.3.1" xref="alg1.l6.m1.1.1.2.3.1.cmml">​</mo><mi id="alg1.l6.m1.1.1.2.3.3" xref="alg1.l6.m1.1.1.2.3.3.cmml">l</mi></mrow></msub><mo id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">=</mo><msub id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"><mi id="alg1.l6.m1.1.1.3.2" xref="alg1.l6.m1.1.1.3.2.cmml">b</mi><mi id="alg1.l6.m1.1.1.3.3" xref="alg1.l6.m1.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><eq id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"></eq><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">𝑤</ci><apply id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3"><times id="alg1.l6.m1.1.1.2.3.1.cmml" xref="alg1.l6.m1.1.1.2.3.1"></times><ci id="alg1.l6.m1.1.1.2.3.2.cmml" xref="alg1.l6.m1.1.1.2.3.2">𝑝</ci><ci id="alg1.l6.m1.1.1.2.3.3.cmml" xref="alg1.l6.m1.1.1.2.3.3">𝑙</ci></apply></apply><apply id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.1.cmml" xref="alg1.l6.m1.1.1.3">subscript</csymbol><ci id="alg1.l6.m1.1.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.2">𝑏</ci><ci id="alg1.l6.m1.1.1.3.3.cmml" xref="alg1.l6.m1.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">w_{pl}=b_{i}</annotation></semantics></math>; <span id="alg1.l6.1" class="ltx_text" style="float:right;"><math id="alg1.l6.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l6.1.m1.1a"><mo id="alg1.l6.1.m1.1.1" xref="alg1.l6.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l6.1.m1.1b"><ci id="alg1.l6.1.m1.1.1.cmml" xref="alg1.l6.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.1.m1.1c">\triangleright</annotation></semantics></math> Information embedded
</span>
</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>              The other weights are trained normally and the

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>              updated model is sent to the server;

</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>         <span id="alg1.l9.2" class="ltx_text ltx_font_bold">else</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>              Each client trains the model on their local data and

</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span>              sends the updated model to the server;

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span>         <span id="alg1.l12.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l12.3" class="ltx_text ltx_font_bold">if</span>
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span>         Server aggregates the model updates from all clients

</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span>         and sends the new global model to each client;

</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.1.1.1" class="ltx_text" style="font-size:80%;">15:</span></span>         Receiver records the <math id="alg1.l15.m1.1" class="ltx_Math" alttext="w_{pg}" display="inline"><semantics id="alg1.l15.m1.1a"><msub id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml"><mi id="alg1.l15.m1.1.1.2" xref="alg1.l15.m1.1.1.2.cmml">w</mi><mrow id="alg1.l15.m1.1.1.3" xref="alg1.l15.m1.1.1.3.cmml"><mi id="alg1.l15.m1.1.1.3.2" xref="alg1.l15.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l15.m1.1.1.3.1" xref="alg1.l15.m1.1.1.3.1.cmml">​</mo><mi id="alg1.l15.m1.1.1.3.3" xref="alg1.l15.m1.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><apply id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1"><csymbol cd="ambiguous" id="alg1.l15.m1.1.1.1.cmml" xref="alg1.l15.m1.1.1">subscript</csymbol><ci id="alg1.l15.m1.1.1.2.cmml" xref="alg1.l15.m1.1.1.2">𝑤</ci><apply id="alg1.l15.m1.1.1.3.cmml" xref="alg1.l15.m1.1.1.3"><times id="alg1.l15.m1.1.1.3.1.cmml" xref="alg1.l15.m1.1.1.3.1"></times><ci id="alg1.l15.m1.1.1.3.2.cmml" xref="alg1.l15.m1.1.1.3.2">𝑝</ci><ci id="alg1.l15.m1.1.1.3.3.cmml" xref="alg1.l15.m1.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">w_{pg}</annotation></semantics></math> and stores it;

</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span>     <span id="alg1.l16.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l16.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l17.1.1.1" class="ltx_text" style="font-size:80%;">17:</span></span><span id="alg1.l17.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l17.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l18.1.1.1" class="ltx_text" style="font-size:80%;">18:</span></span>The receiver calculates the mean <math id="alg1.l18.m1.1" class="ltx_Math" alttext="w_{pg}" display="inline"><semantics id="alg1.l18.m1.1a"><msub id="alg1.l18.m1.1.1" xref="alg1.l18.m1.1.1.cmml"><mi id="alg1.l18.m1.1.1.2" xref="alg1.l18.m1.1.1.2.cmml">w</mi><mrow id="alg1.l18.m1.1.1.3" xref="alg1.l18.m1.1.1.3.cmml"><mi id="alg1.l18.m1.1.1.3.2" xref="alg1.l18.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l18.m1.1.1.3.1" xref="alg1.l18.m1.1.1.3.1.cmml">​</mo><mi id="alg1.l18.m1.1.1.3.3" xref="alg1.l18.m1.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.1b"><apply id="alg1.l18.m1.1.1.cmml" xref="alg1.l18.m1.1.1"><csymbol cd="ambiguous" id="alg1.l18.m1.1.1.1.cmml" xref="alg1.l18.m1.1.1">subscript</csymbol><ci id="alg1.l18.m1.1.1.2.cmml" xref="alg1.l18.m1.1.1.2">𝑤</ci><apply id="alg1.l18.m1.1.1.3.cmml" xref="alg1.l18.m1.1.1.3"><times id="alg1.l18.m1.1.1.3.1.cmml" xref="alg1.l18.m1.1.1.3.1"></times><ci id="alg1.l18.m1.1.1.3.2.cmml" xref="alg1.l18.m1.1.1.3.2">𝑝</ci><ci id="alg1.l18.m1.1.1.3.3.cmml" xref="alg1.l18.m1.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.1c">w_{pg}</annotation></semantics></math> every cycle;

</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l19.2.1.1" class="ltx_text" style="font-size:80%;">19:</span></span><span id="alg1.l19.3" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l19.m1.1" class="ltx_Math" alttext="S_{0}\to S_{N}" display="inline"><semantics id="alg1.l19.m1.1a"><mrow id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml"><msub id="alg1.l19.m1.1.1.2" xref="alg1.l19.m1.1.1.2.cmml"><mi id="alg1.l19.m1.1.1.2.2" xref="alg1.l19.m1.1.1.2.2.cmml">S</mi><mn id="alg1.l19.m1.1.1.2.3" xref="alg1.l19.m1.1.1.2.3.cmml">0</mn></msub><mo stretchy="false" id="alg1.l19.m1.1.1.1" xref="alg1.l19.m1.1.1.1.cmml">→</mo><msub id="alg1.l19.m1.1.1.3" xref="alg1.l19.m1.1.1.3.cmml"><mi id="alg1.l19.m1.1.1.3.2" xref="alg1.l19.m1.1.1.3.2.cmml">S</mi><mi id="alg1.l19.m1.1.1.3.3" xref="alg1.l19.m1.1.1.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><apply id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1"><ci id="alg1.l19.m1.1.1.1.cmml" xref="alg1.l19.m1.1.1.1">→</ci><apply id="alg1.l19.m1.1.1.2.cmml" xref="alg1.l19.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.2.1.cmml" xref="alg1.l19.m1.1.1.2">subscript</csymbol><ci id="alg1.l19.m1.1.1.2.2.cmml" xref="alg1.l19.m1.1.1.2.2">𝑆</ci><cn type="integer" id="alg1.l19.m1.1.1.2.3.cmml" xref="alg1.l19.m1.1.1.2.3">0</cn></apply><apply id="alg1.l19.m1.1.1.3.cmml" xref="alg1.l19.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.3.1.cmml" xref="alg1.l19.m1.1.1.3">subscript</csymbol><ci id="alg1.l19.m1.1.1.3.2.cmml" xref="alg1.l19.m1.1.1.3.2">𝑆</ci><ci id="alg1.l19.m1.1.1.3.3.cmml" xref="alg1.l19.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">S_{0}\to S_{N}</annotation></semantics></math> <span id="alg1.l19.4" class="ltx_text ltx_font_bold">do</span> <span id="alg1.l19.1" class="ltx_text" style="float:right;"><math id="alg1.l19.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l19.1.m1.1a"><mo id="alg1.l19.1.m1.1.1" xref="alg1.l19.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l19.1.m1.1b"><ci id="alg1.l19.1.m1.1.1.cmml" xref="alg1.l19.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.1.m1.1c">\triangleright</annotation></semantics></math> Information removal
</span>
</div>
<div id="alg1.l20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l20.1.1.1" class="ltx_text" style="font-size:80%;">20:</span></span>     <span id="alg1.l20.2" class="ltx_text ltx_font_bold">if</span> <math id="alg1.l20.m1.1" class="ltx_Math" alttext="mean(w_{pg})&gt;0" display="inline"><semantics id="alg1.l20.m1.1a"><mrow id="alg1.l20.m1.1.1" xref="alg1.l20.m1.1.1.cmml"><mrow id="alg1.l20.m1.1.1.1" xref="alg1.l20.m1.1.1.1.cmml"><mi id="alg1.l20.m1.1.1.1.3" xref="alg1.l20.m1.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l20.m1.1.1.1.2" xref="alg1.l20.m1.1.1.1.2.cmml">​</mo><mi id="alg1.l20.m1.1.1.1.4" xref="alg1.l20.m1.1.1.1.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l20.m1.1.1.1.2a" xref="alg1.l20.m1.1.1.1.2.cmml">​</mo><mi id="alg1.l20.m1.1.1.1.5" xref="alg1.l20.m1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l20.m1.1.1.1.2b" xref="alg1.l20.m1.1.1.1.2.cmml">​</mo><mi id="alg1.l20.m1.1.1.1.6" xref="alg1.l20.m1.1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="alg1.l20.m1.1.1.1.2c" xref="alg1.l20.m1.1.1.1.2.cmml">​</mo><mrow id="alg1.l20.m1.1.1.1.1.1" xref="alg1.l20.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.l20.m1.1.1.1.1.1.2" xref="alg1.l20.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l20.m1.1.1.1.1.1.1" xref="alg1.l20.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l20.m1.1.1.1.1.1.1.2" xref="alg1.l20.m1.1.1.1.1.1.1.2.cmml">w</mi><mrow id="alg1.l20.m1.1.1.1.1.1.1.3" xref="alg1.l20.m1.1.1.1.1.1.1.3.cmml"><mi id="alg1.l20.m1.1.1.1.1.1.1.3.2" xref="alg1.l20.m1.1.1.1.1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l20.m1.1.1.1.1.1.1.3.1" xref="alg1.l20.m1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="alg1.l20.m1.1.1.1.1.1.1.3.3" xref="alg1.l20.m1.1.1.1.1.1.1.3.3.cmml">g</mi></mrow></msub><mo stretchy="false" id="alg1.l20.m1.1.1.1.1.1.3" xref="alg1.l20.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l20.m1.1.1.2" xref="alg1.l20.m1.1.1.2.cmml">&gt;</mo><mn id="alg1.l20.m1.1.1.3" xref="alg1.l20.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l20.m1.1b"><apply id="alg1.l20.m1.1.1.cmml" xref="alg1.l20.m1.1.1"><gt id="alg1.l20.m1.1.1.2.cmml" xref="alg1.l20.m1.1.1.2"></gt><apply id="alg1.l20.m1.1.1.1.cmml" xref="alg1.l20.m1.1.1.1"><times id="alg1.l20.m1.1.1.1.2.cmml" xref="alg1.l20.m1.1.1.1.2"></times><ci id="alg1.l20.m1.1.1.1.3.cmml" xref="alg1.l20.m1.1.1.1.3">𝑚</ci><ci id="alg1.l20.m1.1.1.1.4.cmml" xref="alg1.l20.m1.1.1.1.4">𝑒</ci><ci id="alg1.l20.m1.1.1.1.5.cmml" xref="alg1.l20.m1.1.1.1.5">𝑎</ci><ci id="alg1.l20.m1.1.1.1.6.cmml" xref="alg1.l20.m1.1.1.1.6">𝑛</ci><apply id="alg1.l20.m1.1.1.1.1.1.1.cmml" xref="alg1.l20.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l20.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l20.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l20.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l20.m1.1.1.1.1.1.1.2">𝑤</ci><apply id="alg1.l20.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l20.m1.1.1.1.1.1.1.3"><times id="alg1.l20.m1.1.1.1.1.1.1.3.1.cmml" xref="alg1.l20.m1.1.1.1.1.1.1.3.1"></times><ci id="alg1.l20.m1.1.1.1.1.1.1.3.2.cmml" xref="alg1.l20.m1.1.1.1.1.1.1.3.2">𝑝</ci><ci id="alg1.l20.m1.1.1.1.1.1.1.3.3.cmml" xref="alg1.l20.m1.1.1.1.1.1.1.3.3">𝑔</ci></apply></apply></apply><cn type="integer" id="alg1.l20.m1.1.1.3.cmml" xref="alg1.l20.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l20.m1.1c">mean(w_{pg})&gt;0</annotation></semantics></math> <span id="alg1.l20.3" class="ltx_text ltx_font_bold">then</span>

</div>
<div id="alg1.l21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l21.1.1.1" class="ltx_text" style="font-size:80%;">21:</span></span>         <math id="alg1.l21.m1.1" class="ltx_Math" alttext="R_{B}[s]=1" display="inline"><semantics id="alg1.l21.m1.1a"><mrow id="alg1.l21.m1.1.2" xref="alg1.l21.m1.1.2.cmml"><mrow id="alg1.l21.m1.1.2.2" xref="alg1.l21.m1.1.2.2.cmml"><msub id="alg1.l21.m1.1.2.2.2" xref="alg1.l21.m1.1.2.2.2.cmml"><mi id="alg1.l21.m1.1.2.2.2.2" xref="alg1.l21.m1.1.2.2.2.2.cmml">R</mi><mi id="alg1.l21.m1.1.2.2.2.3" xref="alg1.l21.m1.1.2.2.2.3.cmml">B</mi></msub><mo lspace="0em" rspace="0em" id="alg1.l21.m1.1.2.2.1" xref="alg1.l21.m1.1.2.2.1.cmml">​</mo><mrow id="alg1.l21.m1.1.2.2.3.2" xref="alg1.l21.m1.1.2.2.3.1.cmml"><mo stretchy="false" id="alg1.l21.m1.1.2.2.3.2.1" xref="alg1.l21.m1.1.2.2.3.1.1.cmml">[</mo><mi id="alg1.l21.m1.1.1" xref="alg1.l21.m1.1.1.cmml">s</mi><mo stretchy="false" id="alg1.l21.m1.1.2.2.3.2.2" xref="alg1.l21.m1.1.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l21.m1.1.2.1" xref="alg1.l21.m1.1.2.1.cmml">=</mo><mn id="alg1.l21.m1.1.2.3" xref="alg1.l21.m1.1.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l21.m1.1b"><apply id="alg1.l21.m1.1.2.cmml" xref="alg1.l21.m1.1.2"><eq id="alg1.l21.m1.1.2.1.cmml" xref="alg1.l21.m1.1.2.1"></eq><apply id="alg1.l21.m1.1.2.2.cmml" xref="alg1.l21.m1.1.2.2"><times id="alg1.l21.m1.1.2.2.1.cmml" xref="alg1.l21.m1.1.2.2.1"></times><apply id="alg1.l21.m1.1.2.2.2.cmml" xref="alg1.l21.m1.1.2.2.2"><csymbol cd="ambiguous" id="alg1.l21.m1.1.2.2.2.1.cmml" xref="alg1.l21.m1.1.2.2.2">subscript</csymbol><ci id="alg1.l21.m1.1.2.2.2.2.cmml" xref="alg1.l21.m1.1.2.2.2.2">𝑅</ci><ci id="alg1.l21.m1.1.2.2.2.3.cmml" xref="alg1.l21.m1.1.2.2.2.3">𝐵</ci></apply><apply id="alg1.l21.m1.1.2.2.3.1.cmml" xref="alg1.l21.m1.1.2.2.3.2"><csymbol cd="latexml" id="alg1.l21.m1.1.2.2.3.1.1.cmml" xref="alg1.l21.m1.1.2.2.3.2.1">delimited-[]</csymbol><ci id="alg1.l21.m1.1.1.cmml" xref="alg1.l21.m1.1.1">𝑠</ci></apply></apply><cn type="integer" id="alg1.l21.m1.1.2.3.cmml" xref="alg1.l21.m1.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m1.1c">R_{B}[s]=1</annotation></semantics></math>;

</div>
<div id="alg1.l22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l22.1.1.1" class="ltx_text" style="font-size:80%;">22:</span></span>     <span id="alg1.l22.2" class="ltx_text ltx_font_bold">else</span>
</div>
<div id="alg1.l23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l23.1.1.1" class="ltx_text" style="font-size:80%;">23:</span></span>         <math id="alg1.l23.m1.1" class="ltx_Math" alttext="R_{B}[s]=0" display="inline"><semantics id="alg1.l23.m1.1a"><mrow id="alg1.l23.m1.1.2" xref="alg1.l23.m1.1.2.cmml"><mrow id="alg1.l23.m1.1.2.2" xref="alg1.l23.m1.1.2.2.cmml"><msub id="alg1.l23.m1.1.2.2.2" xref="alg1.l23.m1.1.2.2.2.cmml"><mi id="alg1.l23.m1.1.2.2.2.2" xref="alg1.l23.m1.1.2.2.2.2.cmml">R</mi><mi id="alg1.l23.m1.1.2.2.2.3" xref="alg1.l23.m1.1.2.2.2.3.cmml">B</mi></msub><mo lspace="0em" rspace="0em" id="alg1.l23.m1.1.2.2.1" xref="alg1.l23.m1.1.2.2.1.cmml">​</mo><mrow id="alg1.l23.m1.1.2.2.3.2" xref="alg1.l23.m1.1.2.2.3.1.cmml"><mo stretchy="false" id="alg1.l23.m1.1.2.2.3.2.1" xref="alg1.l23.m1.1.2.2.3.1.1.cmml">[</mo><mi id="alg1.l23.m1.1.1" xref="alg1.l23.m1.1.1.cmml">s</mi><mo stretchy="false" id="alg1.l23.m1.1.2.2.3.2.2" xref="alg1.l23.m1.1.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l23.m1.1.2.1" xref="alg1.l23.m1.1.2.1.cmml">=</mo><mn id="alg1.l23.m1.1.2.3" xref="alg1.l23.m1.1.2.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l23.m1.1b"><apply id="alg1.l23.m1.1.2.cmml" xref="alg1.l23.m1.1.2"><eq id="alg1.l23.m1.1.2.1.cmml" xref="alg1.l23.m1.1.2.1"></eq><apply id="alg1.l23.m1.1.2.2.cmml" xref="alg1.l23.m1.1.2.2"><times id="alg1.l23.m1.1.2.2.1.cmml" xref="alg1.l23.m1.1.2.2.1"></times><apply id="alg1.l23.m1.1.2.2.2.cmml" xref="alg1.l23.m1.1.2.2.2"><csymbol cd="ambiguous" id="alg1.l23.m1.1.2.2.2.1.cmml" xref="alg1.l23.m1.1.2.2.2">subscript</csymbol><ci id="alg1.l23.m1.1.2.2.2.2.cmml" xref="alg1.l23.m1.1.2.2.2.2">𝑅</ci><ci id="alg1.l23.m1.1.2.2.2.3.cmml" xref="alg1.l23.m1.1.2.2.2.3">𝐵</ci></apply><apply id="alg1.l23.m1.1.2.2.3.1.cmml" xref="alg1.l23.m1.1.2.2.3.2"><csymbol cd="latexml" id="alg1.l23.m1.1.2.2.3.1.1.cmml" xref="alg1.l23.m1.1.2.2.3.2.1">delimited-[]</csymbol><ci id="alg1.l23.m1.1.1.cmml" xref="alg1.l23.m1.1.1">𝑠</ci></apply></apply><cn type="integer" id="alg1.l23.m1.1.2.3.cmml" xref="alg1.l23.m1.1.2.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l23.m1.1c">R_{B}[s]=0</annotation></semantics></math>;

</div>
<div id="alg1.l24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l24.1.1.1" class="ltx_text" style="font-size:80%;">24:</span></span>     <span id="alg1.l24.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l24.3" class="ltx_text ltx_font_bold">if</span>
</div>
<div id="alg1.l25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l25.1.1.1" class="ltx_text" style="font-size:80%;">25:</span></span><span id="alg1.l25.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l25.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l26.1.1.1" class="ltx_text" style="font-size:80%;">26:</span></span><span id="alg1.l26.2" class="ltx_text ltx_font_bold">return</span> <math id="alg1.l26.m1.1" class="ltx_Math" alttext="R_{B}" display="inline"><semantics id="alg1.l26.m1.1a"><msub id="alg1.l26.m1.1.1" xref="alg1.l26.m1.1.1.cmml"><mi id="alg1.l26.m1.1.1.2" xref="alg1.l26.m1.1.1.2.cmml">R</mi><mi id="alg1.l26.m1.1.1.3" xref="alg1.l26.m1.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l26.m1.1b"><apply id="alg1.l26.m1.1.1.cmml" xref="alg1.l26.m1.1.1"><csymbol cd="ambiguous" id="alg1.l26.m1.1.1.1.cmml" xref="alg1.l26.m1.1.1">subscript</csymbol><ci id="alg1.l26.m1.1.1.2.cmml" xref="alg1.l26.m1.1.1.2">𝑅</ci><ci id="alg1.l26.m1.1.1.3.cmml" xref="alg1.l26.m1.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l26.m1.1c">R_{B}</annotation></semantics></math>

</div>
</div>
</figure>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.5" class="ltx_p">As shown in Algorithm 1, <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="w_{p}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">w</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝑤</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">w_{p}</annotation></semantics></math> is the weight that the sender and receiver agree to use to transmit the message. The <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="w_{pl}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">w</mi><mrow id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml"><mi id="S3.SS3.p3.2.m2.1.1.3.2" xref="S3.SS3.p3.2.m2.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.3.1" xref="S3.SS3.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.3.3" xref="S3.SS3.p3.2.m2.1.1.3.3.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">𝑤</ci><apply id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3"><times id="S3.SS3.p3.2.m2.1.1.3.1.cmml" xref="S3.SS3.p3.2.m2.1.1.3.1"></times><ci id="S3.SS3.p3.2.m2.1.1.3.2.cmml" xref="S3.SS3.p3.2.m2.1.1.3.2">𝑝</ci><ci id="S3.SS3.p3.2.m2.1.1.3.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">w_{pl}</annotation></semantics></math> is the sender’s local weight, which is the same location and size as <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="w_{p}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">w</mi><mi id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝑤</ci><ci id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">w_{p}</annotation></semantics></math>. And the <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="w_{pg}" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">w</mi><mrow id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml"><mi id="S3.SS3.p3.4.m4.1.1.3.2" xref="S3.SS3.p3.4.m4.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.4.m4.1.1.3.1" xref="S3.SS3.p3.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.4.m4.1.1.3.3" xref="S3.SS3.p3.4.m4.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">𝑤</ci><apply id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3"><times id="S3.SS3.p3.4.m4.1.1.3.1.cmml" xref="S3.SS3.p3.4.m4.1.1.3.1"></times><ci id="S3.SS3.p3.4.m4.1.1.3.2.cmml" xref="S3.SS3.p3.4.m4.1.1.3.2">𝑝</ci><ci id="S3.SS3.p3.4.m4.1.1.3.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">w_{pg}</annotation></semantics></math> is the global weight, which is the same location and size as <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="w_{p}" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><msub id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml"><mi id="S3.SS3.p3.5.m5.1.1.2" xref="S3.SS3.p3.5.m5.1.1.2.cmml">w</mi><mi id="S3.SS3.p3.5.m5.1.1.3" xref="S3.SS3.p3.5.m5.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2">𝑤</ci><ci id="S3.SS3.p3.5.m5.1.1.3.cmml" xref="S3.SS3.p3.5.m5.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">w_{p}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.3" class="ltx_p">Lines 1-2. The message is sent in cycles of <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="S_{N}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">S</mi><mi id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">N</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">𝑆</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">S_{N}</annotation></semantics></math>, and <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">n</annotation></semantics></math> is the total round in <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="s_{i}" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><msub id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><mi id="S3.SS3.p4.3.m3.1.1.2" xref="S3.SS3.p4.3.m3.1.1.2.cmml">s</mi><mi id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2">𝑠</ci><ci id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">s_{i}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p">Lines 3-4. The sender embeds the message into the model weights agreed on in advance. This step is repeated in one cycle.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.1" class="ltx_p">Lines 5-6. The sender uses the remaining weights to train the model.</p>
</div>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p">Lines 8-9. Benign client training model.</p>
</div>
<div id="S3.SS3.p8" class="ltx_para">
<p id="S3.SS3.p8.1" class="ltx_p">Lines 11-12. The server aggregates the model updates from all clients and sends the new global model to each client.</p>
</div>
<div id="S3.SS3.p9" class="ltx_para">
<p id="S3.SS3.p9.1" class="ltx_p">Lines 13-14. The receiver records the weight value <math id="S3.SS3.p9.1.m1.1" class="ltx_Math" alttext="w_{p}" display="inline"><semantics id="S3.SS3.p9.1.m1.1a"><msub id="S3.SS3.p9.1.m1.1.1" xref="S3.SS3.p9.1.m1.1.1.cmml"><mi id="S3.SS3.p9.1.m1.1.1.2" xref="S3.SS3.p9.1.m1.1.1.2.cmml">w</mi><mi id="S3.SS3.p9.1.m1.1.1.3" xref="S3.SS3.p9.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p9.1.m1.1b"><apply id="S3.SS3.p9.1.m1.1.1.cmml" xref="S3.SS3.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p9.1.m1.1.1.1.cmml" xref="S3.SS3.p9.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p9.1.m1.1.1.2.cmml" xref="S3.SS3.p9.1.m1.1.1.2">𝑤</ci><ci id="S3.SS3.p9.1.m1.1.1.3.cmml" xref="S3.SS3.p9.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p9.1.m1.1c">w_{p}</annotation></semantics></math> of the agreed position p from the global model and stores it.</p>
</div>
<div id="S3.SS3.p10" class="ltx_para">
<p id="S3.SS3.p10.2" class="ltx_p">Lines 16-24. The receiver calculates the mean <math id="S3.SS3.p10.1.m1.1" class="ltx_Math" alttext="w_{pg}" display="inline"><semantics id="S3.SS3.p10.1.m1.1a"><msub id="S3.SS3.p10.1.m1.1.1" xref="S3.SS3.p10.1.m1.1.1.cmml"><mi id="S3.SS3.p10.1.m1.1.1.2" xref="S3.SS3.p10.1.m1.1.1.2.cmml">w</mi><mrow id="S3.SS3.p10.1.m1.1.1.3" xref="S3.SS3.p10.1.m1.1.1.3.cmml"><mi id="S3.SS3.p10.1.m1.1.1.3.2" xref="S3.SS3.p10.1.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p10.1.m1.1.1.3.1" xref="S3.SS3.p10.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p10.1.m1.1.1.3.3" xref="S3.SS3.p10.1.m1.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p10.1.m1.1b"><apply id="S3.SS3.p10.1.m1.1.1.cmml" xref="S3.SS3.p10.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p10.1.m1.1.1.1.cmml" xref="S3.SS3.p10.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p10.1.m1.1.1.2.cmml" xref="S3.SS3.p10.1.m1.1.1.2">𝑤</ci><apply id="S3.SS3.p10.1.m1.1.1.3.cmml" xref="S3.SS3.p10.1.m1.1.1.3"><times id="S3.SS3.p10.1.m1.1.1.3.1.cmml" xref="S3.SS3.p10.1.m1.1.1.3.1"></times><ci id="S3.SS3.p10.1.m1.1.1.3.2.cmml" xref="S3.SS3.p10.1.m1.1.1.3.2">𝑝</ci><ci id="S3.SS3.p10.1.m1.1.1.3.3.cmml" xref="S3.SS3.p10.1.m1.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p10.1.m1.1c">w_{pg}</annotation></semantics></math> and decodes the message bits as follows. In one cycle if mean <math id="S3.SS3.p10.2.m2.1" class="ltx_Math" alttext="w_{pg}&gt;0" display="inline"><semantics id="S3.SS3.p10.2.m2.1a"><mrow id="S3.SS3.p10.2.m2.1.1" xref="S3.SS3.p10.2.m2.1.1.cmml"><msub id="S3.SS3.p10.2.m2.1.1.2" xref="S3.SS3.p10.2.m2.1.1.2.cmml"><mi id="S3.SS3.p10.2.m2.1.1.2.2" xref="S3.SS3.p10.2.m2.1.1.2.2.cmml">w</mi><mrow id="S3.SS3.p10.2.m2.1.1.2.3" xref="S3.SS3.p10.2.m2.1.1.2.3.cmml"><mi id="S3.SS3.p10.2.m2.1.1.2.3.2" xref="S3.SS3.p10.2.m2.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p10.2.m2.1.1.2.3.1" xref="S3.SS3.p10.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p10.2.m2.1.1.2.3.3" xref="S3.SS3.p10.2.m2.1.1.2.3.3.cmml">g</mi></mrow></msub><mo id="S3.SS3.p10.2.m2.1.1.1" xref="S3.SS3.p10.2.m2.1.1.1.cmml">&gt;</mo><mn id="S3.SS3.p10.2.m2.1.1.3" xref="S3.SS3.p10.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p10.2.m2.1b"><apply id="S3.SS3.p10.2.m2.1.1.cmml" xref="S3.SS3.p10.2.m2.1.1"><gt id="S3.SS3.p10.2.m2.1.1.1.cmml" xref="S3.SS3.p10.2.m2.1.1.1"></gt><apply id="S3.SS3.p10.2.m2.1.1.2.cmml" xref="S3.SS3.p10.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p10.2.m2.1.1.2.1.cmml" xref="S3.SS3.p10.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p10.2.m2.1.1.2.2.cmml" xref="S3.SS3.p10.2.m2.1.1.2.2">𝑤</ci><apply id="S3.SS3.p10.2.m2.1.1.2.3.cmml" xref="S3.SS3.p10.2.m2.1.1.2.3"><times id="S3.SS3.p10.2.m2.1.1.2.3.1.cmml" xref="S3.SS3.p10.2.m2.1.1.2.3.1"></times><ci id="S3.SS3.p10.2.m2.1.1.2.3.2.cmml" xref="S3.SS3.p10.2.m2.1.1.2.3.2">𝑝</ci><ci id="S3.SS3.p10.2.m2.1.1.2.3.3.cmml" xref="S3.SS3.p10.2.m2.1.1.2.3.3">𝑔</ci></apply></apply><cn type="integer" id="S3.SS3.p10.2.m2.1.1.3.cmml" xref="S3.SS3.p10.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p10.2.m2.1c">w_{pg}&gt;0</annotation></semantics></math>, the bit is set to 1, otherwise, it is set to 0.</p>
</div>
<div id="S3.SS3.p11" class="ltx_para">
<p id="S3.SS3.p11.1" class="ltx_p">The decoded message is then compared with the original bit sequence to obtain the received message <math id="S3.SS3.p11.1.m1.1" class="ltx_Math" alttext="R_{B}" display="inline"><semantics id="S3.SS3.p11.1.m1.1a"><msub id="S3.SS3.p11.1.m1.1.1" xref="S3.SS3.p11.1.m1.1.1.cmml"><mi id="S3.SS3.p11.1.m1.1.1.2" xref="S3.SS3.p11.1.m1.1.1.2.cmml">R</mi><mi id="S3.SS3.p11.1.m1.1.1.3" xref="S3.SS3.p11.1.m1.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p11.1.m1.1b"><apply id="S3.SS3.p11.1.m1.1.1.cmml" xref="S3.SS3.p11.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p11.1.m1.1.1.1.cmml" xref="S3.SS3.p11.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p11.1.m1.1.1.2.cmml" xref="S3.SS3.p11.1.m1.1.1.2">𝑅</ci><ci id="S3.SS3.p11.1.m1.1.1.3.cmml" xref="S3.SS3.p11.1.m1.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p11.1.m1.1c">R_{B}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p12" class="ltx_para">
<p id="S3.SS3.p12.1" class="ltx_p">By controlling the direction of the weight updates in this way, the sender can embed their message in the model updates and have it transmitted through the server to the receiver shown as in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.3. Attack Method ‣ 3. Proposed Attack Method ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>The variation of selected weights <math id="S3.F2.2.m1.1" class="ltx_Math" alttext="w_{pg}" display="inline"><semantics id="S3.F2.2.m1.1b"><msub id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml"><mi id="S3.F2.2.m1.1.1.2" xref="S3.F2.2.m1.1.1.2.cmml">w</mi><mrow id="S3.F2.2.m1.1.1.3" xref="S3.F2.2.m1.1.1.3.cmml"><mi id="S3.F2.2.m1.1.1.3.2" xref="S3.F2.2.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.F2.2.m1.1.1.3.1" xref="S3.F2.2.m1.1.1.3.1.cmml">​</mo><mi id="S3.F2.2.m1.1.1.3.3" xref="S3.F2.2.m1.1.1.3.3.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><apply id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.2.m1.1.1.1.cmml" xref="S3.F2.2.m1.1.1">subscript</csymbol><ci id="S3.F2.2.m1.1.1.2.cmml" xref="S3.F2.2.m1.1.1.2">𝑤</ci><apply id="S3.F2.2.m1.1.1.3.cmml" xref="S3.F2.2.m1.1.1.3"><times id="S3.F2.2.m1.1.1.3.1.cmml" xref="S3.F2.2.m1.1.1.3.1"></times><ci id="S3.F2.2.m1.1.1.3.2.cmml" xref="S3.F2.2.m1.1.1.3.2">𝑝</ci><ci id="S3.F2.2.m1.1.1.3.3.cmml" xref="S3.F2.2.m1.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">w_{pg}</annotation></semantics></math> in the global model.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S3.F2.3" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.F2.4" class="ltx_p ltx_figure_panel ltx_align_center">The variation of selected weights in the global model.</p>
</div>
</div>
</figure>
<div id="S3.SS3.p13" class="ltx_para">
<p id="S3.SS3.p13.1" class="ltx_p">This process allows for covert communication between two clients in federated learning through the poisoning attack, where the message bits are encoded in specific model weight and transmitted through the server difficult to be detected by other clients or the server. The mean of the recorded position-specific weights is used to decode the message, and the message capacity can be controlled by the number of rounds and the number of positions used for encoding the bits. As shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.3. Attack Method ‣ 3. Proposed Attack Method ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the blue line is the normal weight change curve, while the red line is the weight change curve used to transmit the information. The receiver gets the bit value by calculating the sum of the vertical coordinates of the curve in one cycle. If the value of the vertical coordinate in this cycle is greater than 0, then its bit value is 1, and otherwise, it is 0. It should be noted that the two red curves here are only 2 weights.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>More Covert Communication</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We propose the following techniques to increase the difficulty of detecting covert communication between two clients in federated learning.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p"><span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_bold">Random selection of weights.</span> Instead of using a fixed position in the model weights to encode the message bits, the sender and the receiver can randomly select the weights for the first round. Note, however, that the random selection here is chosen jointly by the message sender and the receiver in advance at random. That is, the position of the weights of these transmitted messages does not change during the training process. Attention is paid to the fact that the upper limit of the number of weights chosen should have a small impact on the model performance.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_bold">Multiplication of factor.</span> To further mask the poisoned data and make it indistinguishable from benign data, the sender can multiply a factor when modifying the weights during poisoning. We propose using the root mean square <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="(RMS)" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><mrow id="S3.SS4.p3.1.m1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p3.1.m1.1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.SS4.p3.1.m1.1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS4.p3.1.m1.1.1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS4.p3.1.m1.1.1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.1.1.1a" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS4.p3.1.m1.1.1.1.1.4" xref="S3.SS4.p3.1.m1.1.1.1.1.4.cmml">S</mi></mrow><mo stretchy="false" id="S3.SS4.p3.1.m1.1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1"><times id="S3.SS4.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1"></times><ci id="S3.SS4.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.2">𝑅</ci><ci id="S3.SS4.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.3">𝑀</ci><ci id="S3.SS4.p3.1.m1.1.1.1.1.4.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.4">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">(RMS)</annotation></semantics></math> of 500 randomly selected weight values as the factor. It captures the variation in the weight distribution and reduces the distinguishability between the poisoned and benign data.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p"><span id="S3.SS4.p4.1.1" class="ltx_text ltx_font_bold">Zeroing back of weights.</span> Randomly initialized weights can introduce noise and interfere with the covert communication signal. To mitigate this, we propose zeroing back the weights to their initial values of 10 rounds (or another number of rounds) before sending the signal, so that the signal is less affected by the random initialization and the communication is more covert.
By using these techniques, covert communication can be further improved in terms of stealthiness and resilience to detection, while maintaining a sufficient communication capacity and minimizing the impact on the federated learning process.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Analysis of Proposed Attack</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Higher Communication Capacity</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">To achieve greater communication capacity in covert communication between two clients in federated learning, we propose several improvement methods as follows. These methods can be used in combination or individually.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Using more weights.</span> The current neural network parameters are often large and using only one weight to encode the message bits can limit the communication capacity. By selecting more weights for each round of poisoning, more bits can be transmitted over a longer time. For example, using 1000 weights and 20 rounds per cycle, we can send up to 10,000 bits of data in 200 rounds. This shows that adding more weights can increase communication capacity and improve covert communication performance. Note that the number of weights selected should not significantly affect the model performance.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Faster sending frequency.</span> The transmission speed can be doubled by decreasing the number of rounds per cycle from 20 to 10. The number of rounds can be so small that only 1 round is needed. If you send 2,000 bits per cycle, you can send 200,000 bits in 100 cycles when the cycle is equal to 1 round.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Better reception mechanism.</span> Instead of comparing the weight value at the agreed position with 0 to determine the bit of the accepted data, we can use the average value of the recorded position-specific weights as the comparison threshold. This has the advantage of being more covert, and more accurate.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">By using these techniques, the communication capacity of covert communication attacks in federated learning can be significantly increased, while maintaining a low detection rate and a high level of security.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Covert Channel Bandwidth</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To calculate the channel bandwidth for secret communication in joint learning, we need to consider several factors such as the number of weights used for transmission and the transmission cycle. Based on the assumptions provided, we can estimate the channel bandwidth as follows.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">We use 1,000 weights to transmit the message, and each weight can successfully transmit 1 bit every 20 rounds. This means that in one cycle of 20 rounds, we can transmit 1,000 bits of information.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.2" class="ltx_p">If we assume that the training process in federated learning lasts for <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">T</annotation></semantics></math> rounds, then we can transmit <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="T/20" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">T</mi><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">/</mo><mn id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><divide id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"></divide><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">𝑇</ci><cn type="integer" id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">T/20</annotation></semantics></math> cycles of information during the training process.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.3" class="ltx_p">Therefore, the total amount of information that can be transmitted covertly during the training process is <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="B=(T/20)\times 1000" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mrow id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">B</mi><mo id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml">=</mo><mrow id="S4.SS2.p4.1.m1.1.1.1" xref="S4.SS2.p4.1.m1.1.1.1.cmml"><mrow id="S4.SS2.p4.1.m1.1.1.1.1.1" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p4.1.m1.1.1.1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p4.1.m1.1.1.1.1.1.1" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.1.1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.2.cmml">T</mi><mo id="S4.SS2.p4.1.m1.1.1.1.1.1.1.1" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.1.cmml">/</mo><mn id="S4.SS2.p4.1.m1.1.1.1.1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.3.cmml">20</mn></mrow><mo rspace="0.055em" stretchy="false" id="S4.SS2.p4.1.m1.1.1.1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.SS2.p4.1.m1.1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.1.2.cmml">×</mo><mn id="S4.SS2.p4.1.m1.1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.1.3.cmml">1000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><eq id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2"></eq><ci id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3">𝐵</ci><apply id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1.1"><times id="S4.SS2.p4.1.m1.1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.1.2"></times><apply id="S4.SS2.p4.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1.1.1.1"><divide id="S4.SS2.p4.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.1"></divide><ci id="S4.SS2.p4.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.2">𝑇</ci><cn type="integer" id="S4.SS2.p4.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.1.1.1.1.3">20</cn></apply><cn type="integer" id="S4.SS2.p4.1.m1.1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.1.3">1000</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">B=(T/20)\times 1000</annotation></semantics></math> bits.
The channel bandwidth is the rate at which we can transmit this information over time and is given by the formula <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="R=B/T" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mrow id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">R</mi><mo id="S4.SS2.p4.2.m2.1.1.1" xref="S4.SS2.p4.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml"><mi id="S4.SS2.p4.2.m2.1.1.3.2" xref="S4.SS2.p4.2.m2.1.1.3.2.cmml">B</mi><mo id="S4.SS2.p4.2.m2.1.1.3.1" xref="S4.SS2.p4.2.m2.1.1.3.1.cmml">/</mo><mi id="S4.SS2.p4.2.m2.1.1.3.3" xref="S4.SS2.p4.2.m2.1.1.3.3.cmml">T</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><eq id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1.1"></eq><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">𝑅</ci><apply id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3"><divide id="S4.SS2.p4.2.m2.1.1.3.1.cmml" xref="S4.SS2.p4.2.m2.1.1.3.1"></divide><ci id="S4.SS2.p4.2.m2.1.1.3.2.cmml" xref="S4.SS2.p4.2.m2.1.1.3.2">𝐵</ci><ci id="S4.SS2.p4.2.m2.1.1.3.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">R=B/T</annotation></semantics></math>, where <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mi id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><ci id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">R</annotation></semantics></math> is the channel bandwidth in bits per round.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">Plugging in the above values, we get <math id="S4.SS2.p5.1.m1.1" class="ltx_Math" alttext="R=(T/20)\times 1000/T=50" display="inline"><semantics id="S4.SS2.p5.1.m1.1a"><mrow id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml"><mi id="S4.SS2.p5.1.m1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.3.cmml">R</mi><mo id="S4.SS2.p5.1.m1.1.1.4" xref="S4.SS2.p5.1.m1.1.1.4.cmml">=</mo><mrow id="S4.SS2.p5.1.m1.1.1.1" xref="S4.SS2.p5.1.m1.1.1.1.cmml"><mrow id="S4.SS2.p5.1.m1.1.1.1.1" xref="S4.SS2.p5.1.m1.1.1.1.1.cmml"><mrow id="S4.SS2.p5.1.m1.1.1.1.1.1.1" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p5.1.m1.1.1.1.1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.2.cmml">T</mi><mo id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.1" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.1.cmml">/</mo><mn id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.3.cmml">20</mn></mrow><mo rspace="0.055em" stretchy="false" id="S4.SS2.p5.1.m1.1.1.1.1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.SS2.p5.1.m1.1.1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.1.1.2.cmml">×</mo><mn id="S4.SS2.p5.1.m1.1.1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.1.1.3.cmml">1000</mn></mrow><mo id="S4.SS2.p5.1.m1.1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.1.2.cmml">/</mo><mi id="S4.SS2.p5.1.m1.1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.1.3.cmml">T</mi></mrow><mo id="S4.SS2.p5.1.m1.1.1.5" xref="S4.SS2.p5.1.m1.1.1.5.cmml">=</mo><mn id="S4.SS2.p5.1.m1.1.1.6" xref="S4.SS2.p5.1.m1.1.1.6.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><apply id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1"><and id="S4.SS2.p5.1.m1.1.1a.cmml" xref="S4.SS2.p5.1.m1.1.1"></and><apply id="S4.SS2.p5.1.m1.1.1b.cmml" xref="S4.SS2.p5.1.m1.1.1"><eq id="S4.SS2.p5.1.m1.1.1.4.cmml" xref="S4.SS2.p5.1.m1.1.1.4"></eq><ci id="S4.SS2.p5.1.m1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3">𝑅</ci><apply id="S4.SS2.p5.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1.1"><divide id="S4.SS2.p5.1.m1.1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.1.2"></divide><apply id="S4.SS2.p5.1.m1.1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1.1.1"><times id="S4.SS2.p5.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.1.1.2"></times><apply id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1"><divide id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.1"></divide><ci id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.2">𝑇</ci><cn type="integer" id="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.1.1.1.1.1.3">20</cn></apply><cn type="integer" id="S4.SS2.p5.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.1.1.3">1000</cn></apply><ci id="S4.SS2.p5.1.m1.1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.1.3">𝑇</ci></apply></apply><apply id="S4.SS2.p5.1.m1.1.1c.cmml" xref="S4.SS2.p5.1.m1.1.1"><eq id="S4.SS2.p5.1.m1.1.1.5.cmml" xref="S4.SS2.p5.1.m1.1.1.5"></eq><share href="#S4.SS2.p5.1.m1.1.1.1.cmml" id="S4.SS2.p5.1.m1.1.1d.cmml" xref="S4.SS2.p5.1.m1.1.1"></share><cn type="integer" id="S4.SS2.p5.1.m1.1.1.6.cmml" xref="S4.SS2.p5.1.m1.1.1.6">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">R=(T/20)\times 1000/T=50</annotation></semantics></math> bits per round.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p">This means that, on average, we can transmit 50 bits of covert information per round of training in federated learning, using the given assumptions. In the same 200 rounds, we can achieve 10,000-bit information transmissions.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Evaluation Metrics</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">In our evaluation of the proposed covert communication method, we use the following four metrics.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Model accuracy.</span> The accuracy of the federated learning model is an important factor to consider when evaluating the effectiveness of a covert communication attack. We consider both the global model accuracy and local model accuracy in our evaluation. The global model accuracy is the accuracy of the model tested by the server after aggregating all client models, while the local model accuracy is the accuracy of each client model tested by the server. We assume that the server has a validation dataset in <cite class="ltx_cite ltx_citemacro_citep">(Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>; Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; Mallah
et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> and could test each uploaded local model accuracy and global model accuracy at every round. By comparing the accuracy of the model before and after the covert communication process, we can evaluate the impact of covert communication on model accuracy.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">Stealthiness.</span> The goal of covert communication is to make the communication undetectable. Therefore, measuring the degree to which the attacker’s communication is covert is an important evaluation metric. We use the L2-norm-based in <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite> approach and the cosine similarity in <cite class="ltx_cite ltx_citemacro_citep">(Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>; Nguyen
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite> to evaluate the weights similarity between the attacker and the benign clients. The L2-norm-based approach calculates the Euclidean distance between two sets of weights, while the cosine similarity measures the angle between the two weight vectors. By comparing the L2-norm or cosine similarity between the attacker and benign clients, we can evaluate the level of stealthiness.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.3" class="ltx_p"><span id="S5.SS1.p4.3.1" class="ltx_text ltx_font_bold">Robustness.</span> The ability to resist noise-based and perturbation-based defenses [15, 16] is an important factor to consider when evaluating the effectiveness of convert communication attacks. If a covert communication method is easily disrupted by noise or defenses, it may not be a viable technique for real-world applications. We assume that the server adds noise to the model uploaded by the attacker in each round and evaluates the level of noise using <math id="S5.SS1.p4.1.m1.1" class="ltx_Math" alttext="N_{l}" display="inline"><semantics id="S5.SS1.p4.1.m1.1a"><msub id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml"><mi id="S5.SS1.p4.1.m1.1.1.2" xref="S5.SS1.p4.1.m1.1.1.2.cmml">N</mi><mi id="S5.SS1.p4.1.m1.1.1.3" xref="S5.SS1.p4.1.m1.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><apply id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.1.m1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p4.1.m1.1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.1.2">𝑁</ci><ci id="S5.SS1.p4.1.m1.1.1.3.cmml" xref="S5.SS1.p4.1.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">N_{l}</annotation></semantics></math>. If <math id="S5.SS1.p4.2.m2.1" class="ltx_Math" alttext="N_{l}" display="inline"><semantics id="S5.SS1.p4.2.m2.1a"><msub id="S5.SS1.p4.2.m2.1.1" xref="S5.SS1.p4.2.m2.1.1.cmml"><mi id="S5.SS1.p4.2.m2.1.1.2" xref="S5.SS1.p4.2.m2.1.1.2.cmml">N</mi><mi id="S5.SS1.p4.2.m2.1.1.3" xref="S5.SS1.p4.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.1b"><apply id="S5.SS1.p4.2.m2.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.2.m2.1.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p4.2.m2.1.1.2.cmml" xref="S5.SS1.p4.2.m2.1.1.2">𝑁</ci><ci id="S5.SS1.p4.2.m2.1.1.3.cmml" xref="S5.SS1.p4.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.1c">N_{l}</annotation></semantics></math> is equal to 0, it means that there is no additional random Gaussian noise in the model parameters. If <math id="S5.SS1.p4.3.m3.1" class="ltx_Math" alttext="N_{l}" display="inline"><semantics id="S5.SS1.p4.3.m3.1a"><msub id="S5.SS1.p4.3.m3.1.1" xref="S5.SS1.p4.3.m3.1.1.cmml"><mi id="S5.SS1.p4.3.m3.1.1.2" xref="S5.SS1.p4.3.m3.1.1.2.cmml">N</mi><mi id="S5.SS1.p4.3.m3.1.1.3" xref="S5.SS1.p4.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.3.m3.1b"><apply id="S5.SS1.p4.3.m3.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.3.m3.1.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p4.3.m3.1.1.2.cmml" xref="S5.SS1.p4.3.m3.1.1.2">𝑁</ci><ci id="S5.SS1.p4.3.m3.1.1.3.cmml" xref="S5.SS1.p4.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.3.m3.1c">N_{l}</annotation></semantics></math> is equal to 1, it means that the model parameters are all random Gaussian noise. By measuring the robustness of our covert communication method, we can assess its ability to resist noise and perturbation-based defenses.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p id="S5.SS1.p5.1" class="ltx_p"><span id="S5.SS1.p5.1.1" class="ltx_text ltx_font_bold">Successful receive time.</span> The time the receiver successfully receives all the covert messages sent by the attacker is an important evaluation metric. If the covert communication process takes too long or is too unreliable, then it may not be a viable technique for real-world applications. By measuring the successful receive time, we can assess the efficiency and reliability of our covert communication method.</p>
</div>
<div id="S5.SS1.p6" class="ltx_para">
<p id="S5.SS1.p6.1" class="ltx_p">Overall, these evaluation metrics help us assess the effectiveness, efficiency, and robustness of our proposed covert communication method and compare it with other existing methods in the literature.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Experimental Setup</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.2" class="ltx_p"><span id="S5.SS2.p1.2.1" class="ltx_text ltx_font_bold">Experimental data set and network model.</span> We use the handwriting recognition data set MNIST <cite class="ltx_cite ltx_citemacro_citep">(Andreina et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> and the image recognition data set CIFAR10 <cite class="ltx_cite ltx_citemacro_citep">(Shen and Sanghavi, <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite> to complete our experiments. MNIST is a handwriting recognition data set that includes 60,000 training samples and 10,000 test samples. Each sample is a <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="28\times 28" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">28</cn><cn type="integer" id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">28\times 28</annotation></semantics></math> pixel handwritten number. And it has 10 class labels from the number “0” to the number “9”. CIFAR10 has 50,000 training samples and 10,000 test samples. Each sample is a <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="32\times 32\times 3" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mn id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.2.m2.1.1.1" xref="S5.SS2.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.2.m2.1.1.1a" xref="S5.SS2.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.2.m2.1.1.4" xref="S5.SS2.p1.2.m2.1.1.4.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><times id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1.1"></times><cn type="integer" id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">32</cn><cn type="integer" id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3">32</cn><cn type="integer" id="S5.SS2.p1.2.m2.1.1.4.cmml" xref="S5.SS2.p1.2.m2.1.1.4">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">32\times 32\times 3</annotation></semantics></math> image, such as “airplane”, “car”, etc. It also has 10 classes. The network model we used is a 2-layer convolution neural network and an 18-layer ResNet18 <cite class="ltx_cite ltx_citemacro_citep">(He
et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_bold">Sending data.</span> The sending data is the data that the attacker tries to send to the receiver. It includes a short text message and an image message in our experiments. The text message is: <span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_italic">Do not answer! Do not answer!</span> The image message is a gray image of Einstein’s head with a size of 11,040 bits. We send the text message in the 2-layer convolution neural network FL framework with 60 weights every round. And we send the image message using the ResNet18 with 2,250 weights every round.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Experimental Results</h3>

<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Global model accuracy at different attacker ratios.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F3.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F3.2" class="ltx_p ltx_figure_panel ltx_align_center">Global model accuracy at different attacker ratios.</p>
</div>
</div>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p"><span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_bold">Our attack does not destroy the aggregation of the model.</span> As shown in Figure <a href="#S5.F3" title="Figure 3 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we experimented with the variation of the global model accuracy for the different attacker ratios: 0%, 10%, 50%, 90%, and 100%. It can be seen from Figure <a href="#S5.F3" title="Figure 3 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> that the different attacker ratios do not damage the convergence, even if all clients are attackers (100%). This is where our attack method differs from destructive attacks (such as untargeted attacks <cite class="ltx_cite ltx_citemacro_citep">(Fung
et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2018</a>; Tolpegin
et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>; Mahloujifar et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2019</a>; Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite>). The reason why our approach does not damage the accuracy of the global model is that the attacker modifies only a small number of weights, and only a small number of weights changed has little effect on the accuracy of the model. This is because deep neural networks are highly redundant and have many parameters that are not critical to their performance. Additionally, many deep learning models are robust to small perturbations, making them less susceptible to attacks that modify only a small number of weights. Conversely, the attacker can modify the single weight very little, and these small modifications have little impact on deep neural networks.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Comparison of L2 norm for attacker model and benign client model.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F4.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F4.2" class="ltx_p ltx_figure_panel ltx_align_center">Comparison of L2 norm for attacker model and benign client model.</p>
</div>
</div>
</figure>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x5.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Cosine similarity between attacker and benign client, and cosine similarity between benign client and benign client.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F5.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F5.2" class="ltx_p ltx_figure_panel ltx_align_center">Cosine similarity between attacker and benign client, and cosine similarity between benign client and benign client.</p>
</div>
</div>
</figure>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x6.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Comparing local model accuracy of attackers with benign clients.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F6.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F6.2" class="ltx_p ltx_figure_panel ltx_align_center">Comparing local model accuracy of attackers with benign clients.</p>
</div>
</div>
</figure>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.3" class="ltx_p"><span id="S5.SS3.p2.3.1" class="ltx_text ltx_font_bold">Our attack is stealthy.</span> We assume that the server could track each model uploaded by clients in each round and carefully examine each uploaded model. The norm-based approach <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite> has been shown very powerful in recent defenses against federated learning. The underlying idea of this approach is based on the assumption that the attacker and benign client models are inherently different. Figure <a href="#S5.F4" title="Figure 4 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> provides a comparison of the <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mi id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">​</mo><mn id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><times id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1"></times><ci id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">L2</annotation></semantics></math> norm of the attacker and benign client models at different rounds. Figure <a href="#S5.F4" title="Figure 4 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> reveals that the first client represents the attacker, while the other clients are benign. The vertical coordinates represent the weight <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mi id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">​</mo><mn id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><times id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1"></times><ci id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">𝐿</ci><cn type="integer" id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">L2</annotation></semantics></math> parameters. It can be observed that there are no notable differences between the weight <math id="S5.SS3.p2.3.m3.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S5.SS3.p2.3.m3.1a"><mrow id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml"><mi id="S5.SS3.p2.3.m3.1.1.2" xref="S5.SS3.p2.3.m3.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p2.3.m3.1.1.1" xref="S5.SS3.p2.3.m3.1.1.1.cmml">​</mo><mn id="S5.SS3.p2.3.m3.1.1.3" xref="S5.SS3.p2.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><apply id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1"><times id="S5.SS3.p2.3.m3.1.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1.1"></times><ci id="S5.SS3.p2.3.m3.1.1.2.cmml" xref="S5.SS3.p2.3.m3.1.1.2">𝐿</ci><cn type="integer" id="S5.SS3.p2.3.m3.1.1.3.cmml" xref="S5.SS3.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.3.m3.1c">L2</annotation></semantics></math> parameters of the attacker’s weights and the other benign clients’ weights at different stages of the federated learning process (i.e., round = 5, round = 10, and round = 20).</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">Recent work <cite class="ltx_cite ltx_citemacro_citep">(Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>; Nguyen
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite> using the cosine similarity to detect attackers in federated learning exhibits strong defensive capabilities. So, we compare the cosine similarity between the attackers and the benign clients under our approach and the cosine similarity between the benign clients themselves. As shown in Figure <a href="#S5.F5" title="Figure 5 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, the cosine similarity between the attacker and the benign clients is close to 1, which means that the similarity between the attackers and the benign clients is high. Meanwhile, the cosine similarity between the attackers and the benign clients is very close to those of the benign clients. This means that the server cannot use cosine similarity to identify attackers from benign clients.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">There are also federated learning defenses <cite class="ltx_cite ltx_citemacro_citep">(Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; Mallah
et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> that assume that the server has validation data sets to test the accuracy of the local model uploaded by each client. We record the accuracy of the attacker and other benign clients in each round as shown in Figure <a href="#S5.F6" title="Figure 6 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. As in the figure, the attacker’s local mode accuracy is similar to those of the benign clients. This means it is hard for the server with a validation data set to detect the attacker. Moreover, the attacker is trained locally as the benign client, so it has the same positive effect on federated learning. This situation of the attacker continues throughout the federated learning process. Behavior-based detection is ineffective against our attacks because our attack does not destroy or control the model.</p>
</div>
<figure id="S5.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>The influence of different noise levels on message transmission.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F7.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F7.2" class="ltx_p ltx_figure_panel ltx_align_center">The influence of different noise levels on message transmission.</p>
</div>
</div>
</figure>
<div id="S5.SS3.p5" class="ltx_para">
<p id="S5.SS3.p5.1" class="ltx_p"><span id="S5.SS3.p5.1.1" class="ltx_text ltx_font_bold">Our attack is robust.</span> Noise perturbation is a classical technique for federated learning defense. Differential privacy <cite class="ltx_cite ltx_citemacro_citep">(Xie
et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2021</a>; Geyer
et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2017</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> is one of the most popular methods. Differential privacy adds noise (such as Gaussian noise or Laplace noise) to the data or the model to reduce poisoning. We assume that the server can add noise to the attacker model. We experimented with the impact of different noise levels on attacker message transmission. As shown in Figure <a href="#S5.F7" title="Figure 7 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, the attacker sends messages [1,1,0,1,0] with noise levels of 10%, 50%, and 80%. The high level of noise affects the attacker’s transmission effect and reduces the peak signal transmission. But our method still performs well at a 50% noise level.</p>
</div>
<figure id="S5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x8.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>The time when the text message is successfully received.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F8.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F8.2" class="ltx_p ltx_figure_panel ltx_align_center">The time when the text message is successfully received.</p>
</div>
</div>
</figure>
<figure id="S5.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x9.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span>The time when the image message is successfully received.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F9.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F9.2" class="ltx_p ltx_figure_panel ltx_align_center">The time when the image message is successfully received.</p>
</div>
</div>
</figure>
<div id="S5.SS3.p6" class="ltx_para">
<p id="S5.SS3.p6.3" class="ltx_p"><span id="S5.SS3.p6.3.1" class="ltx_text ltx_font_bold">Our attack successfully delivered the messages.</span> We tested the message delivery capability of our method on two different networks. We show the time that the text message was successfully received in Figure <a href="#S5.F8" title="Figure 8 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. We use a 2-layer convolution neural network to send text messages. The text message is 120 bits in total and is successfully received by the receiver at the 80<math id="S5.SS3.p6.1.m1.1" class="ltx_Math" alttext="th" display="inline"><semantics id="S5.SS3.p6.1.m1.1a"><mrow id="S5.SS3.p6.1.m1.1.1" xref="S5.SS3.p6.1.m1.1.1.cmml"><mi id="S5.SS3.p6.1.m1.1.1.2" xref="S5.SS3.p6.1.m1.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p6.1.m1.1.1.1" xref="S5.SS3.p6.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p6.1.m1.1.1.3" xref="S5.SS3.p6.1.m1.1.1.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.1.m1.1b"><apply id="S5.SS3.p6.1.m1.1.1.cmml" xref="S5.SS3.p6.1.m1.1.1"><times id="S5.SS3.p6.1.m1.1.1.1.cmml" xref="S5.SS3.p6.1.m1.1.1.1"></times><ci id="S5.SS3.p6.1.m1.1.1.2.cmml" xref="S5.SS3.p6.1.m1.1.1.2">𝑡</ci><ci id="S5.SS3.p6.1.m1.1.1.3.cmml" xref="S5.SS3.p6.1.m1.1.1.3">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.1.m1.1c">th</annotation></semantics></math> round. Similarly, as shown in Figure <a href="#S5.F9" title="Figure 9 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, the 11,040 bits image was successfully received at the 200th round. With the same round, we achieve more content delivery than in previous work <cite class="ltx_cite ltx_citemacro_citep">(Xie
et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2021</a>)</cite>. We use ResNet18 to send the image message. In the text-sending experiment, the total number of clients is 20, the sending parameter <math id="S5.SS3.p6.2.m2.1" class="ltx_Math" alttext="S_{i}" display="inline"><semantics id="S5.SS3.p6.2.m2.1a"><msub id="S5.SS3.p6.2.m2.1.1" xref="S5.SS3.p6.2.m2.1.1.cmml"><mi id="S5.SS3.p6.2.m2.1.1.2" xref="S5.SS3.p6.2.m2.1.1.2.cmml">S</mi><mi id="S5.SS3.p6.2.m2.1.1.3" xref="S5.SS3.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.2.m2.1b"><apply id="S5.SS3.p6.2.m2.1.1.cmml" xref="S5.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p6.2.m2.1.1.1.cmml" xref="S5.SS3.p6.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p6.2.m2.1.1.2.cmml" xref="S5.SS3.p6.2.m2.1.1.2">𝑆</ci><ci id="S5.SS3.p6.2.m2.1.1.3.cmml" xref="S5.SS3.p6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.2.m2.1c">S_{i}</annotation></semantics></math> = 40 rounds, and the number of weights used to transmit the message is 60. In the image-sending experiment, the number of clients is 20, the sending parameter <math id="S5.SS3.p6.3.m3.1" class="ltx_Math" alttext="S_{i}" display="inline"><semantics id="S5.SS3.p6.3.m3.1a"><msub id="S5.SS3.p6.3.m3.1.1" xref="S5.SS3.p6.3.m3.1.1.cmml"><mi id="S5.SS3.p6.3.m3.1.1.2" xref="S5.SS3.p6.3.m3.1.1.2.cmml">S</mi><mi id="S5.SS3.p6.3.m3.1.1.3" xref="S5.SS3.p6.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.3.m3.1b"><apply id="S5.SS3.p6.3.m3.1.1.cmml" xref="S5.SS3.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.p6.3.m3.1.1.1.cmml" xref="S5.SS3.p6.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.p6.3.m3.1.1.2.cmml" xref="S5.SS3.p6.3.m3.1.1.2">𝑆</ci><ci id="S5.SS3.p6.3.m3.1.1.3.cmml" xref="S5.SS3.p6.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.3.m3.1c">S_{i}</annotation></semantics></math> = 40 rounds and the number of attacker-selected weights is 2,250.</p>
</div>
<figure id="S5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.01342/assets/x10.png" id="S5.F10.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="353" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10. </span>The time when the image message is successfully received.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F10.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F10.2" class="ltx_p ltx_figure_panel ltx_align_center">The time when the image message is successfully received.</p>
</div>
</div>
</figure>
<div id="S5.SS3.p7" class="ltx_para">
<p id="S5.SS3.p7.3" class="ltx_p"><span id="S5.SS3.p7.3.1" class="ltx_text ltx_font_bold">Effect of the number of clients.</span> As shown in Figure <a href="#S5.F10" title="Figure 10 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, we experimented with the effect of the number of clients on the transmission effect with the same above settings. There is only one message sender in the experiment. The number of clients ranges from 10 to 50, and the time to start sending messages is the 20<math id="S5.SS3.p7.1.m1.1" class="ltx_Math" alttext="th" display="inline"><semantics id="S5.SS3.p7.1.m1.1a"><mrow id="S5.SS3.p7.1.m1.1.1" xref="S5.SS3.p7.1.m1.1.1.cmml"><mi id="S5.SS3.p7.1.m1.1.1.2" xref="S5.SS3.p7.1.m1.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p7.1.m1.1.1.1" xref="S5.SS3.p7.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS3.p7.1.m1.1.1.3" xref="S5.SS3.p7.1.m1.1.1.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p7.1.m1.1b"><apply id="S5.SS3.p7.1.m1.1.1.cmml" xref="S5.SS3.p7.1.m1.1.1"><times id="S5.SS3.p7.1.m1.1.1.1.cmml" xref="S5.SS3.p7.1.m1.1.1.1"></times><ci id="S5.SS3.p7.1.m1.1.1.2.cmml" xref="S5.SS3.p7.1.m1.1.1.2">𝑡</ci><ci id="S5.SS3.p7.1.m1.1.1.3.cmml" xref="S5.SS3.p7.1.m1.1.1.3">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p7.1.m1.1c">th</annotation></semantics></math> round, sending parameters <math id="S5.SS3.p7.2.m2.1" class="ltx_Math" alttext="S_{i}" display="inline"><semantics id="S5.SS3.p7.2.m2.1a"><msub id="S5.SS3.p7.2.m2.1.1" xref="S5.SS3.p7.2.m2.1.1.cmml"><mi id="S5.SS3.p7.2.m2.1.1.2" xref="S5.SS3.p7.2.m2.1.1.2.cmml">S</mi><mi id="S5.SS3.p7.2.m2.1.1.3" xref="S5.SS3.p7.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p7.2.m2.1b"><apply id="S5.SS3.p7.2.m2.1.1.cmml" xref="S5.SS3.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p7.2.m2.1.1.1.cmml" xref="S5.SS3.p7.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p7.2.m2.1.1.2.cmml" xref="S5.SS3.p7.2.m2.1.1.2">𝑆</ci><ci id="S5.SS3.p7.2.m2.1.1.3.cmml" xref="S5.SS3.p7.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p7.2.m2.1c">S_{i}</annotation></semantics></math> =40. In the first 20 rounds, the sender does back-to-zero to reduce the effect of the initial value. And, the message sent by the sender is [1, 1, 0, 1, 0]. It can be seen from Figure <a href="#S5.F10" title="Figure 10 ‣ 5.3. Experimental Results ‣ 5. Experiments ‣ Covert Communication Based on the Poisoning Attack in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> that the signal decreases gradually as the number of clients increases. The messages transmitted by the sender are combined with the weights of other client models through averaging. This leads to the sender’s influence on the global model tough. This can be solved by increasing the number of attackers by increasing the number of sending rounds <math id="S5.SS3.p7.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S5.SS3.p7.3.m3.1a"><mi id="S5.SS3.p7.3.m3.1.1" xref="S5.SS3.p7.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p7.3.m3.1b"><ci id="S5.SS3.p7.3.m3.1.1.cmml" xref="S5.SS3.p7.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p7.3.m3.1c">n</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Covert Communication Defenses</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In recent years, several defense methods have been proposed to detect and prevent covert communication attacks in federated learning such as traffic and data detection <cite class="ltx_cite ltx_citemacro_citep">(Copos
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2016</a>)</cite>, and data sanitization <cite class="ltx_cite ltx_citemacro_citep">(Fisk
et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2003</a>; Hameed
et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. In this section, we will discuss the limitations of the existing defense methods for defending against covert communication attacks.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">Traffic and data detection</span> <cite class="ltx_cite ltx_citemacro_citep">(Copos
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2016</a>)</cite>. One of the most common defense methods is traffic and data detection, which analyzes the traffic patterns and data content of the communication between clients. However, this method is not effective in defending against our attacks since we use the same number of parameters for all clients, and we disguise the smuggled data, making it indistinguishable from normal model updates.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p"><span id="S6.p3.1.1" class="ltx_text ltx_font_bold">Data sanitization</span> <cite class="ltx_cite ltx_citemacro_citep">(Fisk
et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2003</a>; Hameed
et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. Data sanitization is another commonly used defense method, where noise is added to the data to destroy any toxic parts. However, our experiments show that even with high noise levels, our method is still effective in transmitting covert messages. Additionally, since the model needs to remain usable, the addition of noise is limited, making this defense method ineffective against our attacks.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold">Model validation</span> <cite class="ltx_cite ltx_citemacro_citep">(Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>; Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2020</a>; Mallah
et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>. Model validation is a defense method where the server uses validation data sets to validate the accuracy of each uploaded model. However, our careful poisoning approach does not affect the accuracy of the models, making this defense method ineffective in preventing covert communication.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">In light of these limitations, we propose a new defense scheme where the server records all model weight changes for all clients. This method of recording all parameters seems to work. However, this approach is computationally expensive and may require additional resources, making it less practical. Therefore, further research is necessary to develop more efficient and effective defense methods to prevent covert communication attacks in federated learning.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Related Works</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Attacks against Federated Learning</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p"><span id="S7.SS1.p1.1.1" class="ltx_text ltx_font_bold">Disruption attacks.</span> Disruption attacks are the attacker aims to destroy the model’s performance either partially or totally. This attack mainly includes targeted poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(Fung
et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2018</a>; Tolpegin
et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>; Mahloujifar et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite> and untargeted poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(Mallah
et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>. For example, a cat and dog recognition model has a low accuracy for cats but a high rate for dogs. Or it has a low accuracy for both cat and dog recognition. This type of attack is high in destructive power and low in stealthiness.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p"><span id="S7.SS1.p2.1.1" class="ltx_text ltx_font_bold">Controlling attacks.</span> The purpose of control-type attacks is to control the model output such as backdoor attacks <cite class="ltx_cite ltx_citemacro_citep">(Sun
et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2019</a>; Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2020</a>; Bagdasaryan and
Shmatikov, <a href="#bib.bib3" title="" class="ltx_ref">2021</a>; Du et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>. The model performs well in normal sample recognition when the input is right. However, if the input sample has a trigger (e.g., a picture of a car with a red square), the output of the model will have controlled by the attacker. For example, the model recognizes a picture of a cat as a dog when the cat picture with a backdoor trigger. This type of attack is highly stealthy and often difficult to detect.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Defenses against Attacks</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p"><span id="S7.SS2.p1.1.1" class="ltx_text ltx_font_bold">Perturbation-based defenses.</span> A perturbation mechanism is a perturbation of data or parameters to destroy the poisoned part of the data or parameters. The perturbation mechanism gains the security improvement of the model at the expense of a small amount of accuracy. One of the most famous perturbation mechanisms is differential privacy. Differential privacy mechanisms have numerous techniques in federated learning privacy preservation <cite class="ltx_cite ltx_citemacro_citep">(Geyer
et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2017</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>. Due to its rigorous mathematical theoretical foundation and good performance, there are also many related studies in security. Du et al. <cite class="ltx_cite ltx_citemacro_citep">(Du et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> demonstrated that applying differential privacy can improve the utility of outlier detection and can effectively mitigate backdoor attacks.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p"><span id="S7.SS2.p2.1.1" class="ltx_text ltx_font_bold">Clustering-based defenses.</span> Clustering-based defense is based on the premise that malicious and benign clients do not have the same purpose. This means that the statistics of the attacker and benign client model parameters will differ. Shen et al. <cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2016</a>)</cite> propose the KMeans approach to distinguish benign clients from malicious clients. Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2019</a>)</cite> use an outlier-based detection method that can mitigate backdoor attacks. Tran et al. and Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Tran
et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2018</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> use a spectral clustering technique to identify backdoor triggers to have a higher defense against backdoor attacks.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p"><span id="S7.SS2.p3.1.1" class="ltx_text ltx_font_bold">Comparison-based defenses.</span> The core of a comparison-based solution is to have a “clean” or “dirty” object for comparison. How to find the client with “clean” or “dirty” parameters is the core problem of this solution. Shen et al. <cite class="ltx_cite ltx_citemacro_citep">(Shen and Sanghavi, <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite> propose a scheme to detect dirty samples by initial correctness. This approach is based on the observation that clean samples are more accurate at the initial stage of training and less accurate for samples carrying backdoor triggers. Ozdayi et al. <cite class="ltx_cite ltx_citemacro_citep">(Ozdayi
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite> find that if a client carries a backdoor task, the two updates parameter of the client will be more similar compared to other benign clients. Cao et al. <cite class="ltx_cite ltx_citemacro_citep">(Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite> further strengthen the assumption of federated learning by assuming that the server in federated learning has a small “clean” verification dataset. The server can use the validation dataset to test the accuracy of each client’s model. The key for this type of technique to work is that the attacker’s behavior is different from that of benign clients (e.g., the attacker model is less accurate).</p>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.1" class="ltx_p">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite> is a Byzantine fault-tolerant algorithm based on Euclidean distance. In the Trim-mean <cite class="ltx_cite ltx_citemacro_citep">(Yin
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2018</a>)</cite> method, the server collects the parameter values from all local model updates and sorts them. This approach uses the trimmed mean as the value of the corresponding parameter in the global model update. Mhamdi et al. <cite class="ltx_cite ltx_citemacro_citep">(Guerraoui
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2018</a>)</cite> proposed Bulya, which is essentially a combination of variants of Krum and trimmed mean. Pillutla et al. <cite class="ltx_cite ltx_citemacro_citep">(Pillutla
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite> propose methods based on the classical geometric median. These methods are effectively provided that the attacker’s model statistics will be very different from those of benign clients and that the number of attackers is small.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Conclusions</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">This paper introduces a novel poisoning-based covert communication technique for federated learning that achieves 100% accuracy in message transmission between two clients. We also present optimizations to increase capacity and enhance the stealthiness of the method. Extensive experiments demonstrate the effectiveness, robustness, and stealthiness of our approach. We also evaluate existing defense and detection methods, which show limited effectiveness against our covert communication attack. Our proposed scheme serves as a foundation for future federated learning attacks, such as malware hiding, and we plan to investigate methods for detecting seemingly harmless clients which can promote fairness in federated learning.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andreina et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sebastien Andreina,
Giorgia Azzurra Marson, Helen
Möllering, and Ghassan Karame.
2021.

</span>
<span class="ltx_bibblock">Baffle: Backdoor detection via feedback-based
federated learning. In <em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">2021 IEEE 41st
International Conference on Distributed Computing Systems (ICDCS)</em>. IEEE,
852–863.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan and
Shmatikov (2021)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan and
Vitaly Shmatikov. 2021.

</span>
<span class="ltx_bibblock">Blind backdoors in deep learning models. In
<em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Usenix Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan,
Andreas Veit, Yiqing Hua,
Deborah Estrin, and Vitaly Shmatikov.
2020.

</span>
<span class="ltx_bibblock">How to backdoor federated learning. In
<em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence
and Statistics</em>. PMLR, 2938–2948.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanchard et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Peva Blanchard, El Mahdi
El Mhamdi, Rachid Guerraoui, and Julien
Stainer. 2017.

</span>
<span class="ltx_bibblock">Machine learning with adversaries: Byzantine
tolerant gradient descent.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brisimi et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Theodora S Brisimi, Ruidi
Chen, Theofanie Mela, Alex Olshevsky,
Ioannis Ch Paschalidis, and Wei Shi.
2018.

</span>
<span class="ltx_bibblock">Federated learning of predictive models from
federated electronic health records.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">International journal of medical
informatics</em> 112 (2018),
59–67.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao
et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiaoyu Cao, Minghong
Fang, Jia Liu, and Neil Zhenqiang
Gong. 2020.

</span>
<span class="ltx_bibblock">Fltrust: Byzantine-robust federated learning via
trust bootstrapping.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.13995</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chandra
et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Swarup Chandra, Zhiqiang
Lin, Ashish Kundu, and Latifur Khan.
2015.

</span>
<span class="ltx_bibblock">Towards a systematic study of the covert channel
attacks in smartphones. In <em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">International
Conference on Security and Privacy in Communication Networks: 10th
International ICST Conference, SecureComm 2014, Beijing, China, September
24-26, 2014, Revised Selected Papers, Part I 10</em>. Springer,
427–435.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Copos
et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Bogdan Copos, Karl
Levitt, Matt Bishop, and Jeff Rowe.
2016.

</span>
<span class="ltx_bibblock">Is anybody home? inferring activity from smart home
network traffic. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">2016 IEEE Security and Privacy
Workshops (SPW)</em>. IEEE, 245–251.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costa
et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Gabriele Costa, Fabio
Pinelli, Simone Soderi, and Gabriele
Tolomei. 2021.

</span>
<span class="ltx_bibblock">Covert channel attack to federated learning
systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.10561</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Andrew Du, Bo Chen,
Tat-Jun Chin, Yee Wei Law,
Michele Sasdelli, Ramesh Rajasegaran,
and Dillon Campbell. 2022.

</span>
<span class="ltx_bibblock">Physical adversarial attacks on an aerial imagery
object detector. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Winter Conference on Applications of Computer Vision</em>.
1796–1806.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Min Du, Ruoxi Jia, and
Dawn Song. 2019.

</span>
<span class="ltx_bibblock">Robust anomaly detection and backdoor attack
detection via differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.07116</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eisenkraft and
Olshtein. (2019)</span>
<span class="ltx_bibblock">
K. Eisenkraft and A.
Olshtein. 2019.

</span>
<span class="ltx_bibblock">Pony’s C<math id="bib.bib13.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="bib.bib13.1.m1.1a"><mo id="bib.bib13.1.m1.1.1" xref="bib.bib13.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="bib.bib13.1.m1.1b"><and id="bib.bib13.1.m1.1.1.cmml" xref="bib.bib13.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="bib.bib13.1.m1.1c">\&amp;</annotation></semantics></math>C servers hidden inside the Bitcoin
blockchain.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
Retrieved 2019, Oct from <a target="_blank" href="https://tinyurl.com/r4wcbyjc" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://tinyurl.com/r4wcbyjc</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang
et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Minghong Fang, Xiaoyu
Cao, Jinyuan Jia, and Neil Zhenqiang
Gong. 2020.

</span>
<span class="ltx_bibblock">Local model poisoning attacks to byzantine-robust
federated learning. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th
USENIX Conference on Security Symposium</em>. 1623–1640.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fisk
et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2003)</span>
<span class="ltx_bibblock">
Gina Fisk, Mike Fisk,
Christos Papadopoulos, and Joshua
Neil. 2003.

</span>
<span class="ltx_bibblock">Eliminating steganography in Internet traffic with
active wardens. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Information Hiding: 5th
International Workshop, IH 2002 Noordwijkerhout, The Netherlands, October
7-9, 2002 Revised Papers 5</em>. Springer, 18–35.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung
et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Clement Fung, Chris JM
Yoon, and Ivan Beschastnikh.
2018.

</span>
<span class="ltx_bibblock">Mitigating sybils in federated learning poisoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1808.04866</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geyer
et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Robin C Geyer, Tassilo
Klein, and Moin Nabi. 2017.

</span>
<span class="ltx_bibblock">Differentially private federated learning: A client
level perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.07557</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giffin et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2003)</span>
<span class="ltx_bibblock">
John Giffin, Rachel
Greenstadt, Peter Litwack, and Richard
Tibbetts. 2003.

</span>
<span class="ltx_bibblock">Covert messaging through TCP timestamps. In
<em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Privacy Enhancing Technologies: Second
International Workshop, PET 2002 San Francisco, CA, USA, April 14–15, 2002
Revised Papers 2</em>. Springer, 194–208.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guerraoui
et al<span id="bib.bib19.3.3.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Rachid Guerraoui,
Sébastien Rouault, et al<span id="bib.bib19.4.1" class="ltx_text">.</span>
2018.

</span>
<span class="ltx_bibblock">The hidden vulnerability of distributed learning in
byzantium. In <em id="bib.bib19.5.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 3521–3530.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hameed
et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Muhammad Zaid Hameed,
András György, and Deniz
Gündüz. 2020.

</span>
<span class="ltx_bibblock">The best defense is a good offense: Adversarial
attacks to avoid modulation detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> 16 (2020),
1074–1087.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He
et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu
Zhang, Shaoqing Ren, and Jian Sun.
2016.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition. In
<em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer
vision and pattern recognition</em>. 770–778.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Horejsi and Chen (2019)</span>
<span class="ltx_bibblock">
J. Horejsi and J. C.
Chen. 2019.

</span>
<span class="ltx_bibblock">Glupteba Hits Routers and Updates C<math id="bib.bib22.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="bib.bib22.1.m1.1a"><mo id="bib.bib22.1.m1.1.1" xref="bib.bib22.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="bib.bib22.1.m1.1b"><and id="bib.bib22.1.m1.1.1.cmml" xref="bib.bib22.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="bib.bib22.1.m1.1c">\&amp;</annotation></semantics></math>C Servers.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
Retrieved 2019, Sept from <a target="_blank" href="https://tinyurl.com/rkbb87yu" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://tinyurl.com/rkbb87yu</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz
et al<span id="bib.bib23.3.3.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan
McMahan, Brendan Avent, Aurélien
Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, et al<span id="bib.bib23.4.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.5.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in
Machine Learning</em> 14, 1–2
(2021), 1–210.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Suyi Li, Yong Cheng,
Wei Wang, Yang Liu, and
Tianjian Chen. 2020.

</span>
<span class="ltx_bibblock">Learning to detect malicious clients for robust
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.00211</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and
Epliremides (2004)</span>
<span class="ltx_bibblock">
Song Li and Anthony
Epliremides. 2004.

</span>
<span class="ltx_bibblock">A network layer covert channel in ad-hoc wireless
networks. In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">2004 First Annual IEEE Communications
Society Conference on Sensor and Ad Hoc Communications and Networks, 2004.
IEEE SECON 2004.</em> IEEE, 88–96.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tao Liu, Zihao Liu,
Qi Liu, Wujie Wen,
Wenyao Xu, and Ming Li.
2020.

</span>
<span class="ltx_bibblock">StegoNet: Turn deep neural network into a
stegomalware. In <em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Annual Computer Security
Applications Conference</em>. 928–938.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Long
et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Guodong Long, Yue Tan,
Jing Jiang, and Chengqi Zhang.
2020.

</span>
<span class="ltx_bibblock">Federated learning for open banking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">Federated Learning: Privacy and
Incentive</em>. Springer, 240–254.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo
et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2007)</span>
<span class="ltx_bibblock">
Xiapu Luo, Edmond WW
Chan, and Rocky KC Chang.
2007.

</span>
<span class="ltx_bibblock">Cloak: A ten-fold way for reliable covert
communications. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Computer Security–ESORICS
2007: 12th European Symposium On Research In Computer Security, Dresden,
Germany, September 24—26, 2007. Proceedings 12</em>. Springer,
283–298.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mahloujifar et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Saeed Mahloujifar,
Mohammad Mahmoody, and Ameer Mohammed.
2019.

</span>
<span class="ltx_bibblock">Universal multi-party poisoning attacks. In
<em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.
PMLR, 4274–4283.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallah
et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ranwa Al Mallah, David
Lopez, Godwin Badu Marfo, and Bilal
Farooq. 2021.

</span>
<span class="ltx_bibblock">Untargeted poisoning attack detection in federated
learning via behavior attestation.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.10904</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Aguera y Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks
from decentralized data. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Artificial
intelligence and statistics</em>. PMLR, 1273–1282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mirzargar and
Stojilović (2019)</span>
<span class="ltx_bibblock">
Seyedeh Sharareh Mirzargar and
Mirjana Stojilović. 2019.

</span>
<span class="ltx_bibblock">Physical side-channel attacks and covert
communication on FPGAs: A survey. In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">2019 29th
International Conference on Field Programmable Logic and Applications
(FPL)</em>. IEEE, 202–210.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dinh C Nguyen, Ming Ding,
Pubudu N Pathirana, Aruna Seneviratne,
Jun Li, and H Vincent Poor.
2021.

</span>
<span class="ltx_bibblock">Federated learning for internet of things: A
comprehensive survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>
23, 3 (2021),
1622–1658.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen
et al<span id="bib.bib34.3.3.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Thien Duc Nguyen, Phillip
Rieger, Roberta De Viti, Huili Chen,
Björn B Brandenburg, Hossein Yalame,
Helen Möllering, Hossein Fereidooni,
Samuel Marchal, Markus Miettinen,
et al<span id="bib.bib34.4.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">FLAME: Taming backdoors in federated learning. In
<em id="bib.bib34.5.1" class="ltx_emph ltx_font_italic">31st USENIX Security Symposium (USENIX Security
22)</em>. 1415–1432.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ozdayi
et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mustafa Safa Ozdayi, Murat
Kantarcioglu, and Yulia R Gel.
2021.

</span>
<span class="ltx_bibblock">Defending against backdoors in federated learning
with robust learning rate. In <em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, Vol. 35.
9268–9276.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan
et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xudong Pan, Mi Zhang,
Duocai Wu, Qifan Xiao,
Shouling Ji, and Min Yang.
2020.

</span>
<span class="ltx_bibblock">Justinian’s gaavernor: Robust distributed learning
with gradient aggregation agent. In <em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 29th USENIX Conference on Security Symposium</em>.
1641–1658.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla
et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Krishna Pillutla, Sham M
Kakade, and Zaid Harchaoui.
2022.

</span>
<span class="ltx_bibblock">Robust aggregation for federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Signal Processing</em>
70 (2022), 1142–1154.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts (2000)</span>
<span class="ltx_bibblock">
SW Roberts.
2000.

</span>
<span class="ltx_bibblock">Control chart tests based on geometric moving
averages.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Technometrics</em> 42,
1 (2000), 97–101.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shejwalkar et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Virat Shejwalkar, Amir
Houmansadr, Peter Kairouz, and Daniel
Ramage. 2022.

</span>
<span class="ltx_bibblock">Back to the drawing board: A critical evaluation of
poisoning attacks on production federated learning. In
<em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">2022 IEEE Symposium on Security and Privacy (SP)</em>.
IEEE, 1354–1371.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen
et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Shiqi Shen, Shruti Tople,
and Prateek Saxena. 2016.

</span>
<span class="ltx_bibblock">Auror: Defending against poisoning attacks in
collaborative deep learning systems. In
<em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd Annual Conference on
Computer Security Applications</em>. 508–519.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen and Sanghavi (2019)</span>
<span class="ltx_bibblock">
Yanyao Shen and Sujay
Sanghavi. 2019.

</span>
<span class="ltx_bibblock">Learning with bad training data via iterative
trimmed loss minimization. In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning</em>. PMLR, 5739–5748.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silva et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Santiago Silva, Boris A
Gutman, Eduardo Romero, Paul M Thompson,
Andre Altmann, and Marco Lorenzi.
2019.

</span>
<span class="ltx_bibblock">Federated learning in distributed medical
databases: Meta-analysis of large-scale subcortical brain data. In
<em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">2019 IEEE 16th international symposium on
biomedical imaging (ISBI 2019)</em>. IEEE, 270–274.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun
et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ziteng Sun, Peter
Kairouz, Ananda Theertha Suresh, and
H Brendan McMahan. 2019.

</span>
<span class="ltx_bibblock">Can you really backdoor federated learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.07963</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tolpegin
et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Vale Tolpegin, Stacey
Truex, Mehmet Emre Gursoy, and Ling
Liu. 2020.

</span>
<span class="ltx_bibblock">Data poisoning attacks against federated learning
systems. In <em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Computer Security–ESORICS 2020: 25th
European Symposium on Research in Computer Security, ESORICS 2020, Guildford,
UK, September 14–18, 2020, Proceedings, Part I 25</em>. Springer,
480–501.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tran
et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Brandon Tran, Jerry Li,
and Aleksander Madry. 2018.

</span>
<span class="ltx_bibblock">Spectral signatures in backdoor attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 31 (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tuptuk and Hailes (2015)</span>
<span class="ltx_bibblock">
Nilufer Tuptuk and
Stephen Hailes. 2015.

</span>
<span class="ltx_bibblock">Covert channel attacks in pervasive computing. In
<em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">2015 IEEE international conference on pervasive
computing and communications (PerCom)</em>. IEEE, 236–242.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Bolun Wang, Yuanshun Yao,
Shawn Shan, Huiying Li,
Bimal Viswanath, Haitao Zheng, and
Ben Y Zhao. 2019.

</span>
<span class="ltx_bibblock">Neural cleanse: Identifying and mitigating backdoor
attacks in neural networks. In <em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium
on Security and Privacy (SP)</em>. IEEE, 707–723.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hongyi Wang, Kartik
Sreenivasan, Shashank Rajput, Harit
Vishwakarma, Saurabh Agarwal, Jy-yong
Sohn, Kangwook Lee, and Dimitris
Papailiopoulos. 2020.

</span>
<span class="ltx_bibblock">Attack of the tails: Yes, you really can backdoor
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 33 (2020),
16070–16084.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhi Wang, Chaoge Liu,
and Xiang Cui. 2021.

</span>
<span class="ltx_bibblock">Evilmodel: hiding malware inside of neural network
models. In <em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">2021 IEEE Symposium on Computers and
Communications (ISCC)</em>. IEEE, 1–7.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li,
Ming Ding, Chuan Ma,
Howard H Yang, Farhad Farokhi,
Shi Jin, Tony QS Quek, and
H Vincent Poor. 2020.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy:
Algorithms and performance analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> 15 (2020),
3454–3469.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie
et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Chulin Xie, Minghao Chen,
Pin-Yu Chen, and Bo Li.
2021.

</span>
<span class="ltx_bibblock">Crfl: Certifiably robust federated learning against
backdoor attacks. In <em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">International Conference on
Machine Learning</em>. PMLR, 11372–11382.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin
et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Dong Yin, Yudong Chen,
Ramchandran Kannan, and Peter
Bartlett. 2018.

</span>
<span class="ltx_bibblock">Byzantine-robust distributed learning: Towards
optimal statistical rates. In <em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning</em>. PMLR, 5650–5659.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zaixi Zhang, Xiaoyu Cao,
Jinyuan Jia, and Neil Zhenqiang Gong.
2022.

</span>
<span class="ltx_bibblock">FLDetector: Defending federated learning against
model poisoning attacks via detecting malicious clients. In
<em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining</em>. 2545–2555.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.01341" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.01342" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.01342">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.01342" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.01343" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 02:15:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
