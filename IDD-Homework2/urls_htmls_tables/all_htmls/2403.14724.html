<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.14724] Six Levels of Privacy: A Framework for Financial Synthetic Data</title><meta property="og:description" content="Synthetic Data is increasingly important in financial applications.
In addition to the benefits it provides, such as improved financial
modeling and better testing procedures, it poses privacy risks as well.
Such data …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Six Levels of Privacy: A Framework for Financial Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Six Levels of Privacy: A Framework for Financial Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.14724">

<!--Generated on Fri Apr  5 14:34:29 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document">Six Levels of Privacy: A Framework 
<br class="ltx_break">for Financial Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tucker Balch, Vamsi K. Potluru, Deepak Paramanand, Manuela Veloso
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Synthetic Data is increasingly important in financial applications.
In addition to the benefits it provides, such as improved financial
modeling and better testing procedures, it poses privacy risks as well.
Such data may arise from client information,
business information, or other proprietary sources that
must be protected.
Even though the process by which Synthetic Data is generated
serves to obscure the original data to some degree,
the extent to which privacy is preserved is hard to assess.
Accordingly, we introduce a hierarchy
of “levels”
of privacy that are useful for categorizing
Synthetic Data generation methods and the
progressively improved protections they offer.
While the six levels were devised in the context of financial
applications, they may also be appropriate for other
industries as well.
Our paper includes: A brief overview of Financial Synthetic Data, how
it can be used, how its value can be assessed, privacy risks, and privacy
attacks. We close with details of the “Six Levels” that include defenses
against those attacks.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p ltx_align_center"><span id="p1.1.1" class="ltx_text">J.P. Morgan Chase &amp; Company AI Research</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As the name suggests, Synthetic Data is artificially
generated rather than produced by real world events.
Synthetic Data is created via two primary methods, namely: 1) By
<span id="S1.p1.1.1" class="ltx_text ltx_font_italic">transforming</span>
real data, or 2) By <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">simulation</span> of real processes.
We refer the reader to the rich literature
on Synthetic Data and the many mechanisms for creating it <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">ADM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite>. In financial applications we
focus on three key uses for Synthetic Data:</p>
</div>
<div id="S1.p2" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Liberate data:</span> Depending on its source, the
sensitivity or risk associated with particular types of data
can be significantly reduced or eliminated when transformed
to synthetic form. We might be able to, accordingly, share it more
freely and with less risk. We refer to this as
“liberating data.”</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Augment for training:</span> Synthetic Data can be used
to augment real data used for training
models in order to fill gaps in the coverage of the
data. In some cases the models trained in this way
perform better than those without augmentation.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Testing:</span> With Synthetic Data we have the advantage of being
able to control the
generation so that we know its properties and
contents. If for instance,
we want to test a fraud detection algorithm, we
can “plant” known fraudulent patterns in the data
to check if an algorithm flags them. Synthetic Data
can also be used to explore the “corner cases”
to see of the processes that use the data break under stress.</p>
</div>
</li>
</ol>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The value of Synthetic Data for each of the above uses may vary
according to the application. Three different properties of the data contribute to
an assessment of its value.
As you will see, these properties are sometimes confounding: It is usually not possible
for a dataset to score well along
all three dimensions at once. The dimensions include:</p>
</div>
<div id="S1.p4" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p"><span id="S1.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Realism:</span> How realistic is the data, in the sense that it matches
the real process or dataset that we seek to emulate? In general, the higher the
fidelity of the Synthetic Data, the more useful it is for downstream processes,
but at the cost of reduced privacy.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p"><span id="S1.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Privacy:</span> How easy is it for an adversary to “reverse engineer” the dataset
to infer properties of the original data? In some cases, it is possible to
discover specific private information about individual records in the original data
even though they are not present in the Synthetic Data (see Section 2: Privacy Attacks).
Other proprietary or competitive information might also be revealed such as
the distributional properties of data elements like age, salary, or credit rating of a client list.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p"><span id="S1.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Utility:</span> How well does the data serve the purpose for which it was created?
As one example, we might want to use the data to augment real data in the training of
an ML model. We would evaluate utility in this case by measuring the uplift
the data provides for the model: E.g., Are its predictions now more accurate?
In another case, we might be using the data to test an existing model or process,
say for processing credit card transactions. These tests might be aimed at discovering “breaks”
in the data processing pipeline (e.g., are large, or negative transactions handled appropriately?)</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The metrics are interrelated, for instance: Increased realism usually suggests
reduced privacy; Increased privacy may degrade utility.
Note that while one might assume realism is the most important
factor, this is not always the case. If we are testing a product
or process and we only use real, or historical data, we might not expose
flaws regarding how the system would respond to new, unexpected scenarios.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In the next section we consider some of the risks regarding privacy for financial data.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Privacy risks for financial data</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Financial institutions are appropriately protective of their
data and the data they hold for their clients. Data sharing between various lines of business within a
company, and potentially, externally with clients or vendors, is governed by
regulations and internal guidelines. These controls are designed
to protect clients’ sensitive information and protect firms from
the unauthorized sharing of
MNPI (Material Non-Public Information), as well as litigation, reputation, and competitive risks.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Here we review some prominent risks and
relevant regulations that apply to financial institutions.
While specific to this industry, these regulations are
representative of those many businesses face.</p>
</div>
<div id="S2.p3" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Fair Credit Reporting Act (FCRA):</span></p>
</div>
<div id="S2.I1.i1.p2" class="ltx_para">
<p id="S2.I1.i1.p2.1" class="ltx_p">This U.S. law requires that information collected by consumer reporting agencies (e.g. credit bureaus) cannot be provided to anyone who does not have a purpose specified in the Act. In particular, the data cannot be used for other purposes
even if data that identify an individual are removed.
In addition, the data user must ensure that identity cannot be
inferred using other non-Personally Identifiable Information (PII) data fields.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Regulation on Unfair, Deceptive or Abusive Acts or Practices (UDAAP):</span> In many cases consumers and
clients can specify how their personal data can be used.
Sharing such data
is a UDAAP violation
if used or shared in a manner contrary to the choices made by, or representations made to, consumers or clients. In particular, in many settings data is subject to privacy elections
made by consumers.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Litigation risks:</span> Inappropriate release of data or functions of data (e.g., models trained on data, insights from data, or synthetic data resembling these datasets) that reveal PII or statistics (e.g., global characteristics) of the data, may pose litigation risks. This is particularly important in the context of data sourced from external vendors: Use of such data is typically constrained by contracts that precisely define the scope of the use.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Competitive risks:</span> Publishing data that reveals the characteristics of a firm’s client base or industries and publicly traded companies the firm has interest in, may pose competitive, antitrust and increased insider trading risks. This might apply even if the published data is synthetic.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Privacy attacks</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In order to appropriately assess the protections privacy measures might
provide, we must consider how data might be exploited or ”attacked” by an adversary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">SZZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>.
We assume there exists an adversary
who aims to extract private information from
Synthetic Data or from some other output model output.
Each type of attack is characterized by
assumptions including: What information is available to
the adversary? What information should be protected?
What is the goal of the attack?
Here we enumerate
the most relevant attacks. Also, see Table <a href="#S3.T1" title="Table 1 ‣ 3 Privacy attacks ‣ Six Levels of Privacy: A Framework for Financial Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for an
analysis of attacks versus regulatory risks.</p>
</div>
<div id="S3.p2" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Reconstruction attacks</span> Also known
as attribute inference attacks.
Reconstruction attacks are characterized by an adversary in possession of partial knowledge of a set of features with the aim to recover <span id="S3.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">sensitive</span> features or the full data sample. For example, if some columns matching public information for an
individual (e.g. from voter registration data) correspond to an entry in the
candidate dataset that also includes private attributes (e.g. credit card billing records),
the presence of the individual can reveal the values of the private attributes for that
person. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">NS07</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Membership inference attacks (MIAs) </span>
In many cases the presence of an individual’s data in a dataset by itself can reveal sensitive information. The adversary’s task in MIA is to
infer whether an individual was present in
the training dataset or not <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">SSS16</a>]</cite>.
An adversary with
knowledge of an individual’s presence in the dataset can further exploit that knowledge in
linkage (or reconstruction) attacks to identify sensitive attributes of that individual.
Thus, MIA can be used as a stepping stone to launch other types of attack.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Property inference attacks </span>
Property inference represents the ability to extract properties of the original dataset from the corresponding synthetic data. In general, property inference refers to learning summary statistics of the original data (e.g. mean value, quantiles, histograms etc.) under the assumption of access to Synthetic Data only. Note that preventing property inference attacks necessarilty
degrades fidelity of the synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">LWSF23</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.2.1" class="ltx_text" style="font-size:80%;">FCRA</span></td>
<td id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.3.1" class="ltx_text" style="font-size:80%;">UDAAP</span></td>
<td id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.4.1" class="ltx_text" style="font-size:80%;">Litigation Risk</span></td>
<td id="S3.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.5.1" class="ltx_text" style="font-size:80%;">Competitive Risk</span></td>
</tr>
<tr id="S3.T1.1.2.2" class="ltx_tr">
<td id="S3.T1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.2.2.1.1" class="ltx_text" style="font-size:80%;">Membership Inference Attack</span></td>
<td id="S3.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.2.2.3.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.2.2.4.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.2.2.5.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
</tr>
<tr id="S3.T1.1.3.3" class="ltx_tr">
<td id="S3.T1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.3.3.1.1" class="ltx_text" style="font-size:80%;">Attribute Inference Attack</span></td>
<td id="S3.T1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.3.3.2.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.3.3.3.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.3.3.4.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.3.3.5.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
</tr>
<tr id="S3.T1.1.4.4" class="ltx_tr">
<td id="S3.T1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.4.4.1.1" class="ltx_text" style="font-size:80%;">Property Inference Attack</span></td>
<td id="S3.T1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.4.4.2.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
<td id="S3.T1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.4.4.3.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
<td id="S3.T1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.4.4.4.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.4.4.5.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
</tr>
<tr id="S3.T1.1.5.5" class="ltx_tr">
<td id="S3.T1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.5.5.1.1" class="ltx_text" style="font-size:80%;">Model Inference Attack</span></td>
<td id="S3.T1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.5.5.2.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.5.5.3.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.5.5.4.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
<td id="S3.T1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.5.5.5.1" class="ltx_text" style="font-size:80%;">Applicable</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Privacy attacks on synthetic data can lead to breach of various regulations in financial
applications.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Privacy levels</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Now we introduce a six-level
privacy defense hierarchy and discuss the privacy attacks, utility implications, and potential privacy guarantees for each level. Each level corresponds to a group of defense mechanisms with increasingly stronger privacy protections.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">These levels can provide guidance to businesses regarding
the security and utility of their Synthetic Data.
For instance, they might choose to allow internal sharing
of Level 2 data if it arises from a non-critical source,
but require Level 4 protections for more sensitive data.
The relevant privacy level should be determined according to
the use case to balance multiple objectives
such as the business goal, security, speed of generation, and utility.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">In the first 4 levels, we consider methods where the data is <span id="S4.p3.1.1" class="ltx_text ltx_font_italic">transformed</span> from
the original dataset to the Synthetic Data. In the figures, the original data appears
on the left, and the arrows indicate how the data is transformed. We focus on tabular
data in these examples, but the principles can apply to other types of
data.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="/html/2403.14724/assets/x1.png" id="S4.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="597" height="176" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Privacy Level 1: Obscure PII</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Privacy Level 1: Obscure PII</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Examples of mechanisms at this level include dropping, replacing, masking, or anonymizing the PII attributes. Since this approach does not modify non-PII attributes in any way, it dones not reduce the utility of downstream tasks and accordingly
there is no utility degradation. This however represents weak privacy protection as data remains vulnerable to reconstruction attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">NS07</a>]</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2403.14724/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="597" height="177" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Privacy Level 2: Obscure PII + noise</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Privacy Level 2: Obscure PII + noise</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In addition to obscuring PII columns, we can deliberately add
noise to other attributes to reduce the effectiveness of potential attacks.
Differential privacy techniques, for instance, can provide formal guarantees against MIA.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Another approach involves randomly “swapping”
data between entries. So for instance, in a demographic dataset, the
ages of the included individuals might be reordered randomly in the
records. This technique aims to provide plausible but randomized data
by making it more difficult for an adversary to infer any information regarding
any particular individual. These techniques
aim to elevate privacy while preserving the utility of the data to a downstream
task.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Depending on the amount of noise and the downstream task, some degree of utility degradation is expected.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2403.14724/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="597" height="260" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Privacy Level 3: Generative modeling. The question mark suggests the possibility of
reverse-engineering the data.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Privacy Level 3: Generative modeling</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Note that Privacy Levels 1 and 2 involve row-by-row transcription of the original data
(with obfuscation or noise as appropriate).
Accordingly, such datasets cannot be larger than the original.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">With Level 3 we move to <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">generative</span> techniques where we analyze the original
data to build a model that can create new data.
Example approaches include Gaussian copula, and Generative-Adversarial-Networks (GAN)
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">PWV16</a>, <a href="#bib.bibx6" title="" class="ltx_ref">GPAM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>14</a>, <a href="#bib.bibx12" title="" class="ltx_ref">PMG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite>. Other
methods use differential privacy techniques to offer additional guarantees
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">ADR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>, <a href="#bib.bibx17" title="" class="ltx_ref">XLW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>, <a href="#bib.bibx18" title="" class="ltx_ref">YJvdS19</a>]</cite>.
In our own work, we have
introduced a KD-tree-based formulation
to model the data that offers additional protections as well <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">KNP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">All these methods enable the creation of new data elements
distinct from the original data. They offer stronger protection
than in Level 1 or Level 2, but are still potentially
subject to attack. The risk is
increased when the relative size of the generated data to
the original data is large: For example, if we generate one million
samples using an original dataset
of only 1,000 we would expect to see generated samples clustering around the
samples in the original data.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2403.14724/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="597" height="251" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Privacy Level 4: Generative modeling + testing</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Level 4: Generative modeling + testing</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">For Level 4 we add explicit testing of each generated dataset to validate its
resistance to specific attacks.
The particular tests and the corresponding scores
required to “pass” depend on the data and the application. For instance,
it may be acceptable for certain properties of the data to “leak” while others should not.
To operationalize this, we leverage published attack algorithms, then score the
data depending on the success of the attack.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">While it is hard to specify which test and which score would be necessary
to achieve Level 4 privacy in all cases, the important and
critical difference above Level 3, is the fact that the data is explicitly tested.
The test and the scoring criteria must be determined by the individual business for the
use case. Example scoring criteria measure resistance to membership inference, attribute
reconstruction, and property attacks. among others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">GBWT23</a>, <a href="#bib.bibx7" title="" class="ltx_ref">HCS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a href="#bib.bibx8" title="" class="ltx_ref">HJC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a href="#bib.bibx3" title="" class="ltx_ref">BDI<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>, <a href="#bib.bibx4" title="" class="ltx_ref">DL24</a>]</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2403.14724/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="597" height="191" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Privacy Level 5: Calibrated simulation</figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Level 5: Calibrated simulation</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">In this approach the generation method
is not trained on real data. In fact, there
is (usually)
no learning in this approach. Instead, we rely on
simulations governed by rules or knowledge
of the process
that would otherwise generate real data.
These rules, however, are calibrated with reference to the real process
such that the generated data follows
some statistical properties of the original, real system.
As an example, we might use a simulation of the stock market to generate
stock price data.
In our own work, we have developed calibrated simulations of equity markets that correspond to
Level 5 privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">VBP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">Utility degradation depends on the downstream task and the simulation framework. This approach generally represents a strong defense against adversarial attacks.
However, they may be exposed to Property Inference Attacks, because
the simulator is calibrated with respect to statistical properties of
the real system.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2403.14724/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="597" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Privacy Level 6: Uncalibrated simulation</figcaption>
</figure>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Level 6: Uncalibrated simulation</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">In this case we may not be aware of the statistical properties
of the modeled system, or we might deliberately avoid adjusting the simulation
to correspond to the properties of the original system.
Even though such a simulation may not provide high fidelity data, it can
still prove quite useful.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">An important
use is testing, in which we might use a simulation to
explore all the potential
values of data fields to see if they “break” our downstream processes.
Additionally, we might choose to embed known examples
of situations we want to be sure our systems detect (e.g., fraudlent transactions).
Another use is to create what-if scenarios
where we hypothesize the impact of one factor on another, to see if
visualization techniques might enable us to discover those relationships in practice.</p>
</div>
<div id="S4.SS6.p3" class="ltx_para">
<p id="S4.SS6.p3.1" class="ltx_p">In general, this method yields a strong privacy guarantee.
It remediates one of the consequences of level 5 generation of defence against PIA attacks,
given that the statistical properties of the data is uncalibrated to the real dataset.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Summary</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We describe six categories, or levels, of privacy
protection for Financial Synthetic Data provided
by different generation techniques. The strength of privacy protection
relates to the resistance the
technique offers against privacy attacks.
Such attacks might enable an adversary to infer information about
individual data points in the original data used to train a generator.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The six levels progress
from least secure (Level 1) to most secure (Level 6), Level 1 depends on
simple masking and obfuscation
(which offers very little protection), while
Level 6, uncalibrated simulation, provides the
strongest protection.
We focus specifically on financial data, but
the categorizations may be useful in other industries
(e.g. healthcare)
and generation techniques as well.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We thank Mohsen Ghassemi and Eleonora Kreačić for many helpful discussions.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Disclaimer</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This paper was prepared for informational purposes by the CDAO group of JPMorgan Chase &amp; Co and its affiliates (“J.P. Morgan”) and is not a product of the Research Department of J.P. Morgan. J.P. Morgan makes no representation and warranty whatsoever and disclaims all liability, for the completeness, accuracy or reliability of the information contained herein. This document is not intended as investment research or investment advice, or a recommendation, offer or solicitation for the purchase or sale of any security, financial instrument, financial product or service, or to be used in any way for evaluating the merits of participating in any transaction, and shall not constitute a solicitation under any jurisdiction or to any person, if such solicitation under such jurisdiction or to such person would be unlawful.
<br class="ltx_break"></p>
</div>
<div id="S7.p2" class="ltx_para ltx_align_center">
<p id="S7.p2.1" class="ltx_p">© 2024 JPMorgan Chase &amp; Co. All rights reserved.</p>
</div>
<div class="ltx_pagination ltx_centering ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ADM<sup id="bib.bibx1.3.3.1" class="ltx_sup"><span id="bib.bibx1.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Samuel A Assefa, Danial Dervovic, Mahmoud Mahfouz, Robert E Tillman, Prashant Reddy, Tucker Balch, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Generating synthetic data in finance: opportunities, challenges and pitfalls.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx1.5.1" class="ltx_text ltx_font_italic">Proceedings of the First ACM International Conference on AI in Finance</span>, pages 1–8, 2020.

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ADR<sup id="bib.bibx2.3.3.1" class="ltx_sup"><span id="bib.bibx2.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Hassan Jameel Asghar, Ming Ding, Thierry Rakotoarivelo, Sirine Mrabet, and Mohamed Ali Kaafar.

</span>
<span class="ltx_bibblock">Differentially private release of high-dimensional datasets using the gaussian copula, 2019.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BDI<sup id="bib.bibx3.3.3.1" class="ltx_sup"><span id="bib.bibx3.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Brian Belgodere, Pierre Dognin, Adam Ivankay, Igor Melnyk, Youssef Mroueh, Aleksandra Mojsilovic, Jiri Navartil, Apoorva Nitsure, Inkit Padhi, Mattia Rigotti, et al.

</span>
<span class="ltx_bibblock">Auditing and generating synthetic data with controllable trust trade-offs.

</span>
<span class="ltx_bibblock"><span id="bib.bibx3.5.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.10819</span>, 2023.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DL24]</span>
<span class="ltx_bibblock">
Yuntao Du and Ninghui Li.

</span>
<span class="ltx_bibblock">Towards principled assessment of tabular data synthesis algorithms.

</span>
<span class="ltx_bibblock"><span id="bib.bibx4.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.06806</span>, 2024.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GBWT23]</span>
<span class="ltx_bibblock">
Matteo Giomi, Franziska Boenisch, Christoph Wehmeyer, and Borbála Tasnádi.

</span>
<span class="ltx_bibblock">A unified framework for quantifying privacy risk in synthetic data, 2023.

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GPAM<sup id="bib.bibx6.3.3.1" class="ltx_sup"><span id="bib.bibx6.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>14]</span>
<span class="ltx_bibblock">
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial networks, 2014.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HCS<sup id="bib.bibx7.3.3.1" class="ltx_sup"><span id="bib.bibx7.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Florimond Houssiau, Samuel N Cohen, Lukasz Szpruch, Owen Daniel, Michaela G Lawrence, Robin Mitra, Henry Wilde, and Callum Mole.

</span>
<span class="ltx_bibblock">A framework for auditable synthetic data generation.

</span>
<span class="ltx_bibblock"><span id="bib.bibx7.5.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.11540</span>, 2022.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HJC<sup id="bib.bibx8.3.3.1" class="ltx_sup"><span id="bib.bibx8.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Florimond Houssiau, James Jordon, Samuel N Cohen, Owen Daniel, Andrew Elliott, James Geddes, Callum Mole, Camila Rangel-Smith, and Lukasz Szpruch.

</span>
<span class="ltx_bibblock">Tapas: a toolbox for adversarial privacy auditing of synthetic data.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx8.5.1" class="ltx_text ltx_font_italic">NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research</span>, 2022.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KNP<sup id="bib.bibx9.3.3.1" class="ltx_sup"><span id="bib.bibx9.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Eleonora Kreačić, Navid Nouri, Vamsi K. Potluru, Tucker Balch, and Manuela Veloso.

</span>
<span class="ltx_bibblock">Differentially private synthetic data using KD-trees.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx9.5.1" class="ltx_text ltx_font_italic">The 39th Conference on Uncertainty in Artificial Intelligence</span>, 2023.

</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LWSF23]</span>
<span class="ltx_bibblock">
Zinan Lin, Shuaiqi Wang, Vyas Sekar, and Giulia Fanti.

</span>
<span class="ltx_bibblock">Summary statistic privacy in data sharing, 2023.

</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[NS07]</span>
<span class="ltx_bibblock">
Arvind Narayanan and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">How to break anonymity of the netflix prize dataset, 2007.

</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PMG<sup id="bib.bibx12.3.3.1" class="ltx_sup"><span id="bib.bibx12.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
Noseong Park, Mahmoud Mohammadi, Kshitij Gorde, Sushil Jajodia, Hongkyu Park, and Youngmin Kim.

</span>
<span class="ltx_bibblock">Data synthesis based on generative adversarial networks.

</span>
<span class="ltx_bibblock"><span id="bib.bibx12.5.1" class="ltx_text ltx_font_italic">Proceedings of the VLDB Endowment</span>, 11(10):1071–1083, jun 2018.

</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PWV16]</span>
<span class="ltx_bibblock">
Neha Patki, Roy Wedge, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">The synthetic data vault.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx13.1.1" class="ltx_text ltx_font_italic">2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)</span>, pages 399–410, 2016.

</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SSS16]</span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx14.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1610.05820, 2016.

</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SZZ<sup id="bib.bibx15.3.3.1" class="ltx_sup"><span id="bib.bibx15.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Hui Sun, Tianqing Zhu, Zhiqiu Zhang, Dawei Jin, Ping Xiong, and Wanlei Zhou.

</span>
<span class="ltx_bibblock">Adversarial attacks against deep generative models on data: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bibx15.5.1" class="ltx_text ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</span>, 35(4):3367–3388, apr 2023.

</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VBP<sup id="bib.bibx16.3.3.1" class="ltx_sup"><span id="bib.bibx16.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Svitlana Vyetrenko, David Byrd, Nick Petosa, Mahmoud Mahfouz, Danial Dervovic, Manuela Veloso, and Tucker Hybinette Balch.

</span>
<span class="ltx_bibblock">Get real: Realism metrics for robust limit order book market simulations, 2019.

</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XLW<sup id="bib.bibx17.3.3.1" class="ltx_sup"><span id="bib.bibx17.3.3.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou.

</span>
<span class="ltx_bibblock">Differentially private generative adversarial network, 2018.

</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YJvdS19]</span>
<span class="ltx_bibblock">
Jinsung Yoon, James Jordon, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">PATE-GAN: Generating synthetic data with differential privacy guarantees.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx18.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.14723" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.14724" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.14724">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.14724" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.14725" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 14:34:29 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
