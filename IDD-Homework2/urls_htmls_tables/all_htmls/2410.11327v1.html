<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Sequential LLM Framework for Fashion Recommendation</title>
<!--Generated on Tue Oct 15 06:48:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.11327v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S1" title="In Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S2" title="In Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S3" title="In Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Fashion Characteristics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S4" title="In Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S4.SS1" title="In 4 Method ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Problem Formulation and Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S4.SS2" title="In 4 Method ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Prompt Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S4.SS3" title="In 4 Method ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Training Strategy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S4.SS4" title="In 4 Method ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Retrieval and Ranking Method</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5" title="In Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.SS1" title="In 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.SS2" title="In 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Evaluation Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.SS3" title="In 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.SS4" title="In 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Further Investigation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S6" title="In Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Sequential LLM Framework for Fashion Recommendation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id2.2.2">Han Liu<sup class="ltx_sup" id="id1.1.1.1"><math alttext="\spadesuit" class="ltx_Math" display="inline" id="id1.1.1.1.m1.1"><semantics id="id1.1.1.1.m1.1a"><mi id="id1.1.1.1.m1.1.1" mathvariant="normal" xref="id1.1.1.1.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="id1.1.1.1.m1.1b"><ci id="id1.1.1.1.m1.1.1.cmml" xref="id1.1.1.1.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.1.m1.1c">\spadesuit</annotation><annotation encoding="application/x-llamapun" id="id1.1.1.1.m1.1d">♠</annotation></semantics></math></sup><sup class="ltx_sup" id="id2.2.2.2"><math alttext="\dagger" class="ltx_Math" display="inline" id="id2.2.2.2.m1.1"><semantics id="id2.2.2.2.m1.1a"><mo id="id2.2.2.2.m1.1.1" xref="id2.2.2.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id2.2.2.2.m1.1b"><ci id="id2.2.2.2.m1.1.1.cmml" xref="id2.2.2.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.2.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="id2.2.2.2.m1.1d">†</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id3.3.3">Xianfeng Tang<sup class="ltx_sup" id="id3.3.3.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id3.3.3.1.m1.1"><semantics id="id3.3.3.1.m1.1a"><mi id="id3.3.3.1.m1.1.1" mathvariant="normal" xref="id3.3.3.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id3.3.3.1.m1.1b"><ci id="id3.3.3.1.m1.1.1.cmml" xref="id3.3.3.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id3.3.3.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id3.3.3.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id4.4.4">Tianlang Chen<sup class="ltx_sup" id="id4.4.4.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id4.4.4.1.m1.1"><semantics id="id4.4.4.1.m1.1a"><mi id="id4.4.4.1.m1.1.1" mathvariant="normal" xref="id4.4.4.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id4.4.4.1.m1.1b"><ci id="id4.4.4.1.m1.1.1.cmml" xref="id4.4.4.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id4.4.4.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id4.4.4.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id5.5.5">Jiapeng Liu<sup class="ltx_sup" id="id5.5.5.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id5.5.5.1.m1.1"><semantics id="id5.5.5.1.m1.1a"><mi id="id5.5.5.1.m1.1.1" mathvariant="normal" xref="id5.5.5.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id5.5.5.1.m1.1b"><ci id="id5.5.5.1.m1.1.1.cmml" xref="id5.5.5.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id5.5.5.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id5.5.5.1.m1.1d">♢</annotation></semantics></math></sup></span>,

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id6.6.6">Indu Indu<sup class="ltx_sup" id="id6.6.6.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id6.6.6.1.m1.1"><semantics id="id6.6.6.1.m1.1a"><mi id="id6.6.6.1.m1.1.1" mathvariant="normal" xref="id6.6.6.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id6.6.6.1.m1.1b"><ci id="id6.6.6.1.m1.1.1.cmml" xref="id6.6.6.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id6.6.6.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id6.6.6.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id8.8.8">Henry Peng Zou<sup class="ltx_sup" id="id7.7.7.1"><math alttext="\clubsuit" class="ltx_Math" display="inline" id="id7.7.7.1.m1.1"><semantics id="id7.7.7.1.m1.1a"><mi id="id7.7.7.1.m1.1.1" mathvariant="normal" xref="id7.7.7.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id7.7.7.1.m1.1b"><ci id="id7.7.7.1.m1.1.1.cmml" xref="id7.7.7.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id7.7.7.1.m1.1c">\clubsuit</annotation><annotation encoding="application/x-llamapun" id="id7.7.7.1.m1.1d">♣</annotation></semantics></math></sup><sup class="ltx_sup" id="id8.8.8.2"><math alttext="\dagger" class="ltx_Math" display="inline" id="id8.8.8.2.m1.1"><semantics id="id8.8.8.2.m1.1a"><mo id="id8.8.8.2.m1.1.1" xref="id8.8.8.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id8.8.8.2.m1.1b"><ci id="id8.8.8.2.m1.1.1.cmml" xref="id8.8.8.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id8.8.8.2.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="id8.8.8.2.m1.1d">†</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id9.9.9">Peng Dai<sup class="ltx_sup" id="id9.9.9.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id9.9.9.1.m1.1"><semantics id="id9.9.9.1.m1.1a"><mi id="id9.9.9.1.m1.1.1" mathvariant="normal" xref="id9.9.9.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id9.9.9.1.m1.1b"><ci id="id9.9.9.1.m1.1.1.cmml" xref="id9.9.9.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id9.9.9.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id9.9.9.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id10.10.10">Roberto Fernandez Galan<sup class="ltx_sup" id="id10.10.10.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id10.10.10.1.m1.1"><semantics id="id10.10.10.1.m1.1a"><mi id="id10.10.10.1.m1.1.1" mathvariant="normal" xref="id10.10.10.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id10.10.10.1.m1.1b"><ci id="id10.10.10.1.m1.1.1.cmml" xref="id10.10.10.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id10.10.10.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id10.10.10.1.m1.1d">♢</annotation></semantics></math></sup></span>,

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id11.11.11">Michael D Porter<sup class="ltx_sup" id="id11.11.11.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id11.11.11.1.m1.1"><semantics id="id11.11.11.1.m1.1a"><mi id="id11.11.11.1.m1.1.1" mathvariant="normal" xref="id11.11.11.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id11.11.11.1.m1.1b"><ci id="id11.11.11.1.m1.1.1.cmml" xref="id11.11.11.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id11.11.11.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id11.11.11.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id12.12.12">Dongmei Jia<sup class="ltx_sup" id="id12.12.12.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id12.12.12.1.m1.1"><semantics id="id12.12.12.1.m1.1a"><mi id="id12.12.12.1.m1.1.1" mathvariant="normal" xref="id12.12.12.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id12.12.12.1.m1.1b"><ci id="id12.12.12.1.m1.1.1.cmml" xref="id12.12.12.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id12.12.12.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id12.12.12.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id13.13.13">Ning Zhang<sup class="ltx_sup" id="id13.13.13.1"><math alttext="\spadesuit" class="ltx_Math" display="inline" id="id13.13.13.1.m1.1"><semantics id="id13.13.13.1.m1.1a"><mi id="id13.13.13.1.m1.1.1" mathvariant="normal" xref="id13.13.13.1.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="id13.13.13.1.m1.1b"><ci id="id13.13.13.1.m1.1.1.cmml" xref="id13.13.13.1.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="id13.13.13.1.m1.1c">\spadesuit</annotation><annotation encoding="application/x-llamapun" id="id13.13.13.1.m1.1d">♠</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="id14.14.14">Lian Xiong<sup class="ltx_sup" id="id14.14.14.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id14.14.14.1.m1.1"><semantics id="id14.14.14.1.m1.1a"><mi id="id14.14.14.1.m1.1.1" mathvariant="normal" xref="id14.14.14.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id14.14.14.1.m1.1b"><ci id="id14.14.14.1.m1.1.1.cmml" xref="id14.14.14.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id14.14.14.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id14.14.14.1.m1.1d">♢</annotation></semantics></math></sup></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.15"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="id15.15.15.m1.1"><semantics id="id15.15.15.m1.1a"><mi id="id15.15.15.m1.1.1" mathvariant="normal" xref="id15.15.15.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id15.15.15.m1.1b"><ci id="id15.15.15.m1.1.1.cmml" xref="id15.15.15.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id15.15.15.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="id15.15.15.m1.1d">♢</annotation></semantics></math></sup>Amazon
<sup class="ltx_sup" id="id16.16.16"><math alttext="\spadesuit" class="ltx_Math" display="inline" id="id16.16.16.m1.1"><semantics id="id16.16.16.m1.1a"><mi id="id16.16.16.m1.1.1" mathvariant="normal" xref="id16.16.16.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="id16.16.16.m1.1b"><ci id="id16.16.16.m1.1.1.cmml" xref="id16.16.16.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="id16.16.16.m1.1c">\spadesuit</annotation><annotation encoding="application/x-llamapun" id="id16.16.16.m1.1d">♠</annotation></semantics></math></sup>Washington University in St. Louis
<sup class="ltx_sup" id="id17.17.17"><math alttext="\clubsuit" class="ltx_Math" display="inline" id="id17.17.17.m1.1"><semantics id="id17.17.17.m1.1a"><mi id="id17.17.17.m1.1.1" mathvariant="normal" xref="id17.17.17.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id17.17.17.m1.1b"><ci id="id17.17.17.m1.1.1.cmml" xref="id17.17.17.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id17.17.17.m1.1c">\clubsuit</annotation><annotation encoding="application/x-llamapun" id="id17.17.17.m1.1d">♣</annotation></semantics></math></sup>University of Illinois Chicago

<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id18.18.id1">{h.liu1,zhang.ning}@wustl.edu</span>,
<span class="ltx_text ltx_font_typewriter" id="id19.19.id2">{xianft,ctianlan,liujiape,indchand}@amazon.com</span>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id20.20.id3">pzou3@uic.edu</span>,
<span class="ltx_text ltx_font_typewriter" id="id21.21.id4">{pengdai,galanrob,mdporter,djia,lianxion}@amazon.com</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id22.id1">The fashion industry is one of the leading domains in the global e-commerce sector, prompting major online retailers to employ recommendation systems for product suggestions and customer convenience.
While recommendation systems have been widely studied, most are designed for general e-commerce problems and struggle with the unique challenges of the fashion domain.
To address these issues, we propose a sequential fashion recommendation framework that leverages a pre-trained large language model (LLM) enhanced with recommendation-specific prompts. Our framework employs parameter-efficient fine-tuning with extensive fashion data and introduces a novel mix-up-based retrieval technique for translating text into relevant product suggestions.
Extensive experiments show our proposed framework significantly enhances fashion recommendation performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.17">
<p class="ltx_p" id="p1.17.18"><span class="ltx_text ltx_font_bold" id="p1.17.18.1">Sequential LLM Framework for Fashion Recommendation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.17.17" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.17.17.17" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.17.17.17.17">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.5.5.5.5.5">
<span class="ltx_td ltx_align_center" id="p1.5.5.5.5.5.5"><span class="ltx_text ltx_font_bold" id="p1.5.5.5.5.5.5.5">
Han Liu<sup class="ltx_sup" id="p1.1.1.1.1.1.1.1.1"><math alttext="\spadesuit" class="ltx_Math" display="inline" id="p1.1.1.1.1.1.1.1.1.m1.1"><semantics id="p1.1.1.1.1.1.1.1.1.m1.1a"><mi id="p1.1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="p1.1.1.1.1.1.1.1.1.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="p1.1.1.1.1.1.1.1.1.m1.1b"><ci id="p1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="p1.1.1.1.1.1.1.1.1.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.1.1.1.1.1.1.1.m1.1c">\spadesuit</annotation><annotation encoding="application/x-llamapun" id="p1.1.1.1.1.1.1.1.1.m1.1d">♠</annotation></semantics></math></sup><sup class="ltx_sup" id="p1.2.2.2.2.2.2.2.2"><math alttext="\dagger" class="ltx_Math" display="inline" id="p1.2.2.2.2.2.2.2.2.m1.1"><semantics id="p1.2.2.2.2.2.2.2.2.m1.1a"><mo id="p1.2.2.2.2.2.2.2.2.m1.1.1" xref="p1.2.2.2.2.2.2.2.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="p1.2.2.2.2.2.2.2.2.m1.1b"><ci id="p1.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="p1.2.2.2.2.2.2.2.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.2.2.2.2.2.2.2.2.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="p1.2.2.2.2.2.2.2.2.m1.1d">†</annotation></semantics></math></sup>,
Xianfeng Tang<sup class="ltx_sup" id="p1.3.3.3.3.3.3.3.3"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.3.3.3.3.3.3.3.3.m1.1"><semantics id="p1.3.3.3.3.3.3.3.3.m1.1a"><mi id="p1.3.3.3.3.3.3.3.3.m1.1.1" mathvariant="normal" xref="p1.3.3.3.3.3.3.3.3.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.3.3.3.3.3.3.3.3.m1.1b"><ci id="p1.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="p1.3.3.3.3.3.3.3.3.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.3.3.3.3.3.3.3.3.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.3.3.3.3.3.3.3.3.m1.1d">♢</annotation></semantics></math></sup>,
Tianlang Chen<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.4"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.4.4.4.4.4.4.4.4.m1.1"><semantics id="p1.4.4.4.4.4.4.4.4.m1.1a"><mi id="p1.4.4.4.4.4.4.4.4.m1.1.1" mathvariant="normal" xref="p1.4.4.4.4.4.4.4.4.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.4.4.4.4.4.4.4.4.m1.1b"><ci id="p1.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="p1.4.4.4.4.4.4.4.4.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.4.4.4.4.4.4.4.4.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.4.4.4.4.4.4.4.4.m1.1d">♢</annotation></semantics></math></sup>,
Jiapeng Liu<sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.5"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.5.5.5.5.5.5.5.5.m1.1"><semantics id="p1.5.5.5.5.5.5.5.5.m1.1a"><mi id="p1.5.5.5.5.5.5.5.5.m1.1.1" mathvariant="normal" xref="p1.5.5.5.5.5.5.5.5.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.5.5.5.5.5.5.5.5.m1.1b"><ci id="p1.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="p1.5.5.5.5.5.5.5.5.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.5.5.5.5.5.5.5.5.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.5.5.5.5.5.5.5.5.m1.1d">♢</annotation></semantics></math></sup>,</span></span></span>
<span class="ltx_tr" id="p1.10.10.10.10.10">
<span class="ltx_td ltx_align_center" id="p1.10.10.10.10.10.5"><span class="ltx_text ltx_font_bold" id="p1.6.6.6.6.6.1.1">Indu Indu<sup class="ltx_sup" id="p1.6.6.6.6.6.1.1.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.6.6.6.6.6.1.1.1.m1.1"><semantics id="p1.6.6.6.6.6.1.1.1.m1.1a"><mi id="p1.6.6.6.6.6.1.1.1.m1.1.1" mathvariant="normal" xref="p1.6.6.6.6.6.1.1.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.6.6.6.6.6.1.1.1.m1.1b"><ci id="p1.6.6.6.6.6.1.1.1.m1.1.1.cmml" xref="p1.6.6.6.6.6.1.1.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.6.6.6.6.6.1.1.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.6.6.6.6.6.1.1.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="p1.8.8.8.8.8.3.3">Henry Peng Zou<sup class="ltx_sup" id="p1.7.7.7.7.7.2.2.1"><math alttext="\clubsuit" class="ltx_Math" display="inline" id="p1.7.7.7.7.7.2.2.1.m1.1"><semantics id="p1.7.7.7.7.7.2.2.1.m1.1a"><mi id="p1.7.7.7.7.7.2.2.1.m1.1.1" mathvariant="normal" xref="p1.7.7.7.7.7.2.2.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="p1.7.7.7.7.7.2.2.1.m1.1b"><ci id="p1.7.7.7.7.7.2.2.1.m1.1.1.cmml" xref="p1.7.7.7.7.7.2.2.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.7.7.7.7.7.2.2.1.m1.1c">\clubsuit</annotation><annotation encoding="application/x-llamapun" id="p1.7.7.7.7.7.2.2.1.m1.1d">♣</annotation></semantics></math></sup><sup class="ltx_sup" id="p1.8.8.8.8.8.3.3.2"><math alttext="\dagger" class="ltx_Math" display="inline" id="p1.8.8.8.8.8.3.3.2.m1.1"><semantics id="p1.8.8.8.8.8.3.3.2.m1.1a"><mo id="p1.8.8.8.8.8.3.3.2.m1.1.1" xref="p1.8.8.8.8.8.3.3.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="p1.8.8.8.8.8.3.3.2.m1.1b"><ci id="p1.8.8.8.8.8.3.3.2.m1.1.1.cmml" xref="p1.8.8.8.8.8.3.3.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.8.8.8.8.8.3.3.2.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="p1.8.8.8.8.8.3.3.2.m1.1d">†</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="p1.9.9.9.9.9.4.4">Peng Dai<sup class="ltx_sup" id="p1.9.9.9.9.9.4.4.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.9.9.9.9.9.4.4.1.m1.1"><semantics id="p1.9.9.9.9.9.4.4.1.m1.1a"><mi id="p1.9.9.9.9.9.4.4.1.m1.1.1" mathvariant="normal" xref="p1.9.9.9.9.9.4.4.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.9.9.9.9.9.4.4.1.m1.1b"><ci id="p1.9.9.9.9.9.4.4.1.m1.1.1.cmml" xref="p1.9.9.9.9.9.4.4.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.9.9.9.9.9.4.4.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.9.9.9.9.9.4.4.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="p1.10.10.10.10.10.5.5">Roberto Fernandez Galan<sup class="ltx_sup" id="p1.10.10.10.10.10.5.5.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.10.10.10.10.10.5.5.1.m1.1"><semantics id="p1.10.10.10.10.10.5.5.1.m1.1a"><mi id="p1.10.10.10.10.10.5.5.1.m1.1.1" mathvariant="normal" xref="p1.10.10.10.10.10.5.5.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.10.10.10.10.10.5.5.1.m1.1b"><ci id="p1.10.10.10.10.10.5.5.1.m1.1.1.cmml" xref="p1.10.10.10.10.10.5.5.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.10.10.10.10.10.5.5.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.10.10.10.10.10.5.5.1.m1.1d">♢</annotation></semantics></math></sup></span>,</span></span>
<span class="ltx_tr" id="p1.14.14.14.14.14">
<span class="ltx_td ltx_align_center" id="p1.14.14.14.14.14.4"><span class="ltx_text ltx_font_bold" id="p1.11.11.11.11.11.1.1">Michael D Porter<sup class="ltx_sup" id="p1.11.11.11.11.11.1.1.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.11.11.11.11.11.1.1.1.m1.1"><semantics id="p1.11.11.11.11.11.1.1.1.m1.1a"><mi id="p1.11.11.11.11.11.1.1.1.m1.1.1" mathvariant="normal" xref="p1.11.11.11.11.11.1.1.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.11.11.11.11.11.1.1.1.m1.1b"><ci id="p1.11.11.11.11.11.1.1.1.m1.1.1.cmml" xref="p1.11.11.11.11.11.1.1.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.11.11.11.11.11.1.1.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.11.11.11.11.11.1.1.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="p1.12.12.12.12.12.2.2">Dongmei Jia<sup class="ltx_sup" id="p1.12.12.12.12.12.2.2.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.12.12.12.12.12.2.2.1.m1.1"><semantics id="p1.12.12.12.12.12.2.2.1.m1.1a"><mi id="p1.12.12.12.12.12.2.2.1.m1.1.1" mathvariant="normal" xref="p1.12.12.12.12.12.2.2.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.12.12.12.12.12.2.2.1.m1.1b"><ci id="p1.12.12.12.12.12.2.2.1.m1.1.1.cmml" xref="p1.12.12.12.12.12.2.2.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.12.12.12.12.12.2.2.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.12.12.12.12.12.2.2.1.m1.1d">♢</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="p1.13.13.13.13.13.3.3">Ning Zhang<sup class="ltx_sup" id="p1.13.13.13.13.13.3.3.1"><math alttext="\spadesuit" class="ltx_Math" display="inline" id="p1.13.13.13.13.13.3.3.1.m1.1"><semantics id="p1.13.13.13.13.13.3.3.1.m1.1a"><mi id="p1.13.13.13.13.13.3.3.1.m1.1.1" mathvariant="normal" xref="p1.13.13.13.13.13.3.3.1.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="p1.13.13.13.13.13.3.3.1.m1.1b"><ci id="p1.13.13.13.13.13.3.3.1.m1.1.1.cmml" xref="p1.13.13.13.13.13.3.3.1.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.13.13.13.13.13.3.3.1.m1.1c">\spadesuit</annotation><annotation encoding="application/x-llamapun" id="p1.13.13.13.13.13.3.3.1.m1.1d">♠</annotation></semantics></math></sup></span>,
<span class="ltx_text ltx_font_bold" id="p1.14.14.14.14.14.4.4">Lian Xiong<sup class="ltx_sup" id="p1.14.14.14.14.14.4.4.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.14.14.14.14.14.4.4.1.m1.1"><semantics id="p1.14.14.14.14.14.4.4.1.m1.1a"><mi id="p1.14.14.14.14.14.4.4.1.m1.1.1" mathvariant="normal" xref="p1.14.14.14.14.14.4.4.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.14.14.14.14.14.4.4.1.m1.1b"><ci id="p1.14.14.14.14.14.4.4.1.m1.1.1.cmml" xref="p1.14.14.14.14.14.4.4.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.14.14.14.14.14.4.4.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.14.14.14.14.14.4.4.1.m1.1d">♢</annotation></semantics></math></sup></span></span></span>
<span class="ltx_tr" id="p1.17.17.17.17.17">
<span class="ltx_td ltx_align_center" id="p1.17.17.17.17.17.3"><sup class="ltx_sup" id="p1.15.15.15.15.15.1.1"><math alttext="\diamondsuit" class="ltx_Math" display="inline" id="p1.15.15.15.15.15.1.1.m1.1"><semantics id="p1.15.15.15.15.15.1.1.m1.1a"><mi id="p1.15.15.15.15.15.1.1.m1.1.1" mathvariant="normal" xref="p1.15.15.15.15.15.1.1.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="p1.15.15.15.15.15.1.1.m1.1b"><ci id="p1.15.15.15.15.15.1.1.m1.1.1.cmml" xref="p1.15.15.15.15.15.1.1.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.15.15.15.15.15.1.1.m1.1c">\diamondsuit</annotation><annotation encoding="application/x-llamapun" id="p1.15.15.15.15.15.1.1.m1.1d">♢</annotation></semantics></math></sup>Amazon
<sup class="ltx_sup" id="p1.16.16.16.16.16.2.2"><math alttext="\spadesuit" class="ltx_Math" display="inline" id="p1.16.16.16.16.16.2.2.m1.1"><semantics id="p1.16.16.16.16.16.2.2.m1.1a"><mi id="p1.16.16.16.16.16.2.2.m1.1.1" mathvariant="normal" xref="p1.16.16.16.16.16.2.2.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="p1.16.16.16.16.16.2.2.m1.1b"><ci id="p1.16.16.16.16.16.2.2.m1.1.1.cmml" xref="p1.16.16.16.16.16.2.2.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.16.16.16.16.16.2.2.m1.1c">\spadesuit</annotation><annotation encoding="application/x-llamapun" id="p1.16.16.16.16.16.2.2.m1.1d">♠</annotation></semantics></math></sup>Washington University in St. Louis
<sup class="ltx_sup" id="p1.17.17.17.17.17.3.3"><math alttext="\clubsuit" class="ltx_Math" display="inline" id="p1.17.17.17.17.17.3.3.m1.1"><semantics id="p1.17.17.17.17.17.3.3.m1.1a"><mi id="p1.17.17.17.17.17.3.3.m1.1.1" mathvariant="normal" xref="p1.17.17.17.17.17.3.3.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="p1.17.17.17.17.17.3.3.m1.1b"><ci id="p1.17.17.17.17.17.3.3.m1.1.1.cmml" xref="p1.17.17.17.17.17.3.3.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.17.17.17.17.17.3.3.m1.1c">\clubsuit</annotation><annotation encoding="application/x-llamapun" id="p1.17.17.17.17.17.3.3.m1.1d">♣</annotation></semantics></math></sup>University of Illinois Chicago</span></span>
<span class="ltx_tr" id="p1.17.17.17.17.18.1">
<span class="ltx_td ltx_align_center" id="p1.17.17.17.17.18.1.1"><span class="ltx_text ltx_font_typewriter" id="p1.17.17.17.17.18.1.1.1">{h.liu1,zhang.ning}@wustl.edu</span>,
<span class="ltx_text ltx_font_typewriter" id="p1.17.17.17.17.18.1.1.2">{xianft,ctianlan,liujiape,indchand}@amazon.com</span>,</span></span>
<span class="ltx_tr" id="p1.17.17.17.17.19.2">
<span class="ltx_td ltx_align_center" id="p1.17.17.17.17.19.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.17.17.17.17.19.2.1.1">pzou3@uic.edu</span>,
<span class="ltx_text ltx_font_typewriter" id="p1.17.17.17.17.19.2.1.2">{pengdai,galanrob,mdporter,djia,lianxion}@amazon.com</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_type">footnotetext: </span>Work done as an intern at Amazon.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In recent years, fashion e-commerce has garnered considerable global attentions from both consumers and investors.
By 2023, the U.S. retail fashion e-commerce market is projected to generate revenues exceeding 207 billion U.S. dollars <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib9" title="">Gelder </a></cite>. One of the primary objectives of e-commerce is to provide a smooth purchase experience for consumers to purchase products they are looking for.
To this end, recommendation systems (RS) have become an essential part of many businesses <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib45" title="">2019</a>); Jin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib19" title="">2023</a>)</cite>.
While existing fashion recommendation systems <cite class="ltx_cite ltx_citemacro_cite">He and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib12" title="">2016b</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib29" title="">2017</a>); Kang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib20" title="">2017</a>); Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib43" title="">2021</a>)</cite> predominantly incorporate the visual appearance into the traditional recommendation, they often require resource-intensive processes for image collection and training. Additionally, they often struggle to capture the evolving nature of user interactions over time. In light of this, there has been a growing interest in sequential recommendation techniques <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib38" title="">2019</a>); Kang and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib21" title="">2018</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib25" title="">2023</a>)</cite>. These techniques model historical user interactions as temporally ordered sequences, thereby achieving remarkable efficacy in capturing both short-term and long-term user preferences.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">While sequential recommendations have succeeded in general e-commerce, the fashion domain poses unique challenges. Our analysis of real-world user interactions on Amazon fashion highlights key differences:
First, the rapid fashion turnover leads to a sparse user-item interaction matrix, intensifying the cold-start problem <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib30" title="">2020</a>)</cite>.
Second, extensive purchase comparisons demand sophisticated approaches to capture fine-grained user preferences.
Third, fashion-specific attributes like seasonality, occasion, and holiday trends require specialized modeling.
Fourth, diverse search queries that reflect explicit user intentions, necessitate novel modeling techniques. Beyond these fashion-specific challenges, traditional recommendation contexts often require specialized models tailored to particular scenarios, such as the cold-start problem <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib8" title="">2020</a>)</cite>, which will result in a large number of models that are challenging to maintain and scale.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To tackle these challenges holistically, we present a sequential fashion recommendation system augmented by a large language model (LLM). Trained on vast and diverse datasets, LLMs have a profound understanding of various domains. Leveraging their extensive knowledge and commonsense reasoning capabilities <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib47" title="">2023</a>)</cite>, LLMs provide a promising solution to generate meaningful recommendations. This is particularly beneficial in overcoming cold start problems and in accurately discerning fine-grained user preferences. Additionally, LLMs could offer a unified framework capable of addressing diverse recommendation tasks.
Our LLM-augmented recommendation system consists of three primary stages. In the first stage, prompt engineering techniques are used to devise specialized prompts that align with recommendation-specific goals, enabling LLM to perceive fine-grained user preferences.
In the second stage, we adapt Parameter-Efficient Fine-Tuning (PEFT) techniques <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib16" title="">2021</a>); Dettmers et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib7" title="">2023</a>)</cite> to mitigate prohibitively expensive training costs.
In the final stage, we utilize predicted product titles and IDs to retrieve and rank potential candidate items. We present a mix-up-based retrieval technique that harnesses the strengths of both ID and title embeddings.
Our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p4">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We conduct an in-depth data analysis on real-world user interaction patterns, identifying four key characteristics for fashion recommendation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose a comprehensive recommendation framework tailored to the fashion domain. Within this framework, we propose advanced LLM enhancement techniques to address the unique challenges for fashion recommendation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">The comprehensive evaluations demonstrate that the proposed framework significantly enhance recommendation performance.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Sequential Recommendation. </span>
Recommendation systems have gained significant interest from both academia and industry <cite class="ltx_cite ltx_citemacro_cite">Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib32" title="">2022</a>)</cite>, with sequential recommendation receiving particular attention due to its exceptional capabilities of capturing the long-term and short-term dynamics of users <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib24" title="">2022</a>); Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib33" title="">2023</a>)</cite>. The objective of sequential recommendation is to predict the next items that users may be interested in based on their historical interactions. There are various techniques being proposed to model user sequential patterns, from the Markov Chain <cite class="ltx_cite ltx_citemacro_cite">He and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib11" title="">2016a</a>); Rendle et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib36" title="">2010</a>)</cite> in early works to recent neural network-based techniques, such as Gated Recurrent Units (GRU) <cite class="ltx_cite ltx_citemacro_cite">Hidasi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib13" title="">2015</a>)</cite>, Convolutional Neural Network (CNN) <cite class="ltx_cite ltx_citemacro_cite">Tang and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib39" title="">2018</a>)</cite>, and Transformer <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib38" title="">2019</a>); Kang and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib21" title="">2018</a>); Hou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib15" title="">2022</a>)</cite>. Recently, Recformer <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib25" title="">2023</a>)</cite>, a transformer-based framework for learning transferable language representations, has been proposed for sequential recommendations. It has shown superior performance, especially in cold-start settings.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Fashion Recommendation.</span>
Fashion recommendation systems, which target one vertical market - fashion and garment products, have gained popularity recently <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib26" title="">2019</a>); Hou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib14" title="">2019</a>)</cite>.
Existing approaches mainly use visual signals to capture fashion characteristics by enhancing item representations <cite class="ltx_cite ltx_citemacro_cite">He and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib12" title="">2016b</a>); He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib10" title="">2016</a>); Kang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib20" title="">2017</a>)</cite>, modeling visual compatibility <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib5" title="">2019</a>); Yin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib42" title="">2019</a>)</cite>, and identifying aesthetic and style information <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib43" title="">2021</a>)</cite>.
For example, <cite class="ltx_cite ltx_citemacro_citet">He and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib12" title="">2016b</a>)</cite> proposed the Visual Bayesian Personalized Ranking (VBPR), which incorporates visual features extracted from product images into matrix factorization frameworks using pre-trained CNNs. <cite class="ltx_cite ltx_citemacro_citet">Yin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib42" title="">2019</a>)</cite> utilized visual encodings to learn visual compatibility by training a triplet network, where an anchor item is paired with both a compatible and a non-compatible item to learn embeddings that capture visual compatibility. Additionally, <cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib43" title="">2021</a>)</cite> introduced a deep aesthetic network that extracts aesthetic features from product images, incorporating them into recommendations to model users’ preferences for aesthetic appeal.
The methods for extracting visual signals have evolved over time. Early studies typically used pre-trained CNNs for visual encodings <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib10" title="">2016</a>); He and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib12" title="">2016b</a>)</cite>. However, recent works have shifted towards training visual encoders on specialized datasets <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib42" title="">2019</a>)</cite> or jointly training visual feature extractors and recommendation modules <cite class="ltx_cite ltx_citemacro_cite">Kang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib20" title="">2017</a>); Lin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib26" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">While incorporating visual signals is an inspiring direction, it falls outside the scope of and is furthermore orthogonal to our current study, which focuses on leveraging textual data to model user interactions. This choice is driven by the fact that learning effective product representations from images typically requires large datasets to generalize well <cite class="ltx_cite ltx_citemacro_cite">Deldjoo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib6" title="">2022</a>)</cite>, which would introduce significant demands in terms of data collection and computational resources, making it challenging for industrial deployment.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering" id="S2.F1.g1" src="fashion_label.eps"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples highlighting fashion characteristics. Figure (a) illustrates the extensive color variations in fashion products, while Figure (b) demonstrates the seasonality attributes of fashion items.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Fashion Characteristics</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Fashion-related shopping presents unique characteristics that must be carefully considered when developing RS. We conduct an in-depth analysis on real-user interaction patterns in Amazon Fashion,
and identify the following key characteristics:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.1"><span class="ltx_text ltx_font_italic" id="S3.p2.1.1">C1: High Turnover of Products.</span>
The fashion domain is characterized by a rapid turnover of items, introducing a continuous stream of unique new products to platforms. For instance, Amazon Fashion adds approximately 3 million new purchasable products each month. Additionally, the volume of new fashion items significantly exceeds that of other categories, being 3.6 times greater than new electronics and 6.7 times more than new toy products on Amazon. This constant influx leads to a notably sparse user-item interaction matrix, gives rise to the cold-start problem <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib30" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p3">
<p class="ltx_p" id="S3.p3.1"><span class="ltx_text ltx_font_italic" id="S3.p3.1.1">C2: Thorough Purchase Comparisons.</span>
Users involved in fashion-related purchases tend to engage in more comprehensive comparisons than those shopping in other categories. For example,
the average interaction length for fashion-related purchases is 55% longer than for electronics and 81% longer than for toy-related purchases. These comprehensive comparisons can be attributed to the extensive range of options—colors, styles, and sizes of fashion products. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S2.F1" title="Figure 1 ‣ 2 Related Work ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">1</span></a> (a) provides an example of a typical shopping page for women’s dresses, which offers 30 different color options.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p4">
<p class="ltx_p" id="S3.p4.1"><span class="ltx_text ltx_font_italic" id="S3.p4.1.1">C3: Fashion Attribute-Driven Shopping.</span>
Fashion items often come with distinct attributes such as seasonality, occasion, and holiday-specific trends, which significantly influence user shopping intention. For instance, Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S2.F1" title="Figure 1 ‣ 2 Related Work ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">1</span></a> (b) shows a selection of items popular in summer, which might not receive the same attention in winter.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p5">
<p class="ltx_p" id="S3.p5.1"><span class="ltx_text ltx_font_italic" id="S3.p5.1.1">C4: High Diversity of Search Queries.</span>
Search queries serve as a crucial context for understanding the evolving interests of users. We analyze the average volume of unique search queries over multiple days across three months. Our analysis shows that the number of unique search queries for fashion items is, on average, 2.63 times as much as electronics and 2.38 times as much as toys.</p>
</div>
<div class="ltx_para" id="S3.p6">
<p class="ltx_p" id="S3.p6.1">We highlight that while other industries may share some characteristics we’ve identified, the simultaneous presence of all four is unique to the fashion industry. Additionally, the importance of each characteristic in fashion differs from other domains. For example, attributes like seasonality, occasion, and trends have a more fine-grained influence on user choice in fashion compared to electronics or consumable products. In fashion, these factors influence not only availability but also social desirability and attractiveness at a given time.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering" id="S3.F2.g1" src="llm4rec_framework_camera.eps"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of our method.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Problem Formulation and Overview</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.17"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.17.1">Problem Formulation.</span>
In the realm of sequential recommendation, consider a system composed of a set of users and items. The set of users is represented by <math alttext="\mathcal{U}=\{u_{1},u_{2},...,u_{N}\}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.4"><semantics id="S4.SS1.p1.1.m1.4a"><mrow id="S4.SS1.p1.1.m1.4.4" xref="S4.SS1.p1.1.m1.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.1.m1.4.4.5" xref="S4.SS1.p1.1.m1.4.4.5.cmml">𝒰</mi><mo id="S4.SS1.p1.1.m1.4.4.4" xref="S4.SS1.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S4.SS1.p1.1.m1.4.4.3.3" xref="S4.SS1.p1.1.m1.4.4.3.4.cmml"><mo id="S4.SS1.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S4.SS1.p1.1.m1.4.4.3.4.cmml">{</mo><msub id="S4.SS1.p1.1.m1.2.2.1.1.1" xref="S4.SS1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.2.2.1.1.1.2" xref="S4.SS1.p1.1.m1.2.2.1.1.1.2.cmml">u</mi><mn id="S4.SS1.p1.1.m1.2.2.1.1.1.3" xref="S4.SS1.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p1.1.m1.4.4.3.3.5" xref="S4.SS1.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p1.1.m1.3.3.2.2.2" xref="S4.SS1.p1.1.m1.3.3.2.2.2.cmml"><mi id="S4.SS1.p1.1.m1.3.3.2.2.2.2" xref="S4.SS1.p1.1.m1.3.3.2.2.2.2.cmml">u</mi><mn id="S4.SS1.p1.1.m1.3.3.2.2.2.3" xref="S4.SS1.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.p1.1.m1.4.4.3.3.6" xref="S4.SS1.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S4.SS1.p1.1.m1.1.1" mathvariant="normal" xref="S4.SS1.p1.1.m1.1.1.cmml">…</mi><mo id="S4.SS1.p1.1.m1.4.4.3.3.7" xref="S4.SS1.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p1.1.m1.4.4.3.3.3" xref="S4.SS1.p1.1.m1.4.4.3.3.3.cmml"><mi id="S4.SS1.p1.1.m1.4.4.3.3.3.2" xref="S4.SS1.p1.1.m1.4.4.3.3.3.2.cmml">u</mi><mi id="S4.SS1.p1.1.m1.4.4.3.3.3.3" xref="S4.SS1.p1.1.m1.4.4.3.3.3.3.cmml">N</mi></msub><mo id="S4.SS1.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S4.SS1.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.4b"><apply id="S4.SS1.p1.1.m1.4.4.cmml" xref="S4.SS1.p1.1.m1.4.4"><eq id="S4.SS1.p1.1.m1.4.4.4.cmml" xref="S4.SS1.p1.1.m1.4.4.4"></eq><ci id="S4.SS1.p1.1.m1.4.4.5.cmml" xref="S4.SS1.p1.1.m1.4.4.5">𝒰</ci><set id="S4.SS1.p1.1.m1.4.4.3.4.cmml" xref="S4.SS1.p1.1.m1.4.4.3.3"><apply id="S4.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S4.SS1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.2.2.1.1.1.2">𝑢</ci><cn id="S4.SS1.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S4.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="S4.SS1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S4.SS1.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S4.SS1.p1.1.m1.3.3.2.2.2.2">𝑢</ci><cn id="S4.SS1.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS1.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">…</ci><apply id="S4.SS1.p1.1.m1.4.4.3.3.3.cmml" xref="S4.SS1.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.4.4.3.3.3.1.cmml" xref="S4.SS1.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.1.m1.4.4.3.3.3.2.cmml" xref="S4.SS1.p1.1.m1.4.4.3.3.3.2">𝑢</ci><ci id="S4.SS1.p1.1.m1.4.4.3.3.3.3.cmml" xref="S4.SS1.p1.1.m1.4.4.3.3.3.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.4c">\mathcal{U}=\{u_{1},u_{2},...,u_{N}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.4d">caligraphic_U = { italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_u start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math>, the set of items by <math alttext="\mathcal{V}=\{v_{1},v_{2},...,v_{M}\}" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.4"><semantics id="S4.SS1.p1.2.m2.4a"><mrow id="S4.SS1.p1.2.m2.4.4" xref="S4.SS1.p1.2.m2.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.2.m2.4.4.5" xref="S4.SS1.p1.2.m2.4.4.5.cmml">𝒱</mi><mo id="S4.SS1.p1.2.m2.4.4.4" xref="S4.SS1.p1.2.m2.4.4.4.cmml">=</mo><mrow id="S4.SS1.p1.2.m2.4.4.3.3" xref="S4.SS1.p1.2.m2.4.4.3.4.cmml"><mo id="S4.SS1.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S4.SS1.p1.2.m2.4.4.3.4.cmml">{</mo><msub id="S4.SS1.p1.2.m2.2.2.1.1.1" xref="S4.SS1.p1.2.m2.2.2.1.1.1.cmml"><mi id="S4.SS1.p1.2.m2.2.2.1.1.1.2" xref="S4.SS1.p1.2.m2.2.2.1.1.1.2.cmml">v</mi><mn id="S4.SS1.p1.2.m2.2.2.1.1.1.3" xref="S4.SS1.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p1.2.m2.4.4.3.3.5" xref="S4.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p1.2.m2.3.3.2.2.2" xref="S4.SS1.p1.2.m2.3.3.2.2.2.cmml"><mi id="S4.SS1.p1.2.m2.3.3.2.2.2.2" xref="S4.SS1.p1.2.m2.3.3.2.2.2.2.cmml">v</mi><mn id="S4.SS1.p1.2.m2.3.3.2.2.2.3" xref="S4.SS1.p1.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.p1.2.m2.4.4.3.3.6" xref="S4.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><mi id="S4.SS1.p1.2.m2.1.1" mathvariant="normal" xref="S4.SS1.p1.2.m2.1.1.cmml">…</mi><mo id="S4.SS1.p1.2.m2.4.4.3.3.7" xref="S4.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p1.2.m2.4.4.3.3.3" xref="S4.SS1.p1.2.m2.4.4.3.3.3.cmml"><mi id="S4.SS1.p1.2.m2.4.4.3.3.3.2" xref="S4.SS1.p1.2.m2.4.4.3.3.3.2.cmml">v</mi><mi id="S4.SS1.p1.2.m2.4.4.3.3.3.3" xref="S4.SS1.p1.2.m2.4.4.3.3.3.3.cmml">M</mi></msub><mo id="S4.SS1.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S4.SS1.p1.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.4b"><apply id="S4.SS1.p1.2.m2.4.4.cmml" xref="S4.SS1.p1.2.m2.4.4"><eq id="S4.SS1.p1.2.m2.4.4.4.cmml" xref="S4.SS1.p1.2.m2.4.4.4"></eq><ci id="S4.SS1.p1.2.m2.4.4.5.cmml" xref="S4.SS1.p1.2.m2.4.4.5">𝒱</ci><set id="S4.SS1.p1.2.m2.4.4.3.4.cmml" xref="S4.SS1.p1.2.m2.4.4.3.3"><apply id="S4.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.2.2.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.2.m2.2.2.1.1.1.2.cmml" xref="S4.SS1.p1.2.m2.2.2.1.1.1.2">𝑣</ci><cn id="S4.SS1.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS1.p1.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S4.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="S4.SS1.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.3.3.2.2.2.1.cmml" xref="S4.SS1.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.2.m2.3.3.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.3.3.2.2.2.2">𝑣</ci><cn id="S4.SS1.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS1.p1.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">…</ci><apply id="S4.SS1.p1.2.m2.4.4.3.3.3.cmml" xref="S4.SS1.p1.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.4.4.3.3.3.1.cmml" xref="S4.SS1.p1.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.2.m2.4.4.3.3.3.2.cmml" xref="S4.SS1.p1.2.m2.4.4.3.3.3.2">𝑣</ci><ci id="S4.SS1.p1.2.m2.4.4.3.3.3.3.cmml" xref="S4.SS1.p1.2.m2.4.4.3.3.3.3">𝑀</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.4c">\mathcal{V}=\{v_{1},v_{2},...,v_{M}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.4d">caligraphic_V = { italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math> and the set of queries as <math alttext="\mathcal{Q}=\{q_{1},q_{2},...,q_{S}\}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.4"><semantics id="S4.SS1.p1.3.m3.4a"><mrow id="S4.SS1.p1.3.m3.4.4" xref="S4.SS1.p1.3.m3.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.3.m3.4.4.5" xref="S4.SS1.p1.3.m3.4.4.5.cmml">𝒬</mi><mo id="S4.SS1.p1.3.m3.4.4.4" xref="S4.SS1.p1.3.m3.4.4.4.cmml">=</mo><mrow id="S4.SS1.p1.3.m3.4.4.3.3" xref="S4.SS1.p1.3.m3.4.4.3.4.cmml"><mo id="S4.SS1.p1.3.m3.4.4.3.3.4" stretchy="false" xref="S4.SS1.p1.3.m3.4.4.3.4.cmml">{</mo><msub id="S4.SS1.p1.3.m3.2.2.1.1.1" xref="S4.SS1.p1.3.m3.2.2.1.1.1.cmml"><mi id="S4.SS1.p1.3.m3.2.2.1.1.1.2" xref="S4.SS1.p1.3.m3.2.2.1.1.1.2.cmml">q</mi><mn id="S4.SS1.p1.3.m3.2.2.1.1.1.3" xref="S4.SS1.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p1.3.m3.4.4.3.3.5" xref="S4.SS1.p1.3.m3.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p1.3.m3.3.3.2.2.2" xref="S4.SS1.p1.3.m3.3.3.2.2.2.cmml"><mi id="S4.SS1.p1.3.m3.3.3.2.2.2.2" xref="S4.SS1.p1.3.m3.3.3.2.2.2.2.cmml">q</mi><mn id="S4.SS1.p1.3.m3.3.3.2.2.2.3" xref="S4.SS1.p1.3.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.p1.3.m3.4.4.3.3.6" xref="S4.SS1.p1.3.m3.4.4.3.4.cmml">,</mo><mi id="S4.SS1.p1.3.m3.1.1" mathvariant="normal" xref="S4.SS1.p1.3.m3.1.1.cmml">…</mi><mo id="S4.SS1.p1.3.m3.4.4.3.3.7" xref="S4.SS1.p1.3.m3.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p1.3.m3.4.4.3.3.3" xref="S4.SS1.p1.3.m3.4.4.3.3.3.cmml"><mi id="S4.SS1.p1.3.m3.4.4.3.3.3.2" xref="S4.SS1.p1.3.m3.4.4.3.3.3.2.cmml">q</mi><mi id="S4.SS1.p1.3.m3.4.4.3.3.3.3" xref="S4.SS1.p1.3.m3.4.4.3.3.3.3.cmml">S</mi></msub><mo id="S4.SS1.p1.3.m3.4.4.3.3.8" stretchy="false" xref="S4.SS1.p1.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.4b"><apply id="S4.SS1.p1.3.m3.4.4.cmml" xref="S4.SS1.p1.3.m3.4.4"><eq id="S4.SS1.p1.3.m3.4.4.4.cmml" xref="S4.SS1.p1.3.m3.4.4.4"></eq><ci id="S4.SS1.p1.3.m3.4.4.5.cmml" xref="S4.SS1.p1.3.m3.4.4.5">𝒬</ci><set id="S4.SS1.p1.3.m3.4.4.3.4.cmml" xref="S4.SS1.p1.3.m3.4.4.3.3"><apply id="S4.SS1.p1.3.m3.2.2.1.1.1.cmml" xref="S4.SS1.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS1.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS1.p1.3.m3.2.2.1.1.1.2">𝑞</ci><cn id="S4.SS1.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS1.p1.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S4.SS1.p1.3.m3.3.3.2.2.2.cmml" xref="S4.SS1.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.3.3.2.2.2.1.cmml" xref="S4.SS1.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.3.m3.3.3.2.2.2.2.cmml" xref="S4.SS1.p1.3.m3.3.3.2.2.2.2">𝑞</ci><cn id="S4.SS1.p1.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S4.SS1.p1.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">…</ci><apply id="S4.SS1.p1.3.m3.4.4.3.3.3.cmml" xref="S4.SS1.p1.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.4.4.3.3.3.1.cmml" xref="S4.SS1.p1.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.3.m3.4.4.3.3.3.2.cmml" xref="S4.SS1.p1.3.m3.4.4.3.3.3.2">𝑞</ci><ci id="S4.SS1.p1.3.m3.4.4.3.3.3.3.cmml" xref="S4.SS1.p1.3.m3.4.4.3.3.3.3">𝑆</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.4c">\mathcal{Q}=\{q_{1},q_{2},...,q_{S}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.4d">caligraphic_Q = { italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_q start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT }</annotation></semantics></math>. Each user <math alttext="u_{i}\in\mathcal{U}" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><msub id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2.2" xref="S4.SS1.p1.4.m4.1.1.2.2.cmml">u</mi><mi id="S4.SS1.p1.4.m4.1.1.2.3" xref="S4.SS1.p1.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">𝒰</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><in id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1"></in><apply id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.2.1.cmml" xref="S4.SS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2.2">𝑢</ci><ci id="S4.SS1.p1.4.m4.1.1.2.3.cmml" xref="S4.SS1.p1.4.m4.1.1.2.3">𝑖</ci></apply><ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">𝒰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">u_{i}\in\mathcal{U}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_U</annotation></semantics></math> is associated with an interaction sequence <math alttext="S_{i}" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><msub id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">S</mi><mi id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">𝑆</ci><ci id="S4.SS1.p1.5.m5.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">S_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>,
which can be denoted as <math alttext="S_{i}=[(s_{1,i},a_{1,i},t_{1,i}),...,(s_{K,i},a_{K,i},t_{K,i})]" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.15"><semantics id="S4.SS1.p1.6.m6.15a"><mrow id="S4.SS1.p1.6.m6.15.15" xref="S4.SS1.p1.6.m6.15.15.cmml"><msub id="S4.SS1.p1.6.m6.15.15.4" xref="S4.SS1.p1.6.m6.15.15.4.cmml"><mi id="S4.SS1.p1.6.m6.15.15.4.2" xref="S4.SS1.p1.6.m6.15.15.4.2.cmml">S</mi><mi id="S4.SS1.p1.6.m6.15.15.4.3" xref="S4.SS1.p1.6.m6.15.15.4.3.cmml">i</mi></msub><mo id="S4.SS1.p1.6.m6.15.15.3" xref="S4.SS1.p1.6.m6.15.15.3.cmml">=</mo><mrow id="S4.SS1.p1.6.m6.15.15.2.2" xref="S4.SS1.p1.6.m6.15.15.2.3.cmml"><mo id="S4.SS1.p1.6.m6.15.15.2.2.3" stretchy="false" xref="S4.SS1.p1.6.m6.15.15.2.3.cmml">[</mo><mrow id="S4.SS1.p1.6.m6.14.14.1.1.1.3" xref="S4.SS1.p1.6.m6.14.14.1.1.1.4.cmml"><mo id="S4.SS1.p1.6.m6.14.14.1.1.1.3.4" stretchy="false" xref="S4.SS1.p1.6.m6.14.14.1.1.1.4.cmml">(</mo><msub id="S4.SS1.p1.6.m6.14.14.1.1.1.1.1" xref="S4.SS1.p1.6.m6.14.14.1.1.1.1.1.cmml"><mi id="S4.SS1.p1.6.m6.14.14.1.1.1.1.1.2" xref="S4.SS1.p1.6.m6.14.14.1.1.1.1.1.2.cmml">s</mi><mrow id="S4.SS1.p1.6.m6.2.2.2.4" xref="S4.SS1.p1.6.m6.2.2.2.3.cmml"><mn id="S4.SS1.p1.6.m6.1.1.1.1" xref="S4.SS1.p1.6.m6.1.1.1.1.cmml">1</mn><mo id="S4.SS1.p1.6.m6.2.2.2.4.1" xref="S4.SS1.p1.6.m6.2.2.2.3.cmml">,</mo><mi id="S4.SS1.p1.6.m6.2.2.2.2" xref="S4.SS1.p1.6.m6.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.6.m6.14.14.1.1.1.3.5" xref="S4.SS1.p1.6.m6.14.14.1.1.1.4.cmml">,</mo><msub id="S4.SS1.p1.6.m6.14.14.1.1.1.2.2" xref="S4.SS1.p1.6.m6.14.14.1.1.1.2.2.cmml"><mi id="S4.SS1.p1.6.m6.14.14.1.1.1.2.2.2" xref="S4.SS1.p1.6.m6.14.14.1.1.1.2.2.2.cmml">a</mi><mrow id="S4.SS1.p1.6.m6.4.4.2.4" xref="S4.SS1.p1.6.m6.4.4.2.3.cmml"><mn id="S4.SS1.p1.6.m6.3.3.1.1" xref="S4.SS1.p1.6.m6.3.3.1.1.cmml">1</mn><mo id="S4.SS1.p1.6.m6.4.4.2.4.1" xref="S4.SS1.p1.6.m6.4.4.2.3.cmml">,</mo><mi id="S4.SS1.p1.6.m6.4.4.2.2" xref="S4.SS1.p1.6.m6.4.4.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.6.m6.14.14.1.1.1.3.6" xref="S4.SS1.p1.6.m6.14.14.1.1.1.4.cmml">,</mo><msub id="S4.SS1.p1.6.m6.14.14.1.1.1.3.3" xref="S4.SS1.p1.6.m6.14.14.1.1.1.3.3.cmml"><mi id="S4.SS1.p1.6.m6.14.14.1.1.1.3.3.2" xref="S4.SS1.p1.6.m6.14.14.1.1.1.3.3.2.cmml">t</mi><mrow id="S4.SS1.p1.6.m6.6.6.2.4" xref="S4.SS1.p1.6.m6.6.6.2.3.cmml"><mn id="S4.SS1.p1.6.m6.5.5.1.1" xref="S4.SS1.p1.6.m6.5.5.1.1.cmml">1</mn><mo id="S4.SS1.p1.6.m6.6.6.2.4.1" xref="S4.SS1.p1.6.m6.6.6.2.3.cmml">,</mo><mi id="S4.SS1.p1.6.m6.6.6.2.2" xref="S4.SS1.p1.6.m6.6.6.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.6.m6.14.14.1.1.1.3.7" stretchy="false" xref="S4.SS1.p1.6.m6.14.14.1.1.1.4.cmml">)</mo></mrow><mo id="S4.SS1.p1.6.m6.15.15.2.2.4" xref="S4.SS1.p1.6.m6.15.15.2.3.cmml">,</mo><mi id="S4.SS1.p1.6.m6.13.13" mathvariant="normal" xref="S4.SS1.p1.6.m6.13.13.cmml">…</mi><mo id="S4.SS1.p1.6.m6.15.15.2.2.5" xref="S4.SS1.p1.6.m6.15.15.2.3.cmml">,</mo><mrow id="S4.SS1.p1.6.m6.15.15.2.2.2.3" xref="S4.SS1.p1.6.m6.15.15.2.2.2.4.cmml"><mo id="S4.SS1.p1.6.m6.15.15.2.2.2.3.4" stretchy="false" xref="S4.SS1.p1.6.m6.15.15.2.2.2.4.cmml">(</mo><msub id="S4.SS1.p1.6.m6.15.15.2.2.2.1.1" xref="S4.SS1.p1.6.m6.15.15.2.2.2.1.1.cmml"><mi id="S4.SS1.p1.6.m6.15.15.2.2.2.1.1.2" xref="S4.SS1.p1.6.m6.15.15.2.2.2.1.1.2.cmml">s</mi><mrow id="S4.SS1.p1.6.m6.8.8.2.4" xref="S4.SS1.p1.6.m6.8.8.2.3.cmml"><mi id="S4.SS1.p1.6.m6.7.7.1.1" xref="S4.SS1.p1.6.m6.7.7.1.1.cmml">K</mi><mo id="S4.SS1.p1.6.m6.8.8.2.4.1" xref="S4.SS1.p1.6.m6.8.8.2.3.cmml">,</mo><mi id="S4.SS1.p1.6.m6.8.8.2.2" xref="S4.SS1.p1.6.m6.8.8.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.6.m6.15.15.2.2.2.3.5" xref="S4.SS1.p1.6.m6.15.15.2.2.2.4.cmml">,</mo><msub id="S4.SS1.p1.6.m6.15.15.2.2.2.2.2" xref="S4.SS1.p1.6.m6.15.15.2.2.2.2.2.cmml"><mi id="S4.SS1.p1.6.m6.15.15.2.2.2.2.2.2" xref="S4.SS1.p1.6.m6.15.15.2.2.2.2.2.2.cmml">a</mi><mrow id="S4.SS1.p1.6.m6.10.10.2.4" xref="S4.SS1.p1.6.m6.10.10.2.3.cmml"><mi id="S4.SS1.p1.6.m6.9.9.1.1" xref="S4.SS1.p1.6.m6.9.9.1.1.cmml">K</mi><mo id="S4.SS1.p1.6.m6.10.10.2.4.1" xref="S4.SS1.p1.6.m6.10.10.2.3.cmml">,</mo><mi id="S4.SS1.p1.6.m6.10.10.2.2" xref="S4.SS1.p1.6.m6.10.10.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.6.m6.15.15.2.2.2.3.6" xref="S4.SS1.p1.6.m6.15.15.2.2.2.4.cmml">,</mo><msub id="S4.SS1.p1.6.m6.15.15.2.2.2.3.3" xref="S4.SS1.p1.6.m6.15.15.2.2.2.3.3.cmml"><mi id="S4.SS1.p1.6.m6.15.15.2.2.2.3.3.2" xref="S4.SS1.p1.6.m6.15.15.2.2.2.3.3.2.cmml">t</mi><mrow id="S4.SS1.p1.6.m6.12.12.2.4" xref="S4.SS1.p1.6.m6.12.12.2.3.cmml"><mi id="S4.SS1.p1.6.m6.11.11.1.1" xref="S4.SS1.p1.6.m6.11.11.1.1.cmml">K</mi><mo id="S4.SS1.p1.6.m6.12.12.2.4.1" xref="S4.SS1.p1.6.m6.12.12.2.3.cmml">,</mo><mi id="S4.SS1.p1.6.m6.12.12.2.2" xref="S4.SS1.p1.6.m6.12.12.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.6.m6.15.15.2.2.2.3.7" stretchy="false" xref="S4.SS1.p1.6.m6.15.15.2.2.2.4.cmml">)</mo></mrow><mo id="S4.SS1.p1.6.m6.15.15.2.2.6" stretchy="false" xref="S4.SS1.p1.6.m6.15.15.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.15b"><apply id="S4.SS1.p1.6.m6.15.15.cmml" xref="S4.SS1.p1.6.m6.15.15"><eq id="S4.SS1.p1.6.m6.15.15.3.cmml" xref="S4.SS1.p1.6.m6.15.15.3"></eq><apply id="S4.SS1.p1.6.m6.15.15.4.cmml" xref="S4.SS1.p1.6.m6.15.15.4"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.15.15.4.1.cmml" xref="S4.SS1.p1.6.m6.15.15.4">subscript</csymbol><ci id="S4.SS1.p1.6.m6.15.15.4.2.cmml" xref="S4.SS1.p1.6.m6.15.15.4.2">𝑆</ci><ci id="S4.SS1.p1.6.m6.15.15.4.3.cmml" xref="S4.SS1.p1.6.m6.15.15.4.3">𝑖</ci></apply><list id="S4.SS1.p1.6.m6.15.15.2.3.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2"><vector id="S4.SS1.p1.6.m6.14.14.1.1.1.4.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.3"><apply id="S4.SS1.p1.6.m6.14.14.1.1.1.1.1.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.14.14.1.1.1.1.1.1.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.6.m6.14.14.1.1.1.1.1.2.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.1.1.2">𝑠</ci><list id="S4.SS1.p1.6.m6.2.2.2.3.cmml" xref="S4.SS1.p1.6.m6.2.2.2.4"><cn id="S4.SS1.p1.6.m6.1.1.1.1.cmml" type="integer" xref="S4.SS1.p1.6.m6.1.1.1.1">1</cn><ci id="S4.SS1.p1.6.m6.2.2.2.2.cmml" xref="S4.SS1.p1.6.m6.2.2.2.2">𝑖</ci></list></apply><apply id="S4.SS1.p1.6.m6.14.14.1.1.1.2.2.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.14.14.1.1.1.2.2.1.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.2.2">subscript</csymbol><ci id="S4.SS1.p1.6.m6.14.14.1.1.1.2.2.2.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.2.2.2">𝑎</ci><list id="S4.SS1.p1.6.m6.4.4.2.3.cmml" xref="S4.SS1.p1.6.m6.4.4.2.4"><cn id="S4.SS1.p1.6.m6.3.3.1.1.cmml" type="integer" xref="S4.SS1.p1.6.m6.3.3.1.1">1</cn><ci id="S4.SS1.p1.6.m6.4.4.2.2.cmml" xref="S4.SS1.p1.6.m6.4.4.2.2">𝑖</ci></list></apply><apply id="S4.SS1.p1.6.m6.14.14.1.1.1.3.3.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.14.14.1.1.1.3.3.1.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.3.3">subscript</csymbol><ci id="S4.SS1.p1.6.m6.14.14.1.1.1.3.3.2.cmml" xref="S4.SS1.p1.6.m6.14.14.1.1.1.3.3.2">𝑡</ci><list id="S4.SS1.p1.6.m6.6.6.2.3.cmml" xref="S4.SS1.p1.6.m6.6.6.2.4"><cn id="S4.SS1.p1.6.m6.5.5.1.1.cmml" type="integer" xref="S4.SS1.p1.6.m6.5.5.1.1">1</cn><ci id="S4.SS1.p1.6.m6.6.6.2.2.cmml" xref="S4.SS1.p1.6.m6.6.6.2.2">𝑖</ci></list></apply></vector><ci id="S4.SS1.p1.6.m6.13.13.cmml" xref="S4.SS1.p1.6.m6.13.13">…</ci><vector id="S4.SS1.p1.6.m6.15.15.2.2.2.4.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.3"><apply id="S4.SS1.p1.6.m6.15.15.2.2.2.1.1.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.15.15.2.2.2.1.1.1.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.1.1">subscript</csymbol><ci id="S4.SS1.p1.6.m6.15.15.2.2.2.1.1.2.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.1.1.2">𝑠</ci><list id="S4.SS1.p1.6.m6.8.8.2.3.cmml" xref="S4.SS1.p1.6.m6.8.8.2.4"><ci id="S4.SS1.p1.6.m6.7.7.1.1.cmml" xref="S4.SS1.p1.6.m6.7.7.1.1">𝐾</ci><ci id="S4.SS1.p1.6.m6.8.8.2.2.cmml" xref="S4.SS1.p1.6.m6.8.8.2.2">𝑖</ci></list></apply><apply id="S4.SS1.p1.6.m6.15.15.2.2.2.2.2.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.15.15.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.6.m6.15.15.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.2.2.2">𝑎</ci><list id="S4.SS1.p1.6.m6.10.10.2.3.cmml" xref="S4.SS1.p1.6.m6.10.10.2.4"><ci id="S4.SS1.p1.6.m6.9.9.1.1.cmml" xref="S4.SS1.p1.6.m6.9.9.1.1">𝐾</ci><ci id="S4.SS1.p1.6.m6.10.10.2.2.cmml" xref="S4.SS1.p1.6.m6.10.10.2.2">𝑖</ci></list></apply><apply id="S4.SS1.p1.6.m6.15.15.2.2.2.3.3.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.15.15.2.2.2.3.3.1.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.3.3">subscript</csymbol><ci id="S4.SS1.p1.6.m6.15.15.2.2.2.3.3.2.cmml" xref="S4.SS1.p1.6.m6.15.15.2.2.2.3.3.2">𝑡</ci><list id="S4.SS1.p1.6.m6.12.12.2.3.cmml" xref="S4.SS1.p1.6.m6.12.12.2.4"><ci id="S4.SS1.p1.6.m6.11.11.1.1.cmml" xref="S4.SS1.p1.6.m6.11.11.1.1">𝐾</ci><ci id="S4.SS1.p1.6.m6.12.12.2.2.cmml" xref="S4.SS1.p1.6.m6.12.12.2.2">𝑖</ci></list></apply></vector></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.15c">S_{i}=[(s_{1,i},a_{1,i},t_{1,i}),...,(s_{K,i},a_{K,i},t_{K,i})]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.15d">italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = [ ( italic_s start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT ) , … , ( italic_s start_POSTSUBSCRIPT italic_K , italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_K , italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_K , italic_i end_POSTSUBSCRIPT ) ]</annotation></semantics></math>, where <math alttext="K" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1"><semantics id="S4.SS1.p1.7.m7.1a"><mi id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><ci id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">italic_K</annotation></semantics></math> is the sequence length, <math alttext="a_{k,i}" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.2"><semantics id="S4.SS1.p1.8.m8.2a"><msub id="S4.SS1.p1.8.m8.2.3" xref="S4.SS1.p1.8.m8.2.3.cmml"><mi id="S4.SS1.p1.8.m8.2.3.2" xref="S4.SS1.p1.8.m8.2.3.2.cmml">a</mi><mrow id="S4.SS1.p1.8.m8.2.2.2.4" xref="S4.SS1.p1.8.m8.2.2.2.3.cmml"><mi id="S4.SS1.p1.8.m8.1.1.1.1" xref="S4.SS1.p1.8.m8.1.1.1.1.cmml">k</mi><mo id="S4.SS1.p1.8.m8.2.2.2.4.1" xref="S4.SS1.p1.8.m8.2.2.2.3.cmml">,</mo><mi id="S4.SS1.p1.8.m8.2.2.2.2" xref="S4.SS1.p1.8.m8.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.2b"><apply id="S4.SS1.p1.8.m8.2.3.cmml" xref="S4.SS1.p1.8.m8.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.8.m8.2.3.1.cmml" xref="S4.SS1.p1.8.m8.2.3">subscript</csymbol><ci id="S4.SS1.p1.8.m8.2.3.2.cmml" xref="S4.SS1.p1.8.m8.2.3.2">𝑎</ci><list id="S4.SS1.p1.8.m8.2.2.2.3.cmml" xref="S4.SS1.p1.8.m8.2.2.2.4"><ci id="S4.SS1.p1.8.m8.1.1.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1.1.1">𝑘</ci><ci id="S4.SS1.p1.8.m8.2.2.2.2.cmml" xref="S4.SS1.p1.8.m8.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.2c">a_{k,i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m8.2d">italic_a start_POSTSUBSCRIPT italic_k , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the specific action type, <math alttext="t_{k,i}" class="ltx_Math" display="inline" id="S4.SS1.p1.9.m9.2"><semantics id="S4.SS1.p1.9.m9.2a"><msub id="S4.SS1.p1.9.m9.2.3" xref="S4.SS1.p1.9.m9.2.3.cmml"><mi id="S4.SS1.p1.9.m9.2.3.2" xref="S4.SS1.p1.9.m9.2.3.2.cmml">t</mi><mrow id="S4.SS1.p1.9.m9.2.2.2.4" xref="S4.SS1.p1.9.m9.2.2.2.3.cmml"><mi id="S4.SS1.p1.9.m9.1.1.1.1" xref="S4.SS1.p1.9.m9.1.1.1.1.cmml">k</mi><mo id="S4.SS1.p1.9.m9.2.2.2.4.1" xref="S4.SS1.p1.9.m9.2.2.2.3.cmml">,</mo><mi id="S4.SS1.p1.9.m9.2.2.2.2" xref="S4.SS1.p1.9.m9.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m9.2b"><apply id="S4.SS1.p1.9.m9.2.3.cmml" xref="S4.SS1.p1.9.m9.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.9.m9.2.3.1.cmml" xref="S4.SS1.p1.9.m9.2.3">subscript</csymbol><ci id="S4.SS1.p1.9.m9.2.3.2.cmml" xref="S4.SS1.p1.9.m9.2.3.2">𝑡</ci><list id="S4.SS1.p1.9.m9.2.2.2.3.cmml" xref="S4.SS1.p1.9.m9.2.2.2.4"><ci id="S4.SS1.p1.9.m9.1.1.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1.1.1">𝑘</ci><ci id="S4.SS1.p1.9.m9.2.2.2.2.cmml" xref="S4.SS1.p1.9.m9.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m9.2c">t_{k,i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.9.m9.2d">italic_t start_POSTSUBSCRIPT italic_k , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the timestamp of the action, <math alttext="s_{k,i}" class="ltx_Math" display="inline" id="S4.SS1.p1.10.m10.2"><semantics id="S4.SS1.p1.10.m10.2a"><msub id="S4.SS1.p1.10.m10.2.3" xref="S4.SS1.p1.10.m10.2.3.cmml"><mi id="S4.SS1.p1.10.m10.2.3.2" xref="S4.SS1.p1.10.m10.2.3.2.cmml">s</mi><mrow id="S4.SS1.p1.10.m10.2.2.2.4" xref="S4.SS1.p1.10.m10.2.2.2.3.cmml"><mi id="S4.SS1.p1.10.m10.1.1.1.1" xref="S4.SS1.p1.10.m10.1.1.1.1.cmml">k</mi><mo id="S4.SS1.p1.10.m10.2.2.2.4.1" xref="S4.SS1.p1.10.m10.2.2.2.3.cmml">,</mo><mi id="S4.SS1.p1.10.m10.2.2.2.2" xref="S4.SS1.p1.10.m10.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m10.2b"><apply id="S4.SS1.p1.10.m10.2.3.cmml" xref="S4.SS1.p1.10.m10.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.10.m10.2.3.1.cmml" xref="S4.SS1.p1.10.m10.2.3">subscript</csymbol><ci id="S4.SS1.p1.10.m10.2.3.2.cmml" xref="S4.SS1.p1.10.m10.2.3.2">𝑠</ci><list id="S4.SS1.p1.10.m10.2.2.2.3.cmml" xref="S4.SS1.p1.10.m10.2.2.2.4"><ci id="S4.SS1.p1.10.m10.1.1.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1.1.1">𝑘</ci><ci id="S4.SS1.p1.10.m10.2.2.2.2.cmml" xref="S4.SS1.p1.10.m10.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.10.m10.2c">s_{k,i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.10.m10.2d">italic_s start_POSTSUBSCRIPT italic_k , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> can be an item or a query depending on the action type. When <math alttext="a_{k,i}" class="ltx_Math" display="inline" id="S4.SS1.p1.11.m11.2"><semantics id="S4.SS1.p1.11.m11.2a"><msub id="S4.SS1.p1.11.m11.2.3" xref="S4.SS1.p1.11.m11.2.3.cmml"><mi id="S4.SS1.p1.11.m11.2.3.2" xref="S4.SS1.p1.11.m11.2.3.2.cmml">a</mi><mrow id="S4.SS1.p1.11.m11.2.2.2.4" xref="S4.SS1.p1.11.m11.2.2.2.3.cmml"><mi id="S4.SS1.p1.11.m11.1.1.1.1" xref="S4.SS1.p1.11.m11.1.1.1.1.cmml">k</mi><mo id="S4.SS1.p1.11.m11.2.2.2.4.1" xref="S4.SS1.p1.11.m11.2.2.2.3.cmml">,</mo><mi id="S4.SS1.p1.11.m11.2.2.2.2" xref="S4.SS1.p1.11.m11.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.11.m11.2b"><apply id="S4.SS1.p1.11.m11.2.3.cmml" xref="S4.SS1.p1.11.m11.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.11.m11.2.3.1.cmml" xref="S4.SS1.p1.11.m11.2.3">subscript</csymbol><ci id="S4.SS1.p1.11.m11.2.3.2.cmml" xref="S4.SS1.p1.11.m11.2.3.2">𝑎</ci><list id="S4.SS1.p1.11.m11.2.2.2.3.cmml" xref="S4.SS1.p1.11.m11.2.2.2.4"><ci id="S4.SS1.p1.11.m11.1.1.1.1.cmml" xref="S4.SS1.p1.11.m11.1.1.1.1">𝑘</ci><ci id="S4.SS1.p1.11.m11.2.2.2.2.cmml" xref="S4.SS1.p1.11.m11.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.11.m11.2c">a_{k,i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.11.m11.2d">italic_a start_POSTSUBSCRIPT italic_k , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents a search action, <math alttext="s_{k,i}\in\mathcal{Q}" class="ltx_Math" display="inline" id="S4.SS1.p1.12.m12.2"><semantics id="S4.SS1.p1.12.m12.2a"><mrow id="S4.SS1.p1.12.m12.2.3" xref="S4.SS1.p1.12.m12.2.3.cmml"><msub id="S4.SS1.p1.12.m12.2.3.2" xref="S4.SS1.p1.12.m12.2.3.2.cmml"><mi id="S4.SS1.p1.12.m12.2.3.2.2" xref="S4.SS1.p1.12.m12.2.3.2.2.cmml">s</mi><mrow id="S4.SS1.p1.12.m12.2.2.2.4" xref="S4.SS1.p1.12.m12.2.2.2.3.cmml"><mi id="S4.SS1.p1.12.m12.1.1.1.1" xref="S4.SS1.p1.12.m12.1.1.1.1.cmml">k</mi><mo id="S4.SS1.p1.12.m12.2.2.2.4.1" xref="S4.SS1.p1.12.m12.2.2.2.3.cmml">,</mo><mi id="S4.SS1.p1.12.m12.2.2.2.2" xref="S4.SS1.p1.12.m12.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.12.m12.2.3.1" xref="S4.SS1.p1.12.m12.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.12.m12.2.3.3" xref="S4.SS1.p1.12.m12.2.3.3.cmml">𝒬</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.12.m12.2b"><apply id="S4.SS1.p1.12.m12.2.3.cmml" xref="S4.SS1.p1.12.m12.2.3"><in id="S4.SS1.p1.12.m12.2.3.1.cmml" xref="S4.SS1.p1.12.m12.2.3.1"></in><apply id="S4.SS1.p1.12.m12.2.3.2.cmml" xref="S4.SS1.p1.12.m12.2.3.2"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m12.2.3.2.1.cmml" xref="S4.SS1.p1.12.m12.2.3.2">subscript</csymbol><ci id="S4.SS1.p1.12.m12.2.3.2.2.cmml" xref="S4.SS1.p1.12.m12.2.3.2.2">𝑠</ci><list id="S4.SS1.p1.12.m12.2.2.2.3.cmml" xref="S4.SS1.p1.12.m12.2.2.2.4"><ci id="S4.SS1.p1.12.m12.1.1.1.1.cmml" xref="S4.SS1.p1.12.m12.1.1.1.1">𝑘</ci><ci id="S4.SS1.p1.12.m12.2.2.2.2.cmml" xref="S4.SS1.p1.12.m12.2.2.2.2">𝑖</ci></list></apply><ci id="S4.SS1.p1.12.m12.2.3.3.cmml" xref="S4.SS1.p1.12.m12.2.3.3">𝒬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.12.m12.2c">s_{k,i}\in\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.12.m12.2d">italic_s start_POSTSUBSCRIPT italic_k , italic_i end_POSTSUBSCRIPT ∈ caligraphic_Q</annotation></semantics></math> represents the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p1.13.m13.1"><semantics id="S4.SS1.p1.13.m13.1a"><mi id="S4.SS1.p1.13.m13.1.1" xref="S4.SS1.p1.13.m13.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.13.m13.1b"><ci id="S4.SS1.p1.13.m13.1.1.cmml" xref="S4.SS1.p1.13.m13.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.13.m13.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.13.m13.1d">italic_k</annotation></semantics></math>-th query. For other actions, <math alttext="s_{k,i}\in\mathcal{V}" class="ltx_Math" display="inline" id="S4.SS1.p1.14.m14.2"><semantics id="S4.SS1.p1.14.m14.2a"><mrow id="S4.SS1.p1.14.m14.2.3" xref="S4.SS1.p1.14.m14.2.3.cmml"><msub id="S4.SS1.p1.14.m14.2.3.2" xref="S4.SS1.p1.14.m14.2.3.2.cmml"><mi id="S4.SS1.p1.14.m14.2.3.2.2" xref="S4.SS1.p1.14.m14.2.3.2.2.cmml">s</mi><mrow id="S4.SS1.p1.14.m14.2.2.2.4" xref="S4.SS1.p1.14.m14.2.2.2.3.cmml"><mi id="S4.SS1.p1.14.m14.1.1.1.1" xref="S4.SS1.p1.14.m14.1.1.1.1.cmml">k</mi><mo id="S4.SS1.p1.14.m14.2.2.2.4.1" xref="S4.SS1.p1.14.m14.2.2.2.3.cmml">,</mo><mi id="S4.SS1.p1.14.m14.2.2.2.2" xref="S4.SS1.p1.14.m14.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S4.SS1.p1.14.m14.2.3.1" xref="S4.SS1.p1.14.m14.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.14.m14.2.3.3" xref="S4.SS1.p1.14.m14.2.3.3.cmml">𝒱</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.14.m14.2b"><apply id="S4.SS1.p1.14.m14.2.3.cmml" xref="S4.SS1.p1.14.m14.2.3"><in id="S4.SS1.p1.14.m14.2.3.1.cmml" xref="S4.SS1.p1.14.m14.2.3.1"></in><apply id="S4.SS1.p1.14.m14.2.3.2.cmml" xref="S4.SS1.p1.14.m14.2.3.2"><csymbol cd="ambiguous" id="S4.SS1.p1.14.m14.2.3.2.1.cmml" xref="S4.SS1.p1.14.m14.2.3.2">subscript</csymbol><ci id="S4.SS1.p1.14.m14.2.3.2.2.cmml" xref="S4.SS1.p1.14.m14.2.3.2.2">𝑠</ci><list id="S4.SS1.p1.14.m14.2.2.2.3.cmml" xref="S4.SS1.p1.14.m14.2.2.2.4"><ci id="S4.SS1.p1.14.m14.1.1.1.1.cmml" xref="S4.SS1.p1.14.m14.1.1.1.1">𝑘</ci><ci id="S4.SS1.p1.14.m14.2.2.2.2.cmml" xref="S4.SS1.p1.14.m14.2.2.2.2">𝑖</ci></list></apply><ci id="S4.SS1.p1.14.m14.2.3.3.cmml" xref="S4.SS1.p1.14.m14.2.3.3">𝒱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.14.m14.2c">s_{k,i}\in\mathcal{V}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.14.m14.2d">italic_s start_POSTSUBSCRIPT italic_k , italic_i end_POSTSUBSCRIPT ∈ caligraphic_V</annotation></semantics></math> represents the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p1.15.m15.1"><semantics id="S4.SS1.p1.15.m15.1a"><mi id="S4.SS1.p1.15.m15.1.1" xref="S4.SS1.p1.15.m15.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.15.m15.1b"><ci id="S4.SS1.p1.15.m15.1.1.cmml" xref="S4.SS1.p1.15.m15.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.15.m15.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.15.m15.1d">italic_k</annotation></semantics></math>-th interacted item. In this paper, we are interested in three action types, search, click, and purchase behavior, and we aim to predict the future item the user will be interested in purchasing after observing interaction sequences <math alttext="S_{i}" class="ltx_Math" display="inline" id="S4.SS1.p1.16.m16.1"><semantics id="S4.SS1.p1.16.m16.1a"><msub id="S4.SS1.p1.16.m16.1.1" xref="S4.SS1.p1.16.m16.1.1.cmml"><mi id="S4.SS1.p1.16.m16.1.1.2" xref="S4.SS1.p1.16.m16.1.1.2.cmml">S</mi><mi id="S4.SS1.p1.16.m16.1.1.3" xref="S4.SS1.p1.16.m16.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.16.m16.1b"><apply id="S4.SS1.p1.16.m16.1.1.cmml" xref="S4.SS1.p1.16.m16.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.16.m16.1.1.1.cmml" xref="S4.SS1.p1.16.m16.1.1">subscript</csymbol><ci id="S4.SS1.p1.16.m16.1.1.2.cmml" xref="S4.SS1.p1.16.m16.1.1.2">𝑆</ci><ci id="S4.SS1.p1.16.m16.1.1.3.cmml" xref="S4.SS1.p1.16.m16.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.16.m16.1c">S_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.16.m16.1d">italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
Additionally, each item <math alttext="v" class="ltx_Math" display="inline" id="S4.SS1.p1.17.m17.1"><semantics id="S4.SS1.p1.17.m17.1a"><mi id="S4.SS1.p1.17.m17.1.1" xref="S4.SS1.p1.17.m17.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.17.m17.1b"><ci id="S4.SS1.p1.17.m17.1.1.cmml" xref="S4.SS1.p1.17.m17.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.17.m17.1c">v</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.17.m17.1d">italic_v</annotation></semantics></math> is associated with an attribute dictionary containing various textual information, such as titles, colors, and descriptions.
We formulate these as key-value attribute pairs and assign a unique ID to each item, in line with ID-based recommendation methods <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib38" title="">2019</a>); Kang and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib21" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Challenges and Overview.</span>
Addressing the unique characteristics of fashion poses significant challenges for recommendation systems. For instance, the cold-start problem remains a persistent issue in recommender systems. Traditional approaches to mitigate this challenge often rely on complex and specialized architectures <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib50" title="">2021</a>); Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib8" title="">2020</a>)</cite>. Capturing fine-grained user preferences further complicates this task, typically requiring specialized modules <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib40" title="">2019</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib4" title="">2021</a>)</cite>. Additionally, leveraging search data to enhance recommendations remains relatively unexplored <cite class="ltx_cite ltx_citemacro_cite">Si et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib37" title="">2023</a>)</cite>, where the primary difficulty lies in the distinct nature of user intent in search versus recommendation tasks.
To address these challenges, we propose an LLM-augmented fashion sequential recommendation system, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S3.F2" title="Figure 2 ‣ 3 Fashion Characteristics ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">2</span></a>. The process initiates with the creation of prompts. A query-product memory module assesses user-item interactions to identify top products associated with user queries. This information is synthesized into a natural language format using a recommendation-specific prompt template, incorporating fashion-related attributes. In the subsequent training stage, we utilize the prepared prompts to fine-tune the LLM through a Parameter-Efficient Fine-Tuning method.
Finally, in the retrieval and ranking stage, we convert the generated titles and IDs into embeddings using two specialized models. These embeddings are integrated into a retrieval module with a mixup strategy, obtaining the final recommended items.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering" id="S4.F3.g1" src="prompt_example.eps"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The demonstration example of our prompt.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Prompt Design</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.1">Recommendation-specific Prompt Construction. </span>
Prompting offers a natural and intuitive interface for humans to interact with LLMs <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib49" title="">2022</a>)</cite>.
Given that LLMs are initially trained for general tasks, specialized prompts are essential for aligning LLMs with recommendation-specific goals.
A demonstration example of our designed prompt is given in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S4.F3" title="Figure 3 ‣ 4.1 Problem Formulation and Overview ‣ 4 Method ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">The instruction segment aims to clearly define the task and consists of three core elements: <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">task description</span> (highlighted in purple), <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">execution requirement</span> (highlighted in blue), and <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.3">format indicator</span> (highlighted in brown). In the task description, we explicitly specify that the context is a recommendation task. The execution requirement emphasizes a set of strategies tailored to address the unique characteristics of fashion. A prime emphasis here is the consideration of sequential order. To address <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.4">C2</span>, we intend for the LLM to focus on varying attributes, as they offer insight into users’ fine-grained preferences. To address <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.5">C3</span>, we emphasize the importance of fashion-specific attributes. To address <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.6">C4</span>, we observed that customers generally have preferences in purchasing the top exposure results on the shopping page, thus we instruct the LLM to prioritize the recommendation in the top exposure results corresponding to the search query. Finally, the format indicator strictly defines an output format for automated decoding.
The input segment is a refined representation of user-item interactions, enriched with detailed item attributes. Search queries are also included to highlight their importance in the recommendation task.
The response segment, employed only during the training phase, encapsulates the final item purchased by the user, including both the product ID and title.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.2.1">Query-product Memory Module. </span>
We observe that users frequently opt to purchase items listed at the top of their search results. In response to this behavior, we propose a Query-Product Memory Module that preserves key-value pairs consisting of search queries and their corresponding product listings. To obtain these product lists, data is grouped by search queries and then sorted by organic position. Recognizing that queries can appear in various forms that convey similar meanings, we employ CLIP <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib35" title="">2021</a>)</cite> to convert these queries into embedding vectors, which serve as the keys in our module. During the recommendation process, the current search query is transformed into its respective embedding, enabling us to compute the cosine distance, identify the nearest <math alttext="Q" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">italic_Q</annotation></semantics></math> matching queries, and subsequently retrieve their associated top <math alttext="V" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><mi id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><ci id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">italic_V</annotation></semantics></math> products.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Training Strategy</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib16" title="">2021</a>)</cite> has emerged as a notable Parameter-Efficient Fine-Tuning (PEFT) technique, offering performance comparable to full fine-tuning while requiring substantially fewer trainable parameters. Consequently, we have adopted this method to fine-tune our model.
We further reduce memory usage by employing model quantization as implemented in QLoRA <cite class="ltx_cite ltx_citemacro_cite">Dettmers et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib7" title="">2023</a>)</cite>. Specifically, we maintain distinct storage and computation data types. We quantize the model to a more memory-efficient storage type and, during the forward and backward passes, dequantize the data back to the computation type to avoid performance loss.
During our preliminary experiments, we observed that the model exhibited a 7% likelihood of generating outputs in an inconsistent format. This inconsistency made the automated decoding of product IDs and titles challenging.
One possible reason is that product titles in e-commerce often display limited sentence coherence and are more like a collection of individual words, setting them apart from typical natural language structures. To mitigate this issue, we identified the high-perplexity prompts and subjected them to additional training cycles relative to their lower-perplexity counterparts.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Retrieval and Ranking Method</h3>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p1.1.1">Title Embedding Model. </span>
To effectively capture the semantic similarity of item titles in recommendation tasks, we leveraged the insight that the items that were purchased in the same search queries should be similar in embedding space. Based on this insight, we first tokenize both the query and product title.
Once tokenized, the model computes the embeddings for query and title by employing the LSTM model.
We train the whole model using a triplet loss <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib18" title="">2016</a>)</cite>, where we pair two hard negatives with one positive pair during each forward pass. The positive match means the item that was purchased from the query. We choose the title that is closest to the query but is not a positive match and the query that is closest to the title but is not a positive match as the hard negatives.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.1">ID Embedding Model. </span>
The ID embedding model maps pre-defined item IDs into their embeddings. We leverage the item embedding table from the CORE model, which has demonstrated superior performance compared to state-of-the-art methods. Specifically, we train the CORE model using user-item interaction sequences, then keep only the item embedding table as our ID embedding model.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.5"><span class="ltx_text ltx_font_bold" id="S4.SS4.p3.5.1">Retrieval with Mixup. </span>
After obtaining both title embeddings and ID embeddings, the next step is to perform retrieval and ranking processes to get the candidate items for recommendation. Title embeddings are designed to capture the semantic content of an item’s title, thus offering better generalization, even if an item hasn’t been seen before (<span class="ltx_text ltx_font_italic" id="S4.SS4.p3.5.2">i.e.</span> cold start).
Conversely, ID embeddings are designed to uniquely represent specific items, so the embedding can capture nuances specific to that item, thus being suitable in top matches.
To effectively combine the advantages of the two methods, we propose a mixup-based retrieval method. This approach begins with separate retrievals based on title and ID embeddings, resulting in two distinct lists of items. To generate our final list of top-<math alttext="K" class="ltx_Math" display="inline" id="S4.SS4.p3.1.m1.1"><semantics id="S4.SS4.p3.1.m1.1a"><mi id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><ci id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.1.m1.1d">italic_K</annotation></semantics></math> items, we adopt the following approach: We select the top-<math alttext="N" class="ltx_Math" display="inline" id="S4.SS4.p3.2.m2.1"><semantics id="S4.SS4.p3.2.m2.1a"><mi id="S4.SS4.p3.2.m2.1.1" xref="S4.SS4.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.m2.1b"><ci id="S4.SS4.p3.2.m2.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.2.m2.1d">italic_N</annotation></semantics></math> items from the ID embedding-based list. Subsequently, we choose items ranging from positions <math alttext="N+1" class="ltx_Math" display="inline" id="S4.SS4.p3.3.m3.1"><semantics id="S4.SS4.p3.3.m3.1a"><mrow id="S4.SS4.p3.3.m3.1.1" xref="S4.SS4.p3.3.m3.1.1.cmml"><mi id="S4.SS4.p3.3.m3.1.1.2" xref="S4.SS4.p3.3.m3.1.1.2.cmml">N</mi><mo id="S4.SS4.p3.3.m3.1.1.1" xref="S4.SS4.p3.3.m3.1.1.1.cmml">+</mo><mn id="S4.SS4.p3.3.m3.1.1.3" xref="S4.SS4.p3.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.3.m3.1b"><apply id="S4.SS4.p3.3.m3.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1"><plus id="S4.SS4.p3.3.m3.1.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1.1"></plus><ci id="S4.SS4.p3.3.m3.1.1.2.cmml" xref="S4.SS4.p3.3.m3.1.1.2">𝑁</ci><cn id="S4.SS4.p3.3.m3.1.1.3.cmml" type="integer" xref="S4.SS4.p3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.3.m3.1c">N+1</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.3.m3.1d">italic_N + 1</annotation></semantics></math> to <math alttext="K" class="ltx_Math" display="inline" id="S4.SS4.p3.4.m4.1"><semantics id="S4.SS4.p3.4.m4.1a"><mi id="S4.SS4.p3.4.m4.1.1" xref="S4.SS4.p3.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.4.m4.1b"><ci id="S4.SS4.p3.4.m4.1.1.cmml" xref="S4.SS4.p3.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.4.m4.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.4.m4.1d">italic_K</annotation></semantics></math> from the title embedding-based list. We set <math alttext="N=1" class="ltx_Math" display="inline" id="S4.SS4.p3.5.m5.1"><semantics id="S4.SS4.p3.5.m5.1a"><mrow id="S4.SS4.p3.5.m5.1.1" xref="S4.SS4.p3.5.m5.1.1.cmml"><mi id="S4.SS4.p3.5.m5.1.1.2" xref="S4.SS4.p3.5.m5.1.1.2.cmml">N</mi><mo id="S4.SS4.p3.5.m5.1.1.1" xref="S4.SS4.p3.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS4.p3.5.m5.1.1.3" xref="S4.SS4.p3.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.5.m5.1b"><apply id="S4.SS4.p3.5.m5.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1"><eq id="S4.SS4.p3.5.m5.1.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1.1"></eq><ci id="S4.SS4.p3.5.m5.1.1.2.cmml" xref="S4.SS4.p3.5.m5.1.1.2">𝑁</ci><cn id="S4.SS4.p3.5.m5.1.1.3.cmml" type="integer" xref="S4.SS4.p3.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.5.m5.1c">N=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.5.m5.1d">italic_N = 1</annotation></semantics></math> for all our experiments.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental Setup</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">Datasets. </span>
We have collected a large-scale dataset derived from customer interactions on the Amazon fashion service, containing approximately 5.9 million user shopping interactions with a total of 2.4 million products.
We aggregated them into four primary categories: Luggage and Bags, Footwear, Accessories and Jewelry, and Clothing. The sequences included three action types: search, click, and purchases. We also filtered the ’click’ interactions on the items that were eventually purchased.
Each item in our dataset is described by an array of attributes such as item and user identifier, product title, category, brand, color, and size.
The statistics of the data after processing are given in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.T1" title="Table 1 ‣ 5.1 Experimental Setup ‣ 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Statistics of the datasets. Avg. Len. represents the average length of interaction sequences.</figcaption>
<table class="ltx_tabular ltx_align_middle" id="S5.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S5.T1.1.1.1.1" style="padding:1pt 0.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1.1">Dataset</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S5.T1.1.1.1.2" style="padding:1pt 0.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.2.1">#Users</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S5.T1.1.1.1.3" style="padding:1pt 0.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.3.1">#Items</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S5.T1.1.1.1.4" style="padding:1pt 0.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.4.1">#Inters.</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S5.T1.1.1.1.5" style="padding:1pt 0.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.5.1">Avg. Len.</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt ltx_border_t" id="S5.T1.1.1.1.6" style="padding:1pt 0.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.6.1">Density</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.2.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.2.2.1" style="padding:1pt 0.1pt;">Lug. &amp; Bags</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.2.2.2" style="padding:1pt 0.1pt;">10,611</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.2.2.3" style="padding:1pt 0.1pt;">61,550</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.2.2.4" style="padding:1pt 0.1pt;">131,647</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.2.2.5" style="padding:1pt 0.1pt;">12.41</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.1.2.2.6" style="padding:1pt 0.1pt;">2.02E-04</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.3.3.1" style="padding:1pt 0.1pt;">Footwear</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.3.3.2" style="padding:1pt 0.1pt;">63,273</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.3.3.3" style="padding:1pt 0.1pt;">380,385</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.3.3.4" style="padding:1pt 0.1pt;">714,628</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.3.3.5" style="padding:1pt 0.1pt;">11.29</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.1.3.3.6" style="padding:1pt 0.1pt;">2.97E-05</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.4.4.1" style="padding:1pt 0.1pt;">Acc. &amp; Jew.</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.4.4.2" style="padding:1pt 0.1pt;">106,104</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.4.4.3" style="padding:1pt 0.1pt;">524,433</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.4.4.4" style="padding:1pt 0.1pt;">1,376,999</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.4.4.5" style="padding:1pt 0.1pt;">12.98</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.1.4.4.6" style="padding:1pt 0.1pt;">2.47E-05</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T1.1.5.5.1" style="padding:1pt 0.1pt;">Clothing</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T1.1.5.5.2" style="padding:1pt 0.1pt;">274,285</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T1.1.5.5.3" style="padding:1pt 0.1pt;">1,386,910</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T1.1.5.5.4" style="padding:1pt 0.1pt;">3,635,414</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T1.1.5.5.5" style="padding:1pt 0.1pt;">13.25</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S5.T1.1.5.5.6" style="padding:1pt 0.1pt;">9.56E-06</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance comparison of our method with the state-of-the-art methods across different datasets. </figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_border_t" id="S5.T2.1.1.1.1" rowspan="2" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" colspan="3" id="S5.T2.1.1.1.2" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.2.1">Luggage &amp; Bags</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" colspan="3" id="S5.T2.1.1.1.3" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.3.1">Footwear</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" colspan="3" id="S5.T2.1.1.1.4" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.4.1">Accessories and Jewelry</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" colspan="3" id="S5.T2.1.1.1.5" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.5.1">Clothing</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.1" style="padding:2.5pt 2.4pt;">Recall@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.2" style="padding:2.5pt 2.4pt;">NDCG@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.2.2.3" style="padding:2.5pt 2.4pt;">MRR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.4" style="padding:2.5pt 2.4pt;">Recall@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.5" style="padding:2.5pt 2.4pt;">NDCG@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.2.2.6" style="padding:2.5pt 2.4pt;">MRR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.7" style="padding:2.5pt 2.4pt;">Recall@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.8" style="padding:2.5pt 2.4pt;">NDCG@10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.2.2.9" style="padding:2.5pt 2.4pt;">MRR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.10" style="padding:2.5pt 2.4pt;">Recall@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.11" style="padding:2.5pt 2.4pt;">NDCG@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.2.2.12" style="padding:2.5pt 2.4pt;">MRR</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.1.3.3.1" style="padding:2.5pt 2.4pt;">GRU4Rec</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.2" style="padding:2.5pt 2.4pt;">0.0336</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.3" style="padding:2.5pt 2.4pt;">0.0221</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.3.3.4" style="padding:2.5pt 2.4pt;">0.0185</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.5" style="padding:2.5pt 2.4pt;">0.0185</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.6" style="padding:2.5pt 2.4pt;">0.0124</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.3.3.7" style="padding:2.5pt 2.4pt;">0.0105</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.8" style="padding:2.5pt 2.4pt;">0.0230</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.9" style="padding:2.5pt 2.4pt;">0.0155</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.3.3.10" style="padding:2.5pt 2.4pt;">0.0131</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.11" style="padding:2.5pt 2.4pt;">0.0221</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.12" style="padding:2.5pt 2.4pt;">0.0155</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.13" style="padding:2.5pt 2.4pt;">0.0134</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.1.4.4.1" style="padding:2.5pt 2.4pt;">SASRec</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.2" style="padding:2.5pt 2.4pt;">0.1015</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.3" style="padding:2.5pt 2.4pt;">0.0613</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.4.4.4" style="padding:2.5pt 2.4pt;">0.0487</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.5" style="padding:2.5pt 2.4pt;">0.0857</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.6" style="padding:2.5pt 2.4pt;">0.0548</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.4.4.7" style="padding:2.5pt 2.4pt;">0.0452</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.8" style="padding:2.5pt 2.4pt;">0.1440</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.9" style="padding:2.5pt 2.4pt;">0.0825</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.4.4.10" style="padding:2.5pt 2.4pt;">0.0631</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.11" style="padding:2.5pt 2.4pt;">0.1485</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.12" style="padding:2.5pt 2.4pt;">0.0827</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.4.4.13" style="padding:2.5pt 2.4pt;">0.0617</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.1.5.5.1" style="padding:2.5pt 2.4pt;">BERT4Rec</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.2" style="padding:2.5pt 2.4pt;">0.0975</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.3" style="padding:2.5pt 2.4pt;">0.0600</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.5.5.4" style="padding:2.5pt 2.4pt;">0.0485</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.5" style="padding:2.5pt 2.4pt;">0.1405</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.6" style="padding:2.5pt 2.4pt;">0.0770</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.5.5.7" style="padding:2.5pt 2.4pt;">0.0568</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.8" style="padding:2.5pt 2.4pt;">0.0904</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.9" style="padding:2.5pt 2.4pt;">0.0580</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.5.5.10" style="padding:2.5pt 2.4pt;">0.0479</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.11" style="padding:2.5pt 2.4pt;">0.0676</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.12" style="padding:2.5pt 2.4pt;">0.0435</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.5.5.13" style="padding:2.5pt 2.4pt;">0.0361</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.1.6.6.1" style="padding:2.5pt 2.4pt;">NextItNet</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.2" style="padding:2.5pt 2.4pt;">0.0176</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.3" style="padding:2.5pt 2.4pt;">0.0094</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.6.6.4" style="padding:2.5pt 2.4pt;">0.0069</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.5" style="padding:2.5pt 2.4pt;">0.0123</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.6" style="padding:2.5pt 2.4pt;">0.0103</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.6.6.7" style="padding:2.5pt 2.4pt;">0.0097</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.8" style="padding:2.5pt 2.4pt;">0.0185</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.9" style="padding:2.5pt 2.4pt;">0.0150</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.6.6.10" style="padding:2.5pt 2.4pt;">0.0139</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.11" style="padding:2.5pt 2.4pt;">0.0111</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.12" style="padding:2.5pt 2.4pt;">0.0087</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.6.6.13" style="padding:2.5pt 2.4pt;">0.0079</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.1.7.7.1" style="padding:2.5pt 2.4pt;">CORE</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.2" style="padding:2.5pt 2.4pt;">0.2612</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.3" style="padding:2.5pt 2.4pt;">0.1404</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.7.7.4" style="padding:2.5pt 2.4pt;">0.1027</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.5" style="padding:2.5pt 2.4pt;">0.3075</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.6" style="padding:2.5pt 2.4pt;">0.1566</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.7.7.7" style="padding:2.5pt 2.4pt;">0.1092</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.8" style="padding:2.5pt 2.4pt;">0.2493</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.9" style="padding:2.5pt 2.4pt;">0.1327</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.7.7.10" style="padding:2.5pt 2.4pt;">0.0962</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.11" style="padding:2.5pt 2.4pt;">0.1989</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.12" style="padding:2.5pt 2.4pt;">0.1008</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.7.7.13" style="padding:2.5pt 2.4pt;">0.0699</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.1.8.8.1" style="padding:2.5pt 2.4pt;">Recformer</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.2" style="padding:2.5pt 2.4pt;">0.2577</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.3" style="padding:2.5pt 2.4pt;">0.1692</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.8.8.4" style="padding:2.5pt 2.4pt;">0.1455</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.5" style="padding:2.5pt 2.4pt;">0.2181</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.6" style="padding:2.5pt 2.4pt;">0.1352</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.8.8.7" style="padding:2.5pt 2.4pt;">0.1161</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.8" style="padding:2.5pt 2.4pt;">0.1719</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.9" style="padding:2.5pt 2.4pt;">0.1132</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.8.8.10" style="padding:2.5pt 2.4pt;">0.1004</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.11" style="padding:2.5pt 2.4pt;">0.1741</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.12" style="padding:2.5pt 2.4pt;">0.1102</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.8.8.13" style="padding:2.5pt 2.4pt;">0.0972</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.1.9.9.1" style="padding:2.5pt 2.4pt;">Recformer w/ query</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.2" style="padding:2.5pt 2.4pt;">0.2642</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.3" style="padding:2.5pt 2.4pt;">0.1834</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.9.9.4" style="padding:2.5pt 2.4pt;">0.1524</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.5" style="padding:2.5pt 2.4pt;">0.2325</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.6" style="padding:2.5pt 2.4pt;">0.1436</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.9.9.7" style="padding:2.5pt 2.4pt;">0.1225</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.8" style="padding:2.5pt 2.4pt;">0.1990</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.9" style="padding:2.5pt 2.4pt;">0.1220</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.9.9.10" style="padding:2.5pt 2.4pt;">0.1046</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.11" style="padding:2.5pt 2.4pt;">0.1888</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.12" style="padding:2.5pt 2.4pt;">0.1276</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.9.9.13" style="padding:2.5pt 2.4pt;">0.1059</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.10.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.10.10.1" style="padding:2.5pt 2.4pt;">Ours</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.2" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.2.1">0.2786</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.3" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.3.1">0.2037</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.10.10.4" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.4.1">0.1804</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.5" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.5.1">0.3377</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.6" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.6.1">0.1791</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.10.10.7" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.7.1">0.1470</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.8" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.8.1">0.2624</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.9" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.9.1">0.1676</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.10.10.10" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.10.1">0.1343</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.11" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.11.1">0.2593</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.12" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.12.1">0.1658</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.10.10.13" style="padding:2.5pt 2.4pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.13.1">0.1440</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">Evaluation Settings. </span>
To assess the efficacy of our sequential recommendation approach, we employ three widely used metrics: Recall@N, NDCG@N, and MRR, where N is set to 10. During the evaluation, we rank the ground-truth item (<span class="ltx_text ltx_font_italic" id="S5.SS1.p2.1.2">i.e.</span>, final purchased item) of each sequence among all items in the same category and report the average values of all sequences in the test data. We employ the common leave-one-out strategy <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib38" title="">2019</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib48" title="">2020</a>)</cite> to split the data for evaluation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.1">Baselines. </span>
To evaluate the performance of the proposed method, we compare it with the following representative baselines: GRU4Rec <cite class="ltx_cite ltx_citemacro_cite">Hidasi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib13" title="">2015</a>)</cite>, SASRec <cite class="ltx_cite ltx_citemacro_cite">Kang and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib21" title="">2018</a>)</cite>, BERT4Rec <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib38" title="">2019</a>)</cite>, NextItNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib44" title="">Yuan et al. </a></cite>, CORE <cite class="ltx_cite ltx_citemacro_cite">Hou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib15" title="">2022</a>)</cite>, and Recformer <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib25" title="">2023</a>)</cite>. To ensure a more fair comparison, we also compare with Recformer w/ query, which is similar to Recformer, with the only change of adding the search query as part of the input.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.2"><span class="ltx_text ltx_font_bold" id="S5.SS1.p4.2.1">Implementation Details. </span>
We select Falcon-7b <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib1" title="">fal </a></cite> as our base LLM model. We implemented the training framework by using Huggingface PEFT library<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>PEFT: <a class="ltx_ref ltx_href" href="https://huggingface.co/docs/peft/index" title="">https://huggingface.co/docs/peft/index</a></span></span></span>. For LoRA, we set rank <math alttext="r" class="ltx_Math" display="inline" id="S5.SS1.p4.1.m1.1"><semantics id="S5.SS1.p4.1.m1.1a"><mi id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><ci id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p4.1.m1.1d">italic_r</annotation></semantics></math> to 16, scaling parameter <math alttext="\alpha" class="ltx_Math" display="inline" id="S5.SS1.p4.2.m2.1"><semantics id="S5.SS1.p4.2.m2.1a"><mi id="S5.SS1.p4.2.m2.1.1" xref="S5.SS1.p4.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.1b"><ci id="S5.SS1.p4.2.m2.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p4.2.m2.1d">italic_α</annotation></semantics></math> to 16, and dropout rate to 0.05. The maximum number of tokens for each interaction sequence is 1024. The models were trained on 8 Nvidia Tesla V100 GPUs. We optimized Falcon with AdamW optimizer <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib31" title="">2017</a>)</cite> with a learning rate 2e-5. We only fine-tuned the model for 1 epoch, except in cases involving prompts with high perplexity, where we selected the top 20% of prompts as high perplexity prompts for fine-tuning 3 epochs. During the generation, we set the max new tokens to 64, the temperature to 0.05, and the probability threshold of nucleus sampling to 0.95. For the implementation of Recformer, we followed the official Github repository<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Recformer: <a class="ltx_ref ltx_href" href="https://github.com/JiachengLi1995/Recformer" title="">https://github.com/JiachengLi1995/Recformer</a></span></span></span>. For all other baselines, we followed the suggested settings and implementations in RecBole <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib46" title="">2021</a>)</cite>. To ensure a fair comparison, we conducted extensive hyperparameter tuning for each baseline method across different datasets.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation Results</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We compared the performance of our method to baselines on four different datasets, the results are given in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.T2" title="Table 2 ‣ 5.1 Experimental Setup ‣ 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">2</span></a>. Our method achieves the best overall performance on all datasets. Notably, we observed a 9.8% improvement in Recall@10 and a 14.4% improvement in NDCG@10 on the footwear dataset. On sparser datasets, the gains are more significant, with our method achieving a 30.4% improvement in Recall@10 and a 64.5% improvement in NDCG@10 on the clothing dataset. This is because item IDs cannot capture the rich semantic relationships that are readily expressed in item texts (<span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.1">e.g.</span>, color, brand).
In comparison to Recformer, which also leveraged text information, our method has the additional advantage of incorporating general knowledge and reasoning capabilities inherent in large language models. This yielded superior performance across recommendation tasks.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation study of different design components.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_t" id="S5.T3.1.1.1.1" style="padding:2pt 1.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.1">Variants</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_t" id="S5.T3.1.1.1.2" style="padding:2pt 1.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.2.1">Recall@10</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_t" id="S5.T3.1.1.1.3" style="padding:2pt 1.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.1">NDCG@10</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" id="S5.T3.1.1.1.4" style="padding:2pt 1.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.4.1">MRR</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.2.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.2.1.1" style="padding:2pt 1.3pt;">Ours</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.2.1.2" style="padding:2pt 1.3pt;">0.2786</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.2.1.3" style="padding:2pt 1.3pt;">0.2037</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.2.1.4" style="padding:2pt 1.3pt;">0.1804</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.3.2.1" style="padding:2pt 1.3pt;">w/o product attributes</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.3.2.2" style="padding:2pt 1.3pt;">0.2293</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.3.2.3" style="padding:2pt 1.3pt;">0.1396</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.3.2.4" style="padding:2pt 1.3pt;">0.1117</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.4.3.1" style="padding:2pt 1.3pt;">w/o query-product memory</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.4.3.2" style="padding:2pt 1.3pt;">0.2595</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.4.3.3" style="padding:2pt 1.3pt;">0.1786</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.4.3.4" style="padding:2pt 1.3pt;">0.1518</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.5.4.1" style="padding:2pt 1.3pt;">w/o text embedding</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.5.4.2" style="padding:2pt 1.3pt;">0.1757</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.5.4.3" style="padding:2pt 1.3pt;">0.1569</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.5.4.4" style="padding:2pt 1.3pt;">0.1510</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.6.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.6.5.1" style="padding:2pt 1.3pt;">w/o id embedding</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.6.5.2" style="padding:2pt 1.3pt;">0.2412</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.6.5.3" style="padding:2pt 1.3pt;">0.1480</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.6.5.4" style="padding:2pt 1.3pt;">0.1189</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.7.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.7.6.1" style="padding:2pt 1.3pt;">w/ CLIP text embedding</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.7.6.2" style="padding:2pt 1.3pt;">0.2004</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.7.6.3" style="padding:2pt 1.3pt;">0.1245</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.7.6.4" style="padding:2pt 1.3pt;">0.1039</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.8.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.8.7.1" style="padding:2pt 1.3pt;">w/o q.p.m. &amp; id emb.</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.8.7.2" style="padding:2pt 1.3pt;">0.2343</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.8.7.3" style="padding:2pt 1.3pt;">0.1424</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.8.7.4" style="padding:2pt 1.3pt;">0.1139</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.9.8">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.9.8.1" style="padding:2pt 1.3pt;">w/o q.p.m. &amp; id. &amp; pro. a.</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.9.8.2" style="padding:2pt 1.3pt;">0.2184</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.9.8.3" style="padding:2pt 1.3pt;">0.1285</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.9.8.4" style="padding:2pt 1.3pt;">0.1006</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Ablation Study</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We analyzed how different components in our design influence recommendation performance by introducing various model variants and testing them on the luggage and bags dataset. Specifically, we consider the following variants: (1) w/o product attributes: Product representation includes only the product title, omitting all attributes. (2) w/o query-product memory: Removes the query-product memory module. (3) w/o text embedding: Uses only ID embeddings for item retrieval. (4) w/o ID embedding: Uses only text embeddings for item retrieval. (5) w/ CLIP text embedding: Uses CLIP models for item retrieval. (6) w/o q.p.m. &amp; id emb.: a combination of the removals from variants (2) and (4). (7) w/o q.p.m. &amp; id. &amp; pro. a.: combining the removals from variants (1), (2), and (4).
The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.T3" title="Table 3 ‣ 5.2 Evaluation Results ‣ 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">3</span></a> show that each component improves performance. Notably, variants 3 and 4 highlight the benefits of our mixup-based retrieval method. The performance gap between variants 4 and 5 indicates that CLIP embedding models are less effective for recommendation tasks. Additionally, the slight performance drop from (4) to (6) indicates that the Query-Product Memory Module mainly influences the ID representation. Comparing (6) and (7) reveals the significance of product attributes in generating precise product titles.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Further Investigation</h3>
<div class="ltx_para ltx_noindent" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p1.1.1">Cold-start Setting. </span>
The cold-start problem is a well-known issue in recommendation systems <cite class="ltx_cite ltx_citemacro_cite">Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib23" title="">2019</a>); Pan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib34" title="">2019</a>); Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib50" title="">2021</a>)</cite>. To assess our model’s performance in a cold-start context, we have selected items from the testing sets that have not appeared in the training sets to construct the cold-start dataset for evaluation. For ID-based methods like CORE, we incorporate a "cold" token embedding into the item embeddings to supply prior knowledge, following the approach in <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib25" title="">2023</a>)</cite>. The results are presented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.F4" title="Figure 4 ‣ 5.4 Further Investigation ‣ 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">4</span></a>. It is evident that text-based methods significantly outperform ID-based approaches, primarily due to the limitations of randomly initialized cold-start item embeddings. Furthermore, our method surpasses Recformer, illustrating the effective incorporation of general knowledge and reasoning capabilities provided by LLMs.</p>
</div>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_block" id="S5.F4.3">
<figure class="ltx_figure" id="S5.F4.1"><img alt="Refer to caption" class="ltx_graphics" id="S5.F4.1.g1" src="cold_start_recall.eps"/>
</figure>
<figure class="ltx_figure" id="S5.F4.2"><img alt="Refer to caption" class="ltx_graphics" id="S5.F4.2.g1" src="cold_start_ndcg.eps"/>
</figure>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Performance comparison between our method with baselines in cold-start settings.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p2.1.1">Zero-shot Setting. </span>
In this setting, the models are required to learn knowledge from pre-trained datasets and directly test on downstream datasets without further fine-tuning, thus ID-based methods are not applicable here. To ensure a fair comparison with Recformer, which undergoes pre-training on large-scale, recommendation specific datasets, we used models pre-trained on the footwear dataset to evaluate performance on three other datasets. We also employed a model trained on the luggage dataset to assess its performance on the footwear dataset. The superior performance given in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.F5" title="Figure 5 ‣ 5.4 Further Investigation ‣ 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">5</span></a> demonstrates that our method can effectively capture and transfer learned knowledge to new tasks based on language understanding.</p>
</div>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_block" id="S5.F5.3">
<figure class="ltx_figure" id="S5.F5.1"><img alt="Refer to caption" class="ltx_graphics" id="S5.F5.1.g1" src="zero_shot_recall.eps"/>
</figure>
<figure class="ltx_figure" id="S5.F5.2"><img alt="Refer to caption" class="ltx_graphics" id="S5.F5.2.g1" src="zero_shot_ndcg.eps"/>
</figure>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Performance comparison between our method with baselines in zero-shot settings.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.1">Low Resource Setting. </span>
In this setting, we trained models on datasets with different ratios of training data. The experiment results are given in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#S5.F6" title="Figure 6 ‣ 5.4 Further Investigation ‣ 5 Experiments ‣ Sequential LLM Framework for Fashion Recommendation"><span class="ltx_text ltx_ref_tag">6</span></a>. We can see that when the less training data is available, the text-based methods outperforms the ID-based CORE, this advantage stems from the transferable knowledge encoded in item texts. Additionally, as the amount of training data increases, our method shows a more significant performance improvement compared to Recformer, highlighting its efficiency in learning task-specific knowledge.</p>
</div>
<figure class="ltx_figure" id="S5.F6">
<div class="ltx_block" id="S5.F6.3">
<figure class="ltx_figure" id="S5.F6.1"><img alt="Refer to caption" class="ltx_graphics ltx_centering" id="S5.F6.1.g1" src="low_res_recall.eps"/>
</figure>
<figure class="ltx_figure" id="S5.F6.2"><img alt="Refer to caption" class="ltx_graphics" id="S5.F6.2.g1" src="low_res_ndcg.eps"/>
</figure>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparison between our method with baselines in low-resource settings.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we propose a sequential fashion recommendation system enhanced by a LLM. Our method consists of three stages: prompt creation, training and inference, and retrieval and ranking.
First, we design specialized prompts that align the model with recommendation-specific goals. Second, we conduct efficient training to optimize the model. Third, we introduce a novel mix-up-based retrieval strategy that utilizes both ID and title embeddings to finalize item recommendations.
Extensive experiments show our method significantly enhances fashion recommendation performance.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1"><span class="ltx_text ltx_font_bold" id="Sx1.p1.1.1">Training and Inference Overhead.</span>
Incorporating LLMs into recommendation systems introduces additional complexities in terms of time and space. Despite these challenges, the domain of enhancing LLM efficiency is evolving swiftly, presenting strategies to alleviate these concerns. For instance, parameter-efficient fine-tuning techniques can notably reduce memory requirements and training time. In terms of inference efficiency, there is a growing body of research dedicated to developing more efficient inference frameworks. Notable contributions include LLMLingua <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib17" title="">2023</a>)</cite>, StreamingLLM <cite class="ltx_cite ltx_citemacro_cite">Xiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib41" title="">2023</a>)</cite>, and PagedAttention <cite class="ltx_cite ltx_citemacro_cite">Kwon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib22" title="">2023</a>)</cite>. These innovations demonstrate the feasibility of reducing the time and space complexities of LLMs. Furthermore, considering the substantial performance improvements the LLM could bring, the increased complexity is a worthwhile investment.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx1.p2.1.1">Incorporating Visual Signals. </span>
Visual signals play an important role in shaping users’ shopping decisions in the fashion domain. Our current approach focuses on textual data to model user interaction patterns, as incorporating images would significantly increase data collection and computational demands. However, integrating visual signals into our recommendation framework remains a promising direction. For instance, we could leverage multimodal LLMs to extract visual attributes such as color palette, lighting, textile type, shoulder style, and boot style <cite class="ltx_cite ltx_citemacro_cite">Zou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib51" title="">2024</a>)</cite>. Incorporating these attributes into our LLM-based recommendation framework could enhance its effectiveness.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p3">
<p class="ltx_p" id="Sx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx1.p3.1.1">Security and Privacy Risks.</span>
Like other machine learning models, LLMs are vulnerable to various security and privacy risks <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib28" title="">2023</a>); Chang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib3" title="">2024</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib27" title="">2024</a>)</cite>. For instance, LLMs can exhibit memorization tendencies that make them susceptible to data extraction attacks, which may recover training samples and thereby compromise user privacy <cite class="ltx_cite ltx_citemacro_cite">Carlini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.11327v1#bib.bib2" title="">2021</a>)</cite>. Addressing these risks with effective countermeasures is an important direction for future work.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Falcon llm.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://falconllm.tii.ae/falcon.html" title="">https://falconllm.tii.ae/falcon.html</a>.

</span>
<span class="ltx_bibblock">Accessed: 2023-08-01.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al. (2021)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et al. 2021.

</span>
<span class="ltx_bibblock">Extracting training data from large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">30th USENIX Security Symposium (USENIX Security 21)</em>, pages 2633–2650.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. (2024)</span>
<span class="ltx_bibblock">
Yuanhaur Chang, Han Liu, Evin Jaff, Chenyang Lu, and Ning Zhang. 2024.

</span>
<span class="ltx_bibblock">Sok: Security and privacy risks of medical ai.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2409.07415</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Hai Chen, Fulan Qian, Jie Chen, Shu Zhao, and Yanping Zhang. 2021.

</span>
<span class="ltx_bibblock">Fg-rs: Capture user fine-grained preferences through attribute information for recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Neurocomputing</em>, 458:195–203.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2019)</span>
<span class="ltx_bibblock">
Wen Chen, Pipei Huang, Jiaming Xu, Xin Guo, Cheng Guo, Fei Sun, Chao Li, Andreas Pfadler, Huan Zhao, and Binqiang Zhao. 2019.

</span>
<span class="ltx_bibblock">Pog: personalized outfit generation for fashion recommendation at alibaba ifashion.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</em>, pages 2662–2670.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deldjoo et al. (2022)</span>
<span class="ltx_bibblock">
Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro Bellogin, and Tommaso Di Noia. 2022.

</span>
<span class="ltx_bibblock">A review of modern fashion recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2202.02757</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock">Qlora: Efficient finetuning of quantized llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2305.14314</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2020)</span>
<span class="ltx_bibblock">
Manqing Dong, Feng Yuan, Lina Yao, Xiwei Xu, and Liming Zhu. 2020.

</span>
<span class="ltx_bibblock">Mamo: Memory-augmented meta-optimization for cold-start recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining</em>, pages 688–697.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
Koen van Gelder.

</span>
<span class="ltx_bibblock">Apparel, footwear and accessories retail e-commerce revenue in the united states from 2017 to 2027.

</span>
<span class="ltx_bibblock">Accessed: 2023-08-01.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
Ruining He, Chunbin Lin, and Julian McAuley. 2016.

</span>
<span class="ltx_bibblock">Fashionista: A fashion-aware graphical system for exploring visually similar items.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 25th International Conference Companion on World Wide Web</em>, pages 199–202.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He and McAuley (2016a)</span>
<span class="ltx_bibblock">
Ruining He and Julian McAuley. 2016a.

</span>
<span class="ltx_bibblock">Fusing similarity models with markov chains for sparse sequential recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">2016 IEEE 16th international conference on data mining (ICDM)</em>. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He and McAuley (2016b)</span>
<span class="ltx_bibblock">
Ruining He and Julian McAuley. 2016b.

</span>
<span class="ltx_bibblock">Vbpr: visual bayesian personalized ranking from implicit feedback.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, volume 30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hidasi et al. (2015)</span>
<span class="ltx_bibblock">
Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015.

</span>
<span class="ltx_bibblock">Session-based recommendations with recurrent neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:1511.06939</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al. (2019)</span>
<span class="ltx_bibblock">
Min Hou, Le Wu, Enhong Chen, Zhi Li, Vincent W Zheng, and Qi Liu. 2019.

</span>
<span class="ltx_bibblock">Explainable fashion recommendation: A semantic attribute region guided approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:1905.12862</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al. (2022)</span>
<span class="ltx_bibblock">
Yupeng Hou, Binbin Hu, Zhiqiang Zhang, and Wayne Xin Zhao. 2022.

</span>
<span class="ltx_bibblock">Core: simple and effective session-based recommendation within consistent representation space.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2106.09685</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. 2023.

</span>
<span class="ltx_bibblock">Llmlingua: Compressing prompts for accelerated inference of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2310.05736</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2016)</span>
<span class="ltx_bibblock">
Shuhui Jiang, Yue Wu, and Yun Fu. 2016.

</span>
<span class="ltx_bibblock">Deep bi-directional cross-triplet embedding for cross-domain clothing retrieval.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 24th ACM international conference on Multimedia</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2023)</span>
<span class="ltx_bibblock">
Wei Jin, Haitao Mao, Zheng Li, Haoming Jiang, Chen Luo, Hongzhi Wen, Haoyu Han, Hanqing Lu, Zhengyang Wang, Ruirui Li, et al. 2023.

</span>
<span class="ltx_bibblock">Amazon-m2: A multilingual multi-locale shopping session dataset for recommendation and text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2307.09688</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al. (2017)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang, Chen Fang, Zhaowen Wang, and Julian McAuley. 2017.

</span>
<span class="ltx_bibblock">Visually-aware fashion recommendation and design with generative image models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">2017 IEEE international conference on data mining (ICDM)</em>, pages 207–216. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">2018 IEEE international conference on data mining (ICDM)</em>, pages 197–206. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwon et al. (2023)</span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023.

</span>
<span class="ltx_bibblock">Efficient memory management for large language model serving with pagedattention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 29th Symposium on Operating Systems Principles</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2019)</span>
<span class="ltx_bibblock">
Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019.

</span>
<span class="ltx_bibblock">Melu: Meta-learned user preference estimator for cold-start recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, pages 1073–1082.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Chenglin Li, Mingjun Zhao, Huanming Zhang, Chenyun Yu, Lei Cheng, Guoqiang Shu, Beibei Kong, and Di Niu. 2022.

</span>
<span class="ltx_bibblock">Recguru: Adversarial learning of generalized user representations for cross-domain recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the fifteenth ACM international conference on web search and data mining</em>, pages 571–581.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023.

</span>
<span class="ltx_bibblock">Text is all you need: Learning language representations for sequential recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2305.13731</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2019)</span>
<span class="ltx_bibblock">
Yujie Lin, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Jun Ma, and Maarten De Rijke. 2019.

</span>
<span class="ltx_bibblock">Improving outfit recommendation with co-supervision of fashion generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">The World Wide Web Conference</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Han Liu, Yuhao Wu, Zhiyuan Yu, and Ning Zhang. 2024.

</span>
<span class="ltx_bibblock">Please tell me more: Privacy impact of explainability through the lens of membership inference attack.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">2024 IEEE Symposium on Security and Privacy (SP)</em>, pages 120–120. IEEE Computer Society.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Han Liu, Yuhao Wu, Shixuan Zhai, Bo Yuan, and Ning Zhang. 2023.

</span>
<span class="ltx_bibblock">Riatig: Reliable and imperceptible adversarial text-to-image generation with natural prompts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 20585–20594.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2017)</span>
<span class="ltx_bibblock">
Qiang Liu, Shu Wu, and Liang Wang. 2017.

</span>
<span class="ltx_bibblock">Deepstyle: Learning user preferences for visual recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 40th international acm sigir conference on research and development in information retrieval</em>, pages 841–844.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020)</span>
<span class="ltx_bibblock">
Siwei Liu, Iadh Ounis, Craig Macdonald, and Zaiqiao Meng. 2020.

</span>
<span class="ltx_bibblock">A heterogeneous graph neural model for cold-start recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval</em>, pages 2029–2032.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2017)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2017.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:1711.05101</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2022)</span>
<span class="ltx_bibblock">
Haixu Ma, Donglin Zeng, and Yufeng Liu. 2022.

</span>
<span class="ltx_bibblock">Learning individualized treatment rules with many treatments: A supervised clustering approach using adaptive fusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Advances in Neural Information Processing Systems</em>, 35:15956–15969.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Haixu Ma, Donglin Zeng, and Yufeng Liu. 2023.

</span>
<span class="ltx_bibblock">Learning optimal group-structured individualized treatment rules with many treatments.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Journal of Machine Learning Research</em>, 24(102):1–48.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. (2019)</span>
<span class="ltx_bibblock">
Feiyang Pan, Shuokai Li, Xiang Ao, Pingzhong Tang, and Qing He. 2019.

</span>
<span class="ltx_bibblock">Warm up cold-start advertisements: Improving ctr predictions via learning to learn id embeddings.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, pages 695–704.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">International conference on machine learning</em>, pages 8748–8763. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rendle et al. (2010)</span>
<span class="ltx_bibblock">
Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010.

</span>
<span class="ltx_bibblock">Factorizing personalized markov chains for next-basket recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 19th international conference on World wide web</em>, pages 811–820.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Si et al. (2023)</span>
<span class="ltx_bibblock">
Zihua Si, Zhongxiang Sun, Xiao Zhang, Jun Xu, Xiaoxue Zang, Yang Song, Kun Gai, and Ji-Rong Wen. 2023.

</span>
<span class="ltx_bibblock">When search meets recommendation: Learning disentangled search representation for recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, pages 1313–1323.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 28th ACM international conference on information and knowledge management</em>, pages 1441–1450.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang and Wang (2018)</span>
<span class="ltx_bibblock">
Jiaxi Tang and Ke Wang. 2018.

</span>
<span class="ltx_bibblock">Personalized top-n sequential recommendation via convolutional sequence embedding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the eleventh ACM international conference on web search and data mining</em>, pages 565–573.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2019)</span>
<span class="ltx_bibblock">
Huizhao Wang, Guanfeng Liu, Yan Zhao, Bolong Zheng, Pengpeng Zhao, and Kai Zheng. 2019.

</span>
<span class="ltx_bibblock">Dmfp: A dynamic multi-faceted fine-grained preference model for recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">2019 IEEE International Conference on Data Mining (ICDM)</em>, pages 608–617. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. (2023)</span>
<span class="ltx_bibblock">
Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. 2023.

</span>
<span class="ltx_bibblock">Efficient streaming language models with attention sinks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2309.17453</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2019)</span>
<span class="ltx_bibblock">
Ruiping Yin, Kan Li, Jie Lu, and Guangquan Zhang. 2019.

</span>
<span class="ltx_bibblock">Enhancing fashion recommendation with visual compatibility relationship.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">The world wide web conference</em>, pages 3434–3440.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2021)</span>
<span class="ltx_bibblock">
Wenhui Yu, Xiangnan He, Jian Pei, Xu Chen, Li Xiong, Jinfei Liu, and Zheng Qin. 2021.

</span>
<span class="ltx_bibblock">Visually aware recommendation with aesthetic features.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">The VLDB Journal</em>, 30:495–513.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(44)</span>
<span class="ltx_bibblock">
Fajie Yuan, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M Jose, and Xiangnan He.

</span>
<span class="ltx_bibblock">A simple convolutional generative network for next item recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 12th ACM international conference on web search and data mining</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019.

</span>
<span class="ltx_bibblock">Deep learning based recommender system: A survey and new perspectives.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">ACM computing surveys (CSUR)</em>, 52(1):1–38.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2021)</span>
<span class="ltx_bibblock">
Wayne Xin Zhao, Shanlei Mu, Yupeng Hou, Zihan Lin, Yushuo Chen, Xingyu Pan, Kaiyuan Li, Yujie Lu, Hui Wang, Changxin Tian, Yingqian Min, Zhichao Feng, Xinyan Fan, Xu Chen, Pengfei Wang, Wendi Ji, Yaliang Li, Xiaoling Wang, and Ji-Rong Wen. 2021.

</span>
<span class="ltx_bibblock">Recbole: Towards a unified, comprehensive and efficient framework for recommendation algorithms.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">CIKM</em>, pages 4653–4664. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023.

</span>
<span class="ltx_bibblock">A survey of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2303.18223</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2020)</span>
<span class="ltx_bibblock">
Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, and Ji-Rong Wen. 2020.

</span>
<span class="ltx_bibblock">S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the 29th ACM international conference on information &amp; knowledge management</em>, pages 1893–1902.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2022)</span>
<span class="ltx_bibblock">
Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022.

</span>
<span class="ltx_bibblock">Large language models are human-level prompt engineers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2211.01910</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
Yongchun Zhu, Ruobing Xie, Fuzhen Zhuang, Kaikai Ge, Ying Sun, Xu Zhang, Leyu Lin, and Juan Cao. 2021.

</span>
<span class="ltx_bibblock">Learning to warm up cold item embeddings for cold-start recommendation with meta scaling and shifting networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et al. (2024)</span>
<span class="ltx_bibblock">
Henry Peng Zou, Gavin Heqing Yu, Ziwei Fan, Dan Bu, Han Liu, Peng Dai, Dongmei Jia, and Cornelia Caragea. 2024.

</span>
<span class="ltx_bibblock">Eiven: Efficient implicit attribute value extraction using multimodal llm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2404.08886</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct 15 06:48:50 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
