<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2105.13995] SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)</title><meta property="og:description" content="Understanding tables is an important and relevant task that involves understanding table structure as well as being able to compare and contrast information within cells. In this paper, we address this challenge by pre…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2105.13995">

<!--Generated on Tue Mar 19 08:02:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nancy X. R. Wang  Diwakar Mahajan<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotemark: </span></span></span></span> Marina Danilevsky  Sara Rosenthal
<br class="ltx_break">IBM Research 
<br class="ltx_break">nancywang1991@gmail.com, {dmahaja, mdanile, sjrosenthal}@us.ibm.com
</span><span class="ltx_author_notes"> Equal Contribution Corresponding Author</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Understanding tables is an important and relevant task that involves understanding table structure as well as being able to compare and contrast information within cells. In this paper, we address this challenge by presenting a new dataset and tasks that addresses this goal in a shared task in SemEval 2020 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS). Our dataset contains 981 manually-generated tables and an auto-generated dataset of 1980 tables providing over 180K statement and over 16M evidence annotations. SEM-TAB-FACTS featured two sub-tasks. In sub-task A, the goal was to determine if a statement is supported, refuted or unknown in relation to a table. In sub-task B, the focus was on identifying the specific cells of a table that provide evidence for the statement. 69 teams signed up to participate in the task with 19 successful submissions to subtask A and 12 successful submissions to subtask B. We present our results and main findings from the competition.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Tables are ubiquitous in documents and presentations for conveying important information in a concise manner. This is true in many domains, stretching from scientific to government documents. In fact, surrounding text in these articles are often statements summarizing or highlighting some information derived from the primary source of data in tables. A relevant example is shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> from a Business Insider article analyzing the impact of Covid-19 <cite class="ltx_cite ltx_citemacro_cite">Aylin Woodward and Gal (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>. Describing all the information provided in this table in a readable manner would be lengthy and considerably more difficult to understand.
Despite their importance, popular question answering (e.g. SQuAD and Natural Question <cite class="ltx_cite ltx_citemacro_cite">Rajpurkar et al. (<a href="#bib.bib20" title="" class="ltx_ref">2016</a>); Kwiatkowski et al. (<a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>) and truth verification tasks (e.g. SemEval-2019 Fact Checking Task <cite class="ltx_cite ltx_citemacro_cite">Mihaylova et al. (<a href="#bib.bib17" title="" class="ltx_ref">2019</a>)</cite>) have not focused on tables, being composed solely of written text.
This is likely due to their complexity to parse and understand, despite their rich amount of information.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2105.13995/assets/bi_corona_img1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="405" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Surrounding text often highlights some information from the table but does not capture all data. Alternately, the linked text may be subjective or even misleading without the original table to check the claims.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Further, the structure of tables allows much more information to be presented in an efficient manner as humans can interpret meaning in the spatial relationship between cells. However, due to their challenging nature, recent algorithms have been less successful at extracting <cite class="ltx_cite ltx_citemacro_cite">Hoffswell and Liu (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> and understanding header and data structure in tables <cite class="ltx_cite ltx_citemacro_cite">Cafarella et al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>. In addition, any hierarchical and nested headers (common in printed documents) increases the difficulty in interpreting data cells, as shown in Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we propose to bridge this gap with statement verification and evidence finding using tables from scientific articles. This important task promotes proper interpretation of the surrounding article. In fact, the misunderstanding of tables can lead to the reporting of fake news that we see as being all too prevalent today.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We present the first SemEval challenge to address table understanding. We introduce a brand new dataset of 1980 tables from scientific articles that addresses two challenging tasks important to table understanding:</p>
</div>
<div id="S1.p5" class="ltx_para">
<dl id="S1.I1" class="ltx_description">
<dt id="S1.I1.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix1.1.1.1" class="ltx_text ltx_font_bold">A: Statement Fact Verification</span></span></dt>
<dd class="ltx_item">
<div id="S1.I1.ix1.p1" class="ltx_para">
<p id="S1.I1.ix1.p1.1" class="ltx_p">Given a statement, determine whether it is <span id="S1.I1.ix1.p1.1.1" class="ltx_text ltx_font_italic">supported</span>, <span id="S1.I1.ix1.p1.1.2" class="ltx_text ltx_font_italic">refuted</span> or <span id="S1.I1.ix1.p1.1.3" class="ltx_text ltx_font_italic">unknown</span> according to the table.</p>
</div>
</dd>
<dt id="S1.I1.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix2.1.1.1" class="ltx_text ltx_font_bold">B: Cell Evidence Selection</span></span></dt>
<dd class="ltx_item">
<div id="S1.I1.ix2.p1" class="ltx_para">
<p id="S1.I1.ix2.p1.1" class="ltx_p">Given a statement, select the cells in the table that provide evidence supporting or refuting the statement.</p>
</div>
</dd>
</dl>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The rest of this paper is formatted as follows: We first discuss related work. We then present a new large table understanding dataset containing close to 2000 tables that is the first to provide evidence labels at the cell level for statements and the first to focus on scientific articles. We provide a detailed analysis of the dataset including several baseline results. We then discuss the performance and approaches of the 19 participants in our challenge and end with an aggregated analysis of participating teams. Finally, we discuss future work.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2105.13995/assets/x1.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="291" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>A complex table sourced from <cite class="ltx_cite ltx_citemacro_cite">East et al. (<a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite> with hierarchical column and row structure. Additional difficulty follows from row hierarchy not being delineated by separate columns.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Natural Language Inference (NLI)</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">The table evidence task can be best understood as a variation of the natural language inference task <cite class="ltx_cite ltx_citemacro_cite">Dagan et al. (<a href="#bib.bib6" title="" class="ltx_ref">2005</a>)</cite>, but on tabular data. NLI asks whether one (or more) sentence entails, refutes, or is unrelated to another sentence; our framing asks whether a given table entails, refutes, or is unrelated to a sentence. Several datasets have been created for studying NLI, such as SNLI <cite class="ltx_cite ltx_citemacro_cite">Bowman et al. (<a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite>, MultiNLI <cite class="ltx_cite ltx_citemacro_cite">Williams et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite>, and SciTail <cite class="ltx_cite ltx_citemacro_cite">Khot et al. (<a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Table QA</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">This task is also closely related to the problem of search and question answering on tables. The closest example would be, given a table that is known to contain the relevant information, return cell values that answer a natural language question <cite class="ltx_cite ltx_citemacro_cite">Pasupat and Liang (<a href="#bib.bib19" title="" class="ltx_ref">2015</a>)</cite>. A variation requires analyzing a collection of tables rather than a single one, along with the natural language question <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a href="#bib.bib22" title="" class="ltx_ref">2016</a>)</cite>. Two of the most recent works are TAPAS <cite class="ltx_cite ltx_citemacro_cite">Herzig et al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite> and TaBERT <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite>, which jointly pre-train over textual and tabular data to facilitate table QA. However, such approaches have previously focused on traditional natural language questions (“What is the population of France?”) rather than inference statements (“France has the highest population in Europe”), which may be entailed, refuted or unknowable from the given table.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Related Datasets</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">The works closest to our dataset are TabFact <cite class="ltx_cite ltx_citemacro_cite">Wenhu Chen and Wang (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> and INFOTABS <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>. Both datasets were sourced from Wikipedia tables and contain hypothesis and premise pairs. TabFact has entailment and refute hypothesis types while INFOTABS has an additional “neutral” hypothesis category, much like our “unknown” statements. Both works show that neural models still lag far behind human performance for the fact checking task with tables.</p>
</div>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p2.1" class="ltx_p">While both datasets have been great at kindling interest in fact verification with tabular data, our dataset differs in two key aspects. First, we source from scientific articles in a variety of domains rather than Wikipedia infoboxes. Scientific tables have very specialized vocabulary and can be more difficult to interpret. Additionally, scientific tables have much more complex structure, like hierarchical column and row headers, rendering the assumption that the first column/row is the header unhelpful. Finally, tables are often directly referenced in scientific text unlike Wikipedia tables that are generally stand-alone. This creates an opportunity to leverage natural statements that depict the original author’s style and intent. The second key differentiator of SEM-TAB-FACTS is the accompanying evidence annotations. We believe the future of fact verification and AI in general will be in cooperation with humans rather than in replacement. Thus, it is essential that models are able to present explanations for decisions on the relationship between the statement and table by showing the most relevant cells in a potentially very large table.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S2.T1.1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">#Tables</span></td>
<td id="S2.T1.1.1.1.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">#Entailed</span></td>
<td id="S2.T1.1.1.1.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">#Refuted</span></td>
<td id="S2.T1.1.1.1.5" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T1.1.1.1.5.1" class="ltx_text ltx_font_bold">#Unknown</span></td>
<td id="S2.T1.1.1.1.6" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T1.1.1.1.6.1" class="ltx_text ltx_font_bold">#Relevant</span></td>
<td id="S2.T1.1.1.1.7" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T1.1.1.1.7.1" class="ltx_text ltx_font_bold">#Irrelevant</span></td>
</tr>
<tr id="S2.T1.1.2.2" class="ltx_tr">
<td id="S2.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_t">Train Crowdsourced</td>
<td id="S2.T1.1.2.2.2" class="ltx_td ltx_align_right ltx_border_t">981</td>
<td id="S2.T1.1.2.2.3" class="ltx_td ltx_align_right ltx_border_t">2,818</td>
<td id="S2.T1.1.2.2.4" class="ltx_td ltx_align_right ltx_border_t">1,688</td>
<td id="S2.T1.1.2.2.5" class="ltx_td ltx_align_right ltx_border_t">0</td>
<td id="S2.T1.1.2.2.6" class="ltx_td ltx_align_right ltx_border_t">0</td>
<td id="S2.T1.1.2.2.7" class="ltx_td ltx_align_right ltx_border_t">0</td>
</tr>
<tr id="S2.T1.1.3.3" class="ltx_tr">
<td id="S2.T1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t">Train Auto-generated</td>
<td id="S2.T1.1.3.3.2" class="ltx_td ltx_align_right ltx_border_t">1,980</td>
<td id="S2.T1.1.3.3.3" class="ltx_td ltx_align_right ltx_border_t">92,136</td>
<td id="S2.T1.1.3.3.4" class="ltx_td ltx_align_right ltx_border_t">87,209</td>
<td id="S2.T1.1.3.3.5" class="ltx_td ltx_align_right ltx_border_t">0</td>
<td id="S2.T1.1.3.3.6" class="ltx_td ltx_align_right ltx_border_t">1,039,058</td>
<td id="S2.T1.1.3.3.7" class="ltx_td ltx_align_right ltx_border_t">15,467,957</td>
</tr>
<tr id="S2.T1.1.4.4" class="ltx_tr">
<td id="S2.T1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_t">Development</td>
<td id="S2.T1.1.4.4.2" class="ltx_td ltx_align_right ltx_border_t">52</td>
<td id="S2.T1.1.4.4.3" class="ltx_td ltx_align_right ltx_border_t">250</td>
<td id="S2.T1.1.4.4.4" class="ltx_td ltx_align_right ltx_border_t">213</td>
<td id="S2.T1.1.4.4.5" class="ltx_td ltx_align_right ltx_border_t">93</td>
<td id="S2.T1.1.4.4.6" class="ltx_td ltx_align_right ltx_border_t">3,048</td>
<td id="S2.T1.1.4.4.7" class="ltx_td ltx_align_right ltx_border_t">2,8495</td>
</tr>
<tr id="S2.T1.1.5.5" class="ltx_tr">
<td id="S2.T1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Test</td>
<td id="S2.T1.1.5.5.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">52</td>
<td id="S2.T1.1.5.5.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">274</td>
<td id="S2.T1.1.5.5.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">248</td>
<td id="S2.T1.1.5.5.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">131</td>
<td id="S2.T1.1.5.5.6" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">3,458</td>
<td id="S2.T1.1.5.5.7" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">26,724</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span> Statistics for our SEM-TAB-FACTS dataset.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset Details</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our dataset consists of two forms of generation: (1) a crowdsourced dataset, and (2) an auto-generated dataset. Table <a href="#S2.T1" title="Table 1 ‣ Related Datasets ‣ 2 Related Work ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents the statistics of the dataset. We detail our dataset creation process in the following sections.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data extraction and preprocessing</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We sourced our tables from scientific articles belonging to active journals that are currently being published by Elsevier and are available on ScienceDirect<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.elsevier.com/__data/promis_misc/sd-content/journals/jnlactive.xlsx" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.elsevier.com/__data/promis_misc/sd-content/journals/jnlactive.xlsx</a></span></span></span>. We utilized Elsevier ScienceDirect APIs<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://dev.elsevier.com/sd_apis.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dev.elsevier.com/sd_apis.html</a></span></span></span> to scrape scientific articles which belong to this list, and satisfy the following criteria: (1) the article is open-access<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://www.elsevier.com/open-access" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.elsevier.com/open-access</a></span></span></span>, (2) the article is available under “Creative Commons Attribution 4.0 (CC-BY)” user license<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://www.elsevier.com/about/policies/open-access-licenses/user-licences" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.elsevier.com/about/policies/open-access-licenses/user-licences</a></span></span></span>, and (3) the article has at least one table. We downloaded 1,920 articles belonging to 722 journals which contained 6,773 tables. We further filtered out complicated tables (e.g. multiple tables in a single table) using hand-written rules to get a set of 2,762 candidate tables from 1,085 articles for annotation. We also extracted sentences mentioning the table within the scientific article as candidate statements, which are corrected and then labeled manually by the annotators.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2105.13995/assets/Sample_appen_statements.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="354" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Sample crowd-sourced statements for one table (sourced from <cite class="ltx_cite ltx_citemacro_cite">Carney et al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>). Please note that these are the original statements without any further corrections nor rephrasing.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Crowdsourced labeling</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The manually generated statements were collected using the crowdsourcing platform Appen<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://appen.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://appen.com/</a></span></span></span>. We collected five entailed and five refuted statements for each table from the business preferred operators (BPO) on Appen. The BPO crowd is composed of employees hired by Appen on an hourly basis at a constant pay rate determined by Appen. We found that the workers were much more motivated for the task as they were able to ask questions if needed and we were also able to provide direct feedback to the workers. We initially attempted generating statements with workers from the Appen open-crowd, which is on-demand, but the quality was very poor as it was hard to automatically validate naturally generated statements. Our instructions explicitly lay out 7 types of statements and ask that workers attempt to make one of each type. We encourage the use of different sets of cells whenever possible. The types of statements are aggregation, superlative, count, comparative, unique, all and usage of caption or common sense knowledge. These are derived from the INFOTABS analysis <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>. We asked workers to avoid subjective adjectives like “best”, “worst”, “seldom” and look-up statements that only require reasoning with one cell. The pay for each statement set was 75 cents. In total, we collected 10000 statements for 1000 unique tables. See Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Data extraction and preprocessing ‣ 3 Dataset Details ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for an example table with its manually generated and natural statements.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Additionally, for our training data, we conducted a verification task to check for grammatical issues and doubly verify the statement label for both the generated and natural in-text statements. The verification task was paid at 3 cents per statement, which equates to 30 cents per table. We restricted the verification task to the workers in the open-crowd from English speaking countries. After verification, we only preserved the statements that were verified to be grammatically correct and the new label matched the original label. Natural statements were also verified in the same process. Although natural statements were generally factually correct, they were sometimes not able to be verified by the referenced table. Additionally, these statements often required rewording to ensure that all parts of the statement can be verified by the table, which was a step taken only for the development and test sets. This left us with 981 tables and 4506 statements. The majority of the removals were due to grammatical errors as most BPO workers are not native English speakers. See Table <a href="#S2.T1" title="Table 1 ‣ Related Datasets ‣ 2 Related Work ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (first row) for detailed statistics of the crowd-sourced training set.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">We initially attempted to collect the development and test sets as well as evidence annotations via the same method as the training set. However, we found that the quality was not gold-level and thus we (three of the authors) decided to manually correct the statements and annotate the evidence ourselves. All authors first annotated a small set of 102 statements to test inter-annotator agreement for statement relationship and evidence labeling. Out of 102 statements, we found 5 statements where at least one of three annotators disagreed on the relationship and a further 5 statements where the relationship was agreed but the evidence annotation differed. The other 92 were in complete agreement, indicating high agreement. Therefore, the annotations for the rest of the dev set were annotated by just one person.
The test set was annotated fully by one author and the two other authors checked the annotations with all disagreements being resolved. See Figure <a href="#S3.F4" title="Figure 4 ‣ 3.2 Crowdsourced labeling ‣ 3 Dataset Details ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> for a screenshot of the statement annotation correction and evidence annotation interface. See the third and fourth rows of Table <a href="#S2.T1" title="Table 1 ‣ Related Datasets ‣ 2 Related Work ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for detailed statistics of the dev and test sets.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2105.13995/assets/sample_label_screenshot.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="375" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Screenshot showing the labeling interface for statement rephrasing, relationship labeling and evidence annotation.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Automatically generated statements</h3>

<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.1.1.1" class="ltx_p" style="width:19.9pt;"><span id="S3.T2.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Input</span></span>
</span>
</th>
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S3.T2.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Template</span></span>
</span>
</th>
<th id="S3.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T2.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Evidence</span></span>
</span>
</th>
<th id="S3.T2.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.4.1.1" class="ltx_p" style="width:156.5pt;"><span id="S3.T2.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Example Statements</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.2.1" class="ltx_tr">
<td id="S3.T2.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.1.1.1" class="ltx_p" style="width:19.9pt;">col_i, col_j</span>
</span>
</td>
<td id="S3.T2.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.2.1.1" class="ltx_p" style="width:142.3pt;">‘The’ + col_i_head + ‘is’ + col_i_val + ‘, when the’ + col_j_head + ‘is’ + col_j_val</span>
</span>
</td>
<td id="S3.T2.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.3.1.1" class="ltx_p" style="width:85.4pt;">col_i_head, col_j_head, col_i_val, col_j_val</span>
</span>
</td>
<td id="S3.T2.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.4.1.1" class="ltx_p" style="width:156.5pt;">The Code is AG3 when the Locality is Los Aguanances3.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.3.2" class="ltx_tr">
<td id="S3.T2.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.1.1.1" class="ltx_p" style="width:19.9pt;">col</span>
</span>
</td>
<td id="S3.T2.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.2.1.1" class="ltx_p" style="width:142.3pt;">col_val + ‘is in’ + col_head</span>
</span>
</td>
<td id="S3.T2.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.3.1.1" class="ltx_p" style="width:85.4pt;">col_val, col_head for entailed; col for refuted</span>
</span>
</td>
<td id="S3.T2.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.4.1.1" class="ltx_p" style="width:156.5pt;">AG3 is in Code.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.4.3" class="ltx_tr">
<td id="S3.T2.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.1.1.1" class="ltx_p" style="width:19.9pt;">col</span>
</span>
</td>
<td id="S3.T2.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.2.1.1" class="ltx_p" style="width:142.3pt;">unique or same values</span>
</span>
</td>
<td id="S3.T2.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.3.1.1" class="ltx_p" style="width:85.4pt;">col for entailed; None for refuted</span>
</span>
</td>
<td id="S3.T2.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.4.1.1" class="ltx_p" style="width:156.5pt;">Sup./Inf. has the same values.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.5.4" class="ltx_tr">
<td id="S3.T2.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.1.1.1" class="ltx_p" style="width:19.9pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.2.1.1" class="ltx_p" style="width:142.3pt;">‘The maximum of’ + col_head +‘is’+val</span>
</span>
</td>
<td id="S3.T2.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.3.1.1" class="ltx_p" style="width:85.4pt;">col[#] for entailed; None for refuted</span>
</span>
</td>
<td id="S3.T2.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.4.1.1" class="ltx_p" style="width:156.5pt;">The maximum of Length(mm) is 2.22.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.6.5" class="ltx_tr">
<td id="S3.T2.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.1.1.1" class="ltx_p" style="width:19.9pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.2.1.1" class="ltx_p" style="width:142.3pt;">‘The minimum of’ + col_head +‘is’+val</span>
</span>
</td>
<td id="S3.T2.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.3.1.1" class="ltx_p" style="width:85.4pt;">col[#] for entailed; None for refuted</span>
</span>
</td>
<td id="S3.T2.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.4.1.1" class="ltx_p" style="width:156.5pt;">The minimum of Length(mm) is 1.54.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.7.6" class="ltx_tr">
<td id="S3.T2.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.1.1.1" class="ltx_p" style="width:19.9pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.2.1.1" class="ltx_p" style="width:142.3pt;">‘The mean of’ + col_head + ‘is’ + val</span>
</span>
</td>
<td id="S3.T2.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.3.1.1" class="ltx_p" style="width:85.4pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.4.1.1" class="ltx_p" style="width:156.5pt;">The mean of Length(mm) is 1.83.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.8.7" class="ltx_tr">
<td id="S3.T2.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.1.1.1" class="ltx_p" style="width:19.9pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.2.1.1" class="ltx_p" style="width:142.3pt;">‘The median of’ + col_head + ‘is’ + val</span>
</span>
</td>
<td id="S3.T2.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.3.1.1" class="ltx_p" style="width:85.4pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.4.1.1" class="ltx_p" style="width:156.5pt;">The median of Length(mm) is 1.73.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.9.8" class="ltx_tr">
<td id="S3.T2.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.1.1.1" class="ltx_p" style="width:19.9pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.2.1.1" class="ltx_p" style="width:142.3pt;">‘The mode of’ + col_head + ‘is’ + val</span>
</span>
</td>
<td id="S3.T2.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.3.1.1" class="ltx_p" style="width:85.4pt;">col[#]</span>
</span>
</td>
<td id="S3.T2.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.4.1.1" class="ltx_p" style="width:156.5pt;">The mode of Length(mm) is 1.54, 1.73, 2.22.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span> Template and evidence rules used for auto-generated ground truth. The examples are derived from Table 4 in Figure 4.</figcaption>
</figure>
<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">IBM Watson™ Discovery<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://www.ibm.com/cloud/watson-discovery</span></span></span> is an AI-powered search and text analytics engine for extracting answers from complex business documents.
One of the available functionalities is a Table Understanding service that produces a detailed enrichment of table data within an html document. We use this service to identify the body and header cells, as well as the <em id="S3.SS3.p1.1.1" class="ltx_emph ltx_font_italic">cell relationships</em>, within our dataset. We then proceed to use a set of templates to automatically create statements about each table. We begin by identifying which cells and columns are numeric and non-numeric using a simple regex. Unlike non-numeric cells, numeric cells and columns are appropriate for specific templates that expect numeric values, such as ‘Value [V] is the maximum of Column [C]’, where every value in column [C] has been identified as numeric. We also generate evidence for some of these templates. The template and evidence generation rules along with their inputs are detailed in Table <a href="#S3.T2" title="Table 2 ‣ 3.3 Automatically generated statements ‣ 3 Dataset Details ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. This process generated 3,512,978 statements from 1,980 tables which were highly skewed in favor of refuted statements. This dataset was then down-sampled to a maximum of 50 statements per table while ensuring a more even distribution between the two classes to form our final released auto-generated dataset. The full statistics for the auto-generated training data is shown in the second row of Table <a href="#S2.T1" title="Table 1 ‣ Related Datasets ‣ 2 Related Work ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation Metrics</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Task A: Statement Fact Verification</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The goal of task A is to determine if a statement is entailed or refuted by the given table, or whether, as is in some cases, this cannot be determined from the table.
We show two evaluation results. The first is a standard 3-way Precision / Recall / F1 micro evaluation of a multi-class classification that evaluates whether each table was classified correctly as Entailed / Refuted / Unknown. This tests whether the classification algorithm understands cases where there is insufficient information to make a determination.
The second, simpler evaluation, uses the same P/R/F1 metric but is a 2-way classification that removes statements with the “unknown” ground truth label from the evaluation. The 2-way metric still penalizes misclassifying refuted/ entailed statement as unknown.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Task B: Cell Evidence Selection</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In Task B, the goal is to determine for each cell and each statement, if the cell is within the minimum set of cells needed to provide evidence for the statement (“relevant”) or not (“irrelevant”). In other words, if the table were shown with all other cells blurred out, would this be enough for a human to reasonably determine that the table entails or refutes the statement?
The evaluation calculates the recall and precision for each cell, with “relevant” cells as the positive category. For some statements, there may be multiple minimal sets of cells that can be used to determine statement entailment or refusal. In such cases, our dataset contains all of these versions. We compare the prediction to each ground truth version and count the highest score.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We present our baseline experimental setup for each task below.</p>
</div>
<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Task A</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">We employ state-of-the-art Table-BERT implementation<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/wenhuchen/Table-Fact-Checking" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/wenhuchen/Table-Fact-Checking</a></span></span></span> as proposed by <cite class="ltx_cite ltx_citemacro_citet">Wenhu Chen and Wang (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>. We utilize Table-BERT’s best performing configuration (Table-BERT-Horizontal-T+F-Template) as (1) using entity-linking to find the relevant columns for a statement, (2) flattening the table by scanning horizontally to form natural statements from the relevant columns and their cell values and (3) classifying the flattened table and the statement using the sentence pair classification setting in BERT. To overcome the lack of unknown statements in our dataset, we supplement each table with randomly chosen statements from other tables. In Table-BERT, if the entity linking results in no matches, the flattened table is marked as [UNK]. As our dataset contains unknown statements, in such cases we consider all columns to be a match and flatten the entire table.</p>
</div>
<div id="S5.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p2.1" class="ltx_p">Using the above process, we perform the following experiments (1) apply the Table-BERT model out-of-the-box (2) re-train Table-BERT model with unknown statement and apply on our test data (3) fine-tune the model in (2) with our manual+auto-generated data and apply on our test data. We also compare these experiments with a majority baseline with entailed as our majority class. The results are presented in Table <a href="#S5.T3" title="Table 3 ‣ Task A ‣ 5 Experiments ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Applying Table-BERT model out-of-the-box provides some improvement over a majority-baseline. However, when the model is retrained with previously missing unknown statements, the performance improves for three-way classification. Further fine-tuning the model with our training dataset (both manual and auto-generated) provides the best performance on the two-way F1-score.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2">
<span id="S5.T3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.1.1.1.1.1.1" class="ltx_p" style="width:113.8pt;"><span id="S5.T3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Experiment</span></span>
</span>
</th>
<th id="S5.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S5.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Test</span></th>
</tr>
<tr id="S5.T3.1.2.2" class="ltx_tr">
<td id="S5.T3.1.2.2.1" class="ltx_td ltx_align_left"><span id="S5.T3.1.2.2.1.1" class="ltx_text ltx_font_bold">2-way</span></td>
<td id="S5.T3.1.2.2.2" class="ltx_td ltx_align_left"><span id="S5.T3.1.2.2.2.1" class="ltx_text ltx_font_bold">3-way</span></td>
</tr>
<tr id="S5.T3.1.3.3" class="ltx_tr">
<th id="S5.T3.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S5.T3.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.1.3.3.1.1.1" class="ltx_p" style="width:113.8pt;">majority-baseline</span>
</span>
</th>
<td id="S5.T3.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t">52.42</td>
<td id="S5.T3.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">42.16</td>
</tr>
<tr id="S5.T3.1.4.4" class="ltx_tr">
<th id="S5.T3.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S5.T3.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.1.4.4.1.1.1" class="ltx_p" style="width:113.8pt;">original Table-BERT</span>
</span>
</th>
<td id="S5.T3.1.4.4.2" class="ltx_td ltx_align_left ltx_border_t">56.77</td>
<td id="S5.T3.1.4.4.3" class="ltx_td ltx_align_left ltx_border_t">45.58</td>
</tr>
<tr id="S5.T3.1.5.5" class="ltx_tr">
<th id="S5.T3.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S5.T3.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.1.5.5.1.1.1" class="ltx_p" style="width:113.8pt;">re-trained Table-BERT</span>
</span>
</th>
<td id="S5.T3.1.5.5.2" class="ltx_td ltx_align_left ltx_border_t">52.96</td>
<td id="S5.T3.1.5.5.3" class="ltx_td ltx_align_left ltx_border_t">48.33</td>
</tr>
<tr id="S5.T3.1.6.6" class="ltx_tr">
<th id="S5.T3.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<span id="S5.T3.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.1.6.6.1.1.1" class="ltx_p" style="width:113.8pt;">+ FT with SEM-TAB-FACTS</span>
</span>
</th>
<td id="S5.T3.1.6.6.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">56.81</td>
<td id="S5.T3.1.6.6.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">48.24</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span> Task A baseline results using F1-score.</figcaption>
</figure>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Task B</h4>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">We present the following two baselines for Task B: (1) a random baseline where each cell is marked relevant or irrelevant randomly (2) a simple word-match-based baseline where a cell is marked relevant if it overlaps with the statement. The baseline results are presented in Table <a href="#S5.T4" title="Table 4 ‣ Task B ‣ 5 Experiments ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Experiment</span></th>
<th id="S5.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">Dev</span></th>
<th id="S5.T4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">Test</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.1.2.1" class="ltx_tr">
<td id="S5.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">random-baseline</td>
<td id="S5.T4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">21.18</td>
<td id="S5.T4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">20.47</td>
</tr>
<tr id="S5.T4.1.3.2" class="ltx_tr">
<td id="S5.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">word-match</td>
<td id="S5.T4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">49.53</td>
<td id="S5.T4.1.3.2.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">47.39</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span> Task B baseline results using F1-Score</figcaption>
</figure>
<figure id="S5.T5" class="ltx_table">
<table id="S5.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T5.1.1.1" class="ltx_tr">
<td id="S5.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">Team</span></td>
<td id="S5.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T5.1.1.1.2.1" class="ltx_text ltx_font_bold">3-way F-Score</span></td>
<td id="S5.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T5.1.1.1.3.1" class="ltx_text ltx_font_bold">2-way F-Score</span></td>
</tr>
<tr id="S5.T5.1.2.2" class="ltx_tr">
<td id="S5.T5.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" colspan="3"><span id="S5.T5.1.2.2.1.1" class="ltx_text ltx_font_bold">Official Leaderboard</span></td>
</tr>
<tr id="S5.T5.1.3.3" class="ltx_tr">
<td id="S5.T5.1.3.3.1" class="ltx_td ltx_align_center ltx_border_t">King001</td>
<td id="S5.T5.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.3.3.2.1" class="ltx_text ltx_font_bold">84.48</span></td>
<td id="S5.T5.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.3.3.3.1" class="ltx_text ltx_font_bold">88.74</span></td>
</tr>
<tr id="S5.T5.1.4.4" class="ltx_tr">
<td id="S5.T5.1.4.4.1" class="ltx_td ltx_align_center">THiFly_Queen</td>
<td id="S5.T5.1.4.4.2" class="ltx_td ltx_align_center">83.76</td>
<td id="S5.T5.1.4.4.3" class="ltx_td ltx_align_center">84.55</td>
</tr>
<tr id="S5.T5.1.5.5" class="ltx_tr">
<td id="S5.T5.1.5.5.1" class="ltx_td ltx_align_center">RyanStark</td>
<td id="S5.T5.1.5.5.2" class="ltx_td ltx_align_center">81.51</td>
<td id="S5.T5.1.5.5.3" class="ltx_td ltx_align_center">87.22</td>
</tr>
<tr id="S5.T5.1.6.6" class="ltx_tr">
<td id="S5.T5.1.6.6.1" class="ltx_td ltx_align_center">sattiy</td>
<td id="S5.T5.1.6.6.2" class="ltx_td ltx_align_center">77.32</td>
<td id="S5.T5.1.6.6.3" class="ltx_td ltx_align_center">84.96</td>
</tr>
<tr id="S5.T5.1.7.7" class="ltx_tr">
<td id="S5.T5.1.7.7.1" class="ltx_td ltx_align_center">BreakingBERT@IITK</td>
<td id="S5.T5.1.7.7.2" class="ltx_td ltx_align_center">69.31</td>
<td id="S5.T5.1.7.7.3" class="ltx_td ltx_align_center">76.81</td>
</tr>
<tr id="S5.T5.1.8.8" class="ltx_tr">
<td id="S5.T5.1.8.8.1" class="ltx_td ltx_align_center">Volta</td>
<td id="S5.T5.1.8.8.2" class="ltx_td ltx_align_center">67.34</td>
<td id="S5.T5.1.8.8.3" class="ltx_td ltx_align_center">72.89</td>
</tr>
<tr id="S5.T5.1.9.9" class="ltx_tr">
<td id="S5.T5.1.9.9.1" class="ltx_td ltx_align_center">TAPAS</td>
<td id="S5.T5.1.9.9.2" class="ltx_td ltx_align_center">66.81</td>
<td id="S5.T5.1.9.9.3" class="ltx_td ltx_align_center">73.13</td>
</tr>
<tr id="S5.T5.1.10.10" class="ltx_tr">
<td id="S5.T5.1.10.10.1" class="ltx_td ltx_align_center">AttesTable</td>
<td id="S5.T5.1.10.10.2" class="ltx_td ltx_align_center">65.59</td>
<td id="S5.T5.1.10.10.3" class="ltx_td ltx_align_center">71.72</td>
</tr>
<tr id="S5.T5.1.11.11" class="ltx_tr">
<td id="S5.T5.1.11.11.1" class="ltx_td ltx_align_center">Yaoxu</td>
<td id="S5.T5.1.11.11.2" class="ltx_td ltx_align_center">60.76</td>
<td id="S5.T5.1.11.11.3" class="ltx_td ltx_align_center">75.8</td>
</tr>
<tr id="S5.T5.1.12.12" class="ltx_tr">
<td id="S5.T5.1.12.12.1" class="ltx_td ltx_align_center">Beary-group</td>
<td id="S5.T5.1.12.12.2" class="ltx_td ltx_align_center">58.37</td>
<td id="S5.T5.1.12.12.3" class="ltx_td ltx_align_center">72.56</td>
</tr>
<tr id="S5.T5.1.13.13" class="ltx_tr">
<td id="S5.T5.1.13.13.1" class="ltx_td ltx_align_center">ok-team</td>
<td id="S5.T5.1.13.13.2" class="ltx_td ltx_align_center">57.79</td>
<td id="S5.T5.1.13.13.3" class="ltx_td ltx_align_center">71.84</td>
</tr>
<tr id="S5.T5.1.14.14" class="ltx_tr">
<td id="S5.T5.1.14.14.1" class="ltx_td ltx_align_center">SUNLP</td>
<td id="S5.T5.1.14.14.2" class="ltx_td ltx_align_center">47.92</td>
<td id="S5.T5.1.14.14.3" class="ltx_td ltx_align_center">59.58</td>
</tr>
<tr id="S5.T5.1.15.15" class="ltx_tr">
<td id="S5.T5.1.15.15.1" class="ltx_td ltx_align_center">FishToucher</td>
<td id="S5.T5.1.15.15.2" class="ltx_td ltx_align_center">41.83</td>
<td id="S5.T5.1.15.15.3" class="ltx_td ltx_align_center">52.01</td>
</tr>
<tr id="S5.T5.1.16.16" class="ltx_tr">
<td id="S5.T5.1.16.16.1" class="ltx_td ltx_align_center">KaushikAcharya</td>
<td id="S5.T5.1.16.16.2" class="ltx_td ltx_align_center">36.23</td>
<td id="S5.T5.1.16.16.3" class="ltx_td ltx_align_center">23.08</td>
</tr>
<tr id="S5.T5.1.17.17" class="ltx_tr">
<td id="S5.T5.1.17.17.1" class="ltx_td ltx_align_center ltx_border_t" colspan="3"><span id="S5.T5.1.17.17.1.1" class="ltx_text ltx_font_bold">Unverified Leaderboard</span></td>
</tr>
<tr id="S5.T5.1.18.18" class="ltx_tr">
<td id="S5.T5.1.18.18.1" class="ltx_td ltx_align_center ltx_border_t">Skywalker</td>
<td id="S5.T5.1.18.18.2" class="ltx_td ltx_align_center ltx_border_t">92.55</td>
<td id="S5.T5.1.18.18.3" class="ltx_td ltx_align_center ltx_border_t">95.15</td>
</tr>
<tr id="S5.T5.1.19.19" class="ltx_tr">
<td id="S5.T5.1.19.19.1" class="ltx_td ltx_align_center">MagicPai</td>
<td id="S5.T5.1.19.19.2" class="ltx_td ltx_align_center">90.88</td>
<td id="S5.T5.1.19.19.3" class="ltx_td ltx_align_center">94.03</td>
</tr>
<tr id="S5.T5.1.20.20" class="ltx_tr">
<td id="S5.T5.1.20.20.1" class="ltx_td ltx_align_center">endworld</td>
<td id="S5.T5.1.20.20.2" class="ltx_td ltx_align_center">82.35</td>
<td id="S5.T5.1.20.20.3" class="ltx_td ltx_align_center">88.16</td>
</tr>
<tr id="S5.T5.1.21.21" class="ltx_tr">
<td id="S5.T5.1.21.21.1" class="ltx_td ltx_align_center">Paima</td>
<td id="S5.T5.1.21.21.2" class="ltx_td ltx_align_center">81.96</td>
<td id="S5.T5.1.21.21.3" class="ltx_td ltx_align_center">88.85</td>
</tr>
<tr id="S5.T5.1.22.22" class="ltx_tr">
<td id="S5.T5.1.22.22.1" class="ltx_td ltx_align_center ltx_border_bb">ravikranc</td>
<td id="S5.T5.1.22.22.2" class="ltx_td ltx_align_center ltx_border_bb">57.90</td>
<td id="S5.T5.1.22.22.3" class="ltx_td ltx_align_center ltx_border_bb">71.99</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span> Task A Leaderboard</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Competition Results</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We present two leaderboards for each task<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We made the assumption that teams would not make any use of the test data, as is usually the case for algorithm evaluation, but we did not make this explicit ahead of time and some teams did not realize this was an issue. We decided to have two leaderboards to have a fair comparison for all teams.</span></span></span>. The official leaderboard is from participants who have given us detailed descriptions on their system and affirmed that they did not incorporate any information from the test set that changed their final model. This is a more accurate representation of system quality. The unverified leaderboard is composed of participants who either did not give enough detail or have affirmed that they incorporated some test data information in their final model. The participants did not have access to labels for test data but some teams altered their models upon examining the input data in the test set. Although we discouraged this approach, we present the results in hopes it can give some interesting information about how much improvement might be possible with having access to input test data.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">19 teams participated in Task A. Of the 14 teams on the official leaderboard, King001 obtained the highest score for task A for both the 2-way (88.74) and 3-way (84.48) F-scores. However, the top three participants have comparable scores. All teams except for the last two beat our best baseline in Table <a href="#S5.T3" title="Table 3 ‣ Task A ‣ 5 Experiments ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The unverified leaderboard includes 5 teams and contains higher scores thank in the official leaderboard. However, due to the reasons outlined above, we cannot say with certainty that the results are reproducible. The full leaderboard results for all participants are in Table <a href="#S5.T5" title="Table 5 ‣ Task B ‣ 5 Experiments ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Task B is a much harder task and fewer teams participated in this challenge. Of the 12 teams that participated, 8 are in the official leaderboard. The best score is 65.17 by BreakingBERT@IITK(65.17) which is noticeably lower than the F-scores in Task A. Similarly to Task A the results in the unverified leaderboard are considerably higher. The full leaderboard results for all participants are in
Table <a href="#S6.T6" title="Table 6 ‣ 6 Competition Results ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S6.T6" class="ltx_table">
<table id="S6.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T6.1.1.1" class="ltx_tr">
<th id="S6.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T6.1.1.1.1.1" class="ltx_text ltx_font_bold">Team</span></th>
<th id="S6.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T6.1.1.1.2.1" class="ltx_text ltx_font_bold">F-Score</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T6.1.2.1" class="ltx_tr">
<td id="S6.T6.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S6.T6.1.2.1.1.1" class="ltx_text ltx_font_bold">Official Leaderboard</span></td>
</tr>
<tr id="S6.T6.1.3.2" class="ltx_tr">
<td id="S6.T6.1.3.2.1" class="ltx_td ltx_align_center ltx_border_t">BreakingBERT@IITK</td>
<td id="S6.T6.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T6.1.3.2.2.1" class="ltx_text ltx_font_bold">65.17</span></td>
</tr>
<tr id="S6.T6.1.4.3" class="ltx_tr">
<td id="S6.T6.1.4.3.1" class="ltx_td ltx_align_center">Volta</td>
<td id="S6.T6.1.4.3.2" class="ltx_td ltx_align_center">62.95</td>
</tr>
<tr id="S6.T6.1.5.4" class="ltx_tr">
<td id="S6.T6.1.5.4.1" class="ltx_td ltx_align_center">King001</td>
<td id="S6.T6.1.5.4.2" class="ltx_td ltx_align_center">62.14</td>
</tr>
<tr id="S6.T6.1.6.5" class="ltx_tr">
<td id="S6.T6.1.6.5.1" class="ltx_td ltx_align_center">FishToucher</td>
<td id="S6.T6.1.6.5.2" class="ltx_td ltx_align_center">60.06</td>
</tr>
<tr id="S6.T6.1.7.6" class="ltx_tr">
<td id="S6.T6.1.7.6.1" class="ltx_td ltx_align_center">RyanStark</td>
<td id="S6.T6.1.7.6.2" class="ltx_td ltx_align_center">54.96</td>
</tr>
<tr id="S6.T6.1.8.7" class="ltx_tr">
<td id="S6.T6.1.8.7.1" class="ltx_td ltx_align_center">Sattiy</td>
<td id="S6.T6.1.8.7.2" class="ltx_td ltx_align_center">48.56</td>
</tr>
<tr id="S6.T6.1.9.8" class="ltx_tr">
<td id="S6.T6.1.9.8.1" class="ltx_td ltx_align_center">AttesTable</td>
<td id="S6.T6.1.9.8.2" class="ltx_td ltx_align_center">43.02</td>
</tr>
<tr id="S6.T6.1.10.9" class="ltx_tr">
<td id="S6.T6.1.10.9.1" class="ltx_td ltx_align_center">KaushikAcharya</td>
<td id="S6.T6.1.10.9.2" class="ltx_td ltx_align_center">33.81</td>
</tr>
<tr id="S6.T6.1.11.10" class="ltx_tr">
<td id="S6.T6.1.11.10.1" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S6.T6.1.11.10.1.1" class="ltx_text ltx_font_bold">Unverified Leaderboard</span></td>
</tr>
<tr id="S6.T6.1.12.11" class="ltx_tr">
<td id="S6.T6.1.12.11.1" class="ltx_td ltx_align_center ltx_border_t">MagicPai</td>
<td id="S6.T6.1.12.11.2" class="ltx_td ltx_align_center ltx_border_t">88.74</td>
</tr>
<tr id="S6.T6.1.13.12" class="ltx_tr">
<td id="S6.T6.1.13.12.1" class="ltx_td ltx_align_center">SkyWalker</td>
<td id="S6.T6.1.13.12.2" class="ltx_td ltx_align_center">73.05</td>
</tr>
<tr id="S6.T6.1.14.13" class="ltx_tr">
<td id="S6.T6.1.14.13.1" class="ltx_td ltx_align_center">endworld</td>
<td id="S6.T6.1.14.13.2" class="ltx_td ltx_align_center">57.85</td>
</tr>
<tr id="S6.T6.1.15.14" class="ltx_tr">
<td id="S6.T6.1.15.14.1" class="ltx_td ltx_align_center ltx_border_bb">Paima</td>
<td id="S6.T6.1.15.14.2" class="ltx_td ltx_align_center ltx_border_bb">51.97</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span> Task B Leaderboard</figcaption>
</figure>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">We summarize the system details for all participating teams in Tables <a href="#S6.T7" title="Table 7 ‣ 6 Competition Results ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (Task A) and <a href="#S6.T8" title="Table 8 ‣ 6 Competition Results ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> (Task B). In general, deep learning was the most popular approach used by the participants e.g. BiLSTM with attention, BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> etc. Most of the participants used transformer-based models to train their systems with flavors ranging from general-domain BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> to table-understanding specific versions like TAPAS <cite class="ltx_cite ltx_citemacro_cite">Herzig et al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite>, TaBERT <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite> and Table-BERT <cite class="ltx_cite ltx_citemacro_cite">Wenhu Chen and Wang (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>. One third of the participants employed some form of ensembling technique in their submission.</p>
</div>
<figure id="S6.T7" class="ltx_table">
<table id="S6.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T7.1.1.1" class="ltx_tr">
<th id="S6.T7.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T7.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Team</span></span>
</span>
</th>
<th id="S6.T7.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.1.1.2.1.1" class="ltx_p" style="width:378.4pt;"><span id="S6.T7.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Description</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T7.1.2.1" class="ltx_tr">
<td id="S6.T7.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.2.1.1.1.1" class="ltx_p" style="width:85.4pt;">AttesTable <cite class="ltx_cite ltx_citemacro_cite">Varma et al. (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S6.T7.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.2.1.2.1.1" class="ltx_p" style="width:378.4pt;">Extended TAPAS to 3 classes by fine-tuning it. Employed a novel way of synthesizing “unknown” samples.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.3.2" class="ltx_tr">
<td id="S6.T7.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.3.2.1.1.1" class="ltx_p" style="width:85.4pt;">BreakingBERT@IITK <cite class="ltx_cite ltx_citemacro_cite">Jindal et al. (<a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S6.T7.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.3.2.2.1.1" class="ltx_p" style="width:378.4pt;">Ensemble models with TAPAS and TableBERT Transformers in a hierarchical two-step method for 3-way classification (unknown vs not unknown first)</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.4.3" class="ltx_tr">
<td id="S6.T7.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.4.3.1.1.1" class="ltx_p" style="width:85.4pt;">Beary-group</span>
</span>
</td>
<td id="S6.T7.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.4.3.2.1.1" class="ltx_p" style="width:378.4pt;">Used TAPAS model with TabFact task, and added unique features. Employed prepossessing tricks like k-fold validation and replacing the characters and did hyperparameter tuning.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.5.4" class="ltx_tr">
<td id="S6.T7.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.5.4.1.1.1" class="ltx_p" style="width:85.4pt;">BOUN <cite class="ltx_cite ltx_citemacro_cite">Köksal et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>*</span>
</span>
</td>
<td id="S6.T7.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.5.4.2.1.1" class="ltx_p" style="width:378.4pt;">Used text augmentation techniques such as back translation and synonym swapping on the TAPAS model. Domain adaptation and joint learning using SemTabFacts and TabFact datasets.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.6.5" class="ltx_tr">
<td id="S6.T7.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.6.5.1.1.1" class="ltx_p" style="width:85.4pt;">endworld</span>
</span>
</td>
<td id="S6.T7.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.6.5.2.1.1" class="ltx_p" style="width:378.4pt;">Data Cleaning. Ensemble combining 80 instances of trained TaPas-Large and label smoothing.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.7.6" class="ltx_tr">
<td id="S6.T7.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.7.6.1.1.1" class="ltx_p" style="width:85.4pt;">FishToucher</span>
</span>
</td>
<td id="S6.T7.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.7.6.2.1.1" class="ltx_p" style="width:378.4pt;">Motivated by TaPas, used BERT and enriched the embedding layer with two new token type embeddings: row and column ids*
(*The team mistakenly submitted an old model version, see paper for more accurate scores)</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.8.7" class="ltx_tr">
<td id="S6.T7.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.8.7.1.1.1" class="ltx_p" style="width:85.4pt;">Kaushik Acharya <cite class="ltx_cite ltx_citemacro_cite">Acharya (<a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S6.T7.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.8.7.2.1.1" class="ltx_p" style="width:378.4pt;">Parsed statements into candidate logical form; mapped result to handwritten rules, to then execute over relevant cells (identified using string matching and universal dependency parsing)</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.9.8" class="ltx_tr">
<td id="S6.T7.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.9.8.1.1.1" class="ltx_p" style="width:85.4pt;">King001</span>
</span>
</td>
<td id="S6.T7.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.9.8.2.1.1" class="ltx_p" style="width:378.4pt;">Trained 20 instances of TaPas, SAT and Table-Bert for an ensemble of 60 models. Used preprocessing like acronym completion, rules to align the table content with the question content, label smoothing.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.10.9" class="ltx_tr">
<td id="S6.T7.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.10.9.1.1.1" class="ltx_p" style="width:85.4pt;">MagicPai</span>
</span>
</td>
<td id="S6.T7.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.10.9.2.1.1" class="ltx_p" style="width:378.4pt;">Multi-model training using models such as TaBERT, tapas_wikisql, tapas_TabFact, tapas_masklm. Finally rule amendments and aligning the distribution of training and test data</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.11.10" class="ltx_tr">
<td id="S6.T7.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.11.10.1.1.1" class="ltx_p" style="width:85.4pt;">ok-team</span>
</span>
</td>
<td id="S6.T7.1.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.11.10.2.1.1" class="ltx_p" style="width:378.4pt;">TAPAS pretrained on TabFact with preprocessing of data (like transforming English numerals to Arabic numerals, removing special characters etc.)</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.12.11" class="ltx_tr">
<td id="S6.T7.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.12.11.1.1.1" class="ltx_p" style="width:85.4pt;">Paima</span>
</span>
</td>
<td id="S6.T7.1.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.12.11.2.1.1" class="ltx_p" style="width:378.4pt;">Fine-tuned TAPAS optimized to perform window scanning on statement-related table data. Pre-processing to reduce abbreviations for table headers, and identifying operation expressions.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.13.12" class="ltx_tr">
<td id="S6.T7.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.13.12.1.1.1" class="ltx_p" style="width:85.4pt;">RyanStark</span>
</span>
</td>
<td id="S6.T7.1.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.13.12.2.1.1" class="ltx_p" style="width:378.4pt;">Multi-model TaBERT pretrained Model fusion. Pre-processing such as case and abbreviations.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.14.13" class="ltx_tr">
<td id="S6.T7.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.14.13.1.1.1" class="ltx_p" style="width:85.4pt;">Sattiy <cite class="ltx_cite ltx_citemacro_cite">Ruan et al. (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S6.T7.1.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.14.13.2.1.1" class="ltx_p" style="width:378.4pt;">Ensemble of 6 fine-tuned pre-trained models on the augmented data with content snap-shot input. Augmented the data provided by expanding the labels. Used Fast Gradient Method and added disturbance to the embedding layer to obtain a more stable word representation and a more general model.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.15.14" class="ltx_tr">
<td id="S6.T7.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.15.14.1.1.1" class="ltx_p" style="width:85.4pt;">SkyWalker</span>
</span>
</td>
<td id="S6.T7.1.15.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.15.14.2.1.1" class="ltx_p" style="width:378.4pt;">Deep learning, LPA rules, TAPAS dataset</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.16.15" class="ltx_tr">
<td id="S6.T7.1.16.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.16.15.1.1.1" class="ltx_p" style="width:85.4pt;">SUNLP</span>
</span>
</td>
<td id="S6.T7.1.16.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.16.15.2.1.1" class="ltx_p" style="width:378.4pt;">BERT for sequence classification, transfer learning</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.17.16" class="ltx_tr">
<td id="S6.T7.1.17.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.17.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.17.16.1.1.1" class="ltx_p" style="width:85.4pt;">TAPAS <cite class="ltx_cite ltx_citemacro_cite">Müller et al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S6.T7.1.17.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.17.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.17.16.2.1.1" class="ltx_p" style="width:378.4pt;">Ensemble of TAPAS (BERT-large-like) models: trained with a Mask-LM task on Wikipedia tables, intermediate pre-training data and TabFact data. Hierarchical two-step method for 3-way classification. Added neutral statements during training: random and by removing one of the evidence columns.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.18.17" class="ltx_tr">
<td id="S6.T7.1.18.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.18.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.18.17.1.1.1" class="ltx_p" style="width:85.4pt;">THiFly_Queen <cite class="ltx_cite ltx_citemacro_cite">Yuxuan et al. (<a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S6.T7.1.18.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.18.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.18.17.2.1.1" class="ltx_p" style="width:378.4pt;">Ensemble models in a hierarchical two-step method. 8-model to identify unknown statements and 9-model ensemble to classify entailed/refuted. Incorporated different ensemble weights for various statement types (count, superlative, unique).</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.19.18" class="ltx_tr">
<td id="S6.T7.1.19.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.19.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.19.18.1.1.1" class="ltx_p" style="width:85.4pt;">Volta <cite class="ltx_cite ltx_citemacro_cite">Gautam et al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S6.T7.1.19.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.19.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.19.18.2.1.1" class="ltx_p" style="width:378.4pt;">Finetuned TAPAS that was pretrained on TabFact. Pre-processing to standardize multiple header rows to a single header.</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.20.19" class="ltx_tr">
<td id="S6.T7.1.20.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.20.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.20.19.1.1.1" class="ltx_p" style="width:85.4pt;">Yaoxu</span>
</span>
</td>
<td id="S6.T7.1.20.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T7.1.20.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.20.19.2.1.1" class="ltx_p" style="width:378.4pt;">Added numeric and enumerate features to TAPAS and also statistic information (such as count) as a new row/column to the table.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Descriptions of systems from participants for Task A. *Note: Team BOUN did not participate in the official leaderboard.</figcaption>
</figure>
<figure id="S6.T8" class="ltx_table">
<table id="S6.T8.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T8.1.1.1" class="ltx_tr">
<th id="S6.T8.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.1.1.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S6.T8.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Team</span></span>
</span>
</th>
<th id="S6.T8.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.1.1.2.1.1" class="ltx_p" style="width:378.4pt;"><span id="S6.T8.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Description</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T8.1.2.1" class="ltx_tr">
<td id="S6.T8.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.2.1.1.1.1" class="ltx_p" style="width:56.9pt;">BreakingBERT @IITK</span>
</span>
</td>
<td id="S6.T8.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.2.1.2.1.1" class="ltx_p" style="width:378.4pt;">An ensemble of an individual cell-based NLI approach and a similarity approach with the cells and statement</span>
</span>
</td>
</tr>
<tr id="S6.T8.1.3.2" class="ltx_tr">
<td id="S6.T8.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.3.2.1.1.1" class="ltx_p" style="width:56.9pt;">FishToucher</span>
</span>
</td>
<td id="S6.T8.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.3.2.2.1.1" class="ltx_p" style="width:378.4pt;">BERT CLS tokens for statement and table cells are used to determine cell relationships to each other, and the statement (for relevant cells)</span>
</span>
</td>
</tr>
<tr id="S6.T8.1.4.3" class="ltx_tr">
<td id="S6.T8.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.4.3.1.1.1" class="ltx_p" style="width:56.9pt;">Kaushik Acharya</span>
</span>
</td>
<td id="S6.T8.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.4.3.2.1.1" class="ltx_p" style="width:378.4pt;">Relevant cells are output as part of Task A</span>
</span>
</td>
</tr>
<tr id="S6.T8.1.5.4" class="ltx_tr">
<td id="S6.T8.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.5.4.1.1.1" class="ltx_p" style="width:56.9pt;">RyanStark</span>
</span>
</td>
<td id="S6.T8.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.5.4.2.1.1" class="ltx_p" style="width:378.4pt;">BOW approach with rules applied based on word matches in header and data cells.</span>
</span>
</td>
</tr>
<tr id="S6.T8.1.6.5" class="ltx_tr">
<td id="S6.T8.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.6.5.1.1.1" class="ltx_p" style="width:56.9pt;">Volta</span>
</span>
</td>
<td id="S6.T8.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S6.T8.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T8.1.6.5.2.1.1" class="ltx_p" style="width:378.4pt;">Finetuned TAPAS for cell selection. Different models for entailed and refuted statements. Used transfer learning and header standardization.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Descriptions of systems from participants for Task B (when provided)</figcaption>
</figure>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">Most of the participants have used the manually generated ground-truth in the development of their systems, with only one team not finding it useful. Further, a large percentage of participants have used the auto-generated ground truth in their systems with three teams not finding it helpful in their evaluation.</p>
</div>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p">In terms of external resources, a majority of the participants used external table understanding resources in their systems. Further, most of the participants employed pre-processing techniques like acronym completion, removing special characters, etc… A substantial percentage of participants used techniques like incorporating word embeddings, entity resolution etc. Finally, a large number of participants used TabFact <cite class="ltx_cite ltx_citemacro_cite">Wenhu Chen and Wang (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> as an external dataset.</p>
</div>
<figure id="S6.T9" class="ltx_table">
<table id="S6.T9.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T9.1.1.1" class="ltx_tr">
<th id="S6.T9.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S6.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.2.1" class="ltx_text ltx_font_bold">Refuted</span></th>
<th id="S6.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.3.1" class="ltx_text ltx_font_bold">Entailed</span></th>
<th id="S6.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.4.1" class="ltx_text ltx_font_bold">Unknown</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T9.1.2.1" class="ltx_tr">
<th id="S6.T9.1.2.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t"><span id="S6.T9.1.2.1.1.1" class="ltx_text ltx_font_bold">Refuted</span></th>
<td id="S6.T9.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">164</td>
<td id="S6.T9.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">81</td>
<td id="S6.T9.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">3</td>
</tr>
<tr id="S6.T9.1.3.2" class="ltx_tr">
<th id="S6.T9.1.3.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t"><span id="S6.T9.1.3.2.1.1" class="ltx_text ltx_font_bold">Entailed</span></th>
<td id="S6.T9.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">46</td>
<td id="S6.T9.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">226</td>
<td id="S6.T9.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">2</td>
</tr>
<tr id="S6.T9.1.4.3" class="ltx_tr">
<th id="S6.T9.1.4.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S6.T9.1.4.3.1.1" class="ltx_text ltx_font_bold">Unknown</span></th>
<td id="S6.T9.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">16</td>
<td id="S6.T9.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">72</td>
<td id="S6.T9.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">43</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span> Task A average confusion matrix</figcaption>
</figure>
<div id="S6.p7" class="ltx_para">
<p id="S6.p7.2" class="ltx_p">We also conducted additional analyses on participant submissions on the official leaderboard. We show through the average confusion matrix for Task A in Table <a href="#S6.T9" title="Table 9 ‣ 6 Competition Results ‣ SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> that the Unknown label was the most difficult. In fact, there were more unknown statements incorrectly labelled as entailed than were correctly categorized. Naturally, the statements with the lowest accuracy (<math id="S6.p7.1.m1.1" class="ltx_Math" alttext="&lt;25\%" display="inline"><semantics id="S6.p7.1.m1.1a"><mrow id="S6.p7.1.m1.1.1" xref="S6.p7.1.m1.1.1.cmml"><mi id="S6.p7.1.m1.1.1.2" xref="S6.p7.1.m1.1.1.2.cmml"></mi><mo id="S6.p7.1.m1.1.1.1" xref="S6.p7.1.m1.1.1.1.cmml">&lt;</mo><mrow id="S6.p7.1.m1.1.1.3" xref="S6.p7.1.m1.1.1.3.cmml"><mn id="S6.p7.1.m1.1.1.3.2" xref="S6.p7.1.m1.1.1.3.2.cmml">25</mn><mo id="S6.p7.1.m1.1.1.3.1" xref="S6.p7.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.1.m1.1b"><apply id="S6.p7.1.m1.1.1.cmml" xref="S6.p7.1.m1.1.1"><lt id="S6.p7.1.m1.1.1.1.cmml" xref="S6.p7.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S6.p7.1.m1.1.1.2.cmml" xref="S6.p7.1.m1.1.1.2">absent</csymbol><apply id="S6.p7.1.m1.1.1.3.cmml" xref="S6.p7.1.m1.1.1.3"><csymbol cd="latexml" id="S6.p7.1.m1.1.1.3.1.cmml" xref="S6.p7.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S6.p7.1.m1.1.1.3.2.cmml" xref="S6.p7.1.m1.1.1.3.2">25</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.1.m1.1c">&lt;25\%</annotation></semantics></math>) consist of mainly unknown statements, especially those statements that have words overlapping with those in the table. Out of the entailed and refuted statements, ones that require numerical reasoning, like range, count or comparisons seemed to be most challenging. The statements with the highest accuracy (<math id="S6.p7.2.m2.1" class="ltx_Math" alttext="&gt;95\%" display="inline"><semantics id="S6.p7.2.m2.1a"><mrow id="S6.p7.2.m2.1.1" xref="S6.p7.2.m2.1.1.cmml"><mi id="S6.p7.2.m2.1.1.2" xref="S6.p7.2.m2.1.1.2.cmml"></mi><mo id="S6.p7.2.m2.1.1.1" xref="S6.p7.2.m2.1.1.1.cmml">&gt;</mo><mrow id="S6.p7.2.m2.1.1.3" xref="S6.p7.2.m2.1.1.3.cmml"><mn id="S6.p7.2.m2.1.1.3.2" xref="S6.p7.2.m2.1.1.3.2.cmml">95</mn><mo id="S6.p7.2.m2.1.1.3.1" xref="S6.p7.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.2.m2.1b"><apply id="S6.p7.2.m2.1.1.cmml" xref="S6.p7.2.m2.1.1"><gt id="S6.p7.2.m2.1.1.1.cmml" xref="S6.p7.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S6.p7.2.m2.1.1.2.cmml" xref="S6.p7.2.m2.1.1.2">absent</csymbol><apply id="S6.p7.2.m2.1.1.3.cmml" xref="S6.p7.2.m2.1.1.3"><csymbol cd="latexml" id="S6.p7.2.m2.1.1.3.1.cmml" xref="S6.p7.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S6.p7.2.m2.1.1.3.2.cmml" xref="S6.p7.2.m2.1.1.3.2">95</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.2.m2.1c">&gt;95\%</annotation></semantics></math>) generally had most words or numbers exactly overlapping with those in the table. In task B, out of the statements with less than 30% evidence F-score, 86% were ones with a refuted relationship. Conversely, the statements with greater than 70% F-score, 74% were ones with an entailed relationship. This shows that it is more difficult to find the most direct evidence to prove that a statement is refuted by a table than it is to show the positive evidence that a particular statement is supported by it. We believe this is an interesting line of research for future studies.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Works</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we presented the data and competition results for SEM-TAB-FACTS, Shared Task 9 of SemEval 2021. We created a large dataset via automated and crowdsourced fact verification as well as evidence finding for tables. Our 19 teams had a variety of techniques to tackle this unique but very relevant problem. The evidence finding scores are still quite low and have a large improvement potential. Additionally, the test set may be expanded in future versions of this task with a combination of manually generated, natural, and automated statements.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acharya (2021)</span>
<span class="ltx_bibblock">
Kaushik Acharya. 2021.

</span>
<span class="ltx_bibblock">Kaushikacharya at SemEval-2021 task 9: Candidate generation for
fact verification over tables.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th international workshop on semantic
evaluation (SemEval-2021)</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aylin Woodward and Gal (2020)</span>
<span class="ltx_bibblock">
Ruobing Su Aylin Woodward and Shayanne Gal. 2020.

</span>
<span class="ltx_bibblock">What to know about the coronavirus outbreak in 17 charts and maps.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Business Insider</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman et al. (2015)</span>
<span class="ltx_bibblock">
Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning.
2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D15-1075" title="" class="ltx_ref ltx_href">A large annotated
corpus for learning natural language inference</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing</em>, pages 632–642, Lisbon, Portugal. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cafarella et al. (2018)</span>
<span class="ltx_bibblock">
Michael Cafarella, Alon Halevy, Hongrae Lee, Jayant Madhavan, Cong Yu,
Daisy Zhe Wang, and Eugene Wu. 2018.

</span>
<span class="ltx_bibblock">Ten years of webtables.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB Endowment</em>, 11(12):2140–2149.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carney et al. (2020)</span>
<span class="ltx_bibblock">
Richard W Carney, Travers Barclay Child, and Xiang Li. 2020.

</span>
<span class="ltx_bibblock">Board connections and crisis performance: Family, state, and
political networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Journal of Corporate Finance</em>, 64:101630.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dagan et al. (2005)</span>
<span class="ltx_bibblock">
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1007/11736790_9" title="" class="ltx_ref ltx_href">The PASCAL recognising
textual entailment challenge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First International Conference on Machine
Learning Challenges: Evaluating Predictive Uncertainty Visual Object
Classification, and Recognizing Textual Entailment</em>, MLCW’05, page 177–190,
Berlin, Heidelberg. Springer-Verlag.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1423" title="" class="ltx_ref ltx_href">BERT: Pre-training of
deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">East et al. (2018)</span>
<span class="ltx_bibblock">
Katherine East, Sara C Hitchman, Ioannis Bakolis, Sarah Williams, Hazel
Cheeseman, Deborah Arnott, and Ann McNeill. 2018.

</span>
<span class="ltx_bibblock">The association between smoking and electronic cigarette use in a
cohort of young people.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Journal of Adolescent Health</em>, 62(5):539–547.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gautam et al. (2021)</span>
<span class="ltx_bibblock">
Devansh Gautam, Kshitij Gupta, and Manish Shrivastava. 2021.

</span>
<span class="ltx_bibblock">Volta at SemEval-2021 task 9: Statement verification and evidence
finding with tables using TAPAS and transfer learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th International Workshop on Semantic
Evaluation (SemEval-2021)</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2020)</span>
<span class="ltx_bibblock">
Vivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek Srikumar. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.210" title="" class="ltx_ref ltx_href">INFOTABS:
Inference on tables as semi-structured data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 2309–2324, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig et al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno,
and Julian Eisenschlos. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.398" title="" class="ltx_ref ltx_href">TaPas:
Weakly supervised table parsing via pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4320–4333, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffswell and Liu (2019)</span>
<span class="ltx_bibblock">
Jane Hoffswell and Zhicheng Liu. 2019.

</span>
<span class="ltx_bibblock">Interactive repair of tables extracted from pdf documents on mobile
devices.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">ACM Human Factors in Computing Systems (CHI)</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jindal et al. (2021)</span>
<span class="ltx_bibblock">
Aditya Jindal, Ankur Gupta, Jaya Srivastava, Preeti Menghwani, Vijit Malik,
Vishesh Kaushik, and Ashutosh Modi. 2021.

</span>
<span class="ltx_bibblock">Breakingbert@iitk at SemEval-2021 task 9: Statement verification
and evidence finding with tables.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th international workshop on semantic
evaluation (SemEval-2021)</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khot et al. (2018)</span>
<span class="ltx_bibblock">
Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17368" title="" class="ltx_ref ltx_href">Scitail: A
textual entailment dataset from science question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">AAAI Conference on Artificial Intelligence</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köksal et al. (2021)</span>
<span class="ltx_bibblock">
Abdullatif Köksal, Yusuf Yüksel, Bekir Yıldırım, and Arzucan
Özgür. 2021.

</span>
<span class="ltx_bibblock">BOUN at SemEval-2021 Task 9: Text Augmentation Techniques for Fact
Verification in Tabular Data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifteenth Workshop on Semantic
Evaluation</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang,
Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00276" title="" class="ltx_ref ltx_href">Natural questions: A
benchmark for question answering research</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:452–466.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mihaylova et al. (2019)</span>
<span class="ltx_bibblock">
Tsvetomila Mihaylova, Georgi Karadzhov, Pepa Atanasova, Ramy Baly, Mitra
Mohtarami, and Preslav Nakov. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/S19-2149" title="" class="ltx_ref ltx_href">SemEval-2019 task
8: Fact checking in community question answering forums</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 13th International Workshop on Semantic
Evaluation</em>, pages 860–869, Minneapolis, Minnesota, USA. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Müller et al. (2021)</span>
<span class="ltx_bibblock">
Thomas Müller, Julian Martin Eisenschlos, and Syrine Krichene. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2104.01099" title="" class="ltx_ref ltx_href">TAPAS at SemEval-2021
task 9: Reasoning over tables with intermediate pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifteenth Workshop on Semantic
Evaluation</em>. International Committee for Computational Linguistics.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat and Liang (2015)</span>
<span class="ltx_bibblock">
Panupong Pasupat and Percy Liang. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/P15-1142" title="" class="ltx_ref ltx_href">Compositional semantic
parsing on semi-structured tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th International Joint Conference on
Natural Language Processing (Volume 1: Long Papers)</em>, pages 1470–1480,
Beijing, China. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et al. (2016)</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D16-1264" title="" class="ltx_ref ltx_href">SQuAD: 100,000+
questions for machine comprehension of text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2383–2392, Austin, Texas. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruan et al. (2021)</span>
<span class="ltx_bibblock">
Xiaoyi Ruan, mei Jin, Jian Ma, Lianxin Jiang, Mo Yang, and Jianping Shen. 2021.

</span>
<span class="ltx_bibblock">Sattiy at SemEval-2021 task 9: Method for statement verification
and evidence finding with tables based on multi-model ensemble.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th international workshop on semantic
evaluation (SemEval-2021)</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2016)</span>
<span class="ltx_bibblock">
Huan Sun, Hao Ma, Xiaodong He, Wen-tau Yih, Yu Su, and Xifeng Yan. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/2872427.2883080" title="" class="ltx_ref ltx_href">Table cell search
for question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Conference on World
Wide Web</em>, WWW ’16, page 771–782, Republic and Canton of Geneva, CHE.
International World Wide Web Conferences Steering Committee.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Varma et al. (2021)</span>
<span class="ltx_bibblock">
Harshit Varma, Aadish Jain, Pratik Ratadiya, and Abhishek Rathi. 2021.

</span>
<span class="ltx_bibblock">Attestable at SemEval-2021 task 9: Extending statement
verification with tables for unknown class, and semantic evidence finding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th international workshop on semantic
evaluation (SemEval-2021)</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wenhu Chen and Wang (2020)</span>
<span class="ltx_bibblock">
Jianshu Chen Yunkai Zhang Hong Wang Shiyang Li Xiyou Zhou Wenhu Chen,
Hongmin Wang and William Yang Wang. 2020.

</span>
<span class="ltx_bibblock">Tabfact : A large-scale dataset for table-based fact verification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>, Addis Ababa, Ethiopia.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams et al. (2018)</span>
<span class="ltx_bibblock">
Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N18-1101" title="" class="ltx_ref ltx_href">A broad-coverage
challenge corpus for sentence understanding through inference</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 1112–1122, New Orleans,
Louisiana. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.745" title="" class="ltx_ref ltx_href">TaBERT:
Pretraining for joint understanding of textual and tabular data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 8413–8426, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuxuan et al. (2021)</span>
<span class="ltx_bibblock">
Zhou Yuxuan, Zhou Kaiyin, Liu Xien, Wu Ji, and Zhu Xiaodan. 2021.

</span>
<span class="ltx_bibblock">Thifly_queen at SemEval-2021 task 9: Statement verification and
evidence finding with tables.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th international workshop on semantic
evaluation (SemEval-2021)</em>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2105.13994" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2105.13995" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2105.13995">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2105.13995" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2105.13996" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 08:02:45 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
