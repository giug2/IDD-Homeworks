<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.17430] LEFL: Low Entropy Client Sampling in Federated Learning</title><meta property="og:description" content="Federated learning (FL) is a machine learning paradigm where multiple clients collaborate to optimize a single global model using their private data. The global model is maintained by a central server that orchestrates…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LEFL: Low Entropy Client Sampling in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="LEFL: Low Entropy Client Sampling in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.17430">

<!--Generated on Tue Feb 27 11:01:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Sampling,  Communication Efficiency,  Performance
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">LEFL: Low Entropy Client Sampling in Federated Learning 
<br class="ltx_break">
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Waqwoya Abebe
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_font_italic">Computer Science</span>
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_italic">Iowa State University
<br class="ltx_break"></span>Ames, IA 
<br class="ltx_break">wmabebe@iastate.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pablo Munoz
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_font_italic">Intel Labs</span>
<br class="ltx_break"><span id="id4.2.id2" class="ltx_text ltx_font_italic">Intel Corporation
<br class="ltx_break"></span>Santa Clara, CA 
<br class="ltx_break">pablo.munoz@intel.com
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ali Jannesari
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_font_italic">Computer Science</span>
<br class="ltx_break"><span id="id6.2.id2" class="ltx_text ltx_font_italic">Iowa State University
<br class="ltx_break"></span>Ames, IA 
<br class="ltx_break">jannesar@iastate.edu
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">Federated learning (FL) is a machine learning paradigm where multiple clients collaborate to optimize a single global model using their private data. The global model is maintained by a central server that orchestrates the FL training process through a series of training rounds. In each round, the server samples clients from a client pool before sending them its latest global model parameters for further optimization. Naive sampling strategies implement random client sampling and fail to factor client data distributions for privacy reasons. Hence we propose LEFL <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Github: <a target="_blank" href="https://github.com/wmabebe/lefl" title="" class="ltx_ref ltx_href"> <span id="footnote1.1.1" class="ltx_text ltx_font_bold">L</span>ow <span id="footnote1.2.2" class="ltx_text ltx_font_bold">E</span>ntropy Client Sampling in <span id="footnote1.3.3" class="ltx_text ltx_font_bold">F</span>ederated <span id="footnote1.4.4" class="ltx_text ltx_font_bold">L</span>earning</a></span></span></span>, an alternative sampling strategy by performing a one-time clustering of clients based on their model’s learned high-level features while respecting data privacy. This enables the server to perform stratified client sampling across clusters in every round. We show datasets of sampled clients selected with this approach yield a low relative entropy with respect to the global data distribution. Consequently, the FL training becomes less noisy and significantly improves the convergence of the global model by as much as 7.4% in some experiments. Furthermore, it also significantly reduces the communication rounds required to achieve a target accuracy.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Sampling, Communication Efficiency, Performance

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> is a machine learning technique used to train machine learning models on decentralized client data. The goal of FL is to train a single global model on collective client data while maintaining client data privacy. FL is organized and orchestrated by a central server that is responsible for managing the global model. The global model is trained in a series of rounds whereby in each round, a sample of clients download the global model parameters, optimize them locally with their private data and upload them back to the server. The server, on its part, aggregates the uploaded model parameters to update the global model for the next round. This iterative process helps maintain client privacy since only parameters/gradients are communicated with the server.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite the overall simplicity of the training process, FL poses several challenges such as data and system heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, which can degrade the global model’s performance. Additionally, communication overhead <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> also poses a major challenge considering the bandwidth limitations of participating client edge devices. Data heterogeneity refers to the imbalance of features, label distribution and/or sample quantities across client datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Such imbalance causes gradient drift <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> between local updates and server updates (which occurs after aggregation). Gradient drift can arise from client model’s overfitting local biased data, bias in aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and covariate shift <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. In turn, gradient drift introduces noise in the global model’s training process and negatively impacts its overall performance.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In every round, the FL server samples a subset of clients that will optimize the global model. Uniform sampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> is a common client sampling technique, but it fails to account for client heterogeneity. In particular, due to client data privacy, the server is unable to sample clients in a representative manner where the collective dataset of the sampled clients resembles the global data distribution. As a result, sampled clients often contain biased data and inevitably upload biased gradients exacerbating gradient drift. Although some works introduce stratified sampling, importance sampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and adaptive sampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, they mostly focus on system heterogeneity or client data size variations. Hence, they fail to address variability in client data distributions (data heterogeneity). This begs the question, can we implement representative client sampling to address data heterogeneity without infringing on client data privacy?</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose a pre-processing step to cluster FL clients based on the similarity of their models latent layers. We sandwich this clustering step between the first and second training rounds. Initially, all FL clients download a small unlabeled public dataset from a different distribution. After conducting a single FL training round on their private dataset, clients use their models to predict the soft-labels of the public dataset. All soft-labels are then uploaded to the server to construct a similarity matrix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> which is used to classify the clients in an unsupervised manner. We demonstrate how this clustering approach groups together models that have learned similar high-level features. Clustering enables the server to conduct stratified client sampling across the clusters such that the sampled clients data yields low relative entropy with respect to the global data distribution. Consequently, the FL training process becomes less noisy, thus improving the global model’s performance. In summary:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a client clustering approach based on the models high-level learned features.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We provide empirical evidence to justify how this scheme allows sampling clients with low relative entropy with respect to the global data distribution.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We demonstrate the effectiveness of low entropy client sampling in various FL experiments in terms of global model accuracy, communication efficiency, and convergence speed.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The remainder of the paper is structured as follows: We present federated learning and aggregation techniques in the Related Works section. The Methodology section describes our proposed client clustering technique, including the clustering algorithm. The Evaluation section presents the experimental setup and empirical evidence to justify the proposed approach. Moreover, we evaluate the proposed technique with various datasets and models against strong baselines. Finally, we summarize our main contributions in the Conclusion.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Works</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In recent years, several schemes have been proposed to address data heterogeneity in FL. These include, modifying the aggregation, clustering clients, varying model architectures and utilizing knowledge distillation or other techniques. Below, we discuss some aggregation techniques and sampling schemes.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Aggregation Techniques</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">One way to tackle data heterogeneity in FL, is to tweak the aggregation method. The first FL work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> proposed FedAvg, a direct averaging of client parameters. Later, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, proposed adding a proximal term, <math id="S2.SS1.p1.1.m1.3" class="ltx_Math" alttext="\frac{\mu}{2}||x_{i}-x^{(t,0)}||^{2}" display="inline"><semantics id="S2.SS1.p1.1.m1.3a"><mrow id="S2.SS1.p1.1.m1.3.3" xref="S2.SS1.p1.1.m1.3.3.cmml"><mfrac id="S2.SS1.p1.1.m1.3.3.3" xref="S2.SS1.p1.1.m1.3.3.3.cmml"><mi id="S2.SS1.p1.1.m1.3.3.3.2" xref="S2.SS1.p1.1.m1.3.3.3.2.cmml">μ</mi><mn id="S2.SS1.p1.1.m1.3.3.3.3" xref="S2.SS1.p1.1.m1.3.3.3.3.cmml">2</mn></mfrac><mo lspace="0em" rspace="0em" id="S2.SS1.p1.1.m1.3.3.2" xref="S2.SS1.p1.1.m1.3.3.2.cmml">​</mo><msup id="S2.SS1.p1.1.m1.3.3.1" xref="S2.SS1.p1.1.m1.3.3.1.cmml"><mrow id="S2.SS1.p1.1.m1.3.3.1.1.1" xref="S2.SS1.p1.1.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.1.m1.3.3.1.1.1.2" xref="S2.SS1.p1.1.m1.3.3.1.1.2.1.cmml">‖</mo><mrow id="S2.SS1.p1.1.m1.3.3.1.1.1.1" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.cmml"><msub id="S2.SS1.p1.1.m1.3.3.1.1.1.1.2" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.cmml"><mi id="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.2" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.2.cmml">x</mi><mi id="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.3" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS1.p1.1.m1.3.3.1.1.1.1.1" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.1.cmml">−</mo><msup id="S2.SS1.p1.1.m1.3.3.1.1.1.1.3" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.3.cmml"><mi id="S2.SS1.p1.1.m1.3.3.1.1.1.1.3.2" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.3.2.cmml">x</mi><mrow id="S2.SS1.p1.1.m1.2.2.2.4" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p1.1.m1.2.2.2.4.1" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">(</mo><mi id="S2.SS1.p1.1.m1.1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p1.1.m1.2.2.2.4.2" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">,</mo><mn id="S2.SS1.p1.1.m1.2.2.2.2" xref="S2.SS1.p1.1.m1.2.2.2.2.cmml">0</mn><mo stretchy="false" id="S2.SS1.p1.1.m1.2.2.2.4.3" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">)</mo></mrow></msup></mrow><mo stretchy="false" id="S2.SS1.p1.1.m1.3.3.1.1.1.3" xref="S2.SS1.p1.1.m1.3.3.1.1.2.1.cmml">‖</mo></mrow><mn id="S2.SS1.p1.1.m1.3.3.1.3" xref="S2.SS1.p1.1.m1.3.3.1.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.3b"><apply id="S2.SS1.p1.1.m1.3.3.cmml" xref="S2.SS1.p1.1.m1.3.3"><times id="S2.SS1.p1.1.m1.3.3.2.cmml" xref="S2.SS1.p1.1.m1.3.3.2"></times><apply id="S2.SS1.p1.1.m1.3.3.3.cmml" xref="S2.SS1.p1.1.m1.3.3.3"><divide id="S2.SS1.p1.1.m1.3.3.3.1.cmml" xref="S2.SS1.p1.1.m1.3.3.3"></divide><ci id="S2.SS1.p1.1.m1.3.3.3.2.cmml" xref="S2.SS1.p1.1.m1.3.3.3.2">𝜇</ci><cn type="integer" id="S2.SS1.p1.1.m1.3.3.3.3.cmml" xref="S2.SS1.p1.1.m1.3.3.3.3">2</cn></apply><apply id="S2.SS1.p1.1.m1.3.3.1.cmml" xref="S2.SS1.p1.1.m1.3.3.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.3.3.1.2.cmml" xref="S2.SS1.p1.1.m1.3.3.1">superscript</csymbol><apply id="S2.SS1.p1.1.m1.3.3.1.1.2.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1"><csymbol cd="latexml" id="S2.SS1.p1.1.m1.3.3.1.1.2.1.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.2">norm</csymbol><apply id="S2.SS1.p1.1.m1.3.3.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1"><minus id="S2.SS1.p1.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.1"></minus><apply id="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.2">subscript</csymbol><ci id="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.2">𝑥</ci><ci id="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.3.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.SS1.p1.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.3.3.1.1.1.1.3.1.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.3">superscript</csymbol><ci id="S2.SS1.p1.1.m1.3.3.1.1.1.1.3.2.cmml" xref="S2.SS1.p1.1.m1.3.3.1.1.1.1.3.2">𝑥</ci><interval closure="open" id="S2.SS1.p1.1.m1.2.2.2.3.cmml" xref="S2.SS1.p1.1.m1.2.2.2.4"><ci id="S2.SS1.p1.1.m1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1">𝑡</ci><cn type="integer" id="S2.SS1.p1.1.m1.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2">0</cn></interval></apply></apply></apply><cn type="integer" id="S2.SS1.p1.1.m1.3.3.1.3.cmml" xref="S2.SS1.p1.1.m1.3.3.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.3c">\frac{\mu}{2}||x_{i}-x^{(t,0)}||^{2}</annotation></semantics></math>, to the client’s local cost function. This extra term helps narrow the gap between the local and global gradients. SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, proposes maintaining control variates on both the server and clients which can be used to control local gradient drift. FedNova <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, proposes a global learning rate adaptation coefficient based on the gradient variance of the aggregated model. Each client then adjusts its learning rate according to the server updates.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Several knowledge distillation-based works have also been proposed to tackle the effect of data heterogeneity. To address the issue of communication overhead, one approach has focused on applying model compression techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. For instance in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, authors proposed reducing the communication overhead by only communicating the encoder component of the model. Furthermore, they implement a local reinforcement learning (RL) agent to filter salient parameters of the encoder for communication. Similarly, knowledge distillation methods have been proposed to help reduce communication overhead <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. These methods usually rely on communicating a smaller knowledge network that is optimized by clients locally.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Our proposed client sampling strategy is implemented over the basic FedAvg approach. However, it is quite simple to adapt it for any of the above aggregation schemes since the only additional step we are proposing is a pre-clustering of clients before full participation plus stratified sampling in each round.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Sampling Techniques</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The initial federated learning work (FedAvg) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, proposed sampling clients uniformly in each round. Despite the simplicity of this approach, it was later shown in SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> that random sampling is biased and can cause client gradient drift. To tackle this issue, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> proposed sampling clients from the multinomial distribution where clients are sampled proportional to the size of their dataset. These approach however, only factored in the dataset size of the participating clients.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, authors propose a sampling the first <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">m</annotation></semantics></math> client updates. This prioritizes powerful clients or clients with fewer samples. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, authors provide two algorithms for clustering clients before applying sampling. The first algorithm clusters clients based on local dataset size, while the latter clusters clients based on gradient similarity. They showed that such extra client cluster information is able to improve the sampling techniques. However, the extra gradient information is as large as the uploaded parameters. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> introduces data augmentation and an extra component called a mediator with knowledge of local class label distribution. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> propose selecting clients that exhibit larger loss. However, this approach does not guarantee optimal performance.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> implemented an estimation scheme to determine the label distribution among the participating clients. Afterwards, they implement a greedy algorithm to pick the set of clients on each round. However, this work expects the server to posses a balanced dataset which may not always be practical. More recently, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> proposed a heterogeneity-aware client sampling mechanism to address class imbalance. They propose a measure, “Quadratic Class-Imbalance Degree” (QCID), to determine the heterogeneity of sampled clients and implement a greedy algorithm to select client samples that minimize this value. Since QCID is computed based on the clients underlying data distribution. In this approach, clients will have to transmit their data distribution information via third party utilities such as fully homomorphic encryption (FHE), requiring a computationally costly service that might not be readily available to participating clients.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">While the naive uniform sampling strategy potentially suffers from gradient drift, the improved unbiased sampling strategies mostly only factor the proportion of samples owned by clients when factoring their sample ratio. Works like <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> that factor client data distribution require extra assumptions or expensive procedures to compute distribution similarities among clients. In our work, we propose clustering clients based on their models high-level learned features before applying stratified random sampling over the clusters. Moreover, once the clustering is complete, the sampling strategy can easily be augmented with unbiased sampling techniques proposed in prior work. Our experiments show that our proposed scheme significantly improves the performance of the global model compared to the state-of-the-art FL baselines.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methodology</span>
</h2>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2312.17430/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="230" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Server side computation after receiving soft-labels from clients (Algorithm <a href="#alg1" title="Algorithm 1 ‣ III Methodology ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The server will construct a similarity matrix and use it to cluster the clients. Afterwards, it will conduct stratified client sampling across clusters in each FL round. </figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The objective of FL is to optimize a single global model using decentralized client data. In each FL round, the global model’s parameters are sent to a selected subset of clients for local optimization. The sampled clients optimize their copy of the global model’s parameters using their local data for a predefined number of epochs before uploading them back to the server. The server, in turn, aggregates the uploaded parameters to update the next version of the global model as shown in (<a href="#S3.E1" title="In III Methodology ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.4" class="ltx_p">The baseline FedAvg algorithm proposes updating the global model parameters <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">w</annotation></semantics></math>, by aggregating the latest local parameters, <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="w^{t}_{i}" display="inline"><semantics id="S3.p2.2.m2.1a"><msubsup id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2.2" xref="S3.p2.2.m2.1.1.2.2.cmml">w</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">i</mi><mi id="S3.p2.2.m2.1.1.2.3" xref="S3.p2.2.m2.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><apply id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.2.1.cmml" xref="S3.p2.2.m2.1.1">superscript</csymbol><ci id="S3.p2.2.m2.1.1.2.2.cmml" xref="S3.p2.2.m2.1.1.2.2">𝑤</ci><ci id="S3.p2.2.m2.1.1.2.3.cmml" xref="S3.p2.2.m2.1.1.2.3">𝑡</ci></apply><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">w^{t}_{i}</annotation></semantics></math>, uploaded by a client <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="C^{i}" display="inline"><semantics id="S3.p2.3.m3.1a"><msup id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml"><mi id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml">C</mi><mi id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1">superscript</csymbol><ci id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2">𝐶</ci><ci id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">C^{i}</annotation></semantics></math> in the current round <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p2.4.m4.1a"><mi id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><ci id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">t</annotation></semantics></math>:</p>
</div>
<div id="S3.p3" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="w^{t+1}=\sum_{i\in s}\frac{|D_{i}|}{|D|}w^{t}_{i}" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.3" xref="S3.E1.m1.2.3.cmml"><msup id="S3.E1.m1.2.3.2" xref="S3.E1.m1.2.3.2.cmml"><mi id="S3.E1.m1.2.3.2.2" xref="S3.E1.m1.2.3.2.2.cmml">w</mi><mrow id="S3.E1.m1.2.3.2.3" xref="S3.E1.m1.2.3.2.3.cmml"><mi id="S3.E1.m1.2.3.2.3.2" xref="S3.E1.m1.2.3.2.3.2.cmml">t</mi><mo id="S3.E1.m1.2.3.2.3.1" xref="S3.E1.m1.2.3.2.3.1.cmml">+</mo><mn id="S3.E1.m1.2.3.2.3.3" xref="S3.E1.m1.2.3.2.3.3.cmml">1</mn></mrow></msup><mo rspace="0.111em" id="S3.E1.m1.2.3.1" xref="S3.E1.m1.2.3.1.cmml">=</mo><mrow id="S3.E1.m1.2.3.3" xref="S3.E1.m1.2.3.3.cmml"><munder id="S3.E1.m1.2.3.3.1" xref="S3.E1.m1.2.3.3.1.cmml"><mo movablelimits="false" id="S3.E1.m1.2.3.3.1.2" xref="S3.E1.m1.2.3.3.1.2.cmml">∑</mo><mrow id="S3.E1.m1.2.3.3.1.3" xref="S3.E1.m1.2.3.3.1.3.cmml"><mi id="S3.E1.m1.2.3.3.1.3.2" xref="S3.E1.m1.2.3.3.1.3.2.cmml">i</mi><mo id="S3.E1.m1.2.3.3.1.3.1" xref="S3.E1.m1.2.3.3.1.3.1.cmml">∈</mo><mi id="S3.E1.m1.2.3.3.1.3.3" xref="S3.E1.m1.2.3.3.1.3.3.cmml">s</mi></mrow></munder><mrow id="S3.E1.m1.2.3.3.2" xref="S3.E1.m1.2.3.3.2.cmml"><mfrac id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo><msub id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">D</mi><mi id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.2.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.3.1" xref="S3.E1.m1.2.2.2.2.1.cmml">|</mo><mi id="S3.E1.m1.2.2.2.1" xref="S3.E1.m1.2.2.2.1.cmml">D</mi><mo stretchy="false" id="S3.E1.m1.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.3.2.1" xref="S3.E1.m1.2.3.3.2.1.cmml">​</mo><msubsup id="S3.E1.m1.2.3.3.2.2" xref="S3.E1.m1.2.3.3.2.2.cmml"><mi id="S3.E1.m1.2.3.3.2.2.2.2" xref="S3.E1.m1.2.3.3.2.2.2.2.cmml">w</mi><mi id="S3.E1.m1.2.3.3.2.2.3" xref="S3.E1.m1.2.3.3.2.2.3.cmml">i</mi><mi id="S3.E1.m1.2.3.3.2.2.2.3" xref="S3.E1.m1.2.3.3.2.2.2.3.cmml">t</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.3.cmml" xref="S3.E1.m1.2.3"><eq id="S3.E1.m1.2.3.1.cmml" xref="S3.E1.m1.2.3.1"></eq><apply id="S3.E1.m1.2.3.2.cmml" xref="S3.E1.m1.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.2.1.cmml" xref="S3.E1.m1.2.3.2">superscript</csymbol><ci id="S3.E1.m1.2.3.2.2.cmml" xref="S3.E1.m1.2.3.2.2">𝑤</ci><apply id="S3.E1.m1.2.3.2.3.cmml" xref="S3.E1.m1.2.3.2.3"><plus id="S3.E1.m1.2.3.2.3.1.cmml" xref="S3.E1.m1.2.3.2.3.1"></plus><ci id="S3.E1.m1.2.3.2.3.2.cmml" xref="S3.E1.m1.2.3.2.3.2">𝑡</ci><cn type="integer" id="S3.E1.m1.2.3.2.3.3.cmml" xref="S3.E1.m1.2.3.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.2.3.3.cmml" xref="S3.E1.m1.2.3.3"><apply id="S3.E1.m1.2.3.3.1.cmml" xref="S3.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.3.1.1.cmml" xref="S3.E1.m1.2.3.3.1">subscript</csymbol><sum id="S3.E1.m1.2.3.3.1.2.cmml" xref="S3.E1.m1.2.3.3.1.2"></sum><apply id="S3.E1.m1.2.3.3.1.3.cmml" xref="S3.E1.m1.2.3.3.1.3"><in id="S3.E1.m1.2.3.3.1.3.1.cmml" xref="S3.E1.m1.2.3.3.1.3.1"></in><ci id="S3.E1.m1.2.3.3.1.3.2.cmml" xref="S3.E1.m1.2.3.3.1.3.2">𝑖</ci><ci id="S3.E1.m1.2.3.3.1.3.3.cmml" xref="S3.E1.m1.2.3.3.1.3.3">𝑠</ci></apply></apply><apply id="S3.E1.m1.2.3.3.2.cmml" xref="S3.E1.m1.2.3.3.2"><times id="S3.E1.m1.2.3.3.2.1.cmml" xref="S3.E1.m1.2.3.3.2.1"></times><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><divide id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2"></divide><apply id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1"><abs id="S3.E1.m1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2"></abs><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2">𝐷</ci><ci id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.3"><abs id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.3.1"></abs><ci id="S3.E1.m1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.1">𝐷</ci></apply></apply><apply id="S3.E1.m1.2.3.3.2.2.cmml" xref="S3.E1.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.3.2.2.1.cmml" xref="S3.E1.m1.2.3.3.2.2">subscript</csymbol><apply id="S3.E1.m1.2.3.3.2.2.2.cmml" xref="S3.E1.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.3.2.2.2.1.cmml" xref="S3.E1.m1.2.3.3.2.2">superscript</csymbol><ci id="S3.E1.m1.2.3.3.2.2.2.2.cmml" xref="S3.E1.m1.2.3.3.2.2.2.2">𝑤</ci><ci id="S3.E1.m1.2.3.3.2.2.2.3.cmml" xref="S3.E1.m1.2.3.3.2.2.2.3">𝑡</ci></apply><ci id="S3.E1.m1.2.3.3.2.2.3.cmml" xref="S3.E1.m1.2.3.3.2.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">w^{t+1}=\sum_{i\in s}\frac{|D_{i}|}{|D|}w^{t}_{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.6" class="ltx_p">where <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="|D_{i}|" display="inline"><semantics id="S3.p4.1.m1.1a"><mrow id="S3.p4.1.m1.1.1.1" xref="S3.p4.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.p4.1.m1.1.1.1.2" xref="S3.p4.1.m1.1.1.2.1.cmml">|</mo><msub id="S3.p4.1.m1.1.1.1.1" xref="S3.p4.1.m1.1.1.1.1.cmml"><mi id="S3.p4.1.m1.1.1.1.1.2" xref="S3.p4.1.m1.1.1.1.1.2.cmml">D</mi><mi id="S3.p4.1.m1.1.1.1.1.3" xref="S3.p4.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.p4.1.m1.1.1.1.3" xref="S3.p4.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.1"><abs id="S3.p4.1.m1.1.1.2.1.cmml" xref="S3.p4.1.m1.1.1.1.2"></abs><apply id="S3.p4.1.m1.1.1.1.1.cmml" xref="S3.p4.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.1.1.cmml" xref="S3.p4.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.p4.1.m1.1.1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.1.1.2">𝐷</ci><ci id="S3.p4.1.m1.1.1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">|D_{i}|</annotation></semantics></math> is the size of the local dataset <math id="S3.p4.2.m2.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p4.2.m2.1a"><msub id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml"><mi id="S3.p4.2.m2.1.1.2" xref="S3.p4.2.m2.1.1.2.cmml">D</mi><mi id="S3.p4.2.m2.1.1.3" xref="S3.p4.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><apply id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p4.2.m2.1.1.1.cmml" xref="S3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.p4.2.m2.1.1.2.cmml" xref="S3.p4.2.m2.1.1.2">𝐷</ci><ci id="S3.p4.2.m2.1.1.3.cmml" xref="S3.p4.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">D_{i}</annotation></semantics></math>, <math id="S3.p4.3.m3.1" class="ltx_Math" alttext="|D|" display="inline"><semantics id="S3.p4.3.m3.1a"><mrow id="S3.p4.3.m3.1.2.2" xref="S3.p4.3.m3.1.2.1.cmml"><mo stretchy="false" id="S3.p4.3.m3.1.2.2.1" xref="S3.p4.3.m3.1.2.1.1.cmml">|</mo><mi id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml">D</mi><mo stretchy="false" id="S3.p4.3.m3.1.2.2.2" xref="S3.p4.3.m3.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><apply id="S3.p4.3.m3.1.2.1.cmml" xref="S3.p4.3.m3.1.2.2"><abs id="S3.p4.3.m3.1.2.1.1.cmml" xref="S3.p4.3.m3.1.2.2.1"></abs><ci id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">|D|</annotation></semantics></math> is the size of the global dataset <math id="S3.p4.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p4.4.m4.1a"><mi id="S3.p4.4.m4.1.1" xref="S3.p4.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.1b"><ci id="S3.p4.4.m4.1.1.cmml" xref="S3.p4.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.1c">D</annotation></semantics></math>, <math id="S3.p4.5.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.p4.5.m5.1a"><mi id="S3.p4.5.m5.1.1" xref="S3.p4.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.p4.5.m5.1b"><ci id="S3.p4.5.m5.1.1.cmml" xref="S3.p4.5.m5.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.5.m5.1c">s</annotation></semantics></math> is the set of sampled clients and <math id="S3.p4.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p4.6.m6.1a"><mi id="S3.p4.6.m6.1.1" xref="S3.p4.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p4.6.m6.1b"><ci id="S3.p4.6.m6.1.1.cmml" xref="S3.p4.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.6.m6.1c">t</annotation></semantics></math> is the FL communication round.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.2" class="ltx_p">In practice, FL clients are expected to possess non-iid (non-independent and identically distributed) data. Non-iid data can manifest as feature skew, label skew or both. In classification problems for instance, the label distributions of clients is expected to vary. Intuitively, such skews introduce noise into the training process, as variation in client data distribution causes client gradient drift. This can lead to slower convergence and degrade performance of the global model. In contrast, in the iid case where data is evenly distributed across all nodes, performing uniform client sampling will suffice for sampling clients that possess representative (iid) data. Here, we define a dataset <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="D_{s}" display="inline"><semantics id="S3.p5.1.m1.1a"><msub id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mi id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">D</mi><mi id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1">subscript</csymbol><ci id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1.2">𝐷</ci><ci id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">D_{s}</annotation></semantics></math> to be representative if it has a similar distribution to the global dataset <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p5.2.m2.1a"><mi id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><ci id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">D</annotation></semantics></math>, i.e., the distribution of the union of datasets belonging to the sampled clients is similar to the global data distribution. This helps the model converge faster and achieve better performance.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.2" class="ltx_p">In the label distribution skew case for instance, the similarity between datasets can be measured as the distance between the probability distribution of <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p6.1.m1.1a"><mi id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><ci id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">D</annotation></semantics></math> and <math id="S3.p6.2.m2.1" class="ltx_Math" alttext="D_{s}" display="inline"><semantics id="S3.p6.2.m2.1a"><msub id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml"><mi id="S3.p6.2.m2.1.1.2" xref="S3.p6.2.m2.1.1.2.cmml">D</mi><mi id="S3.p6.2.m2.1.1.3" xref="S3.p6.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.1b"><apply id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p6.2.m2.1.1.1.cmml" xref="S3.p6.2.m2.1.1">subscript</csymbol><ci id="S3.p6.2.m2.1.1.2.cmml" xref="S3.p6.2.m2.1.1.2">𝐷</ci><ci id="S3.p6.2.m2.1.1.3.cmml" xref="S3.p6.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">D_{s}</annotation></semantics></math>, e.g., using the Kullback–Leibler divergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> (<a href="#S3.E2" title="In III Methodology ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) or other statistical distance metric. Under such circumstance, selecting a subset of clients which contain a balanced number of labels in each round will help reduce aggregation noise. This is tantamount to selecting clients whose collective data is iid. In the non-iid case however, random sampling of clients is unlikely to yield such a representative subset of client data. Since the server is unaware of client data, it has no way of directly measuring the representativity of the datasets belonging to the clients it sampled.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p">With this insight, we want to implement a representative client sampling strategy that can select a subset of clients in each federated round where the selected clients posses representative underlying data. To circumvent server blindness, we propose using the model’s learned high-level features as an indication of underlying client dataset. <span id="S3.p7.1.1" class="ltx_text ltx_font_bold">In particular, we show that selecting clients that have learned a diverse set of high-level features is a good substitute for selecting clients based on their underlying data distribution itself.</span> In this section, we propose an affordable scheme for the server to indirectly infer the models learned high-level features without directly accessing clients data or requiring (all) clients to upload their models. While the former approach violates the clients data privacy, the latter becomes infeasible as the system scales. Afterwards, the server uses this information to cluster similar clients together and apply a stratified sampling across the clusters yielding sampled clients whose combined dataset has a low relative entropy with respect to the global data distribution.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Extra pre-processing steps</figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">  <span id="alg1.l1.1" class="ltx_text ltx_font_bold">Client side</span>

</div>
<div id="alg1.l2" class="ltx_listingline">   1. Download unlabeled public dataset (initial contact)

</div>
<div id="alg1.l3" class="ltx_listingline">   2. Train global model for <math id="alg1.l3.m1.1" class="ltx_Math" alttext="E_{p}" display="inline"><semantics id="alg1.l3.m1.1a"><msub id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mi id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml">E</mi><mi id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1">subscript</csymbol><ci id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2">𝐸</ci><ci id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">E_{p}</annotation></semantics></math> epochs on private data

</div>
<div id="alg1.l4" class="ltx_listingline">   3. Predict soft-labels of public data

</div>
<div id="alg1.l5" class="ltx_listingline">   4. Upload soft-labels

</div>
<div id="alg1.l6" class="ltx_listingline">  <span id="alg1.l6.1" class="ltx_text ltx_font_bold">Server side</span>

</div>
<div id="alg1.l7" class="ltx_listingline">   1. Construct similarity matrix

</div>
<div id="alg1.l8" class="ltx_listingline">   2. Cluster clients

</div>
<div id="alg1.l9" class="ltx_listingline">  <math id="alg1.l9.m1.1" class="ltx_Math" alttext="\circlearrowright" display="inline"><semantics id="alg1.l9.m1.1a"><mo id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml">↻</mo><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><ci id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1">↻</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">\circlearrowright</annotation></semantics></math> Perform stratified client sampling for all rounds

</div>
</div>
</figure>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.2" class="ltx_p">Prior to initializing the FL training, the server prepares a public dataset <math id="S3.p8.1.m1.1" class="ltx_Math" alttext="D_{p}" display="inline"><semantics id="S3.p8.1.m1.1a"><msub id="S3.p8.1.m1.1.1" xref="S3.p8.1.m1.1.1.cmml"><mi id="S3.p8.1.m1.1.1.2" xref="S3.p8.1.m1.1.1.2.cmml">D</mi><mi id="S3.p8.1.m1.1.1.3" xref="S3.p8.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p8.1.m1.1b"><apply id="S3.p8.1.m1.1.1.cmml" xref="S3.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p8.1.m1.1.1.1.cmml" xref="S3.p8.1.m1.1.1">subscript</csymbol><ci id="S3.p8.1.m1.1.1.2.cmml" xref="S3.p8.1.m1.1.1.2">𝐷</ci><ci id="S3.p8.1.m1.1.1.3.cmml" xref="S3.p8.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.1.m1.1c">D_{p}</annotation></semantics></math> with a limited number of samples. This dataset is shipped to the clients upon initial download of the global model. After receiving the global model and public data, clients train their copies of the global model for a limited number of epochs <math id="S3.p8.2.m2.1" class="ltx_Math" alttext="E_{p}" display="inline"><semantics id="S3.p8.2.m2.1a"><msub id="S3.p8.2.m2.1.1" xref="S3.p8.2.m2.1.1.cmml"><mi id="S3.p8.2.m2.1.1.2" xref="S3.p8.2.m2.1.1.2.cmml">E</mi><mi id="S3.p8.2.m2.1.1.3" xref="S3.p8.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p8.2.m2.1b"><apply id="S3.p8.2.m2.1.1.cmml" xref="S3.p8.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p8.2.m2.1.1.1.cmml" xref="S3.p8.2.m2.1.1">subscript</csymbol><ci id="S3.p8.2.m2.1.1.2.cmml" xref="S3.p8.2.m2.1.1.2">𝐸</ci><ci id="S3.p8.2.m2.1.1.3.cmml" xref="S3.p8.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.2.m2.1c">E_{p}</annotation></semantics></math> on their private data and use their trained model to predict the labels of the public dataset. Afterwards, clients will upload the soft-labels outputted on the public dataset back to the server. Having received the soft-labels, the server computes pairwise KL-divergence values between all pairs of soft-labels to create a similarity matrix as shown in Figure <a href="#S3.F1" title="Figure 1 ‣ III Methodology ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.6" class="ltx_p">Given a set of clients <math id="S3.p9.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.p9.1.m1.1a"><mi id="S3.p9.1.m1.1.1" xref="S3.p9.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.p9.1.m1.1b"><ci id="S3.p9.1.m1.1.1.cmml" xref="S3.p9.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.1.m1.1c">C</annotation></semantics></math> where <math id="S3.p9.2.m2.1" class="ltx_Math" alttext="|C|=n" display="inline"><semantics id="S3.p9.2.m2.1a"><mrow id="S3.p9.2.m2.1.2" xref="S3.p9.2.m2.1.2.cmml"><mrow id="S3.p9.2.m2.1.2.2.2" xref="S3.p9.2.m2.1.2.2.1.cmml"><mo stretchy="false" id="S3.p9.2.m2.1.2.2.2.1" xref="S3.p9.2.m2.1.2.2.1.1.cmml">|</mo><mi id="S3.p9.2.m2.1.1" xref="S3.p9.2.m2.1.1.cmml">C</mi><mo stretchy="false" id="S3.p9.2.m2.1.2.2.2.2" xref="S3.p9.2.m2.1.2.2.1.1.cmml">|</mo></mrow><mo id="S3.p9.2.m2.1.2.1" xref="S3.p9.2.m2.1.2.1.cmml">=</mo><mi id="S3.p9.2.m2.1.2.3" xref="S3.p9.2.m2.1.2.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.2.m2.1b"><apply id="S3.p9.2.m2.1.2.cmml" xref="S3.p9.2.m2.1.2"><eq id="S3.p9.2.m2.1.2.1.cmml" xref="S3.p9.2.m2.1.2.1"></eq><apply id="S3.p9.2.m2.1.2.2.1.cmml" xref="S3.p9.2.m2.1.2.2.2"><abs id="S3.p9.2.m2.1.2.2.1.1.cmml" xref="S3.p9.2.m2.1.2.2.2.1"></abs><ci id="S3.p9.2.m2.1.1.cmml" xref="S3.p9.2.m2.1.1">𝐶</ci></apply><ci id="S3.p9.2.m2.1.2.3.cmml" xref="S3.p9.2.m2.1.2.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.2.m2.1c">|C|=n</annotation></semantics></math>, the similarity matrix contains KL-divergence values <math id="S3.p9.3.m3.3" class="ltx_Math" alttext="\alpha^{i}_{j}\quad\forall\&gt;C^{i},C^{j}\in C" display="inline"><semantics id="S3.p9.3.m3.3a"><mrow id="S3.p9.3.m3.3.3" xref="S3.p9.3.m3.3.3.cmml"><mrow id="S3.p9.3.m3.3.3.3.3" xref="S3.p9.3.m3.3.3.3.4.cmml"><msubsup id="S3.p9.3.m3.1.1.1.1.1" xref="S3.p9.3.m3.1.1.1.1.1.cmml"><mi id="S3.p9.3.m3.1.1.1.1.1.2.2" xref="S3.p9.3.m3.1.1.1.1.1.2.2.cmml">α</mi><mi id="S3.p9.3.m3.1.1.1.1.1.3" xref="S3.p9.3.m3.1.1.1.1.1.3.cmml">j</mi><mi id="S3.p9.3.m3.1.1.1.1.1.2.3" xref="S3.p9.3.m3.1.1.1.1.1.2.3.cmml">i</mi></msubsup><mspace width="1.167em" id="S3.p9.3.m3.3.3.3.3.4" xref="S3.p9.3.m3.3.3.3.4.cmml"></mspace><mrow id="S3.p9.3.m3.2.2.2.2.2" xref="S3.p9.3.m3.2.2.2.2.2.cmml"><mo rspace="0.387em" id="S3.p9.3.m3.2.2.2.2.2.1" xref="S3.p9.3.m3.2.2.2.2.2.1.cmml">∀</mo><msup id="S3.p9.3.m3.2.2.2.2.2.2" xref="S3.p9.3.m3.2.2.2.2.2.2.cmml"><mi id="S3.p9.3.m3.2.2.2.2.2.2.2" xref="S3.p9.3.m3.2.2.2.2.2.2.2.cmml">C</mi><mi id="S3.p9.3.m3.2.2.2.2.2.2.3" xref="S3.p9.3.m3.2.2.2.2.2.2.3.cmml">i</mi></msup></mrow><mo id="S3.p9.3.m3.3.3.3.3.5" xref="S3.p9.3.m3.3.3.3.4.cmml">,</mo><msup id="S3.p9.3.m3.3.3.3.3.3" xref="S3.p9.3.m3.3.3.3.3.3.cmml"><mi id="S3.p9.3.m3.3.3.3.3.3.2" xref="S3.p9.3.m3.3.3.3.3.3.2.cmml">C</mi><mi id="S3.p9.3.m3.3.3.3.3.3.3" xref="S3.p9.3.m3.3.3.3.3.3.3.cmml">j</mi></msup></mrow><mo id="S3.p9.3.m3.3.3.4" xref="S3.p9.3.m3.3.3.4.cmml">∈</mo><mi id="S3.p9.3.m3.3.3.5" xref="S3.p9.3.m3.3.3.5.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.3.m3.3b"><apply id="S3.p9.3.m3.3.3.cmml" xref="S3.p9.3.m3.3.3"><in id="S3.p9.3.m3.3.3.4.cmml" xref="S3.p9.3.m3.3.3.4"></in><list id="S3.p9.3.m3.3.3.3.4.cmml" xref="S3.p9.3.m3.3.3.3.3"><apply id="S3.p9.3.m3.1.1.1.1.1.cmml" xref="S3.p9.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p9.3.m3.1.1.1.1.1.1.cmml" xref="S3.p9.3.m3.1.1.1.1.1">subscript</csymbol><apply id="S3.p9.3.m3.1.1.1.1.1.2.cmml" xref="S3.p9.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p9.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.p9.3.m3.1.1.1.1.1">superscript</csymbol><ci id="S3.p9.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.p9.3.m3.1.1.1.1.1.2.2">𝛼</ci><ci id="S3.p9.3.m3.1.1.1.1.1.2.3.cmml" xref="S3.p9.3.m3.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S3.p9.3.m3.1.1.1.1.1.3.cmml" xref="S3.p9.3.m3.1.1.1.1.1.3">𝑗</ci></apply><apply id="S3.p9.3.m3.2.2.2.2.2.cmml" xref="S3.p9.3.m3.2.2.2.2.2"><csymbol cd="latexml" id="S3.p9.3.m3.2.2.2.2.2.1.cmml" xref="S3.p9.3.m3.2.2.2.2.2.1">for-all</csymbol><apply id="S3.p9.3.m3.2.2.2.2.2.2.cmml" xref="S3.p9.3.m3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p9.3.m3.2.2.2.2.2.2.1.cmml" xref="S3.p9.3.m3.2.2.2.2.2.2">superscript</csymbol><ci id="S3.p9.3.m3.2.2.2.2.2.2.2.cmml" xref="S3.p9.3.m3.2.2.2.2.2.2.2">𝐶</ci><ci id="S3.p9.3.m3.2.2.2.2.2.2.3.cmml" xref="S3.p9.3.m3.2.2.2.2.2.2.3">𝑖</ci></apply></apply><apply id="S3.p9.3.m3.3.3.3.3.3.cmml" xref="S3.p9.3.m3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.p9.3.m3.3.3.3.3.3.1.cmml" xref="S3.p9.3.m3.3.3.3.3.3">superscript</csymbol><ci id="S3.p9.3.m3.3.3.3.3.3.2.cmml" xref="S3.p9.3.m3.3.3.3.3.3.2">𝐶</ci><ci id="S3.p9.3.m3.3.3.3.3.3.3.cmml" xref="S3.p9.3.m3.3.3.3.3.3.3">𝑗</ci></apply></list><ci id="S3.p9.3.m3.3.3.5.cmml" xref="S3.p9.3.m3.3.3.5">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.3.m3.3c">\alpha^{i}_{j}\quad\forall\&gt;C^{i},C^{j}\in C</annotation></semantics></math>. If two clients <math id="S3.p9.4.m4.2" class="ltx_Math" alttext="C^{i},C^{j}" display="inline"><semantics id="S3.p9.4.m4.2a"><mrow id="S3.p9.4.m4.2.2.2" xref="S3.p9.4.m4.2.2.3.cmml"><msup id="S3.p9.4.m4.1.1.1.1" xref="S3.p9.4.m4.1.1.1.1.cmml"><mi id="S3.p9.4.m4.1.1.1.1.2" xref="S3.p9.4.m4.1.1.1.1.2.cmml">C</mi><mi id="S3.p9.4.m4.1.1.1.1.3" xref="S3.p9.4.m4.1.1.1.1.3.cmml">i</mi></msup><mo id="S3.p9.4.m4.2.2.2.3" xref="S3.p9.4.m4.2.2.3.cmml">,</mo><msup id="S3.p9.4.m4.2.2.2.2" xref="S3.p9.4.m4.2.2.2.2.cmml"><mi id="S3.p9.4.m4.2.2.2.2.2" xref="S3.p9.4.m4.2.2.2.2.2.cmml">C</mi><mi id="S3.p9.4.m4.2.2.2.2.3" xref="S3.p9.4.m4.2.2.2.2.3.cmml">j</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.4.m4.2b"><list id="S3.p9.4.m4.2.2.3.cmml" xref="S3.p9.4.m4.2.2.2"><apply id="S3.p9.4.m4.1.1.1.1.cmml" xref="S3.p9.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.p9.4.m4.1.1.1.1.1.cmml" xref="S3.p9.4.m4.1.1.1.1">superscript</csymbol><ci id="S3.p9.4.m4.1.1.1.1.2.cmml" xref="S3.p9.4.m4.1.1.1.1.2">𝐶</ci><ci id="S3.p9.4.m4.1.1.1.1.3.cmml" xref="S3.p9.4.m4.1.1.1.1.3">𝑖</ci></apply><apply id="S3.p9.4.m4.2.2.2.2.cmml" xref="S3.p9.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.p9.4.m4.2.2.2.2.1.cmml" xref="S3.p9.4.m4.2.2.2.2">superscript</csymbol><ci id="S3.p9.4.m4.2.2.2.2.2.cmml" xref="S3.p9.4.m4.2.2.2.2.2">𝐶</ci><ci id="S3.p9.4.m4.2.2.2.2.3.cmml" xref="S3.p9.4.m4.2.2.2.2.3">𝑗</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.4.m4.2c">C^{i},C^{j}</annotation></semantics></math> have similar rows <math id="S3.p9.5.m5.1" class="ltx_math_unparsed" alttext="\alpha^{i}_{k},\alpha^{i}_{k}\quad\forall\&gt;k\in\{1..n\}\setminus\{i,j\}" display="inline"><semantics id="S3.p9.5.m5.1a"><mrow id="S3.p9.5.m5.1b"><msubsup id="S3.p9.5.m5.1.1"><mi id="S3.p9.5.m5.1.1.2.2">α</mi><mi id="S3.p9.5.m5.1.1.3">k</mi><mi id="S3.p9.5.m5.1.1.2.3">i</mi></msubsup><mo id="S3.p9.5.m5.1.2">,</mo><msubsup id="S3.p9.5.m5.1.3"><mi id="S3.p9.5.m5.1.3.2.2">α</mi><mi id="S3.p9.5.m5.1.3.3">k</mi><mi id="S3.p9.5.m5.1.3.2.3">i</mi></msubsup><mspace width="1.167em" id="S3.p9.5.m5.1.4"></mspace><mo rspace="0.387em" id="S3.p9.5.m5.1.5">∀</mo><mi id="S3.p9.5.m5.1.6">k</mi><mo id="S3.p9.5.m5.1.7">∈</mo><mrow id="S3.p9.5.m5.1.8"><mo stretchy="false" id="S3.p9.5.m5.1.8.1">{</mo><mn id="S3.p9.5.m5.1.8.2">1</mn><mo lspace="0em" rspace="0.0835em" id="S3.p9.5.m5.1.8.3">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S3.p9.5.m5.1.8.4">.</mo><mi id="S3.p9.5.m5.1.8.5">n</mi><mo stretchy="false" id="S3.p9.5.m5.1.8.6">}</mo></mrow><mo id="S3.p9.5.m5.1.9">∖</mo><mrow id="S3.p9.5.m5.1.10"><mo stretchy="false" id="S3.p9.5.m5.1.10.1">{</mo><mi id="S3.p9.5.m5.1.10.2">i</mi><mo id="S3.p9.5.m5.1.10.3">,</mo><mi id="S3.p9.5.m5.1.10.4">j</mi><mo stretchy="false" id="S3.p9.5.m5.1.10.5">}</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.p9.5.m5.1c">\alpha^{i}_{k},\alpha^{i}_{k}\quad\forall\&gt;k\in\{1..n\}\setminus\{i,j\}</annotation></semantics></math>, we observe that they are similarly divergent from other models in the matrix. This meta information can be used to cluster the clients using an unsupervised clustering algorithm, e.g., KMeans <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. As such, the server groups the clients into <math id="S3.p9.6.m6.1" class="ltx_Math" alttext="log(n)" display="inline"><semantics id="S3.p9.6.m6.1a"><mrow id="S3.p9.6.m6.1.2" xref="S3.p9.6.m6.1.2.cmml"><mi id="S3.p9.6.m6.1.2.2" xref="S3.p9.6.m6.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.p9.6.m6.1.2.1" xref="S3.p9.6.m6.1.2.1.cmml">​</mo><mi id="S3.p9.6.m6.1.2.3" xref="S3.p9.6.m6.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.p9.6.m6.1.2.1a" xref="S3.p9.6.m6.1.2.1.cmml">​</mo><mi id="S3.p9.6.m6.1.2.4" xref="S3.p9.6.m6.1.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.p9.6.m6.1.2.1b" xref="S3.p9.6.m6.1.2.1.cmml">​</mo><mrow id="S3.p9.6.m6.1.2.5.2" xref="S3.p9.6.m6.1.2.cmml"><mo stretchy="false" id="S3.p9.6.m6.1.2.5.2.1" xref="S3.p9.6.m6.1.2.cmml">(</mo><mi id="S3.p9.6.m6.1.1" xref="S3.p9.6.m6.1.1.cmml">n</mi><mo stretchy="false" id="S3.p9.6.m6.1.2.5.2.2" xref="S3.p9.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.6.m6.1b"><apply id="S3.p9.6.m6.1.2.cmml" xref="S3.p9.6.m6.1.2"><times id="S3.p9.6.m6.1.2.1.cmml" xref="S3.p9.6.m6.1.2.1"></times><ci id="S3.p9.6.m6.1.2.2.cmml" xref="S3.p9.6.m6.1.2.2">𝑙</ci><ci id="S3.p9.6.m6.1.2.3.cmml" xref="S3.p9.6.m6.1.2.3">𝑜</ci><ci id="S3.p9.6.m6.1.2.4.cmml" xref="S3.p9.6.m6.1.2.4">𝑔</ci><ci id="S3.p9.6.m6.1.1.cmml" xref="S3.p9.6.m6.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.6.m6.1c">log(n)</annotation></semantics></math> non-overlapping clusters as shown in Figure <a href="#S3.F1" title="Figure 1 ‣ III Methodology ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Once the clients are clustered, the server can now commence the FL process by applying a stratified sampling over the clusters.</p>
</div>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.12" class="ltx_p">To understand why our similarity matrix can help cluster similar clients together, suppose there are N clients that are training a global deep learning classification model (e.g., ResNets) in a federated manner. Each client <math id="S3.p10.1.m1.1" class="ltx_Math" alttext="C^{i}" display="inline"><semantics id="S3.p10.1.m1.1a"><msup id="S3.p10.1.m1.1.1" xref="S3.p10.1.m1.1.1.cmml"><mi id="S3.p10.1.m1.1.1.2" xref="S3.p10.1.m1.1.1.2.cmml">C</mi><mi id="S3.p10.1.m1.1.1.3" xref="S3.p10.1.m1.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p10.1.m1.1b"><apply id="S3.p10.1.m1.1.1.cmml" xref="S3.p10.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p10.1.m1.1.1.1.cmml" xref="S3.p10.1.m1.1.1">superscript</csymbol><ci id="S3.p10.1.m1.1.1.2.cmml" xref="S3.p10.1.m1.1.1.2">𝐶</ci><ci id="S3.p10.1.m1.1.1.3.cmml" xref="S3.p10.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.1.m1.1c">C^{i}</annotation></semantics></math> trains its copy of the global model <math id="S3.p10.2.m2.1" class="ltx_Math" alttext="m_{i}" display="inline"><semantics id="S3.p10.2.m2.1a"><msub id="S3.p10.2.m2.1.1" xref="S3.p10.2.m2.1.1.cmml"><mi id="S3.p10.2.m2.1.1.2" xref="S3.p10.2.m2.1.1.2.cmml">m</mi><mi id="S3.p10.2.m2.1.1.3" xref="S3.p10.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.2.m2.1b"><apply id="S3.p10.2.m2.1.1.cmml" xref="S3.p10.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p10.2.m2.1.1.1.cmml" xref="S3.p10.2.m2.1.1">subscript</csymbol><ci id="S3.p10.2.m2.1.1.2.cmml" xref="S3.p10.2.m2.1.1.2">𝑚</ci><ci id="S3.p10.2.m2.1.1.3.cmml" xref="S3.p10.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.2.m2.1c">m_{i}</annotation></semantics></math> locally on its private data <math id="S3.p10.3.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p10.3.m3.1a"><msub id="S3.p10.3.m3.1.1" xref="S3.p10.3.m3.1.1.cmml"><mi id="S3.p10.3.m3.1.1.2" xref="S3.p10.3.m3.1.1.2.cmml">D</mi><mi id="S3.p10.3.m3.1.1.3" xref="S3.p10.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.3.m3.1b"><apply id="S3.p10.3.m3.1.1.cmml" xref="S3.p10.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p10.3.m3.1.1.1.cmml" xref="S3.p10.3.m3.1.1">subscript</csymbol><ci id="S3.p10.3.m3.1.1.2.cmml" xref="S3.p10.3.m3.1.1.2">𝐷</ci><ci id="S3.p10.3.m3.1.1.3.cmml" xref="S3.p10.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.3.m3.1c">D_{i}</annotation></semantics></math> for a limited number of epochs (e.g., 10). Afterwards, it uses <math id="S3.p10.4.m4.1" class="ltx_Math" alttext="m_{i}" display="inline"><semantics id="S3.p10.4.m4.1a"><msub id="S3.p10.4.m4.1.1" xref="S3.p10.4.m4.1.1.cmml"><mi id="S3.p10.4.m4.1.1.2" xref="S3.p10.4.m4.1.1.2.cmml">m</mi><mi id="S3.p10.4.m4.1.1.3" xref="S3.p10.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.4.m4.1b"><apply id="S3.p10.4.m4.1.1.cmml" xref="S3.p10.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p10.4.m4.1.1.1.cmml" xref="S3.p10.4.m4.1.1">subscript</csymbol><ci id="S3.p10.4.m4.1.1.2.cmml" xref="S3.p10.4.m4.1.1.2">𝑚</ci><ci id="S3.p10.4.m4.1.1.3.cmml" xref="S3.p10.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.4.m4.1c">m_{i}</annotation></semantics></math> to predict labels on an unlabeled public test dataset <math id="S3.p10.5.m5.1" class="ltx_Math" alttext="D_{p}" display="inline"><semantics id="S3.p10.5.m5.1a"><msub id="S3.p10.5.m5.1.1" xref="S3.p10.5.m5.1.1.cmml"><mi id="S3.p10.5.m5.1.1.2" xref="S3.p10.5.m5.1.1.2.cmml">D</mi><mi id="S3.p10.5.m5.1.1.3" xref="S3.p10.5.m5.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.5.m5.1b"><apply id="S3.p10.5.m5.1.1.cmml" xref="S3.p10.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p10.5.m5.1.1.1.cmml" xref="S3.p10.5.m5.1.1">subscript</csymbol><ci id="S3.p10.5.m5.1.1.2.cmml" xref="S3.p10.5.m5.1.1.2">𝐷</ci><ci id="S3.p10.5.m5.1.1.3.cmml" xref="S3.p10.5.m5.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.5.m5.1c">D_{p}</annotation></semantics></math>. Let <math id="S3.p10.6.m6.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.p10.6.m6.1a"><msub id="S3.p10.6.m6.1.1" xref="S3.p10.6.m6.1.1.cmml"><mi id="S3.p10.6.m6.1.1.2" xref="S3.p10.6.m6.1.1.2.cmml">p</mi><mi id="S3.p10.6.m6.1.1.3" xref="S3.p10.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.6.m6.1b"><apply id="S3.p10.6.m6.1.1.cmml" xref="S3.p10.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p10.6.m6.1.1.1.cmml" xref="S3.p10.6.m6.1.1">subscript</csymbol><ci id="S3.p10.6.m6.1.1.2.cmml" xref="S3.p10.6.m6.1.1.2">𝑝</ci><ci id="S3.p10.6.m6.1.1.3.cmml" xref="S3.p10.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.6.m6.1c">p_{i}</annotation></semantics></math> and <math id="S3.p10.7.m7.1" class="ltx_Math" alttext="p_{j}" display="inline"><semantics id="S3.p10.7.m7.1a"><msub id="S3.p10.7.m7.1.1" xref="S3.p10.7.m7.1.1.cmml"><mi id="S3.p10.7.m7.1.1.2" xref="S3.p10.7.m7.1.1.2.cmml">p</mi><mi id="S3.p10.7.m7.1.1.3" xref="S3.p10.7.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.7.m7.1b"><apply id="S3.p10.7.m7.1.1.cmml" xref="S3.p10.7.m7.1.1"><csymbol cd="ambiguous" id="S3.p10.7.m7.1.1.1.cmml" xref="S3.p10.7.m7.1.1">subscript</csymbol><ci id="S3.p10.7.m7.1.1.2.cmml" xref="S3.p10.7.m7.1.1.2">𝑝</ci><ci id="S3.p10.7.m7.1.1.3.cmml" xref="S3.p10.7.m7.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.7.m7.1c">p_{j}</annotation></semantics></math> be the soft-label probability distributions output by models <math id="S3.p10.8.m8.1" class="ltx_Math" alttext="m_{i}" display="inline"><semantics id="S3.p10.8.m8.1a"><msub id="S3.p10.8.m8.1.1" xref="S3.p10.8.m8.1.1.cmml"><mi id="S3.p10.8.m8.1.1.2" xref="S3.p10.8.m8.1.1.2.cmml">m</mi><mi id="S3.p10.8.m8.1.1.3" xref="S3.p10.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.8.m8.1b"><apply id="S3.p10.8.m8.1.1.cmml" xref="S3.p10.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p10.8.m8.1.1.1.cmml" xref="S3.p10.8.m8.1.1">subscript</csymbol><ci id="S3.p10.8.m8.1.1.2.cmml" xref="S3.p10.8.m8.1.1.2">𝑚</ci><ci id="S3.p10.8.m8.1.1.3.cmml" xref="S3.p10.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.8.m8.1c">m_{i}</annotation></semantics></math> and <math id="S3.p10.9.m9.1" class="ltx_Math" alttext="m_{j}" display="inline"><semantics id="S3.p10.9.m9.1a"><msub id="S3.p10.9.m9.1.1" xref="S3.p10.9.m9.1.1.cmml"><mi id="S3.p10.9.m9.1.1.2" xref="S3.p10.9.m9.1.1.2.cmml">m</mi><mi id="S3.p10.9.m9.1.1.3" xref="S3.p10.9.m9.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.9.m9.1b"><apply id="S3.p10.9.m9.1.1.cmml" xref="S3.p10.9.m9.1.1"><csymbol cd="ambiguous" id="S3.p10.9.m9.1.1.1.cmml" xref="S3.p10.9.m9.1.1">subscript</csymbol><ci id="S3.p10.9.m9.1.1.2.cmml" xref="S3.p10.9.m9.1.1.2">𝑚</ci><ci id="S3.p10.9.m9.1.1.3.cmml" xref="S3.p10.9.m9.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.9.m9.1c">m_{j}</annotation></semantics></math> on the public dataset <math id="S3.p10.10.m10.1" class="ltx_Math" alttext="D_{p}" display="inline"><semantics id="S3.p10.10.m10.1a"><msub id="S3.p10.10.m10.1.1" xref="S3.p10.10.m10.1.1.cmml"><mi id="S3.p10.10.m10.1.1.2" xref="S3.p10.10.m10.1.1.2.cmml">D</mi><mi id="S3.p10.10.m10.1.1.3" xref="S3.p10.10.m10.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.10.m10.1b"><apply id="S3.p10.10.m10.1.1.cmml" xref="S3.p10.10.m10.1.1"><csymbol cd="ambiguous" id="S3.p10.10.m10.1.1.1.cmml" xref="S3.p10.10.m10.1.1">subscript</csymbol><ci id="S3.p10.10.m10.1.1.2.cmml" xref="S3.p10.10.m10.1.1.2">𝐷</ci><ci id="S3.p10.10.m10.1.1.3.cmml" xref="S3.p10.10.m10.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.10.m10.1c">D_{p}</annotation></semantics></math>. The KL-divergence between <math id="S3.p10.11.m11.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.p10.11.m11.1a"><msub id="S3.p10.11.m11.1.1" xref="S3.p10.11.m11.1.1.cmml"><mi id="S3.p10.11.m11.1.1.2" xref="S3.p10.11.m11.1.1.2.cmml">p</mi><mi id="S3.p10.11.m11.1.1.3" xref="S3.p10.11.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.11.m11.1b"><apply id="S3.p10.11.m11.1.1.cmml" xref="S3.p10.11.m11.1.1"><csymbol cd="ambiguous" id="S3.p10.11.m11.1.1.1.cmml" xref="S3.p10.11.m11.1.1">subscript</csymbol><ci id="S3.p10.11.m11.1.1.2.cmml" xref="S3.p10.11.m11.1.1.2">𝑝</ci><ci id="S3.p10.11.m11.1.1.3.cmml" xref="S3.p10.11.m11.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.11.m11.1c">p_{i}</annotation></semantics></math> and <math id="S3.p10.12.m12.1" class="ltx_Math" alttext="p_{j}" display="inline"><semantics id="S3.p10.12.m12.1a"><msub id="S3.p10.12.m12.1.1" xref="S3.p10.12.m12.1.1.cmml"><mi id="S3.p10.12.m12.1.1.2" xref="S3.p10.12.m12.1.1.2.cmml">p</mi><mi id="S3.p10.12.m12.1.1.3" xref="S3.p10.12.m12.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p10.12.m12.1b"><apply id="S3.p10.12.m12.1.1.cmml" xref="S3.p10.12.m12.1.1"><csymbol cd="ambiguous" id="S3.p10.12.m12.1.1.1.cmml" xref="S3.p10.12.m12.1.1">subscript</csymbol><ci id="S3.p10.12.m12.1.1.2.cmml" xref="S3.p10.12.m12.1.1.2">𝑝</ci><ci id="S3.p10.12.m12.1.1.3.cmml" xref="S3.p10.12.m12.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.12.m12.1c">p_{j}</annotation></semantics></math> can be written as:</p>
</div>
<div id="S3.p11" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.6" class="ltx_math_unparsed" alttext="\alpha^{i}_{j}=KL(p_{i}||p_{j})=\sum_{c=1}^{K}p_{i,c}\log\left(\frac{p_{i,c}}{p_{j,c}}\right)" display="block"><semantics id="S3.E2.m1.6a"><mrow id="S3.E2.m1.6b"><msubsup id="S3.E2.m1.6.7"><mi id="S3.E2.m1.6.7.2.2">α</mi><mi id="S3.E2.m1.6.7.3">j</mi><mi id="S3.E2.m1.6.7.2.3">i</mi></msubsup><mo id="S3.E2.m1.6.8">=</mo><mi id="S3.E2.m1.6.9">K</mi><mi id="S3.E2.m1.6.10">L</mi><mrow id="S3.E2.m1.6.11"><mo stretchy="false" id="S3.E2.m1.6.11.1">(</mo><msub id="S3.E2.m1.6.11.2"><mi id="S3.E2.m1.6.11.2.2">p</mi><mi id="S3.E2.m1.6.11.2.3">i</mi></msub><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E2.m1.6.11.3">|</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E2.m1.6.11.4">|</mo><msub id="S3.E2.m1.6.11.5"><mi id="S3.E2.m1.6.11.5.2">p</mi><mi id="S3.E2.m1.6.11.5.3">j</mi></msub><mo stretchy="false" id="S3.E2.m1.6.11.6">)</mo></mrow><mo rspace="0.111em" id="S3.E2.m1.6.12">=</mo><munderover id="S3.E2.m1.6.13"><mo movablelimits="false" id="S3.E2.m1.6.13.2.2">∑</mo><mrow id="S3.E2.m1.6.13.2.3"><mi id="S3.E2.m1.6.13.2.3.2">c</mi><mo id="S3.E2.m1.6.13.2.3.1">=</mo><mn id="S3.E2.m1.6.13.2.3.3">1</mn></mrow><mi id="S3.E2.m1.6.13.3">K</mi></munderover><msub id="S3.E2.m1.6.14"><mi id="S3.E2.m1.6.14.2">p</mi><mrow id="S3.E2.m1.2.2.2.4"><mi id="S3.E2.m1.1.1.1.1">i</mi><mo id="S3.E2.m1.2.2.2.4.1">,</mo><mi id="S3.E2.m1.2.2.2.2">c</mi></mrow></msub><mi id="S3.E2.m1.6.15">log</mi><mrow id="S3.E2.m1.6.16"><mo id="S3.E2.m1.6.16.1">(</mo><mfrac id="S3.E2.m1.6.6"><msub id="S3.E2.m1.4.4.2"><mi id="S3.E2.m1.4.4.2.4">p</mi><mrow id="S3.E2.m1.4.4.2.2.2.4"><mi id="S3.E2.m1.3.3.1.1.1.1">i</mi><mo id="S3.E2.m1.4.4.2.2.2.4.1">,</mo><mi id="S3.E2.m1.4.4.2.2.2.2">c</mi></mrow></msub><msub id="S3.E2.m1.6.6.4"><mi id="S3.E2.m1.6.6.4.4">p</mi><mrow id="S3.E2.m1.6.6.4.2.2.4"><mi id="S3.E2.m1.5.5.3.1.1.1">j</mi><mo id="S3.E2.m1.6.6.4.2.2.4.1">,</mo><mi id="S3.E2.m1.6.6.4.2.2.2">c</mi></mrow></msub></mfrac><mo id="S3.E2.m1.6.16.2">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.6c">\alpha^{i}_{j}=KL(p_{i}||p_{j})=\sum_{c=1}^{K}p_{i,c}\log\left(\frac{p_{i,c}}{p_{j,c}}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.p12" class="ltx_para">
<p id="S3.p12.1" class="ltx_p">where <math id="S3.p12.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.p12.1.m1.1a"><mi id="S3.p12.1.m1.1.1" xref="S3.p12.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.p12.1.m1.1b"><ci id="S3.p12.1.m1.1.1.cmml" xref="S3.p12.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p12.1.m1.1c">K</annotation></semantics></math> is the number of classes in the classification problem. We make two conjectures why this approach helps group similar clients together.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Assumption 1.</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">All client models are trained on the same task with the same model initialization, hyper-parameter settings and optimization algorithms, and the models are trained for the same number of epochs.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Assumption 2.</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.6" class="ltx_p">The global dataset <math id="S3.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.1.m1.1c">D</annotation></semantics></math> (collective client dataset) is composed of a limited number of labels (e.g., 10). Each client’s local dataset contains an arbitrary number of unique labels (labels <math id="S3.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.2.m2.1a"><mo id="S3.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">∈</mo><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.2.m2.1b"><in id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.2.m2.1c">\in</annotation></semantics></math> <math id="S3.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.3.m3.1a"><msub id="S3.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml">D</mi><mi id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2">𝐷</ci><ci id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.3.m3.1c">D_{i}</annotation></semantics></math> <math id="S3.SS0.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\subseteq" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.4.m4.1a"><mo id="S3.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">⊆</mo><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.4.m4.1b"><subset id="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1"></subset></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.4.m4.1c">\subseteq</annotation></semantics></math> labels <math id="S3.SS0.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.5.m5.1a"><mo id="S3.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.cmml">∈</mo><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.5.m5.1b"><in id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.5.m5.1c">\in</annotation></semantics></math> <math id="S3.SS0.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.6.m6.1a"><mi id="S3.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px2.p1.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.6.m6.1b"><ci id="S3.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.6.m6.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.6.m6.1c">D</annotation></semantics></math> ) and an arbitrary number of samples for each label.</p>
</div>
<div id="S3.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p2.6" class="ltx_p">High-level features can be represented as a function of the input data and the model’s parameters. Let’s denote the input data as <math id="S3.SS0.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS0.SSS0.Px2.p2.1.m1.1a"><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.1.m1.1b"><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.1.m1.1c">x</annotation></semantics></math>, and the parameters of the model as <math id="S3.SS0.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS0.SSS0.Px2.p2.2.m2.1a"><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.2.m2.1b"><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.2.m2.1c">\theta</annotation></semantics></math>. The high-level features can be denoted as <math id="S3.SS0.SSS0.Px2.p2.3.m3.2" class="ltx_Math" alttext="H(x;\theta)" display="inline"><semantics id="S3.SS0.SSS0.Px2.p2.3.m3.2a"><mrow id="S3.SS0.SSS0.Px2.p2.3.m3.2.3" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.cmml"><mi id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.2" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.1" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.1.cmml">​</mo><mrow id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.2" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.2.1" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.1.cmml">(</mo><mi id="S3.SS0.SSS0.Px2.p2.3.m3.1.1" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1.cmml">x</mi><mo id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.2.2" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.1.cmml">;</mo><mi id="S3.SS0.SSS0.Px2.p2.3.m3.2.2" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.2.cmml">θ</mi><mo stretchy="false" id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.2.3" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.3.m3.2b"><apply id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3"><times id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.1.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.1"></times><ci id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.2.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.2">𝐻</ci><list id="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.1.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.3.3.2"><ci id="S3.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1">𝑥</ci><ci id="S3.SS0.SSS0.Px2.p2.3.m3.2.2.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.2.2">𝜃</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.3.m3.2c">H(x;\theta)</annotation></semantics></math>, which indicates that the features are obtained by applying a transformation <math id="S3.SS0.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS0.SSS0.Px2.p2.4.m4.1a"><mi id="S3.SS0.SSS0.Px2.p2.4.m4.1.1" xref="S3.SS0.SSS0.Px2.p2.4.m4.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.4.m4.1b"><ci id="S3.SS0.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.4.m4.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.4.m4.1c">H</annotation></semantics></math> to the input <math id="S3.SS0.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS0.SSS0.Px2.p2.5.m5.1a"><mi id="S3.SS0.SSS0.Px2.p2.5.m5.1.1" xref="S3.SS0.SSS0.Px2.p2.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.5.m5.1b"><ci id="S3.SS0.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.5.m5.1c">x</annotation></semantics></math> using the model’s parameters <math id="S3.SS0.SSS0.Px2.p2.6.m6.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS0.SSS0.Px2.p2.6.m6.1a"><mi id="S3.SS0.SSS0.Px2.p2.6.m6.1.1" xref="S3.SS0.SSS0.Px2.p2.6.m6.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.6.m6.1b"><ci id="S3.SS0.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.6.m6.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.6.m6.1c">\theta</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Conjecture 1:</h5>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p1.4" class="ltx_p">If the KL-divergence, <math id="S3.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\alpha^{i}_{j}" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.1.m1.1a"><msubsup id="S3.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.2" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.2.cmml">α</mi><mi id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml">j</mi><mi id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.3" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.2">𝛼</ci><ci id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.3">𝑖</ci></apply><ci id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.1.m1.1c">\alpha^{i}_{j}</annotation></semantics></math>, between <math id="S3.SS0.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.2.m2.1a"><msub id="S3.SS0.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">p</mi><mi id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.2.m2.1b"><apply id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1.2">𝑝</ci><ci id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.2.m2.1c">p_{i}</annotation></semantics></math> and <math id="S3.SS0.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="p_{j}" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.3.m3.1a"><msub id="S3.SS0.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml">p</mi><mi id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2">𝑝</ci><ci id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.3.m3.1c">p_{j}</annotation></semantics></math> is small, then we can expect that the high-level learned representation of models <math id="S3.SS0.SSS0.Px3.p1.4.m4.2" class="ltx_Math" alttext="m_{i},m_{j}" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.4.m4.2a"><mrow id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.3.cmml"><msub id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.2" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.2.cmml">m</mi><mi id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.3" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.3" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.3.cmml">,</mo><msub id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.cmml"><mi id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.2" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.2.cmml">m</mi><mi id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.3" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.4.m4.2b"><list id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.3.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2"><apply id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.2">𝑚</ci><ci id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.2">𝑚</ci><ci id="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.3.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.2.2.2.2.3">𝑗</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.4.m4.2c">m_{i},m_{j}</annotation></semantics></math> could be similar.</p>
</div>
<div id="S3.SS0.SSS0.Px3.p2" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="\alpha^{i}_{j}+\alpha^{j}_{i}&lt;\epsilon_{1}\rightarrow\left\|H_{i}(x;\theta_{i})-H_{j}(x;\theta_{j})\right\|&lt;\epsilon_{0}" display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mrow id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml"><msubsup id="S3.E3.m1.3.3.3.2" xref="S3.E3.m1.3.3.3.2.cmml"><mi id="S3.E3.m1.3.3.3.2.2.2" xref="S3.E3.m1.3.3.3.2.2.2.cmml">α</mi><mi id="S3.E3.m1.3.3.3.2.3" xref="S3.E3.m1.3.3.3.2.3.cmml">j</mi><mi id="S3.E3.m1.3.3.3.2.2.3" xref="S3.E3.m1.3.3.3.2.2.3.cmml">i</mi></msubsup><mo id="S3.E3.m1.3.3.3.1" xref="S3.E3.m1.3.3.3.1.cmml">+</mo><msubsup id="S3.E3.m1.3.3.3.3" xref="S3.E3.m1.3.3.3.3.cmml"><mi id="S3.E3.m1.3.3.3.3.2.2" xref="S3.E3.m1.3.3.3.3.2.2.cmml">α</mi><mi id="S3.E3.m1.3.3.3.3.3" xref="S3.E3.m1.3.3.3.3.3.cmml">i</mi><mi id="S3.E3.m1.3.3.3.3.2.3" xref="S3.E3.m1.3.3.3.3.2.3.cmml">j</mi></msubsup></mrow><mo id="S3.E3.m1.3.3.4" xref="S3.E3.m1.3.3.4.cmml">&lt;</mo><msub id="S3.E3.m1.3.3.5" xref="S3.E3.m1.3.3.5.cmml"><mi id="S3.E3.m1.3.3.5.2" xref="S3.E3.m1.3.3.5.2.cmml">ϵ</mi><mn id="S3.E3.m1.3.3.5.3" xref="S3.E3.m1.3.3.5.3.cmml">1</mn></msub><mo stretchy="false" id="S3.E3.m1.3.3.6" xref="S3.E3.m1.3.3.6.cmml">→</mo><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.2.1.cmml">‖</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.2.cmml">H</mi><mi id="S3.E3.m1.3.3.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">​</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">x</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.2.cmml">;</mo><msub id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml">θ</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.1.1.4" xref="S3.E3.m1.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.3.cmml">−</mo><mrow id="S3.E3.m1.3.3.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.2.cmml"><msub id="S3.E3.m1.3.3.1.1.1.2.3" xref="S3.E3.m1.3.3.1.1.1.2.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.2.3.2" xref="S3.E3.m1.3.3.1.1.1.2.3.2.cmml">H</mi><mi id="S3.E3.m1.3.3.1.1.1.2.3.3" xref="S3.E3.m1.3.3.1.1.1.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.2.2.cmml">​</mo><mrow id="S3.E3.m1.3.3.1.1.1.2.1.1" xref="S3.E3.m1.3.3.1.1.1.2.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.2.1.1.2" xref="S3.E3.m1.3.3.1.1.1.2.1.2.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">x</mi><mo id="S3.E3.m1.3.3.1.1.1.2.1.1.3" xref="S3.E3.m1.3.3.1.1.1.2.1.2.cmml">;</mo><msub id="S3.E3.m1.3.3.1.1.1.2.1.1.1" xref="S3.E3.m1.3.3.1.1.1.2.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.2.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.2.1.1.1.2.cmml">θ</mi><mi id="S3.E3.m1.3.3.1.1.1.2.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.2.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.2.1.1.4" xref="S3.E3.m1.3.3.1.1.1.2.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.3" xref="S3.E3.m1.3.3.1.2.1.cmml">‖</mo></mrow><mo id="S3.E3.m1.3.3.7" xref="S3.E3.m1.3.3.7.cmml">&lt;</mo><msub id="S3.E3.m1.3.3.8" xref="S3.E3.m1.3.3.8.cmml"><mi id="S3.E3.m1.3.3.8.2" xref="S3.E3.m1.3.3.8.2.cmml">ϵ</mi><mn id="S3.E3.m1.3.3.8.3" xref="S3.E3.m1.3.3.8.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><and id="S3.E3.m1.3.3a.cmml" xref="S3.E3.m1.3.3"></and><apply id="S3.E3.m1.3.3b.cmml" xref="S3.E3.m1.3.3"><lt id="S3.E3.m1.3.3.4.cmml" xref="S3.E3.m1.3.3.4"></lt><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"><plus id="S3.E3.m1.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.1"></plus><apply id="S3.E3.m1.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.2.1.cmml" xref="S3.E3.m1.3.3.3.2">subscript</csymbol><apply id="S3.E3.m1.3.3.3.2.2.cmml" xref="S3.E3.m1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.2.2.1.cmml" xref="S3.E3.m1.3.3.3.2">superscript</csymbol><ci id="S3.E3.m1.3.3.3.2.2.2.cmml" xref="S3.E3.m1.3.3.3.2.2.2">𝛼</ci><ci id="S3.E3.m1.3.3.3.2.2.3.cmml" xref="S3.E3.m1.3.3.3.2.2.3">𝑖</ci></apply><ci id="S3.E3.m1.3.3.3.2.3.cmml" xref="S3.E3.m1.3.3.3.2.3">𝑗</ci></apply><apply id="S3.E3.m1.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.3">subscript</csymbol><apply id="S3.E3.m1.3.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.3.2.1.cmml" xref="S3.E3.m1.3.3.3.3">superscript</csymbol><ci id="S3.E3.m1.3.3.3.3.2.2.cmml" xref="S3.E3.m1.3.3.3.3.2.2">𝛼</ci><ci id="S3.E3.m1.3.3.3.3.2.3.cmml" xref="S3.E3.m1.3.3.3.3.2.3">𝑗</ci></apply><ci id="S3.E3.m1.3.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3.3">𝑖</ci></apply></apply><apply id="S3.E3.m1.3.3.5.cmml" xref="S3.E3.m1.3.3.5"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.5.1.cmml" xref="S3.E3.m1.3.3.5">subscript</csymbol><ci id="S3.E3.m1.3.3.5.2.cmml" xref="S3.E3.m1.3.3.5.2">italic-ϵ</ci><cn type="integer" id="S3.E3.m1.3.3.5.3.cmml" xref="S3.E3.m1.3.3.5.3">1</cn></apply></apply><apply id="S3.E3.m1.3.3c.cmml" xref="S3.E3.m1.3.3"><ci id="S3.E3.m1.3.3.6.cmml" xref="S3.E3.m1.3.3.6">→</ci><share href="#S3.E3.m1.3.3.5.cmml" id="S3.E3.m1.3.3d.cmml" xref="S3.E3.m1.3.3"></share><apply id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2">norm</csymbol><apply id="S3.E3.m1.3.3.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"><minus id="S3.E3.m1.3.3.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.3"></minus><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"></times><apply id="S3.E3.m1.3.3.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2">𝐻</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3">𝑖</ci></apply><list id="S3.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝑥</ci><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2">𝜃</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3">𝑖</ci></apply></list></apply><apply id="S3.E3.m1.3.3.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2"><times id="S3.E3.m1.3.3.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2.2"></times><apply id="S3.E3.m1.3.3.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.2.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2.3.2">𝐻</ci><ci id="S3.E3.m1.3.3.1.1.1.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.2.3.3">𝑗</ci></apply><list id="S3.E3.m1.3.3.1.1.1.2.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2.1.1"><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝑥</ci><apply id="S3.E3.m1.3.3.1.1.1.2.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.2.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.2.1.1.1">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.2.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2.1.1.1.2">𝜃</ci><ci id="S3.E3.m1.3.3.1.1.1.2.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.2.1.1.1.3">𝑗</ci></apply></list></apply></apply></apply></apply><apply id="S3.E3.m1.3.3e.cmml" xref="S3.E3.m1.3.3"><lt id="S3.E3.m1.3.3.7.cmml" xref="S3.E3.m1.3.3.7"></lt><share href="#S3.E3.m1.3.3.1.cmml" id="S3.E3.m1.3.3f.cmml" xref="S3.E3.m1.3.3"></share><apply id="S3.E3.m1.3.3.8.cmml" xref="S3.E3.m1.3.3.8"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.8.1.cmml" xref="S3.E3.m1.3.3.8">subscript</csymbol><ci id="S3.E3.m1.3.3.8.2.cmml" xref="S3.E3.m1.3.3.8.2">italic-ϵ</ci><cn type="integer" id="S3.E3.m1.3.3.8.3.cmml" xref="S3.E3.m1.3.3.8.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\alpha^{i}_{j}+\alpha^{j}_{i}&lt;\epsilon_{1}\rightarrow\left\|H_{i}(x;\theta_{i})-H_{j}(x;\theta_{j})\right\|&lt;\epsilon_{0}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS0.SSS0.Px3.p3" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p3.2" class="ltx_p">where <math id="S3.SS0.SSS0.Px3.p3.1.m1.1" class="ltx_Math" alttext="\epsilon_{0}" display="inline"><semantics id="S3.SS0.SSS0.Px3.p3.1.m1.1a"><msub id="S3.SS0.SSS0.Px3.p3.1.m1.1.1" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2.cmml">ϵ</mi><mn id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.3" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p3.1.m1.1b"><apply id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2">italic-ϵ</ci><cn type="integer" id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p3.1.m1.1c">\epsilon_{0}</annotation></semantics></math> and <math id="S3.SS0.SSS0.Px3.p3.2.m2.1" class="ltx_Math" alttext="\epsilon_{1}" display="inline"><semantics id="S3.SS0.SSS0.Px3.p3.2.m2.1a"><msub id="S3.SS0.SSS0.Px3.p3.2.m2.1.1" xref="S3.SS0.SSS0.Px3.p3.2.m2.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p3.2.m2.1.1.2" xref="S3.SS0.SSS0.Px3.p3.2.m2.1.1.2.cmml">ϵ</mi><mn id="S3.SS0.SSS0.Px3.p3.2.m2.1.1.3" xref="S3.SS0.SSS0.Px3.p3.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p3.2.m2.1b"><apply id="S3.SS0.SSS0.Px3.p3.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p3.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p3.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p3.2.m2.1.1.2">italic-ϵ</ci><cn type="integer" id="S3.SS0.SSS0.Px3.p3.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px3.p3.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p3.2.m2.1c">\epsilon_{1}</annotation></semantics></math> are small threshold values.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Conjecture 2:</h5>

<div id="S3.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px4.p1.3" class="ltx_p">If two rows in the KL-based similarity matrix, <math id="S3.SS0.SSS0.Px4.p1.1.m1.2" class="ltx_Math" alttext="\alpha^{i}_{k},\alpha^{j}_{k}" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.1.m1.2a"><mrow id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.3.cmml"><msubsup id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.2" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.2.cmml">α</mi><mi id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.3.cmml">k</mi><mi id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.3.cmml">i</mi></msubsup><mo id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.3.cmml">,</mo><msubsup id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.2" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.2.cmml">α</mi><mi id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.3.cmml">k</mi><mi id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.3.cmml">j</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.1.m1.2b"><list id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.3.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2"><apply id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1">superscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.2">𝛼</ci><ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.1.3">𝑘</ci></apply><apply id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2">subscript</csymbol><apply id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2">superscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.2">𝛼</ci><ci id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.2.3">𝑗</ci></apply><ci id="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.2.2.2.2.3">𝑘</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.1.m1.2c">\alpha^{i}_{k},\alpha^{j}_{k}</annotation></semantics></math>, have similar values, then models <math id="S3.SS0.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="m_{i}" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.2.m2.1a"><msub id="S3.SS0.SSS0.Px4.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.cmml"><mi id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml">m</mi><mi id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.2.m2.1b"><apply id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2">𝑚</ci><ci id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.2.m2.1c">m_{i}</annotation></semantics></math> and <math id="S3.SS0.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="m_{j}" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.3.m3.1a"><msub id="S3.SS0.SSS0.Px4.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1.cmml"><mi id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1.2.cmml">m</mi><mi id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1.2">𝑚</ci><ci id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.3.m3.1c">m_{j}</annotation></semantics></math> have learned similar high-level feature representations via relativity with the same subset of models.</p>
</div>
<div id="S3.SS0.SSS0.Px4.p2" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.4" class="ltx_Math" alttext="\frac{1}{N}\sum_{k}|\alpha^{i}_{k}-\alpha^{j}_{k}|&lt;\epsilon_{2}\rightarrow\left\|H_{i}(x;\theta_{i})-H_{j}(x;\theta_{j})\right\|&lt;\epsilon_{0}" display="block"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.4" xref="S3.E4.m1.4.4.cmml"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.cmml"><mfrac id="S3.E4.m1.3.3.1.3" xref="S3.E4.m1.3.3.1.3.cmml"><mn id="S3.E4.m1.3.3.1.3.2" xref="S3.E4.m1.3.3.1.3.2.cmml">1</mn><mi id="S3.E4.m1.3.3.1.3.3" xref="S3.E4.m1.3.3.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.2.cmml">​</mo><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><munder id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E4.m1.3.3.1.1.2.2" xref="S3.E4.m1.3.3.1.1.2.2.cmml">∑</mo><mi id="S3.E4.m1.3.3.1.1.2.3" xref="S3.E4.m1.3.3.1.1.2.3.cmml">k</mi></munder><mrow id="S3.E4.m1.3.3.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.2.1.cmml">|</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml"><msubsup id="S3.E4.m1.3.3.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.2.2.2.cmml">α</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.2.3" xref="S3.E4.m1.3.3.1.1.1.1.1.2.3.cmml">k</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.2.2.3" xref="S3.E4.m1.3.3.1.1.1.1.1.2.2.3.cmml">i</mi></msubsup><mo id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">−</mo><msubsup id="S3.E4.m1.3.3.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.3.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2.2.cmml">α</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3.cmml">k</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.3.2.3" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2.3.cmml">j</mi></msubsup></mrow><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow><mo id="S3.E4.m1.4.4.4" xref="S3.E4.m1.4.4.4.cmml">&lt;</mo><msub id="S3.E4.m1.4.4.5" xref="S3.E4.m1.4.4.5.cmml"><mi id="S3.E4.m1.4.4.5.2" xref="S3.E4.m1.4.4.5.2.cmml">ϵ</mi><mn id="S3.E4.m1.4.4.5.3" xref="S3.E4.m1.4.4.5.3.cmml">2</mn></msub><mo stretchy="false" id="S3.E4.m1.4.4.6" xref="S3.E4.m1.4.4.6.cmml">→</mo><mrow id="S3.E4.m1.4.4.2.1" xref="S3.E4.m1.4.4.2.2.cmml"><mo id="S3.E4.m1.4.4.2.1.2" xref="S3.E4.m1.4.4.2.2.1.cmml">‖</mo><mrow id="S3.E4.m1.4.4.2.1.1" xref="S3.E4.m1.4.4.2.1.1.cmml"><mrow id="S3.E4.m1.4.4.2.1.1.1" xref="S3.E4.m1.4.4.2.1.1.1.cmml"><msub id="S3.E4.m1.4.4.2.1.1.1.3" xref="S3.E4.m1.4.4.2.1.1.1.3.cmml"><mi id="S3.E4.m1.4.4.2.1.1.1.3.2" xref="S3.E4.m1.4.4.2.1.1.1.3.2.cmml">H</mi><mi id="S3.E4.m1.4.4.2.1.1.1.3.3" xref="S3.E4.m1.4.4.2.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.2.1.1.1.2" xref="S3.E4.m1.4.4.2.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.4.4.2.1.1.1.1.1" xref="S3.E4.m1.4.4.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.2.1.1.1.1.1.2" xref="S3.E4.m1.4.4.2.1.1.1.1.2.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">x</mi><mo id="S3.E4.m1.4.4.2.1.1.1.1.1.3" xref="S3.E4.m1.4.4.2.1.1.1.1.2.cmml">;</mo><msub id="S3.E4.m1.4.4.2.1.1.1.1.1.1" xref="S3.E4.m1.4.4.2.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.4.4.2.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.2.1.1.1.1.1.1.2.cmml">θ</mi><mi id="S3.E4.m1.4.4.2.1.1.1.1.1.1.3" xref="S3.E4.m1.4.4.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E4.m1.4.4.2.1.1.1.1.1.4" xref="S3.E4.m1.4.4.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.4.4.2.1.1.3" xref="S3.E4.m1.4.4.2.1.1.3.cmml">−</mo><mrow id="S3.E4.m1.4.4.2.1.1.2" xref="S3.E4.m1.4.4.2.1.1.2.cmml"><msub id="S3.E4.m1.4.4.2.1.1.2.3" xref="S3.E4.m1.4.4.2.1.1.2.3.cmml"><mi id="S3.E4.m1.4.4.2.1.1.2.3.2" xref="S3.E4.m1.4.4.2.1.1.2.3.2.cmml">H</mi><mi id="S3.E4.m1.4.4.2.1.1.2.3.3" xref="S3.E4.m1.4.4.2.1.1.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.2.1.1.2.2" xref="S3.E4.m1.4.4.2.1.1.2.2.cmml">​</mo><mrow id="S3.E4.m1.4.4.2.1.1.2.1.1" xref="S3.E4.m1.4.4.2.1.1.2.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.2.1.1.2.1.1.2" xref="S3.E4.m1.4.4.2.1.1.2.1.2.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">x</mi><mo id="S3.E4.m1.4.4.2.1.1.2.1.1.3" xref="S3.E4.m1.4.4.2.1.1.2.1.2.cmml">;</mo><msub id="S3.E4.m1.4.4.2.1.1.2.1.1.1" xref="S3.E4.m1.4.4.2.1.1.2.1.1.1.cmml"><mi id="S3.E4.m1.4.4.2.1.1.2.1.1.1.2" xref="S3.E4.m1.4.4.2.1.1.2.1.1.1.2.cmml">θ</mi><mi id="S3.E4.m1.4.4.2.1.1.2.1.1.1.3" xref="S3.E4.m1.4.4.2.1.1.2.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E4.m1.4.4.2.1.1.2.1.1.4" xref="S3.E4.m1.4.4.2.1.1.2.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.4.4.2.1.3" xref="S3.E4.m1.4.4.2.2.1.cmml">‖</mo></mrow><mo id="S3.E4.m1.4.4.7" xref="S3.E4.m1.4.4.7.cmml">&lt;</mo><msub id="S3.E4.m1.4.4.8" xref="S3.E4.m1.4.4.8.cmml"><mi id="S3.E4.m1.4.4.8.2" xref="S3.E4.m1.4.4.8.2.cmml">ϵ</mi><mn id="S3.E4.m1.4.4.8.3" xref="S3.E4.m1.4.4.8.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.4.cmml" xref="S3.E4.m1.4.4"><and id="S3.E4.m1.4.4a.cmml" xref="S3.E4.m1.4.4"></and><apply id="S3.E4.m1.4.4b.cmml" xref="S3.E4.m1.4.4"><lt id="S3.E4.m1.4.4.4.cmml" xref="S3.E4.m1.4.4.4"></lt><apply id="S3.E4.m1.3.3.1.cmml" xref="S3.E4.m1.3.3.1"><times id="S3.E4.m1.3.3.1.2.cmml" xref="S3.E4.m1.3.3.1.2"></times><apply id="S3.E4.m1.3.3.1.3.cmml" xref="S3.E4.m1.3.3.1.3"><divide id="S3.E4.m1.3.3.1.3.1.cmml" xref="S3.E4.m1.3.3.1.3"></divide><cn type="integer" id="S3.E4.m1.3.3.1.3.2.cmml" xref="S3.E4.m1.3.3.1.3.2">1</cn><ci id="S3.E4.m1.3.3.1.3.3.cmml" xref="S3.E4.m1.3.3.1.3.3">𝑁</ci></apply><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1.1"><apply id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.2">subscript</csymbol><sum id="S3.E4.m1.3.3.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.2.2"></sum><ci id="S3.E4.m1.3.3.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.2.3">𝑘</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1"><abs id="S3.E4.m1.3.3.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2"></abs><apply id="S3.E4.m1.3.3.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"><minus id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1"></minus><apply id="S3.E4.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2.2.2">𝛼</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2.2.3">𝑖</ci></apply><ci id="S3.E4.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2.3">𝑘</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2.2">𝛼</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2.3">𝑗</ci></apply><ci id="S3.E4.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3">𝑘</ci></apply></apply></apply></apply></apply><apply id="S3.E4.m1.4.4.5.cmml" xref="S3.E4.m1.4.4.5"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.5.1.cmml" xref="S3.E4.m1.4.4.5">subscript</csymbol><ci id="S3.E4.m1.4.4.5.2.cmml" xref="S3.E4.m1.4.4.5.2">italic-ϵ</ci><cn type="integer" id="S3.E4.m1.4.4.5.3.cmml" xref="S3.E4.m1.4.4.5.3">2</cn></apply></apply><apply id="S3.E4.m1.4.4c.cmml" xref="S3.E4.m1.4.4"><ci id="S3.E4.m1.4.4.6.cmml" xref="S3.E4.m1.4.4.6">→</ci><share href="#S3.E4.m1.4.4.5.cmml" id="S3.E4.m1.4.4d.cmml" xref="S3.E4.m1.4.4"></share><apply id="S3.E4.m1.4.4.2.2.cmml" xref="S3.E4.m1.4.4.2.1"><csymbol cd="latexml" id="S3.E4.m1.4.4.2.2.1.cmml" xref="S3.E4.m1.4.4.2.1.2">norm</csymbol><apply id="S3.E4.m1.4.4.2.1.1.cmml" xref="S3.E4.m1.4.4.2.1.1"><minus id="S3.E4.m1.4.4.2.1.1.3.cmml" xref="S3.E4.m1.4.4.2.1.1.3"></minus><apply id="S3.E4.m1.4.4.2.1.1.1.cmml" xref="S3.E4.m1.4.4.2.1.1.1"><times id="S3.E4.m1.4.4.2.1.1.1.2.cmml" xref="S3.E4.m1.4.4.2.1.1.1.2"></times><apply id="S3.E4.m1.4.4.2.1.1.1.3.cmml" xref="S3.E4.m1.4.4.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.2.1.1.1.3.1.cmml" xref="S3.E4.m1.4.4.2.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.4.4.2.1.1.1.3.2.cmml" xref="S3.E4.m1.4.4.2.1.1.1.3.2">𝐻</ci><ci id="S3.E4.m1.4.4.2.1.1.1.3.3.cmml" xref="S3.E4.m1.4.4.2.1.1.1.3.3">𝑖</ci></apply><list id="S3.E4.m1.4.4.2.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.2.1.1.1.1.1"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝑥</ci><apply id="S3.E4.m1.4.4.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.4.4.2.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.2.1.1.1.1.1.1.2">𝜃</ci><ci id="S3.E4.m1.4.4.2.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.4.4.2.1.1.1.1.1.1.3">𝑖</ci></apply></list></apply><apply id="S3.E4.m1.4.4.2.1.1.2.cmml" xref="S3.E4.m1.4.4.2.1.1.2"><times id="S3.E4.m1.4.4.2.1.1.2.2.cmml" xref="S3.E4.m1.4.4.2.1.1.2.2"></times><apply id="S3.E4.m1.4.4.2.1.1.2.3.cmml" xref="S3.E4.m1.4.4.2.1.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.2.1.1.2.3.1.cmml" xref="S3.E4.m1.4.4.2.1.1.2.3">subscript</csymbol><ci id="S3.E4.m1.4.4.2.1.1.2.3.2.cmml" xref="S3.E4.m1.4.4.2.1.1.2.3.2">𝐻</ci><ci id="S3.E4.m1.4.4.2.1.1.2.3.3.cmml" xref="S3.E4.m1.4.4.2.1.1.2.3.3">𝑗</ci></apply><list id="S3.E4.m1.4.4.2.1.1.2.1.2.cmml" xref="S3.E4.m1.4.4.2.1.1.2.1.1"><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝑥</ci><apply id="S3.E4.m1.4.4.2.1.1.2.1.1.1.cmml" xref="S3.E4.m1.4.4.2.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.2.1.1.2.1.1.1.1.cmml" xref="S3.E4.m1.4.4.2.1.1.2.1.1.1">subscript</csymbol><ci id="S3.E4.m1.4.4.2.1.1.2.1.1.1.2.cmml" xref="S3.E4.m1.4.4.2.1.1.2.1.1.1.2">𝜃</ci><ci id="S3.E4.m1.4.4.2.1.1.2.1.1.1.3.cmml" xref="S3.E4.m1.4.4.2.1.1.2.1.1.1.3">𝑗</ci></apply></list></apply></apply></apply></apply><apply id="S3.E4.m1.4.4e.cmml" xref="S3.E4.m1.4.4"><lt id="S3.E4.m1.4.4.7.cmml" xref="S3.E4.m1.4.4.7"></lt><share href="#S3.E4.m1.4.4.2.cmml" id="S3.E4.m1.4.4f.cmml" xref="S3.E4.m1.4.4"></share><apply id="S3.E4.m1.4.4.8.cmml" xref="S3.E4.m1.4.4.8"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.8.1.cmml" xref="S3.E4.m1.4.4.8">subscript</csymbol><ci id="S3.E4.m1.4.4.8.2.cmml" xref="S3.E4.m1.4.4.8.2">italic-ϵ</ci><cn type="integer" id="S3.E4.m1.4.4.8.3.cmml" xref="S3.E4.m1.4.4.8.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\frac{1}{N}\sum_{k}|\alpha^{i}_{k}-\alpha^{j}_{k}|&lt;\epsilon_{2}\rightarrow\left\|H_{i}(x;\theta_{i})-H_{j}(x;\theta_{j})\right\|&lt;\epsilon_{0}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS0.SSS0.Px4.p3" class="ltx_para">
<p id="S3.SS0.SSS0.Px4.p3.1" class="ltx_p">where <math id="S3.SS0.SSS0.Px4.p3.1.m1.1" class="ltx_Math" alttext="\epsilon_{2}" display="inline"><semantics id="S3.SS0.SSS0.Px4.p3.1.m1.1a"><msub id="S3.SS0.SSS0.Px4.p3.1.m1.1.1" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px4.p3.1.m1.1.1.2" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1.2.cmml">ϵ</mi><mn id="S3.SS0.SSS0.Px4.p3.1.m1.1.1.3" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p3.1.m1.1b"><apply id="S3.SS0.SSS0.Px4.p3.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p3.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px4.p3.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1.2">italic-ϵ</ci><cn type="integer" id="S3.SS0.SSS0.Px4.p3.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p3.1.m1.1c">\epsilon_{2}</annotation></semantics></math> is a threshold value.</p>
</div>
<div id="S3.SS0.SSS0.Px4.p4" class="ltx_para">
<p id="S3.SS0.SSS0.Px4.p4.1" class="ltx_p">This is because the soft-label distribution is determined by the learned feature representations and the decision boundaries in the classification task. If two identical models trained on datasets with differing data distributions produce similar soft-label distributions, then it suggests that they have learned similar decision boundaries, which in turn indicates that they have learned similar feature representations. In the evaluation section we first empirically test the conjectures and compare the proposed scheme against baseline FL aggregation methods.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Evaluation</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section we present experiments to demonstrate the viability of the proposed scheme. We first conduct empirical tests to evaluate our conjectures. Afterwards, we run FL experiments to compare our clustering scheme against strong baselines.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Testing Conjectures</span>
</h3>

<figure id="S4.F2" class="ltx_figure"><img src="/html/2312.17430/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="640" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparing CKA values for every layer of a pair of randomly selected models. Models 1a and 1b belong to the same cluster, whereas model 2a comes from a different cluster. Red diagonal highlights region where model layers intersect.</figcaption>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2312.17430/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Average Euclidean distance of latent space vectors among clients within stratified clusters vs. random clusters. Details of experiments A - F will be discussed in supplementary materials.</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2312.17430/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Comparing average relative entropy values of stratified samples vs. random samples over 500 communication rounds. The figure subtitles summarize the experiment settings (model - dataset - number of clients @ client sampling ratio)</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2312.17430/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_img_landscape" width="461" height="173" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Comparing performance of our work (LEFL) against FedAvg, FedProx FedNova and SCAFFOLD. Each experiment was conducted on a specified dataset using a predifined number of clients with a certain model and client sample ratio. The figure subtitles summarize the experiment settings (model - dataset - number of clients @ client sampling ratio). </figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.5" class="ltx_p">To test the conjectures, we designed a Federated Learning (FL) experiments involving <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">N</annotation></semantics></math> participating clients. We partitioned the CIFAR-10 train data in a non-independent and identically distributed manner among the clients. In particular we implemented label-based skews where clients are assigned samples of labels from the Dirichlet distribution (distribution-based label skew) and where clients have strict number of labels selected at random (quantity-based label skew) as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. At the start of the experiment, clients download a global model from the FL server and optimize it using their local dataset for 10 epochs. Afterwards, the clients use their model to make an inference on 1000 uniformly selected samples from a public dataset (TinyImageNet). The soft-label outputs from the client models is then used to construct a pairwise KL-based similarity matrix <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">M</annotation></semantics></math>, i.e., given models <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="m_{i}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">m</mi><mi id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝑚</ci><ci id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">m_{i}</annotation></semantics></math> and <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="m_{j}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">m</mi><mi id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">𝑚</ci><ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">m_{j}</annotation></semantics></math>, <math id="S4.SS1.p1.5.m5.2" class="ltx_math_unparsed" alttext="M[i][j]=\alpha^{i}_{j}=KL(p_{i}||p_{j})" display="inline"><semantics id="S4.SS1.p1.5.m5.2a"><mrow id="S4.SS1.p1.5.m5.2b"><mi id="S4.SS1.p1.5.m5.2.3">M</mi><mrow id="S4.SS1.p1.5.m5.2.4"><mo stretchy="false" id="S4.SS1.p1.5.m5.2.4.1">[</mo><mi id="S4.SS1.p1.5.m5.1.1">i</mi><mo stretchy="false" id="S4.SS1.p1.5.m5.2.4.2">]</mo></mrow><mrow id="S4.SS1.p1.5.m5.2.5"><mo stretchy="false" id="S4.SS1.p1.5.m5.2.5.1">[</mo><mi id="S4.SS1.p1.5.m5.2.2">j</mi><mo stretchy="false" id="S4.SS1.p1.5.m5.2.5.2">]</mo></mrow><mo id="S4.SS1.p1.5.m5.2.6">=</mo><msubsup id="S4.SS1.p1.5.m5.2.7"><mi id="S4.SS1.p1.5.m5.2.7.2.2">α</mi><mi id="S4.SS1.p1.5.m5.2.7.3">j</mi><mi id="S4.SS1.p1.5.m5.2.7.2.3">i</mi></msubsup><mo id="S4.SS1.p1.5.m5.2.8">=</mo><mi id="S4.SS1.p1.5.m5.2.9">K</mi><mi id="S4.SS1.p1.5.m5.2.10">L</mi><mrow id="S4.SS1.p1.5.m5.2.11"><mo stretchy="false" id="S4.SS1.p1.5.m5.2.11.1">(</mo><msub id="S4.SS1.p1.5.m5.2.11.2"><mi id="S4.SS1.p1.5.m5.2.11.2.2">p</mi><mi id="S4.SS1.p1.5.m5.2.11.2.3">i</mi></msub><mo fence="false" rspace="0.167em" stretchy="false" id="S4.SS1.p1.5.m5.2.11.3">|</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S4.SS1.p1.5.m5.2.11.4">|</mo><msub id="S4.SS1.p1.5.m5.2.11.5"><mi id="S4.SS1.p1.5.m5.2.11.5.2">p</mi><mi id="S4.SS1.p1.5.m5.2.11.5.3">j</mi></msub><mo stretchy="false" id="S4.SS1.p1.5.m5.2.11.6">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.2c">M[i][j]=\alpha^{i}_{j}=KL(p_{i}||p_{j})</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.5" class="ltx_p">In line with conjecture 2, we set out to test whether similar rows <math id="S4.SS1.p2.1.m1.4" class="ltx_Math" alttext="M[i],M[j]" display="inline"><semantics id="S4.SS1.p2.1.m1.4a"><mrow id="S4.SS1.p2.1.m1.4.4.2" xref="S4.SS1.p2.1.m1.4.4.3.cmml"><mrow id="S4.SS1.p2.1.m1.3.3.1.1" xref="S4.SS1.p2.1.m1.3.3.1.1.cmml"><mi id="S4.SS1.p2.1.m1.3.3.1.1.2" xref="S4.SS1.p2.1.m1.3.3.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.3.3.1.1.1" xref="S4.SS1.p2.1.m1.3.3.1.1.1.cmml">​</mo><mrow id="S4.SS1.p2.1.m1.3.3.1.1.3.2" xref="S4.SS1.p2.1.m1.3.3.1.1.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.3.3.1.1.3.2.1" xref="S4.SS1.p2.1.m1.3.3.1.1.3.1.1.cmml">[</mo><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS1.p2.1.m1.3.3.1.1.3.2.2" xref="S4.SS1.p2.1.m1.3.3.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo id="S4.SS1.p2.1.m1.4.4.2.3" xref="S4.SS1.p2.1.m1.4.4.3.cmml">,</mo><mrow id="S4.SS1.p2.1.m1.4.4.2.2" xref="S4.SS1.p2.1.m1.4.4.2.2.cmml"><mi id="S4.SS1.p2.1.m1.4.4.2.2.2" xref="S4.SS1.p2.1.m1.4.4.2.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.4.4.2.2.1" xref="S4.SS1.p2.1.m1.4.4.2.2.1.cmml">​</mo><mrow id="S4.SS1.p2.1.m1.4.4.2.2.3.2" xref="S4.SS1.p2.1.m1.4.4.2.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.4.4.2.2.3.2.1" xref="S4.SS1.p2.1.m1.4.4.2.2.3.1.1.cmml">[</mo><mi id="S4.SS1.p2.1.m1.2.2" xref="S4.SS1.p2.1.m1.2.2.cmml">j</mi><mo stretchy="false" id="S4.SS1.p2.1.m1.4.4.2.2.3.2.2" xref="S4.SS1.p2.1.m1.4.4.2.2.3.1.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.4b"><list id="S4.SS1.p2.1.m1.4.4.3.cmml" xref="S4.SS1.p2.1.m1.4.4.2"><apply id="S4.SS1.p2.1.m1.3.3.1.1.cmml" xref="S4.SS1.p2.1.m1.3.3.1.1"><times id="S4.SS1.p2.1.m1.3.3.1.1.1.cmml" xref="S4.SS1.p2.1.m1.3.3.1.1.1"></times><ci id="S4.SS1.p2.1.m1.3.3.1.1.2.cmml" xref="S4.SS1.p2.1.m1.3.3.1.1.2">𝑀</ci><apply id="S4.SS1.p2.1.m1.3.3.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.3.3.1.1.3.2"><csymbol cd="latexml" id="S4.SS1.p2.1.m1.3.3.1.1.3.1.1.cmml" xref="S4.SS1.p2.1.m1.3.3.1.1.3.2.1">delimited-[]</csymbol><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑖</ci></apply></apply><apply id="S4.SS1.p2.1.m1.4.4.2.2.cmml" xref="S4.SS1.p2.1.m1.4.4.2.2"><times id="S4.SS1.p2.1.m1.4.4.2.2.1.cmml" xref="S4.SS1.p2.1.m1.4.4.2.2.1"></times><ci id="S4.SS1.p2.1.m1.4.4.2.2.2.cmml" xref="S4.SS1.p2.1.m1.4.4.2.2.2">𝑀</ci><apply id="S4.SS1.p2.1.m1.4.4.2.2.3.1.cmml" xref="S4.SS1.p2.1.m1.4.4.2.2.3.2"><csymbol cd="latexml" id="S4.SS1.p2.1.m1.4.4.2.2.3.1.1.cmml" xref="S4.SS1.p2.1.m1.4.4.2.2.3.2.1">delimited-[]</csymbol><ci id="S4.SS1.p2.1.m1.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2">𝑗</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.4c">M[i],M[j]</annotation></semantics></math> indicate models <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="m_{i}" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><msub id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">m</mi><mi id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝑚</ci><ci id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">m_{i}</annotation></semantics></math> and <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="m_{j}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><msub id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">m</mi><mi id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑚</ci><ci id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">m_{j}</annotation></semantics></math> have learned similar high level features. To test this hypothesis, we clustered the client models into <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="log(N)" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mrow id="S4.SS1.p2.4.m4.1.2" xref="S4.SS1.p2.4.m4.1.2.cmml"><mi id="S4.SS1.p2.4.m4.1.2.2" xref="S4.SS1.p2.4.m4.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.4.m4.1.2.1" xref="S4.SS1.p2.4.m4.1.2.1.cmml">​</mo><mi id="S4.SS1.p2.4.m4.1.2.3" xref="S4.SS1.p2.4.m4.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.4.m4.1.2.1a" xref="S4.SS1.p2.4.m4.1.2.1.cmml">​</mo><mi id="S4.SS1.p2.4.m4.1.2.4" xref="S4.SS1.p2.4.m4.1.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.4.m4.1.2.1b" xref="S4.SS1.p2.4.m4.1.2.1.cmml">​</mo><mrow id="S4.SS1.p2.4.m4.1.2.5.2" xref="S4.SS1.p2.4.m4.1.2.cmml"><mo stretchy="false" id="S4.SS1.p2.4.m4.1.2.5.2.1" xref="S4.SS1.p2.4.m4.1.2.cmml">(</mo><mi id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">N</mi><mo stretchy="false" id="S4.SS1.p2.4.m4.1.2.5.2.2" xref="S4.SS1.p2.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.2.cmml" xref="S4.SS1.p2.4.m4.1.2"><times id="S4.SS1.p2.4.m4.1.2.1.cmml" xref="S4.SS1.p2.4.m4.1.2.1"></times><ci id="S4.SS1.p2.4.m4.1.2.2.cmml" xref="S4.SS1.p2.4.m4.1.2.2">𝑙</ci><ci id="S4.SS1.p2.4.m4.1.2.3.cmml" xref="S4.SS1.p2.4.m4.1.2.3">𝑜</ci><ci id="S4.SS1.p2.4.m4.1.2.4.cmml" xref="S4.SS1.p2.4.m4.1.2.4">𝑔</ci><ci id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">log(N)</annotation></semantics></math> groups by feeding <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mi id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><ci id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">M</annotation></semantics></math> to a KMeans model. This step groups together clients with similar rows in the similarity matrix. Next we used 1000 samples of CIFAR-10 test data to compute the latent space vectors produced by the models as well as the Centered Kernel Alignment (CKA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> values of the models for all layers. The latent space vectors were used to compute the average euclidean distance between the high level features of models within clusters. Similarly, CKA values were used to test similarities of learned features between inter-cluster and intra-cluster model pairs.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">As shown in Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the average euclidean distance of latent space vectors of models clustered using this scheme is smaller compared to models clustered randomly. This indicates despite the stochastic distribution of data among client datasets, the proposed scheme performs better at clustering models that have learned similar high level features. Experiments A - D of Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> were conducted on the CIFAR-10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> dataset while E and F were conducted on the EMNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> dataset. The details of the experiment will be included in the supplementary material.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">Moreover, Fig. <a href="#S4.F2" title="Figure 2 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> juxtaposes CKA heatmaps for a pair of randomly selected inter-cluster models against a pair of intra-cluster models. The experiments involve 20 clients with CIFAR-10 dataset and ResNet-18 models grouped into 5 clusters. CKA intensity values range from 0 (no similarity) to 1 (complete similarity) values. Identical models are characterized by intense values across a heatmap’s diagonal. The heatmaps suggest that while all pairs learned similar low level features (intense values in top left diagonal), the intra-cluster pairs additionally exhibit increased similarity in the latent layers of the model pairs (intense values in bottom right diagonal). In contrast, the inter-cluster pairs share a dark region in the latent layers. This indicates the utility of the similarity matrix in extracting similar models further reinforcing the proposed conjectures.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.2" class="ltx_p">Finally, we measure the relative entropy of sampled client datasets by applying stratified sampling across the client clusters and selecting a proportional number of clients from each cluster. As shown in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the sampled clients dataset <math id="S4.SS1.p5.1.m1.1" class="ltx_Math" alttext="D_{s}" display="inline"><semantics id="S4.SS1.p5.1.m1.1a"><msub id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml"><mi id="S4.SS1.p5.1.m1.1.1.2" xref="S4.SS1.p5.1.m1.1.1.2.cmml">D</mi><mi id="S4.SS1.p5.1.m1.1.1.3" xref="S4.SS1.p5.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><apply id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p5.1.m1.1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p5.1.m1.1.1.2.cmml" xref="S4.SS1.p5.1.m1.1.1.2">𝐷</ci><ci id="S4.SS1.p5.1.m1.1.1.3.cmml" xref="S4.SS1.p5.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">D_{s}</annotation></semantics></math> of the stratified samples maintains a relatively smaller relative entropy with respect to the global data distribution <math id="S4.SS1.p5.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS1.p5.2.m2.1a"><mi id="S4.SS1.p5.2.m2.1.1" xref="S4.SS1.p5.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><ci id="S4.SS1.p5.2.m2.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">D</annotation></semantics></math> as compared to uniform client samples of the same size. This proves the proposed scheme offers a means of selecting clients with better representative local data in each FL round.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Federated Learning Experiments</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We run several experiments on image classification datasets to test the performance of the client clustering scheme. In particular, we used the CIFAR-10, CIFAR-100, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and EMNIST datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">CIFAR-10 is a popular computer vision dataset that consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. The dataset is divided into two sets, a training set of 50,000 images and a test set of 10,000 images. Similarly, the CIFAR-100 dataset is an advanced version of the CIFAR-10 dataset which also consists of 60,000 32x32 color images. It contains 100 classes with 600 images per class. The dataset is also split into a training set of 50,000 images and a test set of 10,000 images. Each class in the dataset contains exactly 500 training images and 100 testing images.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">The EMNIST (short for Extended MNIST) dataset is a dataset of handwritten characters derived from the original MNIST dataset. It contains over 800,000 images, split into six different subsets. In our experiments, we consider the case where the dataset is split “byclass”, which has a total of 814,255 images of handwritten characters from 62 classes, including uppercase and lowercase letters, digits, and special characters.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.5" class="ltx_p">In all experiments, the datasets are partitioned in a non-iid manner. In particular, we utilize the benchmark from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> to apply distribution-based (labeldir) and quantity-based (labelX - where X is the number of unique labels per dataset) label skews. Distribution-based label skew divides the labels among clients, such that a proportion of the samples of each label is divided according to a Dirichlet distribution, i.e., each node <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mi id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><ci id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">v</annotation></semantics></math> is allotted <math id="S4.SS2.p4.2.m2.3" class="ltx_Math" alttext="p_{k,v}\sim Dir_{N}(\beta=0.5)" display="inline"><semantics id="S4.SS2.p4.2.m2.3a"><mrow id="S4.SS2.p4.2.m2.3.3" xref="S4.SS2.p4.2.m2.3.3.cmml"><msub id="S4.SS2.p4.2.m2.3.3.3" xref="S4.SS2.p4.2.m2.3.3.3.cmml"><mi id="S4.SS2.p4.2.m2.3.3.3.2" xref="S4.SS2.p4.2.m2.3.3.3.2.cmml">p</mi><mrow id="S4.SS2.p4.2.m2.2.2.2.4" xref="S4.SS2.p4.2.m2.2.2.2.3.cmml"><mi id="S4.SS2.p4.2.m2.1.1.1.1" xref="S4.SS2.p4.2.m2.1.1.1.1.cmml">k</mi><mo id="S4.SS2.p4.2.m2.2.2.2.4.1" xref="S4.SS2.p4.2.m2.2.2.2.3.cmml">,</mo><mi id="S4.SS2.p4.2.m2.2.2.2.2" xref="S4.SS2.p4.2.m2.2.2.2.2.cmml">v</mi></mrow></msub><mo id="S4.SS2.p4.2.m2.3.3.2" xref="S4.SS2.p4.2.m2.3.3.2.cmml">∼</mo><mrow id="S4.SS2.p4.2.m2.3.3.1" xref="S4.SS2.p4.2.m2.3.3.1.cmml"><mi id="S4.SS2.p4.2.m2.3.3.1.3" xref="S4.SS2.p4.2.m2.3.3.1.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.3.3.1.2" xref="S4.SS2.p4.2.m2.3.3.1.2.cmml">​</mo><mi id="S4.SS2.p4.2.m2.3.3.1.4" xref="S4.SS2.p4.2.m2.3.3.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.3.3.1.2a" xref="S4.SS2.p4.2.m2.3.3.1.2.cmml">​</mo><msub id="S4.SS2.p4.2.m2.3.3.1.5" xref="S4.SS2.p4.2.m2.3.3.1.5.cmml"><mi id="S4.SS2.p4.2.m2.3.3.1.5.2" xref="S4.SS2.p4.2.m2.3.3.1.5.2.cmml">r</mi><mi id="S4.SS2.p4.2.m2.3.3.1.5.3" xref="S4.SS2.p4.2.m2.3.3.1.5.3.cmml">N</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.3.3.1.2b" xref="S4.SS2.p4.2.m2.3.3.1.2.cmml">​</mo><mrow id="S4.SS2.p4.2.m2.3.3.1.1.1" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p4.2.m2.3.3.1.1.1.2" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p4.2.m2.3.3.1.1.1.1" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.cmml"><mi id="S4.SS2.p4.2.m2.3.3.1.1.1.1.2" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.2.cmml">β</mi><mo id="S4.SS2.p4.2.m2.3.3.1.1.1.1.1" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.p4.2.m2.3.3.1.1.1.1.3" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.3.cmml">0.5</mn></mrow><mo stretchy="false" id="S4.SS2.p4.2.m2.3.3.1.1.1.3" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.3b"><apply id="S4.SS2.p4.2.m2.3.3.cmml" xref="S4.SS2.p4.2.m2.3.3"><csymbol cd="latexml" id="S4.SS2.p4.2.m2.3.3.2.cmml" xref="S4.SS2.p4.2.m2.3.3.2">similar-to</csymbol><apply id="S4.SS2.p4.2.m2.3.3.3.cmml" xref="S4.SS2.p4.2.m2.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.3.3.3.1.cmml" xref="S4.SS2.p4.2.m2.3.3.3">subscript</csymbol><ci id="S4.SS2.p4.2.m2.3.3.3.2.cmml" xref="S4.SS2.p4.2.m2.3.3.3.2">𝑝</ci><list id="S4.SS2.p4.2.m2.2.2.2.3.cmml" xref="S4.SS2.p4.2.m2.2.2.2.4"><ci id="S4.SS2.p4.2.m2.1.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1.1.1">𝑘</ci><ci id="S4.SS2.p4.2.m2.2.2.2.2.cmml" xref="S4.SS2.p4.2.m2.2.2.2.2">𝑣</ci></list></apply><apply id="S4.SS2.p4.2.m2.3.3.1.cmml" xref="S4.SS2.p4.2.m2.3.3.1"><times id="S4.SS2.p4.2.m2.3.3.1.2.cmml" xref="S4.SS2.p4.2.m2.3.3.1.2"></times><ci id="S4.SS2.p4.2.m2.3.3.1.3.cmml" xref="S4.SS2.p4.2.m2.3.3.1.3">𝐷</ci><ci id="S4.SS2.p4.2.m2.3.3.1.4.cmml" xref="S4.SS2.p4.2.m2.3.3.1.4">𝑖</ci><apply id="S4.SS2.p4.2.m2.3.3.1.5.cmml" xref="S4.SS2.p4.2.m2.3.3.1.5"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.3.3.1.5.1.cmml" xref="S4.SS2.p4.2.m2.3.3.1.5">subscript</csymbol><ci id="S4.SS2.p4.2.m2.3.3.1.5.2.cmml" xref="S4.SS2.p4.2.m2.3.3.1.5.2">𝑟</ci><ci id="S4.SS2.p4.2.m2.3.3.1.5.3.cmml" xref="S4.SS2.p4.2.m2.3.3.1.5.3">𝑁</ci></apply><apply id="S4.SS2.p4.2.m2.3.3.1.1.1.1.cmml" xref="S4.SS2.p4.2.m2.3.3.1.1.1"><eq id="S4.SS2.p4.2.m2.3.3.1.1.1.1.1.cmml" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.1"></eq><ci id="S4.SS2.p4.2.m2.3.3.1.1.1.1.2.cmml" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.2">𝛽</ci><cn type="float" id="S4.SS2.p4.2.m2.3.3.1.1.1.1.3.cmml" xref="S4.SS2.p4.2.m2.3.3.1.1.1.1.3">0.5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.3c">p_{k,v}\sim Dir_{N}(\beta=0.5)</annotation></semantics></math> proportion of the instances of class <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mi id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><ci id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">k</annotation></semantics></math>. Here, a concentration parameter <math id="S4.SS2.p4.4.m4.2" class="ltx_Math" alttext="\beta\in[0,1]" display="inline"><semantics id="S4.SS2.p4.4.m4.2a"><mrow id="S4.SS2.p4.4.m4.2.3" xref="S4.SS2.p4.4.m4.2.3.cmml"><mi id="S4.SS2.p4.4.m4.2.3.2" xref="S4.SS2.p4.4.m4.2.3.2.cmml">β</mi><mo id="S4.SS2.p4.4.m4.2.3.1" xref="S4.SS2.p4.4.m4.2.3.1.cmml">∈</mo><mrow id="S4.SS2.p4.4.m4.2.3.3.2" xref="S4.SS2.p4.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS2.p4.4.m4.2.3.3.2.1" xref="S4.SS2.p4.4.m4.2.3.3.1.cmml">[</mo><mn id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml">0</mn><mo id="S4.SS2.p4.4.m4.2.3.3.2.2" xref="S4.SS2.p4.4.m4.2.3.3.1.cmml">,</mo><mn id="S4.SS2.p4.4.m4.2.2" xref="S4.SS2.p4.4.m4.2.2.cmml">1</mn><mo stretchy="false" id="S4.SS2.p4.4.m4.2.3.3.2.3" xref="S4.SS2.p4.4.m4.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.2b"><apply id="S4.SS2.p4.4.m4.2.3.cmml" xref="S4.SS2.p4.4.m4.2.3"><in id="S4.SS2.p4.4.m4.2.3.1.cmml" xref="S4.SS2.p4.4.m4.2.3.1"></in><ci id="S4.SS2.p4.4.m4.2.3.2.cmml" xref="S4.SS2.p4.4.m4.2.3.2">𝛽</ci><interval closure="closed" id="S4.SS2.p4.4.m4.2.3.3.1.cmml" xref="S4.SS2.p4.4.m4.2.3.3.2"><cn type="integer" id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1">0</cn><cn type="integer" id="S4.SS2.p4.4.m4.2.2.cmml" xref="S4.SS2.p4.4.m4.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.2c">\beta\in[0,1]</annotation></semantics></math> will determine the amount by which the labels are skewed. The smaller the value of <math id="S4.SS2.p4.5.m5.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p4.5.m5.1a"><mi id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><ci id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">\beta</annotation></semantics></math>, the higher the non-iid skew. The quantity-based label sets a hard limit on the number of labels each client possesses. In our EMNIST experiments for instance we specified skew value to label15 to specify that each client only possesses 15 labels out of a total of 62 labels found in the dataset.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">In the CIFAR-10 experiments, each client is equipped with ResNet-20 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, EfficientNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and MobileNet_v3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> models whereas in the EMNIST experiments clients deployed a 3-layer FFNN, with 784, 128 and 62 neurons. In each training round, the server samples a specified number of clients whose task is to download the latest global model, optimize it with their local datasets and upload the model parameters back to the server. For our proposed scheme, we utlize 1000 uniformly selected samples of TinyImagenet and FashionMNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> as global data when conducting CIFAR and EMNIST experiments respectively. As such, the global data used to compute the similarity matrix is derived from a different distribution. We examine the effect of our clustering scheme under different sampling ratios and evaluate both the convergence speed and accuracy as well as the communication cost to reach a specified target accuracy below.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.5.1.1" class="ltx_text">IV-B</span>1 </span>Convergence Analysis</h4>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparing communication cost to reach a target accuracy of 70% and 40%.</figcaption>
<div id="S4.T1.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:192.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-148.9pt,66.0pt) scale(0.592788081408641,0.592788081408641) ;">
<table id="S4.T1.5.5" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.5.5.6" class="ltx_tr">
<td id="S4.T1.5.5.6.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T1.5.5.6.1.1" class="ltx_text ltx_font_bold">Dataset, Model</span></td>
<td id="S4.T1.5.5.6.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T1.5.5.6.2.1" class="ltx_text ltx_font_bold">Target Accuracy</span></td>
<td id="S4.T1.5.5.6.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T1.5.5.6.3.1" class="ltx_text">
<span id="S4.T1.5.5.6.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.5.5.6.3.1.1.1" class="ltx_tr">
<span id="S4.T1.5.5.6.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.5.5.6.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Algorithm</span></span></span>
</span></span></td>
<td id="S4.T1.5.5.6.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T1.5.5.6.4.1" class="ltx_text ltx_font_bold">Communication Rounds</span></td>
<td id="S4.T1.5.5.6.5" class="ltx_td ltx_align_center ltx_border_t" colspan="3"><span id="S4.T1.5.5.6.5.1" class="ltx_text ltx_font_bold">Communication Cost</span></td>
<td id="S4.T1.5.5.6.6" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S4.T1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.2" class="ltx_td"></td>
<td id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Round/Client</span></td>
<td id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center">
<math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\Delta</annotation></semantics></math><span id="S4.T1.1.1.1.1.1" class="ltx_text ltx_font_bold"> Cost</span>
</td>
</tr>
<tr id="S4.T1.5.5.7" class="ltx_tr">
<td id="S4.T1.5.5.7.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="5"><span id="S4.T1.5.5.7.1.1" class="ltx_text"><span id="S4.T1.5.5.7.1.1.1" class="ltx_text"></span> <span id="S4.T1.5.5.7.1.1.2" class="ltx_text">
<span id="S4.T1.5.5.7.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.5.5.7.1.1.2.1.1" class="ltx_tr">
<span id="S4.T1.5.5.7.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">CIFAR-10</span></span>
<span id="S4.T1.5.5.7.1.1.2.1.2" class="ltx_tr">
<span id="S4.T1.5.5.7.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">100 clients</span></span>
<span id="S4.T1.5.5.7.1.1.2.1.3" class="ltx_tr">
<span id="S4.T1.5.5.7.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">10% sample ratio</span></span>
<span id="S4.T1.5.5.7.1.1.2.1.4" class="ltx_tr">
<span id="S4.T1.5.5.7.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center">ResNet-20</span></span>
</span></span> <span id="S4.T1.5.5.7.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T1.5.5.7.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="5"><span id="S4.T1.5.5.7.2.1" class="ltx_text">70%</span></td>
<td id="S4.T1.5.5.7.3" class="ltx_td ltx_align_center ltx_border_t">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T1.5.5.7.4" class="ltx_td ltx_align_center ltx_border_t">256</td>
<td id="S4.T1.5.5.7.5" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.5.5.7.6" class="ltx_td ltx_align_center ltx_border_t">2.1MB</td>
<td id="S4.T1.5.5.7.7" class="ltx_td ltx_align_center ltx_border_t">5.2GB</td>
<td id="S4.T1.5.5.7.8" class="ltx_td ltx_align_center ltx_border_t">0</td>
</tr>
<tr id="S4.T1.5.5.8" class="ltx_tr">
<td id="S4.T1.5.5.8.1" class="ltx_td ltx_align_center">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S4.T1.5.5.8.2" class="ltx_td ltx_align_center">294</td>
<td id="S4.T1.5.5.8.3" class="ltx_td"></td>
<td id="S4.T1.5.5.8.4" class="ltx_td ltx_align_center">2.1MB</td>
<td id="S4.T1.5.5.8.5" class="ltx_td ltx_align_center">6.02GB</td>
<td id="S4.T1.5.5.8.6" class="ltx_td ltx_align_center">+0.82GB</td>
</tr>
<tr id="S4.T1.5.5.9" class="ltx_tr">
<td id="S4.T1.5.5.9.1" class="ltx_td ltx_align_center">SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T1.5.5.9.2" class="ltx_td ltx_align_center">234</td>
<td id="S4.T1.5.5.9.3" class="ltx_td"></td>
<td id="S4.T1.5.5.9.4" class="ltx_td ltx_align_center">4.3MB</td>
<td id="S4.T1.5.5.9.5" class="ltx_td ltx_align_center">9.8GB</td>
<td id="S4.T1.5.5.9.6" class="ltx_td ltx_align_center">+4.6GB</td>
</tr>
<tr id="S4.T1.5.5.10" class="ltx_tr">
<td id="S4.T1.5.5.10.1" class="ltx_td ltx_align_center">FedNova <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S4.T1.5.5.10.2" class="ltx_td ltx_align_center">221</td>
<td id="S4.T1.5.5.10.3" class="ltx_td"></td>
<td id="S4.T1.5.5.10.4" class="ltx_td ltx_align_center">4.2MB</td>
<td id="S4.T1.5.5.10.5" class="ltx_td ltx_align_center">9.06GB</td>
<td id="S4.T1.5.5.10.6" class="ltx_td ltx_align_center">+3.86GB</td>
</tr>
<tr id="S4.T1.2.2.2" class="ltx_tr">
<td id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center">LEFL (Ours)</td>
<td id="S4.T1.2.2.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.2.2.2.3.1" class="ltx_text ltx_font_bold">69</span></td>
<td id="S4.T1.2.2.2.4" class="ltx_td"></td>
<td id="S4.T1.2.2.2.5" class="ltx_td ltx_align_center">2.1MB</td>
<td id="S4.T1.2.2.2.1" class="ltx_td ltx_align_center">1.4GB + 208MB<sup id="S4.T1.2.2.2.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S4.T1.2.2.2.6" class="ltx_td ltx_align_center"><span id="S4.T1.2.2.2.6.1" class="ltx_text ltx_font_bold">-3.78GB</span></td>
</tr>
<tr id="S4.T1.5.5.11" class="ltx_tr">
<td id="S4.T1.5.5.11.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="5"><span id="S4.T1.5.5.11.1.1" class="ltx_text"><span id="S4.T1.5.5.11.1.1.1" class="ltx_text"></span> <span id="S4.T1.5.5.11.1.1.2" class="ltx_text">
<span id="S4.T1.5.5.11.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.5.5.11.1.1.2.1.1" class="ltx_tr">
<span id="S4.T1.5.5.11.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">CIFAR-100</span></span>
<span id="S4.T1.5.5.11.1.1.2.1.2" class="ltx_tr">
<span id="S4.T1.5.5.11.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">100 clients</span></span>
<span id="S4.T1.5.5.11.1.1.2.1.3" class="ltx_tr">
<span id="S4.T1.5.5.11.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">10% sample ratio</span></span>
<span id="S4.T1.5.5.11.1.1.2.1.4" class="ltx_tr">
<span id="S4.T1.5.5.11.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center">ResNet-20</span></span>
</span></span> <span id="S4.T1.5.5.11.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T1.5.5.11.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="5"><span id="S4.T1.5.5.11.2.1" class="ltx_text">40%</span></td>
<td id="S4.T1.5.5.11.3" class="ltx_td ltx_align_center ltx_border_t">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T1.5.5.11.4" class="ltx_td ltx_align_center ltx_border_t">421</td>
<td id="S4.T1.5.5.11.5" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.5.5.11.6" class="ltx_td ltx_align_center ltx_border_t">2.1MB</td>
<td id="S4.T1.5.5.11.7" class="ltx_td ltx_align_center ltx_border_t">8.6GB</td>
<td id="S4.T1.5.5.11.8" class="ltx_td ltx_align_center ltx_border_t">0</td>
</tr>
<tr id="S4.T1.5.5.12" class="ltx_tr">
<td id="S4.T1.5.5.12.1" class="ltx_td ltx_align_center">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S4.T1.5.5.12.2" class="ltx_td ltx_align_center">&gt;500</td>
<td id="S4.T1.5.5.12.3" class="ltx_td"></td>
<td id="S4.T1.5.5.12.4" class="ltx_td ltx_align_center">2.1MB</td>
<td id="S4.T1.5.5.12.5" class="ltx_td ltx_align_center">&gt;10.2GB</td>
<td id="S4.T1.5.5.12.6" class="ltx_td ltx_align_center">&gt;+1.6GB</td>
</tr>
<tr id="S4.T1.5.5.13" class="ltx_tr">
<td id="S4.T1.5.5.13.1" class="ltx_td ltx_align_center">SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T1.5.5.13.2" class="ltx_td ltx_align_center">294</td>
<td id="S4.T1.5.5.13.3" class="ltx_td"></td>
<td id="S4.T1.5.5.13.4" class="ltx_td ltx_align_center">4.3MB</td>
<td id="S4.T1.5.5.13.5" class="ltx_td ltx_align_center">12.3GB</td>
<td id="S4.T1.5.5.13.6" class="ltx_td ltx_align_center">+3.7GB</td>
</tr>
<tr id="S4.T1.5.5.14" class="ltx_tr">
<td id="S4.T1.5.5.14.1" class="ltx_td ltx_align_center">FedNova <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S4.T1.5.5.14.2" class="ltx_td ltx_align_center">419</td>
<td id="S4.T1.5.5.14.3" class="ltx_td"></td>
<td id="S4.T1.5.5.14.4" class="ltx_td ltx_align_center">4.2MB</td>
<td id="S4.T1.5.5.14.5" class="ltx_td ltx_align_center">17.18GB</td>
<td id="S4.T1.5.5.14.6" class="ltx_td ltx_align_center">+8.5GB</td>
</tr>
<tr id="S4.T1.3.3.3" class="ltx_tr">
<td id="S4.T1.3.3.3.2" class="ltx_td ltx_align_center">LEFL (Ours)</td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.3.3.1" class="ltx_text ltx_font_bold">79</span></td>
<td id="S4.T1.3.3.3.4" class="ltx_td"></td>
<td id="S4.T1.3.3.3.5" class="ltx_td ltx_align_center">2.1MB</td>
<td id="S4.T1.3.3.3.1" class="ltx_td ltx_align_center">1.62GB + 208MB<sup id="S4.T1.3.3.3.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S4.T1.3.3.3.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.3.6.1" class="ltx_text ltx_font_bold">-6.9GB</span></td>
</tr>
<tr id="S4.T1.5.5.15" class="ltx_tr">
<td id="S4.T1.5.5.15.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="5"><span id="S4.T1.5.5.15.1.1" class="ltx_text"><span id="S4.T1.5.5.15.1.1.1" class="ltx_text"></span> <span id="S4.T1.5.5.15.1.1.2" class="ltx_text">
<span id="S4.T1.5.5.15.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.5.5.15.1.1.2.1.1" class="ltx_tr">
<span id="S4.T1.5.5.15.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">EMNIST</span></span>
<span id="S4.T1.5.5.15.1.1.2.1.2" class="ltx_tr">
<span id="S4.T1.5.5.15.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">1000 clients</span></span>
<span id="S4.T1.5.5.15.1.1.2.1.3" class="ltx_tr">
<span id="S4.T1.5.5.15.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">1% sample ratio</span></span>
<span id="S4.T1.5.5.15.1.1.2.1.4" class="ltx_tr">
<span id="S4.T1.5.5.15.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center">3-layer FFNN</span></span>
</span></span> <span id="S4.T1.5.5.15.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T1.5.5.15.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="5"><span id="S4.T1.5.5.15.2.1" class="ltx_text">70%</span></td>
<td id="S4.T1.5.5.15.3" class="ltx_td ltx_align_center ltx_border_t">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T1.5.5.15.4" class="ltx_td ltx_align_center ltx_border_t">224</td>
<td id="S4.T1.5.5.15.5" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.5.5.15.6" class="ltx_td ltx_align_center ltx_border_t">0.41MB</td>
<td id="S4.T1.5.5.15.7" class="ltx_td ltx_align_center ltx_border_t">0.89GB</td>
<td id="S4.T1.5.5.15.8" class="ltx_td ltx_align_center ltx_border_t">0</td>
</tr>
<tr id="S4.T1.5.5.16" class="ltx_tr">
<td id="S4.T1.5.5.16.1" class="ltx_td ltx_align_center">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S4.T1.5.5.16.2" class="ltx_td ltx_align_center">372</td>
<td id="S4.T1.5.5.16.3" class="ltx_td"></td>
<td id="S4.T1.5.5.16.4" class="ltx_td ltx_align_center">0.41MB</td>
<td id="S4.T1.5.5.16.5" class="ltx_td ltx_align_center">1.48GB</td>
<td id="S4.T1.5.5.16.6" class="ltx_td ltx_align_center">+0.59GB</td>
</tr>
<tr id="S4.T1.5.5.17" class="ltx_tr">
<td id="S4.T1.5.5.17.1" class="ltx_td ltx_align_center">SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T1.5.5.17.2" class="ltx_td ltx_align_center">174</td>
<td id="S4.T1.5.5.17.3" class="ltx_td"></td>
<td id="S4.T1.5.5.17.4" class="ltx_td ltx_align_center">0.83MB</td>
<td id="S4.T1.5.5.17.5" class="ltx_td ltx_align_center">1.41GB</td>
<td id="S4.T1.5.5.17.6" class="ltx_td ltx_align_center">+0.52GB</td>
</tr>
<tr id="S4.T1.5.5.18" class="ltx_tr">
<td id="S4.T1.5.5.18.1" class="ltx_td ltx_align_center">FedNova <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S4.T1.5.5.18.2" class="ltx_td ltx_align_center">236</td>
<td id="S4.T1.5.5.18.3" class="ltx_td"></td>
<td id="S4.T1.5.5.18.4" class="ltx_td ltx_align_center">0.82MB</td>
<td id="S4.T1.5.5.18.5" class="ltx_td ltx_align_center">1.88GB</td>
<td id="S4.T1.5.5.18.6" class="ltx_td ltx_align_center">+0.99GB</td>
</tr>
<tr id="S4.T1.4.4.4" class="ltx_tr">
<td id="S4.T1.4.4.4.2" class="ltx_td ltx_align_center">LEFL (Ours)</td>
<td id="S4.T1.4.4.4.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.3.1" class="ltx_text ltx_font_bold">29</span></td>
<td id="S4.T1.4.4.4.4" class="ltx_td"></td>
<td id="S4.T1.4.4.4.5" class="ltx_td ltx_align_center">0.41MB</td>
<td id="S4.T1.4.4.4.1" class="ltx_td ltx_align_center">0.11GB + 0.8GB<sup id="S4.T1.4.4.4.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S4.T1.4.4.4.6" class="ltx_td ltx_align_center">+0.02GB</td>
</tr>
<tr id="S4.T1.5.5.5" class="ltx_tr">
<td id="S4.T1.5.5.5.1" class="ltx_td ltx_align_left ltx_border_t" colspan="7">
<sup id="S4.T1.5.5.5.1.1" class="ltx_sup">∗</sup> values show additional download/upload of public dataset and soft-labels required by our method.</td>
<td id="S4.T1.5.5.5.2" class="ltx_td ltx_border_t"></td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.2" class="ltx_p">We run experiments for a specified number of rounds (eg. 500) to compare the convergence speed and convergence accuracies of the competing algorithms. All experiments used local training epochs <math id="S4.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="E_{p}=10" display="inline"><semantics id="S4.SS2.SSS1.p1.1.m1.1a"><mrow id="S4.SS2.SSS1.p1.1.m1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.cmml"><msub id="S4.SS2.SSS1.p1.1.m1.1.1.2" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml"><mi id="S4.SS2.SSS1.p1.1.m1.1.1.2.2" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.2.cmml">E</mi><mi id="S4.SS2.SSS1.p1.1.m1.1.1.2.3" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.3.cmml">p</mi></msub><mo id="S4.SS2.SSS1.p1.1.m1.1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS1.p1.1.m1.1.1.3" xref="S4.SS2.SSS1.p1.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.1.m1.1b"><apply id="S4.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1"><eq id="S4.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.1"></eq><apply id="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS1.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.2">𝐸</ci><ci id="S4.SS2.SSS1.p1.1.m1.1.1.2.3.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.3">𝑝</ci></apply><cn type="integer" id="S4.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.1.m1.1c">E_{p}=10</annotation></semantics></math>. Here, we wanted to see how the dataset complexity, data heterogeneity and sampling ratios affected convergence. As such, we experimented with different datasets with high (70%), medium (10%) and low (1%) client sampling. Similarly, we experimented with both distribution-based and quantity-based label skews. We used <math id="S4.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="S4.SS2.SSS1.p1.2.m2.1a"><mrow id="S4.SS2.SSS1.p1.2.m2.1.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS1.p1.2.m2.1.1.2" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.cmml">β</mi><mo id="S4.SS2.SSS1.p1.2.m2.1.1.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS1.p1.2.m2.1.1.3" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.2.m2.1b"><apply id="S4.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1"><eq id="S4.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.1"></eq><ci id="S4.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.2">𝛽</ci><cn type="float" id="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.2.m2.1c">\beta=0.5</annotation></semantics></math> for our distribution-based skew and label15 for the quantity based skew, i.e, each client in this setting will possess a maximum of 15 labels.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">In the ResNet-20 experiments, we used both CIFAR-10 and CIFAR-100 datasets. Each client used SGD with learning rate of 0.01 and weight decay rate of 0.99. We tested medium and high sample rates for clients of size 100 and 50 respectively. As shown in the first row of Fig.  <a href="#S4.F5" title="Figure 5 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, our approach significantly improves the convergence speed while achieving an accuracy boost of 6% in the CIFAR-10 100 clients experiment and 7.4% in the CIFAR-100 100 client experiment.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p">We conducted two experiments using the EMNIST dataset on 1000 clients and a sample rate of 1% as shown in the first two plots of the second row in Fig.  <a href="#S4.F5" title="Figure 5 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We applied a distribution-based label skew (labeldir) in the first case and a quantity-based label skew (label15) in the latter. We used a 3-layer FFNN with an SGD optimizer, a learning rate of 0.01 and decay rate of 0.99. This experiment not only presents a small learning rate, but also a large number of participants which could potentially gain the most from stratified sampling. We observed an increase of 5% and 6% compared to SCAFFOLD for experiments one and two respectively.</p>
</div>
<div id="S4.SS2.SSS1.p4" class="ltx_para">
<p id="S4.SS2.SSS1.p4.3" class="ltx_p">Finally, we compared our scheme using MobileNet_v3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and EfficientNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> on the CIFAR-10 dataset. We used 30 clients and 10% sample rate in all experiments. We kept the hyperparameters the same as the previous experiments. While the MobileNet_v3 experiment yielded a 2.4% increase, the EfficientNet experiments yielded a 1.3% increase compared to FedNova. SCAFFOLD diverged in both cases as shown in the last two plots of the second row in Fig.  <a href="#S4.F5" title="Figure 5 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Overall, the EfficientNet and MobileNet_v3 experiments showed a drop in performance for all algorithms due to increased model size which led to client models overfitting local data. In particular, while the ResNet-20 model we implemented was only about <math id="S4.SS2.SSS1.p4.1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S4.SS2.SSS1.p4.1.m1.1a"><mo id="S4.SS2.SSS1.p4.1.m1.1.1" xref="S4.SS2.SSS1.p4.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.1.m1.1b"><approx id="S4.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p4.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.1.m1.1c">\approx</annotation></semantics></math>1MB in size, the MobileNet_v3 was <math id="S4.SS2.SSS1.p4.2.m2.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S4.SS2.SSS1.p4.2.m2.1a"><mo id="S4.SS2.SSS1.p4.2.m2.1.1" xref="S4.SS2.SSS1.p4.2.m2.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.2.m2.1b"><approx id="S4.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p4.2.m2.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.2.m2.1c">\approx</annotation></semantics></math>5MB and the EfficientNet was <math id="S4.SS2.SSS1.p4.3.m3.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S4.SS2.SSS1.p4.3.m3.1a"><mo id="S4.SS2.SSS1.p4.3.m3.1.1" xref="S4.SS2.SSS1.p4.3.m3.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p4.3.m3.1b"><approx id="S4.SS2.SSS1.p4.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p4.3.m3.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p4.3.m3.1c">\approx</annotation></semantics></math>15MB. Despite this, our method displayed marginal improvement.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.5.1.1" class="ltx_text">IV-B</span>2 </span>Communication Overhead</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">In addition to improved convergence accuracy, our proposed scheme exhibits quicker convergence which translates into reduced communication overhead. To measure communication overhead, we count the number of rounds it takes the competing algorithms to achieve a specified target accuracy in Table <a href="#S4.T1" title="TABLE I ‣ IV-B1 Convergence Analysis ‣ IV-B Federated Learning Experiments ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. We also measure the communication cost (<math id="S4.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.SS2.SSS2.p1.1.m1.1a"><mi mathvariant="normal" id="S4.SS2.SSS2.p1.1.m1.1.1" xref="S4.SS2.SSS2.p1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.1.m1.1b"><ci id="S4.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.1.m1.1c">\Delta</annotation></semantics></math> Cost) relative to the FedAvg algorithm. This gives us a good idea of how much communication overhead all algorithms are incurring.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">We present three scenarios using the CIFAR-10, CIFAR-100 and EMNIST datasets. In the CIFAR experiments, we deploy 100 clients with ResNet-20 models and apply a client sample rate of 10%. In the EMNIST experiment, we deploy 1000 clients using a 3-layer FFNN model and a client sample rate of 1%. In all three cases, our proposed method achieves the target accuracy in significantly fewer number of rounds. Consequently, the proposed solution saved an extra 3.78GB and a 6.9GB worth of communication for the CIFAR-10 and CIFAR-100 experiments respectively. For the EMNIST experiments however, despite converging significantly faster, there was still a 0.02GB additional communication cost incurred as a result of the large number of clients and a relatively smaller model size. This cost was incurred when downloading the 1000 sample sized public dataset which was relatively large. Such scenarios will require a smaller public dataset, for instance, just having 100 samples. But in practice, this might not be an issue as FL models will likely be large deep learning models that are several times larger than the unlabeled public dataset.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Ablation Study</span>
</h2>

<figure id="S5.F6" class="ltx_figure"><img src="/html/2312.17430/assets/x6.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="184" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparing euclidean distance and average relative entropy for the manually partitioned quantity-based label skew. The relative entropy was measured for 10 rounds as opposed to the experiments in the main paper that were run for 500 rounds.</figcaption>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We experimented with manual data split involving 24 models. Similar to the previous experiment, we applied a quantity based skew where the first two labels of the CIFAR-10 dataset were divided amongst 5 nodes, the next 2 labels among another 5 nodes, and so on, until the last pair of labels was divided among the remaining 4 nodes. As expected, we observed that the clustering scheme was able to group the clients that contained the same labels. The CKA values of two randomly selected model pairs in this experiment are presented in the last row of Fig. <a href="#S4.F2" title="Figure 2 ‣ IV-A Testing Conjectures ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (i.e. Quantity-based label skew (manual)). The heatmaps exhibit a similar pattern as the examples in the main section. As shown in Fig. <a href="#S5.F6" title="Figure 6 ‣ V Ablation Study ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> the average euclidean distance between the models inside the clusters vs models from random clusters has a wide gap. This can be attributed to the clustering scheme correctly classifying the models. The average relative entropy of our sampling strategy is also close to 0 whereas a random sampling strategy yields a much higher relative relative entropy.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Limitations</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we make assumptions such as the uniformity of the participating client architectures and loss functions. Hence, these assumptions may not hold under system heterogeneity where client architectures vary. As such an alternative approach has to be taken such as utilizing knowledge distillation and a common knowledge network that serves as an intermediary among clients such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">As discussed in the introduction, the primary objective of this work is to implement a representative (stratified) client sampling in FL without compromising client data privacy. Selecting client samples with representative data reduces the chances of aggregating biased gradients and gradient drift. However, the server has no way of knowing client data, thus it cannot conduct stratified client sampling. In light of this, we proposed clustering clients based on their models learned high-level features. We empirically demonstrated that clustering models based on learned high-level features can help yield client samples with low relative entropy with respect to the global data distribution, i.e., it can improve the representativeness of the sampled clients dataset. However, computing the learned high-level features and comparing them against each other is an expensive task. A naive approach may require all clients to upload their models after the first FL round and make <math id="S7.p1.1.m1.1" class="ltx_Math" alttext="n^{2}" display="inline"><semantics id="S7.p1.1.m1.1a"><msup id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml"><mi id="S7.p1.1.m1.1.1.2" xref="S7.p1.1.m1.1.1.2.cmml">n</mi><mn id="S7.p1.1.m1.1.1.3" xref="S7.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><apply id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S7.p1.1.m1.1.1.1.cmml" xref="S7.p1.1.m1.1.1">superscript</csymbol><ci id="S7.p1.1.m1.1.1.2.cmml" xref="S7.p1.1.m1.1.1.2">𝑛</ci><cn type="integer" id="S7.p1.1.m1.1.1.3.cmml" xref="S7.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">n^{2}</annotation></semantics></math> model comparisons. This, however, is impractical especially under a cross-device FL setting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> which could possibly involve hundreds of thousands or even millions of client devices.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">In this paper, we first showed that clustering clients based on the learned high-level features can improve the representativeness of sampled client data. Next we proposed an affordable means of computing and comparing the learned high-level features via the soft-labels and similarity matrix. A small public dataset from a completely different distribution can be downloaded by all clients during initial contact. Similarly, uploading soft-labels back to the server is significantly cheaper than communicating the parameters of a large neural network. In Table <a href="#S4.T1" title="TABLE I ‣ IV-B1 Convergence Analysis ‣ IV-B Federated Learning Experiments ‣ IV Evaluation ‣ LEFL: Low Entropy Client Sampling in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, we show the extra upload/download cost incurred by the experiments are minimal.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">Finally, the convergence experiments we conducted demonstrate that applying stratified client sampling using our method considerably improves the convergence and accuracy of the global model even against strong baselines like SCAFFOLD. Moreover, the number of rounds it takes to achieve a target accuracy is much fewer thus significantly decreasing the communication overhead and overall computational expense.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Waqwoya Abebe and Ali Jannesari.

</span>
<span class="ltx_bibblock">Optimizing decentralized learning with local heterogeneity using topology morphing and clustering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)</span>, pages 355–366. IEEE, 2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Yae Jee Cho, Jianyu Wang, and Gauri Joshi.

</span>
<span class="ltx_bibblock">Client selection in federated learning: Convergence analysis and power-of-choice selection strategies.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2010.01243</span>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Yae Jee Cho, Jianyu Wang, and Gauri Joshi.

</span>
<span class="ltx_bibblock">Towards understanding biased client selection in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">International Conference on Artificial Intelligence and Statistics</span>, pages 10351–10375. PMLR, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik.

</span>
<span class="ltx_bibblock">Emnist: Extending mnist to handwritten letters.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">2017 international joint conference on neural networks (IJCNN)</span>, pages 2921–2926. IEEE, 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Moming Duan, Duo Liu, Xianzhang Chen, Yujuan Tan, Jinting Ren, Lei Qiao, and Liang Liang.

</span>
<span class="ltx_bibblock">Astraea: Self-balancing federated learning for improving classification accuracy of mobile deep learning applications.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">2019 IEEE 37th international conference on computer design (ICCD)</span>, pages 246–254. IEEE, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Yann Fraboni, Richard Vidal, Laetitia Kameni, and Marco Lorenzi.

</span>
<span class="ltx_bibblock">Clustered sampling: Low-variance and improved representativity for clients selection in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 3407–3416. PMLR, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Dashan Gao, Yang Liu, Anbu Huang, Ce Ju, Han Yu, and Qiang Yang.

</span>
<span class="ltx_bibblock">Privacy-preserving heterogeneous federated transfer learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">2019 IEEE international conference on big data (Big Data)</span>, pages 2552–2559. IEEE, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Jack Goetz, Kshitiz Malik, Duc Bui, Seungwhan Moon, Honglei Liu, and Anuj Kumar.

</span>
<span class="ltx_bibblock">Active federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.12641</span>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. A. Hartigan and M. A. Wong.

</span>
<span class="ltx_bibblock">A k-means clustering algorithm.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">JSTOR: Applied Statistics</span>, 28(1):100–108, 1979.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Chaoyang He, Murali Annavaram, and Salman Avestimehr.

</span>
<span class="ltx_bibblock">Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proc. of Advances in Neural Information Processing Systems (NeurIPS)</span>, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</span>, pages 770–778, 2016.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, and Hartwig Adam.

</span>
<span class="ltx_bibblock">Searching for mobilenetv3.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</span>, October 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam.

</span>
<span class="ltx_bibblock">Mobilenets: Efficient convolutional neural networks for mobile vision applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1704.04861</span>, 2017.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Foundations and Trends® in Machine Learning</span>, 14(1–2):1–210, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Similarity of neural network representations revisited.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages 3519–3529. PMLR, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. Kullback and R. A. Leibler.

</span>
<span class="ltx_bibblock">On Information and Sufficiency.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">The Annals of Mathematical Statistics</span>, 22(1):79 – 86, 1951.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Daliang Li and Junpu Wang.

</span>
<span class="ltx_bibblock">FedMD: Heterogenous Federated Learning via Model Distillation.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He.

</span>
<span class="ltx_bibblock">Federated learning on non-iid data silos: An experimental study.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">2022 IEEE 38th International Conference on Data Engineering (ICDE)</span>, pages 965–978. IEEE, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine Learning and Systems</span>, 2:429–450, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang.

</span>
<span class="ltx_bibblock">On the convergence of fedavg on non-iid data.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.02189</span>, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Bing Luo, Wenli Xiao, Shiqiang Wang, Jianwei Huang, and Leandros Tassiulas.

</span>
<span class="ltx_bibblock">Tackling system and statistical heterogeneity for federated learning with adaptive client sampling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">IEEE INFOCOM 2022-IEEE conference on computer communications</span>, pages 1739–1748. IEEE, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
WANG Luping, WANG Wei, and LI Bo.

</span>
<span class="ltx_bibblock">Cmfl: Mitigating communication overhead for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">2019 IEEE 39th international conference on distributed computing systems (ICDCS)</span>, pages 954–964. IEEE, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Proc. of International Conference on Artificial Intelligence and Statistics (AISTATS)</span>, 2017.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Elsa Rizk, Stefan Vlaski, and Ali H Sayed.

</span>
<span class="ltx_bibblock">Optimal importance sampling for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 3095–3099. IEEE, 2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Felix Sattler, Simon Wiedemann, Klaus-Robert Müller, and Wojciech Samek.

</span>
<span class="ltx_bibblock">Robust and communication-efficient federated learning from non-iid data.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">IEEE transactions on neural networks and learning systems</span>, 31(9):3400–3413, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Hyowoon Seo, Jihong Park, Seungeun Oh, Mehdi Bennis, and Seong-Lyun Kim.

</span>
<span class="ltx_bibblock">Federated Knowledge Distillation.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Machine Learning and Wireless Communications</span>, page 457, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Suhail Mohmad Shah and Vincent KN Lau.

</span>
<span class="ltx_bibblock">Model compression for communication efficient federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Mingxing Tan and Quoc Le.

</span>
<span class="ltx_bibblock">Efficientnet: Rethinking model scaling for convolutional neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages 6105–6114. PMLR, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Tackling the objective inconsistency problem in heterogeneous federated optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 33:7611–7623, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Han Xiao, Kashif Rasul, and Roland Vollgraf.

</span>
<span class="ltx_bibblock">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1708.07747</span>, 2017.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Jinjin Xu, Wenli Du, Yaochu Jin, Wangli He, and Ran Cheng.

</span>
<span class="ltx_bibblock">Ternary compression for communication-efficient federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>, 33(3):1162–1176, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Miao Yang, Ximin Wang, Hongbin Zhu, Haifeng Wang, and Hua Qian.

</span>
<span class="ltx_bibblock">Federated learning with class imbalance reduction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">2021 29th European Signal Processing Conference (EUSIPCO)</span>, pages 2174–2178. IEEE, 2021.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Sixing Yu, Phuong Nguyen, Waqwoya Abebe, Ali Anwar, and Ali Jannesari.

</span>
<span class="ltx_bibblock">Spatl: Salient parameter aggregation and transfer learning for heterogeneous clients in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2111.14345</span>, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Sixing Yu, Phuong Nguyen, Waqwoya Abebe, Wei Qian, Ali Anwar, and Ali Jannesari.

</span>
<span class="ltx_bibblock">Spatl: salient parameter aggregation and transfer learning for heterogeneous federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">2022 SC22: International Conference for High Performance Computing, Networking, Storage and Analysis (SC)</span>, pages 495–508. IEEE Computer Society, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Sixing Yu, Phuong Nguyen, Waqwoya Abebe, Justin Stanley, Pablo Munoz, and Ali Jannesari.

</span>
<span class="ltx_bibblock">Resource-aware heterogeneous federated learning using neural architecture search.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.05716</span>, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Syed Zawad, Ahsan Ali, Pin-Yu Chen, Ali Anwar, Yi Zhou, Nathalie Baracaldo, Yuan Tian, and Feng Yan.

</span>
<span class="ltx_bibblock">Curse or redemption? how data heterogeneity affects the robustness of federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</span>, volume 35, pages 10807–10814, 2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Jianyi Zhang, Ang Li, Minxue Tang, Jingwei Sun, Xiang Chen, Fan Zhang, Changyou Chen, Yiran Chen, and Hai Li.

</span>
<span class="ltx_bibblock">Fed-cbs: A heterogeneity-aware client sampling mechanism for federated learning via class-imbalance reduction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 41354–41381. PMLR, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.17429" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.17430" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2312.17430">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.17430" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.17431" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 11:01:07 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
