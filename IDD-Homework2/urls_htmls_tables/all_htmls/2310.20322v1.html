<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.20322] FA Team at the NTCIR-17 UFO Task</title><meta property="og:description" content="The FA team participated in the Table Data Extraction (TDE) and Text-to-Table Relationship Extraction (TTRE) tasks of the NTCIR-17 Understanding of Non-Financial Objects in Financial Reports (UFO).
This paper reports o…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FA Team at the NTCIR-17 UFO Task">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FA Team at the NTCIR-17 UFO Task">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.20322">

<!--Generated on Tue Feb 27 21:43:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Information Extraction,  Relationship Extraction">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">FA Team at the NTCIR-17 UFO Task</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuki Okumura
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Fast Accounting Co., Ltd.</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_country">Japan</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:okumura.yuki@fastaccounting.co.jp">okumura.yuki@fastaccounting.co.jp</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Masato Fujitake
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_affiliation_institution">FA Research, Fast Accounting Co., Ltd.</span><span id="id4.2.id2" class="ltx_text ltx_affiliation_country">Japan</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:fujitake@fastaccounting.co.jp">fujitake@fastaccounting.co.jp</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id5.id1" class="ltx_p">The FA team participated in the Table Data Extraction (TDE) and Text-to-Table Relationship Extraction (TTRE) tasks of the NTCIR-17 Understanding of Non-Financial Objects in Financial Reports (UFO).
This paper reports our approach to solving the problems and discusses the official results.
We successfully utilized various enhancement techniques based on the ELECTRA language model to extract valuable data from tables.
Our efforts resulted in an impressive TDE accuracy rate of 93.43%, positioning us in second place on the Leaderboard rankings.
This outstanding achievement is a testament to our proposed approach’s effectiveness.
In the TTRE task, we proposed the rule-based method to extract meaningful relationships between the text and tables task and confirmed the performance.</p>
</div>
<div class="ltx_keywords">Information Extraction, Relationship Extraction
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Team Name</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">FA</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Subtasks</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">Table Data Extraction subtask (Japanese) 
<br class="ltx_break">Text-to-Table Relationship Extraction subtask (Japanese)</p>
</div>
</section>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In natural language processing and information retrieval, extracting valuable data from tables and recognizing the connection between the written content and table representations is crucial.
These tasks are fundamental in several domains, including data analysis, decision-making, and knowledge extraction, particularly in specific fields like financial reporting.
As financial reporting becomes increasingly inundated with non-financial information, it is imperative for stakeholders, investors, and financial analysts to effectively understand and interpret the data for analysis.
During the 17th NTCIR Conference on Understanding Non-financial Objects in Financial Reports (UFO)<cite class="ltx_cite ltx_citemacro_citep">(Kimura et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite>, two tasks were used to encourage the development of practical algorithms for extracting and interpreting table-related data.
These tasks, known as Table Data Extraction (TDE) and Text-to-Table Relational Extraction (TTRE), provide a structured framework for studying and addressing the complexities involved in these processes.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">We share our practical approach to conducting these tasks in this paper.
For the TDE task, we leveraged advanced techniques using the powerful language model called ELECTRA <cite class="ltx_cite ltx_citemacro_citep">(Clark et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>.
Furthermore, we introduced a post-correction method based on the Levenshtein distance for the language model’s output to reduce errors.
This approach resulted in an impressive accuracy rate of 93.43%, showcasing its effectiveness.
For the TTRE task, we proposed a rule-based method to address the issue and validated the method.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The structure of this paper is as follows: Section <a href="#S2" title="2. Related Work ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> covers related work, Section <a href="#S3" title="3. Methods ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> gives a detailed overview of our method, Section <a href="#S4" title="4. Experiments ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents results and analysis, and Section <a href="#S5" title="5. Conclusions ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> concludes with a discussion of the implications of our work and future research directions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Table Data Extraction (TDE).</span>
Extracting information from tabular data is complex and challenging because it requires considering the information in the cells and the surrounding information.
Therefore, a method that treats data not as individual cells but as a group of rows has been proposed to handle table structures.
In previous research, cells are connected using special symbols, and treated as a single textual information, considered an input method to the language model <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>.
Treating table data as sequence data makes it possible to classify information in a row effectively.
Recently, a method involves approaching cell information as a Named Entity Recognition task <cite class="ltx_cite ltx_citemacro_citep">(Souza et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>.
The words can be accurately classified by treating the table data as sequence data and adapting NER as sequence labeling.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">We have developed a novel approach to analyzing table data based on previous research findings.
We treat tables as sequence data and extract information accordingly.
Unlike existing studies, our method differs in two key respects.
First, we combine both data of the classification-target cell and the corresponding entire row.
It allows us to consider the broader context of the whole row, thereby enhancing the accuracy of our analysis.
Second, we treated the task as a cell-by-cell classification rather than an NER task to focus on a target cell.
We have conducted a comparison experiment between the proposed method and the NER approach to demonstrate the effectiveness of the proposed method.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">To handle the sequence data, we utilized a language model that models language using word occurrence probabilities.
Recent years have seen the emergence of various methods, including BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>.
We employed ELECTRA <cite class="ltx_cite ltx_citemacro_citep">(Clark et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>, an extension of BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite> to extract table information.
While BERT performs pre-training by randomly filling in sentences, ELECTRA <cite class="ltx_cite ltx_citemacro_citep">(Clark et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> proposes a more sophisticated way of filling in sentences by focusing on each word and guessing which parts have been filled in by language models, thus improving accuracy compared to BERT.
For table information extraction, we adapted ELECTRA, which better handles the meaning of each word than the whole sentence, as the target of table information is a short string of a few words.
In a preliminary experiment, we conducted a verification of ELECTRA’s effectiveness as compared to BERT.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Text-to-Table Relationship Extraction (TTRE).</span>
To link sentences and tabular data, one can consider it a specialized case of the Entity Linking task.
The task aims to connect a given text with a representation of knowledge.
Two primary approaches, rule-based and machine learning-based methods, have been proposed for this task.
Rule-based methods have been proposed to link elements based on similarity measured by Levenshtein Distance <cite class="ltx_cite ltx_citemacro_citep">(Ohsawa and Matsuo, <a href="#bib.bib8" title="" class="ltx_ref">2014</a>; Levenshtein et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">1966</a>)</cite>.
The Levenshtein distance measures the similarity of two strings by counting edit operations to make them identical.
However, rule-based methods have issues, such as a lower matching rate due to differences in notation.
Therefore, machine learning-based methods have recently been used to improve robustness <cite class="ltx_cite ltx_citemacro_citep">(Sevgili et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>.
In this study, since this task is a particular case dealing with Entity Linking table data, we adopted a rule-based approach that eliminates complexity to clarify future issues.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methods</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Table Data Extraction</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The task is to understand the structure of the tables in the financial report.
More specifically, it is to predict the role of each cell in the table.
The input is a report written in HTML, and the output is an ID assigned to every table cell in the report and its categories (Metadata, Header, Attribute, Data) for the cell.
Structuring the tables can be used for numerical comparisons between firms.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">To address this issue, we use a language model-based text classification model to predict the category of each table cell.
Instead of outputting raw model results, we utilize a post-correction technique to improve accuracy.
Details are described below.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2310.20322/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>
The architecture of the proposed method.
Sentence classification is performed by inputting a cell and the line in which the cell is located.</figcaption>
</figure>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span>Cell Classification Method</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.3" class="ltx_p">We utilized contextual information surrounding the target cells of the table to improve cell classification.
Our classification pipeline, depicted in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.1. Table Data Extraction ‣ 3. Methods ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, incorporates a language model.
Due to the brevity of cell text, predicting meaning based solely on text is challenging.
To address this issue and account for table structure, we treated an entire row and corresponding cells as a single text for classification.
Each cell’s information is combined using a specific marker to indicate the joining of cells and the classification of cell information.
A special token <span id="S3.SS1.SSS1.p1.3.1" class="ltx_text ltx_font_typewriter">[SEP]</span> is added to each cell to express the division of cells in the row representation, as shown in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.1. Table Data Extraction ‣ 3. Methods ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
However, since the maximum input token length for the language model is <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mi id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><ci id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">L</annotation></semantics></math>, if the input target is longer than <math id="S3.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><mi id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><ci id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">L</annotation></semantics></math> tokens, the sentence is truncated, and only <math id="S3.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS1.SSS1.p1.3.m3.1a"><mi id="S3.SS1.SSS1.p1.3.m3.1.1" xref="S3.SS1.SSS1.p1.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.3.m3.1b"><ci id="S3.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p1.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.3.m3.1c">L</annotation></semantics></math> tokens are used.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2310.20322/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="334" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>
The pipeline of the proposed correction method.
After classifying all cells in a row, the current pattern is matched against any existing ones, and the most similar one is selected.
</figcaption>
</figure>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span>Post-Correction Method</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">We propose a post-correction method to improve the classification accuracy of the language model’s results.
The output results classified cell by cell may be inconsistent across an entire row.
Therefore, we propose a post-correction method based on edit distance to ensure consistency.
The pipeline is described in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1.1. Cell Classification Method ‣ 3.1. Table Data Extraction ‣ 3. Methods ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p">The cell categories predicted by the language model are collected row by row to check whether the sequential pattern was present in the training data.
As shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1.1. Cell Classification Method ‣ 3.1. Table Data Extraction ‣ 3. Methods ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, pattern matching is performed using the Levenshtein distance.
The 93 patterns were extracted from all the DryRun and Formal Run train dataset row series distributed in the UFO task.
Suppose the output sequence does not match the patterns.
In that case, it is corrected to one that can be matched at minimum cost by a Levenshtein distance editing operation.
However, if the length of a predicted sequence is longer than the patterns, the add and delete operations are ignored, and only replacements are performed.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Text-to-Table Relationship Extraction</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The objective is to match tables and their corresponding explanations in financial reports.
The task involves analyzing an HTML-formatted report and generating related sets of explanatory text and table elements (such as headers, data, and schemas).
Extracting supplemental information is necessary for tables to effectively describe structured information.
This enables a comprehensive analysis of the enterprise.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We present a rule-based approach to linking complex tables with textual representations.
Understanding both text and table information poses a challenge.
We evaluate the effectiveness of a rule-based approach as a baseline without a machine learning method.
The following pipeline is used to output results from the input.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Extract the table from the HTML and separate the text from the table.
We remark that it is necessary to maintain and extract that information because rowspan and colspan in the HTML can mess up the table’s structure.
In extracting the tables, we recorded the order in which the tables and descriptions appeared and stored them as structural data.
We use this recorded data to extract the table that precedes the description when we select the table in the following steps.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Preprocess to increase the match rate.
Specifically, the sentences to be extracted are divided based on particles and parentheses.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Identify the Name.
In the table structure, the top two rows and the left two columns are often not numerical values but rather headers or other keys.
Therefore, cells in this area are candidates for assigning Names.
The percentage of matches with the segmented sentences is measured for each cell.
The cell is assigned as Name if the match rate is greater than 70% in the Levenshtein distance.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Identify Value.
There are two ways to identify a value.
The usual pattern is that if two Names are found in a candidate area, the cell at the intersection of the row and column of the found cell is identified as Value.
Exceptionally, only one Name is detected in a candidate area.
In that case, all row or column elements corresponding to the detected cell are retained as candidates for Value.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p">Narrow down the candidates of Value.
Since Value is basically expressed numerically, the candidates should be numerical values.
As a candidate judgment, at least 50% of the text of the value item must contain numeric characters.
Cells not meeting this criterion are removed from the value candidates and labeled as “etc.”, defined as a misc category.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Table Data Extraction</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Implementation Details</h4>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Category distribution in TDE dataset.</figcaption>
<div id="S4.T1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:85.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(80.0pt,-15.8pt) scale(1.58464035759314,1.58464035759314) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Dataset</th>
<th id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Total</th>
<th id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">header</th>
<th id="S4.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">attribute</th>
<th id="S4.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">data</th>
<th id="S4.T1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">metadata</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">train</th>
<th id="S4.T1.1.1.2.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">78,926</th>
<td id="S4.T1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16,568</td>
<td id="S4.T1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14430</td>
<td id="S4.T1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47,680</td>
<td id="S4.T1.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">248</td>
</tr>
<tr id="S4.T1.1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">test</th>
<th id="S4.T1.1.1.3.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r">45,499</th>
<td id="S4.T1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">-</td>
<td id="S4.T1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">-</td>
<td id="S4.T1.1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">-</td>
<td id="S4.T1.1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_bb">-</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">Table <a href="#S4.T1" title="Table 1 ‣ 4.1.1. Implementation Details ‣ 4.1. Table Data Extraction ‣ 4. Experiments ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides detailed information about the dataset.
Unfortunately, we could not confirm the number of categories in the test data, as it was not disclosed.
The evaluation results are presented as the macro average of accuracy per table.
The Japanese-language model “izumi-lab/electra-base-japanese-discriminator”<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://huggingface.co/izumi-lab/electra-base-japanese-discriminator" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/izumi-lab/electra-base-japanese-discriminator</a></span></span></span> was used as the pre-trained ELECTRA model.
The max token length <math id="S4.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS1.SSS1.p1.1.m1.1a"><mi id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b"><ci id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">L</annotation></semantics></math> is set to 128.
Fine-tuning was performed using the following parameters, and the model with the highest accuracy was adopted through 5-part cross-validation.
The optimizer was Adam, and training was performed with a learning rate of 1e-5.
The training period was five epochs.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Performance comparison with the state-of-the-art
methods on TDE.
</figcaption>
<div id="S4.T2.1" class="ltx_inline-block ltx_transformed_outer" style="width:173.4pt;height:171.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(32.1pt,-31.8pt) scale(1.58881022973976,1.58881022973976) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Team</th>
<th id="S4.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">F1-score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.2.1" class="ltx_tr">
<td id="S4.T2.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">KSU</td>
<td id="S4.T2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.2.1.2.1" class="ltx_text ltx_font_bold">0.9537</span></td>
</tr>
<tr id="S4.T2.1.1.3.2" class="ltx_tr">
<td id="S4.T2.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r">FA (Ours)</td>
<td id="S4.T2.1.1.3.2.2" class="ltx_td ltx_align_center">0.9343</td>
</tr>
<tr id="S4.T2.1.1.4.3" class="ltx_tr">
<td id="S4.T2.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r">OUC</td>
<td id="S4.T2.1.1.4.3.2" class="ltx_td ltx_align_center">0.9217</td>
</tr>
<tr id="S4.T2.1.1.5.4" class="ltx_tr">
<td id="S4.T2.1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_r">jpxiteam</td>
<td id="S4.T2.1.1.5.4.2" class="ltx_td ltx_align_center">0.8287</td>
</tr>
<tr id="S4.T2.1.1.6.5" class="ltx_tr">
<td id="S4.T2.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">TO</td>
<td id="S4.T2.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">0.7981</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Main Result</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Table <a href="#S4.T2" title="Table 2 ‣ 4.1.1. Implementation Details ‣ 4.1. Table Data Extraction ‣ 4. Experiments ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> displays team names and accuracy on the Formal Run Leaders Board<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://sites.google.com/view/ntcir17-ufo/leaderboard?authuser=0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://sites.google.com/view/ntcir17-ufo/leaderboard?authuser=0</a></span></span></span>.
Our method achieved 93.43%, making us second with competitive accuracy.
KSU employed a method considering the table structure based on BERT, while OUC uses BERT Large <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>.
The jpxiteam uses ChatGPT, and the TO uses rule-based methods.
The proposed method achieves high accuracy using the Electra-based language model with fine-tuning and post-processing.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Ablation studies on TDE.
</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_transformed_outer" style="width:650.4pt;height:143.3pt;vertical-align:-1.3pt;"><span class="ltx_transformed_inner" style="transform:translate(77.9pt,-17.0pt) scale(1.31473560575173,1.31473560575173) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Approach</th>
<th id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Target Cell Information</th>
<th id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Row Information</th>
<th id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Post Correction Method</th>
<th id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">F1-score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.2.1" class="ltx_tr">
<th id="S4.T3.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Sentence Classification</th>
<td id="S4.T3.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T3.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T3.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S4.T3.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.1.2.1.5.1" class="ltx_text ltx_font_bold">0.9343</span></td>
</tr>
<tr id="S4.T3.1.1.3.2" class="ltx_tr">
<th id="S4.T3.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sentence Classification</th>
<td id="S4.T3.1.1.3.2.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.3.2.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.3.2.4" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.1.1.3.2.5" class="ltx_td ltx_align_center">0.9321</td>
</tr>
<tr id="S4.T3.1.1.4.3" class="ltx_tr">
<th id="S4.T3.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sentence Classification</th>
<td id="S4.T3.1.1.4.3.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.4.3.3" class="ltx_td"></td>
<td id="S4.T3.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S4.T3.1.1.4.3.5" class="ltx_td ltx_align_center">0.9236</td>
</tr>
<tr id="S4.T3.1.1.5.4" class="ltx_tr">
<th id="S4.T3.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sentence Classification</th>
<td id="S4.T3.1.1.5.4.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.5.4.3" class="ltx_td"></td>
<td id="S4.T3.1.1.5.4.4" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.1.1.5.4.5" class="ltx_td ltx_align_center">0.9140</td>
</tr>
<tr id="S4.T3.1.1.6.5" class="ltx_tr">
<th id="S4.T3.1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Sequence Labeling (NER)</th>
<td id="S4.T3.1.1.6.5.2" class="ltx_td ltx_border_bb ltx_border_t"></td>
<td id="S4.T3.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">✓</td>
<td id="S4.T3.1.1.6.5.4" class="ltx_td ltx_border_bb ltx_border_r ltx_border_t"></td>
<td id="S4.T3.1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.7937</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2310.20322/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="342" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>
Distribution of token lengths in the cells of the table.
Most of the content within the cells contains only a limited number of tokens, indicating that the text is brief and comprises individual words rather than entire sentences.
</figcaption>
</figure>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Detailed Analysis</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">We conducted a detailed analysis to see what effectively extracts the table information.
Here, we analyzed each cell and the component analysis of the method.</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<p id="S4.SS1.SSS3.p2.1" class="ltx_p">First, we analyzed the token length of each cell handled by the language model because the length of the tokens affects the semantic information that the language model obtains from the text.
The histograms of the length and frequency of the tokens in each cell are shown in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.1.2. Main Result ‣ 4.1. Table Data Extraction ‣ 4. Experiments ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
It also shows that the number of tokens in each cell is concentrated into a few tokens.
This suggests the language model may not obtain enough text to ensure context when dealing with cells.</p>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p id="S4.SS1.SSS3.p3.1" class="ltx_p">Next, we conducted an ablation study to analyze what affects performance in the TDE task.
In this experiment, we validated the NER approach of sequence modeling with ELECTRA+CRF to confirm the effectiveness of the cell-by-cell text classification approach.
In NER, each line was used as an input, and as in text classification, cell delimiters were represented by special tokens <span id="S4.SS1.SSS3.p3.1.1" class="ltx_text ltx_font_typewriter">[SEP]</span>, the category of each token between <span id="S4.SS1.SSS3.p3.1.2" class="ltx_text ltx_font_typewriter">[SEP]</span> was predicted, and if multiple tokens in a cell made separate predictions, the later prediction was given priority.
The experiment results are shown in Table <a href="#S4.T3" title="Table 3 ‣ 4.1.2. Main Result ‣ 4.1. Table Data Extraction ‣ 4. Experiments ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS1.SSS3.p4" class="ltx_para">
<p id="S4.SS1.SSS3.p4.1" class="ltx_p">We confirm that the classification approach with a single cell achieved 91% accuracy compared to 79% accuracy with NER and that the extraction of table information as a classification task is 12 points more accurate.
In addition, based on the analysis of token length in cells, it was confirmed that even text with a few tokens can achieve a certain degree of accuracy in language models.
At first, it was thought that incorporating lengthy sequences of tokens and contextual information, such as complete sentences, would increase accuracy.
It was proven that the assumption may only sometimes be accurate.
When comparing text classification that considers cells alone and cells plus entire rows, the accuracy is improved by two points to 93%.
Therefore, ensuring context in the TDE task is essential, as a few tokens alone cannot consider the surrounding information.
To enhance output consistency, post-processing was implemented. We verified the efficacy of post-processing, resulting in improved accuracy.</p>
</div>
<div id="S4.SS1.SSS3.p5" class="ltx_para">
<p id="S4.SS1.SSS3.p5.1" class="ltx_p">For future accuracy improvements, we believe it is crucial to use domain-specific pre-trained models <cite class="ltx_cite ltx_citemacro_citep">(Choi et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2022</a>)</cite>.
We used an existing pre-trained language model to implement our proposed method, a model trained by a generic corpus such as Wikipedia.
However, in this case, the text sentences in the tables are shorter than general sentences.
Moreover, in some cases, more than the generic content is required.
Therefore, using a pre-trained model specific to table representation, rather than a pre-trained model trained on generic data and for generic purposes, will allow for more accurate classification.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Text-to-Table Relationship Extraction</h3>

<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Implementation Details</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">The data used for the test is a total of 25 HTML files, and we answer cells corresponding to a total of 11,867 cell descriptions.
The accuracy in evaluation is measured by the F-1 score.
The three perspectives are considered: “Name”, “Value”, and their average.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span>Text to Table Relationship Extraction result.</figcaption>
<div id="S4.T4.1" class="ltx_inline-block ltx_transformed_outer" style="width:303.5pt;height:76.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(44.3pt,-11.1pt) scale(1.4121422563703,1.4121422563703) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Method</th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Name</th>
<th id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Value</th>
<th id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Total</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.2.1" class="ltx_tr">
<th id="S4.T4.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Rule-based (Ours)</th>
<td id="S4.T4.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">0.0341</td>
<td id="S4.T4.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0131</td>
<td id="S4.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.0236</td>
</tr>
<tr id="S4.T4.1.1.3.2" class="ltx_tr">
<th id="S4.T4.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Random</th>
<td id="S4.T4.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_bb">0.0008</td>
<td id="S4.T4.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.0004</td>
<td id="S4.T4.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_bb">0.0006</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Main Result and Discussion</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The experiment results are shown in table <a href="#S4.T4" title="Table 4 ‣ 4.2.1. Implementation Details ‣ 4.2. Text-to-Table Relationship Extraction ‣ 4. Experiments ‣ FA Team at the NTCIR-17 UFO Task" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
Also shown are the results of the random prediction output using the code provided by the organizer of the UFO task.
We see that our result of an overall F1 score is 2.4%.
Also, Name and Value scored 3.4% and 1.3%, respectively, confirming that Name achieves better on a rule basis.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">From the experiments, the rule-based approach can extract relationships in several patterns, which is verified by the comparison with random prediction.
Still, the overall accuracy could be better and needs further improvement for practical usage.
First, the Levenshtein distance was used to determine the match rate in the rule-based approach.
Currently, we use a fixed match rate for all cases.
However, changing the match rate based on attributes adaptively, such as Name and Value, is necessary.
In addition, we regarded the text as a numerical expression if 50% of the text was a numerical expression, etc., otherwise.
Thus, the classification accuracy needed to be higher.
For instance, a binary classification model should be introduced to separate the data and etc elements.
Moreover, it is necessary to consider introducing a machine-learning approach.
Specifically, although we extracted the data when there is a match in terms of “Name”, we believe it may be practical to increase the accuracy by using a method that measures the similarity of feature values.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We presented our methodology and the results of our participation in the task of understanding non-financial objects (UFO) in NTCIR-17 financial reports, specifically in table data extraction (TDE) and text-to-table relationship extraction (TTRE).
The fact that our language model and post-processing method for table data extraction achieved an accuracy of 93.43% and ranked second on the Leaderboard demonstrates the success and robustness of our proposed approach.
In addition, the detailed analysis demonstrated the effectiveness of our approach by comparing it with other methods, such as named entity recognition approaches.
For text-to-table relationship extraction, our rule-based approach has established a baseline for future research.
With these results, we discussed future research directions, including the need for domain-specific pre-trained models and the introduction of machine-learning approaches.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hongmin Wang,
Jianshu Chen, Yunkai Zhang,
Hong Wang, Shiyang Li,
Xiyou Zhou, and William Yang Wang.
2020.

</span>
<span class="ltx_bibblock">Tabfact: A large-scale dataset for table-based fact
verification. In <em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">Proceedings of the International
Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Dongha Choi, HongSeok
Choi, and Hyunju Lee. 2022.

</span>
<span class="ltx_bibblock">Domain Knowledge Transferring for Pre-trained
Language Model via Calibrated Activation Boundary Distillation. In
<em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Meeting of the
Association for Computational Linguistics</em>. 1658–1669.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Kevin Clark, Minh-Thang
Luong, Quoc V. Le, and Christopher D.
Manning. 2020.

</span>
<span class="ltx_bibblock">ELECTRA: Pre-training Text Encoders as
Discriminators Rather Than Generators. In
<em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on
Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei
Chang, Kenton Lee, and Kristina
Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional
transformers for language understanding. In
<em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proceedings of the North American Chapter of the
Association for Computational Linguistics</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kimura et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yasutomo Kimura, Hokuto
Ototake, Kazuma Kadowaki, Takahito
Kondo, and Makoto P. Kato.
2023.

</span>
<span class="ltx_bibblock">Overview of the NTCIR-17 UFO Task.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proceedings of The 17th NTCIR Conference</em>
(12 2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levenshtein et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (1966)</span>
<span class="ltx_bibblock">
Vladimir I Levenshtein et al<span id="bib.bib7.3.1" class="ltx_text">.</span>
1966.

</span>
<span class="ltx_bibblock">Binary codes capable of correcting deletions,
insertions, and reversals. In <em id="bib.bib7.4.1" class="ltx_emph ltx_font_italic">Soviet physics
doklady</em>, Vol. 10. 707–710.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ohsawa and Matsuo (2014)</span>
<span class="ltx_bibblock">
Shohei Ohsawa and Yutaka
Matsuo. 2014.

</span>
<span class="ltx_bibblock">Popularity Prediction for Entities on SNS Using
Semantic Relations.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Transactions of The Japanese Society for
Artificial Intelligence</em> 29 (2014),
469–482.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sevgili et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Özge Sevgili, Artem
Shelmanov, Mikhail Arkhipov, Alexander
Panchenko, and Chris Biemann.
2022.

</span>
<span class="ltx_bibblock">Neural entity linking: A survey of models based on
deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Semantic Web</em> 13,
3 (2022), 527–570.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Souza et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Fábio Souza, Rodrigo
Nogueira, and Roberto Lotufo.
2020.

</span>
<span class="ltx_bibblock">Portuguese Named Entity Recognition using
BERT-CRF.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.10649</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.20321" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.20322" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.20322">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.20322" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.20323" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 21:43:32 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
