<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2301.01824] Privacy and Efficiency of Communications in Federated Split Learning</title><meta property="og:description" content="Everyday, large amounts of sensitive data  is distributed across mobile phones, wearable devices, and other sensors. Traditionally, these enormous datasets have been processed on a single system, with complex models beâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Privacy and Efficiency of Communications in Federated Split Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Privacy and Efficiency of Communications in Federated Split Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2301.01824">

<!--Generated on Fri Mar  1 04:19:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:207%;">
<span id="id8.id1" class="ltx_text" style="font-size:48%;">
</span>Privacy and Efficiency of Communications in 
<br class="ltx_break">Federated Split Learning

</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">

<span id="id7.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="id5.5.5.5" class="ltx_tr">
<span id="id1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">ZongshunÂ Zhang<sup id="id1.1.1.1.1.1" class="ltx_sup"><span id="id1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">â€¡</span></sup></span>
<span id="id2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">AndreaÂ Pinto<sup id="id2.2.2.2.2.1" class="ltx_sup"><span id="id2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">â‹†</span></sup></span>
<span id="id3.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">ValeriaÂ Turina<sup id="id3.3.3.3.3.1" class="ltx_sup"><span id="id3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">â‹†</span></sup></span>
<span id="id4.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Flavio Esposito<sup id="id4.4.4.4.4.1" class="ltx_sup"><span id="id4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">â‹†</span></sup></span>
<span id="id5.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Ibrahim Matta<sup id="id5.5.5.5.5.1" class="ltx_sup"><span id="id5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">â€¡</span></sup></span></span>
<span id="id7.7.7.7" class="ltx_tr">
<span id="id6.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_colspan ltx_colspan_2"><sup id="id6.6.6.6.1.1" class="ltx_sup"><span id="id6.6.6.6.1.1.1" class="ltx_text ltx_font_italic">â€¡</span></sup>Computer Science Department</span>
<span id="id7.7.7.7.3" class="ltx_td ltx_th ltx_th_column"></span>
<span id="id7.7.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_colspan ltx_colspan_2"><sup id="id7.7.7.7.2.1" class="ltx_sup"><span id="id7.7.7.7.2.1.1" class="ltx_text ltx_font_italic">â‹†</span></sup>Computer Science Department</span></span>
</span>
<span class="ltx_tbody">
<span id="id7.7.7.8.1" class="ltx_tr">
<span id="id7.7.7.8.1.1" class="ltx_td ltx_align_center ltx_colspan ltx_colspan_2">Boston University</span>
<span id="id7.7.7.8.1.2" class="ltx_td"></span>
<span id="id7.7.7.8.1.3" class="ltx_td ltx_align_center ltx_colspan ltx_colspan_2">Saint Louis University</span></span>
<span id="id7.7.7.9.2" class="ltx_tr">
<span id="id7.7.7.9.2.1" class="ltx_td ltx_align_center ltx_colspan ltx_colspan_5"><span id="id7.7.7.9.2.1.1" class="ltx_text ltx_font_typewriter">Technical Report</span></span></span>
</span>
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Everyday, large amounts of sensitive data <span id="id9.id1.1" class="ltx_text" style="color:#000000;"> is</span> distributed across mobile phones, wearable devices, and other sensors. Traditionally, these enormous datasets have been processed on a single system, with complex models being trained to make valuable predictions.
Distributed machine learning techniques such as Federated and Split Learning have recently been developed to protect user <span id="id9.id1.2" class="ltx_text" style="color:#000000;"> data and</span> privacy better while ensuring high performance. Both of these distributed learning architectures have advantages and disadvantages.
In this paper, we examine these tradeoffs and suggest a new hybrid Federated Split Learning architecture that combines the efficiency and privacy benefits of both.
Our evaluation demonstrates how our hybrid Federated Split Learning approach can lower the amount of processing power required by each client running a distributed learning system, reduce training and inference time while keeping a similar accuracy. We also discuss the resiliency of our approach to deep learning privacy inference attacks and compare our solution to other recently proposed benchmarks.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">CENTRALIZED machine learning (ML) training is becoming unsustainableÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Aside from the advantages of re-training often to optimize revenuesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, several learning applications need to run their processes at the edge of the network, not in the core of a datacenter, for multiple reasons, including end-to-end latency minimization by running machine learning algorithms locally on an end-device, and privacy concerns of trusting third-party cloudsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Several Machine Learning (ML) models trade user experience improvements on mobile devices for sensible data exploitation; see e.g., text recommendation in keyboardsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> or vocal assistantsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
In these and other applications, a decentralized learning approach may be preferable to a centralized system since sensitive data may remain locally within a client and not transferred over a computer network.
</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite its benefits in several use cases, running machine learning training and inference jobs within local devices has several limitations: computing capacity is often limited, battery drains faster with intensive processing and the mobile or other end-devices have limited memory and storage capabilities.
For example, our experiments show that to fine-tune a VGG-16Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> Neural Network, pre-trained on
ImageNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> with Cifar-10Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, tens of minutes are needed to reach <math id="S1.p2.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S1.p2.1.m1.1a"><mrow id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml"><mn id="S1.p2.1.m1.1.1.2" xref="S1.p2.1.m1.1.1.2.cmml">90</mn><mo id="S1.p2.1.m1.1.1.1" xref="S1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><apply id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1"><csymbol cd="latexml" id="S1.p2.1.m1.1.1.1.cmml" xref="S1.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.p2.1.m1.1.1.2.cmml" xref="S1.p2.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">90\%</annotation></semantics></math> accuracy on an NVDIA V100 GPU.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Different distributed neural network architectures have been proposed to preserve privacy and guarantee timely convergence â€“ for example Federated LearningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, Split LearningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, or hybrid approachesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Federated Learning (FL)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> averages the weights of the learned Neural Network model on each edge device to create a single model, which will update the local ones.
Previous research has shown that this strategy can achieve higher accuracy than considering only a local modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and at the same time can preserve the privacy of the data.
<span id="S1.p3.1.1" class="ltx_text" style="color:#000000;"> Split Learning (SL) architecture splits the entire NN into partitions of layers. Each partition is executed on a different entity (i.e., edge and cloud), and different edge NN partitions can be paired with the cloud partition.</span>
Thus, this approach takes advantage of distributed datasets while keeping user data private.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">On one hand, FL is easy to scale to many devices given that there are enough resources to meet training Service Level Agreements (SLAs).
Thus, FL is impractical in edge training/inference settings, where resources are limited.
On the other hand, Split Learning can train with limited resources, but it doesnâ€™t scale to many devices well since it is not parallel.
Especially when we pair different edge devices with not independent and identically distributed (Non-IID) data with the central cloud, the training may not converge at allÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.
Another drawback of SL is that the intermediate data can be costly to transmit and store in client or server nodesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
Furthermore, since the intermediate data in the forward propagation is derived from the source data, there is a privacy concern.
We further discuss these two models in SectionÂ <a href="#S2" title="2 Distributed Learning Architectures: Background and Related Work â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To cope with the inefficiencies of the existing distributed learning models,
<span id="S1.p5.1.1" class="ltx_text" style="color:#000000;"> we propose</span> a novel distributed learning architecture, Federated Split Learning (FSL)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, which combines the benefits of FL and SL while mitigating their drawbacks. We discuss the generality of our FSL and a novel methodology to optimize both delay and privacy guarantees.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The FSL model is characterized by multiple edge client â€“ server pairs.
Such pairs train their copy of the NN simultaneously, providing the parallelism of federated learning, while the client-server separation brings the advantages of the split learning.
Each computing pair partitions the NN.
After some pairs have completed some training epochs, the server NN weights are averaged in a central cloud server, as in classical FL algorithmsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. We call this central cloud node the â€œParameter Server nodeâ€ in FigureÂ <a href="#S1.F1.sf4" title="In Figure 1 â€£ 1 Introduction â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">There are other techniques, i.e., Parallel Split Learning (PSL)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, and Federated Reconstruction (FRC)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, close to our proposal.
<span id="S1.p7.1.1" class="ltx_text" style="color:#000000;"> But they have some disadvantages comparing to FSL.</span>
While the PSL architecture has only one cloud server node, FSL allows parallel server computations.
FSL and FRC have similar privacy levels (SecÂ <a href="#S4.SS1" title="4.1 Privacy Attacker Model and Assumptions â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>), but our evaluations shows that FRC doubles the training time compared to FSL, considering no dominant transmission delays.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">We evaluate the benefits of our FSL architecture by testing it with different NN models and tasks: from image classification to an Internet traffic classificationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.
Aside from testing <span id="S1.p8.1.1" class="ltx_text" style="color:#000000;"> training performance of</span> our proposed hybrid federated-split architecture, we evaluated the privacy-performance tradeoff of FSL and SL, and give ideas on how to enhance the privacy guarantee of these schemes using <span id="S1.p8.1.2" class="ltx_text" style="color:#000000;"> Client-based Privacy Approach (CPA) and</span> novel neural network partitioning approaches.
Furthermore, we realized that <span id="S1.p8.1.3" class="ltx_text" style="color:#000000;"> certain ways of partitioning NN</span>
could reduce transmission delay and enhance privacy together.
Our experiment results show that
by combining different privacy approaches and NN partitioning methods, our FSL may achieve both high efficiency with respect to training time, privacy guarantees and accuracy.
</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x1.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_img_portrait" width="461" height="586" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Federated Learning</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x2.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_img_portrait" width="461" height="586" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Split Learning</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x3.png" id="S1.F1.sf3.g1" class="ltx_graphics ltx_img_portrait" width="461" height="586" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S1.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Parallel Split Learning</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x4.png" id="S1.F1.sf4.g1" class="ltx_graphics ltx_img_portrait" width="461" height="572" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S1.F1.sf4.3.2" class="ltx_text" style="font-size:90%;">Federated Split Learning</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.9.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.10.2" class="ltx_text" style="font-size:90%;">Distributed NN Training Architectures:
<span id="S1.F1.10.2.1" class="ltx_text ltx_font_italic">(a)Â Federated Learning:</span> The NN is in the client. The parameter server calculates the average weights among clients and overrides the local weights.
<span id="S1.F1.10.2.2" class="ltx_text ltx_font_italic">(b)Â Split Learning:</span>
<span id="S1.F1.10.2.3" class="ltx_text" style="color:#000000;"> The server partition sequentially trains with each of the clients. Client weights are shared with the next training client.</span>
<span id="S1.F1.10.2.4" class="ltx_text ltx_font_italic">(c)Â Parallel Split Learning:</span> <span id="S1.F1.10.2.5" class="ltx_text" style="color:#000000;"> The server trains clientsâ€™ output in batches in parallel, but the clientâ€™s weights are kept private.</span>
<span id="S1.F1.10.2.6" class="ltx_text ltx_font_italic">(d)Â Federated Split Learning:</span> <span id="S1.F1.10.2.7" class="ltx_text" style="color:#000000;"> Multiple Edge Server and Client pairs train simultaneously. The Edge Serversâ€™ weights are averaged by a Parameter Server. The clients weights are kept private. </span>
</span></figcaption>
</figure>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">The rest of the paper is organized as follows:
in SectionÂ <a href="#S2" title="2 Distributed Learning Architectures: Background and Related Work â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we introduce the background and the related works to discuss FSL.
Then, we describe the proposed FSL system in SectionÂ <a href="#S3" title="3 Privacy-Oblivious FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
In SectionÂ <a href="#S4" title="4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> we discuss the Client-based Privacy Approach (CPA) <span id="S1.p9.1.1" class="ltx_text" style="color:#000000;"> and motivations to partition NN at edge that can be applied in any split learning based architecture.</span>
Our evaluation with training and inference metrics is presented in SectionÂ <a href="#S5.SS2" title="5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>, while the privacy evaluation is presented in SectionÂ <a href="#S5.SS3" title="5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Distributed Learning Architectures: 
<br class="ltx_break">Background and Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Federated Learning</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> is a decentralized machine learning technique that trains neural network models using data sources â€œownedâ€ by multiple clients (FigureÂ <a href="#S1.F1.sf1" title="In Figure 1 â€£ 1 Introduction â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>).
A logically centralized parameter server holds the latest neural network model, and orchestrates the sharing of its weights between all clients.
</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.2" class="ltx_p">At the beginning of the training phase of a federated learning process, the parameter server sends the same randomly initialized set of neural network weights to each client.
Each client then trains a local model for multiple epochs using its local dataset.
Until the client models have extracted enough features, that is, a given accuracy threshold is reached, the parameter server keeps retrieving, averaging, and overwriting the weights
(FigureÂ <a href="#S1.F1.sf1" title="In Figure 1 â€£ 1 Introduction â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>
â€“ steps <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.p2.1.m1.1a"><mn id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><cn type="integer" id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">1</annotation></semantics></math> to <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.p2.2.m2.1a"><mn id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><cn type="integer" id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">3</annotation></semantics></math>).
Thus, the global model could take advantage of the privately-owned datasets which would not transmit through the network.
Moreover, FL has parameters to specify the frequency for the parameter server to average the weights of a certain group of clients.
In this way, system architects can balance the network traffic and model accuracy.
Thus, FL is considered scalable in terms of the number of clients, as long as
such clients have enough computational power and storage resources to meet the training constraints, or Service Level Objectives (SLOs).
</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Split Learning</span><span id="S2.p3.1.2" class="ltx_text" style="color:#000000;"> Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite></span> is a distributed machine learning technique that is characterized by a computational split of the neural network model into two partitions. Each partition could run on a separate computing node, hence splitting the computational resource demand.
To train a NN model with split learning, the NN must first be partitioned <span id="S2.p3.1.3" class="ltx_text" style="color:#000000;"> on different nodes</span>.
Then, the forward propagation phase starts.
When the end of the NN partition at the first node is reached, the outputs of the last layer of activation functions are sent to the server node â€” step 1 (FigureÂ <a href="#S1.F1.sf2" title="In Figure 1 â€£ 1 Introduction â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>).
Then those outputs are used as inputs to the second NN partition and continue the forward propagation.
After calculating the loss, the backward propagation in the server node is started.
Once the backward propagation reaches the input layer of the serverâ€™s partition,
the gradients of the inputs are sent to the last activation in the client to finish the backward propagation for client NN â€” step 2. Finally, the complete NN weights are updated with the gradients.
However, the serverâ€™s NN partition can also pair with other clientsâ€™ NN partition with the same client NN structure.
First, the trained weights on the last client are moved to the new client â€” step 3. Then the new server and client pair trains as mentioned above â€” steps 4 and 5. </p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The SL algorithm preserves data privacy but suffers from a long convergence time with Non-Independent and Identically Distributed (non-IID) data sources (FigureÂ <a href="#S2.F2" title="Figure 2 â€£ 2 Distributed Learning Architectures: Background and Related Work â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), and large intermediate data to transmit. Moreover, training with more than one client is sequential, hence poorly scalable.
Some solutions attempted to mitigate the transmission delay of such intermediate data. For example, in BottleNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and BBNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, the authors aim at compressing the intermediate data with a particular NN design.
In Early-ExitÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> instead the idea is to add classifiers at the early layers to avoid computing the complete model.
Previous workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> also used knowledge distillation to reduce the complexity of client models and the data to transmit.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">In this paper, we consider hybrid split-federated learning systems, to combine their benefits while minimizing their drawbacks. For example, we show that hybrid Federated Split Learning and Parallel Split Learning can converge with non-IID sources faster than Split Learning.</p>
</div>
<div id="S2.p6" class="ltx_para ltx_noindent">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text ltx_font_bold">Combining Split and Federated Learning.</span>
Other researchers have proposed combining the advantages of split and federated learning.
<span id="S2.p6.1.2" class="ltx_text" style="color:#000000;"> 
In Parallel Split Learning (PSL)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> (FigureÂ <a href="#S1.F1.sf3" title="In Figure 1 â€£ 1 Introduction â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(c)</span></a>), they train the client NN partition on multiple edge nodes in parallel.
During the Forward Propagation phase, the activation function results from different clients are sent to a single remote server.
Such server then backward propagates the gradient from the loss function to the clients.
</span></p>
</div>
<div id="S2.p7" class="ltx_para ltx_noindent">
<p id="S2.p7.1" class="ltx_p"><span id="S2.p7.1.1" class="ltx_text ltx_font_bold">Model specific approaches.</span>
FedSLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> is one example of Recurrent Neural Networks (RNN).
The idea is to unroll the RNNâ€™s feedback loop and split the recurrent NN partition to different nodes with the sequence data segments.
After each epoch, devices average and overwrite their weights.
This approach combines the benefit of SL and FL in the RNN training setting without introducing much overhead.</p>
</div>
<div id="S2.p8" class="ltx_para ltx_noindent">
<p id="S2.p8.1" class="ltx_p"><span id="S2.p8.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">FL Extensions.</span>
Some works extend the FL model instead of designing a hybrid architecture.
The authors of Federated Construction (FRC)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, prioritize user data privacy trading off the efficiency of the training process.
Their model is partitioned into <span id="S2.p8.1.2" class="ltx_text ltx_font_italic">global</span> and <span id="S2.p8.1.3" class="ltx_text ltx_font_italic">local</span> shards and both deployed in each edge device, and the two partitions are trained alternately.
A parameter server then sends the global shard and retrieves the corresponding updated weights.
This design makes the training stateless and, consequently, highly scalable for storage.</p>
</div>
<div id="S2.p9" class="ltx_para ltx_noindent">
<p id="S2.p9.1" class="ltx_p"><span id="S2.p9.1.1" class="ltx_text ltx_font_bold">Source Data Privacy.</span>

One of the advantages of these edge training systems is the high perceived level of source data privacy:
userâ€™s data doesnâ€™t leave the edge device.
However, the adversaries can also learn the source data from the NN weights.
All systems mentioned except for FRC <span id="S2.p9.1.2" class="ltx_text" style="color:#000000;"> and PSL</span> cannot maintain the privacy for NN weightsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
They maintain this privacy since they do not share the complete NN weights or the activation results.</p>
</div>
<div id="S2.p10" class="ltx_para">
<p id="S2.p10.1" class="ltx_p"><span id="S2.p10.1.1" class="ltx_text" style="color:#000000;">Another threat discussed in NoPeekÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> targets the results of the activation function, which can be used to reconstruct the source data with an autoencoder NN.</span>
<span id="S2.p10.1.2" class="ltx_text" style="color:#000000;"> Certain edge intelligence systems that partition Neural Networks and transmit intermediate data in between partitions are vulnerable to this threat.</span>
Possible mitigation uses the Distance Correlation (DC) lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> added to the original loss function to measure the difference between the source and the intermediate data.
This approach maximizes DC loss and accuracy while updating the NNâ€™s weights by solving a Multi-Objective Optimization Problem.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2301.01824/assets/x5.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="199" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Accuracy degradation when training with Non-IID data.</span></figcaption>
</figure>
<div id="S2.p11" class="ltx_para ltx_noindent">
<p id="S2.p11.1" class="ltx_p"><span id="S2.p11.1.1" class="ltx_text ltx_font_bold">Client-Based Privacy Approach (CPA).</span>
NoPeekâ€™s loss function improves the resilience in reconstructing private source data from the intermediate data.
However, sharing the loss and constructing the distributed gradient graphs are either unsafe or need an extra management system.
To overcome this limitation, we propose <span id="S2.p11.1.2" class="ltx_text" style="color:#000000;"> an extension from NoPeek, namely Client-based Privacy Approach.</span>
The idea is to add noise <span id="S2.p11.1.3" class="ltx_text" style="color:#000000;"> with user specified methods</span> to the results of activation functions in clients, so there would be less features to be used by the autoencoder NN <span id="S2.p11.1.4" class="ltx_text" style="color:#000000;"> (SectionÂ <a href="#S4.SS3" title="4.3 Client-Based Privacy Approach in Distributed Setting via Distance Correlation (CPA-DC) â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>)</span>.</p>
</div>
<div id="S2.p12" class="ltx_para ltx_noindent">
<p id="S2.p12.1" class="ltx_p"><span id="S2.p12.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Privacy Approaches.<span id="S2.p12.1.1.1" class="ltx_text ltx_font_medium">
We will mainly compare DC and Differential Privacy (DP-SGD) under CPA framework.
DP-SGD is a widely used lightweight algorithmic approach for data privacyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
The idea is to add a Gaussian noise to the gradients during a training phase of a NN.
Thus the clientâ€™s output, generated by the updated weights, will confuse the adversary.
Comparing to Homomorphic Encryption (HE) or Secure Multi-Party Computation (SMPC), we consider it fits better in our client and edge server setup, while the privacy level of encryption has been well discussed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
It is not cost efficient at edge to consume a lot of battery for encryption and decryption steps.
There are also methods , i.e., model compression(<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>), can potentially enhance privacy guarantee and consume power lower than HE but higher than DP-SGD .
But comparing existing privacy methods is not the focus of this project and we consider it as a future work.
We mainly want to show the proposed CPA is a general approach and it provides high attack resilience with different methods including DC and DP-SGD.
Thus, in this paper, we evaluate the traditional DP-SGD applied to the complete model
and compare it with DP-SGD only applied to the clients using the CPA framework (SectionÂ <a href="#S5.SS3.SSS6" title="5.3.6 Privacy Evaluation with Differential Privacy Approach â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3.6</span></a>).
</span></span></p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Privacy-Oblivious FSL</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we detail our proposed Federated Split Learning (FSL) architecture, that we originally proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
FSL is a hybrid approach that combines the advantages of SL and FL.
<span id="S3.p1.1.1" class="ltx_text" style="color:#000000;"> It avoids sending usersâ€™ source data or sharing the complete NN parameters through the network while being scalable.</span></p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.3" class="ltx_p">Our FSL architecture shown in Fig.Â <a href="#S1.F1.sf4" title="In Figure 1 â€£ 1 Introduction â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a> has three types of entities: <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.2.2"><mo stretchy="false" id="S3.p2.1.m1.1.2.2.1">(</mo><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S3.p2.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">(i)</annotation></semantics></math> edge servers, <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="(ii)" display="inline"><semantics id="S3.p2.2.m2.1a"><mrow id="S3.p2.2.m2.1.1.1" xref="S3.p2.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S3.p2.2.m2.1.1.1.2" xref="S3.p2.2.m2.1.1.1.1.cmml">(</mo><mrow id="S3.p2.2.m2.1.1.1.1" xref="S3.p2.2.m2.1.1.1.1.cmml"><mi id="S3.p2.2.m2.1.1.1.1.2" xref="S3.p2.2.m2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p2.2.m2.1.1.1.1.1" xref="S3.p2.2.m2.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.p2.2.m2.1.1.1.1.3" xref="S3.p2.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S3.p2.2.m2.1.1.1.3" xref="S3.p2.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1"><times id="S3.p2.2.m2.1.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1.1.1"></times><ci id="S3.p2.2.m2.1.1.1.1.2.cmml" xref="S3.p2.2.m2.1.1.1.1.2">ğ‘–</ci><ci id="S3.p2.2.m2.1.1.1.1.3.cmml" xref="S3.p2.2.m2.1.1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">(ii)</annotation></semantics></math> clients, and <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="(iii)" display="inline"><semantics id="S3.p2.3.m3.1a"><mrow id="S3.p2.3.m3.1.1.1" xref="S3.p2.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S3.p2.3.m3.1.1.1.2" xref="S3.p2.3.m3.1.1.1.1.cmml">(</mo><mrow id="S3.p2.3.m3.1.1.1.1" xref="S3.p2.3.m3.1.1.1.1.cmml"><mi id="S3.p2.3.m3.1.1.1.1.2" xref="S3.p2.3.m3.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.1.1.1.1.1" xref="S3.p2.3.m3.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.p2.3.m3.1.1.1.1.3" xref="S3.p2.3.m3.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p2.3.m3.1.1.1.1.1a" xref="S3.p2.3.m3.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.p2.3.m3.1.1.1.1.4" xref="S3.p2.3.m3.1.1.1.1.4.cmml">i</mi></mrow><mo stretchy="false" id="S3.p2.3.m3.1.1.1.3" xref="S3.p2.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.1.1.cmml" xref="S3.p2.3.m3.1.1.1"><times id="S3.p2.3.m3.1.1.1.1.1.cmml" xref="S3.p2.3.m3.1.1.1.1.1"></times><ci id="S3.p2.3.m3.1.1.1.1.2.cmml" xref="S3.p2.3.m3.1.1.1.1.2">ğ‘–</ci><ci id="S3.p2.3.m3.1.1.1.1.3.cmml" xref="S3.p2.3.m3.1.1.1.1.3">ğ‘–</ci><ci id="S3.p2.3.m3.1.1.1.1.4.cmml" xref="S3.p2.3.m3.1.1.1.1.4">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">(iii)</annotation></semantics></math> parameter servers.
To train a NN with FSL, we first setup a<span id="S3.p2.3.1" class="ltx_text" style="color:#000000;"> n</span> authentication protocolÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> among the entities to pair
<span id="S3.p2.3.2" class="ltx_text" style="color:#000000;"> each client with one edge server, and edge servers with a parameter server.</span>
After pairs are found, the communications are sent without encryption.
Then, in each client and server pair, we partition the complete NN into the clientâ€™s partition and (edge) serverâ€™s partition.
</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text" style="color:#000000;">FSL has three training steps. In step 1, the client forward propagates with source data and transmits the intermediate data to the edge server. The server then finishes the propagation and calculates the loss.
In step 2, the server backward propagates to client source data.
In step 3, after epochs, the <span id="S3.p3.1.1.1" class="ltx_text ltx_font_italic">parameter server</span> averages the weights in the edge servers.
</span></p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.2" class="ltx_p"><span id="S3.p4.2.1" class="ltx_text" style="color:#000000;">Consequently, FSL will have multiple advantages compared to the other approaches discussed.
FSL clients will have a lower resource demand compared to FL since it will have  fewer NN layers to train.
 Thus FSL is a more practical scheme for edge intelligence application.
Also, while FSL only averages the weights in the edge servers, FedAVG averages the complete weights.
 Therefore FSL avoids potential vulnerability to model inversion attacksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
 Moreover, FSL provides better scalability than SL, since client and server pairs can train independently.</span>
Compared with the FRCÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> architecture, we note that the latter is inefficient in training time. It updates the parameters of one partition on each forward and backward propagation execution and runs multiple times to update the full model.
Compared with <span id="S3.p4.2.2" class="ltx_text" style="color:#000000;"> Parallel Split LearningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite></span>, we found four <span id="S3.p4.2.3" class="ltx_text" style="color:#000000;"> potential suboptimalities.</span>
First, since the edge devices have to synchronize with the central server,
clients may have to wait until the server has finished with processing all
the results of the activation functions in its queue.
In the worst case, assuming that all activation function results from <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p4.1.m1.1a"><mi id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><ci id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">n</annotation></semantics></math> clients arrive at the same time, the lower bound of waiting time for each client to continue on with backward propagation is <math id="S3.p4.2.m2.1" class="ltx_Math" alttext="O(n)" display="inline"><semantics id="S3.p4.2.m2.1a"><mrow id="S3.p4.2.m2.1.2" xref="S3.p4.2.m2.1.2.cmml"><mi id="S3.p4.2.m2.1.2.2" xref="S3.p4.2.m2.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.p4.2.m2.1.2.1" xref="S3.p4.2.m2.1.2.1.cmml">â€‹</mo><mrow id="S3.p4.2.m2.1.2.3.2" xref="S3.p4.2.m2.1.2.cmml"><mo stretchy="false" id="S3.p4.2.m2.1.2.3.2.1" xref="S3.p4.2.m2.1.2.cmml">(</mo><mi id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml">n</mi><mo stretchy="false" id="S3.p4.2.m2.1.2.3.2.2" xref="S3.p4.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><apply id="S3.p4.2.m2.1.2.cmml" xref="S3.p4.2.m2.1.2"><times id="S3.p4.2.m2.1.2.1.cmml" xref="S3.p4.2.m2.1.2.1"></times><ci id="S3.p4.2.m2.1.2.2.cmml" xref="S3.p4.2.m2.1.2.2">ğ‘‚</ci><ci id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">O(n)</annotation></semantics></math>. We hence conclude that PSL is not as scalable as our FSL.
Second, we also observe that the PSL server would temporarily store multiple batches of the results of activation functions, so it needs a sophisticated logging and compaction storage system to recover from failures.
Consequently, PSL is less robust than our FSL, since
FSL has to maintain fewer states in each isolated pair.
Third, the PSL design may suffer from resiliency problems.
<span id="S3.p4.2.4" class="ltx_text" style="color:#000000;"> Meanwhile, in FSL, failure in one pair wonâ€™t prevent other pairs from training or inference.</span>
Fo<span id="S3.p4.2.5" class="ltx_text" style="color:#000000;"> u</span>rth, in PSL, since all intermediate data will be transmitted and processed by the single server, bandwidth and computation resource at the server node may get congested.
<span id="S3.p4.2.6" class="ltx_text" style="color:#000000;"> Our findings are presented in SectionÂ <a href="#S5" title="5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</span></p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Privacy-Aware FSL</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We have discussed the efficiency and fault-tolerance properties of FSL. In this section, we consider instead the privacy-preserving properties of different architectures and propose our privacy-aware FSL.
In particular, we discuss how to complement general split learning based architectures to mitigate the problem of sharing the output values of NN activation functions or weights over an honest but curious network.
We first give a formal definition of our privacy attacker model, and then we discuss how a Client-based Privacy Approach and <span id="S4.p1.1.1" class="ltx_text" style="color:#000000;"> certain ways of partitioning Neural Network would help avoid such attack.</span></p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_italic">Privacy Attacker Model and Assumptions</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We assume an attacker can capture the <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">Intermediate Data</span> (the results of last layer activation functions transmitted from client to edge server) in plaintext. Moreover, we assume that <span id="S4.SS1.p1.1.2" class="ltx_text" style="color:#000000;"> attacker knows the client NN architecture.</span>
Consequently, the adversary can implement an AutoEncoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> NN to reproduce the source data fed into the client model.
<span id="S4.SS1.p1.1.3" class="ltx_text" style="color:#000000;"> Moreover, to train the autoencoder NN, we assume that some datasets with features similar to the client source data are accessible to the adversary.</span></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_italic">Attack Resilience</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text" style="color:#000000;">Given the attacker model, in order to compare the level of privacy guarantee among different privacy approaches, we define an </span><span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic" style="color:#000000;">Attack Resilience</span><span id="S4.SS2.p1.1.3" class="ltx_text" style="color:#000000;"> metric (</span><math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi mathcolor="#000000" id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\tau</annotation></semantics></math><span id="S4.SS2.p1.1.4" class="ltx_text" style="color:#000000;">) as:</span></p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.2" class="ltx_Math" alttext="\tau=1-\frac{\|correct\|}{\|reconstructed\|}" display="block"><semantics id="S4.E1.m1.2a"><mrow id="S4.E1.m1.2.3" xref="S4.E1.m1.2.3.cmml"><mi mathcolor="#000000" id="S4.E1.m1.2.3.2" xref="S4.E1.m1.2.3.2.cmml">Ï„</mi><mo mathcolor="#000000" id="S4.E1.m1.2.3.1" xref="S4.E1.m1.2.3.1.cmml">=</mo><mrow id="S4.E1.m1.2.3.3" xref="S4.E1.m1.2.3.3.cmml"><mn mathcolor="#000000" id="S4.E1.m1.2.3.3.2" xref="S4.E1.m1.2.3.3.2.cmml">1</mn><mo mathcolor="#000000" id="S4.E1.m1.2.3.3.1" xref="S4.E1.m1.2.3.3.1.cmml">âˆ’</mo><mfrac mathcolor="#000000" id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml"><mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.E1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.2.1.cmml">â€–</mo><mrow id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S4.E1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1a" xref="S4.E1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.1.1.1.1.1.4" xref="S4.E1.m1.1.1.1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1b" xref="S4.E1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.1.1.1.1.1.5" xref="S4.E1.m1.1.1.1.1.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1c" xref="S4.E1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.1.1.1.1.1.6" xref="S4.E1.m1.1.1.1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1d" xref="S4.E1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.1.1.1.1.1.7" xref="S4.E1.m1.1.1.1.1.1.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1e" xref="S4.E1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.1.1.1.1.1.8" xref="S4.E1.m1.1.1.1.1.1.8.cmml">t</mi></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.2.1.cmml">â€–</mo></mrow><mrow id="S4.E1.m1.2.2.2.1" xref="S4.E1.m1.2.2.2.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.E1.m1.2.2.2.1.2" xref="S4.E1.m1.2.2.2.2.1.cmml">â€–</mo><mrow id="S4.E1.m1.2.2.2.1.1" xref="S4.E1.m1.2.2.2.1.1.cmml"><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.2" xref="S4.E1.m1.2.2.2.1.1.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.3" xref="S4.E1.m1.2.2.2.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1a" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.4" xref="S4.E1.m1.2.2.2.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1b" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.5" xref="S4.E1.m1.2.2.2.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1c" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.6" xref="S4.E1.m1.2.2.2.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1d" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.7" xref="S4.E1.m1.2.2.2.1.1.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1e" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.8" xref="S4.E1.m1.2.2.2.1.1.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1f" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.9" xref="S4.E1.m1.2.2.2.1.1.9.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1g" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.10" xref="S4.E1.m1.2.2.2.1.1.10.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1h" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.11" xref="S4.E1.m1.2.2.2.1.1.11.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1i" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.12" xref="S4.E1.m1.2.2.2.1.1.12.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1j" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.13" xref="S4.E1.m1.2.2.2.1.1.13.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.1.1.1k" xref="S4.E1.m1.2.2.2.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E1.m1.2.2.2.1.1.14" xref="S4.E1.m1.2.2.2.1.1.14.cmml">d</mi></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E1.m1.2.2.2.1.3" xref="S4.E1.m1.2.2.2.2.1.cmml">â€–</mo></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.2b"><apply id="S4.E1.m1.2.3.cmml" xref="S4.E1.m1.2.3"><eq id="S4.E1.m1.2.3.1.cmml" xref="S4.E1.m1.2.3.1"></eq><ci id="S4.E1.m1.2.3.2.cmml" xref="S4.E1.m1.2.3.2">ğœ</ci><apply id="S4.E1.m1.2.3.3.cmml" xref="S4.E1.m1.2.3.3"><minus id="S4.E1.m1.2.3.3.1.cmml" xref="S4.E1.m1.2.3.3.1"></minus><cn type="integer" id="S4.E1.m1.2.3.3.2.cmml" xref="S4.E1.m1.2.3.3.2">1</cn><apply id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.2.2"><divide id="S4.E1.m1.2.2.3.cmml" xref="S4.E1.m1.2.2"></divide><apply id="S4.E1.m1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1"><csymbol cd="latexml" id="S4.E1.m1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.2">norm</csymbol><apply id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1"><times id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1"></times><ci id="S4.E1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.2">ğ‘</ci><ci id="S4.E1.m1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.3">ğ‘œ</ci><ci id="S4.E1.m1.1.1.1.1.1.4.cmml" xref="S4.E1.m1.1.1.1.1.1.4">ğ‘Ÿ</ci><ci id="S4.E1.m1.1.1.1.1.1.5.cmml" xref="S4.E1.m1.1.1.1.1.1.5">ğ‘Ÿ</ci><ci id="S4.E1.m1.1.1.1.1.1.6.cmml" xref="S4.E1.m1.1.1.1.1.1.6">ğ‘’</ci><ci id="S4.E1.m1.1.1.1.1.1.7.cmml" xref="S4.E1.m1.1.1.1.1.1.7">ğ‘</ci><ci id="S4.E1.m1.1.1.1.1.1.8.cmml" xref="S4.E1.m1.1.1.1.1.1.8">ğ‘¡</ci></apply></apply><apply id="S4.E1.m1.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.1"><csymbol cd="latexml" id="S4.E1.m1.2.2.2.2.1.cmml" xref="S4.E1.m1.2.2.2.1.2">norm</csymbol><apply id="S4.E1.m1.2.2.2.1.1.cmml" xref="S4.E1.m1.2.2.2.1.1"><times id="S4.E1.m1.2.2.2.1.1.1.cmml" xref="S4.E1.m1.2.2.2.1.1.1"></times><ci id="S4.E1.m1.2.2.2.1.1.2.cmml" xref="S4.E1.m1.2.2.2.1.1.2">ğ‘Ÿ</ci><ci id="S4.E1.m1.2.2.2.1.1.3.cmml" xref="S4.E1.m1.2.2.2.1.1.3">ğ‘’</ci><ci id="S4.E1.m1.2.2.2.1.1.4.cmml" xref="S4.E1.m1.2.2.2.1.1.4">ğ‘</ci><ci id="S4.E1.m1.2.2.2.1.1.5.cmml" xref="S4.E1.m1.2.2.2.1.1.5">ğ‘œ</ci><ci id="S4.E1.m1.2.2.2.1.1.6.cmml" xref="S4.E1.m1.2.2.2.1.1.6">ğ‘›</ci><ci id="S4.E1.m1.2.2.2.1.1.7.cmml" xref="S4.E1.m1.2.2.2.1.1.7">ğ‘ </ci><ci id="S4.E1.m1.2.2.2.1.1.8.cmml" xref="S4.E1.m1.2.2.2.1.1.8">ğ‘¡</ci><ci id="S4.E1.m1.2.2.2.1.1.9.cmml" xref="S4.E1.m1.2.2.2.1.1.9">ğ‘Ÿ</ci><ci id="S4.E1.m1.2.2.2.1.1.10.cmml" xref="S4.E1.m1.2.2.2.1.1.10">ğ‘¢</ci><ci id="S4.E1.m1.2.2.2.1.1.11.cmml" xref="S4.E1.m1.2.2.2.1.1.11">ğ‘</ci><ci id="S4.E1.m1.2.2.2.1.1.12.cmml" xref="S4.E1.m1.2.2.2.1.1.12">ğ‘¡</ci><ci id="S4.E1.m1.2.2.2.1.1.13.cmml" xref="S4.E1.m1.2.2.2.1.1.13">ğ‘’</ci><ci id="S4.E1.m1.2.2.2.1.1.14.cmml" xref="S4.E1.m1.2.2.2.1.1.14">ğ‘‘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.2c">\tau=1-\frac{\|correct\|}{\|reconstructed\|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.3" class="ltx_p"><span id="S4.SS2.p1.3.1" class="ltx_text" style="color:#000000;">It measures the misclassification rate.
</span><math id="S4.SS2.p1.2.m1.1" class="ltx_Math" alttext="\|correct\|" display="inline"><semantics id="S4.SS2.p1.2.m1.1a"><mrow id="S4.SS2.p1.2.m1.1.1.1" xref="S4.SS2.p1.2.m1.1.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.SS2.p1.2.m1.1.1.1.2" xref="S4.SS2.p1.2.m1.1.1.2.1.cmml">â€–</mo><mrow id="S4.SS2.p1.2.m1.1.1.1.1" xref="S4.SS2.p1.2.m1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS2.p1.2.m1.1.1.1.1.2" xref="S4.SS2.p1.2.m1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m1.1.1.1.1.1" xref="S4.SS2.p1.2.m1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.2.m1.1.1.1.1.3" xref="S4.SS2.p1.2.m1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m1.1.1.1.1.1a" xref="S4.SS2.p1.2.m1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.2.m1.1.1.1.1.4" xref="S4.SS2.p1.2.m1.1.1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m1.1.1.1.1.1b" xref="S4.SS2.p1.2.m1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.2.m1.1.1.1.1.5" xref="S4.SS2.p1.2.m1.1.1.1.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m1.1.1.1.1.1c" xref="S4.SS2.p1.2.m1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.2.m1.1.1.1.1.6" xref="S4.SS2.p1.2.m1.1.1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m1.1.1.1.1.1d" xref="S4.SS2.p1.2.m1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.2.m1.1.1.1.1.7" xref="S4.SS2.p1.2.m1.1.1.1.1.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m1.1.1.1.1.1e" xref="S4.SS2.p1.2.m1.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.2.m1.1.1.1.1.8" xref="S4.SS2.p1.2.m1.1.1.1.1.8.cmml">t</mi></mrow><mo mathcolor="#000000" stretchy="false" id="S4.SS2.p1.2.m1.1.1.1.3" xref="S4.SS2.p1.2.m1.1.1.2.1.cmml">â€–</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m1.1b"><apply id="S4.SS2.p1.2.m1.1.1.2.cmml" xref="S4.SS2.p1.2.m1.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.2.m1.1.1.2.1.cmml" xref="S4.SS2.p1.2.m1.1.1.1.2">norm</csymbol><apply id="S4.SS2.p1.2.m1.1.1.1.1.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1"><times id="S4.SS2.p1.2.m1.1.1.1.1.1.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.1"></times><ci id="S4.SS2.p1.2.m1.1.1.1.1.2.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.2">ğ‘</ci><ci id="S4.SS2.p1.2.m1.1.1.1.1.3.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.3">ğ‘œ</ci><ci id="S4.SS2.p1.2.m1.1.1.1.1.4.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.4">ğ‘Ÿ</ci><ci id="S4.SS2.p1.2.m1.1.1.1.1.5.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.5">ğ‘Ÿ</ci><ci id="S4.SS2.p1.2.m1.1.1.1.1.6.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.6">ğ‘’</ci><ci id="S4.SS2.p1.2.m1.1.1.1.1.7.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.7">ğ‘</ci><ci id="S4.SS2.p1.2.m1.1.1.1.1.8.cmml" xref="S4.SS2.p1.2.m1.1.1.1.1.8">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m1.1c">\|correct\|</annotation></semantics></math><span id="S4.SS2.p1.3.2" class="ltx_text" style="color:#000000;"> counts the number of images, reproduced by the attacker, which can be correctly classified by a trained classifier (Section </span><a href="#S5.SS3.SSS3" title="5.3.3 Privacy Evaluation: Methodology â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">5.3.3</span></a><span id="S4.SS2.p1.3.3" class="ltx_text" style="color:#000000;">).
And </span><math id="S4.SS2.p1.3.m2.1" class="ltx_Math" alttext="\|reconstructed\|" display="inline"><semantics id="S4.SS2.p1.3.m2.1a"><mrow id="S4.SS2.p1.3.m2.1.1.1" xref="S4.SS2.p1.3.m2.1.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.SS2.p1.3.m2.1.1.1.2" xref="S4.SS2.p1.3.m2.1.1.2.1.cmml">â€–</mo><mrow id="S4.SS2.p1.3.m2.1.1.1.1" xref="S4.SS2.p1.3.m2.1.1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.2" xref="S4.SS2.p1.3.m2.1.1.1.1.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.3" xref="S4.SS2.p1.3.m2.1.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1a" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.4" xref="S4.SS2.p1.3.m2.1.1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1b" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.5" xref="S4.SS2.p1.3.m2.1.1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1c" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.6" xref="S4.SS2.p1.3.m2.1.1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1d" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.7" xref="S4.SS2.p1.3.m2.1.1.1.1.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1e" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.8" xref="S4.SS2.p1.3.m2.1.1.1.1.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1f" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.9" xref="S4.SS2.p1.3.m2.1.1.1.1.9.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1g" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.10" xref="S4.SS2.p1.3.m2.1.1.1.1.10.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1h" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.11" xref="S4.SS2.p1.3.m2.1.1.1.1.11.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1i" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.12" xref="S4.SS2.p1.3.m2.1.1.1.1.12.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1j" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.13" xref="S4.SS2.p1.3.m2.1.1.1.1.13.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m2.1.1.1.1.1k" xref="S4.SS2.p1.3.m2.1.1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.SS2.p1.3.m2.1.1.1.1.14" xref="S4.SS2.p1.3.m2.1.1.1.1.14.cmml">d</mi></mrow><mo mathcolor="#000000" stretchy="false" id="S4.SS2.p1.3.m2.1.1.1.3" xref="S4.SS2.p1.3.m2.1.1.2.1.cmml">â€–</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m2.1b"><apply id="S4.SS2.p1.3.m2.1.1.2.cmml" xref="S4.SS2.p1.3.m2.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.3.m2.1.1.2.1.cmml" xref="S4.SS2.p1.3.m2.1.1.1.2">norm</csymbol><apply id="S4.SS2.p1.3.m2.1.1.1.1.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1"><times id="S4.SS2.p1.3.m2.1.1.1.1.1.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.1"></times><ci id="S4.SS2.p1.3.m2.1.1.1.1.2.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.2">ğ‘Ÿ</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.3.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.3">ğ‘’</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.4.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.4">ğ‘</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.5.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.5">ğ‘œ</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.6.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.6">ğ‘›</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.7.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.7">ğ‘ </ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.8.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.8">ğ‘¡</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.9.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.9">ğ‘Ÿ</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.10.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.10">ğ‘¢</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.11.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.11">ğ‘</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.12.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.12">ğ‘¡</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.13.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.13">ğ‘’</ci><ci id="S4.SS2.p1.3.m2.1.1.1.1.14.cmml" xref="S4.SS2.p1.3.m2.1.1.1.1.14">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m2.1c">\|reconstructed\|</annotation></semantics></math><span id="S4.SS2.p1.3.4" class="ltx_text" style="color:#000000;"> is the total number of reproduced images.
</span><span id="S4.SS2.p1.3.5" class="ltx_text"></span></p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span><span id="S4.SS3.1.1" class="ltx_text ltx_font_italic">Client-Based Privacy Approach in Distributed Setting via Distance Correlation (CPA-DC)</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Motivated by the NoPeek approachÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, where weights are updated based on the sum of two loss functions, i.e., Cross-Entropy, and Distance Correlation (DC), we adopted the idea of using two loss functions into an alternately scheduling mechanism with two rounds:
the <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">regular round</span>, minimizes the cross-entropy loss function in the (edge) server. The <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">Distance Correlation round</span>, maximizes the DC loss function in the client.
The idea is that we add noise that make source and intermediate data different to clientâ€™s weights.
We define this alternating behavior with loss functions in EquationÂ <a href="#S4.E2" title="In 4.3 Client-Based Privacy Approach in Distributed Setting via Distance Correlation (CPA-DC) â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>:</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.4" class="ltx_Math" alttext="L=\begin{cases}Loss(g(f(x)),label)&amp;if\hskip 5.69046pte~{}$mod$~{}F~{}$== 0$\\
m\cdot DC(x,f(x))&amp;\text{otherwise,}\end{cases}" display="block"><semantics id="S4.E2.m1.4a"><mrow id="S4.E2.m1.4.5" xref="S4.E2.m1.4.5.cmml"><mi id="S4.E2.m1.4.5.2" xref="S4.E2.m1.4.5.2.cmml">L</mi><mo id="S4.E2.m1.4.5.1" xref="S4.E2.m1.4.5.1.cmml">=</mo><mrow id="S4.E2.m1.4.4" xref="S4.E2.m1.4.5.3.1.cmml"><mo id="S4.E2.m1.4.4.5" xref="S4.E2.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S4.E2.m1.4.4.4" xref="S4.E2.m1.4.5.3.1.cmml"><mtr id="S4.E2.m1.4.4.4a" xref="S4.E2.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E2.m1.4.4.4b" xref="S4.E2.m1.4.5.3.1.cmml"><mrow id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.5" xref="S4.E2.m1.1.1.1.1.1.1.5.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.4" xref="S4.E2.m1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S4.E2.m1.1.1.1.1.1.1.6" xref="S4.E2.m1.1.1.1.1.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.4a" xref="S4.E2.m1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S4.E2.m1.1.1.1.1.1.1.7" xref="S4.E2.m1.1.1.1.1.1.1.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.4b" xref="S4.E2.m1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S4.E2.m1.1.1.1.1.1.1.8" xref="S4.E2.m1.1.1.1.1.1.1.8.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.4c" xref="S4.E2.m1.1.1.1.1.1.1.4.cmml">â€‹</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.1.1.3.3.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.3.2.3" xref="S4.E2.m1.1.1.1.1.1.1.3.3.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.2.1.1" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.2.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.2.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.2.cmml">â€‹</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.3.2.1" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml">(</mo><mi id="S4.E2.m1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml">x</mi><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.3.2.2" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.1.1.1.1.1.1.3.2.4" xref="S4.E2.m1.1.1.1.1.1.1.3.3.cmml">,</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.3.2.2" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.3.2.2.2" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.3.2.2.1" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml">â€‹</mo><mi id="S4.E2.m1.1.1.1.1.1.1.3.2.2.3" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.3.2.2.1a" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml">â€‹</mo><mi id="S4.E2.m1.1.1.1.1.1.1.3.2.2.4" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.4.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.3.2.2.1b" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml">â€‹</mo><mi id="S4.E2.m1.1.1.1.1.1.1.3.2.2.5" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.3.2.2.1c" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml">â€‹</mo><mi id="S4.E2.m1.1.1.1.1.1.1.3.2.2.6" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.6.cmml">l</mi></mrow><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.3.2.5" xref="S4.E2.m1.1.1.1.1.1.1.3.3.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E2.m1.4.4.4c" xref="S4.E2.m1.4.5.3.1.cmml"><mrow id="S4.E2.m1.2.2.2.2.2.1" xref="S4.E2.m1.2.2.2.2.2.1.cmml"><mi id="S4.E2.m1.2.2.2.2.2.1.2" xref="S4.E2.m1.2.2.2.2.2.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.2.2.1.1" xref="S4.E2.m1.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S4.E2.m1.2.2.2.2.2.1.3" xref="S4.E2.m1.2.2.2.2.2.1.3.cmml">f</mi><mo lspace="0.570em" rspace="0em" id="S4.E2.m1.2.2.2.2.2.1.1a" xref="S4.E2.m1.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S4.E2.m1.2.2.2.2.2.1.4" xref="S4.E2.m1.2.2.2.2.2.1.4.cmml">e</mi><mo lspace="0.330em" rspace="0em" id="S4.E2.m1.2.2.2.2.2.1.1b" xref="S4.E2.m1.2.2.2.2.2.1.1.cmml">â€‹</mo><mtext id="S4.E2.m1.2.2.2.2.2.1.5" xref="S4.E2.m1.2.2.2.2.2.1.5a.cmml">mod</mtext><mo lspace="0.330em" rspace="0em" id="S4.E2.m1.2.2.2.2.2.1.1c" xref="S4.E2.m1.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S4.E2.m1.2.2.2.2.2.1.6" xref="S4.E2.m1.2.2.2.2.2.1.6.cmml">F</mi><mo lspace="0.330em" rspace="0em" id="S4.E2.m1.2.2.2.2.2.1.1d" xref="S4.E2.m1.2.2.2.2.2.1.1.cmml">â€‹</mo><mtext id="S4.E2.m1.2.2.2.2.2.1.7" xref="S4.E2.m1.2.2.2.2.2.1.7a.cmml">== 0</mtext></mrow></mtd></mtr><mtr id="S4.E2.m1.4.4.4d" xref="S4.E2.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E2.m1.4.4.4e" xref="S4.E2.m1.4.5.3.1.cmml"><mrow id="S4.E2.m1.3.3.3.3.1.1" xref="S4.E2.m1.3.3.3.3.1.1.cmml"><mrow id="S4.E2.m1.3.3.3.3.1.1.5" xref="S4.E2.m1.3.3.3.3.1.1.5.cmml"><mi id="S4.E2.m1.3.3.3.3.1.1.5.2" xref="S4.E2.m1.3.3.3.3.1.1.5.2.cmml">m</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E2.m1.3.3.3.3.1.1.5.1" xref="S4.E2.m1.3.3.3.3.1.1.5.1.cmml">â‹…</mo><mi id="S4.E2.m1.3.3.3.3.1.1.5.3" xref="S4.E2.m1.3.3.3.3.1.1.5.3.cmml">D</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.3.3.1.1.4" xref="S4.E2.m1.3.3.3.3.1.1.4.cmml">â€‹</mo><mi id="S4.E2.m1.3.3.3.3.1.1.6" xref="S4.E2.m1.3.3.3.3.1.1.6.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.3.3.1.1.4a" xref="S4.E2.m1.3.3.3.3.1.1.4.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.3.3.1.1.3.1" xref="S4.E2.m1.3.3.3.3.1.1.3.2.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.3.3.1.1.3.1.2" xref="S4.E2.m1.3.3.3.3.1.1.3.2.cmml">(</mo><mi id="S4.E2.m1.3.3.3.3.1.1.2" xref="S4.E2.m1.3.3.3.3.1.1.2.cmml">x</mi><mo id="S4.E2.m1.3.3.3.3.1.1.3.1.3" xref="S4.E2.m1.3.3.3.3.1.1.3.2.cmml">,</mo><mrow id="S4.E2.m1.3.3.3.3.1.1.3.1.1" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.cmml"><mi id="S4.E2.m1.3.3.3.3.1.1.3.1.1.2" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.3.3.1.1.3.1.1.1" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.1.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.3.3.1.1.3.1.1.3.2" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.3.3.1.1.3.1.1.3.2.1" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.cmml">(</mo><mi id="S4.E2.m1.3.3.3.3.1.1.1" xref="S4.E2.m1.3.3.3.3.1.1.1.cmml">x</mi><mo stretchy="false" id="S4.E2.m1.3.3.3.3.1.1.3.1.1.3.2.2" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E2.m1.3.3.3.3.1.1.3.1.4" xref="S4.E2.m1.3.3.3.3.1.1.3.2.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E2.m1.4.4.4f" xref="S4.E2.m1.4.5.3.1.cmml"><mtext id="S4.E2.m1.4.4.4.4.2.1" xref="S4.E2.m1.4.4.4.4.2.1a.cmml">otherwise,</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.4b"><apply id="S4.E2.m1.4.5.cmml" xref="S4.E2.m1.4.5"><eq id="S4.E2.m1.4.5.1.cmml" xref="S4.E2.m1.4.5.1"></eq><ci id="S4.E2.m1.4.5.2.cmml" xref="S4.E2.m1.4.5.2">ğ¿</ci><apply id="S4.E2.m1.4.5.3.1.cmml" xref="S4.E2.m1.4.4"><csymbol cd="latexml" id="S4.E2.m1.4.5.3.1.1.cmml" xref="S4.E2.m1.4.4.5">cases</csymbol><apply id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1"><times id="S4.E2.m1.1.1.1.1.1.1.4.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4"></times><ci id="S4.E2.m1.1.1.1.1.1.1.5.cmml" xref="S4.E2.m1.1.1.1.1.1.1.5">ğ¿</ci><ci id="S4.E2.m1.1.1.1.1.1.1.6.cmml" xref="S4.E2.m1.1.1.1.1.1.1.6">ğ‘œ</ci><ci id="S4.E2.m1.1.1.1.1.1.1.7.cmml" xref="S4.E2.m1.1.1.1.1.1.1.7">ğ‘ </ci><ci id="S4.E2.m1.1.1.1.1.1.1.8.cmml" xref="S4.E2.m1.1.1.1.1.1.1.8">ğ‘ </ci><interval closure="open" id="S4.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2"><apply id="S4.E2.m1.1.1.1.1.1.1.2.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1"><times id="S4.E2.m1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.2"></times><ci id="S4.E2.m1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.3">ğ‘”</ci><apply id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1"><times id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.1"></times><ci id="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.1.1.1.1.1.2">ğ‘“</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1">ğ‘¥</ci></apply></apply><apply id="S4.E2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2"><times id="S4.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.1"></times><ci id="S4.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.2">ğ‘™</ci><ci id="S4.E2.m1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.3">ğ‘</ci><ci id="S4.E2.m1.1.1.1.1.1.1.3.2.2.4.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.4">ğ‘</ci><ci id="S4.E2.m1.1.1.1.1.1.1.3.2.2.5.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.5">ğ‘’</ci><ci id="S4.E2.m1.1.1.1.1.1.1.3.2.2.6.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2.2.6">ğ‘™</ci></apply></interval></apply><apply id="S4.E2.m1.2.2.2.2.2.1.cmml" xref="S4.E2.m1.2.2.2.2.2.1"><times id="S4.E2.m1.2.2.2.2.2.1.1.cmml" xref="S4.E2.m1.2.2.2.2.2.1.1"></times><ci id="S4.E2.m1.2.2.2.2.2.1.2.cmml" xref="S4.E2.m1.2.2.2.2.2.1.2">ğ‘–</ci><ci id="S4.E2.m1.2.2.2.2.2.1.3.cmml" xref="S4.E2.m1.2.2.2.2.2.1.3">ğ‘“</ci><ci id="S4.E2.m1.2.2.2.2.2.1.4.cmml" xref="S4.E2.m1.2.2.2.2.2.1.4">ğ‘’</ci><ci id="S4.E2.m1.2.2.2.2.2.1.5a.cmml" xref="S4.E2.m1.2.2.2.2.2.1.5"><mtext id="S4.E2.m1.2.2.2.2.2.1.5.cmml" xref="S4.E2.m1.2.2.2.2.2.1.5">mod</mtext></ci><ci id="S4.E2.m1.2.2.2.2.2.1.6.cmml" xref="S4.E2.m1.2.2.2.2.2.1.6">ğ¹</ci><ci id="S4.E2.m1.2.2.2.2.2.1.7a.cmml" xref="S4.E2.m1.2.2.2.2.2.1.7"><mtext id="S4.E2.m1.2.2.2.2.2.1.7.cmml" xref="S4.E2.m1.2.2.2.2.2.1.7">== 0</mtext></ci></apply><apply id="S4.E2.m1.3.3.3.3.1.1.cmml" xref="S4.E2.m1.3.3.3.3.1.1"><times id="S4.E2.m1.3.3.3.3.1.1.4.cmml" xref="S4.E2.m1.3.3.3.3.1.1.4"></times><apply id="S4.E2.m1.3.3.3.3.1.1.5.cmml" xref="S4.E2.m1.3.3.3.3.1.1.5"><ci id="S4.E2.m1.3.3.3.3.1.1.5.1.cmml" xref="S4.E2.m1.3.3.3.3.1.1.5.1">â‹…</ci><ci id="S4.E2.m1.3.3.3.3.1.1.5.2.cmml" xref="S4.E2.m1.3.3.3.3.1.1.5.2">ğ‘š</ci><ci id="S4.E2.m1.3.3.3.3.1.1.5.3.cmml" xref="S4.E2.m1.3.3.3.3.1.1.5.3">ğ·</ci></apply><ci id="S4.E2.m1.3.3.3.3.1.1.6.cmml" xref="S4.E2.m1.3.3.3.3.1.1.6">ğ¶</ci><interval closure="open" id="S4.E2.m1.3.3.3.3.1.1.3.2.cmml" xref="S4.E2.m1.3.3.3.3.1.1.3.1"><ci id="S4.E2.m1.3.3.3.3.1.1.2.cmml" xref="S4.E2.m1.3.3.3.3.1.1.2">ğ‘¥</ci><apply id="S4.E2.m1.3.3.3.3.1.1.3.1.1.cmml" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1"><times id="S4.E2.m1.3.3.3.3.1.1.3.1.1.1.cmml" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.1"></times><ci id="S4.E2.m1.3.3.3.3.1.1.3.1.1.2.cmml" xref="S4.E2.m1.3.3.3.3.1.1.3.1.1.2">ğ‘“</ci><ci id="S4.E2.m1.3.3.3.3.1.1.1.cmml" xref="S4.E2.m1.3.3.3.3.1.1.1">ğ‘¥</ci></apply></interval></apply><ci id="S4.E2.m1.4.4.4.4.2.1a.cmml" xref="S4.E2.m1.4.4.4.4.2.1"><mtext id="S4.E2.m1.4.4.4.4.2.1.cmml" xref="S4.E2.m1.4.4.4.4.2.1">otherwise,</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.4c">L=\begin{cases}Loss(g(f(x)),label)&amp;if\hskip 5.69046pte~{}$mod$~{}F~{}$== 0$\\
m\cdot DC(x,f(x))&amp;\text{otherwise,}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS3.p2.13" class="ltx_p">where <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">L</annotation></semantics></math> is the measured loss value, <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">e</annotation></semantics></math> represents the epoch index, <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mi id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><ci id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">F</annotation></semantics></math> represents the <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="DC\_Frequency" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1a" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S4.SS3.p2.4.m4.1.1.4" xref="S4.SS3.p2.4.m4.1.1.4.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1b" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.5" xref="S4.SS3.p2.4.m4.1.1.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1c" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.6" xref="S4.SS3.p2.4.m4.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1d" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.7" xref="S4.SS3.p2.4.m4.1.1.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1e" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.8" xref="S4.SS3.p2.4.m4.1.1.8.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1f" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.9" xref="S4.SS3.p2.4.m4.1.1.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1g" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.10" xref="S4.SS3.p2.4.m4.1.1.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1h" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.11" xref="S4.SS3.p2.4.m4.1.1.11.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1i" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.12" xref="S4.SS3.p2.4.m4.1.1.12.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1j" xref="S4.SS3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.4.m4.1.1.13" xref="S4.SS3.p2.4.m4.1.1.13.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><times id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1.1"></times><ci id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2">ğ·</ci><ci id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3">ğ¶</ci><ci id="S4.SS3.p2.4.m4.1.1.4.cmml" xref="S4.SS3.p2.4.m4.1.1.4">_</ci><ci id="S4.SS3.p2.4.m4.1.1.5.cmml" xref="S4.SS3.p2.4.m4.1.1.5">ğ¹</ci><ci id="S4.SS3.p2.4.m4.1.1.6.cmml" xref="S4.SS3.p2.4.m4.1.1.6">ğ‘Ÿ</ci><ci id="S4.SS3.p2.4.m4.1.1.7.cmml" xref="S4.SS3.p2.4.m4.1.1.7">ğ‘’</ci><ci id="S4.SS3.p2.4.m4.1.1.8.cmml" xref="S4.SS3.p2.4.m4.1.1.8">ğ‘</ci><ci id="S4.SS3.p2.4.m4.1.1.9.cmml" xref="S4.SS3.p2.4.m4.1.1.9">ğ‘¢</ci><ci id="S4.SS3.p2.4.m4.1.1.10.cmml" xref="S4.SS3.p2.4.m4.1.1.10">ğ‘’</ci><ci id="S4.SS3.p2.4.m4.1.1.11.cmml" xref="S4.SS3.p2.4.m4.1.1.11">ğ‘›</ci><ci id="S4.SS3.p2.4.m4.1.1.12.cmml" xref="S4.SS3.p2.4.m4.1.1.12">ğ‘</ci><ci id="S4.SS3.p2.4.m4.1.1.13.cmml" xref="S4.SS3.p2.4.m4.1.1.13">ğ‘¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">DC\_Frequency</annotation></semantics></math>, <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="Loss(\cdot)" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.2" xref="S4.SS3.p2.5.m5.1.2.cmml"><mi id="S4.SS3.p2.5.m5.1.2.2" xref="S4.SS3.p2.5.m5.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.5.m5.1.2.1" xref="S4.SS3.p2.5.m5.1.2.1.cmml">â€‹</mo><mi id="S4.SS3.p2.5.m5.1.2.3" xref="S4.SS3.p2.5.m5.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.5.m5.1.2.1a" xref="S4.SS3.p2.5.m5.1.2.1.cmml">â€‹</mo><mi id="S4.SS3.p2.5.m5.1.2.4" xref="S4.SS3.p2.5.m5.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.5.m5.1.2.1b" xref="S4.SS3.p2.5.m5.1.2.1.cmml">â€‹</mo><mi id="S4.SS3.p2.5.m5.1.2.5" xref="S4.SS3.p2.5.m5.1.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.5.m5.1.2.1c" xref="S4.SS3.p2.5.m5.1.2.1.cmml">â€‹</mo><mrow id="S4.SS3.p2.5.m5.1.2.6.2" xref="S4.SS3.p2.5.m5.1.2.cmml"><mo stretchy="false" id="S4.SS3.p2.5.m5.1.2.6.2.1" xref="S4.SS3.p2.5.m5.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml">â‹…</mo><mo stretchy="false" id="S4.SS3.p2.5.m5.1.2.6.2.2" xref="S4.SS3.p2.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.2.cmml" xref="S4.SS3.p2.5.m5.1.2"><times id="S4.SS3.p2.5.m5.1.2.1.cmml" xref="S4.SS3.p2.5.m5.1.2.1"></times><ci id="S4.SS3.p2.5.m5.1.2.2.cmml" xref="S4.SS3.p2.5.m5.1.2.2">ğ¿</ci><ci id="S4.SS3.p2.5.m5.1.2.3.cmml" xref="S4.SS3.p2.5.m5.1.2.3">ğ‘œ</ci><ci id="S4.SS3.p2.5.m5.1.2.4.cmml" xref="S4.SS3.p2.5.m5.1.2.4">ğ‘ </ci><ci id="S4.SS3.p2.5.m5.1.2.5.cmml" xref="S4.SS3.p2.5.m5.1.2.5">ğ‘ </ci><ci id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">Loss(\cdot)</annotation></semantics></math> is the loss function used to measure mis-classifications, <math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="DC" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mrow id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml"><mi id="S4.SS3.p2.6.m6.1.1.2" xref="S4.SS3.p2.6.m6.1.1.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.6.m6.1.1.1" xref="S4.SS3.p2.6.m6.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.6.m6.1.1.3" xref="S4.SS3.p2.6.m6.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><apply id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1"><times id="S4.SS3.p2.6.m6.1.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1.1"></times><ci id="S4.SS3.p2.6.m6.1.1.2.cmml" xref="S4.SS3.p2.6.m6.1.1.2">ğ·</ci><ci id="S4.SS3.p2.6.m6.1.1.3.cmml" xref="S4.SS3.p2.6.m6.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">DC</annotation></semantics></math> is the distance correlation loss, <math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><mi id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><ci id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">m</annotation></semantics></math> is the <span id="S4.SS3.p2.13.3" class="ltx_text ltx_font_italic">loss multiplier</span>, <math id="S4.SS3.p2.8.m8.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS3.p2.8.m8.1a"><mi id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><ci id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">f</annotation></semantics></math> is the client NN, <math id="S4.SS3.p2.9.m9.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S4.SS3.p2.9.m9.1a"><mi id="S4.SS3.p2.9.m9.1.1" xref="S4.SS3.p2.9.m9.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.9.m9.1b"><ci id="S4.SS3.p2.9.m9.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.9.m9.1c">g</annotation></semantics></math> is the server NN, <math id="S4.SS3.p2.10.m10.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SS3.p2.10.m10.1a"><mi id="S4.SS3.p2.10.m10.1.1" xref="S4.SS3.p2.10.m10.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.10.m10.1b"><ci id="S4.SS3.p2.10.m10.1.1.cmml" xref="S4.SS3.p2.10.m10.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.10.m10.1c">x</annotation></semantics></math> is the source data, and <math id="S4.SS3.p2.11.m11.1" class="ltx_Math" alttext="label" display="inline"><semantics id="S4.SS3.p2.11.m11.1a"><mrow id="S4.SS3.p2.11.m11.1.1" xref="S4.SS3.p2.11.m11.1.1.cmml"><mi id="S4.SS3.p2.11.m11.1.1.2" xref="S4.SS3.p2.11.m11.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.11.m11.1.1.1" xref="S4.SS3.p2.11.m11.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.11.m11.1.1.3" xref="S4.SS3.p2.11.m11.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.11.m11.1.1.1a" xref="S4.SS3.p2.11.m11.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.11.m11.1.1.4" xref="S4.SS3.p2.11.m11.1.1.4.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.11.m11.1.1.1b" xref="S4.SS3.p2.11.m11.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.11.m11.1.1.5" xref="S4.SS3.p2.11.m11.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.11.m11.1.1.1c" xref="S4.SS3.p2.11.m11.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p2.11.m11.1.1.6" xref="S4.SS3.p2.11.m11.1.1.6.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.11.m11.1b"><apply id="S4.SS3.p2.11.m11.1.1.cmml" xref="S4.SS3.p2.11.m11.1.1"><times id="S4.SS3.p2.11.m11.1.1.1.cmml" xref="S4.SS3.p2.11.m11.1.1.1"></times><ci id="S4.SS3.p2.11.m11.1.1.2.cmml" xref="S4.SS3.p2.11.m11.1.1.2">ğ‘™</ci><ci id="S4.SS3.p2.11.m11.1.1.3.cmml" xref="S4.SS3.p2.11.m11.1.1.3">ğ‘</ci><ci id="S4.SS3.p2.11.m11.1.1.4.cmml" xref="S4.SS3.p2.11.m11.1.1.4">ğ‘</ci><ci id="S4.SS3.p2.11.m11.1.1.5.cmml" xref="S4.SS3.p2.11.m11.1.1.5">ğ‘’</ci><ci id="S4.SS3.p2.11.m11.1.1.6.cmml" xref="S4.SS3.p2.11.m11.1.1.6">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.11.m11.1c">label</annotation></semantics></math> is the labels in the source data.
<span id="S4.SS3.p2.13.2" class="ltx_text" style="color:#000000;"> Notice that <math id="S4.SS3.p2.12.1.m1.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S4.SS3.p2.12.1.m1.1a"><mi mathcolor="#000000" id="S4.SS3.p2.12.1.m1.1.1" xref="S4.SS3.p2.12.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.12.1.m1.1b"><ci id="S4.SS3.p2.12.1.m1.1.1.cmml" xref="S4.SS3.p2.12.1.m1.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.12.1.m1.1c">F</annotation></semantics></math> controls the alternation frequency and <math id="S4.SS3.p2.13.2.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.SS3.p2.13.2.m2.1a"><mi mathcolor="#000000" id="S4.SS3.p2.13.2.m2.1.1" xref="S4.SS3.p2.13.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.13.2.m2.1b"><ci id="S4.SS3.p2.13.2.m2.1.1.cmml" xref="S4.SS3.p2.13.2.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.13.2.m2.1c">m</annotation></semantics></math> adds a weight to the DC loss.</span></p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">The alternating loss function is a policy. Our Client-Based Privacy Approach (CPA) can also work with other loss functions or methods adding random noise to the regular round.
In the evaluation, we explored several methods to embed the noise.
In particular, we explored the trade-off between training time and the highest attack resilience.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span><span id="S4.SS4.1.1" class="ltx_text ltx_font_italic">How many layers do we assign
<br class="ltx_break">to each neural network partition?</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this section, we discuss the problem of selecting how many layers need to be assigned for each NN partition<span id="S4.SS4.p1.1.1" class="ltx_text" style="color:#000000;"> , i.e., client NN depth</span>.
This tradeoff will tune training time <span id="S4.SS4.p1.1.2" class="ltx_text" style="color:#000000;"> (processing and transmission delay)</span>, privacy, and accuracy.
Capturing the tradeoff between all these metrics is challenging.
To illustrate,
consider the tradeoff between processing delay and transmission delay.
<span id="S4.SS4.p1.1.3" class="ltx_text" style="color:#000000;"> 
The size difference among output layers in different partitions can be large, so a few partitioning policies may lead to significant transmission overhead, increasing training time and hence diminishing the gain of the hybrid FSL compared to the original Federated Learning architecture.
In VGG-16<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, the output size of the first convolutional layer is two times the size of the second convolutional layer.
Thus, a system with a model cut after the second convolutional layer can tradeoff the extra processing delay at low-capacity clients while yielding a lower transmission delay. We evaluate this effect in SectionÂ <a href="#S5.SS2.SSS2" title="5.2.2 Training Time Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.2</span></a>.</span></p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.4" class="ltx_p"><span id="S4.SS4.p2.4.4" class="ltx_text" style="color:#000000;">Analytically, this effect is captured by solving
ProblemÂ <a href="#S4.E3" title="In 4.4 How many layers do we assign to each neural network partition? â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>,
where
<math id="S4.SS4.p2.1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS4.p2.1.1.m1.1a"><mi mathcolor="#000000" id="S4.SS4.p2.1.1.m1.1.1" xref="S4.SS4.p2.1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.1.m1.1b"><ci id="S4.SS4.p2.1.1.m1.1.1.cmml" xref="S4.SS4.p2.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.1.m1.1c">\alpha</annotation></semantics></math> and <math id="S4.SS4.p2.2.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS4.p2.2.2.m2.1a"><mi mathcolor="#000000" id="S4.SS4.p2.2.2.m2.1.1" xref="S4.SS4.p2.2.2.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.2.m2.1b"><ci id="S4.SS4.p2.2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.2.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.2.m2.1c">\beta</annotation></semantics></math> are developer-specified parameters that represent positive weights for the transmission delay of intermediate data (I) and computation delay (C), the parameter <math id="S4.SS4.p2.3.3.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS4.p2.3.3.m3.1a"><mi mathcolor="#000000" id="S4.SS4.p2.3.3.m3.1.1" xref="S4.SS4.p2.3.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.3.m3.1b"><ci id="S4.SS4.p2.3.3.m3.1.1.cmml" xref="S4.SS4.p2.3.3.m3.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.3.m3.1c">d</annotation></semantics></math> represents the depth of the client neural network, and finally, <math id="S4.SS4.p2.4.4.m4.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S4.SS4.p2.4.4.m4.1a"><mi mathcolor="#000000" id="S4.SS4.p2.4.4.m4.1.1" xref="S4.SS4.p2.4.4.m4.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.4.4.m4.1b"><ci id="S4.SS4.p2.4.4.m4.1.1.cmml" xref="S4.SS4.p2.4.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.4.4.m4.1c">b</annotation></semantics></math> represents the bandwidth, which is measured periodically.
To efficiently solve this problem,
we follow the approach inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>,
where
we build two regression models to predict the delays I and C, given the available bandwidth by profiling the model, i.e., computing the output size and processing time for each layer in the client NN, instead of training the full model.
</span>
<span id="S4.SS4.p2.4.5" class="ltx_text" style="color:#000000;"></span></p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.21" class="ltx_Math" alttext="\begin{split}\min_{d}(\alpha I(d\mid b)+\beta C(d))\end{split}" display="block"><semantics id="S4.E3.m1.21a"><mtable displaystyle="true" id="S4.E3.m1.21.21.4"><mtr id="S4.E3.m1.21.21.4a"><mtd class="ltx_align_right" columnalign="right" id="S4.E3.m1.21.21.4b"><mrow id="S4.E3.m1.21.21.4.19.19.19.19"><munder id="S4.E3.m1.20.20.3.18.18.18.18.1"><mi mathcolor="#000000" id="S4.E3.m1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml">min</mi><mi mathcolor="#000000" id="S4.E3.m1.2.2.2.2.2.2.1" xref="S4.E3.m1.2.2.2.2.2.2.1.cmml">d</mi></munder><mo id="S4.E3.m1.21.21.4.19.19.19.19a" xref="S4.E3.m1.19.19.2.3.cmml">â¡</mo><mrow id="S4.E3.m1.21.21.4.19.19.19.19.2"><mo mathcolor="#000000" stretchy="false" id="S4.E3.m1.3.3.3.3.3.3" xref="S4.E3.m1.19.19.2.3.cmml">(</mo><mrow id="S4.E3.m1.21.21.4.19.19.19.19.2.1"><mrow id="S4.E3.m1.21.21.4.19.19.19.19.2.1.1"><mi mathcolor="#000000" id="S4.E3.m1.4.4.4.4.4.4" xref="S4.E3.m1.4.4.4.4.4.4.cmml">Î±</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.21.21.4.19.19.19.19.2.1.1.2" xref="S4.E3.m1.19.19.2.3.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E3.m1.5.5.5.5.5.5" xref="S4.E3.m1.5.5.5.5.5.5.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.21.21.4.19.19.19.19.2.1.1.2a" xref="S4.E3.m1.19.19.2.3.cmml">â€‹</mo><mrow id="S4.E3.m1.21.21.4.19.19.19.19.2.1.1.1.1"><mo mathcolor="#000000" stretchy="false" id="S4.E3.m1.6.6.6.6.6.6" xref="S4.E3.m1.19.19.2.3.cmml">(</mo><mrow id="S4.E3.m1.21.21.4.19.19.19.19.2.1.1.1.1.1"><mi mathcolor="#000000" id="S4.E3.m1.7.7.7.7.7.7" xref="S4.E3.m1.7.7.7.7.7.7.cmml">d</mi><mo mathcolor="#000000" id="S4.E3.m1.8.8.8.8.8.8" xref="S4.E3.m1.8.8.8.8.8.8.cmml">âˆ£</mo><mi mathcolor="#000000" id="S4.E3.m1.9.9.9.9.9.9" xref="S4.E3.m1.9.9.9.9.9.9.cmml">b</mi></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E3.m1.10.10.10.10.10.10" xref="S4.E3.m1.19.19.2.3.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S4.E3.m1.11.11.11.11.11.11" xref="S4.E3.m1.11.11.11.11.11.11.cmml">+</mo><mrow id="S4.E3.m1.21.21.4.19.19.19.19.2.1.2"><mi mathcolor="#000000" id="S4.E3.m1.12.12.12.12.12.12" xref="S4.E3.m1.12.12.12.12.12.12.cmml">Î²</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.21.21.4.19.19.19.19.2.1.2.1" xref="S4.E3.m1.19.19.2.3.cmml">â€‹</mo><mi mathcolor="#000000" id="S4.E3.m1.13.13.13.13.13.13" xref="S4.E3.m1.13.13.13.13.13.13.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.21.21.4.19.19.19.19.2.1.2.1a" xref="S4.E3.m1.19.19.2.3.cmml">â€‹</mo><mrow id="S4.E3.m1.21.21.4.19.19.19.19.2.1.2.2"><mo mathcolor="#000000" stretchy="false" id="S4.E3.m1.14.14.14.14.14.14" xref="S4.E3.m1.19.19.2.3.cmml">(</mo><mi mathcolor="#000000" id="S4.E3.m1.15.15.15.15.15.15" xref="S4.E3.m1.15.15.15.15.15.15.cmml">d</mi><mo mathcolor="#000000" stretchy="false" id="S4.E3.m1.16.16.16.16.16.16" xref="S4.E3.m1.19.19.2.3.cmml">)</mo></mrow></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E3.m1.17.17.17.17.17.17" xref="S4.E3.m1.19.19.2.3.cmml">)</mo></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S4.E3.m1.21b"><apply id="S4.E3.m1.19.19.2.3.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"><apply id="S4.E3.m1.18.18.1.1.1.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"><csymbol cd="ambiguous" id="S4.E3.m1.18.18.1.1.1.1.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a">subscript</csymbol><min id="S4.E3.m1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1"></min><ci id="S4.E3.m1.2.2.2.2.2.2.1.cmml" xref="S4.E3.m1.2.2.2.2.2.2.1">ğ‘‘</ci></apply><apply id="S4.E3.m1.19.19.2.2.2.1.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"><plus id="S4.E3.m1.11.11.11.11.11.11.cmml" xref="S4.E3.m1.11.11.11.11.11.11"></plus><apply id="S4.E3.m1.19.19.2.2.2.1.1.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"><times id="S4.E3.m1.19.19.2.2.2.1.1.2.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"></times><ci id="S4.E3.m1.4.4.4.4.4.4.cmml" xref="S4.E3.m1.4.4.4.4.4.4">ğ›¼</ci><ci id="S4.E3.m1.5.5.5.5.5.5.cmml" xref="S4.E3.m1.5.5.5.5.5.5">ğ¼</ci><apply id="S4.E3.m1.19.19.2.2.2.1.1.1.1.1.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"><csymbol cd="latexml" id="S4.E3.m1.8.8.8.8.8.8.cmml" xref="S4.E3.m1.8.8.8.8.8.8">conditional</csymbol><ci id="S4.E3.m1.7.7.7.7.7.7.cmml" xref="S4.E3.m1.7.7.7.7.7.7">ğ‘‘</ci><ci id="S4.E3.m1.9.9.9.9.9.9.cmml" xref="S4.E3.m1.9.9.9.9.9.9">ğ‘</ci></apply></apply><apply id="S4.E3.m1.19.19.2.2.2.1.3.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"><times id="S4.E3.m1.19.19.2.2.2.1.3.1.cmml" xref="S4.E3.m1.21.21.4.19.19.19.19a"></times><ci id="S4.E3.m1.12.12.12.12.12.12.cmml" xref="S4.E3.m1.12.12.12.12.12.12">ğ›½</ci><ci id="S4.E3.m1.13.13.13.13.13.13.cmml" xref="S4.E3.m1.13.13.13.13.13.13">ğ¶</ci><ci id="S4.E3.m1.15.15.15.15.15.15.cmml" xref="S4.E3.m1.15.15.15.15.15.15">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.21c">\begin{split}\min_{d}(\alpha I(d\mid b)+\beta C(d))\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.5" class="ltx_p"><span id="S4.SS4.p3.5.5" class="ltx_text" style="color:#000000;">The solution of ProblemÂ <a href="#S4.E3" title="In 4.4 How many layers do we assign to each neural network partition? â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> is optimal with respect to delays, however, it can be sub-optimal with respect to privacy and accuracy.
As Section <a href="#S5.SS2.SSS2" title="5.2.2 Training Time Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.2</span></a> shows, the client processing and transmission delay of FSL reach the minimum when the client NN depth is between 7 and 16.
In Fig.Â <a href="#S5.F7.sf1" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a>, instead, the client NN needs more than 16 layers to be above <math id="S4.SS4.p3.1.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S4.SS4.p3.1.1.m1.1a"><mrow id="S4.SS4.p3.1.1.m1.1.1" xref="S4.SS4.p3.1.1.m1.1.1.cmml"><mn mathcolor="#000000" id="S4.SS4.p3.1.1.m1.1.1.2" xref="S4.SS4.p3.1.1.m1.1.1.2.cmml">90</mn><mo mathcolor="#000000" id="S4.SS4.p3.1.1.m1.1.1.1" xref="S4.SS4.p3.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.1.m1.1b"><apply id="S4.SS4.p3.1.1.m1.1.1.cmml" xref="S4.SS4.p3.1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p3.1.1.m1.1.1.1.cmml" xref="S4.SS4.p3.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.p3.1.1.m1.1.1.2.cmml" xref="S4.SS4.p3.1.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.1.m1.1c">90\%</annotation></semantics></math> attack resiliency.
Thus, we conclude that an optimal NN partitioning decision should balance different objectives and constraints, including transmission delay, processing time, privacy, and accuracy, as shown in our Problem formulationÂ <a href="#S4.E4" title="In 4.4 How many layers do we assign to each neural network partition? â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
In such a problem, <math id="S4.SS4.p3.2.2.m2.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S4.SS4.p3.2.2.m2.1a"><mi mathcolor="#000000" id="S4.SS4.p3.2.2.m2.1.1" xref="S4.SS4.p3.2.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.2.m2.1b"><ci id="S4.SS4.p3.2.2.m2.1.1.cmml" xref="S4.SS4.p3.2.2.m2.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.2.m2.1c">W</annotation></semantics></math> represents the model weight vector, <math id="S4.SS4.p3.3.3.m3.4" class="ltx_Math" alttext="(I^{\prime},C^{\prime},A,R)" display="inline"><semantics id="S4.SS4.p3.3.3.m3.4a"><mrow id="S4.SS4.p3.3.3.m3.4.4.2" xref="S4.SS4.p3.3.3.m3.4.4.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p3.3.3.m3.4.4.2.3" xref="S4.SS4.p3.3.3.m3.4.4.3.cmml">(</mo><msup id="S4.SS4.p3.3.3.m3.3.3.1.1" xref="S4.SS4.p3.3.3.m3.3.3.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.3.3.m3.3.3.1.1.2" xref="S4.SS4.p3.3.3.m3.3.3.1.1.2.cmml">I</mi><mo mathcolor="#000000" id="S4.SS4.p3.3.3.m3.3.3.1.1.3" xref="S4.SS4.p3.3.3.m3.3.3.1.1.3.cmml">â€²</mo></msup><mo mathcolor="#000000" id="S4.SS4.p3.3.3.m3.4.4.2.4" xref="S4.SS4.p3.3.3.m3.4.4.3.cmml">,</mo><msup id="S4.SS4.p3.3.3.m3.4.4.2.2" xref="S4.SS4.p3.3.3.m3.4.4.2.2.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.3.3.m3.4.4.2.2.2" xref="S4.SS4.p3.3.3.m3.4.4.2.2.2.cmml">C</mi><mo mathcolor="#000000" id="S4.SS4.p3.3.3.m3.4.4.2.2.3" xref="S4.SS4.p3.3.3.m3.4.4.2.2.3.cmml">â€²</mo></msup><mo mathcolor="#000000" id="S4.SS4.p3.3.3.m3.4.4.2.5" xref="S4.SS4.p3.3.3.m3.4.4.3.cmml">,</mo><mi mathcolor="#000000" id="S4.SS4.p3.3.3.m3.1.1" xref="S4.SS4.p3.3.3.m3.1.1.cmml">A</mi><mo mathcolor="#000000" id="S4.SS4.p3.3.3.m3.4.4.2.6" xref="S4.SS4.p3.3.3.m3.4.4.3.cmml">,</mo><mi mathcolor="#000000" id="S4.SS4.p3.3.3.m3.2.2" xref="S4.SS4.p3.3.3.m3.2.2.cmml">R</mi><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p3.3.3.m3.4.4.2.7" xref="S4.SS4.p3.3.3.m3.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.3.3.m3.4b"><vector id="S4.SS4.p3.3.3.m3.4.4.3.cmml" xref="S4.SS4.p3.3.3.m3.4.4.2"><apply id="S4.SS4.p3.3.3.m3.3.3.1.1.cmml" xref="S4.SS4.p3.3.3.m3.3.3.1.1"><csymbol cd="ambiguous" id="S4.SS4.p3.3.3.m3.3.3.1.1.1.cmml" xref="S4.SS4.p3.3.3.m3.3.3.1.1">superscript</csymbol><ci id="S4.SS4.p3.3.3.m3.3.3.1.1.2.cmml" xref="S4.SS4.p3.3.3.m3.3.3.1.1.2">ğ¼</ci><ci id="S4.SS4.p3.3.3.m3.3.3.1.1.3.cmml" xref="S4.SS4.p3.3.3.m3.3.3.1.1.3">â€²</ci></apply><apply id="S4.SS4.p3.3.3.m3.4.4.2.2.cmml" xref="S4.SS4.p3.3.3.m3.4.4.2.2"><csymbol cd="ambiguous" id="S4.SS4.p3.3.3.m3.4.4.2.2.1.cmml" xref="S4.SS4.p3.3.3.m3.4.4.2.2">superscript</csymbol><ci id="S4.SS4.p3.3.3.m3.4.4.2.2.2.cmml" xref="S4.SS4.p3.3.3.m3.4.4.2.2.2">ğ¶</ci><ci id="S4.SS4.p3.3.3.m3.4.4.2.2.3.cmml" xref="S4.SS4.p3.3.3.m3.4.4.2.2.3">â€²</ci></apply><ci id="S4.SS4.p3.3.3.m3.1.1.cmml" xref="S4.SS4.p3.3.3.m3.1.1">ğ´</ci><ci id="S4.SS4.p3.3.3.m3.2.2.cmml" xref="S4.SS4.p3.3.3.m3.2.2">ğ‘…</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.3.3.m3.4c">(I^{\prime},C^{\prime},A,R)</annotation></semantics></math> is the tuple representing the observations for transmission delay, computation delay, accuracy, and resilience, <math id="S4.SS4.p3.4.4.m4.2" class="ltx_Math" alttext="(\gamma,\kappa)" display="inline"><semantics id="S4.SS4.p3.4.4.m4.2a"><mrow id="S4.SS4.p3.4.4.m4.2.3.2" xref="S4.SS4.p3.4.4.m4.2.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p3.4.4.m4.2.3.2.1" xref="S4.SS4.p3.4.4.m4.2.3.1.cmml">(</mo><mi mathcolor="#000000" id="S4.SS4.p3.4.4.m4.1.1" xref="S4.SS4.p3.4.4.m4.1.1.cmml">Î³</mi><mo mathcolor="#000000" id="S4.SS4.p3.4.4.m4.2.3.2.2" xref="S4.SS4.p3.4.4.m4.2.3.1.cmml">,</mo><mi mathcolor="#000000" id="S4.SS4.p3.4.4.m4.2.2" xref="S4.SS4.p3.4.4.m4.2.2.cmml">Îº</mi><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p3.4.4.m4.2.3.2.3" xref="S4.SS4.p3.4.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.4.4.m4.2b"><interval closure="open" id="S4.SS4.p3.4.4.m4.2.3.1.cmml" xref="S4.SS4.p3.4.4.m4.2.3.2"><ci id="S4.SS4.p3.4.4.m4.1.1.cmml" xref="S4.SS4.p3.4.4.m4.1.1">ğ›¾</ci><ci id="S4.SS4.p3.4.4.m4.2.2.cmml" xref="S4.SS4.p3.4.4.m4.2.2">ğœ…</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.4.4.m4.2c">(\gamma,\kappa)</annotation></semantics></math> are new user-specified positive weights, and <math id="S4.SS4.p3.5.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS4.p3.5.5.m5.1a"><mi mathcolor="#000000" id="S4.SS4.p3.5.5.m5.1.1" xref="S4.SS4.p3.5.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.5.5.m5.1b"><ci id="S4.SS4.p3.5.5.m5.1.1.cmml" xref="S4.SS4.p3.5.5.m5.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.5.5.m5.1c">d</annotation></semantics></math> is the client NN depth.</span></p>
<table id="S4.E4" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E4X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E4X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\max_{W,d}" display="inline"><semantics id="S4.E4X.2.1.1.m1.2a"><munder id="S4.E4X.2.1.1.m1.2.3" xref="S4.E4X.2.1.1.m1.2.3.cmml"><mi mathcolor="#000000" id="S4.E4X.2.1.1.m1.2.3.2" xref="S4.E4X.2.1.1.m1.2.3.2.cmml">max</mi><mrow id="S4.E4X.2.1.1.m1.2.2.2.4" xref="S4.E4X.2.1.1.m1.2.2.2.3.cmml"><mi mathcolor="#000000" id="S4.E4X.2.1.1.m1.1.1.1.1" xref="S4.E4X.2.1.1.m1.1.1.1.1.cmml">W</mi><mo mathcolor="#000000" id="S4.E4X.2.1.1.m1.2.2.2.4.1" xref="S4.E4X.2.1.1.m1.2.2.2.3.cmml">,</mo><mi mathcolor="#000000" id="S4.E4X.2.1.1.m1.2.2.2.2" xref="S4.E4X.2.1.1.m1.2.2.2.2.cmml">d</mi></mrow></munder><annotation-xml encoding="MathML-Content" id="S4.E4X.2.1.1.m1.2b"><apply id="S4.E4X.2.1.1.m1.2.3.cmml" xref="S4.E4X.2.1.1.m1.2.3"><csymbol cd="ambiguous" id="S4.E4X.2.1.1.m1.2.3.1.cmml" xref="S4.E4X.2.1.1.m1.2.3">subscript</csymbol><max id="S4.E4X.2.1.1.m1.2.3.2.cmml" xref="S4.E4X.2.1.1.m1.2.3.2"></max><list id="S4.E4X.2.1.1.m1.2.2.2.3.cmml" xref="S4.E4X.2.1.1.m1.2.2.2.4"><ci id="S4.E4X.2.1.1.m1.1.1.1.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1">ğ‘Š</ci><ci id="S4.E4X.2.1.1.m1.2.2.2.2.cmml" xref="S4.E4X.2.1.1.m1.2.2.2.2">ğ‘‘</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4X.2.1.1.m1.2c">\displaystyle\max_{W,d}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E4X.3.2.2.m1.3" class="ltx_math_unparsed" alttext="\displaystyle(-\alpha I^{\prime}(W,d\mid b)-\beta C^{\prime}(W,d)" display="inline"><semantics id="S4.E4X.3.2.2.m1.3a"><mrow id="S4.E4X.3.2.2.m1.3b"><mo mathcolor="#000000" stretchy="false" id="S4.E4X.3.2.2.m1.3.4">(</mo><mo lspace="0em" mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.5">âˆ’</mo><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.6">Î±</mi><msup id="S4.E4X.3.2.2.m1.3.7"><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.7.2">I</mi><mo mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.7.3">â€²</mo></msup><mrow id="S4.E4X.3.2.2.m1.3.8"><mo mathcolor="#000000" stretchy="false" id="S4.E4X.3.2.2.m1.3.8.1">(</mo><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.1.1">W</mi><mo mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.8.2">,</mo><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.8.3">d</mi><mo lspace="0em" mathcolor="#000000" rspace="0.167em" id="S4.E4X.3.2.2.m1.3.8.4">âˆ£</mo><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.8.5">b</mi><mo mathcolor="#000000" stretchy="false" id="S4.E4X.3.2.2.m1.3.8.6">)</mo></mrow><mo mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.9">âˆ’</mo><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.10">Î²</mi><msup id="S4.E4X.3.2.2.m1.3.11"><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.11.2">C</mi><mo mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.11.3">â€²</mo></msup><mrow id="S4.E4X.3.2.2.m1.3.12"><mo mathcolor="#000000" stretchy="false" id="S4.E4X.3.2.2.m1.3.12.1">(</mo><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.2.2">W</mi><mo mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.12.2">,</mo><mi mathcolor="#000000" id="S4.E4X.3.2.2.m1.3.3">d</mi><mo mathcolor="#000000" stretchy="false" id="S4.E4X.3.2.2.m1.3.12.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.E4X.3.2.2.m1.3c">\displaystyle(-\alpha I^{\prime}(W,d\mid b)-\beta C^{\prime}(W,d)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
<tr id="S4.E4Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E4Xa.2.1.1.m1.4" class="ltx_math_unparsed" alttext="\displaystyle+\gamma A(W,d)+\kappa R(W,d))" display="inline"><semantics id="S4.E4Xa.2.1.1.m1.4a"><mrow id="S4.E4Xa.2.1.1.m1.4b"><mo mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.5">+</mo><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.6">Î³</mi><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.7">A</mi><mrow id="S4.E4Xa.2.1.1.m1.4.8"><mo mathcolor="#000000" stretchy="false" id="S4.E4Xa.2.1.1.m1.4.8.1">(</mo><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.1.1">W</mi><mo mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.8.2">,</mo><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.2.2">d</mi><mo mathcolor="#000000" stretchy="false" id="S4.E4Xa.2.1.1.m1.4.8.3">)</mo></mrow><mo mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.9">+</mo><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.10">Îº</mi><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.11">R</mi><mrow id="S4.E4Xa.2.1.1.m1.4.12"><mo mathcolor="#000000" stretchy="false" id="S4.E4Xa.2.1.1.m1.4.12.1">(</mo><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.3.3">W</mi><mo mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.12.2">,</mo><mi mathcolor="#000000" id="S4.E4Xa.2.1.1.m1.4.4">d</mi><mo mathcolor="#000000" stretchy="false" id="S4.E4Xa.2.1.1.m1.4.12.3">)</mo></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E4Xa.2.1.1.m1.4.13">)</mo></mrow><annotation encoding="application/x-tex" id="S4.E4Xa.2.1.1.m1.4c">\displaystyle+\gamma A(W,d)+\kappa R(W,d))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.3" class="ltx_p"><span id="S4.SS4.p4.3.3" class="ltx_text" style="color:#000000;">To solve ProblemÂ <a href="#S4.E4" title="In 4.4 How many layers do we assign to each neural network partition? â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>,
we have to train <math id="S4.SS4.p4.1.1.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S4.SS4.p4.1.1.m1.1a"><mi mathcolor="#000000" id="S4.SS4.p4.1.1.m1.1.1" xref="S4.SS4.p4.1.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.1.1.m1.1b"><ci id="S4.SS4.p4.1.1.m1.1.1.cmml" xref="S4.SS4.p4.1.1.m1.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.1.1.m1.1c">W</annotation></semantics></math> for each <math id="S4.SS4.p4.2.2.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS4.p4.2.2.m2.1a"><mi mathcolor="#000000" id="S4.SS4.p4.2.2.m2.1.1" xref="S4.SS4.p4.2.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.2.2.m2.1b"><ci id="S4.SS4.p4.2.2.m2.1.1.cmml" xref="S4.SS4.p4.2.2.m2.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.2.2.m2.1c">d</annotation></semantics></math> until convergence and then find the best <math id="S4.SS4.p4.3.3.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS4.p4.3.3.m3.1a"><mi mathcolor="#000000" id="S4.SS4.p4.3.3.m3.1.1" xref="S4.SS4.p4.3.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.3.3.m3.1b"><ci id="S4.SS4.p4.3.3.m3.1.1.cmml" xref="S4.SS4.p4.3.3.m3.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.3.3.m3.1c">d</annotation></semantics></math>.
This brute force method is inefficient.
A more efficient approach would rely on predicting the delays, accuracy, and privacy without the full training of the model.
Extending the approach inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> to go beyond profiling delays,
is challenging.
This is because the accuracy and attack resilience for each client and edge server pair is harder to profile and predict.
Specifically, their profiling depends on the weights trained on other pairs,
the distribution of source data among clients,
number of clients, number of layers to average in SerAVG, and
training epochs (Sec.Â <a href="#S5.SS2.SSS4" title="5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.4</span></a> and <a href="#S5.SS3" title="5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>).
Another work can predict the model accuracy<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>,
but it is based on the already trained model.
Therefore, for our FSL architecture with SerAVG, a prediction method for partitioning remains an open question for future work.
In this paper, we experimentally demonstrate the best model partitioning that balances requirements on training time, accuracy, and privacy.
</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Evaluation Results</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text" style="color:#000000;">In this section, we describe the evaluation results related to our Privacy-Oblivious FSL (POFSL) and Privacy-Aware FSL (PAFSL) architectures with our privacy-aware approaches (CPA in SectionÂ <a href="#S4.SS3" title="4.3 Client-Based Privacy Approach in Distributed Setting via Distance Correlation (CPA-DC) â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> and Neural Network Partitioning in SectionÂ <a href="#S4.SS4" title="4.4 How many layers do we assign to each neural network partition? â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>).
Our evaluation demonstrates the advantages of FSL over PSL and FRC in terms of training time, memory
usage, and convergence rate.
Moreover, we also show that our privacy-aware approaches can prevent the reconstruction of source images from intermediate data in the Split Learning-based systems.
We first discuss our experimental setup, then present our evaluation results of POFSL and PAFSL in SectionsÂ <a href="#S5.SS2" title="5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a> and <a href="#S5.SS3" title="5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>.
</span></p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span id="S5.SS1.1.1" class="ltx_text ltx_font_italic">Experimental Setup</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text" style="color:#000000;">This experiment set studies the convergence for POFSL and the privacy guarantee of PAFSL across different hardware and applications with different NNs and datasets.
</span></p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.2" class="ltx_p"><span id="S5.SS1.p2.2.2" class="ltx_text" style="color:#000000;">For the hardware, we used two types of nodes on Chameleon CloudÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.
One has an RTX6000 GPU, two Intel Xeon Gold <math id="S5.SS1.p2.1.1.m1.1" class="ltx_Math" alttext="6126" display="inline"><semantics id="S5.SS1.p2.1.1.m1.1a"><mn mathcolor="#000000" id="S5.SS1.p2.1.1.m1.1.1" xref="S5.SS1.p2.1.1.m1.1.1.cmml">6126</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.1.m1.1b"><cn type="integer" id="S5.SS1.p2.1.1.m1.1.1.cmml" xref="S5.SS1.p2.1.1.m1.1.1">6126</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.1.m1.1c">6126</annotation></semantics></math> CPUs
and <math id="S5.SS1.p2.2.2.m2.1" class="ltx_Math" alttext="187" display="inline"><semantics id="S5.SS1.p2.2.2.m2.1a"><mn mathcolor="#000000" id="S5.SS1.p2.2.2.m2.1.1" xref="S5.SS1.p2.2.2.m2.1.1.cmml">187</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.2.m2.1b"><cn type="integer" id="S5.SS1.p2.2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.2.m2.1.1">187</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.2.m2.1c">187</annotation></semantics></math> GB memory.
The other one has four NVIDIA V100 GPUs, two Intel Xeon Gold 6230 CPUs
and 128 GB of memory.
We emulated the computer network among our distributed learning entities on the localhost interface on a physical machine, and each experiment was set to use a single GPU. So that we can ignore the network bandwidth bottlenecks.
</span></p>
</div>
<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x6.png" id="S5.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">LENET+MNIST 
<br class="ltx_break">Client Measurements</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x7.png" id="S5.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">LENET+MNIST 
<br class="ltx_break">Server Measurements</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x8.png" id="S5.F3.sf3.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">LENET+MNIST 
<br class="ltx_break">Intermediate Data</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x9.png" id="S5.F3.sf4.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F3.sf4.3.2" class="ltx_text" style="font-size:90%;">VPN Workload 
<br class="ltx_break">Client Measurements</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F3.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x10.png" id="S5.F3.sf5.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S5.F3.sf5.3.2" class="ltx_text" style="font-size:90%;">VPN Workload 
<br class="ltx_break">Server Measurements</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.5.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S5.F3.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">LeNet+MNIST<span id="S5.F3.6.2.1" class="ltx_text ltx_font_upright">: (a)Â Client Time, (b)Â Server Time, (c)Â Intermediate data size.
Observations: 1) Intermediate data size is correlated with the times taken by the PSL architecture while having <span id="S5.F3.6.2.1.1" class="ltx_text" style="color:#000000;"> little</span> correlation under FSL;
2) FRC has almost twice the overall training time as FL;
3) Plots are obtained by averaging 20 clientsâ€™ results. Intermediate data size is under batch size of 16 and each image was resized to (1,32,32).
</span>VPN Workload<span id="S5.F3.6.2.2" class="ltx_text ltx_font_upright">: (d)Â Client Time (e)Â Server Time. Similar considerations are valid for the VPN dataset. Tested with 5 clients with a one dimentional NN with input size of (1,784). Still, FSL has the shortest Client F&amp;B time compared to the other settings.
</span></span></figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x11.png" id="S5.F4.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="395" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">Pair Time</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x12.png" id="S5.F4.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="395" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">Client Time</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x13.png" id="S5.F4.sf3.g1" class="ltx_graphics ltx_img_square" width="461" height="395" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F4.sf3.3.2" class="ltx_text" style="font-size:90%;">Server Time</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F4.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x14.png" id="S5.F4.sf4.g1" class="ltx_graphics ltx_img_square" width="461" height="465" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F4.sf4.3.2" class="ltx_text" style="font-size:90%;">Intermediate Data Size</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S5.F4.3.2" class="ltx_text" style="font-size:90%;">VGG + CiFar10: Plots show the effect of Cut Index over
(a)Â averaged overall training time, (b)Â time spent in clients (5 clients average), (c)Â time spent in server, (d)Â intermediate data size.
The transmission delay caused by intermediate data size can dominate the training time (occurring during F&amp;B propagation). </span></figcaption>
</figure>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text" style="color:#000000;">For the applications, we considered three classification tasks and implemented with PyTorchÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.
Then the distributed communication among entities of the systems was handled by PySyftÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> and PyGridÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and no encryption is applied on the transmission.
The first application runs a general image classification task with a VGG-16Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> Convolutional Neural Network (CNN). The model was pre-trained using ImagenetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and then trained with the CIFAR-10 datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
We run this task on 5 clients running a NVIDIA V100 GPU.
The second task uses a LENETÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> CNN to recognize handwritten numbers in the MNIST datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> on 20 clients running a NVIDIA RTX6000 GPU.
The third task classifies traffic, not images. In particular, we decomposed
a one-dimensional-CNN, trained with the ISCX VPN-nonVPN (ISCX) traffic datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, using 5 clients running on a RTX6000 GPU.
We partitioned the dataset and assign ed
among different clients
with Independent and Identically Distributed (IID) probabilities and all our plots show <math id="S5.SS1.p3.1.1.m1.1" class="ltx_Math" alttext="95\%" display="inline"><semantics id="S5.SS1.p3.1.1.m1.1a"><mrow id="S5.SS1.p3.1.1.m1.1.1" xref="S5.SS1.p3.1.1.m1.1.1.cmml"><mn mathcolor="#000000" id="S5.SS1.p3.1.1.m1.1.1.2" xref="S5.SS1.p3.1.1.m1.1.1.2.cmml">95</mn><mo mathcolor="#000000" id="S5.SS1.p3.1.1.m1.1.1.1" xref="S5.SS1.p3.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.1.m1.1b"><apply id="S5.SS1.p3.1.1.m1.1.1.cmml" xref="S5.SS1.p3.1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.p3.1.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.p3.1.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.1.m1.1.1.2">95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.1.m1.1c">95\%</annotation></semantics></math> confidence intervals, unless otherwise specified.
Our goal is to verify that FSL can always converge, with different tasks, different NNs, different devices, and different data distributions. We verified the advantages in delay or privacy of FSL over existing solutions.
</span></p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span id="S5.SS2.1.1" class="ltx_text ltx_font_italic">Evaluation Results for Privacy-Oblivious FSL </span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">This section illustrates the methodology and draws observations of our experiments. Overall, our evaluations show that POFSL has less overhead and <span id="S5.SS2.p1.1.1" class="ltx_text" style="color:#000000;"> similar</span> accuracy <span id="S5.SS2.p1.1.2" class="ltx_text" style="color:#000000;"> comparing to existing solutions.</span>
In particular, we evaluate training time (Sec.Â <a href="#S5.SS2.SSS2" title="5.2.2 Training Time Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.2</span></a>), memory consumption (Sec.Â <a href="#S5.SS2.SSS3" title="5.2.3 Memory Consumption Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.3</span></a>), and learner accuracy (Sec.Â <a href="#S5.SS2.SSS4" title="5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.4</span></a>).</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Experiment Design</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Given the size of the different datasets and number of clients, to reach at least <math id="S5.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S5.SS2.SSS1.p1.1.m1.1a"><mrow id="S5.SS2.SSS1.p1.1.m1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.cmml"><mn id="S5.SS2.SSS1.p1.1.m1.1.1.2" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml">90</mn><mo id="S5.SS2.SSS1.p1.1.m1.1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.1.m1.1b"><apply id="S5.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.1.m1.1c">90\%</annotation></semantics></math> accuracy, the neural networks used for image classification needed 20 epochs. While for the traffic classification model, 80 epochs were used.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Training Time Evaluation</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">To evaluate training time, let us consider the experiment whose results are reported in FiguresÂ <a href="#S5.F3" title="Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>Â andÂ <a href="#S5.F4" title="Figure 4 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
The x-axis indicates the <span id="S5.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">Cut Index</span>, i.e., the index of the last layer running in the client/local part of the NN.
When tested over the MNIST scenario, we can observe from FigureÂ <a href="#S5.F3.sf1" title="In Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> and <a href="#S5.F3.sf2" title="In Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>
that FSL has the shortest â€œClient Forward and Backward Propagationâ€ (Client F&amp;B) time among all other distributed architectures.
<span id="S5.SS2.SSS2.p1.1.2" class="ltx_text" style="color:#000000;"> The Client F&amp;B time includes transmission time for gradients and computing both activations and gradients in Client NN. And Server F&amp;B time includes transmission time for hidden variable from client to server and computation in Server NN. Notice that the weight update time is separately counted by â€œClient Update Timeâ€œ and â€œServer Update Timeâ€œ.</span>
Moreover, we note that PSL is more vulnerable than FSL to limited bandwidth across splits.
PSL is consistently the slowest, due to its inefficient server design; the server has to synchronize the intermediate data, and it must process all batches of intermediate data in each training epoch sequentially.
</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p">Observing FRC and FL, we see the F&amp;B times do not change along with the Cut Index (FiguresÂ <a href="#S5.F3.sf1" title="In Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> and <a href="#S5.F3.sf2" title="In Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>).
Note also that FRC is not training time efficient.
It updates its complete model with two almost full forward and backward stepsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
This can be noted in the same figures: the FRC total F&amp;B time for local and shared weights is almost doubled compared to the FL training time.</p>
</div>
<div id="S5.SS2.SSS2.p3" class="ltx_para">
<p id="S5.SS2.SSS2.p3.1" class="ltx_p">We were able to obtain similar results comparing the F&amp;B times on another predicting scenario: the 1D CNN implemented byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> (FiguresÂ <a href="#S5.F3.sf4" title="In Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(d)</span></a>Â andÂ <a href="#S5.F3.sf5" title="In Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(e)</span></a>).
Due to the limited size of this neural network (with only two convolutional layers), we evaluated the architectures with merely two Cut Indexes: at layer 3 and layer 6 of the NN.
Even in this experiment, we observe how our FSL still has the shortest Client F&amp;B time. PSL is the worst performant at each cut, and FL keeps performing better than FRC. </p>
</div>
<div id="S5.SS2.SSS2.p4" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p4.1" class="ltx_p"><span id="S5.SS2.SSS2.p4.1.1" class="ltx_text ltx_font_bold">FSL consistently uses less time in each training epoch than the other analyzed architectures.</span> <span id="S5.SS2.SSS2.p4.1.2" class="ltx_text ltx_font_italic">We found that PSL perform worse than FSL because of the single-server architecture. PSL has
similar results when comparing its client F&amp;B time with FL and FRC.
FRC is not training time efficient.
Its total F&amp;B time almost doubles compared to FL.</span></p>
</div>
<div id="S5.SS2.SSS2.p5" class="ltx_para">
<p id="S5.SS2.SSS2.p5.1" class="ltx_p">When evaluating the training time on the CIFAR-10 scenario, we found a different trend (Fig.Â <a href="#S5.F4.sf1" title="In Figure 4 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a>): PSL had the longest training time, except for cut index of 30.
Moreover, FSL did not always perform the best. When most of the layers run within the client, FL has a shorter training time.
<span id="S5.SS2.SSS2.p5.1.1" class="ltx_text" style="color:#000000;"> This is because the size of intermediate data changes as the cut moves, and with smaller data to send, the overall training time can be shorter.
Fig.Â <a href="#S5.F4.sf2" title="In Figure 4 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a> andÂ <a href="#S5.F4.sf3" title="In Figure 4 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a>
show the extra F&amp;B time during training.
And existing works for SL have discussed the similar behaviorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.</span></p>
</div>
<div id="S5.SS2.SSS2.p6" class="ltx_para">
<p id="S5.SS2.SSS2.p6.1" class="ltx_p">In particular, we show that FSL
outperforms PSL as PSL F&amp;B time is more vulnerable to the intermediate data transmission.
In FigureÂ <a href="#S5.F3" title="Figure 3 â€£ 5.1 Experimental Setup â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, Client F&amp;B time of FSL keeps decreasing with smaller Cut Index, while that of PSL still increases at
Cut Index 6, 5 and 3, 2, although the intermediate data in this experiment is much smaller than using VGG-16.
This behavior is caused by the single server bottleneck.
Thus, FSL is more scalable in terms of training time.
Such observation also explains why both client and server F&amp;B times of PSL are consistently larger than FSL.
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS2.p7" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p7.1" class="ltx_p"><span id="S5.SS2.SSS2.p7.1.1" class="ltx_text ltx_font_bold">The intermediate data and gradients can cause significant network overhead.</span> Such overhead, however is better mitigated by our FSL than PSL.
<span id="S5.SS2.SSS2.p7.1.2" class="ltx_text" style="color:#000000;"> Existing workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> for Split Learning, as well as our partitioning strategies (SectionÂ <a href="#S4.SS4" title="4.4 How many layers do we assign to each neural network partition? â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>) can further mitigate the communication overhead.</span>
Thus, the additional delay in FSL is not considered a severe bottleneck compared to those systems training at the edge, like FL.
</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3 </span>Memory Consumption Evaluation</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">Memory usage of each entity in the edge training and inference systems limits the scope of devices that can join the system.
To compare which system is more flexible to deploy in terms of memory capacity on devices, we show that each entity has calculated memory usage in the FSL, PSL, FL, and FRC systems.</p>
</div>
<div id="S5.SS2.SSS3.p2" class="ltx_para">
<p id="S5.SS2.SSS3.p2.1" class="ltx_p">Real-world memory utilization can be highly variable as it depends on several implementation factors, such as libraries used and the Remote Procedure Calls (RPCs) implemented.
However, the size of a model and its activation at each layer are known.
The following results show that FSLâ€™s clients consume less memory compared to FL and FRC, and any of its servers occupy less memory than PSL.</p>
</div>
<div id="S5.SS2.SSS3.p3" class="ltx_para">
<p id="S5.SS2.SSS3.p3.1" class="ltx_p">The two plots in FigureÂ <a href="#S5.F5" title="Figure 5 â€£ 5.2.3 Memory Consumption Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> show the memory demands computed at the client and the server for each architecture.
The x-axis shows the Cut Index and the y-axis represents the corresponding expected memory usages in MB.
Note that FL and FRC do not split the NN, so their memory demands are only shown in the left plot.</p>
</div>
<div id="S5.SS2.SSS3.p4" class="ltx_para">
<p id="S5.SS2.SSS3.p4.1" class="ltx_p">As shown in FigureÂ <a href="#S5.F5.sf1" title="In Figure 5 â€£ 5.2.3 Memory Consumption Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>, the sizes of each client NNâ€™s weight and <span id="S5.SS2.SSS3.p4.1.1" class="ltx_text" style="color:#000000;"> the results at each layer are the same in FSL and PSL.</span>
Since FRC and FL compute the full NN in the client during training, they require more than five times the memory, for Cut Index 4 to 30.
FigureÂ <a href="#S5.F5.sf2" title="In Figure 5 â€£ 5.2.3 Memory Consumption Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a> instead shows that the server memory demand decreases with the cut index, as expected.
However, notice that PSL server need more memory to hold intermediate data from different clients.</p>
</div>
<div id="S5.SS2.SSS3.p5" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS3.p5.1" class="ltx_p"><span id="S5.SS2.SSS3.p5.1.1" class="ltx_text ltx_font_bold">Memory usage of FSL compared to other systems.</span> To conclude, we found that FSLâ€™s servers are lightweight compared to the PSL system. Consequently, state management would be easier in FSL. Also, FSLâ€™s clients are lightweight compared to FRC and FL, during training, so they are more suitable at edge.</p>
</div>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x15.png" id="S5.F5.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x16.png" id="S5.F5.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S5.F5.4.2" class="ltx_text" style="font-size:90%;">FSLâ€™s server has lower memory demand compared to PSL, and FSLâ€™s client has lower memory demand compared to FRC/FL.
<span id="S5.F5.4.2.1" class="ltx_text ltx_font_italic">VGG + CiFar10</span>: (a) Client and (b) Server memory demand (sum of model weights size and outputs at each layer). Batch size is 32 and each image was resized to (3,32,32).
</span></figcaption>
</figure>
</section>
<section id="S5.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.4 </span>Learner Accuracy Evaluation</h4>

<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x17.png" id="S5.F6.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="395" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">Accuracy (Cut Index = 3)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x18.png" id="S5.F6.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="395" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Accuracy (Cut Index = 5)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x19.png" id="S5.F6.sf3.g1" class="ltx_graphics ltx_img_square" width="461" height="395" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F6.sf3.3.2" class="ltx_text" style="font-size:90%;">Accuracy (Cut Index = 7)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x20.png" id="S5.F6.sf4.g1" class="ltx_graphics ltx_img_square" width="664" height="578" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F6.sf4.3.2" class="ltx_text" style="font-size:90%;">Accuracy (different number of clients)
</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S5.F6.3.2" class="ltx_text" style="font-size:90%;">
In plotsÂ (a),Â (b)Â andÂ (c), the accuracy of SerAVG is better than NonAVG but lower while mostly close to FedAVG. SerAVG: Average the server NNâ€™s weights; NonAVG: Each pair trains on its own; FedAVG: Average the complete NNâ€™s weights.
In plotÂ (d), the FSL and PSL accuracy is similar.
</span></figcaption>
</figure>
<div id="S5.SS2.SSS4.p1" class="ltx_para">
<p id="S5.SS2.SSS4.p1.1" class="ltx_p">In this subsection, we focus on evaluating the convergence of SerAVG, proposed and detailed in SectionÂ <a href="#S3" title="3 Privacy-Oblivious FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
Unlike FedAVG in Federated Learning, SerAVG averages the server NN weights.
We begin by discussing the correctness of SerAVG, comparing the accuracy of SerAVG PSL, and FedAVG (FL).
Then, we compare the convergence rates based on different source data sizes and Cut Indexes.</p>
</div>
<div id="S5.SS2.SSS4.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS4.p2.2" class="ltx_p"><span id="S5.SS2.SSS4.p2.2.2" class="ltx_text ltx_font_bold">SerAVG Evaluation</span>:
In this experiment set, we evaluate if SerAVG can enhance the accuracy of every model joining the training process, given that the source data at clients are non-IID distributed. Our results are reported in FiguresÂ <a href="#S5.F6.sf1" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>,Â <a href="#S5.F6.sf2" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>Â andÂ <a href="#S5.F6.sf3" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a>.
To train the MNIST model, we split the training set in two parts, part 0 and part 1.
The two parts represent two <span id="S5.SS2.SSS4.p2.2.3" class="ltx_text" style="color:#000000;"> collections of skewed data sources at client geolocations.</span>
We then let each part include data corresponding to half of the labels in the MNIST dataset.
We then split the MNIST test set into two parts in the same way.
Note that the aforementioned way of splitting training set and test set is an extreme <span id="S5.SS2.SSS4.p2.2.4" class="ltx_text" style="color:#000000;"> Non-IID case. </span>For example, a model trained on part 0 of the training set has no knowledge of the labels in part 1 of training set.
To assess how well the systems may learn and predict on Non-IID data on more realistic data distributions, we further add <math id="S5.SS2.SSS4.p2.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S5.SS2.SSS4.p2.1.m1.1a"><mrow id="S5.SS2.SSS4.p2.1.m1.1.1" xref="S5.SS2.SSS4.p2.1.m1.1.1.cmml"><mn id="S5.SS2.SSS4.p2.1.m1.1.1.2" xref="S5.SS2.SSS4.p2.1.m1.1.1.2.cmml">10</mn><mo id="S5.SS2.SSS4.p2.1.m1.1.1.1" xref="S5.SS2.SSS4.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p2.1.m1.1b"><apply id="S5.SS2.SSS4.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.SSS4.p2.1.m1.1.1.1.cmml" xref="S5.SS2.SSS4.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.SSS4.p2.1.m1.1.1.2.cmml" xref="S5.SS2.SSS4.p2.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p2.1.m1.1c">10\%</annotation></semantics></math> samples uniformly and randomly, selected from the complete MNIST dataset to all the four parts <span id="S5.SS2.SSS4.p2.2.5" class="ltx_text" style="color:#000000;"> of datasets</span> so that the model trained on either part of the training set may be able to classify labels in the other partition.
Consider FiguresÂ <a href="#S5.F6.sf1" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>,Â <a href="#S5.F6.sf2" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>Â andÂ <a href="#S5.F6.sf3" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a>.
The x-axis represents the data partitions used in training and validation, <span id="S5.SS2.SSS4.p2.2.1" class="ltx_text" style="color:#000000;"> i.e.,Â <math id="S5.SS2.SSS4.p2.2.1.m1.1" class="ltx_Math" alttext="0~{}\&amp;~{}1" display="inline"><semantics id="S5.SS2.SSS4.p2.2.1.m1.1a"><mrow id="S5.SS2.SSS4.p2.2.1.m1.1.1" xref="S5.SS2.SSS4.p2.2.1.m1.1.1.cmml"><mn mathcolor="#000000" id="S5.SS2.SSS4.p2.2.1.m1.1.1.2" xref="S5.SS2.SSS4.p2.2.1.m1.1.1.2.cmml">0</mn><mo lspace="0.552em" mathcolor="#000000" rspace="0.552em" id="S5.SS2.SSS4.p2.2.1.m1.1.1.1" xref="S5.SS2.SSS4.p2.2.1.m1.1.1.1.cmml">&amp;</mo><mn mathcolor="#000000" id="S5.SS2.SSS4.p2.2.1.m1.1.1.3" xref="S5.SS2.SSS4.p2.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p2.2.1.m1.1b"><apply id="S5.SS2.SSS4.p2.2.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p2.2.1.m1.1.1"><and id="S5.SS2.SSS4.p2.2.1.m1.1.1.1.cmml" xref="S5.SS2.SSS4.p2.2.1.m1.1.1.1"></and><cn type="integer" id="S5.SS2.SSS4.p2.2.1.m1.1.1.2.cmml" xref="S5.SS2.SSS4.p2.2.1.m1.1.1.2">0</cn><cn type="integer" id="S5.SS2.SSS4.p2.2.1.m1.1.1.3.cmml" xref="S5.SS2.SSS4.p2.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p2.2.1.m1.1c">0~{}\&amp;~{}1</annotation></semantics></math> means data part 0 was used in training and part 1 was used during the validation phase.</span>
The y-axis shows the validation set accuracy.
From left to right, the accuracy decreases when the server/shared NN for FSL, PSL, and FRC is shallower.
When the Cut Index is 3, SerAVG, FedAvG, and PSL perform equally well.
When the Cut Index is greater than 3, SerAVG is worse than FedAVG and lower but close to PSL.
We conclude that SerAVG can enhance the accuracy in the Non-IID source data setting, while worse than FL and PSL.
</p>
</div>
<div id="S5.SS2.SSS4.p3" class="ltx_para">
<p id="S5.SS2.SSS4.p3.1" class="ltx_p"><span id="S5.SS2.SSS4.p3.1.1" class="ltx_text" style="color:#000000;">Note that FedAVG averages all weights, while FSL never shares the clientâ€™s weight in the SerAVG setting.
Thus, FSL clients cannot benefit from the gradients calculated at other clients and that may lead to lower accuracy.
Comparing PSL and FSL,
the PSL server optimizes for minimal loss using all clientsâ€™ batch output.
On the other hand, SerAVG averages the trained weights on each server heuristically based on FedAVG. Thus, SerAVG will have lower accuracy compared with PSL.
And each client NN trained with a Non-IID dataset can extract little features from the other Non-IID dataset.
</span></p>
</div>
<div id="S5.SS2.SSS4.p4" class="ltx_para">
<p id="S5.SS2.SSS4.p4.1" class="ltx_p">Note also a similar but smoother drop in accuracy based on Cut Indexes with Independent and Identically Distributed (IID) partitioned CIFAR10 dataset and VGG16 NN in FigureÂ <a href="#S5.F7.sf1" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a>.
The two experiments with MNIST and CIFAR10 datasets suggest that SerAVG can preserve similar accuracy patterns even when applied to different NN models and Cut Indexes.</p>
</div>
<div id="S5.SS2.SSS4.p5" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS4.p5.3" class="ltx_p"><span id="S5.SS2.SSS4.p5.3.1" class="ltx_text ltx_font_bold">Tradeoff between resource demand and accuracy.</span>
In this experiment we evaluated the accuracy of FSL with small resource demand, i.e., when the size of the input data is limited, and the client model runs on limited resources.
We found that with LENET and MNIST, the validation dataset can reach an accuracy range of <math id="S5.SS2.SSS4.p5.1.m1.1" class="ltx_Math" alttext="87\%" display="inline"><semantics id="S5.SS2.SSS4.p5.1.m1.1a"><mrow id="S5.SS2.SSS4.p5.1.m1.1.1" xref="S5.SS2.SSS4.p5.1.m1.1.1.cmml"><mn id="S5.SS2.SSS4.p5.1.m1.1.1.2" xref="S5.SS2.SSS4.p5.1.m1.1.1.2.cmml">87</mn><mo id="S5.SS2.SSS4.p5.1.m1.1.1.1" xref="S5.SS2.SSS4.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p5.1.m1.1b"><apply id="S5.SS2.SSS4.p5.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p5.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.SSS4.p5.1.m1.1.1.1.cmml" xref="S5.SS2.SSS4.p5.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.SSS4.p5.1.m1.1.1.2.cmml" xref="S5.SS2.SSS4.p5.1.m1.1.1.2">87</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p5.1.m1.1c">87\%</annotation></semantics></math> to <math id="S5.SS2.SSS4.p5.2.m2.1" class="ltx_Math" alttext="93\%" display="inline"><semantics id="S5.SS2.SSS4.p5.2.m2.1a"><mrow id="S5.SS2.SSS4.p5.2.m2.1.1" xref="S5.SS2.SSS4.p5.2.m2.1.1.cmml"><mn id="S5.SS2.SSS4.p5.2.m2.1.1.2" xref="S5.SS2.SSS4.p5.2.m2.1.1.2.cmml">93</mn><mo id="S5.SS2.SSS4.p5.2.m2.1.1.1" xref="S5.SS2.SSS4.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p5.2.m2.1b"><apply id="S5.SS2.SSS4.p5.2.m2.1.1.cmml" xref="S5.SS2.SSS4.p5.2.m2.1.1"><csymbol cd="latexml" id="S5.SS2.SSS4.p5.2.m2.1.1.1.cmml" xref="S5.SS2.SSS4.p5.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.SSS4.p5.2.m2.1.1.2.cmml" xref="S5.SS2.SSS4.p5.2.m2.1.1.2">93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p5.2.m2.1c">93\%</annotation></semantics></math>, as long as each client has enough data to train the machine learning model.
By varying the number of clients, we quantified the expected drop in accuracy for both architectures.
Our results are shown in FigureÂ <a href="#S5.F6.sf4" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(d)</span></a>.
The x-axis indicates the index of epochs, and the y-axis shows the corresponding test set accuracy after a certain number of epochs.
<span id="S5.SS2.SSS4.p5.3.2" class="ltx_text" style="color:#000000;"> The dataset is IID among 20, 100, and 500 clients to study how the data size affects convergence.</span>
In FiguresÂ <a href="#S5.F6.sf1" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, <a href="#S5.F6.sf2" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>, <a href="#S5.F6.sf3" title="In Figure 6 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a> and <a href="#S5.F7.sf1" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a>, we also noted that FSL (implementing the SerAVG mechanism) keeps high accuracy when the Cut Index is small, allowing deployments over resource limited device given high performance requirement.
We expect a higher accuracy for both architectures with more effort in tuning the hyper-parameters, given prior results in similar contextsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.
While our accuracy results show <math id="S5.SS2.SSS4.p5.3.m3.1" class="ltx_Math" alttext="95\%" display="inline"><semantics id="S5.SS2.SSS4.p5.3.m3.1a"><mrow id="S5.SS2.SSS4.p5.3.m3.1.1" xref="S5.SS2.SSS4.p5.3.m3.1.1.cmml"><mn id="S5.SS2.SSS4.p5.3.m3.1.1.2" xref="S5.SS2.SSS4.p5.3.m3.1.1.2.cmml">95</mn><mo id="S5.SS2.SSS4.p5.3.m3.1.1.1" xref="S5.SS2.SSS4.p5.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p5.3.m3.1b"><apply id="S5.SS2.SSS4.p5.3.m3.1.1.cmml" xref="S5.SS2.SSS4.p5.3.m3.1.1"><csymbol cd="latexml" id="S5.SS2.SSS4.p5.3.m3.1.1.1.cmml" xref="S5.SS2.SSS4.p5.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.SSS4.p5.3.m3.1.1.2.cmml" xref="S5.SS2.SSS4.p5.3.m3.1.1.2">95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p5.3.m3.1c">95\%</annotation></semantics></math> confidence intervals, parameter tuning
is out of the scope of this paper.</p>
</div>
<figure id="S5.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x21.png" id="S5.F7.sf1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="327" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F7.sf1.3.2" class="ltx_text" style="font-size:90%;">Privacy Oblivious 
<br class="ltx_break">(VGG16+Cifar-10)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x22.png" id="S5.F7.sf2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="327" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F7.sf2.3.2" class="ltx_text" style="font-size:90%;">DC 1 &amp; Muiltiplier=2.0 
<br class="ltx_break">(VGG16+Cifar-10)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x23.png" id="S5.F7.sf3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="327" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F7.sf3.3.2" class="ltx_text" style="font-size:90%;">Privacy Oblivious 
<br class="ltx_break">(Lenet+MNIST)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F7.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x24.png" id="S5.F7.sf4.g1" class="ltx_graphics ltx_img_landscape" width="461" height="327" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F7.sf4.3.2" class="ltx_text" style="font-size:90%;">DC 1 &amp; Multiplier=0.3 
<br class="ltx_break">(Lenet+MNIST)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.4.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S5.F7.2.1" class="ltx_text" style="font-size:90%;">Accuracy and Attack Resilience for Privacy Oblivious and Privacy Aware Architectures based on Cut Index. Note: DC 1 in captions refer to <math id="S5.F7.2.1.m1.1" class="ltx_Math" alttext="DC\_Frequency=1" display="inline"><semantics id="S5.F7.2.1.m1.1b"><mrow id="S5.F7.2.1.m1.1.1" xref="S5.F7.2.1.m1.1.1.cmml"><mrow id="S5.F7.2.1.m1.1.1.2" xref="S5.F7.2.1.m1.1.1.2.cmml"><mi id="S5.F7.2.1.m1.1.1.2.2" xref="S5.F7.2.1.m1.1.1.2.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.3" xref="S5.F7.2.1.m1.1.1.2.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1b" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.F7.2.1.m1.1.1.2.4" xref="S5.F7.2.1.m1.1.1.2.4.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1c" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.5" xref="S5.F7.2.1.m1.1.1.2.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1d" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.6" xref="S5.F7.2.1.m1.1.1.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1e" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.7" xref="S5.F7.2.1.m1.1.1.2.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1f" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.8" xref="S5.F7.2.1.m1.1.1.2.8.cmml">q</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1g" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.9" xref="S5.F7.2.1.m1.1.1.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1h" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.10" xref="S5.F7.2.1.m1.1.1.2.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1i" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.11" xref="S5.F7.2.1.m1.1.1.2.11.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1j" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.12" xref="S5.F7.2.1.m1.1.1.2.12.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.F7.2.1.m1.1.1.2.1k" xref="S5.F7.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.F7.2.1.m1.1.1.2.13" xref="S5.F7.2.1.m1.1.1.2.13.cmml">y</mi></mrow><mo id="S5.F7.2.1.m1.1.1.1" xref="S5.F7.2.1.m1.1.1.1.cmml">=</mo><mn id="S5.F7.2.1.m1.1.1.3" xref="S5.F7.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.2.1.m1.1c"><apply id="S5.F7.2.1.m1.1.1.cmml" xref="S5.F7.2.1.m1.1.1"><eq id="S5.F7.2.1.m1.1.1.1.cmml" xref="S5.F7.2.1.m1.1.1.1"></eq><apply id="S5.F7.2.1.m1.1.1.2.cmml" xref="S5.F7.2.1.m1.1.1.2"><times id="S5.F7.2.1.m1.1.1.2.1.cmml" xref="S5.F7.2.1.m1.1.1.2.1"></times><ci id="S5.F7.2.1.m1.1.1.2.2.cmml" xref="S5.F7.2.1.m1.1.1.2.2">ğ·</ci><ci id="S5.F7.2.1.m1.1.1.2.3.cmml" xref="S5.F7.2.1.m1.1.1.2.3">ğ¶</ci><ci id="S5.F7.2.1.m1.1.1.2.4.cmml" xref="S5.F7.2.1.m1.1.1.2.4">_</ci><ci id="S5.F7.2.1.m1.1.1.2.5.cmml" xref="S5.F7.2.1.m1.1.1.2.5">ğ¹</ci><ci id="S5.F7.2.1.m1.1.1.2.6.cmml" xref="S5.F7.2.1.m1.1.1.2.6">ğ‘Ÿ</ci><ci id="S5.F7.2.1.m1.1.1.2.7.cmml" xref="S5.F7.2.1.m1.1.1.2.7">ğ‘’</ci><ci id="S5.F7.2.1.m1.1.1.2.8.cmml" xref="S5.F7.2.1.m1.1.1.2.8">ğ‘</ci><ci id="S5.F7.2.1.m1.1.1.2.9.cmml" xref="S5.F7.2.1.m1.1.1.2.9">ğ‘¢</ci><ci id="S5.F7.2.1.m1.1.1.2.10.cmml" xref="S5.F7.2.1.m1.1.1.2.10">ğ‘’</ci><ci id="S5.F7.2.1.m1.1.1.2.11.cmml" xref="S5.F7.2.1.m1.1.1.2.11">ğ‘›</ci><ci id="S5.F7.2.1.m1.1.1.2.12.cmml" xref="S5.F7.2.1.m1.1.1.2.12">ğ‘</ci><ci id="S5.F7.2.1.m1.1.1.2.13.cmml" xref="S5.F7.2.1.m1.1.1.2.13">ğ‘¦</ci></apply><cn type="integer" id="S5.F7.2.1.m1.1.1.3.cmml" xref="S5.F7.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.2.1.m1.1d">DC\_Frequency=1</annotation></semantics></math>.
These figures show that to reach high accuracy and attack resilience, the Cut Index cannot be too big or too small and loss multiplier is another way to enhance attack resilience. Furthermore, loss multiplier can be more practical than DC_Frequency, since it doesnâ€™t introduce overhead to the training steps.
</span></figcaption>
</figure>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span><span id="S5.SS3.1.1" class="ltx_text ltx_font_italic">Evaluation Results for Privacy-Aware FSL</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">In this section we present the evaluation results of our privacy-aware FSL (PAFSL) architecture and show that it can provide <span id="S5.SS3.p1.1.1" class="ltx_text" style="color:#000000;"> certain</span> privacy guarantees.
FSL clients do not share the source data and model weights, so adversaries cannot directly access the source data or reconstruct them with the model weights using model inversion attacksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
However, when compared with Federated Reconstruction (FRC)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> which trains a complete model at the client, FSL still sends the intermediate data through a network to complete the forward and backward propagation between clients and (edge) servers. An adversary could use such data to reproduce the source data, e.g., through an AutoencoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> NN,
trained with certain dataset, in SectionÂ <a href="#S4.SS1" title="4.1 Privacy Attacker Model and Assumptions â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">To assess how our approach mitigates such vulnerabilities, we first introduce the evaluation setup, the design and usage of the attacker Autoencoder NN, and our experiment methodology.
Then, we discuss the results of different <span id="S5.SS3.p2.1.1" class="ltx_text" style="color:#000000;"> privacy</span> approaches, i.e., NoPeekÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> <span id="S5.SS3.p2.1.2" class="ltx_text" style="color:#000000;"> and</span> the Client Based Privacy Approach (CPA), <span id="S5.SS3.p2.1.3" class="ltx_text" style="color:#000000;"> and privacy level of different ways of paritioning the NN.</span>
NoPeek solves a multi-objective optimization problem of two loss functions, i.e., one maximizes accuracy, and the other maximizes the differences between source images and intermediate data.
For CPA, we evaluate CPA-DC and CPA-DP.
CPA-DC (SectionÂ <a href="#S4.SS3" title="4.3 Client-Based Privacy Approach in Distributed Setting via Distance Correlation (CPA-DC) â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>) <span id="S5.SS3.p2.1.4" class="ltx_text" style="color:#000000;"> optimize the two loss function in NoPeek alternatively.</span>
CPA-DP applies a DP-SGD<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> algorithm in the clients.
Finally
we evaluate the privacy guarantee of different partitioning of client NN and server NN <span id="S5.SS3.p2.1.5" class="ltx_text" style="color:#000000;"> motivated by SectionÂ <a href="#S4.SS4" title="4.4 How many layers do we assign to each neural network partition? â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</span>
We conclude this section by presenting results that demonstrate the high resilience to privacy attacks of our proposed FSL and the advantages in training efficiency.</p>
</div>
<section id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>Evaluation Settings</h4>

<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p id="S5.SS3.SSS1.p1.1" class="ltx_p"><span id="S5.SS3.SSS1.p1.1.1" class="ltx_text" style="color:#000000;">Our Privacy-Aware FSL and PSL extend our Privacy-Oblivious version by adding the CPA.
Partitioning the NN was made easy by considering only sequential NNs (e.g., LeNET and VGG16).
We tested both systems with the same image classification workloads (e.g., MNIST and CIFAR10) on the same hardware (i.e., NVIDIA RTX6000 and NVIDIA V100, respectively) as the Privacy-Oblivious setting.
</span></p>
</div>
</section>
<section id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Setup the Attackerâ€™s Auto-Encoder Neural Network</h4>

<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p id="S5.SS3.SSS2.p1.1" class="ltx_p">In this subsection we explain how we define our privacy attack, given the assumptions mentioned in SectionÂ <a href="#S4.SS1" title="4.1 Privacy Attacker Model and Assumptions â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. To understand how the privacy attack works, it is useful to recall how the Autoencoder NN that we used work. In particular, the Autoencoder is composed of two parts: an encoder and a decoder.
We need a dataset similar to the source images to train the Autoencoder NN.</p>
</div>
<div id="S5.SS3.SSS2.p2" class="ltx_para">
<p id="S5.SS3.SSS2.p2.2" class="ltx_p">While the encoder uses convolutional layers to extract latent variables from its input dataset, the decoder uses the last layerâ€™s activation function outputs from the encoder and transposes the convolutional layers to reproduce the input dataset of the encoder.
Consequently, the encoder NN structure is the same as the client NN structure, and the attacker is the decoder NN.
The <math id="S5.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="i^{th}" display="inline"><semantics id="S5.SS3.SSS2.p2.1.m1.1a"><msup id="S5.SS3.SSS2.p2.1.m1.1.1" xref="S5.SS3.SSS2.p2.1.m1.1.1.cmml"><mi id="S5.SS3.SSS2.p2.1.m1.1.1.2" xref="S5.SS3.SSS2.p2.1.m1.1.1.2.cmml">i</mi><mrow id="S5.SS3.SSS2.p2.1.m1.1.1.3" xref="S5.SS3.SSS2.p2.1.m1.1.1.3.cmml"><mi id="S5.SS3.SSS2.p2.1.m1.1.1.3.2" xref="S5.SS3.SSS2.p2.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS2.p2.1.m1.1.1.3.1" xref="S5.SS3.SSS2.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS3.SSS2.p2.1.m1.1.1.3.3" xref="S5.SS3.SSS2.p2.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.1.m1.1b"><apply id="S5.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS2.p2.1.m1.1.1.1.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1">superscript</csymbol><ci id="S5.SS3.SSS2.p2.1.m1.1.1.2.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1.2">ğ‘–</ci><apply id="S5.SS3.SSS2.p2.1.m1.1.1.3.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1.3"><times id="S5.SS3.SSS2.p2.1.m1.1.1.3.1.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1.3.1"></times><ci id="S5.SS3.SSS2.p2.1.m1.1.1.3.2.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1.3.2">ğ‘¡</ci><ci id="S5.SS3.SSS2.p2.1.m1.1.1.3.3.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.1.m1.1c">i^{th}</annotation></semantics></math> layer of encoder would be the <math id="S5.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="i^{th}" display="inline"><semantics id="S5.SS3.SSS2.p2.2.m2.1a"><msup id="S5.SS3.SSS2.p2.2.m2.1.1" xref="S5.SS3.SSS2.p2.2.m2.1.1.cmml"><mi id="S5.SS3.SSS2.p2.2.m2.1.1.2" xref="S5.SS3.SSS2.p2.2.m2.1.1.2.cmml">i</mi><mrow id="S5.SS3.SSS2.p2.2.m2.1.1.3" xref="S5.SS3.SSS2.p2.2.m2.1.1.3.cmml"><mi id="S5.SS3.SSS2.p2.2.m2.1.1.3.2" xref="S5.SS3.SSS2.p2.2.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS2.p2.2.m2.1.1.3.1" xref="S5.SS3.SSS2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS3.SSS2.p2.2.m2.1.1.3.3" xref="S5.SS3.SSS2.p2.2.m2.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.2.m2.1b"><apply id="S5.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS2.p2.2.m2.1.1.1.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1">superscript</csymbol><ci id="S5.SS3.SSS2.p2.2.m2.1.1.2.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1.2">ğ‘–</ci><apply id="S5.SS3.SSS2.p2.2.m2.1.1.3.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1.3"><times id="S5.SS3.SSS2.p2.2.m2.1.1.3.1.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1.3.1"></times><ci id="S5.SS3.SSS2.p2.2.m2.1.1.3.2.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1.3.2">ğ‘¡</ci><ci id="S5.SS3.SSS2.p2.2.m2.1.1.3.3.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.2.m2.1c">i^{th}</annotation></semantics></math> last layer of decoder, with transposed convolutional layer.
We assume the attackerâ€™s decoder structure strictly mirrors the client NN structure.
Thus, we expect better attack resilience for SL-based systems in the real world.
</p>
</div>
</section>
<section id="S5.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.3 </span>Privacy Evaluation: Methodology</h4>

<div id="S5.SS3.SSS3.p1" class="ltx_para">
<p id="S5.SS3.SSS3.p1.1" class="ltx_p">In this subset of our evaluation, we want to show <span id="S5.SS3.SSS3.p1.1.1" class="ltx_text" style="color:#000000;"> both CPA and carefully designed ways of partitioning NN provide high attack resilience while preserving high accuracy, based on different datasets, NNs, for split learning based systems.</span></p>
</div>
<div id="S5.SS3.SSS3.p2" class="ltx_para">
<p id="S5.SS3.SSS3.p2.1" class="ltx_p">Each experiment includes trials initializing the Autoencoderâ€™s weights and data-loaders with different random seeds.
In each trial,
the attacker used a dataset containing similar features to the learnerâ€™s source dataset.
To reconstruct MNIST, we selected EMNISTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, and for CIFAR10 we selected the CIFAR100Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
The EMNIST dataset contains hand-written characters instead of numbers in MNIST, so features like lines and curves are the same and attacker can decode those activation function outputs.
Similarly, the CIFAR100 dataset contains 100 classes of RGB images instead of the 10 classes in CIFAR10, so the common features, e.g. classifying cat or dog, can be used to reconstruct with
the activation function outputs from the CIFAR10 dataset.
</p>
</div>
<div id="S5.SS3.SSS3.p3" class="ltx_para">
<p id="S5.SS3.SSS3.p3.1" class="ltx_p">For each trial of the experiment, we first let the attacker learn to reproduce her datasets.
Based on the MSE loss, <span id="S5.SS3.SSS3.p3.1.1" class="ltx_text ltx_font_italic">i.e.</span>Â a loss function that measures how different the original and reproduced images are, the attacker updates her weights in each epoch.
After 20 epochs, we used the decoder to reproduce the learnerâ€™s dataset from the intermediate data.</p>
</div>
<div id="S5.SS3.SSS3.p4" class="ltx_para">
<p id="S5.SS3.SSS3.p4.1" class="ltx_p">When an autoencoder NN is trained, we train a new classifier with the same NN structure and source data as the learner to classify the reproduced images for 20 epochs.
The mean and standard deviation of this classifierâ€™s <span id="S5.SS3.SSS3.p4.1.1" class="ltx_text ltx_font_italic">attack resilience</span> <math id="S5.SS3.SSS3.p4.1.m1.1" class="ltx_Math" alttext="\tau~{}" display="inline"><semantics id="S5.SS3.SSS3.p4.1.m1.1a"><mi id="S5.SS3.SSS3.p4.1.m1.1.1" xref="S5.SS3.SSS3.p4.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p4.1.m1.1b"><ci id="S5.SS3.SSS3.p4.1.m1.1.1.cmml" xref="S5.SS3.SSS3.p4.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS3.p4.1.m1.1c">\tau~{}</annotation></semantics></math> in section <a href="#S4.SS2" title="4.2 Attack Resilience â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
<div id="S5.SS3.SSS3.p5" class="ltx_para">
<p id="S5.SS3.SSS3.p5.1" class="ltx_p">We show the results comparing the four systems, i.e., POFSL, POPSL, PAFSL, and PAPSL, with different CPAs and Cut Indexes.
Then, we evaluate the trade-off between accuracy and attack resilience for FSL and PSL.
</p>
</div>
</section>
<section id="S5.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.4 </span>Privacy Evaluation using NoPeek</h4>

<div id="S5.SS3.SSS4.p1" class="ltx_para">
<p id="S5.SS3.SSS4.p1.1" class="ltx_p">As we illustrated in SectionÂ <a href="#S2" title="2 Distributed Learning Architectures: Background and Related Work â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, NoPeek solves a multi-objective optimization problem that takes in the source data and intermediate data to maximize the difference with a Distance Correlation (DC) loss function, as well as the prediction and labels to maximize the accuracy.
To solve such optimization problem, NoPeek has to share the value of the loss over an network which may cause vulnerability or added complexity of maintaining the gradient graph.
As shown in TableÂ <a href="#S5.T1" title="TABLE I â€£ 5.3.4 Privacy Evaluation using NoPeek â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, this approach has both high attack resilience (i.e., 97% for PSL and 98% for FSL) and high learnerâ€™s accuracy (i.e., 97% for PSL and 96% for FSL) when trained for the same number of epochs and clients as the Privacy Oblivious experiment with the MNIST dataset and LENET NN.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.1.2.1" class="ltx_tr">
<th id="S5.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">cases</th>
<th id="S5.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">PSL</th>
<th id="S5.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">FSL</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.1.1" class="ltx_tr">
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">attack_resilience(<math id="S5.T1.1.1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S5.T1.1.1.1.m1.1a"><mi id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">\tau</annotation></semantics></math>)</td>
<td id="S5.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9733</td>
<td id="S5.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">0.9837</td>
</tr>
<tr id="S5.T1.1.3.1" class="ltx_tr">
<td id="S5.T1.1.3.1.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">learner_accuracy</td>
<td id="S5.T1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.9702</td>
<td id="S5.T1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">0.9614</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.5.2.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S5.T1.3.1" class="ltx_text" style="font-size:90%;color:#000000;"> NoPeek stats with 20 clients training <math id="S5.T1.3.1.m1.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S5.T1.3.1.m1.1b"><mn mathcolor="#000000" id="S5.T1.3.1.m1.1.1" xref="S5.T1.3.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S5.T1.3.1.m1.1c"><cn type="integer" id="S5.T1.3.1.m1.1.1.cmml" xref="S5.T1.3.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.1.m1.1d">20</annotation></semantics></math> epochs.</span></figcaption>
</figure>
</section>
<section id="S5.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.5 </span>Evaluation Result using Client-Based Privacy Approach via Distance Correlation</h4>

<div id="S5.SS3.SSS5.p1" class="ltx_para">
<p id="S5.SS3.SSS5.p1.1" class="ltx_p">To mitigate the drawbacks of the loss value sharing, we consider a new approach that prevents transmitting data outside clients, improving upon NoPeek.
We optimize for the similar two objectives in NoPeek alternatively in the Client-Based Privacy Approach (CPA) via DC.
As shown in
EquationÂ <a href="#S4.E2" title="In 4.3 Client-Based Privacy Approach in Distributed Setting via Distance Correlation (CPA-DC) â€£ 4 Privacy-Aware FSL â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, there are <span id="S5.SS3.SSS5.p1.1.1" class="ltx_text ltx_font_italic">DC FrequencyÂ (F)</span> and <span id="S5.SS3.SSS5.p1.1.2" class="ltx_text ltx_font_italic">Loss MultiplierÂ (m)</span> to evaluate. <span id="S5.SS3.SSS5.p1.1.3" class="ltx_text ltx_font_italic">DC FrequencyÂ (F)</span> defines how many times the DC loss function is optimized after the loss function for accuracy is optimized once.
<span id="S5.SS3.SSS5.p1.1.4" class="ltx_text ltx_font_italic">Loss MultiplierÂ (m)</span> is applied to the loss function result but has the equivalent effect of multiplying the learning rate by a factor <math id="S5.SS3.SSS5.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S5.SS3.SSS5.p1.1.m1.1a"><mi id="S5.SS3.SSS5.p1.1.m1.1.1" xref="S5.SS3.SSS5.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p1.1.m1.1b"><ci id="S5.SS3.SSS5.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS5.p1.1.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p1.1.m1.1c">m</annotation></semantics></math>.
These two parameters control how different the intermediate data and source data will be,
by changing the frequency of optimizing the DC loss and by changing the learning rate of gradients applied during that optimization, respectively.</p>
</div>
<div id="S5.SS3.SSS5.p2" class="ltx_para">
<p id="S5.SS3.SSS5.p2.1" class="ltx_p"><span id="S5.SS3.SSS5.p2.1.2" class="ltx_text" style="color:#000000;">We note multiple tradeoffs in CPA-DC. First,</span> CPA-DC is not as training time-efficient as NoPeek. NoPeek can optimize its two objectives simultaneously while CPA-DC has to solve them sequentially.
However, we consider that NoPeek transfers more information than necessary over a network.
<span id="S5.SS3.SSS5.p2.1.1" class="ltx_text" style="color:#000000;"> 
Second, there are tradeoffs for <span id="S5.SS3.SSS5.p2.1.1.1" class="ltx_text ltx_font_italic">DC FrequencyÂ (F)</span> and <span id="S5.SS3.SSS5.p2.1.1.2" class="ltx_text ltx_font_italic">Loss MultiplierÂ (m)</span>.
Increasing <span id="S5.SS3.SSS5.p2.1.1.3" class="ltx_text ltx_font_italic">F</span> adds more epochs to optimize for DC loss, so the attack resilience would be higher at the expense of a longer training time.
Moreover, we introduced <span id="S5.SS3.SSS5.p2.1.1.4" class="ltx_text ltx_font_italic">m</span>, so that we can keep a small <span id="S5.SS3.SSS5.p2.1.1.5" class="ltx_text ltx_font_italic">F</span> and only increase <span id="S5.SS3.SSS5.p2.1.1.6" class="ltx_text ltx_font_italic">m</span>, which reduces training time while maintaining attack resilience.
We multiply larger <span id="S5.SS3.SSS5.p2.1.1.7" class="ltx_text ltx_font_italic">m</span> by the DC loss, similar to increasing the gradient descent step size.
Thus, we need less DC epochs to maintain the attack resilience, given a larger <span id="S5.SS3.SSS5.p2.1.1.8" class="ltx_text ltx_font_italic">m</span>, while the DC loss becomes less accurate.
Based on the discussion, intuitively we expect that a large <span id="S5.SS3.SSS5.p2.1.1.9" class="ltx_text ltx_font_italic">m</span> combined with <span id="S5.SS3.SSS5.p2.1.1.10" class="ltx_text ltx_font_italic">F</span> of <math id="S5.SS3.SSS5.p2.1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS3.SSS5.p2.1.1.m1.1a"><mn mathcolor="#000000" id="S5.SS3.SSS5.p2.1.1.m1.1.1" xref="S5.SS3.SSS5.p2.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p2.1.1.m1.1b"><cn type="integer" id="S5.SS3.SSS5.p2.1.1.m1.1.1.cmml" xref="S5.SS3.SSS5.p2.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p2.1.1.m1.1c">1</annotation></semantics></math> can balance between training time efficiency and DC loss gradientsâ€™ accuracy.
These two parameters should be carefully designed in a production environment.
</span></p>
</div>
<div id="S5.SS3.SSS5.p3" class="ltx_para">
<p id="S5.SS3.SSS5.p3.1" class="ltx_p">We first experimented MNIST classification with different DC Frequencies with a constant loss multiplier of 0.1 (equivalent to reducing the learning rate by <math id="S5.SS3.SSS5.p3.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S5.SS3.SSS5.p3.1.m1.1a"><mrow id="S5.SS3.SSS5.p3.1.m1.1.1" xref="S5.SS3.SSS5.p3.1.m1.1.1.cmml"><mn id="S5.SS3.SSS5.p3.1.m1.1.1.2" xref="S5.SS3.SSS5.p3.1.m1.1.1.2.cmml">10</mn><mo id="S5.SS3.SSS5.p3.1.m1.1.1.1" xref="S5.SS3.SSS5.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p3.1.m1.1b"><apply id="S5.SS3.SSS5.p3.1.m1.1.1.cmml" xref="S5.SS3.SSS5.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.SSS5.p3.1.m1.1.1.1.cmml" xref="S5.SS3.SSS5.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS5.p3.1.m1.1.1.2.cmml" xref="S5.SS3.SSS5.p3.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p3.1.m1.1c">10\%</annotation></semantics></math>) and studied the tradeoff between accuracy and attack resilience, as shown in Fig.Â <a href="#S5.F8.sf1" title="In Figure 8 â€£ 5.3.5 Evaluation Result using Client-Based Privacy Approach via Distance Correlation â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a>.
The x-axis represents the DC Frequency, the left y-axis shows the learner accuracy and the right y-axis shows the corresponding attack resilience.</p>
</div>
<div id="S5.SS3.SSS5.p4" class="ltx_para">
<p id="S5.SS3.SSS5.p4.1" class="ltx_p">From the top plot of FigureÂ <a href="#S5.F8" title="Figure 8 â€£ 5.3.5 Evaluation Result using Client-Based Privacy Approach via Distance Correlation â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>A DC Frequency of zero corresponds to POFSL and POPSL without the privacy-aware approaches.</span></span></span>, as DC Frequency is increasing, for both Privacy Aware FSL (PAFSL) and Privacy Aware PSL (PAPSL) systems, the attack resiliency increases and the learner accuracy decreases, as expected.</p>
</div>
<div id="S5.SS3.SSS5.p5" class="ltx_para">
<p id="S5.SS3.SSS5.p5.4" class="ltx_p">Notice that PAFSL achieves better accuracy and good resilience for most DC Frequency values.
For DC Frequency from 10 to 20, given that the attack resilience of PAFSL and PAPSL are close within <math id="S5.SS3.SSS5.p5.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S5.SS3.SSS5.p5.1.m1.1a"><mrow id="S5.SS3.SSS5.p5.1.m1.1.1" xref="S5.SS3.SSS5.p5.1.m1.1.1.cmml"><mn id="S5.SS3.SSS5.p5.1.m1.1.1.2" xref="S5.SS3.SSS5.p5.1.m1.1.1.2.cmml">10</mn><mo id="S5.SS3.SSS5.p5.1.m1.1.1.1" xref="S5.SS3.SSS5.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p5.1.m1.1b"><apply id="S5.SS3.SSS5.p5.1.m1.1.1.cmml" xref="S5.SS3.SSS5.p5.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.SSS5.p5.1.m1.1.1.1.cmml" xref="S5.SS3.SSS5.p5.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS5.p5.1.m1.1.1.2.cmml" xref="S5.SS3.SSS5.p5.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p5.1.m1.1c">10\%</annotation></semantics></math> difference, PAFSL achieves more than <math id="S5.SS3.SSS5.p5.2.m2.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S5.SS3.SSS5.p5.2.m2.1a"><mrow id="S5.SS3.SSS5.p5.2.m2.1.1" xref="S5.SS3.SSS5.p5.2.m2.1.1.cmml"><mn id="S5.SS3.SSS5.p5.2.m2.1.1.2" xref="S5.SS3.SSS5.p5.2.m2.1.1.2.cmml">90</mn><mo id="S5.SS3.SSS5.p5.2.m2.1.1.1" xref="S5.SS3.SSS5.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p5.2.m2.1b"><apply id="S5.SS3.SSS5.p5.2.m2.1.1.cmml" xref="S5.SS3.SSS5.p5.2.m2.1.1"><csymbol cd="latexml" id="S5.SS3.SSS5.p5.2.m2.1.1.1.cmml" xref="S5.SS3.SSS5.p5.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS5.p5.2.m2.1.1.2.cmml" xref="S5.SS3.SSS5.p5.2.m2.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p5.2.m2.1c">90\%</annotation></semantics></math> accuracy.
From 25 to 35, PAPSL does not learn any features while PAFSL still has about <math id="S5.SS3.SSS5.p5.3.m3.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S5.SS3.SSS5.p5.3.m3.1a"><mrow id="S5.SS3.SSS5.p5.3.m3.1.1" xref="S5.SS3.SSS5.p5.3.m3.1.1.cmml"><mn id="S5.SS3.SSS5.p5.3.m3.1.1.2" xref="S5.SS3.SSS5.p5.3.m3.1.1.2.cmml">80</mn><mo id="S5.SS3.SSS5.p5.3.m3.1.1.1" xref="S5.SS3.SSS5.p5.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p5.3.m3.1b"><apply id="S5.SS3.SSS5.p5.3.m3.1.1.cmml" xref="S5.SS3.SSS5.p5.3.m3.1.1"><csymbol cd="latexml" id="S5.SS3.SSS5.p5.3.m3.1.1.1.cmml" xref="S5.SS3.SSS5.p5.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS5.p5.3.m3.1.1.2.cmml" xref="S5.SS3.SSS5.p5.3.m3.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p5.3.m3.1c">80\%</annotation></semantics></math> accuracy.
When DC Frequency is five, the PAPSL has an advantage over PAFSL, with close accuracy, and PAPSL has around <math id="S5.SS3.SSS5.p5.4.m4.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S5.SS3.SSS5.p5.4.m4.1a"><mrow id="S5.SS3.SSS5.p5.4.m4.1.1" xref="S5.SS3.SSS5.p5.4.m4.1.1.cmml"><mn id="S5.SS3.SSS5.p5.4.m4.1.1.2" xref="S5.SS3.SSS5.p5.4.m4.1.1.2.cmml">20</mn><mo id="S5.SS3.SSS5.p5.4.m4.1.1.1" xref="S5.SS3.SSS5.p5.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p5.4.m4.1b"><apply id="S5.SS3.SSS5.p5.4.m4.1.1.cmml" xref="S5.SS3.SSS5.p5.4.m4.1.1"><csymbol cd="latexml" id="S5.SS3.SSS5.p5.4.m4.1.1.1.cmml" xref="S5.SS3.SSS5.p5.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS5.p5.4.m4.1.1.2.cmml" xref="S5.SS3.SSS5.p5.4.m4.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p5.4.m4.1c">20\%</annotation></semantics></math> more attack resilience.
<br class="ltx_break"><span id="S5.SS3.SSS5.p5.4.1" class="ltx_text ltx_font_bold">The result shows that PAFSL with CPA-DC is easier to tune for high accuracy and attack resilience.</span> <span id="S5.SS3.SSS5.p5.4.2" class="ltx_text ltx_font_italic">Within wider domain of DC Frequency, PAFSL has higher accuracy and good attack resilience compared to PAPSL.</span>
This is because of the learning rate (step size) in SerAVG and PSL.
The server weight update rule of PSL is shown in EquationÂ <a href="#S5.E5" title="In 5.3.5 Evaluation Result using Client-Based Privacy Approach via Distance Correlation â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
<table id="S5.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E5.m1.1" class="ltx_Math" alttext="W_{g}^{t+1}=W_{g}^{t}-\eta\sum_{i=1}^{N_{C}}\dfrac{\partial g(f(x_{i}))}{\partial W_{g}}" display="block"><semantics id="S5.E5.m1.1a"><mrow id="S5.E5.m1.1.2" xref="S5.E5.m1.1.2.cmml"><msubsup id="S5.E5.m1.1.2.2" xref="S5.E5.m1.1.2.2.cmml"><mi id="S5.E5.m1.1.2.2.2.2" xref="S5.E5.m1.1.2.2.2.2.cmml">W</mi><mi id="S5.E5.m1.1.2.2.2.3" xref="S5.E5.m1.1.2.2.2.3.cmml">g</mi><mrow id="S5.E5.m1.1.2.2.3" xref="S5.E5.m1.1.2.2.3.cmml"><mi id="S5.E5.m1.1.2.2.3.2" xref="S5.E5.m1.1.2.2.3.2.cmml">t</mi><mo id="S5.E5.m1.1.2.2.3.1" xref="S5.E5.m1.1.2.2.3.1.cmml">+</mo><mn id="S5.E5.m1.1.2.2.3.3" xref="S5.E5.m1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S5.E5.m1.1.2.1" xref="S5.E5.m1.1.2.1.cmml">=</mo><mrow id="S5.E5.m1.1.2.3" xref="S5.E5.m1.1.2.3.cmml"><msubsup id="S5.E5.m1.1.2.3.2" xref="S5.E5.m1.1.2.3.2.cmml"><mi id="S5.E5.m1.1.2.3.2.2.2" xref="S5.E5.m1.1.2.3.2.2.2.cmml">W</mi><mi id="S5.E5.m1.1.2.3.2.2.3" xref="S5.E5.m1.1.2.3.2.2.3.cmml">g</mi><mi id="S5.E5.m1.1.2.3.2.3" xref="S5.E5.m1.1.2.3.2.3.cmml">t</mi></msubsup><mo id="S5.E5.m1.1.2.3.1" xref="S5.E5.m1.1.2.3.1.cmml">âˆ’</mo><mrow id="S5.E5.m1.1.2.3.3" xref="S5.E5.m1.1.2.3.3.cmml"><mi id="S5.E5.m1.1.2.3.3.2" xref="S5.E5.m1.1.2.3.3.2.cmml">Î·</mi><mo lspace="0em" rspace="0em" id="S5.E5.m1.1.2.3.3.1" xref="S5.E5.m1.1.2.3.3.1.cmml">â€‹</mo><mrow id="S5.E5.m1.1.2.3.3.3" xref="S5.E5.m1.1.2.3.3.3.cmml"><munderover id="S5.E5.m1.1.2.3.3.3.1" xref="S5.E5.m1.1.2.3.3.3.1.cmml"><mo movablelimits="false" id="S5.E5.m1.1.2.3.3.3.1.2.2" xref="S5.E5.m1.1.2.3.3.3.1.2.2.cmml">âˆ‘</mo><mrow id="S5.E5.m1.1.2.3.3.3.1.2.3" xref="S5.E5.m1.1.2.3.3.3.1.2.3.cmml"><mi id="S5.E5.m1.1.2.3.3.3.1.2.3.2" xref="S5.E5.m1.1.2.3.3.3.1.2.3.2.cmml">i</mi><mo id="S5.E5.m1.1.2.3.3.3.1.2.3.1" xref="S5.E5.m1.1.2.3.3.3.1.2.3.1.cmml">=</mo><mn id="S5.E5.m1.1.2.3.3.3.1.2.3.3" xref="S5.E5.m1.1.2.3.3.3.1.2.3.3.cmml">1</mn></mrow><msub id="S5.E5.m1.1.2.3.3.3.1.3" xref="S5.E5.m1.1.2.3.3.3.1.3.cmml"><mi id="S5.E5.m1.1.2.3.3.3.1.3.2" xref="S5.E5.m1.1.2.3.3.3.1.3.2.cmml">N</mi><mi id="S5.E5.m1.1.2.3.3.3.1.3.3" xref="S5.E5.m1.1.2.3.3.3.1.3.3.cmml">C</mi></msub></munderover><mfrac id="S5.E5.m1.1.1" xref="S5.E5.m1.1.1.cmml"><mrow id="S5.E5.m1.1.1.1" xref="S5.E5.m1.1.1.1.cmml"><mo rspace="0em" id="S5.E5.m1.1.1.1.2" xref="S5.E5.m1.1.1.1.2.cmml">âˆ‚</mo><mrow id="S5.E5.m1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml"><mi id="S5.E5.m1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E5.m1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E5.m1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E5.m1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.E5.m1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S5.E5.m1.1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E5.m1.1.1.1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S5.E5.m1.1.1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S5.E5.m1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E5.m1.1.1.3" xref="S5.E5.m1.1.1.3.cmml"><mo rspace="0em" id="S5.E5.m1.1.1.3.1" xref="S5.E5.m1.1.1.3.1.cmml">âˆ‚</mo><msub id="S5.E5.m1.1.1.3.2" xref="S5.E5.m1.1.1.3.2.cmml"><mi id="S5.E5.m1.1.1.3.2.2" xref="S5.E5.m1.1.1.3.2.2.cmml">W</mi><mi id="S5.E5.m1.1.1.3.2.3" xref="S5.E5.m1.1.1.3.2.3.cmml">g</mi></msub></mrow></mfrac></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.1b"><apply id="S5.E5.m1.1.2.cmml" xref="S5.E5.m1.1.2"><eq id="S5.E5.m1.1.2.1.cmml" xref="S5.E5.m1.1.2.1"></eq><apply id="S5.E5.m1.1.2.2.cmml" xref="S5.E5.m1.1.2.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.2.2.1.cmml" xref="S5.E5.m1.1.2.2">superscript</csymbol><apply id="S5.E5.m1.1.2.2.2.cmml" xref="S5.E5.m1.1.2.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.2.2.2.1.cmml" xref="S5.E5.m1.1.2.2">subscript</csymbol><ci id="S5.E5.m1.1.2.2.2.2.cmml" xref="S5.E5.m1.1.2.2.2.2">ğ‘Š</ci><ci id="S5.E5.m1.1.2.2.2.3.cmml" xref="S5.E5.m1.1.2.2.2.3">ğ‘”</ci></apply><apply id="S5.E5.m1.1.2.2.3.cmml" xref="S5.E5.m1.1.2.2.3"><plus id="S5.E5.m1.1.2.2.3.1.cmml" xref="S5.E5.m1.1.2.2.3.1"></plus><ci id="S5.E5.m1.1.2.2.3.2.cmml" xref="S5.E5.m1.1.2.2.3.2">ğ‘¡</ci><cn type="integer" id="S5.E5.m1.1.2.2.3.3.cmml" xref="S5.E5.m1.1.2.2.3.3">1</cn></apply></apply><apply id="S5.E5.m1.1.2.3.cmml" xref="S5.E5.m1.1.2.3"><minus id="S5.E5.m1.1.2.3.1.cmml" xref="S5.E5.m1.1.2.3.1"></minus><apply id="S5.E5.m1.1.2.3.2.cmml" xref="S5.E5.m1.1.2.3.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.2.3.2.1.cmml" xref="S5.E5.m1.1.2.3.2">superscript</csymbol><apply id="S5.E5.m1.1.2.3.2.2.cmml" xref="S5.E5.m1.1.2.3.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.2.3.2.2.1.cmml" xref="S5.E5.m1.1.2.3.2">subscript</csymbol><ci id="S5.E5.m1.1.2.3.2.2.2.cmml" xref="S5.E5.m1.1.2.3.2.2.2">ğ‘Š</ci><ci id="S5.E5.m1.1.2.3.2.2.3.cmml" xref="S5.E5.m1.1.2.3.2.2.3">ğ‘”</ci></apply><ci id="S5.E5.m1.1.2.3.2.3.cmml" xref="S5.E5.m1.1.2.3.2.3">ğ‘¡</ci></apply><apply id="S5.E5.m1.1.2.3.3.cmml" xref="S5.E5.m1.1.2.3.3"><times id="S5.E5.m1.1.2.3.3.1.cmml" xref="S5.E5.m1.1.2.3.3.1"></times><ci id="S5.E5.m1.1.2.3.3.2.cmml" xref="S5.E5.m1.1.2.3.3.2">ğœ‚</ci><apply id="S5.E5.m1.1.2.3.3.3.cmml" xref="S5.E5.m1.1.2.3.3.3"><apply id="S5.E5.m1.1.2.3.3.3.1.cmml" xref="S5.E5.m1.1.2.3.3.3.1"><csymbol cd="ambiguous" id="S5.E5.m1.1.2.3.3.3.1.1.cmml" xref="S5.E5.m1.1.2.3.3.3.1">superscript</csymbol><apply id="S5.E5.m1.1.2.3.3.3.1.2.cmml" xref="S5.E5.m1.1.2.3.3.3.1"><csymbol cd="ambiguous" id="S5.E5.m1.1.2.3.3.3.1.2.1.cmml" xref="S5.E5.m1.1.2.3.3.3.1">subscript</csymbol><sum id="S5.E5.m1.1.2.3.3.3.1.2.2.cmml" xref="S5.E5.m1.1.2.3.3.3.1.2.2"></sum><apply id="S5.E5.m1.1.2.3.3.3.1.2.3.cmml" xref="S5.E5.m1.1.2.3.3.3.1.2.3"><eq id="S5.E5.m1.1.2.3.3.3.1.2.3.1.cmml" xref="S5.E5.m1.1.2.3.3.3.1.2.3.1"></eq><ci id="S5.E5.m1.1.2.3.3.3.1.2.3.2.cmml" xref="S5.E5.m1.1.2.3.3.3.1.2.3.2">ğ‘–</ci><cn type="integer" id="S5.E5.m1.1.2.3.3.3.1.2.3.3.cmml" xref="S5.E5.m1.1.2.3.3.3.1.2.3.3">1</cn></apply></apply><apply id="S5.E5.m1.1.2.3.3.3.1.3.cmml" xref="S5.E5.m1.1.2.3.3.3.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.1.2.3.3.3.1.3.1.cmml" xref="S5.E5.m1.1.2.3.3.3.1.3">subscript</csymbol><ci id="S5.E5.m1.1.2.3.3.3.1.3.2.cmml" xref="S5.E5.m1.1.2.3.3.3.1.3.2">ğ‘</ci><ci id="S5.E5.m1.1.2.3.3.3.1.3.3.cmml" xref="S5.E5.m1.1.2.3.3.3.1.3.3">ğ¶</ci></apply></apply><apply id="S5.E5.m1.1.1.cmml" xref="S5.E5.m1.1.1"><divide id="S5.E5.m1.1.1.2.cmml" xref="S5.E5.m1.1.1"></divide><apply id="S5.E5.m1.1.1.1.cmml" xref="S5.E5.m1.1.1.1"><partialdiff id="S5.E5.m1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.2"></partialdiff><apply id="S5.E5.m1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1"><times id="S5.E5.m1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.2"></times><ci id="S5.E5.m1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.3">ğ‘”</ci><apply id="S5.E5.m1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1"><times id="S5.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2"></times><ci id="S5.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.3">ğ‘“</ci><apply id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply><apply id="S5.E5.m1.1.1.3.cmml" xref="S5.E5.m1.1.1.3"><partialdiff id="S5.E5.m1.1.1.3.1.cmml" xref="S5.E5.m1.1.1.3.1"></partialdiff><apply id="S5.E5.m1.1.1.3.2.cmml" xref="S5.E5.m1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.3.2.1.cmml" xref="S5.E5.m1.1.1.3.2">subscript</csymbol><ci id="S5.E5.m1.1.1.3.2.2.cmml" xref="S5.E5.m1.1.1.3.2.2">ğ‘Š</ci><ci id="S5.E5.m1.1.1.3.2.3.cmml" xref="S5.E5.m1.1.1.3.2.3">ğ‘”</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.1c">W_{g}^{t+1}=W_{g}^{t}-\eta\sum_{i=1}^{N_{C}}\dfrac{\partial g(f(x_{i}))}{\partial W_{g}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S5.SS3.SSS5.p5.5" class="ltx_p">The server weight update rule of FSL is shown in EquationÂ <a href="#S5.E6" title="In 5.3.5 Evaluation Result using Client-Based Privacy Approach via Distance Correlation â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div id="S5.SS3.SSS5.p6" class="ltx_para">
<table id="S5.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E6.m1.18" class="ltx_Math" alttext="\begin{split}W_{g}^{t+1}&amp;=\frac{\sum_{i=1}^{N_{C}}(W_{g}^{t}-\eta\dfrac{\partial g(f(x_{i}))}{\partial W_{g}})}{N_{C}}\\
&amp;=W_{g}^{t}-\frac{\eta}{N_{C}}\sum_{i=1}^{N_{C}}\dfrac{\partial g(f(x_{i}))}{\partial W_{g}},\end{split}" display="block"><semantics id="S5.E6.m1.18a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S5.E6.m1.18.18.2"><mtr id="S5.E6.m1.18.18.2a"><mtd class="ltx_align_right" columnalign="right" id="S5.E6.m1.18.18.2b"><msubsup id="S5.E6.m1.3.3.3.3.3"><mi id="S5.E6.m1.1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.cmml">W</mi><mi id="S5.E6.m1.2.2.2.2.2.2.1" xref="S5.E6.m1.2.2.2.2.2.2.1.cmml">g</mi><mrow id="S5.E6.m1.3.3.3.3.3.3.1" xref="S5.E6.m1.3.3.3.3.3.3.1.cmml"><mi id="S5.E6.m1.3.3.3.3.3.3.1.2" xref="S5.E6.m1.3.3.3.3.3.3.1.2.cmml">t</mi><mo id="S5.E6.m1.3.3.3.3.3.3.1.1" xref="S5.E6.m1.3.3.3.3.3.3.1.1.cmml">+</mo><mn id="S5.E6.m1.3.3.3.3.3.3.1.3" xref="S5.E6.m1.3.3.3.3.3.3.1.3.cmml">1</mn></mrow></msubsup></mtd><mtd class="ltx_align_left" columnalign="left" id="S5.E6.m1.18.18.2c"><mrow id="S5.E6.m1.5.5.5.5.2"><mi id="S5.E6.m1.5.5.5.5.2.3" xref="S5.E6.m1.17.17.1.1.1.cmml"></mi><mo id="S5.E6.m1.4.4.4.4.1.1" xref="S5.E6.m1.4.4.4.4.1.1.cmml">=</mo><mfrac id="S5.E6.m1.5.5.5.5.2.2" xref="S5.E6.m1.5.5.5.5.2.2.cmml"><mrow id="S5.E6.m1.5.5.5.5.2.2.2" xref="S5.E6.m1.5.5.5.5.2.2.2.cmml"><msubsup id="S5.E6.m1.5.5.5.5.2.2.2.3" xref="S5.E6.m1.5.5.5.5.2.2.2.3.cmml"><mo id="S5.E6.m1.5.5.5.5.2.2.2.3.2.2" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.2.cmml">âˆ‘</mo><mrow id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.2" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.2.cmml">i</mi><mo id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.1" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.1.cmml">=</mo><mn id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.3" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.3.cmml">1</mn></mrow><msub id="S5.E6.m1.5.5.5.5.2.2.2.3.3" xref="S5.E6.m1.5.5.5.5.2.2.2.3.3.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.2.3.3.2" xref="S5.E6.m1.5.5.5.5.2.2.2.3.3.2.cmml">N</mi><mi id="S5.E6.m1.5.5.5.5.2.2.2.3.3.3" xref="S5.E6.m1.5.5.5.5.2.2.2.3.3.3.cmml">C</mi></msub></msubsup><mrow id="S5.E6.m1.5.5.5.5.2.2.2.2.1" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.cmml"><mo lspace="0em" stretchy="false" id="S5.E6.m1.5.5.5.5.2.2.2.2.1.2" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.cmml">(</mo><mrow id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.cmml"><msubsup id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.2" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.2.cmml">W</mi><mi id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.3" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.3.cmml">g</mi><mi id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.3" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.3.cmml">t</mi></msubsup><mo id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.1" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.1.cmml">âˆ’</mo><mrow id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.2" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.2.cmml">Î·</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.1" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.1.cmml">â€‹</mo><mstyle displaystyle="true" id="S5.E6.m1.5.5.5.5.2.2.1.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.cmml"><mfrac id="S5.E6.m1.5.5.5.5.2.2.1.1a" xref="S5.E6.m1.5.5.5.5.2.2.1.1.cmml"><mrow id="S5.E6.m1.5.5.5.5.2.2.1.1.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.cmml"><mo rspace="0em" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.2.cmml">âˆ‚</mo><mrow id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.3" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.3" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.3" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.3" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E6.m1.5.5.5.5.2.2.1.1.3" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.cmml"><mo rspace="0em" id="S5.E6.m1.5.5.5.5.2.2.1.1.3.1" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.1.cmml">âˆ‚</mo><msub id="S5.E6.m1.5.5.5.5.2.2.1.1.3.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.2" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.2.cmml">W</mi><mi id="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.3" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.3.cmml">g</mi></msub></mrow></mfrac></mstyle></mrow></mrow><mo stretchy="false" id="S5.E6.m1.5.5.5.5.2.2.2.2.1.3" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><msub id="S5.E6.m1.5.5.5.5.2.2.4" xref="S5.E6.m1.5.5.5.5.2.2.4.cmml"><mi id="S5.E6.m1.5.5.5.5.2.2.4.2" xref="S5.E6.m1.5.5.5.5.2.2.4.2.cmml">N</mi><mi id="S5.E6.m1.5.5.5.5.2.2.4.3" xref="S5.E6.m1.5.5.5.5.2.2.4.3.cmml">C</mi></msub></mfrac></mrow></mtd></mtr><mtr id="S5.E6.m1.18.18.2d"><mtd id="S5.E6.m1.18.18.2e" xref="S5.E6.m1.17.17.1.1.1.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S5.E6.m1.18.18.2f"><mrow id="S5.E6.m1.18.18.2.17.12.12.12"><mrow id="S5.E6.m1.18.18.2.17.12.12.12.1"><mi id="S5.E6.m1.18.18.2.17.12.12.12.1.1" xref="S5.E6.m1.17.17.1.1.1.cmml"></mi><mo id="S5.E6.m1.6.6.6.1.1.1" xref="S5.E6.m1.6.6.6.1.1.1.cmml">=</mo><mrow id="S5.E6.m1.18.18.2.17.12.12.12.1.2"><msubsup id="S5.E6.m1.18.18.2.17.12.12.12.1.2.1"><mi id="S5.E6.m1.7.7.7.2.2.2" xref="S5.E6.m1.7.7.7.2.2.2.cmml">W</mi><mi id="S5.E6.m1.8.8.8.3.3.3.1" xref="S5.E6.m1.8.8.8.3.3.3.1.cmml">g</mi><mi id="S5.E6.m1.9.9.9.4.4.4.1" xref="S5.E6.m1.9.9.9.4.4.4.1.cmml">t</mi></msubsup><mo id="S5.E6.m1.10.10.10.5.5.5" xref="S5.E6.m1.10.10.10.5.5.5.cmml">âˆ’</mo><mrow id="S5.E6.m1.18.18.2.17.12.12.12.1.2.2"><mfrac id="S5.E6.m1.11.11.11.6.6.6" xref="S5.E6.m1.11.11.11.6.6.6.cmml"><mi id="S5.E6.m1.11.11.11.6.6.6.2" xref="S5.E6.m1.11.11.11.6.6.6.2.cmml">Î·</mi><msub id="S5.E6.m1.11.11.11.6.6.6.3" xref="S5.E6.m1.11.11.11.6.6.6.3.cmml"><mi id="S5.E6.m1.11.11.11.6.6.6.3.2" xref="S5.E6.m1.11.11.11.6.6.6.3.2.cmml">N</mi><mi id="S5.E6.m1.11.11.11.6.6.6.3.3" xref="S5.E6.m1.11.11.11.6.6.6.3.3.cmml">C</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S5.E6.m1.18.18.2.17.12.12.12.1.2.2.1" xref="S5.E6.m1.17.17.1.1.1.cmml">â€‹</mo><mrow id="S5.E6.m1.18.18.2.17.12.12.12.1.2.2.2"><munderover id="S5.E6.m1.18.18.2.17.12.12.12.1.2.2.2.1"><mo movablelimits="false" id="S5.E6.m1.12.12.12.7.7.7" xref="S5.E6.m1.12.12.12.7.7.7.cmml">âˆ‘</mo><mrow id="S5.E6.m1.13.13.13.8.8.8.1" xref="S5.E6.m1.13.13.13.8.8.8.1.cmml"><mi id="S5.E6.m1.13.13.13.8.8.8.1.2" xref="S5.E6.m1.13.13.13.8.8.8.1.2.cmml">i</mi><mo id="S5.E6.m1.13.13.13.8.8.8.1.1" xref="S5.E6.m1.13.13.13.8.8.8.1.1.cmml">=</mo><mn id="S5.E6.m1.13.13.13.8.8.8.1.3" xref="S5.E6.m1.13.13.13.8.8.8.1.3.cmml">1</mn></mrow><msub id="S5.E6.m1.14.14.14.9.9.9.1" xref="S5.E6.m1.14.14.14.9.9.9.1.cmml"><mi id="S5.E6.m1.14.14.14.9.9.9.1.2" xref="S5.E6.m1.14.14.14.9.9.9.1.2.cmml">N</mi><mi id="S5.E6.m1.14.14.14.9.9.9.1.3" xref="S5.E6.m1.14.14.14.9.9.9.1.3.cmml">C</mi></msub></munderover><mfrac id="S5.E6.m1.15.15.15.10.10.10" xref="S5.E6.m1.15.15.15.10.10.10.cmml"><mrow id="S5.E6.m1.15.15.15.10.10.10.1" xref="S5.E6.m1.15.15.15.10.10.10.1.cmml"><mo rspace="0em" id="S5.E6.m1.15.15.15.10.10.10.1.2" xref="S5.E6.m1.15.15.15.10.10.10.1.2.cmml">âˆ‚</mo><mrow id="S5.E6.m1.15.15.15.10.10.10.1.1" xref="S5.E6.m1.15.15.15.10.10.10.1.1.cmml"><mi id="S5.E6.m1.15.15.15.10.10.10.1.1.3" xref="S5.E6.m1.15.15.15.10.10.10.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.15.15.15.10.10.10.1.1.2" xref="S5.E6.m1.15.15.15.10.10.10.1.1.2.cmml">â€‹</mo><mrow id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.2" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.cmml">(</mo><mrow id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.cmml"><mi id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.3" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.2" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.2" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.2" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.3" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.3" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.3" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E6.m1.15.15.15.10.10.10.3" xref="S5.E6.m1.15.15.15.10.10.10.3.cmml"><mo rspace="0em" id="S5.E6.m1.15.15.15.10.10.10.3.1" xref="S5.E6.m1.15.15.15.10.10.10.3.1.cmml">âˆ‚</mo><msub id="S5.E6.m1.15.15.15.10.10.10.3.2" xref="S5.E6.m1.15.15.15.10.10.10.3.2.cmml"><mi id="S5.E6.m1.15.15.15.10.10.10.3.2.2" xref="S5.E6.m1.15.15.15.10.10.10.3.2.2.cmml">W</mi><mi id="S5.E6.m1.15.15.15.10.10.10.3.2.3" xref="S5.E6.m1.15.15.15.10.10.10.3.2.3.cmml">g</mi></msub></mrow></mfrac></mrow></mrow></mrow></mrow><mo id="S5.E6.m1.16.16.16.11.11.11" xref="S5.E6.m1.17.17.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S5.E6.m1.18b"><apply id="S5.E6.m1.17.17.1.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><and id="S5.E6.m1.17.17.1.1.1a.cmml" xref="S5.E6.m1.5.5.5.5.2.3"></and><apply id="S5.E6.m1.17.17.1.1.1b.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><eq id="S5.E6.m1.4.4.4.4.1.1.cmml" xref="S5.E6.m1.4.4.4.4.1.1"></eq><apply id="S5.E6.m1.17.17.1.1.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.17.17.1.1.1.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3">superscript</csymbol><apply id="S5.E6.m1.17.17.1.1.1.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.17.17.1.1.1.2.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1">ğ‘Š</ci><ci id="S5.E6.m1.2.2.2.2.2.2.1.cmml" xref="S5.E6.m1.2.2.2.2.2.2.1">ğ‘”</ci></apply><apply id="S5.E6.m1.3.3.3.3.3.3.1.cmml" xref="S5.E6.m1.3.3.3.3.3.3.1"><plus id="S5.E6.m1.3.3.3.3.3.3.1.1.cmml" xref="S5.E6.m1.3.3.3.3.3.3.1.1"></plus><ci id="S5.E6.m1.3.3.3.3.3.3.1.2.cmml" xref="S5.E6.m1.3.3.3.3.3.3.1.2">ğ‘¡</ci><cn type="integer" id="S5.E6.m1.3.3.3.3.3.3.1.3.cmml" xref="S5.E6.m1.3.3.3.3.3.3.1.3">1</cn></apply></apply><apply id="S5.E6.m1.5.5.5.5.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2"><divide id="S5.E6.m1.5.5.5.5.2.2.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2"></divide><apply id="S5.E6.m1.5.5.5.5.2.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2"><apply id="S5.E6.m1.5.5.5.5.2.2.2.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.2.3.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3">superscript</csymbol><apply id="S5.E6.m1.5.5.5.5.2.2.2.3.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.2.3.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3">subscript</csymbol><sum id="S5.E6.m1.5.5.5.5.2.2.2.3.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.2"></sum><apply id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3"><eq id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.1"></eq><ci id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.2">ğ‘–</ci><cn type="integer" id="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.2.3.3">1</cn></apply></apply><apply id="S5.E6.m1.5.5.5.5.2.2.2.3.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.3"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.2.3.3.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.3">subscript</csymbol><ci id="S5.E6.m1.5.5.5.5.2.2.2.3.3.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.3.2">ğ‘</ci><ci id="S5.E6.m1.5.5.5.5.2.2.2.3.3.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.3.3.3">ğ¶</ci></apply></apply><apply id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1"><minus id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.1"></minus><apply id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2">superscript</csymbol><apply id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2">subscript</csymbol><ci id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.2">ğ‘Š</ci><ci id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.2.3">ğ‘”</ci></apply><ci id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.2.3">ğ‘¡</ci></apply><apply id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3"><times id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.1"></times><ci id="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.2.2.1.1.3.2">ğœ‚</ci><apply id="S5.E6.m1.5.5.5.5.2.2.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1"><divide id="S5.E6.m1.5.5.5.5.2.2.1.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1"></divide><apply id="S5.E6.m1.5.5.5.5.2.2.1.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1"><partialdiff id="S5.E6.m1.5.5.5.5.2.2.1.1.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.2"></partialdiff><apply id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1"><times id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.2"></times><ci id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.3">ğ‘”</ci><apply id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1"><times id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.2"></times><ci id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.3">ğ‘“</ci><apply id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply><apply id="S5.E6.m1.5.5.5.5.2.2.1.1.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3"><partialdiff id="S5.E6.m1.5.5.5.5.2.2.1.1.3.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.1"></partialdiff><apply id="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.2">subscript</csymbol><ci id="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.2">ğ‘Š</ci><ci id="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.1.1.3.2.3">ğ‘”</ci></apply></apply></apply></apply></apply></apply><apply id="S5.E6.m1.5.5.5.5.2.2.4.cmml" xref="S5.E6.m1.5.5.5.5.2.2.4"><csymbol cd="ambiguous" id="S5.E6.m1.5.5.5.5.2.2.4.1.cmml" xref="S5.E6.m1.5.5.5.5.2.2.4">subscript</csymbol><ci id="S5.E6.m1.5.5.5.5.2.2.4.2.cmml" xref="S5.E6.m1.5.5.5.5.2.2.4.2">ğ‘</ci><ci id="S5.E6.m1.5.5.5.5.2.2.4.3.cmml" xref="S5.E6.m1.5.5.5.5.2.2.4.3">ğ¶</ci></apply></apply></apply><apply id="S5.E6.m1.17.17.1.1.1c.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><eq id="S5.E6.m1.6.6.6.1.1.1.cmml" xref="S5.E6.m1.6.6.6.1.1.1"></eq><share href="#S5.E6.m1.17.17.1.1.1.4.cmml" id="S5.E6.m1.17.17.1.1.1d.cmml" xref="S5.E6.m1.5.5.5.5.2.3"></share><apply id="S5.E6.m1.17.17.1.1.1.6.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><minus id="S5.E6.m1.10.10.10.5.5.5.cmml" xref="S5.E6.m1.10.10.10.5.5.5"></minus><apply id="S5.E6.m1.17.17.1.1.1.6.2.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.17.17.1.1.1.6.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3">superscript</csymbol><apply id="S5.E6.m1.17.17.1.1.1.6.2.2.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.17.17.1.1.1.6.2.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3">subscript</csymbol><ci id="S5.E6.m1.7.7.7.2.2.2.cmml" xref="S5.E6.m1.7.7.7.2.2.2">ğ‘Š</ci><ci id="S5.E6.m1.8.8.8.3.3.3.1.cmml" xref="S5.E6.m1.8.8.8.3.3.3.1">ğ‘”</ci></apply><ci id="S5.E6.m1.9.9.9.4.4.4.1.cmml" xref="S5.E6.m1.9.9.9.4.4.4.1">ğ‘¡</ci></apply><apply id="S5.E6.m1.17.17.1.1.1.6.3.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><times id="S5.E6.m1.17.17.1.1.1.6.3.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3"></times><apply id="S5.E6.m1.11.11.11.6.6.6.cmml" xref="S5.E6.m1.11.11.11.6.6.6"><divide id="S5.E6.m1.11.11.11.6.6.6.1.cmml" xref="S5.E6.m1.11.11.11.6.6.6"></divide><ci id="S5.E6.m1.11.11.11.6.6.6.2.cmml" xref="S5.E6.m1.11.11.11.6.6.6.2">ğœ‚</ci><apply id="S5.E6.m1.11.11.11.6.6.6.3.cmml" xref="S5.E6.m1.11.11.11.6.6.6.3"><csymbol cd="ambiguous" id="S5.E6.m1.11.11.11.6.6.6.3.1.cmml" xref="S5.E6.m1.11.11.11.6.6.6.3">subscript</csymbol><ci id="S5.E6.m1.11.11.11.6.6.6.3.2.cmml" xref="S5.E6.m1.11.11.11.6.6.6.3.2">ğ‘</ci><ci id="S5.E6.m1.11.11.11.6.6.6.3.3.cmml" xref="S5.E6.m1.11.11.11.6.6.6.3.3">ğ¶</ci></apply></apply><apply id="S5.E6.m1.17.17.1.1.1.6.3.3.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><apply id="S5.E6.m1.17.17.1.1.1.6.3.3.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.17.17.1.1.1.6.3.3.1.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3">superscript</csymbol><apply id="S5.E6.m1.17.17.1.1.1.6.3.3.1.2.cmml" xref="S5.E6.m1.5.5.5.5.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.17.17.1.1.1.6.3.3.1.2.1.cmml" xref="S5.E6.m1.5.5.5.5.2.3">subscript</csymbol><sum id="S5.E6.m1.12.12.12.7.7.7.cmml" xref="S5.E6.m1.12.12.12.7.7.7"></sum><apply id="S5.E6.m1.13.13.13.8.8.8.1.cmml" xref="S5.E6.m1.13.13.13.8.8.8.1"><eq id="S5.E6.m1.13.13.13.8.8.8.1.1.cmml" xref="S5.E6.m1.13.13.13.8.8.8.1.1"></eq><ci id="S5.E6.m1.13.13.13.8.8.8.1.2.cmml" xref="S5.E6.m1.13.13.13.8.8.8.1.2">ğ‘–</ci><cn type="integer" id="S5.E6.m1.13.13.13.8.8.8.1.3.cmml" xref="S5.E6.m1.13.13.13.8.8.8.1.3">1</cn></apply></apply><apply id="S5.E6.m1.14.14.14.9.9.9.1.cmml" xref="S5.E6.m1.14.14.14.9.9.9.1"><csymbol cd="ambiguous" id="S5.E6.m1.14.14.14.9.9.9.1.1.cmml" xref="S5.E6.m1.14.14.14.9.9.9.1">subscript</csymbol><ci id="S5.E6.m1.14.14.14.9.9.9.1.2.cmml" xref="S5.E6.m1.14.14.14.9.9.9.1.2">ğ‘</ci><ci id="S5.E6.m1.14.14.14.9.9.9.1.3.cmml" xref="S5.E6.m1.14.14.14.9.9.9.1.3">ğ¶</ci></apply></apply><apply id="S5.E6.m1.15.15.15.10.10.10.cmml" xref="S5.E6.m1.15.15.15.10.10.10"><divide id="S5.E6.m1.15.15.15.10.10.10.2.cmml" xref="S5.E6.m1.15.15.15.10.10.10"></divide><apply id="S5.E6.m1.15.15.15.10.10.10.1.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1"><partialdiff id="S5.E6.m1.15.15.15.10.10.10.1.2.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.2"></partialdiff><apply id="S5.E6.m1.15.15.15.10.10.10.1.1.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1"><times id="S5.E6.m1.15.15.15.10.10.10.1.1.2.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.2"></times><ci id="S5.E6.m1.15.15.15.10.10.10.1.1.3.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.3">ğ‘”</ci><apply id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1"><times id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.2.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.2"></times><ci id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.3.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.3">ğ‘“</ci><apply id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E6.m1.15.15.15.10.10.10.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply><apply id="S5.E6.m1.15.15.15.10.10.10.3.cmml" xref="S5.E6.m1.15.15.15.10.10.10.3"><partialdiff id="S5.E6.m1.15.15.15.10.10.10.3.1.cmml" xref="S5.E6.m1.15.15.15.10.10.10.3.1"></partialdiff><apply id="S5.E6.m1.15.15.15.10.10.10.3.2.cmml" xref="S5.E6.m1.15.15.15.10.10.10.3.2"><csymbol cd="ambiguous" id="S5.E6.m1.15.15.15.10.10.10.3.2.1.cmml" xref="S5.E6.m1.15.15.15.10.10.10.3.2">subscript</csymbol><ci id="S5.E6.m1.15.15.15.10.10.10.3.2.2.cmml" xref="S5.E6.m1.15.15.15.10.10.10.3.2.2">ğ‘Š</ci><ci id="S5.E6.m1.15.15.15.10.10.10.3.2.3.cmml" xref="S5.E6.m1.15.15.15.10.10.10.3.2.3">ğ‘”</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E6.m1.18c">\begin{split}W_{g}^{t+1}&amp;=\frac{\sum_{i=1}^{N_{C}}(W_{g}^{t}-\eta\dfrac{\partial g(f(x_{i}))}{\partial W_{g}})}{N_{C}}\\
&amp;=W_{g}^{t}-\frac{\eta}{N_{C}}\sum_{i=1}^{N_{C}}\dfrac{\partial g(f(x_{i}))}{\partial W_{g}},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S5.SS3.SSS5.p6.7" class="ltx_p">where <math id="S5.SS3.SSS5.p6.1.m1.1" class="ltx_Math" alttext="W_{g}^{t}" display="inline"><semantics id="S5.SS3.SSS5.p6.1.m1.1a"><msubsup id="S5.SS3.SSS5.p6.1.m1.1.1" xref="S5.SS3.SSS5.p6.1.m1.1.1.cmml"><mi id="S5.SS3.SSS5.p6.1.m1.1.1.2.2" xref="S5.SS3.SSS5.p6.1.m1.1.1.2.2.cmml">W</mi><mi id="S5.SS3.SSS5.p6.1.m1.1.1.2.3" xref="S5.SS3.SSS5.p6.1.m1.1.1.2.3.cmml">g</mi><mi id="S5.SS3.SSS5.p6.1.m1.1.1.3" xref="S5.SS3.SSS5.p6.1.m1.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p6.1.m1.1b"><apply id="S5.SS3.SSS5.p6.1.m1.1.1.cmml" xref="S5.SS3.SSS5.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS5.p6.1.m1.1.1.1.cmml" xref="S5.SS3.SSS5.p6.1.m1.1.1">superscript</csymbol><apply id="S5.SS3.SSS5.p6.1.m1.1.1.2.cmml" xref="S5.SS3.SSS5.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS5.p6.1.m1.1.1.2.1.cmml" xref="S5.SS3.SSS5.p6.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.SSS5.p6.1.m1.1.1.2.2.cmml" xref="S5.SS3.SSS5.p6.1.m1.1.1.2.2">ğ‘Š</ci><ci id="S5.SS3.SSS5.p6.1.m1.1.1.2.3.cmml" xref="S5.SS3.SSS5.p6.1.m1.1.1.2.3">ğ‘”</ci></apply><ci id="S5.SS3.SSS5.p6.1.m1.1.1.3.cmml" xref="S5.SS3.SSS5.p6.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p6.1.m1.1c">W_{g}^{t}</annotation></semantics></math> indicates the weights in the server at iteration <math id="S5.SS3.SSS5.p6.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.SS3.SSS5.p6.2.m2.1a"><mi id="S5.SS3.SSS5.p6.2.m2.1.1" xref="S5.SS3.SSS5.p6.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p6.2.m2.1b"><ci id="S5.SS3.SSS5.p6.2.m2.1.1.cmml" xref="S5.SS3.SSS5.p6.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p6.2.m2.1c">t</annotation></semantics></math>, <math id="S5.SS3.SSS5.p6.3.m3.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S5.SS3.SSS5.p6.3.m3.1a"><mi id="S5.SS3.SSS5.p6.3.m3.1.1" xref="S5.SS3.SSS5.p6.3.m3.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p6.3.m3.1b"><ci id="S5.SS3.SSS5.p6.3.m3.1.1.cmml" xref="S5.SS3.SSS5.p6.3.m3.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p6.3.m3.1c">g</annotation></semantics></math> is the server NN, <math id="S5.SS3.SSS5.p6.4.m4.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.SS3.SSS5.p6.4.m4.1a"><mi id="S5.SS3.SSS5.p6.4.m4.1.1" xref="S5.SS3.SSS5.p6.4.m4.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p6.4.m4.1b"><ci id="S5.SS3.SSS5.p6.4.m4.1.1.cmml" xref="S5.SS3.SSS5.p6.4.m4.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p6.4.m4.1c">f</annotation></semantics></math> is the client NN, <math id="S5.SS3.SSS5.p6.5.m5.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S5.SS3.SSS5.p6.5.m5.1a"><msub id="S5.SS3.SSS5.p6.5.m5.1.1" xref="S5.SS3.SSS5.p6.5.m5.1.1.cmml"><mi id="S5.SS3.SSS5.p6.5.m5.1.1.2" xref="S5.SS3.SSS5.p6.5.m5.1.1.2.cmml">x</mi><mi id="S5.SS3.SSS5.p6.5.m5.1.1.3" xref="S5.SS3.SSS5.p6.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p6.5.m5.1b"><apply id="S5.SS3.SSS5.p6.5.m5.1.1.cmml" xref="S5.SS3.SSS5.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS5.p6.5.m5.1.1.1.cmml" xref="S5.SS3.SSS5.p6.5.m5.1.1">subscript</csymbol><ci id="S5.SS3.SSS5.p6.5.m5.1.1.2.cmml" xref="S5.SS3.SSS5.p6.5.m5.1.1.2">ğ‘¥</ci><ci id="S5.SS3.SSS5.p6.5.m5.1.1.3.cmml" xref="S5.SS3.SSS5.p6.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p6.5.m5.1c">x_{i}</annotation></semantics></math> represent the i-th batch of data, <math id="S5.SS3.SSS5.p6.6.m6.1" class="ltx_Math" alttext="N_{C}" display="inline"><semantics id="S5.SS3.SSS5.p6.6.m6.1a"><msub id="S5.SS3.SSS5.p6.6.m6.1.1" xref="S5.SS3.SSS5.p6.6.m6.1.1.cmml"><mi id="S5.SS3.SSS5.p6.6.m6.1.1.2" xref="S5.SS3.SSS5.p6.6.m6.1.1.2.cmml">N</mi><mi id="S5.SS3.SSS5.p6.6.m6.1.1.3" xref="S5.SS3.SSS5.p6.6.m6.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p6.6.m6.1b"><apply id="S5.SS3.SSS5.p6.6.m6.1.1.cmml" xref="S5.SS3.SSS5.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS5.p6.6.m6.1.1.1.cmml" xref="S5.SS3.SSS5.p6.6.m6.1.1">subscript</csymbol><ci id="S5.SS3.SSS5.p6.6.m6.1.1.2.cmml" xref="S5.SS3.SSS5.p6.6.m6.1.1.2">ğ‘</ci><ci id="S5.SS3.SSS5.p6.6.m6.1.1.3.cmml" xref="S5.SS3.SSS5.p6.6.m6.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p6.6.m6.1c">N_{C}</annotation></semantics></math> is the number of clients, and <math id="S5.SS3.SSS5.p6.7.m7.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S5.SS3.SSS5.p6.7.m7.1a"><mi id="S5.SS3.SSS5.p6.7.m7.1.1" xref="S5.SS3.SSS5.p6.7.m7.1.1.cmml">Î·</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p6.7.m7.1b"><ci id="S5.SS3.SSS5.p6.7.m7.1.1.cmml" xref="S5.SS3.SSS5.p6.7.m7.1.1">ğœ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p6.7.m7.1c">\eta</annotation></semantics></math> is the step size.
Intuitively, since PSL has a larger step size, its server NN can be confused quicker than FSL servers by the intermediate data.
Moreover, the confused server NN can further confuse the client NN.
It justifies our observation that PSLâ€™s accuracy and attack resilience become unstable quickly when increasing the <span id="S5.SS3.SSS5.p6.7.1" class="ltx_text ltx_font_italic">DC FrequencyÂ (F)</span>. Therefore, we conclude that <span id="S5.SS3.SSS5.p6.7.2" class="ltx_text ltx_font_italic">FSL is easier to tune compared to PSL.</span></p>
</div>
<div id="S5.SS3.SSS5.p7" class="ltx_para">
<p id="S5.SS3.SSS5.p7.1" class="ltx_p"><span id="S5.SS3.SSS5.p7.1.1" class="ltx_text" style="color:#000000;">In FiguresÂ <a href="#S5.F7.sf2" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(b)</span></a> andÂ <a href="#S5.F7.sf4" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(d)</span></a>,
with a fixed <span id="S5.SS3.SSS5.p7.1.1.1" class="ltx_text ltx_font_italic">DC FrequencyÂ (F)</span>, we show the accuracy (left y-axis) and attack resilience (right y-axis) based on different  <span id="S5.SS3.SSS5.p7.1.1.2" class="ltx_text ltx_font_italic">Loss MultiplierÂ (m)</span>  for different models and datasets.</span>
Furthermore, we compared the privacy oblivious cases (FigureÂ <a href="#S5.F7.sf1" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a> and FigureÂ <a href="#S5.F7.sf3" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(c)</span></a>), and the privacy aware cases at different Cut Indexes (x-axis).
<span id="S5.SS3.SSS5.p7.1.2" class="ltx_text" style="color:#000000;"> As expected, increasing the <span id="S5.SS3.SSS5.p7.1.2.1" class="ltx_text ltx_font_italic">Loss MultiplierÂ (m)</span> enhances attack resilience but reduces accuracy, especially when the client NN is deep.</span></p>
</div>
<div id="S5.SS3.SSS5.p8" class="ltx_para">
<p id="S5.SS3.SSS5.p8.1" class="ltx_p"><span id="S5.SS3.SSS5.p8.1.1" class="ltx_text" style="color:#000000;">Overall our evaluation of CPA-DC shows good attack resilience and accuracy with a combination of small <span id="S5.SS3.SSS5.p8.1.1.1" class="ltx_text ltx_font_italic">DC FrequencyÂ (F)</span> and big <span id="S5.SS3.SSS5.p8.1.1.2" class="ltx_text ltx_font_italic">Loss MultiplierÂ (m)</span>.
And our FSL has better accuracy and similar attack resilience to PSL.
We hence conclude that our CPA-DC can defend against our attacker model.</span></p>
</div>
<figure id="S5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/figures/performance/2_square_Client-Based_Approach_DC_Loss_in_Client_Params_Summary_Train_Wide_UP.png" id="S5.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="178" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F8.sf1.3.2" class="ltx_text" style="font-size:90%;">CPA-DC (Multiplier=0.1)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x25.png" id="S5.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="138" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F8.sf2.3.2" class="ltx_text" style="font-size:90%;">CPA-DP</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2301.01824/assets/x26.png" id="S5.F8.sf3.g1" class="ltx_graphics ltx_img_landscape" width="664" height="200" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F8.sf3.3.2" class="ltx_text" style="font-size:90%;">DP-SGD in Complete NN</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.4.2.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S5.F8.2.1" class="ltx_text" style="font-size:90%;">LeNet+MNIST: Learner accuracy and
attack resilience (<math id="S5.F8.2.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S5.F8.2.1.m1.1b"><mi id="S5.F8.2.1.m1.1.1" xref="S5.F8.2.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S5.F8.2.1.m1.1c"><ci id="S5.F8.2.1.m1.1.1.cmml" xref="S5.F8.2.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.2.1.m1.1d">\tau</annotation></semantics></math>) with 20 clients and Cut Index of 3 for Client-Based Privacy Approaches (via DC (a) and via DP (b)) and DP-SGD on the global learner model (c). Our FSL with both client-based policies guarantee high-level of privacy and accuracy.</span></figcaption>
</figure>
</section>
<section id="S5.SS3.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.6 </span>Privacy Evaluation with Differential Privacy Approach</h4>

<div id="S5.SS3.SSS6.p1" class="ltx_para">
<p id="S5.SS3.SSS6.p1.2" class="ltx_p"><span id="S5.SS3.SSS6.p1.2.2" class="ltx_text" style="color:#000000;">The previous section has discussed the CPA-DC, but instead of DC there are other lightweight methods that can
enhance the privacy guarantee which adds noise to the client NN while prevent depleting the client battery quickly.
In this section, we compare CPA-DP (using the popular DP-SGDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> algorithm inside clients) and CPA-DC.
Also, we show that naÃ¯vely using DP-SGD in an FSL system would lead to low accuracy.
The implementation extends POFSL with a DP-SGD optimizer, provided by the OpacusÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> library.
This method would add normally distributed random noise to the gradients during backward propagation based on <math id="S5.SS3.SSS6.p1.1.1.m1.1" class="ltx_Math" alttext="noise\_multiplier" display="inline"><semantics id="S5.SS3.SSS6.p1.1.1.m1.1a"><mrow id="S5.SS3.SSS6.p1.1.1.m1.1.1" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.2" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.3" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1a" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.4" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1b" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.5" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1c" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.6" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1d" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" mathvariant="normal" id="S5.SS3.SSS6.p1.1.1.m1.1.1.7" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1e" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.8" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1f" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.9" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1g" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.10" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1h" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.11" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1i" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.12" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1j" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.13" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1k" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.14" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1l" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.15" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1m" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.16" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p1.1.1.m1.1.1.1n" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.1.1.m1.1.1.17" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.17.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p1.1.1.m1.1b"><apply id="S5.SS3.SSS6.p1.1.1.m1.1.1.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1"><times id="S5.SS3.SSS6.p1.1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.1"></times><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.3.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.4.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.5.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.6.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.7.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.7">_</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.8.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.9.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.10.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.11.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.12.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.13.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.13">ğ‘</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.14.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.15.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.16.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p1.1.1.m1.1.1.17.cmml" xref="S5.SS3.SSS6.p1.1.1.m1.1.1.17">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p1.1.1.m1.1c">noise\_multiplier</annotation></semantics></math> <math id="S5.SS3.SSS6.p1.2.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.SS3.SSS6.p1.2.2.m2.1a"><mi mathcolor="#000000" id="S5.SS3.SSS6.p1.2.2.m2.1.1" xref="S5.SS3.SSS6.p1.2.2.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p1.2.2.m2.1b"><ci id="S5.SS3.SSS6.p1.2.2.m2.1.1.cmml" xref="S5.SS3.SSS6.p1.2.2.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p1.2.2.m2.1c">\epsilon</annotation></semantics></math>.
This parameter controls the magnitude of the noise added.
Notice that DC generates the gradients in a specific direction to reduce correlation between intermediate data and source data in each <span id="S5.SS3.SSS6.p1.2.2.1" class="ltx_text ltx_font_italic">Distance Correlation round</span>.
So we expect CPA-DP to have a worse level of privacy, given the same level of learner accuracy, compared to CPA-DC.
Thus, the focus of this section is to show that CPA can be applied with other privacy methods like DP, despite DPâ€™s worse privacy compared to DC.
</span></p>
</div>
<div id="S5.SS3.SSS6.p2" class="ltx_para">
<p id="S5.SS3.SSS6.p2.7" class="ltx_p">We summarize the results of CPA-DP in Fig.Â <a href="#S5.F8.sf2" title="In Figure 8 â€£ 5.3.5 Evaluation Result using Client-Based Privacy Approach via Distance Correlation â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>.
This plot shows the result when Cut Index equals 3.
The x-axis is the <math id="S5.SS3.SSS6.p2.1.m1.1" class="ltx_Math" alttext="noise\_multiplier" display="inline"><semantics id="S5.SS3.SSS6.p2.1.m1.1a"><mrow id="S5.SS3.SSS6.p2.1.m1.1.1" xref="S5.SS3.SSS6.p2.1.m1.1.1.cmml"><mi id="S5.SS3.SSS6.p2.1.m1.1.1.2" xref="S5.SS3.SSS6.p2.1.m1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.3" xref="S5.SS3.SSS6.p2.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1a" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.4" xref="S5.SS3.SSS6.p2.1.m1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1b" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.5" xref="S5.SS3.SSS6.p2.1.m1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1c" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.6" xref="S5.SS3.SSS6.p2.1.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1d" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS6.p2.1.m1.1.1.7" xref="S5.SS3.SSS6.p2.1.m1.1.1.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1e" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.8" xref="S5.SS3.SSS6.p2.1.m1.1.1.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1f" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.9" xref="S5.SS3.SSS6.p2.1.m1.1.1.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1g" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.10" xref="S5.SS3.SSS6.p2.1.m1.1.1.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1h" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.11" xref="S5.SS3.SSS6.p2.1.m1.1.1.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1i" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.12" xref="S5.SS3.SSS6.p2.1.m1.1.1.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1j" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.13" xref="S5.SS3.SSS6.p2.1.m1.1.1.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1k" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.14" xref="S5.SS3.SSS6.p2.1.m1.1.1.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1l" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.15" xref="S5.SS3.SSS6.p2.1.m1.1.1.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1m" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.16" xref="S5.SS3.SSS6.p2.1.m1.1.1.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.1.m1.1.1.1n" xref="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.1.m1.1.1.17" xref="S5.SS3.SSS6.p2.1.m1.1.1.17.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p2.1.m1.1b"><apply id="S5.SS3.SSS6.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1"><times id="S5.SS3.SSS6.p2.1.m1.1.1.1.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.1"></times><ci id="S5.SS3.SSS6.p2.1.m1.1.1.2.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.3.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.4.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.5.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.6.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.7.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.7">_</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.8.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.9.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.10.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.11.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.12.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.13.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.13">ğ‘</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.14.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.15.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.16.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.1.m1.1.1.17.cmml" xref="S5.SS3.SSS6.p2.1.m1.1.1.17">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p2.1.m1.1c">noise\_multiplier</annotation></semantics></math>.
<span id="S5.SS3.SSS6.p2.4.3" class="ltx_text" style="color:#000000;"> The attack resiliency of FSL and PSL with <math id="S5.SS3.SSS6.p2.2.1.m1.1" class="ltx_Math" alttext="noise\_multiplier&gt;0" display="inline"><semantics id="S5.SS3.SSS6.p2.2.1.m1.1a"><mrow id="S5.SS3.SSS6.p2.2.1.m1.1.1" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.cmml"><mrow id="S5.SS3.SSS6.p2.2.1.m1.1.1.2" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.cmml"><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.2" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.3" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1a" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.4" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1b" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.5" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1c" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.6" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1d" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" mathvariant="normal" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.7" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1e" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.8" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1f" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.9" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1g" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.10" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1h" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.11" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1i" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.12" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1j" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.13" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1k" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.14" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1l" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.15" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1m" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.16" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1n" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.17" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.17.cmml">r</mi></mrow><mo mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.1" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.1.cmml">&gt;</mo><mn mathcolor="#000000" id="S5.SS3.SSS6.p2.2.1.m1.1.1.3" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p2.2.1.m1.1b"><apply id="S5.SS3.SSS6.p2.2.1.m1.1.1.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1"><gt id="S5.SS3.SSS6.p2.2.1.m1.1.1.1.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.1"></gt><apply id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2"><times id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.1"></times><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.2.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.3.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.4.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.5.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.6.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.7.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.7">_</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.8.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.9.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.10.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.11.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.12.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.13.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.13">ğ‘</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.14.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.15.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.16.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.2.1.m1.1.1.2.17.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.2.17">ğ‘Ÿ</ci></apply><cn type="integer" id="S5.SS3.SSS6.p2.2.1.m1.1.1.3.cmml" xref="S5.SS3.SSS6.p2.2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p2.2.1.m1.1c">noise\_multiplier&gt;0</annotation></semantics></math> is consistently better by nearly <math id="S5.SS3.SSS6.p2.3.2.m2.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S5.SS3.SSS6.p2.3.2.m2.1a"><mrow id="S5.SS3.SSS6.p2.3.2.m2.1.1" xref="S5.SS3.SSS6.p2.3.2.m2.1.1.cmml"><mn mathcolor="#000000" id="S5.SS3.SSS6.p2.3.2.m2.1.1.2" xref="S5.SS3.SSS6.p2.3.2.m2.1.1.2.cmml">5</mn><mo mathcolor="#000000" id="S5.SS3.SSS6.p2.3.2.m2.1.1.1" xref="S5.SS3.SSS6.p2.3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p2.3.2.m2.1b"><apply id="S5.SS3.SSS6.p2.3.2.m2.1.1.cmml" xref="S5.SS3.SSS6.p2.3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS3.SSS6.p2.3.2.m2.1.1.1.cmml" xref="S5.SS3.SSS6.p2.3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS6.p2.3.2.m2.1.1.2.cmml" xref="S5.SS3.SSS6.p2.3.2.m2.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p2.3.2.m2.1c">5\%</annotation></semantics></math> than FSL and PSL with <math id="S5.SS3.SSS6.p2.4.3.m3.1" class="ltx_Math" alttext="noise\_multiplier=0" display="inline"><semantics id="S5.SS3.SSS6.p2.4.3.m3.1a"><mrow id="S5.SS3.SSS6.p2.4.3.m3.1.1" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.cmml"><mrow id="S5.SS3.SSS6.p2.4.3.m3.1.1.2" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.cmml"><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.2" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.3" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1a" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.4" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1b" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.5" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1c" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.6" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1d" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" mathvariant="normal" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.7" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1e" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.8" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1f" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.9" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1g" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.10" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1h" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.11" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1i" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.12" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1j" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.13" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1k" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.14" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1l" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.15" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1m" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.16" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1n" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.17" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.17.cmml">r</mi></mrow><mo mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.1" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.1.cmml">=</mo><mn mathcolor="#000000" id="S5.SS3.SSS6.p2.4.3.m3.1.1.3" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p2.4.3.m3.1b"><apply id="S5.SS3.SSS6.p2.4.3.m3.1.1.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1"><eq id="S5.SS3.SSS6.p2.4.3.m3.1.1.1.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.1"></eq><apply id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2"><times id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.1"></times><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.2.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.3.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.4.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.5.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.6.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.7.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.7">_</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.8.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.9.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.10.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.11.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.12.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.13.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.13">ğ‘</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.14.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.15.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.16.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.4.3.m3.1.1.2.17.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.2.17">ğ‘Ÿ</ci></apply><cn type="integer" id="S5.SS3.SSS6.p2.4.3.m3.1.1.3.cmml" xref="S5.SS3.SSS6.p2.4.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p2.4.3.m3.1c">noise\_multiplier=0</annotation></semantics></math>.</span>
At the same time, the accuracy decreases by less than <math id="S5.SS3.SSS6.p2.5.m2.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S5.SS3.SSS6.p2.5.m2.1a"><mrow id="S5.SS3.SSS6.p2.5.m2.1.1" xref="S5.SS3.SSS6.p2.5.m2.1.1.cmml"><mn id="S5.SS3.SSS6.p2.5.m2.1.1.2" xref="S5.SS3.SSS6.p2.5.m2.1.1.2.cmml">1</mn><mo id="S5.SS3.SSS6.p2.5.m2.1.1.1" xref="S5.SS3.SSS6.p2.5.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p2.5.m2.1b"><apply id="S5.SS3.SSS6.p2.5.m2.1.1.cmml" xref="S5.SS3.SSS6.p2.5.m2.1.1"><csymbol cd="latexml" id="S5.SS3.SSS6.p2.5.m2.1.1.1.cmml" xref="S5.SS3.SSS6.p2.5.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS6.p2.5.m2.1.1.2.cmml" xref="S5.SS3.SSS6.p2.5.m2.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p2.5.m2.1c">1\%</annotation></semantics></math> in either FSL or PSL from <math id="S5.SS3.SSS6.p2.6.m3.1" class="ltx_Math" alttext="noise\_multiplier=0" display="inline"><semantics id="S5.SS3.SSS6.p2.6.m3.1a"><mrow id="S5.SS3.SSS6.p2.6.m3.1.1" xref="S5.SS3.SSS6.p2.6.m3.1.1.cmml"><mrow id="S5.SS3.SSS6.p2.6.m3.1.1.2" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.cmml"><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.2" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.3" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1a" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.4" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1b" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.5" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1c" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.6" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1d" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS6.p2.6.m3.1.1.2.7" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1e" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.8" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1f" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.9" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1g" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.10" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1h" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.11" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1i" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.12" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1j" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.13" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1k" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.14" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1l" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.15" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1m" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.16" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.6.m3.1.1.2.1n" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.6.m3.1.1.2.17" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.17.cmml">r</mi></mrow><mo id="S5.SS3.SSS6.p2.6.m3.1.1.1" xref="S5.SS3.SSS6.p2.6.m3.1.1.1.cmml">=</mo><mn id="S5.SS3.SSS6.p2.6.m3.1.1.3" xref="S5.SS3.SSS6.p2.6.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p2.6.m3.1b"><apply id="S5.SS3.SSS6.p2.6.m3.1.1.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1"><eq id="S5.SS3.SSS6.p2.6.m3.1.1.1.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.1"></eq><apply id="S5.SS3.SSS6.p2.6.m3.1.1.2.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2"><times id="S5.SS3.SSS6.p2.6.m3.1.1.2.1.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.1"></times><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.2.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.3.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.4.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.5.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.6.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.7.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.7">_</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.8.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.9.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.10.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.11.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.12.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.13.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.13">ğ‘</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.14.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.15.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.16.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.6.m3.1.1.2.17.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.2.17">ğ‘Ÿ</ci></apply><cn type="integer" id="S5.SS3.SSS6.p2.6.m3.1.1.3.cmml" xref="S5.SS3.SSS6.p2.6.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p2.6.m3.1c">noise\_multiplier=0</annotation></semantics></math> to <math id="S5.SS3.SSS6.p2.7.m4.1" class="ltx_Math" alttext="noise\_multiplier=4" display="inline"><semantics id="S5.SS3.SSS6.p2.7.m4.1a"><mrow id="S5.SS3.SSS6.p2.7.m4.1.1" xref="S5.SS3.SSS6.p2.7.m4.1.1.cmml"><mrow id="S5.SS3.SSS6.p2.7.m4.1.1.2" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.cmml"><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.2" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.3" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1a" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.4" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1b" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.5" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1c" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.6" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1d" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS6.p2.7.m4.1.1.2.7" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1e" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.8" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1f" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.9" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1g" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.10" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1h" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.11" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1i" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.12" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1j" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.13" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1k" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.14" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1l" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.15" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1m" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.16" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p2.7.m4.1.1.2.1n" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p2.7.m4.1.1.2.17" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.17.cmml">r</mi></mrow><mo id="S5.SS3.SSS6.p2.7.m4.1.1.1" xref="S5.SS3.SSS6.p2.7.m4.1.1.1.cmml">=</mo><mn id="S5.SS3.SSS6.p2.7.m4.1.1.3" xref="S5.SS3.SSS6.p2.7.m4.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p2.7.m4.1b"><apply id="S5.SS3.SSS6.p2.7.m4.1.1.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1"><eq id="S5.SS3.SSS6.p2.7.m4.1.1.1.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.1"></eq><apply id="S5.SS3.SSS6.p2.7.m4.1.1.2.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2"><times id="S5.SS3.SSS6.p2.7.m4.1.1.2.1.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.1"></times><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.2.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.3.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.4.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.5.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.6.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.7.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.7">_</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.8.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.9.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.10.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.11.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.12.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.13.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.13">ğ‘</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.14.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.15.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.16.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p2.7.m4.1.1.2.17.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.2.17">ğ‘Ÿ</ci></apply><cn type="integer" id="S5.SS3.SSS6.p2.7.m4.1.1.3.cmml" xref="S5.SS3.SSS6.p2.7.m4.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p2.7.m4.1c">noise\_multiplier=4</annotation></semantics></math>.</p>
</div>
<div id="S5.SS3.SSS6.p3" class="ltx_para">
<p id="S5.SS3.SSS6.p3.1" class="ltx_p"><span id="S5.SS3.SSS6.p3.1.1" class="ltx_text ltx_font_bold">CPA is a general approach and can be customized with different methods to enhance attack resilience.</span> The evaluation shows that CPA-DP can also improve attack resilience, while the learner accuracy does not change much.
Comparing with CPA-DC, both methods provide similar learner accuracy, but CPA-DCâ€™s attack resilience is higher.
</p>
</div>
<div id="S5.SS3.SSS6.p4" class="ltx_para">
<p id="S5.SS3.SSS6.p4.2" class="ltx_p">We now compare CPA-DP against applying DP-SGD in both client NN and server NN.
FigureÂ <a href="#S5.F8.sf3" title="In Figure 8 â€£ 5.3.5 Evaluation Result using Client-Based Privacy Approach via Distance Correlation â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(c)</span></a> shows high attack resilience, but the learner accuracy of FSL drops below <math id="S5.SS3.SSS6.p4.1.m1.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S5.SS3.SSS6.p4.1.m1.1a"><mrow id="S5.SS3.SSS6.p4.1.m1.1.1" xref="S5.SS3.SSS6.p4.1.m1.1.1.cmml"><mn id="S5.SS3.SSS6.p4.1.m1.1.1.2" xref="S5.SS3.SSS6.p4.1.m1.1.1.2.cmml">60</mn><mo id="S5.SS3.SSS6.p4.1.m1.1.1.1" xref="S5.SS3.SSS6.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p4.1.m1.1b"><apply id="S5.SS3.SSS6.p4.1.m1.1.1.cmml" xref="S5.SS3.SSS6.p4.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.SSS6.p4.1.m1.1.1.1.cmml" xref="S5.SS3.SSS6.p4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS6.p4.1.m1.1.1.2.cmml" xref="S5.SS3.SSS6.p4.1.m1.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p4.1.m1.1c">60\%</annotation></semantics></math> when <math id="S5.SS3.SSS6.p4.2.m2.1" class="ltx_Math" alttext="noise\_multiplier\geq 0.3" display="inline"><semantics id="S5.SS3.SSS6.p4.2.m2.1a"><mrow id="S5.SS3.SSS6.p4.2.m2.1.1" xref="S5.SS3.SSS6.p4.2.m2.1.1.cmml"><mrow id="S5.SS3.SSS6.p4.2.m2.1.1.2" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.cmml"><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.2" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.3" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1a" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.4" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1b" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.5" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1c" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.6" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1d" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS6.p4.2.m2.1.1.2.7" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1e" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.8" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1f" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.9" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1g" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.10" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1h" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.11" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1i" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.12" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1j" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.13" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1k" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.14" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1l" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.15" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1m" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.16" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p4.2.m2.1.1.2.1n" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p4.2.m2.1.1.2.17" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.17.cmml">r</mi></mrow><mo id="S5.SS3.SSS6.p4.2.m2.1.1.1" xref="S5.SS3.SSS6.p4.2.m2.1.1.1.cmml">â‰¥</mo><mn id="S5.SS3.SSS6.p4.2.m2.1.1.3" xref="S5.SS3.SSS6.p4.2.m2.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p4.2.m2.1b"><apply id="S5.SS3.SSS6.p4.2.m2.1.1.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1"><geq id="S5.SS3.SSS6.p4.2.m2.1.1.1.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.1"></geq><apply id="S5.SS3.SSS6.p4.2.m2.1.1.2.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2"><times id="S5.SS3.SSS6.p4.2.m2.1.1.2.1.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.1"></times><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.2.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.3.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.4.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.5.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.6.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.7.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.7">_</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.8.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.9.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.10.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.11.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.12.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.13.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.13">ğ‘</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.14.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.15.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.16.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p4.2.m2.1.1.2.17.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.2.17">ğ‘Ÿ</ci></apply><cn type="float" id="S5.SS3.SSS6.p4.2.m2.1.1.3.cmml" xref="S5.SS3.SSS6.p4.2.m2.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p4.2.m2.1c">noise\_multiplier\geq 0.3</annotation></semantics></math>.
Meanwhile, PSL shows a similar behavior as using CPA-DP.
So, CPA-DP is considered a better method for FSL to enhance its attack resilience than with DP-SGD applied in both clients and servers.
The reason for FSLâ€™s lower accuracy under DP-SGD and high noise can be attributed
to its SerAVG.
After applying SerAVG, the distribution of the random noise in the server NN can be arbitrary, as shown in E.q., <a href="#S5.E7" title="In 5.3.6 Privacy Evaluation with Differential Privacy Approach â€£ 5.3 Evaluation Results for Privacy-Aware FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, while the noise in the client NN stays intact.
Thus, the resulting complete NN in FSL may not converge.</p>
<table id="S5.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E7.m1.2" class="ltx_Math" alttext="W_{g}^{t+1}=W_{g}^{t}-\frac{\eta}{N_{C}}\sum_{i=1}^{N_{C}}(\dfrac{\partial g(f(x_{i}))}{\partial W_{g}}+e_{g_{i}}^{t})" display="block"><semantics id="S5.E7.m1.2a"><mrow id="S5.E7.m1.2.2" xref="S5.E7.m1.2.2.cmml"><msubsup id="S5.E7.m1.2.2.3" xref="S5.E7.m1.2.2.3.cmml"><mi id="S5.E7.m1.2.2.3.2.2" xref="S5.E7.m1.2.2.3.2.2.cmml">W</mi><mi id="S5.E7.m1.2.2.3.2.3" xref="S5.E7.m1.2.2.3.2.3.cmml">g</mi><mrow id="S5.E7.m1.2.2.3.3" xref="S5.E7.m1.2.2.3.3.cmml"><mi id="S5.E7.m1.2.2.3.3.2" xref="S5.E7.m1.2.2.3.3.2.cmml">t</mi><mo id="S5.E7.m1.2.2.3.3.1" xref="S5.E7.m1.2.2.3.3.1.cmml">+</mo><mn id="S5.E7.m1.2.2.3.3.3" xref="S5.E7.m1.2.2.3.3.3.cmml">1</mn></mrow></msubsup><mo id="S5.E7.m1.2.2.2" xref="S5.E7.m1.2.2.2.cmml">=</mo><mrow id="S5.E7.m1.2.2.1" xref="S5.E7.m1.2.2.1.cmml"><msubsup id="S5.E7.m1.2.2.1.3" xref="S5.E7.m1.2.2.1.3.cmml"><mi id="S5.E7.m1.2.2.1.3.2.2" xref="S5.E7.m1.2.2.1.3.2.2.cmml">W</mi><mi id="S5.E7.m1.2.2.1.3.2.3" xref="S5.E7.m1.2.2.1.3.2.3.cmml">g</mi><mi id="S5.E7.m1.2.2.1.3.3" xref="S5.E7.m1.2.2.1.3.3.cmml">t</mi></msubsup><mo id="S5.E7.m1.2.2.1.2" xref="S5.E7.m1.2.2.1.2.cmml">âˆ’</mo><mrow id="S5.E7.m1.2.2.1.1" xref="S5.E7.m1.2.2.1.1.cmml"><mfrac id="S5.E7.m1.2.2.1.1.3" xref="S5.E7.m1.2.2.1.1.3.cmml"><mi id="S5.E7.m1.2.2.1.1.3.2" xref="S5.E7.m1.2.2.1.1.3.2.cmml">Î·</mi><msub id="S5.E7.m1.2.2.1.1.3.3" xref="S5.E7.m1.2.2.1.1.3.3.cmml"><mi id="S5.E7.m1.2.2.1.1.3.3.2" xref="S5.E7.m1.2.2.1.1.3.3.2.cmml">N</mi><mi id="S5.E7.m1.2.2.1.1.3.3.3" xref="S5.E7.m1.2.2.1.1.3.3.3.cmml">C</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S5.E7.m1.2.2.1.1.2" xref="S5.E7.m1.2.2.1.1.2.cmml">â€‹</mo><mrow id="S5.E7.m1.2.2.1.1.1" xref="S5.E7.m1.2.2.1.1.1.cmml"><munderover id="S5.E7.m1.2.2.1.1.1.2" xref="S5.E7.m1.2.2.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S5.E7.m1.2.2.1.1.1.2.2.2" xref="S5.E7.m1.2.2.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S5.E7.m1.2.2.1.1.1.2.2.3" xref="S5.E7.m1.2.2.1.1.1.2.2.3.cmml"><mi id="S5.E7.m1.2.2.1.1.1.2.2.3.2" xref="S5.E7.m1.2.2.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E7.m1.2.2.1.1.1.2.2.3.1" xref="S5.E7.m1.2.2.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E7.m1.2.2.1.1.1.2.2.3.3" xref="S5.E7.m1.2.2.1.1.1.2.2.3.3.cmml">1</mn></mrow><msub id="S5.E7.m1.2.2.1.1.1.2.3" xref="S5.E7.m1.2.2.1.1.1.2.3.cmml"><mi id="S5.E7.m1.2.2.1.1.1.2.3.2" xref="S5.E7.m1.2.2.1.1.1.2.3.2.cmml">N</mi><mi id="S5.E7.m1.2.2.1.1.1.2.3.3" xref="S5.E7.m1.2.2.1.1.1.2.3.3.cmml">C</mi></msub></munderover><mrow id="S5.E7.m1.2.2.1.1.1.1.1" xref="S5.E7.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E7.m1.2.2.1.1.1.1.1.2" xref="S5.E7.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E7.m1.2.2.1.1.1.1.1.1" xref="S5.E7.m1.2.2.1.1.1.1.1.1.cmml"><mfrac id="S5.E7.m1.1.1" xref="S5.E7.m1.1.1.cmml"><mrow id="S5.E7.m1.1.1.1" xref="S5.E7.m1.1.1.1.cmml"><mo rspace="0em" id="S5.E7.m1.1.1.1.2" xref="S5.E7.m1.1.1.1.2.cmml">âˆ‚</mo><mrow id="S5.E7.m1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.cmml"><mi id="S5.E7.m1.1.1.1.1.3" xref="S5.E7.m1.1.1.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.1.1.1.1.2" xref="S5.E7.m1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E7.m1.1.1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E7.m1.1.1.1.1.1.1.2" xref="S5.E7.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E7.m1.1.1.1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.E7.m1.1.1.1.1.1.1.1.3" xref="S5.E7.m1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.1.1.1.1.1.1.1.2" xref="S5.E7.m1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.E7.m1.1.1.1.1.1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E7.m1.1.1.1.1.1.1.1.1.1.2" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.E7.m1.1.1.1.1.1.1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S5.E7.m1.1.1.1.1.1.1.1.1.1.3" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S5.E7.m1.1.1.1.1.1.1.3" xref="S5.E7.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E7.m1.1.1.3" xref="S5.E7.m1.1.1.3.cmml"><mo rspace="0em" id="S5.E7.m1.1.1.3.1" xref="S5.E7.m1.1.1.3.1.cmml">âˆ‚</mo><msub id="S5.E7.m1.1.1.3.2" xref="S5.E7.m1.1.1.3.2.cmml"><mi id="S5.E7.m1.1.1.3.2.2" xref="S5.E7.m1.1.1.3.2.2.cmml">W</mi><mi id="S5.E7.m1.1.1.3.2.3" xref="S5.E7.m1.1.1.3.2.3.cmml">g</mi></msub></mrow></mfrac><mo id="S5.E7.m1.2.2.1.1.1.1.1.1.1" xref="S5.E7.m1.2.2.1.1.1.1.1.1.1.cmml">+</mo><msubsup id="S5.E7.m1.2.2.1.1.1.1.1.1.2" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.2" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">e</mi><msub id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.cmml"><mi id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.2" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.2.cmml">g</mi><mi id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.3" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.3.cmml">i</mi></msub><mi id="S5.E7.m1.2.2.1.1.1.1.1.1.2.3" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup></mrow><mo stretchy="false" id="S5.E7.m1.2.2.1.1.1.1.1.3" xref="S5.E7.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E7.m1.2b"><apply id="S5.E7.m1.2.2.cmml" xref="S5.E7.m1.2.2"><eq id="S5.E7.m1.2.2.2.cmml" xref="S5.E7.m1.2.2.2"></eq><apply id="S5.E7.m1.2.2.3.cmml" xref="S5.E7.m1.2.2.3"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.3.1.cmml" xref="S5.E7.m1.2.2.3">superscript</csymbol><apply id="S5.E7.m1.2.2.3.2.cmml" xref="S5.E7.m1.2.2.3"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.3.2.1.cmml" xref="S5.E7.m1.2.2.3">subscript</csymbol><ci id="S5.E7.m1.2.2.3.2.2.cmml" xref="S5.E7.m1.2.2.3.2.2">ğ‘Š</ci><ci id="S5.E7.m1.2.2.3.2.3.cmml" xref="S5.E7.m1.2.2.3.2.3">ğ‘”</ci></apply><apply id="S5.E7.m1.2.2.3.3.cmml" xref="S5.E7.m1.2.2.3.3"><plus id="S5.E7.m1.2.2.3.3.1.cmml" xref="S5.E7.m1.2.2.3.3.1"></plus><ci id="S5.E7.m1.2.2.3.3.2.cmml" xref="S5.E7.m1.2.2.3.3.2">ğ‘¡</ci><cn type="integer" id="S5.E7.m1.2.2.3.3.3.cmml" xref="S5.E7.m1.2.2.3.3.3">1</cn></apply></apply><apply id="S5.E7.m1.2.2.1.cmml" xref="S5.E7.m1.2.2.1"><minus id="S5.E7.m1.2.2.1.2.cmml" xref="S5.E7.m1.2.2.1.2"></minus><apply id="S5.E7.m1.2.2.1.3.cmml" xref="S5.E7.m1.2.2.1.3"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.3.1.cmml" xref="S5.E7.m1.2.2.1.3">superscript</csymbol><apply id="S5.E7.m1.2.2.1.3.2.cmml" xref="S5.E7.m1.2.2.1.3"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.3.2.1.cmml" xref="S5.E7.m1.2.2.1.3">subscript</csymbol><ci id="S5.E7.m1.2.2.1.3.2.2.cmml" xref="S5.E7.m1.2.2.1.3.2.2">ğ‘Š</ci><ci id="S5.E7.m1.2.2.1.3.2.3.cmml" xref="S5.E7.m1.2.2.1.3.2.3">ğ‘”</ci></apply><ci id="S5.E7.m1.2.2.1.3.3.cmml" xref="S5.E7.m1.2.2.1.3.3">ğ‘¡</ci></apply><apply id="S5.E7.m1.2.2.1.1.cmml" xref="S5.E7.m1.2.2.1.1"><times id="S5.E7.m1.2.2.1.1.2.cmml" xref="S5.E7.m1.2.2.1.1.2"></times><apply id="S5.E7.m1.2.2.1.1.3.cmml" xref="S5.E7.m1.2.2.1.1.3"><divide id="S5.E7.m1.2.2.1.1.3.1.cmml" xref="S5.E7.m1.2.2.1.1.3"></divide><ci id="S5.E7.m1.2.2.1.1.3.2.cmml" xref="S5.E7.m1.2.2.1.1.3.2">ğœ‚</ci><apply id="S5.E7.m1.2.2.1.1.3.3.cmml" xref="S5.E7.m1.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.1.3.3.1.cmml" xref="S5.E7.m1.2.2.1.1.3.3">subscript</csymbol><ci id="S5.E7.m1.2.2.1.1.3.3.2.cmml" xref="S5.E7.m1.2.2.1.1.3.3.2">ğ‘</ci><ci id="S5.E7.m1.2.2.1.1.3.3.3.cmml" xref="S5.E7.m1.2.2.1.1.3.3.3">ğ¶</ci></apply></apply><apply id="S5.E7.m1.2.2.1.1.1.cmml" xref="S5.E7.m1.2.2.1.1.1"><apply id="S5.E7.m1.2.2.1.1.1.2.cmml" xref="S5.E7.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.1.1.2.1.cmml" xref="S5.E7.m1.2.2.1.1.1.2">superscript</csymbol><apply id="S5.E7.m1.2.2.1.1.1.2.2.cmml" xref="S5.E7.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.1.1.2.2.1.cmml" xref="S5.E7.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S5.E7.m1.2.2.1.1.1.2.2.2.cmml" xref="S5.E7.m1.2.2.1.1.1.2.2.2"></sum><apply id="S5.E7.m1.2.2.1.1.1.2.2.3.cmml" xref="S5.E7.m1.2.2.1.1.1.2.2.3"><eq id="S5.E7.m1.2.2.1.1.1.2.2.3.1.cmml" xref="S5.E7.m1.2.2.1.1.1.2.2.3.1"></eq><ci id="S5.E7.m1.2.2.1.1.1.2.2.3.2.cmml" xref="S5.E7.m1.2.2.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S5.E7.m1.2.2.1.1.1.2.2.3.3.cmml" xref="S5.E7.m1.2.2.1.1.1.2.2.3.3">1</cn></apply></apply><apply id="S5.E7.m1.2.2.1.1.1.2.3.cmml" xref="S5.E7.m1.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.1.1.2.3.1.cmml" xref="S5.E7.m1.2.2.1.1.1.2.3">subscript</csymbol><ci id="S5.E7.m1.2.2.1.1.1.2.3.2.cmml" xref="S5.E7.m1.2.2.1.1.1.2.3.2">ğ‘</ci><ci id="S5.E7.m1.2.2.1.1.1.2.3.3.cmml" xref="S5.E7.m1.2.2.1.1.1.2.3.3">ğ¶</ci></apply></apply><apply id="S5.E7.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1"><plus id="S5.E7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.1"></plus><apply id="S5.E7.m1.1.1.cmml" xref="S5.E7.m1.1.1"><divide id="S5.E7.m1.1.1.2.cmml" xref="S5.E7.m1.1.1"></divide><apply id="S5.E7.m1.1.1.1.cmml" xref="S5.E7.m1.1.1.1"><partialdiff id="S5.E7.m1.1.1.1.2.cmml" xref="S5.E7.m1.1.1.1.2"></partialdiff><apply id="S5.E7.m1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1"><times id="S5.E7.m1.1.1.1.1.2.cmml" xref="S5.E7.m1.1.1.1.1.2"></times><ci id="S5.E7.m1.1.1.1.1.3.cmml" xref="S5.E7.m1.1.1.1.1.3">ğ‘”</ci><apply id="S5.E7.m1.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1.1"><times id="S5.E7.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.1.1.1.1.1.1.1.2"></times><ci id="S5.E7.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.1.1.1.1.1.1.1.3">ğ‘“</ci><apply id="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply><apply id="S5.E7.m1.1.1.3.cmml" xref="S5.E7.m1.1.1.3"><partialdiff id="S5.E7.m1.1.1.3.1.cmml" xref="S5.E7.m1.1.1.3.1"></partialdiff><apply id="S5.E7.m1.1.1.3.2.cmml" xref="S5.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E7.m1.1.1.3.2.1.cmml" xref="S5.E7.m1.1.1.3.2">subscript</csymbol><ci id="S5.E7.m1.1.1.3.2.2.cmml" xref="S5.E7.m1.1.1.3.2.2">ğ‘Š</ci><ci id="S5.E7.m1.1.1.3.2.3.cmml" xref="S5.E7.m1.1.1.3.2.3">ğ‘”</ci></apply></apply></apply><apply id="S5.E7.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2">superscript</csymbol><apply id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.1.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.2.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.2">ğ‘’</ci><apply id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.1.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3">subscript</csymbol><ci id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.2.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.2">ğ‘”</ci><ci id="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.3.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.2.3.3">ğ‘–</ci></apply></apply><ci id="S5.E7.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S5.E7.m1.2.2.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E7.m1.2c">W_{g}^{t+1}=W_{g}^{t}-\frac{\eta}{N_{C}}\sum_{i=1}^{N_{C}}(\dfrac{\partial g(f(x_{i}))}{\partial W_{g}}+e_{g_{i}}^{t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S5.SS3.SSS6.p5" class="ltx_para">
<p id="S5.SS3.SSS6.p5.4" class="ltx_p">The variable <math id="S5.SS3.SSS6.p5.1.m1.1" class="ltx_Math" alttext="e_{g_{i}}^{t}" display="inline"><semantics id="S5.SS3.SSS6.p5.1.m1.1a"><msubsup id="S5.SS3.SSS6.p5.1.m1.1.1" xref="S5.SS3.SSS6.p5.1.m1.1.1.cmml"><mi id="S5.SS3.SSS6.p5.1.m1.1.1.2.2" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.2.cmml">e</mi><msub id="S5.SS3.SSS6.p5.1.m1.1.1.2.3" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.3.cmml"><mi id="S5.SS3.SSS6.p5.1.m1.1.1.2.3.2" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.3.2.cmml">g</mi><mi id="S5.SS3.SSS6.p5.1.m1.1.1.2.3.3" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.3.3.cmml">i</mi></msub><mi id="S5.SS3.SSS6.p5.1.m1.1.1.3" xref="S5.SS3.SSS6.p5.1.m1.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p5.1.m1.1b"><apply id="S5.SS3.SSS6.p5.1.m1.1.1.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS6.p5.1.m1.1.1.1.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1">superscript</csymbol><apply id="S5.SS3.SSS6.p5.1.m1.1.1.2.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS6.p5.1.m1.1.1.2.1.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.SSS6.p5.1.m1.1.1.2.2.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.2">ğ‘’</ci><apply id="S5.SS3.SSS6.p5.1.m1.1.1.2.3.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S5.SS3.SSS6.p5.1.m1.1.1.2.3.1.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.3">subscript</csymbol><ci id="S5.SS3.SSS6.p5.1.m1.1.1.2.3.2.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.3.2">ğ‘”</ci><ci id="S5.SS3.SSS6.p5.1.m1.1.1.2.3.3.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1.2.3.3">ğ‘–</ci></apply></apply><ci id="S5.SS3.SSS6.p5.1.m1.1.1.3.cmml" xref="S5.SS3.SSS6.p5.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p5.1.m1.1c">e_{g_{i}}^{t}</annotation></semantics></math> indicates the gaussian noise added for the <math id="S5.SS3.SSS6.p5.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS3.SSS6.p5.2.m2.1a"><mi id="S5.SS3.SSS6.p5.2.m2.1.1" xref="S5.SS3.SSS6.p5.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p5.2.m2.1b"><ci id="S5.SS3.SSS6.p5.2.m2.1.1.cmml" xref="S5.SS3.SSS6.p5.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p5.2.m2.1c">i</annotation></semantics></math>-th server NN at iteration <math id="S5.SS3.SSS6.p5.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.SS3.SSS6.p5.3.m3.1a"><mi id="S5.SS3.SSS6.p5.3.m3.1.1" xref="S5.SS3.SSS6.p5.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p5.3.m3.1b"><ci id="S5.SS3.SSS6.p5.3.m3.1.1.cmml" xref="S5.SS3.SSS6.p5.3.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p5.3.m3.1c">t</annotation></semantics></math> according to <math id="S5.SS3.SSS6.p5.4.m4.2" class="ltx_Math" alttext="e_{g_{i}}^{t}\sim\mathcal{N}(0,\,(noise\_multiplier\times max\_gradient\_norm)^{2})\," display="inline"><semantics id="S5.SS3.SSS6.p5.4.m4.2a"><mrow id="S5.SS3.SSS6.p5.4.m4.2.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.cmml"><msubsup id="S5.SS3.SSS6.p5.4.m4.2.2.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.cmml"><mi id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.2.cmml">e</mi><msub id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.cmml"><mi id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.2.cmml">g</mi><mi id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.3.cmml">i</mi></msub><mi id="S5.SS3.SSS6.p5.4.m4.2.2.3.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.3.cmml">t</mi></msubsup><mo id="S5.SS3.SSS6.p5.4.m4.2.2.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.2.cmml">âˆ¼</mo><mrow id="S5.SS3.SSS6.p5.4.m4.2.2.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS3.SSS6.p5.4.m4.2.2.1.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.3.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.2.cmml">â€‹</mo><mrow id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.2.cmml"><mo stretchy="false" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.2.cmml">(</mo><mn id="S5.SS3.SSS6.p5.4.m4.1.1" xref="S5.SS3.SSS6.p5.4.m4.1.1.cmml">0</mn><mo rspace="0.337em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.2.cmml">,</mo><msup id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.cmml"><mrow id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.cmml"><mrow id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml"><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.2" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1a" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.4" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1b" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.5" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1c" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.6" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1d" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.7" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1e" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.8" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1f" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.9" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1g" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.10" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.10.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1h" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.11" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1i" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.12" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1j" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.13" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.13.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1k" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.14" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1l" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.15" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1m" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.16" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.16.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1n" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.17" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.17.cmml">r</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.1.cmml">Ã—</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml">m</mi></mrow><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1a" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.4" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1b" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.5" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1c" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.6" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.6.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1d" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.7" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1e" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.8" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1f" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.9" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.9.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1g" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.10" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1h" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.11" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.11.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1i" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.12" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.12.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1j" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.13" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.13.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1k" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.14" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.14.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1l" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.15" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.15.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1m" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.16" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.16.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1n" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.17" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.17.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1o" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.18" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.18.cmml">m</mi></mrow><mo stretchy="false" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.3" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.4" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS6.p5.4.m4.2b"><apply id="S5.SS3.SSS6.p5.4.m4.2.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2"><csymbol cd="latexml" id="S5.SS3.SSS6.p5.4.m4.2.2.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.2">similar-to</csymbol><apply id="S5.SS3.SSS6.p5.4.m4.2.2.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3"><csymbol cd="ambiguous" id="S5.SS3.SSS6.p5.4.m4.2.2.3.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3">superscript</csymbol><apply id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3"><csymbol cd="ambiguous" id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3">subscript</csymbol><ci id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.2">ğ‘’</ci><apply id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3"><csymbol cd="ambiguous" id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3">subscript</csymbol><ci id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.2">ğ‘”</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.2.3.3">ğ‘–</ci></apply></apply><ci id="S5.SS3.SSS6.p5.4.m4.2.2.3.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.3.3">ğ‘¡</ci></apply><apply id="S5.SS3.SSS6.p5.4.m4.2.2.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1"><times id="S5.SS3.SSS6.p5.4.m4.2.2.1.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.2"></times><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.3">ğ’©</ci><interval closure="open" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1"><cn type="integer" id="S5.SS3.SSS6.p5.4.m4.1.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.1.1">0</cn><apply id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1">superscript</csymbol><apply id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1"><times id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.1"></times><apply id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2"><times id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.1"></times><apply id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2"><times id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.1"></times><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.2.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.2">ğ‘›</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.3">ğ‘œ</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.4.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.4">ğ‘–</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.5.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.5">ğ‘ </ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.6.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.6">ğ‘’</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.7.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.7">_</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.8.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.8">ğ‘š</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.9.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.9">ğ‘¢</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.10.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.10">ğ‘™</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.11.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.11">ğ‘¡</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.12.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.12">ğ‘–</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.13.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.13">ğ‘</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.14.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.14">ğ‘™</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.15.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.15">ğ‘–</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.16.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.16">ğ‘’</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.17.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.2.17">ğ‘Ÿ</ci></apply><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.2.3">ğ‘š</ci></apply><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.3">ğ‘</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.4.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.4">ğ‘¥</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.5.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.5">_</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.6.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.6">ğ‘”</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.7.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.7">ğ‘Ÿ</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.8.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.8">ğ‘</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.9.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.9">ğ‘‘</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.10.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.10">ğ‘–</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.11.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.11">ğ‘’</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.12.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.12">ğ‘›</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.13.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.13">ğ‘¡</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.14.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.14">_</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.15.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.15">ğ‘›</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.16.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.16">ğ‘œ</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.17.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.17">ğ‘Ÿ</ci><ci id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.18.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.1.1.1.18">ğ‘š</ci></apply><cn type="integer" id="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.3.cmml" xref="S5.SS3.SSS6.p5.4.m4.2.2.1.1.1.1.3">2</cn></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS6.p5.4.m4.2c">e_{g_{i}}^{t}\sim\mathcal{N}(0,\,(noise\_multiplier\times max\_gradient\_norm)^{2})\,</annotation></semantics></math>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS3.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.7 </span>Evaluation Using Different ways of Partitioning NN</h4>

<div id="S5.SS3.SSS7.p1" class="ltx_para">
<p id="S5.SS3.SSS7.p1.1" class="ltx_p">In FigureÂ <a href="#S5.F7.sf1" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a>Â andÂ FigureÂ <a href="#S5.F7.sf3" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(c)</span></a>, the right y-axis shows the attack resilience, and the x-axis indicates the Cut Indexes.
Overall, if we have a deeper client NN (i.e., moving from smaller to bigger Cut Indexes), the attack resilience increases and accuracy decreases
(consistent with the SerAVG Evaluation in SectionÂ <a href="#S5.SS2.SSS4" title="5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.4</span></a>).
After adding more layers, the intermediate data would have less features from the source data, but only keeps those that can improve the classification <span id="S5.SS3.SSS7.p1.1.1" class="ltx_text" style="color:#000000;"> accuracy.</span>
Thus, less features are preserved and the attackerâ€™s ability to reconstruct the sourceâ€™s data is hindered.</p>
</div>
<div id="S5.SS3.SSS7.p2" class="ltx_para">
<p id="S5.SS3.SSS7.p2.1" class="ltx_p">We also want to emphasize that with CIFAR10 workload, when there are 7 layers in the clients, the attack resilience reaches about <math id="S5.SS3.SSS7.p2.1.m1.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S5.SS3.SSS7.p2.1.m1.1a"><mrow id="S5.SS3.SSS7.p2.1.m1.1.1" xref="S5.SS3.SSS7.p2.1.m1.1.1.cmml"><mn id="S5.SS3.SSS7.p2.1.m1.1.1.2" xref="S5.SS3.SSS7.p2.1.m1.1.1.2.cmml">80</mn><mo id="S5.SS3.SSS7.p2.1.m1.1.1.1" xref="S5.SS3.SSS7.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS7.p2.1.m1.1b"><apply id="S5.SS3.SSS7.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS7.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.SSS7.p2.1.m1.1.1.1.cmml" xref="S5.SS3.SSS7.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS7.p2.1.m1.1.1.2.cmml" xref="S5.SS3.SSS7.p2.1.m1.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS7.p2.1.m1.1c">80\%</annotation></semantics></math>.
We reach the same result with MNIST workload at the Cut Index of 4.
No extra privacy-aware method was used, and as we discussed earlier, the
transmission delay can also be reduced with a deeper NN in the client
due to potentially smaller intermediate data.
</p>
</div>
<div id="S5.SS3.SSS7.p3" class="ltx_para">
<p id="S5.SS3.SSS7.p3.1" class="ltx_p"><span id="S5.SS3.SSS7.p3.1.1" class="ltx_text ltx_font_bold">Cut Index is an important <span id="S5.SS3.SSS7.p3.1.1.1" class="ltx_text" style="color:#000000;"> hyper-parameter</span> for training delay, accuracy and privacy.</span> <span id="S5.SS3.SSS7.p3.1.2" class="ltx_text ltx_font_italic">Different Cut Indexes bring the following tradeoff: the deeper client NN adds more resource demand at the edge, but reduces the transmission time and enhances attack resilience. On the other hand, a shallower server NN may lead to lower accuracy with SerAVG.</span></p>
</div>
<div id="S5.SS3.SSS7.p4" class="ltx_para">
<p id="S5.SS3.SSS7.p4.5" class="ltx_p">Furthermore, system architects can combine the approaches mentioned above, e.g., having a moderately deep NN in clients and using the CPA-DC, to find a balance between resource demand and performance.
As in FigureÂ <a href="#S5.F7.sf4" title="In Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(d)</span></a>, with <math id="S5.SS3.SSS7.p4.1.m1.1" class="ltx_Math" alttext="cut\_index=4" display="inline"><semantics id="S5.SS3.SSS7.p4.1.m1.1a"><mrow id="S5.SS3.SSS7.p4.1.m1.1.1" xref="S5.SS3.SSS7.p4.1.m1.1.1.cmml"><mrow id="S5.SS3.SSS7.p4.1.m1.1.1.2" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.cmml"><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.2" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.3" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1a" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.4" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1b" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS7.p4.1.m1.1.1.2.5" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1c" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.6" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1d" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.7" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.7.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1e" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.8" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.8.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1f" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.9" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.1.m1.1.1.2.1g" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.1.m1.1.1.2.10" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.10.cmml">x</mi></mrow><mo id="S5.SS3.SSS7.p4.1.m1.1.1.1" xref="S5.SS3.SSS7.p4.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.SSS7.p4.1.m1.1.1.3" xref="S5.SS3.SSS7.p4.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS7.p4.1.m1.1b"><apply id="S5.SS3.SSS7.p4.1.m1.1.1.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1"><eq id="S5.SS3.SSS7.p4.1.m1.1.1.1.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.1"></eq><apply id="S5.SS3.SSS7.p4.1.m1.1.1.2.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2"><times id="S5.SS3.SSS7.p4.1.m1.1.1.2.1.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.1"></times><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.2.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.2">ğ‘</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.3.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.3">ğ‘¢</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.4.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.4">ğ‘¡</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.5.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.5">_</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.6.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.6">ğ‘–</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.7.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.7">ğ‘›</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.8.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.8">ğ‘‘</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.9.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.9">ğ‘’</ci><ci id="S5.SS3.SSS7.p4.1.m1.1.1.2.10.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.2.10">ğ‘¥</ci></apply><cn type="integer" id="S5.SS3.SSS7.p4.1.m1.1.1.3.cmml" xref="S5.SS3.SSS7.p4.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS7.p4.1.m1.1c">cut\_index=4</annotation></semantics></math>, <math id="S5.SS3.SSS7.p4.2.m2.1" class="ltx_Math" alttext="DC\_Frequency=1" display="inline"><semantics id="S5.SS3.SSS7.p4.2.m2.1a"><mrow id="S5.SS3.SSS7.p4.2.m2.1.1" xref="S5.SS3.SSS7.p4.2.m2.1.1.cmml"><mrow id="S5.SS3.SSS7.p4.2.m2.1.1.2" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.cmml"><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.2" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.3" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1a" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS7.p4.2.m2.1.1.2.4" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.4.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1b" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.5" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1c" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.6" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1d" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.7" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1e" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.8" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.8.cmml">q</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1f" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.9" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1g" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.10" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1h" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.11" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.11.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1i" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.12" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.12.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.2.m2.1.1.2.1j" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.2.m2.1.1.2.13" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.13.cmml">y</mi></mrow><mo id="S5.SS3.SSS7.p4.2.m2.1.1.1" xref="S5.SS3.SSS7.p4.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.SSS7.p4.2.m2.1.1.3" xref="S5.SS3.SSS7.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS7.p4.2.m2.1b"><apply id="S5.SS3.SSS7.p4.2.m2.1.1.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1"><eq id="S5.SS3.SSS7.p4.2.m2.1.1.1.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.1"></eq><apply id="S5.SS3.SSS7.p4.2.m2.1.1.2.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2"><times id="S5.SS3.SSS7.p4.2.m2.1.1.2.1.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.1"></times><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.2.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.2">ğ·</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.3.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.3">ğ¶</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.4.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.4">_</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.5.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.5">ğ¹</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.6.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.6">ğ‘Ÿ</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.7.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.7">ğ‘’</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.8.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.8">ğ‘</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.9.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.9">ğ‘¢</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.10.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.10">ğ‘’</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.11.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.11">ğ‘›</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.12.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.12">ğ‘</ci><ci id="S5.SS3.SSS7.p4.2.m2.1.1.2.13.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.2.13">ğ‘¦</ci></apply><cn type="integer" id="S5.SS3.SSS7.p4.2.m2.1.1.3.cmml" xref="S5.SS3.SSS7.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS7.p4.2.m2.1c">DC\_Frequency=1</annotation></semantics></math> and <math id="S5.SS3.SSS7.p4.3.m3.1" class="ltx_Math" alttext="loss\_multiplier=0.3" display="inline"><semantics id="S5.SS3.SSS7.p4.3.m3.1a"><mrow id="S5.SS3.SSS7.p4.3.m3.1.1" xref="S5.SS3.SSS7.p4.3.m3.1.1.cmml"><mrow id="S5.SS3.SSS7.p4.3.m3.1.1.2" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.cmml"><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.2" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.3" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1a" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.4" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1b" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.5" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1c" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S5.SS3.SSS7.p4.3.m3.1.1.2.6" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.6.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1d" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.7" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1e" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.8" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.8.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1f" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.9" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.9.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1g" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.10" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1h" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.11" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1i" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.12" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.12.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1j" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.13" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.13.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1k" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.14" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.14.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1l" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.15" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.15.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS3.SSS7.p4.3.m3.1.1.2.1m" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S5.SS3.SSS7.p4.3.m3.1.1.2.16" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.16.cmml">r</mi></mrow><mo id="S5.SS3.SSS7.p4.3.m3.1.1.1" xref="S5.SS3.SSS7.p4.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS3.SSS7.p4.3.m3.1.1.3" xref="S5.SS3.SSS7.p4.3.m3.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS7.p4.3.m3.1b"><apply id="S5.SS3.SSS7.p4.3.m3.1.1.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1"><eq id="S5.SS3.SSS7.p4.3.m3.1.1.1.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.1"></eq><apply id="S5.SS3.SSS7.p4.3.m3.1.1.2.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2"><times id="S5.SS3.SSS7.p4.3.m3.1.1.2.1.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.1"></times><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.2.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.2">ğ‘™</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.3.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.3">ğ‘œ</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.4.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.4">ğ‘ </ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.5.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.5">ğ‘ </ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.6.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.6">_</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.7.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.7">ğ‘š</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.8.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.8">ğ‘¢</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.9.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.9">ğ‘™</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.10.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.10">ğ‘¡</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.11.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.11">ğ‘–</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.12.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.12">ğ‘</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.13.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.13">ğ‘™</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.14.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.14">ğ‘–</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.15.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.15">ğ‘’</ci><ci id="S5.SS3.SSS7.p4.3.m3.1.1.2.16.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.2.16">ğ‘Ÿ</ci></apply><cn type="float" id="S5.SS3.SSS7.p4.3.m3.1.1.3.cmml" xref="S5.SS3.SSS7.p4.3.m3.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS7.p4.3.m3.1c">loss\_multiplier=0.3</annotation></semantics></math>, we still get about <math id="S5.SS3.SSS7.p4.4.m4.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S5.SS3.SSS7.p4.4.m4.1a"><mrow id="S5.SS3.SSS7.p4.4.m4.1.1" xref="S5.SS3.SSS7.p4.4.m4.1.1.cmml"><mn id="S5.SS3.SSS7.p4.4.m4.1.1.2" xref="S5.SS3.SSS7.p4.4.m4.1.1.2.cmml">80</mn><mo id="S5.SS3.SSS7.p4.4.m4.1.1.1" xref="S5.SS3.SSS7.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS7.p4.4.m4.1b"><apply id="S5.SS3.SSS7.p4.4.m4.1.1.cmml" xref="S5.SS3.SSS7.p4.4.m4.1.1"><csymbol cd="latexml" id="S5.SS3.SSS7.p4.4.m4.1.1.1.cmml" xref="S5.SS3.SSS7.p4.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS7.p4.4.m4.1.1.2.cmml" xref="S5.SS3.SSS7.p4.4.m4.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS7.p4.4.m4.1c">80\%</annotation></semantics></math> attack resilience and more than <math id="S5.SS3.SSS7.p4.5.m5.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S5.SS3.SSS7.p4.5.m5.1a"><mrow id="S5.SS3.SSS7.p4.5.m5.1.1" xref="S5.SS3.SSS7.p4.5.m5.1.1.cmml"><mn id="S5.SS3.SSS7.p4.5.m5.1.1.2" xref="S5.SS3.SSS7.p4.5.m5.1.1.2.cmml">90</mn><mo id="S5.SS3.SSS7.p4.5.m5.1.1.1" xref="S5.SS3.SSS7.p4.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS7.p4.5.m5.1b"><apply id="S5.SS3.SSS7.p4.5.m5.1.1.cmml" xref="S5.SS3.SSS7.p4.5.m5.1.1"><csymbol cd="latexml" id="S5.SS3.SSS7.p4.5.m5.1.1.1.cmml" xref="S5.SS3.SSS7.p4.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS7.p4.5.m5.1.1.2.cmml" xref="S5.SS3.SSS7.p4.5.m5.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS7.p4.5.m5.1c">90\%</annotation></semantics></math> accuracy.</p>
</div>
<div id="S5.SS3.SSS7.p5" class="ltx_para">
<p id="S5.SS3.SSS7.p5.1" class="ltx_p">On the other hand, <span id="S5.SS3.SSS7.p5.1.1" class="ltx_text" style="color:#000000;"> when</span> comparing FSL and PSL, we note that FSL has more <span id="S5.SS3.SSS7.p5.1.2" class="ltx_text" style="color:#000000;"> hyper-</span>parameters to tune.
<span id="S5.SS3.SSS7.p5.1.3" class="ltx_text" style="color:#000000;"> But, i</span>n all experiments reported in FigureÂ <a href="#S5.F7" title="Figure 7 â€£ 5.2.4 Learner Accuracy Evaluation â€£ 5.2 Evaluation Results for Privacy-Oblivious FSL â€£ 5 Evaluation Results â€£ Privacy and Efficiency of Communications in Federated Split Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, when the Cut Index is large, FSL has a better accuracy than PSL.
So we conclude that <span id="S5.SS3.SSS7.p5.1.4" class="ltx_text" style="color:#000000;"> a carefully specified way of partitioning the NN can benefit the most when applied in hybrid federated-split learning systems.</span></p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Systems like Federated Learning (FL), Split Learning (SL), and later works aim to fit specific scenarios such as distributed model training and inference.
However, they are not flexible enough to fit some use cases with the recent development in edge and constrained devices.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">In this work, we propose and extensively evaluate Federated Split Learning (FSL), a system for efficient training and inference with high-level privacy for clientsâ€™ source data.
We present a Client-based Privacy Approach (CPA) for split learning-based systems <span id="S6.p2.1.1" class="ltx_text" style="color:#000000;"> to provide high attack resilience by adding noise to the intermediate data.</span>
<span id="S6.p2.1.2" class="ltx_text" style="color:#000000;"> We also study the training time, accuracy and privacy level of different ways to partitioning a NN in FSL.</span>
As further works, we aim to research <span id="S6.p2.1.3" class="ltx_text" style="color:#000000;"> prediction based NN partitioning methods.</span></p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Moreover, comparisons between FSL and existing NN training and inference systems at the edge are carried out, along with explanations of their pros and cons against FSL.
Among the main analyzed systems, the Parallel Split Learning (PSL)â€™s principal limitation is a slow and stateful server, and the Federated Reconstruction (FRC) system is inefficient in training time and inference time.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work has been supported by National Science Foundation Awards CNS-1908574 and CNS-1908677.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
D.Â H. Mahlool and M.Â H. Abed, â€œA comprehensive survey on federated learning:
Concept and applications,â€ <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2201.09384, 2022. [Online].
Available: https://arxiv.org/abs/2201.09384

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
P.Â Moritz, R.Â Nishihara, S.Â Wang, A.Â Tumanov, R.Â Liaw, E.Â Liang, M.Â Elibol,
Z.Â Yang, W.Â Paul, M.Â I. Jordan, and I.Â Stoica, â€œRay: A distributed framework
for emerging ai applications,â€ ser. OSDIâ€™18.Â Â Â USA: USENIX Association, 2018, p. 561â€“577.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
C.Â Park, D.Â Hong, and C.Â Seo, â€œAn attack-based evaluation method for
differentially private learning against model inversion attack,â€ <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol.Â 7, pp. 124â€‰988â€“124â€‰999, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S.Â Ramaswamy, R.Â Mathews, K.Â Rao, and F.Â Beaufays, â€œFederated learning for
emoji prediction in a mobile keyboard,â€ 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A.Â e.Â a. Hard, â€œFederated learning for mobile keyboard prediction,â€
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
D.Â Leroy, A.Â Coucke, T.Â Lavril, T.Â Gisselbrecht, and J.Â Dureau,
â€œFederated learning for keyword spotting,â€ in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019</em>, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
K.Â Simonyan and A.Â Zisserman, â€œVery deep convolutional networks for
large-scale image recognition,â€ <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1409.1556, 2015.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J.Â Deng, W.Â Dong, R.Â Socher, L.-J. Li, K.Â Li, and L.Â Fei-Fei, â€œImagenet: A
large-scale hierarchical image database,â€ in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2009.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A.Â Krizhevsky, â€œLearning multiple layers of features from tiny images,â€ Tech.
Rep., 2009.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
O.Â Gupta and R.Â Raskar, â€œDistributed learning of deep neural network over
multiple agents,â€ <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Journal of Network and Computer Applications</em>,
August 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A.Â Abedi and S.Â S. Khan, â€œFedsl: Federated split learning on distributed
sequential data in recurrent neural networks,â€ 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
C.Â Thapa, M.Â A.Â P. Chamikara, and S.Â Camtepe, â€œSplitfed: When federated
learning meets split learning,â€ 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J.Â Jeon and J.Â Kim, â€œPrivacy-sensitive parallel split learning,â€ in
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ICOIN</em>, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
H.Â McMahan, E.Â Moore, D.Â Ramage, S.Â Hampson, and B.Â A. yÂ Arcas,
â€œCommunication-efficient learning of deep networks from decentralized
data,â€ in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">AISTATS</em>, 2017.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
X.Â Li, K.Â Huang, W.Â Yang, S.Â Wang, and Z.Â Zhang, â€œOn the convergence of fedavg
on non-iid data,â€ in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y.Â Fraboni, R.Â Vidal, and M.Â Lorenzi, â€œFree-rider attacks on model aggregation
in federated learning,â€ in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">AISTATS</em>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
T.Â Li, A.Â K. Sahu, M.Â Zaheer, M.Â Sanjabi, A.Â Talwalkar, and V.Â Smith,
â€œFederated optimization in heterogeneous networks,â€ 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Y.Â Gao, M.Â Kim, S.Â Abuadbba, Y.Â Kim, C.Â Thapa, K.Â Kim, S.Â A.
Camtep, H.Â Kim, and S.Â Nepal, â€œEnd-to-end evaluation of federated
learning and split learning for internet of things,â€ in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">SRDS</em>, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
H.Â Zhou, W.Â Zhang, C.Â Wang, X.Â Ma, and H.Â Yu, â€œBbnet: A novel convolutional
neural network structure in edge-cloud collaborative inference,â€
<em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
A.Â E. Eshratifar, A.Â Esmaili, and M.Â Pedram, â€œBottlenet: A deep learning
architecture for intelligent mobile cloud computing services,â€ in
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ISLPED</em>.Â Â Â IEEE, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y.Â Matsubara, M.Â Levorato, and F.Â Restuccia, â€œSplit computing and early
exiting for deep learning applications: Survey and research challenges,â€
<em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.04505</em>, 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y.Â Matsubara, S.Â Baidya, D.Â Callegaro, M.Â Levorato, and S.Â Singh, â€œDistilled
split deep neural networks for edge-assisted real-time systems,â€ in
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">HotEdgeVideo</em>.Â Â Â New York, NY,
USA: ACM, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
V.Â Turina, Z.Â Zhang, F.Â Esposito, and I.Â Matta, â€œFederated or split? a
performance and privacy analysis of hybrid split and federated learning
architectures,â€ in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE CLOUD</em>, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
K.Â Singhal, H.Â Sidahmed, Z.Â Garrett, S.Â Wu, J.Â K. Rush, and S.Â Prakash,
â€œFederated reconstruction: Partially local federated learning,â€ in
<em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J.Â Yan and J.Â Yuan, â€œA survey of traffic classification in software defined
networks,â€ in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">HotICN</em>, 2018.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
H.Â Yang, J.Â Zhao, Z.Â Xiong, K.-Y. Lam, S.Â Sun, and L.Â Xiao,
â€œPrivacy-preserving federated learning for uav-enabled networks:
Learning-based joint scheduling and resource management,â€ <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Journal
on Selected Areas in Communications</em>, 2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
M.Â Fredrikson, S.Â Jha, and T.Â Ristenpart, â€œModel inversion attacks that
exploit confidence information and basic countermeasures,â€ in
<em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CCS</em>.Â Â Â New York, NY, USA: ACM,
2015.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
S.Â Hidano, T.Â Murakami, S.Â Katsumata, S.Â Kiyomoto, and G.Â Hanaoka,
â€œModel inversion attacks for prediction systems: Without knowledge of
non-sensitive attributes,â€ in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">PST</em>, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
P.Â Vepakomma, A.Â Singh, O.Â Gupta, and R.Â Raskar, â€œNopeek: Information
leakage reduction to share activations in distributed deep learning,â€ in
<em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ICDMW</em>, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
M.Â Abadi, A.Â Chu, I.Â Goodfellow, H.Â B. McMahan, I.Â Mironov, K.Â Talwar, and
L.Â Zhang, â€œDeep learning with differential privacy,â€ ser. CCS â€™16.Â Â Â ACM, 2016.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Y.Â Mao, S.Â Yi, Q.Â Li, J.Â Feng, F.Â Xu, and S.Â Zhong, â€œLearning from
differentially private neural activations with edge computing,â€ in
<em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">SEC</em>, 2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J.Â Huang, C.Â Samplawski, D.Â Ganesan, B.Â Marlin, and H.Â Kwon, â€œClio: Enabling
automatic compilation of deep learning pipelines across iot and cloud,â€ in
<em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">MobiCom</em>.Â Â Â ACM, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
S.Â Qiu, D.Â Wang, G.Â Xu, and S.Â Kumari, â€œPractical and provably secure
three-factor authentication protocol based on extended chaotic-maps for
mobile lightweight devices,â€ <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and
Secure Computing</em>, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Q.Â Jiang, N.Â Zhang, J.Â Ni, J.Â Ma, X.Â Ma, and K.-K.Â R. Choo, â€œUnified biometric
privacy preserving three-factor authentication and key agreement for
cloud-assisted autonomous vehicles,â€ <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Vehicular
Technology</em>, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
G.Â E. Hinton and R.Â S. Zemel, â€œAutoencoders, minimum description length and
helmholtz free energy,â€ in <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">NIPS</em>.Â Â Â San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1993.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Y.Â Kang, J.Â Hauswald, C.Â Gao, A.Â Rovinski, T.Â Mudge, J.Â Mars, and L.Â Tang,
â€œNeurosurgeon: Collaborative intelligence between the cloud and mobile
edge,â€ in <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">ASPLOS</em>, 2017.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
T.Â Unterthiner, D.Â Keysers, S.Â Gelly, O.Â Bousquet, and I.Â Tolstikhin,
â€œPredicting neural network accuracy from weights,â€ 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
K.Â K. et. al., â€œLessons learned from the chameleon testbed,â€ in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">ATC</em>,
July 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A.Â e.Â a. Paszke, â€œPytorch: An imperative style, high-performance deep learning
library,â€ in <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.Â Â Â Curran
Associates, Inc., 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
T.Â Ryffel, A.Â Trask, M.Â Dahl, B.Â Wagner, J.Â Mancuso, D.Â Rueckert, and
J.Â Passerat-Palmbach, â€œA generic framework for privacy preserving deep
learning,â€ <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.04017</em>, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
(2020) Pygrid. [Online]. Available: https://github.com/OpenMined/PyGrid

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Y.Â Lecun, L.Â Bottou, Y.Â Bengio, and P.Â Haffner, â€œGradient-based
learning applied to document recognition,â€ <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>,
1998.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Y.Â LeCun and C.Â Cortes, â€œMNIST handwritten digit database,â€ 2010.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
W.Â Wang, M.Â Zhu, J.Â Wang, X.Â Zeng, and Z.Â Yang, â€œEnd-to-end encrypted traffic
classification with one-dimensional convolution neural networks,â€ in
<em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ISI</em>, 2017.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
J.Â Bergstra and Y.Â Bengio, â€œRandom search for hyper-parameter optimization,â€
<em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">JMLR</em>, 2012.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
L.Â Li, K.Â Jamieson, G.Â DeSalvo, A.Â Rostamizadeh, and A.Â Talwalkar, â€œHyperband:
A novel bandit-based approach to hyperparameter optimization,â€ <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">JMLR</em>,
2018.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
G.Â Cohen, S.Â Afshar, J.Â Tapson, and A.Â van Schaik, â€œEmnist: Extending
mnist to handwritten letters,â€ in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">IJCNN</em>, 2017.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
(2021, oct) Opacus. [Online]. Available: https://opacus.ai/

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2301.01823" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2301.01824" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2301.01824">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2301.01824" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2301.01825" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 04:19:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
