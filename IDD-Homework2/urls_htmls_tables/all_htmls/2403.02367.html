<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation</title>
<!--Generated on Mon Mar  4 11:56:52 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2403.02367v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S1" title="1 Introduction ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2" title="2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Neural Networks for MT</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS1" title="2.1 Recurrent Neural Network Architectures ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Recurrent Neural Network Architectures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS2" title="2.2 Transformer Architecture ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Transformer Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS3" title="2.3 Attention ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Attention</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS4" title="2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>NMT</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS4.SSS1" title="2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.1 </span>Modelling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS4.SSS2" title="2.4.2 Learning ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.2 </span>Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS4.SSS3" title="2.4.3 Inference ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.3 </span>Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS5" title="2.5 Subword Models ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Subword Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS6" title="2.6 NMT Tools ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.6 </span>NMT Tools</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS7" title="2.7 Hyperparameter Optimization ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.7 </span>Hyperparameter Optimization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3" title="3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Architecture of adaptNMT</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS1" title="3.1 adaptNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>adaptNMT</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS1.SSS1" title="3.1.1 Initialization and logging ‣ 3.1 adaptNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Initialization and logging</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS1.SSS2" title="3.1.2 Modes of operation ‣ 3.1 adaptNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Modes of operation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS1.SSS3" title="3.1.3 Customization of models ‣ 3.1 adaptNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Customization of models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS1.SSS4" title="3.1.4 Use of subword segmentation ‣ 3.1 adaptNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.4 </span>Use of subword segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS1.SSS5" title="3.1.5 Translation and evaluation ‣ 3.1 adaptNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.5 </span>Translation and evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS2" title="3.2 serverNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>serverNMT</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4" title="4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Empirical Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.SS1" title="4.1 Infrastructure ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Infrastructure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.SS2" title="4.2 Metrics ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.SS3" title="4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Results: Automatic Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.SS4" title="4.4 Environmental Impact ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Environmental Impact</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.SS5" title="4.5 Stochastic Nuances ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Stochastic Nuances</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S5" title="5 Discussion ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S6" title="6 Conclusion and Future Work ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion and Future Work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content"><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2403.02367v1 [cs.CL] 04 Mar 2024</div></div>
<article class="ltx_document ltx_authors_1line"><span class="ltx_ERROR undefined" id="id1">\jyear</span>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">2023</p>
</div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1">[1,2]<span class="ltx_ERROR undefined" id="p2.1.1">\fnm</span>Séamus <span class="ltx_ERROR undefined" id="p2.1.2">\sur</span>Lankford</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">[1]<span class="ltx_ERROR undefined" id="p3.1.1">\orgdiv</span>ADAPT Centre, <span class="ltx_ERROR undefined" id="p3.1.2">\orgname</span>Dublin City University, <span class="ltx_ERROR undefined" id="p3.1.3">\orgaddress</span><span class="ltx_ERROR undefined" id="p3.1.4">\city</span>Dublin, <span class="ltx_ERROR undefined" id="p3.1.5">\country</span>Ireland</p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">2]<span class="ltx_ERROR undefined" id="p4.1.1">\orgdiv</span>ADAPT Centre, <span class="ltx_ERROR undefined" id="p4.1.2">\orgname</span>Munster Technological University, <span class="ltx_ERROR undefined" id="p4.1.3">\orgaddress</span><span class="ltx_ERROR undefined" id="p4.1.4">\city</span>Cork, <span class="ltx_ERROR undefined" id="p4.1.5">\country</span>Ireland</p>
</div>
<h1 class="ltx_title ltx_title_document">adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:seamus.lankford@mtu.ie">seamus.lankford@mtu.ie</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id1.1.id1">\fnm</span>Haithem <span class="ltx_ERROR undefined" id="id2.2.id2">\sur</span>Afli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:haithem.afli@mtu.ie">haithem.afli@mtu.ie</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id3.1.id1">\fnm</span>Andy <span class="ltx_ERROR undefined" id="id4.2.id2">\sur</span>Way
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:andy.way@adaptcentre.ie">andy.way@adaptcentre.ie</a>
</span>
<span class="ltx_contact ltx_role_affiliation">*
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">adaptNMT streamlines all processes involved in the development and deployment of RNN and Transformer neural translation models. As an open-source application, it is designed for both technical and non-technical users who work in the field of machine translation. Built upon the widely-adopted OpenNMT ecosystem, the application is particularly useful for new entrants to the field since the setup of the development environment and creation of train, validation and test splits is greatly simplified. Graphing, embedded within the application, illustrates the progress of model training, and SentencePiece is used for creating subword segmentation models. Hyperparameter customization is facilitated through an intuitive user interface, and a single-click model development approach has been implemented. Models developed by adaptNMT can be evaluated using a range of metrics, and deployed as a translation service within the application. To support eco-friendly research in the NLP space, a green report also flags the power consumption and kgCO<sub class="ltx_sub" id="id5.id1.1">2</sub> emissions generated during model development. The application is freely available.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://github.com/adaptNMT" title="">http://github.com/adaptNMT</a></span></span></span></p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Neural Machine Translation, Language Technology, NMT, Natural Language Processing, green NLP.
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Explainable Artificial Intelligence (XAI) <cite class="ltx_cite ltx_citemacro_citep">(Gunning et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib19" title="">2019</a>; Arrieta et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib2" title="">2020</a>)</cite> seeks to ensure that the results of AI solutions are easily understood by humans. It is against this backdrop that adaptNMT has been developed to afford users a form of <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">Explainable Neural Machine Translation (XNMT)</span>. The stages involved in a typical NMT process are broken down into a series of independent steps including environment setup, dataset preparation, training of subword models, parameterizing and training of main models, evaluation and deployment. This modular approach has created an effective NMT model development process for both technical and less technical practitioners in the field. Given the environmental impact of building and running of large AI models <cite class="ltx_cite ltx_citemacro_citep">(Strubell et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib52" title="">2019</a>; Henderson et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib20" title="">2020</a>; Jooste et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib23" title="">2022b</a>)</cite>, we also compute carbon emissions in a ‘green report’, primarily as an information aid, but hopefully as a way to encourage reusable and sustainable model development.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">An important part of this research involves developing applications and models to address the challenges of language technology. It is hoped that such work will be of particular benefit to newcomers to the field of Machine Translation (MT) and in particular to those who wish to learn more about NMT.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In order to have a thorough understanding of how NMT models are trained, the individual components and the mathematical concepts underpinning both RNN- and Transformer-based models are explained and illustrated in this paper. The application is built upon OpenNMT <cite class="ltx_cite ltx_citemacro_citep">(Klein et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib26" title="">2017</a>)</cite> and subsequently inherits all of its features. Unlike many NMT toolkits, a CLI (command line interface) approach is not used. The interface is designed and fully implemented in Google Colab.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="colab.research.google.com" title="">colab.research.google.com</a></span></span></span> For an educational setting, and indeed for research practitioners, a Colab cloud-hosted<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="cloud.google.com" title="">cloud.google.com</a></span></span></span> solution is often more intuitive to use. Furthermore, the training of models can be viewed and controlled using the Google Colab mobile app which is ideal for builds with long run times. GUI controls, also implemented within adaptNMT, enable the customization of all key parameters required when training NMT models.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The application can be run in local mode enabling existing infrastructure to be utilised, or in hosted mode which allows for rapid scaling of the infrastructure. A deploy function allows for the immediate deployment of trained models.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This paper is organized by initially presenting background information on NMT and related work on system-building environments in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2" title="2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>. This is followed by a detailed description of the adaptNMT architecture and its key features in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3" title="3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>. An empirical evaluation of models is carried out in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4" title="4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>. The system is discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S5" title="5 Discussion ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> before drawing conclusions and describing future work in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S6" title="6 Conclusion and Future Work ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>. For newcomers to the field, we suggest going straight to Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3" title="3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> to examine the platform’s capabilities, and then discovering more about the various components and their statistical underpinning in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2" title="2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>. This can be followed by the remaining sections in their logical sequence.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Neural Networks for MT</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Recurrent Neural Network Architectures</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Recurrent Neural Networks (RNNs) <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib49" title="">2016a</a>; Sennrich and Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib48" title="">2019</a>; Araabi and Monz, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib1" title="">2020</a>)</cite> are often used for the tasks of Natural Language Processing (NLP), speech recognition and MT. RNNs, such as Long Short-Term Memory (LSTM) <cite class="ltx_cite ltx_citemacro_citep">(Hochreiter and Schmidhuber, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib21" title="">1997</a>)</cite>, were designed to support sequences of input data. LSTM models use an encoder-decoder architecture which enables variable length input sequences to predict variable length output sequences. This architecture is the cornerstone of many complex sequence prediction problems such as speech recognition and MT.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">RNN models enable previous outputs to be used as inputs through the use of hidden states. In the context of MT, such neural networks were ideal due to their ability to process inputs of any length. In the initial stages of NMT, the RNN encoder-decoder framework was adopted and variable-length source sentences were encoded as fixed-length vectors <cite class="ltx_cite ltx_citemacro_citep">(Cho et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib14" title="">2014</a>; Sutskever et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib53" title="">2014</a>)</cite>.
An improvement upon the basic RNN approach was proposed in <cite class="ltx_cite ltx_citemacro_citet">Bahdanau et al (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib4" title="">2014</a>)</cite> which enhanced translation performance of the basic encoder-decoder architecture by replacing fixed-length vectors with variable-length vectors. A bidirectional RNN was now employed to read input sentences in the forward direction to produce forward hidden states while also producing backward hidden states by reading input sentences in the reverse direction. This development enabled neural networks to more accurately process long sentences, which previously had served as bottlenecks to performance, given their tendency to ‘forget’ words in long input sequences which are ‘too far away’ from the current word being processed.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">More importantly, <cite class="ltx_cite ltx_citemacro_citet">Bahdanau et al (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib4" title="">2014</a>)</cite> introduced the concept of ‘attention’ to the basic RNN architecture, similar in spirit and intention to ‘alignments’ in the forerunner to NMT, Statistical MT <cite class="ltx_cite ltx_citemacro_citep">(Och and Ney, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib37" title="">2003</a>)</cite>. In attention-augmented NMT, the system could now pay special heed to the most relevant other source-sentence words and use them as contextual clues when considering how best to select the most appropriate target words(s) for translationally ambiguous words in the same string.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Transformer Architecture</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Following the introduction of the attention mechanism, a natural line of investigation was to see whether attention could do most of the heavy lifting of translation by itself. Accordingly, <cite class="ltx_cite ltx_citemacro_citet">Vaswani et al (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib55" title="">2017</a>)</cite> proposed that “attention is all you need” in their ‘Transformer architecture’, which has achieved state-of-the-art (SOTA) performance on many NLP benchmarks by relying solely on an attention mechanism, removing recurrence and convolution, while allowing the use of much simpler feed-forward neural networks.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="397" id="S2.F1.g1" src="extracted/5447326/transformer.png" width="275"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.3.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.4.2" style="font-size:90%;"> <span class="ltx_text" id="S2.F1.4.2.1" style="font-size:89%;">The Transformer architecture using an encoder-decoder <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib55" title="">2017</a>)</cite>. The encoder maps an input sequence to the decoder. The decoder generates a new output by combining the encoder output with the decoder output from the previous step. </span></span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">This approach follows an encoder-decoder structure, and allows models to develop a long memory which is particularly useful in the area of language translation. The task of the encoder is to map an input sequence to a sequence of continuous representations, which is then passed to a decoder to generate an output sequence by using the output of the encoder together with the decoder output from the previous time step. Both the encoder and decoder each consist of a stack of 6 identical layers, whose structure is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.F1" title="Figure 1 ‣ 2.2 Transformer Architecture ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>. In the encoder, each layer is composed of two sub-layers: a multi-head self-attention mechanism and a fully connected feed-forward network. In the case of the decoder, there are three sub-layers: one which takes the previous output of the decoder stack, another which implements a multi-head self-attention mechanism, and the final layer which implements a fully connected feed-forward network.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Attention</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.F2" title="Figure 2 ‣ 2.3 Attention ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, the attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key, as shown in Equation (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E1" title="1 ‣ 2.3 Attention ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="177" id="S2.F2.g1" src="extracted/5447326/attention.png" width="99"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.3.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.4.2" style="font-size:90%;"> <span class="ltx_text" id="S2.F2.4.2.1" style="font-size:89%;"> Multi-Head Attention in the Decoder <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib55" title="">2017</a>)</cite>. In the decoder, a multi-head layer receives queries from the previous decoder sublayer, and the keys and values from the encoder output. The decoder can now attend to all words in the input sequence. </span></span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">The query, keys and values used as inputs to the the attention mechanism are different projections of the same input sentence (‘self-attention’) and capture the relationships between the different words of the same sentence.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.4">Both a scaled dot-product attention and a multi-head attention are used in the Transformer architecture. With scaled dot-product attention, a dot product is initially computed for each query <math alttext="q" class="ltx_Math" display="inline" id="S2.SS3.p3.1.m1.1"><semantics id="S2.SS3.p3.1.m1.1a"><mi id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><ci id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.1.m1.1d">italic_q</annotation></semantics></math> with all of the keys <math alttext="k" class="ltx_Math" display="inline" id="S2.SS3.p3.2.m2.1"><semantics id="S2.SS3.p3.2.m2.1a"><mi id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.1b"><ci id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.2.m2.1d">italic_k</annotation></semantics></math>. Subsequently, each result is divided by <math alttext="\sqrt{d_{k}}" class="ltx_Math" display="inline" id="S2.SS3.p3.3.m3.1"><semantics id="S2.SS3.p3.3.m3.1a"><msqrt id="S2.SS3.p3.3.m3.1.1" xref="S2.SS3.p3.3.m3.1.1.cmml"><msub id="S2.SS3.p3.3.m3.1.1.2" xref="S2.SS3.p3.3.m3.1.1.2.cmml"><mi id="S2.SS3.p3.3.m3.1.1.2.2" xref="S2.SS3.p3.3.m3.1.1.2.2.cmml">d</mi><mi id="S2.SS3.p3.3.m3.1.1.2.3" xref="S2.SS3.p3.3.m3.1.1.2.3.cmml">k</mi></msub></msqrt><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.1b"><apply id="S2.SS3.p3.3.m3.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1"><root id="S2.SS3.p3.3.m3.1.1a.cmml" xref="S2.SS3.p3.3.m3.1.1"></root><apply id="S2.SS3.p3.3.m3.1.1.2.cmml" xref="S2.SS3.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p3.3.m3.1.1.2.1.cmml" xref="S2.SS3.p3.3.m3.1.1.2">subscript</csymbol><ci id="S2.SS3.p3.3.m3.1.1.2.2.cmml" xref="S2.SS3.p3.3.m3.1.1.2.2">𝑑</ci><ci id="S2.SS3.p3.3.m3.1.1.2.3.cmml" xref="S2.SS3.p3.3.m3.1.1.2.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.1c">\sqrt{d_{k}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.3.m3.1d">square-root start_ARG italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> and a Softmax function is applied. The process leads to the weights which are used to scale the values, <math alttext="v" class="ltx_Math" display="inline" id="S2.SS3.p3.4.m4.1"><semantics id="S2.SS3.p3.4.m4.1a"><mi id="S2.SS3.p3.4.m4.1.1" xref="S2.SS3.p3.4.m4.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.4.m4.1b"><ci id="S2.SS3.p3.4.m4.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.4.m4.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.4.m4.1d">italic_v</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1">The Softmax function allows us to perform multiclass classification which makes it a good choice in the final layer of neural network-based classifiers. The function forces the outputs of the neural network to a total sum to 1, which can be viewed as a probability distribution across multiple classes. Therefore, Softmax is the ideal choice as the output activation function, given that NMT is essentially a multiclass classification problem where the output classes represent the words within the vocabulary.</p>
</div>
<div class="ltx_para" id="S2.SS3.p5">
<p class="ltx_p" id="S2.SS3.p5.3">Computations performed by scaled dot-product attention can be efficiently applied on the entire set of queries simultaneously. To achieve this, the matrices, <math alttext="Q" class="ltx_Math" display="inline" id="S2.SS3.p5.1.m1.1"><semantics id="S2.SS3.p5.1.m1.1a"><mi id="S2.SS3.p5.1.m1.1.1" xref="S2.SS3.p5.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.1.m1.1b"><ci id="S2.SS3.p5.1.m1.1.1.cmml" xref="S2.SS3.p5.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p5.1.m1.1d">italic_Q</annotation></semantics></math>, <math alttext="K" class="ltx_Math" display="inline" id="S2.SS3.p5.2.m2.1"><semantics id="S2.SS3.p5.2.m2.1a"><mi id="S2.SS3.p5.2.m2.1.1" xref="S2.SS3.p5.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.2.m2.1b"><ci id="S2.SS3.p5.2.m2.1.1.cmml" xref="S2.SS3.p5.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p5.2.m2.1d">italic_K</annotation></semantics></math> and <math alttext="V" class="ltx_Math" display="inline" id="S2.SS3.p5.3.m3.1"><semantics id="S2.SS3.p5.3.m3.1a"><mi id="S2.SS3.p5.3.m3.1.1" xref="S2.SS3.p5.3.m3.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.3.m3.1b"><ci id="S2.SS3.p5.3.m3.1.1.cmml" xref="S2.SS3.p5.3.m3.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.3.m3.1c">V</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p5.3.m3.1d">italic_V</annotation></semantics></math>, are supplied as inputs to the attention function:</p>
</div>
<div class="ltx_para" id="S2.SS3.p6">
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="attention(Q,K,V)=softmax(QK^{T}/\sqrt{d_{k}})V" class="ltx_Math" display="block" id="S2.E1.m1.4"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.4.4.3" xref="S2.E1.m1.4.4.3.cmml"><mi id="S2.E1.m1.4.4.3.2" xref="S2.E1.m1.4.4.3.2.cmml">a</mi><mo id="S2.E1.m1.4.4.3.1" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.3" xref="S2.E1.m1.4.4.3.3.cmml">t</mi><mo id="S2.E1.m1.4.4.3.1a" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.4" xref="S2.E1.m1.4.4.3.4.cmml">t</mi><mo id="S2.E1.m1.4.4.3.1b" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.5" xref="S2.E1.m1.4.4.3.5.cmml">e</mi><mo id="S2.E1.m1.4.4.3.1c" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.6" xref="S2.E1.m1.4.4.3.6.cmml">n</mi><mo id="S2.E1.m1.4.4.3.1d" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.7" xref="S2.E1.m1.4.4.3.7.cmml">t</mi><mo id="S2.E1.m1.4.4.3.1e" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.8" xref="S2.E1.m1.4.4.3.8.cmml">i</mi><mo id="S2.E1.m1.4.4.3.1f" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.9" xref="S2.E1.m1.4.4.3.9.cmml">o</mi><mo id="S2.E1.m1.4.4.3.1g" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.4.4.3.10" xref="S2.E1.m1.4.4.3.10.cmml">n</mi><mo id="S2.E1.m1.4.4.3.1h" xref="S2.E1.m1.4.4.3.1.cmml">⁢</mo><mrow id="S2.E1.m1.4.4.3.11.2" xref="S2.E1.m1.4.4.3.11.1.cmml"><mo id="S2.E1.m1.4.4.3.11.2.1" stretchy="false" xref="S2.E1.m1.4.4.3.11.1.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">Q</mi><mo id="S2.E1.m1.4.4.3.11.2.2" xref="S2.E1.m1.4.4.3.11.1.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">K</mi><mo id="S2.E1.m1.4.4.3.11.2.3" xref="S2.E1.m1.4.4.3.11.1.cmml">,</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">V</mi><mo id="S2.E1.m1.4.4.3.11.2.4" stretchy="false" xref="S2.E1.m1.4.4.3.11.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml">=</mo><mrow id="S2.E1.m1.4.4.1" xref="S2.E1.m1.4.4.1.cmml"><mi id="S2.E1.m1.4.4.1.3" xref="S2.E1.m1.4.4.1.3.cmml">s</mi><mo id="S2.E1.m1.4.4.1.2" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mi id="S2.E1.m1.4.4.1.4" xref="S2.E1.m1.4.4.1.4.cmml">o</mi><mo id="S2.E1.m1.4.4.1.2a" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mi id="S2.E1.m1.4.4.1.5" xref="S2.E1.m1.4.4.1.5.cmml">f</mi><mo id="S2.E1.m1.4.4.1.2b" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mi id="S2.E1.m1.4.4.1.6" xref="S2.E1.m1.4.4.1.6.cmml">t</mi><mo id="S2.E1.m1.4.4.1.2c" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mi id="S2.E1.m1.4.4.1.7" xref="S2.E1.m1.4.4.1.7.cmml">m</mi><mo id="S2.E1.m1.4.4.1.2d" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mi id="S2.E1.m1.4.4.1.8" xref="S2.E1.m1.4.4.1.8.cmml">a</mi><mo id="S2.E1.m1.4.4.1.2e" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mi id="S2.E1.m1.4.4.1.9" xref="S2.E1.m1.4.4.1.9.cmml">x</mi><mo id="S2.E1.m1.4.4.1.2f" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.4.4.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.cmml"><mo id="S2.E1.m1.4.4.1.1.1.2" stretchy="false" xref="S2.E1.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.4.4.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.cmml"><mrow id="S2.E1.m1.4.4.1.1.1.1.2" xref="S2.E1.m1.4.4.1.1.1.1.2.cmml"><mi id="S2.E1.m1.4.4.1.1.1.1.2.2" xref="S2.E1.m1.4.4.1.1.1.1.2.2.cmml">Q</mi><mo id="S2.E1.m1.4.4.1.1.1.1.2.1" xref="S2.E1.m1.4.4.1.1.1.1.2.1.cmml">⁢</mo><msup id="S2.E1.m1.4.4.1.1.1.1.2.3" xref="S2.E1.m1.4.4.1.1.1.1.2.3.cmml"><mi id="S2.E1.m1.4.4.1.1.1.1.2.3.2" xref="S2.E1.m1.4.4.1.1.1.1.2.3.2.cmml">K</mi><mi id="S2.E1.m1.4.4.1.1.1.1.2.3.3" xref="S2.E1.m1.4.4.1.1.1.1.2.3.3.cmml">T</mi></msup></mrow><mo id="S2.E1.m1.4.4.1.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.1.cmml">/</mo><msqrt id="S2.E1.m1.4.4.1.1.1.1.3" xref="S2.E1.m1.4.4.1.1.1.1.3.cmml"><msub id="S2.E1.m1.4.4.1.1.1.1.3.2" xref="S2.E1.m1.4.4.1.1.1.1.3.2.cmml"><mi id="S2.E1.m1.4.4.1.1.1.1.3.2.2" xref="S2.E1.m1.4.4.1.1.1.1.3.2.2.cmml">d</mi><mi id="S2.E1.m1.4.4.1.1.1.1.3.2.3" xref="S2.E1.m1.4.4.1.1.1.1.3.2.3.cmml">k</mi></msub></msqrt></mrow><mo id="S2.E1.m1.4.4.1.1.1.3" stretchy="false" xref="S2.E1.m1.4.4.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E1.m1.4.4.1.2g" xref="S2.E1.m1.4.4.1.2.cmml">⁢</mo><mi id="S2.E1.m1.4.4.1.10" xref="S2.E1.m1.4.4.1.10.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><eq id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"></eq><apply id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4.3"><times id="S2.E1.m1.4.4.3.1.cmml" xref="S2.E1.m1.4.4.3.1"></times><ci id="S2.E1.m1.4.4.3.2.cmml" xref="S2.E1.m1.4.4.3.2">𝑎</ci><ci id="S2.E1.m1.4.4.3.3.cmml" xref="S2.E1.m1.4.4.3.3">𝑡</ci><ci id="S2.E1.m1.4.4.3.4.cmml" xref="S2.E1.m1.4.4.3.4">𝑡</ci><ci id="S2.E1.m1.4.4.3.5.cmml" xref="S2.E1.m1.4.4.3.5">𝑒</ci><ci id="S2.E1.m1.4.4.3.6.cmml" xref="S2.E1.m1.4.4.3.6">𝑛</ci><ci id="S2.E1.m1.4.4.3.7.cmml" xref="S2.E1.m1.4.4.3.7">𝑡</ci><ci id="S2.E1.m1.4.4.3.8.cmml" xref="S2.E1.m1.4.4.3.8">𝑖</ci><ci id="S2.E1.m1.4.4.3.9.cmml" xref="S2.E1.m1.4.4.3.9">𝑜</ci><ci id="S2.E1.m1.4.4.3.10.cmml" xref="S2.E1.m1.4.4.3.10">𝑛</ci><vector id="S2.E1.m1.4.4.3.11.1.cmml" xref="S2.E1.m1.4.4.3.11.2"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑄</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝐾</ci><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝑉</ci></vector></apply><apply id="S2.E1.m1.4.4.1.cmml" xref="S2.E1.m1.4.4.1"><times id="S2.E1.m1.4.4.1.2.cmml" xref="S2.E1.m1.4.4.1.2"></times><ci id="S2.E1.m1.4.4.1.3.cmml" xref="S2.E1.m1.4.4.1.3">𝑠</ci><ci id="S2.E1.m1.4.4.1.4.cmml" xref="S2.E1.m1.4.4.1.4">𝑜</ci><ci id="S2.E1.m1.4.4.1.5.cmml" xref="S2.E1.m1.4.4.1.5">𝑓</ci><ci id="S2.E1.m1.4.4.1.6.cmml" xref="S2.E1.m1.4.4.1.6">𝑡</ci><ci id="S2.E1.m1.4.4.1.7.cmml" xref="S2.E1.m1.4.4.1.7">𝑚</ci><ci id="S2.E1.m1.4.4.1.8.cmml" xref="S2.E1.m1.4.4.1.8">𝑎</ci><ci id="S2.E1.m1.4.4.1.9.cmml" xref="S2.E1.m1.4.4.1.9">𝑥</ci><apply id="S2.E1.m1.4.4.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1"><divide id="S2.E1.m1.4.4.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1"></divide><apply id="S2.E1.m1.4.4.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2"><times id="S2.E1.m1.4.4.1.1.1.1.2.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.1"></times><ci id="S2.E1.m1.4.4.1.1.1.1.2.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.2">𝑄</ci><apply id="S2.E1.m1.4.4.1.1.1.1.2.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3">superscript</csymbol><ci id="S2.E1.m1.4.4.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3.2">𝐾</ci><ci id="S2.E1.m1.4.4.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S2.E1.m1.4.4.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3"><root id="S2.E1.m1.4.4.1.1.1.1.3a.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3"></root><apply id="S2.E1.m1.4.4.1.1.1.1.3.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.1.1.1.1.3.2.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.4.4.1.1.1.1.3.2.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2.2">𝑑</ci><ci id="S2.E1.m1.4.4.1.1.1.1.3.2.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2.3">𝑘</ci></apply></apply></apply><ci id="S2.E1.m1.4.4.1.10.cmml" xref="S2.E1.m1.4.4.1.10">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">attention(Q,K,V)=softmax(QK^{T}/\sqrt{d_{k}})V</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.4d">italic_a italic_t italic_t italic_e italic_n italic_t italic_i italic_o italic_n ( italic_Q , italic_K , italic_V ) = italic_s italic_o italic_f italic_t italic_m italic_a italic_x ( italic_Q italic_K start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT / square-root start_ARG italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG ) italic_V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>NMT</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">While much research effort concentrates on creating new SOTA NMT models, excellent descriptions of the technology are also available within the literature for those starting out in the field, or for those with a less technical background <cite class="ltx_cite ltx_citemacro_citep">(Forcada, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib17" title="">2017</a>; Way, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib57" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">The availability of large parallel corpora has enabled NMT to develop high-performing MT models. Breakthrough performance improvements in the area of MT have been achieved through research efforts focusing on NMT <cite class="ltx_cite ltx_citemacro_citep">(Bahdanau et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib4" title="">2014</a>)</cite> but the advent of the Transformer architecture has greatly improved MT performance. Consequently, SOTA performance has been attained on multiple language pairs <cite class="ltx_cite ltx_citemacro_citep">(Bojar et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib9" title="">2017</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib10" title="">2018</a>; Lankford et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib32" title="">2021b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib34" title="">2022b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib33" title="">2022a</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.4">Similar to many deep-learning approaches, NMT development is underpinned by the mathematics of probability. At a fundamental level, the goal is to predict the probabilistic distribution <math alttext="P(y|x)" class="ltx_Math" display="inline" id="S2.SS4.p3.1.m1.1"><semantics id="S2.SS4.p3.1.m1.1a"><mrow id="S2.SS4.p3.1.m1.1.1" xref="S2.SS4.p3.1.m1.1.1.cmml"><mi id="S2.SS4.p3.1.m1.1.1.3" xref="S2.SS4.p3.1.m1.1.1.3.cmml">P</mi><mo id="S2.SS4.p3.1.m1.1.1.2" xref="S2.SS4.p3.1.m1.1.1.2.cmml">⁢</mo><mrow id="S2.SS4.p3.1.m1.1.1.1.1" xref="S2.SS4.p3.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS4.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS4.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS4.p3.1.m1.1.1.1.1.1" xref="S2.SS4.p3.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS4.p3.1.m1.1.1.1.1.1.2" xref="S2.SS4.p3.1.m1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS4.p3.1.m1.1.1.1.1.1.1" xref="S2.SS4.p3.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS4.p3.1.m1.1.1.1.1.1.3" xref="S2.SS4.p3.1.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.SS4.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS4.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.1.m1.1b"><apply id="S2.SS4.p3.1.m1.1.1.cmml" xref="S2.SS4.p3.1.m1.1.1"><times id="S2.SS4.p3.1.m1.1.1.2.cmml" xref="S2.SS4.p3.1.m1.1.1.2"></times><ci id="S2.SS4.p3.1.m1.1.1.3.cmml" xref="S2.SS4.p3.1.m1.1.1.3">𝑃</ci><apply id="S2.SS4.p3.1.m1.1.1.1.1.1.cmml" xref="S2.SS4.p3.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS4.p3.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS4.p3.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS4.p3.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS4.p3.1.m1.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS4.p3.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS4.p3.1.m1.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.1.m1.1c">P(y|x)</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.1.m1.1d">italic_P ( italic_y | italic_x )</annotation></semantics></math> given a dataset <math alttext="D" class="ltx_Math" display="inline" id="S2.SS4.p3.2.m2.1"><semantics id="S2.SS4.p3.2.m2.1a"><mi id="S2.SS4.p3.2.m2.1.1" xref="S2.SS4.p3.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.2.m2.1b"><ci id="S2.SS4.p3.2.m2.1.1.cmml" xref="S2.SS4.p3.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.2.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.2.m2.1d">italic_D</annotation></semantics></math>, where <math alttext="x" class="ltx_Math" display="inline" id="S2.SS4.p3.3.m3.1"><semantics id="S2.SS4.p3.3.m3.1a"><mi id="S2.SS4.p3.3.m3.1.1" xref="S2.SS4.p3.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.3.m3.1b"><ci id="S2.SS4.p3.3.m3.1.1.cmml" xref="S2.SS4.p3.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.3.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.3.m3.1d">italic_x</annotation></semantics></math> represents the source input sentence and <math alttext="y" class="ltx_Math" display="inline" id="S2.SS4.p3.4.m4.1"><semantics id="S2.SS4.p3.4.m4.1a"><mi id="S2.SS4.p3.4.m4.1.1" xref="S2.SS4.p3.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.4.m4.1b"><ci id="S2.SS4.p3.4.m4.1.1.cmml" xref="S2.SS4.p3.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.4.m4.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.4.m4.1d">italic_y</annotation></semantics></math> represents the target output sentence.</p>
</div>
<div class="ltx_para" id="S2.SS4.p4">
<p class="ltx_p" id="S2.SS4.p4.6">Supervised training of an NMT model develops the model weights by comparing the predicted <math alttext="P(y|x)" class="ltx_Math" display="inline" id="S2.SS4.p4.1.m1.1"><semantics id="S2.SS4.p4.1.m1.1a"><mrow id="S2.SS4.p4.1.m1.1.1" xref="S2.SS4.p4.1.m1.1.1.cmml"><mi id="S2.SS4.p4.1.m1.1.1.3" xref="S2.SS4.p4.1.m1.1.1.3.cmml">P</mi><mo id="S2.SS4.p4.1.m1.1.1.2" xref="S2.SS4.p4.1.m1.1.1.2.cmml">⁢</mo><mrow id="S2.SS4.p4.1.m1.1.1.1.1" xref="S2.SS4.p4.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS4.p4.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS4.p4.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS4.p4.1.m1.1.1.1.1.1" xref="S2.SS4.p4.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS4.p4.1.m1.1.1.1.1.1.2" xref="S2.SS4.p4.1.m1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS4.p4.1.m1.1.1.1.1.1.1" xref="S2.SS4.p4.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS4.p4.1.m1.1.1.1.1.1.3" xref="S2.SS4.p4.1.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.SS4.p4.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS4.p4.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.1.m1.1b"><apply id="S2.SS4.p4.1.m1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1"><times id="S2.SS4.p4.1.m1.1.1.2.cmml" xref="S2.SS4.p4.1.m1.1.1.2"></times><ci id="S2.SS4.p4.1.m1.1.1.3.cmml" xref="S2.SS4.p4.1.m1.1.1.3">𝑃</ci><apply id="S2.SS4.p4.1.m1.1.1.1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS4.p4.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS4.p4.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS4.p4.1.m1.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS4.p4.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS4.p4.1.m1.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.1.m1.1c">P(y|x)</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.1.m1.1d">italic_P ( italic_y | italic_x )</annotation></semantics></math> with the correct <math alttext="y" class="ltx_Math" display="inline" id="S2.SS4.p4.2.m2.1"><semantics id="S2.SS4.p4.2.m2.1a"><mi id="S2.SS4.p4.2.m2.1.1" xref="S2.SS4.p4.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.2.m2.1b"><ci id="S2.SS4.p4.2.m2.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.2.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.2.m2.1d">italic_y</annotation></semantics></math> sentences of the training dataset, <math alttext="D\textsubscript{Train}" class="ltx_Math" display="inline" id="S2.SS4.p4.3.m3.1"><semantics id="S2.SS4.p4.3.m3.1a"><mrow id="S2.SS4.p4.3.m3.1.1" xref="S2.SS4.p4.3.m3.1.1.cmml"><mi id="S2.SS4.p4.3.m3.1.1.2" xref="S2.SS4.p4.3.m3.1.1.2.cmml">D</mi><mo id="S2.SS4.p4.3.m3.1.1.1" xref="S2.SS4.p4.3.m3.1.1.1.cmml">⁢</mo><mtext id="S2.SS4.p4.3.m3.1.1.3" xref="S2.SS4.p4.3.m3.1.1.3b.cmml"><sub class="ltx_sub" id="S2.SS4.p4.3.m3.1.1.3.1nest">Train</sub></mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.3.m3.1b"><apply id="S2.SS4.p4.3.m3.1.1.cmml" xref="S2.SS4.p4.3.m3.1.1"><times id="S2.SS4.p4.3.m3.1.1.1.cmml" xref="S2.SS4.p4.3.m3.1.1.1"></times><ci id="S2.SS4.p4.3.m3.1.1.2.cmml" xref="S2.SS4.p4.3.m3.1.1.2">𝐷</ci><ci id="S2.SS4.p4.3.m3.1.1.3b.cmml" xref="S2.SS4.p4.3.m3.1.1.3"><mtext id="S2.SS4.p4.3.m3.1.1.3.cmml" xref="S2.SS4.p4.3.m3.1.1.3"><sub class="ltx_sub" id="S2.SS4.p4.3.m3.1.1.3.1anest">Train</sub></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.3.m3.1c">D\textsubscript{Train}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.3.m3.1d">italic_D</annotation></semantics></math>. In evaluating the performance of an NMT model, automatic evaluation results are determined when the predicted <math alttext="P(y|x)" class="ltx_Math" display="inline" id="S2.SS4.p4.4.m4.1"><semantics id="S2.SS4.p4.4.m4.1a"><mrow id="S2.SS4.p4.4.m4.1.1" xref="S2.SS4.p4.4.m4.1.1.cmml"><mi id="S2.SS4.p4.4.m4.1.1.3" xref="S2.SS4.p4.4.m4.1.1.3.cmml">P</mi><mo id="S2.SS4.p4.4.m4.1.1.2" xref="S2.SS4.p4.4.m4.1.1.2.cmml">⁢</mo><mrow id="S2.SS4.p4.4.m4.1.1.1.1" xref="S2.SS4.p4.4.m4.1.1.1.1.1.cmml"><mo id="S2.SS4.p4.4.m4.1.1.1.1.2" stretchy="false" xref="S2.SS4.p4.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS4.p4.4.m4.1.1.1.1.1" xref="S2.SS4.p4.4.m4.1.1.1.1.1.cmml"><mi id="S2.SS4.p4.4.m4.1.1.1.1.1.2" xref="S2.SS4.p4.4.m4.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS4.p4.4.m4.1.1.1.1.1.1" xref="S2.SS4.p4.4.m4.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS4.p4.4.m4.1.1.1.1.1.3" xref="S2.SS4.p4.4.m4.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.SS4.p4.4.m4.1.1.1.1.3" stretchy="false" xref="S2.SS4.p4.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.4.m4.1b"><apply id="S2.SS4.p4.4.m4.1.1.cmml" xref="S2.SS4.p4.4.m4.1.1"><times id="S2.SS4.p4.4.m4.1.1.2.cmml" xref="S2.SS4.p4.4.m4.1.1.2"></times><ci id="S2.SS4.p4.4.m4.1.1.3.cmml" xref="S2.SS4.p4.4.m4.1.1.3">𝑃</ci><apply id="S2.SS4.p4.4.m4.1.1.1.1.1.cmml" xref="S2.SS4.p4.4.m4.1.1.1.1"><csymbol cd="latexml" id="S2.SS4.p4.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS4.p4.4.m4.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS4.p4.4.m4.1.1.1.1.1.2.cmml" xref="S2.SS4.p4.4.m4.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS4.p4.4.m4.1.1.1.1.1.3.cmml" xref="S2.SS4.p4.4.m4.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.4.m4.1c">P(y|x)</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.4.m4.1d">italic_P ( italic_y | italic_x )</annotation></semantics></math> sentences are compared with the correct <math alttext="y" class="ltx_Math" display="inline" id="S2.SS4.p4.5.m5.1"><semantics id="S2.SS4.p4.5.m5.1a"><mi id="S2.SS4.p4.5.m5.1.1" xref="S2.SS4.p4.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.5.m5.1b"><ci id="S2.SS4.p4.5.m5.1.1.cmml" xref="S2.SS4.p4.5.m5.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.5.m5.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.5.m5.1d">italic_y</annotation></semantics></math> sentences of the test dataset, <math alttext="D\textsubscript{Test}" class="ltx_Math" display="inline" id="S2.SS4.p4.6.m6.1"><semantics id="S2.SS4.p4.6.m6.1a"><mrow id="S2.SS4.p4.6.m6.1.1" xref="S2.SS4.p4.6.m6.1.1.cmml"><mi id="S2.SS4.p4.6.m6.1.1.2" xref="S2.SS4.p4.6.m6.1.1.2.cmml">D</mi><mo id="S2.SS4.p4.6.m6.1.1.1" xref="S2.SS4.p4.6.m6.1.1.1.cmml">⁢</mo><mtext id="S2.SS4.p4.6.m6.1.1.3" xref="S2.SS4.p4.6.m6.1.1.3b.cmml"><sub class="ltx_sub" id="S2.SS4.p4.6.m6.1.1.3.1nest">Test</sub></mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.6.m6.1b"><apply id="S2.SS4.p4.6.m6.1.1.cmml" xref="S2.SS4.p4.6.m6.1.1"><times id="S2.SS4.p4.6.m6.1.1.1.cmml" xref="S2.SS4.p4.6.m6.1.1.1"></times><ci id="S2.SS4.p4.6.m6.1.1.2.cmml" xref="S2.SS4.p4.6.m6.1.1.2">𝐷</ci><ci id="S2.SS4.p4.6.m6.1.1.3b.cmml" xref="S2.SS4.p4.6.m6.1.1.3"><mtext id="S2.SS4.p4.6.m6.1.1.3.cmml" xref="S2.SS4.p4.6.m6.1.1.3"><sub class="ltx_sub" id="S2.SS4.p4.6.m6.1.1.3.1anest">Test</sub></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.6.m6.1c">D\textsubscript{Test}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.6.m6.1d">italic_D</annotation></semantics></math>.
</p>
</div>
<div class="ltx_para" id="S2.SS4.p5">
<p class="ltx_p" id="S2.SS4.p5.1">In adopting a deep learning paradigm, MT inherits the mathematical first principles which are inherent to this approach. To understand these principles, the manner in which neural networks model a conditional distribution is outlined. Furthermore, the encoder-decoder mechanism used for training NMT models is presented in the modelling subsection, and model optimization using training objectives is outlined in the learning subsection. Finally, the mathematics of how translated sentences are generated is explored in the inference subsection.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1 </span>Modelling</h4>
<div class="ltx_para" id="S2.SS4.SSS1.p1">
<p class="ltx_p" id="S2.SS4.SSS1.p1.2">In NMT, sentence-level translation is modelled using input and output sentences as sequences. Using this approach, an NMT model implements a sequence-to-sequence model with a given source sentence, <math alttext="x=(x_{1},...,x_{s})" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p1.1.m1.3"><semantics id="S2.SS4.SSS1.p1.1.m1.3a"><mrow id="S2.SS4.SSS1.p1.1.m1.3.3" xref="S2.SS4.SSS1.p1.1.m1.3.3.cmml"><mi id="S2.SS4.SSS1.p1.1.m1.3.3.4" xref="S2.SS4.SSS1.p1.1.m1.3.3.4.cmml">x</mi><mo id="S2.SS4.SSS1.p1.1.m1.3.3.3" xref="S2.SS4.SSS1.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S2.SS4.SSS1.p1.1.m1.3.3.2.2" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.3.cmml"><mo id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.3" stretchy="false" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.3.cmml">(</mo><msub id="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1" xref="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.2" xref="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.3" xref="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.4" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.3.cmml">,</mo><mi id="S2.SS4.SSS1.p1.1.m1.1.1" mathvariant="normal" xref="S2.SS4.SSS1.p1.1.m1.1.1.cmml">…</mi><mo id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.5" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.3.cmml">,</mo><msub id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.2" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.2.cmml">x</mi><mi id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.3" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.3.cmml">s</mi></msub><mo id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.6" stretchy="false" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.1.m1.3b"><apply id="S2.SS4.SSS1.p1.1.m1.3.3.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3"><eq id="S2.SS4.SSS1.p1.1.m1.3.3.3.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3.3"></eq><ci id="S2.SS4.SSS1.p1.1.m1.3.3.4.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3.4">𝑥</ci><vector id="S2.SS4.SSS1.p1.1.m1.3.3.2.3.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2"><apply id="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.2">𝑥</ci><cn id="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS4.SSS1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S2.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1">…</ci><apply id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.2">𝑥</ci><ci id="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.3.cmml" xref="S2.SS4.SSS1.p1.1.m1.3.3.2.2.2.3">𝑠</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.1.m1.3c">x=(x_{1},...,x_{s})</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p1.1.m1.3d">italic_x = ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT )</annotation></semantics></math> generating a target sentence <math alttext="y=(y_{1},...,y_{t})" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p1.2.m2.3"><semantics id="S2.SS4.SSS1.p1.2.m2.3a"><mrow id="S2.SS4.SSS1.p1.2.m2.3.3" xref="S2.SS4.SSS1.p1.2.m2.3.3.cmml"><mi id="S2.SS4.SSS1.p1.2.m2.3.3.4" xref="S2.SS4.SSS1.p1.2.m2.3.3.4.cmml">y</mi><mo id="S2.SS4.SSS1.p1.2.m2.3.3.3" xref="S2.SS4.SSS1.p1.2.m2.3.3.3.cmml">=</mo><mrow id="S2.SS4.SSS1.p1.2.m2.3.3.2.2" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.3.cmml"><mo id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.3" stretchy="false" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.3.cmml">(</mo><msub id="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1" xref="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.cmml"><mi id="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.2" xref="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.2.cmml">y</mi><mn id="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.3" xref="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.4" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.3.cmml">,</mo><mi id="S2.SS4.SSS1.p1.2.m2.1.1" mathvariant="normal" xref="S2.SS4.SSS1.p1.2.m2.1.1.cmml">…</mi><mo id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.5" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.3.cmml">,</mo><msub id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.cmml"><mi id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.2" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.2.cmml">y</mi><mi id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.3" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.3.cmml">t</mi></msub><mo id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.6" stretchy="false" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.2.m2.3b"><apply id="S2.SS4.SSS1.p1.2.m2.3.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3"><eq id="S2.SS4.SSS1.p1.2.m2.3.3.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3.3"></eq><ci id="S2.SS4.SSS1.p1.2.m2.3.3.4.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3.4">𝑦</ci><vector id="S2.SS4.SSS1.p1.2.m2.3.3.2.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2"><apply id="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.2">𝑦</ci><cn id="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS4.SSS1.p1.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S2.SS4.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1">…</ci><apply id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.2">𝑦</ci><ci id="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.3.3.2.2.2.3">𝑡</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.2.m2.3c">y=(y_{1},...,y_{t})</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p1.2.m2.3d">italic_y = ( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p2">
<p class="ltx_p" id="S2.SS4.SSS1.p2.2">In effect, such a sequence-to-sequence NMT model acts as a conditional language model. The decoder within the model predicts the next word of the target sentence <math alttext="y" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p2.1.m1.1"><semantics id="S2.SS4.SSS1.p2.1.m1.1a"><mi id="S2.SS4.SSS1.p2.1.m1.1.1" xref="S2.SS4.SSS1.p2.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.1.m1.1b"><ci id="S2.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p2.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p2.1.m1.1d">italic_y</annotation></semantics></math>, while such predictions are conditioned on the source sentence <math alttext="x" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p2.2.m2.1"><semantics id="S2.SS4.SSS1.p2.2.m2.1a"><mi id="S2.SS4.SSS1.p2.2.m2.1.1" xref="S2.SS4.SSS1.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.2.m2.1b"><ci id="S2.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p2.2.m2.1d">italic_x</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p3">
<p class="ltx_p" id="S2.SS4.SSS1.p3.3">By applying the chain rule, a model’s prediction (i.e. translation <math alttext="y" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p3.1.m1.1"><semantics id="S2.SS4.SSS1.p3.1.m1.1a"><mi id="S2.SS4.SSS1.p3.1.m1.1.1" xref="S2.SS4.SSS1.p3.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p3.1.m1.1b"><ci id="S2.SS4.SSS1.p3.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p3.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p3.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p3.1.m1.1d">italic_y</annotation></semantics></math> of length <math alttext="T" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p3.2.m2.1"><semantics id="S2.SS4.SSS1.p3.2.m2.1a"><mi id="S2.SS4.SSS1.p3.2.m2.1.1" xref="S2.SS4.SSS1.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p3.2.m2.1b"><ci id="S2.SS4.SSS1.p3.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p3.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p3.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p3.2.m2.1d">italic_T</annotation></semantics></math>) maximizes the probability <math alttext="P(y|x)" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p3.3.m3.1"><semantics id="S2.SS4.SSS1.p3.3.m3.1a"><mrow id="S2.SS4.SSS1.p3.3.m3.1.1" xref="S2.SS4.SSS1.p3.3.m3.1.1.cmml"><mi id="S2.SS4.SSS1.p3.3.m3.1.1.3" xref="S2.SS4.SSS1.p3.3.m3.1.1.3.cmml">P</mi><mo id="S2.SS4.SSS1.p3.3.m3.1.1.2" xref="S2.SS4.SSS1.p3.3.m3.1.1.2.cmml">⁢</mo><mrow id="S2.SS4.SSS1.p3.3.m3.1.1.1.1" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.cmml"><mo id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.2" stretchy="false" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.2" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.1" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.3" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.3" stretchy="false" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p3.3.m3.1b"><apply id="S2.SS4.SSS1.p3.3.m3.1.1.cmml" xref="S2.SS4.SSS1.p3.3.m3.1.1"><times id="S2.SS4.SSS1.p3.3.m3.1.1.2.cmml" xref="S2.SS4.SSS1.p3.3.m3.1.1.2"></times><ci id="S2.SS4.SSS1.p3.3.m3.1.1.3.cmml" xref="S2.SS4.SSS1.p3.3.m3.1.1.3">𝑃</ci><apply id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.cmml" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1"><csymbol cd="latexml" id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS4.SSS1.p3.3.m3.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p3.3.m3.1c">P(y|x)</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p3.3.m3.1d">italic_P ( italic_y | italic_x )</annotation></semantics></math> identified in Equations (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E2" title="2 ‣ 2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>) and (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E3" title="3 ‣ 2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>):</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p4">
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(y|x)=P(y_{1}|x)P(y_{2}|y_{1},x)P(y_{3}|y_{1},y_{2},x)P(y_{T}|y_{1},...,y_{T-%
1},x)" class="ltx_Math" display="block" id="S2.E2.m1.9"><semantics id="S2.E2.m1.9a"><mrow id="S2.E2.m1.9.9" xref="S2.E2.m1.9.9.cmml"><mrow id="S2.E2.m1.5.5.1" xref="S2.E2.m1.5.5.1.cmml"><mi id="S2.E2.m1.5.5.1.3" xref="S2.E2.m1.5.5.1.3.cmml">P</mi><mo id="S2.E2.m1.5.5.1.2" xref="S2.E2.m1.5.5.1.2.cmml">⁢</mo><mrow id="S2.E2.m1.5.5.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.cmml"><mo id="S2.E2.m1.5.5.1.1.1.2" stretchy="false" xref="S2.E2.m1.5.5.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.5.5.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.cmml"><mi id="S2.E2.m1.5.5.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.E2.m1.5.5.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.cmml">|</mo><mi id="S2.E2.m1.5.5.1.1.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.E2.m1.5.5.1.1.1.3" stretchy="false" xref="S2.E2.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.9.9.6" xref="S2.E2.m1.9.9.6.cmml">=</mo><mrow id="S2.E2.m1.9.9.5" xref="S2.E2.m1.9.9.5.cmml"><mi id="S2.E2.m1.9.9.5.6" xref="S2.E2.m1.9.9.5.6.cmml">P</mi><mo id="S2.E2.m1.9.9.5.5" xref="S2.E2.m1.9.9.5.5.cmml">⁢</mo><mrow id="S2.E2.m1.6.6.2.1.1" xref="S2.E2.m1.6.6.2.1.1.1.cmml"><mo id="S2.E2.m1.6.6.2.1.1.2" stretchy="false" xref="S2.E2.m1.6.6.2.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.6.6.2.1.1.1" xref="S2.E2.m1.6.6.2.1.1.1.cmml"><msub id="S2.E2.m1.6.6.2.1.1.1.2" xref="S2.E2.m1.6.6.2.1.1.1.2.cmml"><mi id="S2.E2.m1.6.6.2.1.1.1.2.2" xref="S2.E2.m1.6.6.2.1.1.1.2.2.cmml">y</mi><mn id="S2.E2.m1.6.6.2.1.1.1.2.3" xref="S2.E2.m1.6.6.2.1.1.1.2.3.cmml">1</mn></msub><mo fence="false" id="S2.E2.m1.6.6.2.1.1.1.1" xref="S2.E2.m1.6.6.2.1.1.1.1.cmml">|</mo><mi id="S2.E2.m1.6.6.2.1.1.1.3" xref="S2.E2.m1.6.6.2.1.1.1.3.cmml">x</mi></mrow><mo id="S2.E2.m1.6.6.2.1.1.3" stretchy="false" xref="S2.E2.m1.6.6.2.1.1.1.cmml">)</mo></mrow><mo id="S2.E2.m1.9.9.5.5a" xref="S2.E2.m1.9.9.5.5.cmml">⁢</mo><mi id="S2.E2.m1.9.9.5.7" xref="S2.E2.m1.9.9.5.7.cmml">P</mi><mo id="S2.E2.m1.9.9.5.5b" xref="S2.E2.m1.9.9.5.5.cmml">⁢</mo><mrow id="S2.E2.m1.7.7.3.2.1" xref="S2.E2.m1.7.7.3.2.1.1.cmml"><mo id="S2.E2.m1.7.7.3.2.1.2" stretchy="false" xref="S2.E2.m1.7.7.3.2.1.1.cmml">(</mo><mrow id="S2.E2.m1.7.7.3.2.1.1" xref="S2.E2.m1.7.7.3.2.1.1.cmml"><msub id="S2.E2.m1.7.7.3.2.1.1.3" xref="S2.E2.m1.7.7.3.2.1.1.3.cmml"><mi id="S2.E2.m1.7.7.3.2.1.1.3.2" xref="S2.E2.m1.7.7.3.2.1.1.3.2.cmml">y</mi><mn id="S2.E2.m1.7.7.3.2.1.1.3.3" xref="S2.E2.m1.7.7.3.2.1.1.3.3.cmml">2</mn></msub><mo fence="false" id="S2.E2.m1.7.7.3.2.1.1.2" xref="S2.E2.m1.7.7.3.2.1.1.2.cmml">|</mo><mrow id="S2.E2.m1.7.7.3.2.1.1.1.1" xref="S2.E2.m1.7.7.3.2.1.1.1.2.cmml"><msub id="S2.E2.m1.7.7.3.2.1.1.1.1.1" xref="S2.E2.m1.7.7.3.2.1.1.1.1.1.cmml"><mi id="S2.E2.m1.7.7.3.2.1.1.1.1.1.2" xref="S2.E2.m1.7.7.3.2.1.1.1.1.1.2.cmml">y</mi><mn id="S2.E2.m1.7.7.3.2.1.1.1.1.1.3" xref="S2.E2.m1.7.7.3.2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2.m1.7.7.3.2.1.1.1.1.2" xref="S2.E2.m1.7.7.3.2.1.1.1.2.cmml">,</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">x</mi></mrow></mrow><mo id="S2.E2.m1.7.7.3.2.1.3" stretchy="false" xref="S2.E2.m1.7.7.3.2.1.1.cmml">)</mo></mrow><mo id="S2.E2.m1.9.9.5.5c" xref="S2.E2.m1.9.9.5.5.cmml">⁢</mo><mi id="S2.E2.m1.9.9.5.8" xref="S2.E2.m1.9.9.5.8.cmml">P</mi><mo id="S2.E2.m1.9.9.5.5d" xref="S2.E2.m1.9.9.5.5.cmml">⁢</mo><mrow id="S2.E2.m1.8.8.4.3.1" xref="S2.E2.m1.8.8.4.3.1.1.cmml"><mo id="S2.E2.m1.8.8.4.3.1.2" stretchy="false" xref="S2.E2.m1.8.8.4.3.1.1.cmml">(</mo><mrow id="S2.E2.m1.8.8.4.3.1.1" xref="S2.E2.m1.8.8.4.3.1.1.cmml"><msub id="S2.E2.m1.8.8.4.3.1.1.4" xref="S2.E2.m1.8.8.4.3.1.1.4.cmml"><mi id="S2.E2.m1.8.8.4.3.1.1.4.2" xref="S2.E2.m1.8.8.4.3.1.1.4.2.cmml">y</mi><mn id="S2.E2.m1.8.8.4.3.1.1.4.3" xref="S2.E2.m1.8.8.4.3.1.1.4.3.cmml">3</mn></msub><mo fence="false" id="S2.E2.m1.8.8.4.3.1.1.3" xref="S2.E2.m1.8.8.4.3.1.1.3.cmml">|</mo><mrow id="S2.E2.m1.8.8.4.3.1.1.2.2" xref="S2.E2.m1.8.8.4.3.1.1.2.3.cmml"><msub id="S2.E2.m1.8.8.4.3.1.1.1.1.1" xref="S2.E2.m1.8.8.4.3.1.1.1.1.1.cmml"><mi id="S2.E2.m1.8.8.4.3.1.1.1.1.1.2" xref="S2.E2.m1.8.8.4.3.1.1.1.1.1.2.cmml">y</mi><mn id="S2.E2.m1.8.8.4.3.1.1.1.1.1.3" xref="S2.E2.m1.8.8.4.3.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2.m1.8.8.4.3.1.1.2.2.3" xref="S2.E2.m1.8.8.4.3.1.1.2.3.cmml">,</mo><msub id="S2.E2.m1.8.8.4.3.1.1.2.2.2" xref="S2.E2.m1.8.8.4.3.1.1.2.2.2.cmml"><mi id="S2.E2.m1.8.8.4.3.1.1.2.2.2.2" xref="S2.E2.m1.8.8.4.3.1.1.2.2.2.2.cmml">y</mi><mn id="S2.E2.m1.8.8.4.3.1.1.2.2.2.3" xref="S2.E2.m1.8.8.4.3.1.1.2.2.2.3.cmml">2</mn></msub><mo id="S2.E2.m1.8.8.4.3.1.1.2.2.4" xref="S2.E2.m1.8.8.4.3.1.1.2.3.cmml">,</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">x</mi></mrow></mrow><mo id="S2.E2.m1.8.8.4.3.1.3" stretchy="false" xref="S2.E2.m1.8.8.4.3.1.1.cmml">)</mo></mrow><mo id="S2.E2.m1.9.9.5.5e" xref="S2.E2.m1.9.9.5.5.cmml">⁢</mo><mi id="S2.E2.m1.9.9.5.9" xref="S2.E2.m1.9.9.5.9.cmml">P</mi><mo id="S2.E2.m1.9.9.5.5f" xref="S2.E2.m1.9.9.5.5.cmml">⁢</mo><mrow id="S2.E2.m1.9.9.5.4.1" xref="S2.E2.m1.9.9.5.4.1.1.cmml"><mo id="S2.E2.m1.9.9.5.4.1.2" stretchy="false" xref="S2.E2.m1.9.9.5.4.1.1.cmml">(</mo><mrow id="S2.E2.m1.9.9.5.4.1.1" xref="S2.E2.m1.9.9.5.4.1.1.cmml"><msub id="S2.E2.m1.9.9.5.4.1.1.4" xref="S2.E2.m1.9.9.5.4.1.1.4.cmml"><mi id="S2.E2.m1.9.9.5.4.1.1.4.2" xref="S2.E2.m1.9.9.5.4.1.1.4.2.cmml">y</mi><mi id="S2.E2.m1.9.9.5.4.1.1.4.3" xref="S2.E2.m1.9.9.5.4.1.1.4.3.cmml">T</mi></msub><mo fence="false" id="S2.E2.m1.9.9.5.4.1.1.3" xref="S2.E2.m1.9.9.5.4.1.1.3.cmml">|</mo><mrow id="S2.E2.m1.9.9.5.4.1.1.2.2" xref="S2.E2.m1.9.9.5.4.1.1.2.3.cmml"><msub id="S2.E2.m1.9.9.5.4.1.1.1.1.1" xref="S2.E2.m1.9.9.5.4.1.1.1.1.1.cmml"><mi id="S2.E2.m1.9.9.5.4.1.1.1.1.1.2" xref="S2.E2.m1.9.9.5.4.1.1.1.1.1.2.cmml">y</mi><mn id="S2.E2.m1.9.9.5.4.1.1.1.1.1.3" xref="S2.E2.m1.9.9.5.4.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2.m1.9.9.5.4.1.1.2.2.3" xref="S2.E2.m1.9.9.5.4.1.1.2.3.cmml">,</mo><mi id="S2.E2.m1.3.3" mathvariant="normal" xref="S2.E2.m1.3.3.cmml">…</mi><mo id="S2.E2.m1.9.9.5.4.1.1.2.2.4" xref="S2.E2.m1.9.9.5.4.1.1.2.3.cmml">,</mo><msub id="S2.E2.m1.9.9.5.4.1.1.2.2.2" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.cmml"><mi id="S2.E2.m1.9.9.5.4.1.1.2.2.2.2" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.2.cmml">y</mi><mrow id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.cmml"><mi id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.2" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.2.cmml">T</mi><mo id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.1" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.1.cmml">−</mo><mn id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.3" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.E2.m1.9.9.5.4.1.1.2.2.5" xref="S2.E2.m1.9.9.5.4.1.1.2.3.cmml">,</mo><mi id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml">x</mi></mrow></mrow><mo id="S2.E2.m1.9.9.5.4.1.3" stretchy="false" xref="S2.E2.m1.9.9.5.4.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.9b"><apply id="S2.E2.m1.9.9.cmml" xref="S2.E2.m1.9.9"><eq id="S2.E2.m1.9.9.6.cmml" xref="S2.E2.m1.9.9.6"></eq><apply id="S2.E2.m1.5.5.1.cmml" xref="S2.E2.m1.5.5.1"><times id="S2.E2.m1.5.5.1.2.cmml" xref="S2.E2.m1.5.5.1.2"></times><ci id="S2.E2.m1.5.5.1.3.cmml" xref="S2.E2.m1.5.5.1.3">𝑃</ci><apply id="S2.E2.m1.5.5.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.5.5.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1">conditional</csymbol><ci id="S2.E2.m1.5.5.1.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2">𝑦</ci><ci id="S2.E2.m1.5.5.1.1.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S2.E2.m1.9.9.5.cmml" xref="S2.E2.m1.9.9.5"><times id="S2.E2.m1.9.9.5.5.cmml" xref="S2.E2.m1.9.9.5.5"></times><ci id="S2.E2.m1.9.9.5.6.cmml" xref="S2.E2.m1.9.9.5.6">𝑃</ci><apply id="S2.E2.m1.6.6.2.1.1.1.cmml" xref="S2.E2.m1.6.6.2.1.1"><csymbol cd="latexml" id="S2.E2.m1.6.6.2.1.1.1.1.cmml" xref="S2.E2.m1.6.6.2.1.1.1.1">conditional</csymbol><apply id="S2.E2.m1.6.6.2.1.1.1.2.cmml" xref="S2.E2.m1.6.6.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.6.6.2.1.1.1.2.1.cmml" xref="S2.E2.m1.6.6.2.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.6.6.2.1.1.1.2.2.cmml" xref="S2.E2.m1.6.6.2.1.1.1.2.2">𝑦</ci><cn id="S2.E2.m1.6.6.2.1.1.1.2.3.cmml" type="integer" xref="S2.E2.m1.6.6.2.1.1.1.2.3">1</cn></apply><ci id="S2.E2.m1.6.6.2.1.1.1.3.cmml" xref="S2.E2.m1.6.6.2.1.1.1.3">𝑥</ci></apply><ci id="S2.E2.m1.9.9.5.7.cmml" xref="S2.E2.m1.9.9.5.7">𝑃</ci><apply id="S2.E2.m1.7.7.3.2.1.1.cmml" xref="S2.E2.m1.7.7.3.2.1"><csymbol cd="latexml" id="S2.E2.m1.7.7.3.2.1.1.2.cmml" xref="S2.E2.m1.7.7.3.2.1.1.2">conditional</csymbol><apply id="S2.E2.m1.7.7.3.2.1.1.3.cmml" xref="S2.E2.m1.7.7.3.2.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.3.2.1.1.3.1.cmml" xref="S2.E2.m1.7.7.3.2.1.1.3">subscript</csymbol><ci id="S2.E2.m1.7.7.3.2.1.1.3.2.cmml" xref="S2.E2.m1.7.7.3.2.1.1.3.2">𝑦</ci><cn id="S2.E2.m1.7.7.3.2.1.1.3.3.cmml" type="integer" xref="S2.E2.m1.7.7.3.2.1.1.3.3">2</cn></apply><list id="S2.E2.m1.7.7.3.2.1.1.1.2.cmml" xref="S2.E2.m1.7.7.3.2.1.1.1.1"><apply id="S2.E2.m1.7.7.3.2.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.3.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.3.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.3.2.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.7.7.3.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.3.2.1.1.1.1.1.2">𝑦</ci><cn id="S2.E2.m1.7.7.3.2.1.1.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.7.7.3.2.1.1.1.1.1.3">1</cn></apply><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝑥</ci></list></apply><ci id="S2.E2.m1.9.9.5.8.cmml" xref="S2.E2.m1.9.9.5.8">𝑃</ci><apply id="S2.E2.m1.8.8.4.3.1.1.cmml" xref="S2.E2.m1.8.8.4.3.1"><csymbol cd="latexml" id="S2.E2.m1.8.8.4.3.1.1.3.cmml" xref="S2.E2.m1.8.8.4.3.1.1.3">conditional</csymbol><apply id="S2.E2.m1.8.8.4.3.1.1.4.cmml" xref="S2.E2.m1.8.8.4.3.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.8.8.4.3.1.1.4.1.cmml" xref="S2.E2.m1.8.8.4.3.1.1.4">subscript</csymbol><ci id="S2.E2.m1.8.8.4.3.1.1.4.2.cmml" xref="S2.E2.m1.8.8.4.3.1.1.4.2">𝑦</ci><cn id="S2.E2.m1.8.8.4.3.1.1.4.3.cmml" type="integer" xref="S2.E2.m1.8.8.4.3.1.1.4.3">3</cn></apply><list id="S2.E2.m1.8.8.4.3.1.1.2.3.cmml" xref="S2.E2.m1.8.8.4.3.1.1.2.2"><apply id="S2.E2.m1.8.8.4.3.1.1.1.1.1.cmml" xref="S2.E2.m1.8.8.4.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.8.8.4.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.8.8.4.3.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.8.8.4.3.1.1.1.1.1.2.cmml" xref="S2.E2.m1.8.8.4.3.1.1.1.1.1.2">𝑦</ci><cn id="S2.E2.m1.8.8.4.3.1.1.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.8.8.4.3.1.1.1.1.1.3">1</cn></apply><apply id="S2.E2.m1.8.8.4.3.1.1.2.2.2.cmml" xref="S2.E2.m1.8.8.4.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.8.8.4.3.1.1.2.2.2.1.cmml" xref="S2.E2.m1.8.8.4.3.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.8.8.4.3.1.1.2.2.2.2.cmml" xref="S2.E2.m1.8.8.4.3.1.1.2.2.2.2">𝑦</ci><cn id="S2.E2.m1.8.8.4.3.1.1.2.2.2.3.cmml" type="integer" xref="S2.E2.m1.8.8.4.3.1.1.2.2.2.3">2</cn></apply><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">𝑥</ci></list></apply><ci id="S2.E2.m1.9.9.5.9.cmml" xref="S2.E2.m1.9.9.5.9">𝑃</ci><apply id="S2.E2.m1.9.9.5.4.1.1.cmml" xref="S2.E2.m1.9.9.5.4.1"><csymbol cd="latexml" id="S2.E2.m1.9.9.5.4.1.1.3.cmml" xref="S2.E2.m1.9.9.5.4.1.1.3">conditional</csymbol><apply id="S2.E2.m1.9.9.5.4.1.1.4.cmml" xref="S2.E2.m1.9.9.5.4.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.5.4.1.1.4.1.cmml" xref="S2.E2.m1.9.9.5.4.1.1.4">subscript</csymbol><ci id="S2.E2.m1.9.9.5.4.1.1.4.2.cmml" xref="S2.E2.m1.9.9.5.4.1.1.4.2">𝑦</ci><ci id="S2.E2.m1.9.9.5.4.1.1.4.3.cmml" xref="S2.E2.m1.9.9.5.4.1.1.4.3">𝑇</ci></apply><list id="S2.E2.m1.9.9.5.4.1.1.2.3.cmml" xref="S2.E2.m1.9.9.5.4.1.1.2.2"><apply id="S2.E2.m1.9.9.5.4.1.1.1.1.1.cmml" xref="S2.E2.m1.9.9.5.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.5.4.1.1.1.1.1.1.cmml" xref="S2.E2.m1.9.9.5.4.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.9.9.5.4.1.1.1.1.1.2.cmml" xref="S2.E2.m1.9.9.5.4.1.1.1.1.1.2">𝑦</ci><cn id="S2.E2.m1.9.9.5.4.1.1.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.9.9.5.4.1.1.1.1.1.3">1</cn></apply><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">…</ci><apply id="S2.E2.m1.9.9.5.4.1.1.2.2.2.cmml" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.5.4.1.1.2.2.2.1.cmml" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.9.9.5.4.1.1.2.2.2.2.cmml" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.2">𝑦</ci><apply id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.cmml" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3"><minus id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.1.cmml" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.1"></minus><ci id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.2.cmml" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.2">𝑇</ci><cn id="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.3.cmml" type="integer" xref="S2.E2.m1.9.9.5.4.1.1.2.2.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4">𝑥</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.9c">P(y|x)=P(y_{1}|x)P(y_{2}|y_{1},x)P(y_{3}|y_{1},y_{2},x)P(y_{T}|y_{1},...,y_{T-%
1},x)</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.9d">italic_P ( italic_y | italic_x ) = italic_P ( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | italic_x ) italic_P ( italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x ) italic_P ( italic_y start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x ) italic_P ( italic_y start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT | italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_y start_POSTSUBSCRIPT italic_T - 1 end_POSTSUBSCRIPT , italic_x )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p5">
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(y|x)=\prod_{t=1}^{T}P(y_{t}|y_{1},...,y_{T-1},x)" class="ltx_Math" display="block" id="S2.E3.m1.4"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><mrow id="S2.E3.m1.3.3.1" xref="S2.E3.m1.3.3.1.cmml"><mi id="S2.E3.m1.3.3.1.3" xref="S2.E3.m1.3.3.1.3.cmml">P</mi><mo id="S2.E3.m1.3.3.1.2" xref="S2.E3.m1.3.3.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.cmml"><mo id="S2.E3.m1.3.3.1.1.1.2" stretchy="false" xref="S2.E3.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.3.3.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.cmml"><mi id="S2.E3.m1.3.3.1.1.1.1.2" xref="S2.E3.m1.3.3.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.E3.m1.3.3.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.cmml">|</mo><mi id="S2.E3.m1.3.3.1.1.1.1.3" xref="S2.E3.m1.3.3.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.E3.m1.3.3.1.1.1.3" stretchy="false" xref="S2.E3.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.3" rspace="0.111em" xref="S2.E3.m1.4.4.3.cmml">=</mo><mrow id="S2.E3.m1.4.4.2" xref="S2.E3.m1.4.4.2.cmml"><munderover id="S2.E3.m1.4.4.2.2" xref="S2.E3.m1.4.4.2.2.cmml"><mo id="S2.E3.m1.4.4.2.2.2.2" movablelimits="false" xref="S2.E3.m1.4.4.2.2.2.2.cmml">∏</mo><mrow id="S2.E3.m1.4.4.2.2.2.3" xref="S2.E3.m1.4.4.2.2.2.3.cmml"><mi id="S2.E3.m1.4.4.2.2.2.3.2" xref="S2.E3.m1.4.4.2.2.2.3.2.cmml">t</mi><mo id="S2.E3.m1.4.4.2.2.2.3.1" xref="S2.E3.m1.4.4.2.2.2.3.1.cmml">=</mo><mn id="S2.E3.m1.4.4.2.2.2.3.3" xref="S2.E3.m1.4.4.2.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E3.m1.4.4.2.2.3" xref="S2.E3.m1.4.4.2.2.3.cmml">T</mi></munderover><mrow id="S2.E3.m1.4.4.2.1" xref="S2.E3.m1.4.4.2.1.cmml"><mi id="S2.E3.m1.4.4.2.1.3" xref="S2.E3.m1.4.4.2.1.3.cmml">P</mi><mo id="S2.E3.m1.4.4.2.1.2" xref="S2.E3.m1.4.4.2.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.4.4.2.1.1.1" xref="S2.E3.m1.4.4.2.1.1.1.1.cmml"><mo id="S2.E3.m1.4.4.2.1.1.1.2" stretchy="false" xref="S2.E3.m1.4.4.2.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.4.4.2.1.1.1.1" xref="S2.E3.m1.4.4.2.1.1.1.1.cmml"><msub id="S2.E3.m1.4.4.2.1.1.1.1.4" xref="S2.E3.m1.4.4.2.1.1.1.1.4.cmml"><mi id="S2.E3.m1.4.4.2.1.1.1.1.4.2" xref="S2.E3.m1.4.4.2.1.1.1.1.4.2.cmml">y</mi><mi id="S2.E3.m1.4.4.2.1.1.1.1.4.3" xref="S2.E3.m1.4.4.2.1.1.1.1.4.3.cmml">t</mi></msub><mo fence="false" id="S2.E3.m1.4.4.2.1.1.1.1.3" xref="S2.E3.m1.4.4.2.1.1.1.1.3.cmml">|</mo><mrow id="S2.E3.m1.4.4.2.1.1.1.1.2.2" xref="S2.E3.m1.4.4.2.1.1.1.1.2.3.cmml"><msub id="S2.E3.m1.4.4.2.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.2.cmml">y</mi><mn id="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E3.m1.4.4.2.1.1.1.1.2.2.3" xref="S2.E3.m1.4.4.2.1.1.1.1.2.3.cmml">,</mo><mi id="S2.E3.m1.1.1" mathvariant="normal" xref="S2.E3.m1.1.1.cmml">…</mi><mo id="S2.E3.m1.4.4.2.1.1.1.1.2.2.4" xref="S2.E3.m1.4.4.2.1.1.1.1.2.3.cmml">,</mo><msub id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.cmml"><mi id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.2" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.2.cmml">y</mi><mrow id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.cmml"><mi id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.2" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.2.cmml">T</mi><mo id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.1" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.3" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.E3.m1.4.4.2.1.1.1.1.2.2.5" xref="S2.E3.m1.4.4.2.1.1.1.1.2.3.cmml">,</mo><mi id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml">x</mi></mrow></mrow><mo id="S2.E3.m1.4.4.2.1.1.1.3" stretchy="false" xref="S2.E3.m1.4.4.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4"><eq id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3"></eq><apply id="S2.E3.m1.3.3.1.cmml" xref="S2.E3.m1.3.3.1"><times id="S2.E3.m1.3.3.1.2.cmml" xref="S2.E3.m1.3.3.1.2"></times><ci id="S2.E3.m1.3.3.1.3.cmml" xref="S2.E3.m1.3.3.1.3">𝑃</ci><apply id="S2.E3.m1.3.3.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.3.3.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1">conditional</csymbol><ci id="S2.E3.m1.3.3.1.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.2">𝑦</ci><ci id="S2.E3.m1.3.3.1.1.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S2.E3.m1.4.4.2.cmml" xref="S2.E3.m1.4.4.2"><apply id="S2.E3.m1.4.4.2.2.cmml" xref="S2.E3.m1.4.4.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.2.2.1.cmml" xref="S2.E3.m1.4.4.2.2">superscript</csymbol><apply id="S2.E3.m1.4.4.2.2.2.cmml" xref="S2.E3.m1.4.4.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.2.2.2.1.cmml" xref="S2.E3.m1.4.4.2.2">subscript</csymbol><csymbol cd="latexml" id="S2.E3.m1.4.4.2.2.2.2.cmml" xref="S2.E3.m1.4.4.2.2.2.2">product</csymbol><apply id="S2.E3.m1.4.4.2.2.2.3.cmml" xref="S2.E3.m1.4.4.2.2.2.3"><eq id="S2.E3.m1.4.4.2.2.2.3.1.cmml" xref="S2.E3.m1.4.4.2.2.2.3.1"></eq><ci id="S2.E3.m1.4.4.2.2.2.3.2.cmml" xref="S2.E3.m1.4.4.2.2.2.3.2">𝑡</ci><cn id="S2.E3.m1.4.4.2.2.2.3.3.cmml" type="integer" xref="S2.E3.m1.4.4.2.2.2.3.3">1</cn></apply></apply><ci id="S2.E3.m1.4.4.2.2.3.cmml" xref="S2.E3.m1.4.4.2.2.3">𝑇</ci></apply><apply id="S2.E3.m1.4.4.2.1.cmml" xref="S2.E3.m1.4.4.2.1"><times id="S2.E3.m1.4.4.2.1.2.cmml" xref="S2.E3.m1.4.4.2.1.2"></times><ci id="S2.E3.m1.4.4.2.1.3.cmml" xref="S2.E3.m1.4.4.2.1.3">𝑃</ci><apply id="S2.E3.m1.4.4.2.1.1.1.1.cmml" xref="S2.E3.m1.4.4.2.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.2.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.3">conditional</csymbol><apply id="S2.E3.m1.4.4.2.1.1.1.1.4.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.2.1.1.1.1.4.1.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.4">subscript</csymbol><ci id="S2.E3.m1.4.4.2.1.1.1.1.4.2.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.4.2">𝑦</ci><ci id="S2.E3.m1.4.4.2.1.1.1.1.4.3.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.4.3">𝑡</ci></apply><list id="S2.E3.m1.4.4.2.1.1.1.1.2.3.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2"><apply id="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.2">𝑦</ci><cn id="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E3.m1.4.4.2.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">…</ci><apply id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.2">𝑦</ci><apply id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3"><minus id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.1.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.1"></minus><ci id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.2.cmml" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.2">𝑇</ci><cn id="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.3.cmml" type="integer" xref="S2.E3.m1.4.4.2.1.1.1.1.2.2.2.3.3">1</cn></apply></apply><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">𝑥</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">P(y|x)=\prod_{t=1}^{T}P(y_{t}|y_{1},...,y_{T-1},x)</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.4d">italic_P ( italic_y | italic_x ) = ∏ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_P ( italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_y start_POSTSUBSCRIPT italic_T - 1 end_POSTSUBSCRIPT , italic_x )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p6">
<p class="ltx_p" id="S2.SS4.SSS1.p6.1">Prior to Transformer, encoder-decoder models that incorporate RNNs were the most common method of representing text sequences in NMT. RNNs are networks which accumulate information composed of similar units repeated over time. In NMT, a primary function of the RNN encoder is that it encodes text, i.e. it turns text into a numeric representation. Neurons within an RNN are illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.F3" title="Figure 3 ‣ 2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="128" id="S2.F3.g1" src="extracted/5447326/neurons.png" width="314"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F3.10.5.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S2.F3.8.4" style="font-size:80%;">Neurons within an RNN. At the input side, the neuron’s input at time <math alttext="t" class="ltx_Math" display="inline" id="S2.F3.5.1.m1.1"><semantics id="S2.F3.5.1.m1.1b"><mi id="S2.F3.5.1.m1.1.1" xref="S2.F3.5.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.F3.5.1.m1.1c"><ci id="S2.F3.5.1.m1.1.1.cmml" xref="S2.F3.5.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.5.1.m1.1d">t</annotation><annotation encoding="application/x-llamapun" id="S2.F3.5.1.m1.1e">italic_t</annotation></semantics></math> is a function of the encoded word (i.e. input vector <math alttext="x_{t}" class="ltx_Math" display="inline" id="S2.F3.6.2.m2.1"><semantics id="S2.F3.6.2.m2.1b"><msub id="S2.F3.6.2.m2.1.1" xref="S2.F3.6.2.m2.1.1.cmml"><mi id="S2.F3.6.2.m2.1.1.2" xref="S2.F3.6.2.m2.1.1.2.cmml">x</mi><mi id="S2.F3.6.2.m2.1.1.3" xref="S2.F3.6.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F3.6.2.m2.1c"><apply id="S2.F3.6.2.m2.1.1.cmml" xref="S2.F3.6.2.m2.1.1"><csymbol cd="ambiguous" id="S2.F3.6.2.m2.1.1.1.cmml" xref="S2.F3.6.2.m2.1.1">subscript</csymbol><ci id="S2.F3.6.2.m2.1.1.2.cmml" xref="S2.F3.6.2.m2.1.1.2">𝑥</ci><ci id="S2.F3.6.2.m2.1.1.3.cmml" xref="S2.F3.6.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.6.2.m2.1d">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.6.2.m2.1e">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>) and a hidden state vector <math alttext="h_{t-1}" class="ltx_Math" display="inline" id="S2.F3.7.3.m3.1"><semantics id="S2.F3.7.3.m3.1b"><msub id="S2.F3.7.3.m3.1.1" xref="S2.F3.7.3.m3.1.1.cmml"><mi id="S2.F3.7.3.m3.1.1.2" xref="S2.F3.7.3.m3.1.1.2.cmml">h</mi><mrow id="S2.F3.7.3.m3.1.1.3" xref="S2.F3.7.3.m3.1.1.3.cmml"><mi id="S2.F3.7.3.m3.1.1.3.2" xref="S2.F3.7.3.m3.1.1.3.2.cmml">t</mi><mo id="S2.F3.7.3.m3.1.1.3.1" xref="S2.F3.7.3.m3.1.1.3.1.cmml">−</mo><mn id="S2.F3.7.3.m3.1.1.3.3" xref="S2.F3.7.3.m3.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.F3.7.3.m3.1c"><apply id="S2.F3.7.3.m3.1.1.cmml" xref="S2.F3.7.3.m3.1.1"><csymbol cd="ambiguous" id="S2.F3.7.3.m3.1.1.1.cmml" xref="S2.F3.7.3.m3.1.1">subscript</csymbol><ci id="S2.F3.7.3.m3.1.1.2.cmml" xref="S2.F3.7.3.m3.1.1.2">ℎ</ci><apply id="S2.F3.7.3.m3.1.1.3.cmml" xref="S2.F3.7.3.m3.1.1.3"><minus id="S2.F3.7.3.m3.1.1.3.1.cmml" xref="S2.F3.7.3.m3.1.1.3.1"></minus><ci id="S2.F3.7.3.m3.1.1.3.2.cmml" xref="S2.F3.7.3.m3.1.1.3.2">𝑡</ci><cn id="S2.F3.7.3.m3.1.1.3.3.cmml" type="integer" xref="S2.F3.7.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.7.3.m3.1d">h_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.7.3.m3.1e">italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math> which contains the previous sequence. The output generated by the neuron is represented by the vector <math alttext="O_{t}" class="ltx_Math" display="inline" id="S2.F3.8.4.m4.1"><semantics id="S2.F3.8.4.m4.1b"><msub id="S2.F3.8.4.m4.1.1" xref="S2.F3.8.4.m4.1.1.cmml"><mi id="S2.F3.8.4.m4.1.1.2" xref="S2.F3.8.4.m4.1.1.2.cmml">O</mi><mi id="S2.F3.8.4.m4.1.1.3" xref="S2.F3.8.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F3.8.4.m4.1c"><apply id="S2.F3.8.4.m4.1.1.cmml" xref="S2.F3.8.4.m4.1.1"><csymbol cd="ambiguous" id="S2.F3.8.4.m4.1.1.1.cmml" xref="S2.F3.8.4.m4.1.1">subscript</csymbol><ci id="S2.F3.8.4.m4.1.1.2.cmml" xref="S2.F3.8.4.m4.1.1.2">𝑂</ci><ci id="S2.F3.8.4.m4.1.1.3.cmml" xref="S2.F3.8.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.8.4.m4.1d">O_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.8.4.m4.1e">italic_O start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.</span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS4.SSS1.p7">
<p class="ltx_p" id="S2.SS4.SSS1.p7.1">Decoders unfold the vector representing the sequence state and return text. An important distinction between an encoder and a decoder is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.F4" title="Figure 4 ‣ 2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>, where it can be seen that both the encoder hidden state and the output from the previous decoding state are required by the decoder.</p>
</div>
<figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="302" id="S2.F4.g1" src="extracted/5447326/nmtarch.png" width="471"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F4.4.2.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S2.F4.2.1" style="font-size:90%;"> <span class="ltx_text" id="S2.F4.2.1.1" style="font-size:89%;"> Encoder-decoder architecture. The encoder encodes the entire input sequence into a fixed-length <span class="ltx_text ltx_font_italic" id="S2.F4.2.1.1.1">context vector</span>, <math alttext="c" class="ltx_Math" display="inline" id="S2.F4.2.1.1.m1.1"><semantics id="S2.F4.2.1.1.m1.1b"><mi id="S2.F4.2.1.1.m1.1.1" xref="S2.F4.2.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.F4.2.1.1.m1.1c"><ci id="S2.F4.2.1.1.m1.1.1.cmml" xref="S2.F4.2.1.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.2.1.1.m1.1d">c</annotation><annotation encoding="application/x-llamapun" id="S2.F4.2.1.1.m1.1e">italic_c</annotation></semantics></math>, by processing input time steps. The function of the decoder is to read this <span class="ltx_text ltx_font_italic" id="S2.F4.2.1.1.2">context vector</span> while stepping through output time steps. </span></span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS4.SSS1.p8">
<p class="ltx_p" id="S2.SS4.SSS1.p8.1">To kick-start processing of the decoder, a special token &lt;start&gt; is used since there is no previous output. The calculations carried out by the encoder are summarized in Equation (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E4" title="4 ‣ 2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>):</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p9">
<table class="ltx_equation ltx_eqn_table" id="S2.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="h_{t}=RNN_{ENC}(x_{t},h_{t-1})" class="ltx_Math" display="block" id="S2.E4.m1.2"><semantics id="S2.E4.m1.2a"><mrow id="S2.E4.m1.2.2" xref="S2.E4.m1.2.2.cmml"><msub id="S2.E4.m1.2.2.4" xref="S2.E4.m1.2.2.4.cmml"><mi id="S2.E4.m1.2.2.4.2" xref="S2.E4.m1.2.2.4.2.cmml">h</mi><mi id="S2.E4.m1.2.2.4.3" xref="S2.E4.m1.2.2.4.3.cmml">t</mi></msub><mo id="S2.E4.m1.2.2.3" xref="S2.E4.m1.2.2.3.cmml">=</mo><mrow id="S2.E4.m1.2.2.2" xref="S2.E4.m1.2.2.2.cmml"><mi id="S2.E4.m1.2.2.2.4" xref="S2.E4.m1.2.2.2.4.cmml">R</mi><mo id="S2.E4.m1.2.2.2.3" xref="S2.E4.m1.2.2.2.3.cmml">⁢</mo><mi id="S2.E4.m1.2.2.2.5" xref="S2.E4.m1.2.2.2.5.cmml">N</mi><mo id="S2.E4.m1.2.2.2.3a" xref="S2.E4.m1.2.2.2.3.cmml">⁢</mo><msub id="S2.E4.m1.2.2.2.6" xref="S2.E4.m1.2.2.2.6.cmml"><mi id="S2.E4.m1.2.2.2.6.2" xref="S2.E4.m1.2.2.2.6.2.cmml">N</mi><mrow id="S2.E4.m1.2.2.2.6.3" xref="S2.E4.m1.2.2.2.6.3.cmml"><mi id="S2.E4.m1.2.2.2.6.3.2" xref="S2.E4.m1.2.2.2.6.3.2.cmml">E</mi><mo id="S2.E4.m1.2.2.2.6.3.1" xref="S2.E4.m1.2.2.2.6.3.1.cmml">⁢</mo><mi id="S2.E4.m1.2.2.2.6.3.3" xref="S2.E4.m1.2.2.2.6.3.3.cmml">N</mi><mo id="S2.E4.m1.2.2.2.6.3.1a" xref="S2.E4.m1.2.2.2.6.3.1.cmml">⁢</mo><mi id="S2.E4.m1.2.2.2.6.3.4" xref="S2.E4.m1.2.2.2.6.3.4.cmml">C</mi></mrow></msub><mo id="S2.E4.m1.2.2.2.3b" xref="S2.E4.m1.2.2.2.3.cmml">⁢</mo><mrow id="S2.E4.m1.2.2.2.2.2" xref="S2.E4.m1.2.2.2.2.3.cmml"><mo id="S2.E4.m1.2.2.2.2.2.3" stretchy="false" xref="S2.E4.m1.2.2.2.2.3.cmml">(</mo><msub id="S2.E4.m1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.E4.m1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E4.m1.2.2.2.2.2.4" xref="S2.E4.m1.2.2.2.2.3.cmml">,</mo><msub id="S2.E4.m1.2.2.2.2.2.2" xref="S2.E4.m1.2.2.2.2.2.2.cmml"><mi id="S2.E4.m1.2.2.2.2.2.2.2" xref="S2.E4.m1.2.2.2.2.2.2.2.cmml">h</mi><mrow id="S2.E4.m1.2.2.2.2.2.2.3" xref="S2.E4.m1.2.2.2.2.2.2.3.cmml"><mi id="S2.E4.m1.2.2.2.2.2.2.3.2" xref="S2.E4.m1.2.2.2.2.2.2.3.2.cmml">t</mi><mo id="S2.E4.m1.2.2.2.2.2.2.3.1" xref="S2.E4.m1.2.2.2.2.2.2.3.1.cmml">−</mo><mn id="S2.E4.m1.2.2.2.2.2.2.3.3" xref="S2.E4.m1.2.2.2.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.E4.m1.2.2.2.2.2.5" stretchy="false" xref="S2.E4.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.2b"><apply id="S2.E4.m1.2.2.cmml" xref="S2.E4.m1.2.2"><eq id="S2.E4.m1.2.2.3.cmml" xref="S2.E4.m1.2.2.3"></eq><apply id="S2.E4.m1.2.2.4.cmml" xref="S2.E4.m1.2.2.4"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.4.1.cmml" xref="S2.E4.m1.2.2.4">subscript</csymbol><ci id="S2.E4.m1.2.2.4.2.cmml" xref="S2.E4.m1.2.2.4.2">ℎ</ci><ci id="S2.E4.m1.2.2.4.3.cmml" xref="S2.E4.m1.2.2.4.3">𝑡</ci></apply><apply id="S2.E4.m1.2.2.2.cmml" xref="S2.E4.m1.2.2.2"><times id="S2.E4.m1.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.3"></times><ci id="S2.E4.m1.2.2.2.4.cmml" xref="S2.E4.m1.2.2.2.4">𝑅</ci><ci id="S2.E4.m1.2.2.2.5.cmml" xref="S2.E4.m1.2.2.2.5">𝑁</ci><apply id="S2.E4.m1.2.2.2.6.cmml" xref="S2.E4.m1.2.2.2.6"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.6.1.cmml" xref="S2.E4.m1.2.2.2.6">subscript</csymbol><ci id="S2.E4.m1.2.2.2.6.2.cmml" xref="S2.E4.m1.2.2.2.6.2">𝑁</ci><apply id="S2.E4.m1.2.2.2.6.3.cmml" xref="S2.E4.m1.2.2.2.6.3"><times id="S2.E4.m1.2.2.2.6.3.1.cmml" xref="S2.E4.m1.2.2.2.6.3.1"></times><ci id="S2.E4.m1.2.2.2.6.3.2.cmml" xref="S2.E4.m1.2.2.2.6.3.2">𝐸</ci><ci id="S2.E4.m1.2.2.2.6.3.3.cmml" xref="S2.E4.m1.2.2.2.6.3.3">𝑁</ci><ci id="S2.E4.m1.2.2.2.6.3.4.cmml" xref="S2.E4.m1.2.2.2.6.3.4">𝐶</ci></apply></apply><interval closure="open" id="S2.E4.m1.2.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.2.2"><apply id="S2.E4.m1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E4.m1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S2.E4.m1.2.2.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.2.2.1.cmml" xref="S2.E4.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S2.E4.m1.2.2.2.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.2.2.2">ℎ</ci><apply id="S2.E4.m1.2.2.2.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.2.2.2.3"><minus id="S2.E4.m1.2.2.2.2.2.2.3.1.cmml" xref="S2.E4.m1.2.2.2.2.2.2.3.1"></minus><ci id="S2.E4.m1.2.2.2.2.2.2.3.2.cmml" xref="S2.E4.m1.2.2.2.2.2.2.3.2">𝑡</ci><cn id="S2.E4.m1.2.2.2.2.2.2.3.3.cmml" type="integer" xref="S2.E4.m1.2.2.2.2.2.2.3.3">1</cn></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.2c">h_{t}=RNN_{ENC}(x_{t},h_{t-1})</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m1.2d">italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_R italic_N italic_N start_POSTSUBSCRIPT italic_E italic_N italic_C end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<br class="ltx_break"/>
<p class="ltx_p" id="S2.SS4.SSS1.p9.4">The <math alttext="RNN_{ENC}" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p9.1.m1.1"><semantics id="S2.SS4.SSS1.p9.1.m1.1a"><mrow id="S2.SS4.SSS1.p9.1.m1.1.1" xref="S2.SS4.SSS1.p9.1.m1.1.1.cmml"><mi id="S2.SS4.SSS1.p9.1.m1.1.1.2" xref="S2.SS4.SSS1.p9.1.m1.1.1.2.cmml">R</mi><mo id="S2.SS4.SSS1.p9.1.m1.1.1.1" xref="S2.SS4.SSS1.p9.1.m1.1.1.1.cmml">⁢</mo><mi id="S2.SS4.SSS1.p9.1.m1.1.1.3" xref="S2.SS4.SSS1.p9.1.m1.1.1.3.cmml">N</mi><mo id="S2.SS4.SSS1.p9.1.m1.1.1.1a" xref="S2.SS4.SSS1.p9.1.m1.1.1.1.cmml">⁢</mo><msub id="S2.SS4.SSS1.p9.1.m1.1.1.4" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.cmml"><mi id="S2.SS4.SSS1.p9.1.m1.1.1.4.2" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.2.cmml">N</mi><mrow id="S2.SS4.SSS1.p9.1.m1.1.1.4.3" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.cmml"><mi id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.2" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.2.cmml">E</mi><mo id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.1" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.3" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.3.cmml">N</mi><mo id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.1a" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.4" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.4.cmml">C</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p9.1.m1.1b"><apply id="S2.SS4.SSS1.p9.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1"><times id="S2.SS4.SSS1.p9.1.m1.1.1.1.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.1"></times><ci id="S2.SS4.SSS1.p9.1.m1.1.1.2.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.2">𝑅</ci><ci id="S2.SS4.SSS1.p9.1.m1.1.1.3.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.3">𝑁</ci><apply id="S2.SS4.SSS1.p9.1.m1.1.1.4.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p9.1.m1.1.1.4.1.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4">subscript</csymbol><ci id="S2.SS4.SSS1.p9.1.m1.1.1.4.2.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.2">𝑁</ci><apply id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3"><times id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.1.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.1"></times><ci id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.2.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.2">𝐸</ci><ci id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.3.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.3">𝑁</ci><ci id="S2.SS4.SSS1.p9.1.m1.1.1.4.3.4.cmml" xref="S2.SS4.SSS1.p9.1.m1.1.1.4.3.4">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p9.1.m1.1c">RNN_{ENC}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p9.1.m1.1d">italic_R italic_N italic_N start_POSTSUBSCRIPT italic_E italic_N italic_C end_POSTSUBSCRIPT</annotation></semantics></math> function is iteratively applied over the input sequence to generate the final encoder state, <math alttext="h_{s}" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p9.2.m2.1"><semantics id="S2.SS4.SSS1.p9.2.m2.1a"><msub id="S2.SS4.SSS1.p9.2.m2.1.1" xref="S2.SS4.SSS1.p9.2.m2.1.1.cmml"><mi id="S2.SS4.SSS1.p9.2.m2.1.1.2" xref="S2.SS4.SSS1.p9.2.m2.1.1.2.cmml">h</mi><mi id="S2.SS4.SSS1.p9.2.m2.1.1.3" xref="S2.SS4.SSS1.p9.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p9.2.m2.1b"><apply id="S2.SS4.SSS1.p9.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p9.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p9.2.m2.1.1.1.cmml" xref="S2.SS4.SSS1.p9.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p9.2.m2.1.1.2.cmml" xref="S2.SS4.SSS1.p9.2.m2.1.1.2">ℎ</ci><ci id="S2.SS4.SSS1.p9.2.m2.1.1.3.cmml" xref="S2.SS4.SSS1.p9.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p9.2.m2.1c">h_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p9.2.m2.1d">italic_h start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> which is fed to the decoder. The complete source sentence is effectively represented by <math alttext="h_{s}" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p9.3.m3.1"><semantics id="S2.SS4.SSS1.p9.3.m3.1a"><msub id="S2.SS4.SSS1.p9.3.m3.1.1" xref="S2.SS4.SSS1.p9.3.m3.1.1.cmml"><mi id="S2.SS4.SSS1.p9.3.m3.1.1.2" xref="S2.SS4.SSS1.p9.3.m3.1.1.2.cmml">h</mi><mi id="S2.SS4.SSS1.p9.3.m3.1.1.3" xref="S2.SS4.SSS1.p9.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p9.3.m3.1b"><apply id="S2.SS4.SSS1.p9.3.m3.1.1.cmml" xref="S2.SS4.SSS1.p9.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p9.3.m3.1.1.1.cmml" xref="S2.SS4.SSS1.p9.3.m3.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p9.3.m3.1.1.2.cmml" xref="S2.SS4.SSS1.p9.3.m3.1.1.2">ℎ</ci><ci id="S2.SS4.SSS1.p9.3.m3.1.1.3.cmml" xref="S2.SS4.SSS1.p9.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p9.3.m3.1c">h_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p9.3.m3.1d">italic_h start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>. The decoder within the model predicts the next word of the target sentence y, while such predictions are conditional on the source sentence <math alttext="x" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p9.4.m4.1"><semantics id="S2.SS4.SSS1.p9.4.m4.1a"><mi id="S2.SS4.SSS1.p9.4.m4.1.1" xref="S2.SS4.SSS1.p9.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p9.4.m4.1b"><ci id="S2.SS4.SSS1.p9.4.m4.1.1.cmml" xref="S2.SS4.SSS1.p9.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p9.4.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p9.4.m4.1d">italic_x</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p10">
<p class="ltx_p" id="S2.SS4.SSS1.p10.3">The RNN decoder, <math alttext="RNN_{DEC}" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p10.1.m1.1"><semantics id="S2.SS4.SSS1.p10.1.m1.1a"><mrow id="S2.SS4.SSS1.p10.1.m1.1.1" xref="S2.SS4.SSS1.p10.1.m1.1.1.cmml"><mi id="S2.SS4.SSS1.p10.1.m1.1.1.2" xref="S2.SS4.SSS1.p10.1.m1.1.1.2.cmml">R</mi><mo id="S2.SS4.SSS1.p10.1.m1.1.1.1" xref="S2.SS4.SSS1.p10.1.m1.1.1.1.cmml">⁢</mo><mi id="S2.SS4.SSS1.p10.1.m1.1.1.3" xref="S2.SS4.SSS1.p10.1.m1.1.1.3.cmml">N</mi><mo id="S2.SS4.SSS1.p10.1.m1.1.1.1a" xref="S2.SS4.SSS1.p10.1.m1.1.1.1.cmml">⁢</mo><msub id="S2.SS4.SSS1.p10.1.m1.1.1.4" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.cmml"><mi id="S2.SS4.SSS1.p10.1.m1.1.1.4.2" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.2.cmml">N</mi><mrow id="S2.SS4.SSS1.p10.1.m1.1.1.4.3" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.cmml"><mi id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.2" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.2.cmml">D</mi><mo id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.1" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.3" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.3.cmml">E</mi><mo id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.1a" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.4" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.4.cmml">C</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p10.1.m1.1b"><apply id="S2.SS4.SSS1.p10.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1"><times id="S2.SS4.SSS1.p10.1.m1.1.1.1.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.1"></times><ci id="S2.SS4.SSS1.p10.1.m1.1.1.2.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.2">𝑅</ci><ci id="S2.SS4.SSS1.p10.1.m1.1.1.3.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.3">𝑁</ci><apply id="S2.SS4.SSS1.p10.1.m1.1.1.4.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p10.1.m1.1.1.4.1.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4">subscript</csymbol><ci id="S2.SS4.SSS1.p10.1.m1.1.1.4.2.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.2">𝑁</ci><apply id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3"><times id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.1.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.1"></times><ci id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.2.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.2">𝐷</ci><ci id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.3.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.3">𝐸</ci><ci id="S2.SS4.SSS1.p10.1.m1.1.1.4.3.4.cmml" xref="S2.SS4.SSS1.p10.1.m1.1.1.4.3.4">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p10.1.m1.1c">RNN_{DEC}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p10.1.m1.1d">italic_R italic_N italic_N start_POSTSUBSCRIPT italic_D italic_E italic_C end_POSTSUBSCRIPT</annotation></semantics></math>, creates a state vector <math alttext="s_{t}" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p10.2.m2.1"><semantics id="S2.SS4.SSS1.p10.2.m2.1a"><msub id="S2.SS4.SSS1.p10.2.m2.1.1" xref="S2.SS4.SSS1.p10.2.m2.1.1.cmml"><mi id="S2.SS4.SSS1.p10.2.m2.1.1.2" xref="S2.SS4.SSS1.p10.2.m2.1.1.2.cmml">s</mi><mi id="S2.SS4.SSS1.p10.2.m2.1.1.3" xref="S2.SS4.SSS1.p10.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p10.2.m2.1b"><apply id="S2.SS4.SSS1.p10.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p10.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p10.2.m2.1.1.1.cmml" xref="S2.SS4.SSS1.p10.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p10.2.m2.1.1.2.cmml" xref="S2.SS4.SSS1.p10.2.m2.1.1.2">𝑠</ci><ci id="S2.SS4.SSS1.p10.2.m2.1.1.3.cmml" xref="S2.SS4.SSS1.p10.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p10.2.m2.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p10.2.m2.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> by compressing the decoding history <math alttext="{y_{0},…,y_{t-1}}" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p10.3.m3.3"><semantics id="S2.SS4.SSS1.p10.3.m3.3a"><mrow id="S2.SS4.SSS1.p10.3.m3.3.3.2" xref="S2.SS4.SSS1.p10.3.m3.3.3.3.cmml"><msub id="S2.SS4.SSS1.p10.3.m3.2.2.1.1" xref="S2.SS4.SSS1.p10.3.m3.2.2.1.1.cmml"><mi id="S2.SS4.SSS1.p10.3.m3.2.2.1.1.2" xref="S2.SS4.SSS1.p10.3.m3.2.2.1.1.2.cmml">y</mi><mn id="S2.SS4.SSS1.p10.3.m3.2.2.1.1.3" xref="S2.SS4.SSS1.p10.3.m3.2.2.1.1.3.cmml">0</mn></msub><mo id="S2.SS4.SSS1.p10.3.m3.3.3.2.3" xref="S2.SS4.SSS1.p10.3.m3.3.3.3.cmml">,</mo><mi id="S2.SS4.SSS1.p10.3.m3.1.1" mathvariant="normal" xref="S2.SS4.SSS1.p10.3.m3.1.1.cmml">…</mi><mo id="S2.SS4.SSS1.p10.3.m3.3.3.2.4" xref="S2.SS4.SSS1.p10.3.m3.3.3.3.cmml">,</mo><msub id="S2.SS4.SSS1.p10.3.m3.3.3.2.2" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.cmml"><mi id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.2" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.2.cmml">y</mi><mrow id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.cmml"><mi id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.2" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.2.cmml">t</mi><mo id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.1" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.1.cmml">−</mo><mn id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.3" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p10.3.m3.3b"><list id="S2.SS4.SSS1.p10.3.m3.3.3.3.cmml" xref="S2.SS4.SSS1.p10.3.m3.3.3.2"><apply id="S2.SS4.SSS1.p10.3.m3.2.2.1.1.cmml" xref="S2.SS4.SSS1.p10.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p10.3.m3.2.2.1.1.1.cmml" xref="S2.SS4.SSS1.p10.3.m3.2.2.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p10.3.m3.2.2.1.1.2.cmml" xref="S2.SS4.SSS1.p10.3.m3.2.2.1.1.2">𝑦</ci><cn id="S2.SS4.SSS1.p10.3.m3.2.2.1.1.3.cmml" type="integer" xref="S2.SS4.SSS1.p10.3.m3.2.2.1.1.3">0</cn></apply><ci id="S2.SS4.SSS1.p10.3.m3.1.1.cmml" xref="S2.SS4.SSS1.p10.3.m3.1.1">…</ci><apply id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.cmml" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.1.cmml" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2">subscript</csymbol><ci id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.2.cmml" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.2">𝑦</ci><apply id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.cmml" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3"><minus id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.1.cmml" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.1"></minus><ci id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.2.cmml" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.2">𝑡</ci><cn id="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.3.cmml" type="integer" xref="S2.SS4.SSS1.p10.3.m3.3.3.2.2.3.3">1</cn></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p10.3.m3.3c">{y_{0},…,y_{t-1}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS1.p10.3.m3.3d">italic_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math> which is described in Equation (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E5" title="5 ‣ 2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>). The distribution of target tokens is predicted by a classification layer which typically uses the Softmax activation function.</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS1.p11">
<table class="ltx_equation ltx_eqn_table" id="S2.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="s_{t}=RNN_{DEC}(y_{t-1},s_{t-1})" class="ltx_Math" display="block" id="S2.E5.m1.2"><semantics id="S2.E5.m1.2a"><mrow id="S2.E5.m1.2.2" xref="S2.E5.m1.2.2.cmml"><msub id="S2.E5.m1.2.2.4" xref="S2.E5.m1.2.2.4.cmml"><mi id="S2.E5.m1.2.2.4.2" xref="S2.E5.m1.2.2.4.2.cmml">s</mi><mi id="S2.E5.m1.2.2.4.3" xref="S2.E5.m1.2.2.4.3.cmml">t</mi></msub><mo id="S2.E5.m1.2.2.3" xref="S2.E5.m1.2.2.3.cmml">=</mo><mrow id="S2.E5.m1.2.2.2" xref="S2.E5.m1.2.2.2.cmml"><mi id="S2.E5.m1.2.2.2.4" xref="S2.E5.m1.2.2.2.4.cmml">R</mi><mo id="S2.E5.m1.2.2.2.3" xref="S2.E5.m1.2.2.2.3.cmml">⁢</mo><mi id="S2.E5.m1.2.2.2.5" xref="S2.E5.m1.2.2.2.5.cmml">N</mi><mo id="S2.E5.m1.2.2.2.3a" xref="S2.E5.m1.2.2.2.3.cmml">⁢</mo><msub id="S2.E5.m1.2.2.2.6" xref="S2.E5.m1.2.2.2.6.cmml"><mi id="S2.E5.m1.2.2.2.6.2" xref="S2.E5.m1.2.2.2.6.2.cmml">N</mi><mrow id="S2.E5.m1.2.2.2.6.3" xref="S2.E5.m1.2.2.2.6.3.cmml"><mi id="S2.E5.m1.2.2.2.6.3.2" xref="S2.E5.m1.2.2.2.6.3.2.cmml">D</mi><mo id="S2.E5.m1.2.2.2.6.3.1" xref="S2.E5.m1.2.2.2.6.3.1.cmml">⁢</mo><mi id="S2.E5.m1.2.2.2.6.3.3" xref="S2.E5.m1.2.2.2.6.3.3.cmml">E</mi><mo id="S2.E5.m1.2.2.2.6.3.1a" xref="S2.E5.m1.2.2.2.6.3.1.cmml">⁢</mo><mi id="S2.E5.m1.2.2.2.6.3.4" xref="S2.E5.m1.2.2.2.6.3.4.cmml">C</mi></mrow></msub><mo id="S2.E5.m1.2.2.2.3b" xref="S2.E5.m1.2.2.2.3.cmml">⁢</mo><mrow id="S2.E5.m1.2.2.2.2.2" xref="S2.E5.m1.2.2.2.2.3.cmml"><mo id="S2.E5.m1.2.2.2.2.2.3" stretchy="false" xref="S2.E5.m1.2.2.2.2.3.cmml">(</mo><msub id="S2.E5.m1.1.1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.1.1.cmml"><mi id="S2.E5.m1.1.1.1.1.1.1.2" xref="S2.E5.m1.1.1.1.1.1.1.2.cmml">y</mi><mrow id="S2.E5.m1.1.1.1.1.1.1.3" xref="S2.E5.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.E5.m1.1.1.1.1.1.1.3.2" xref="S2.E5.m1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="S2.E5.m1.1.1.1.1.1.1.3.1" xref="S2.E5.m1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="S2.E5.m1.1.1.1.1.1.1.3.3" xref="S2.E5.m1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S2.E5.m1.2.2.2.2.2.4" xref="S2.E5.m1.2.2.2.2.3.cmml">,</mo><msub id="S2.E5.m1.2.2.2.2.2.2" xref="S2.E5.m1.2.2.2.2.2.2.cmml"><mi id="S2.E5.m1.2.2.2.2.2.2.2" xref="S2.E5.m1.2.2.2.2.2.2.2.cmml">s</mi><mrow id="S2.E5.m1.2.2.2.2.2.2.3" xref="S2.E5.m1.2.2.2.2.2.2.3.cmml"><mi id="S2.E5.m1.2.2.2.2.2.2.3.2" xref="S2.E5.m1.2.2.2.2.2.2.3.2.cmml">t</mi><mo id="S2.E5.m1.2.2.2.2.2.2.3.1" xref="S2.E5.m1.2.2.2.2.2.2.3.1.cmml">−</mo><mn id="S2.E5.m1.2.2.2.2.2.2.3.3" xref="S2.E5.m1.2.2.2.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.E5.m1.2.2.2.2.2.5" stretchy="false" xref="S2.E5.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.2b"><apply id="S2.E5.m1.2.2.cmml" xref="S2.E5.m1.2.2"><eq id="S2.E5.m1.2.2.3.cmml" xref="S2.E5.m1.2.2.3"></eq><apply id="S2.E5.m1.2.2.4.cmml" xref="S2.E5.m1.2.2.4"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.4.1.cmml" xref="S2.E5.m1.2.2.4">subscript</csymbol><ci id="S2.E5.m1.2.2.4.2.cmml" xref="S2.E5.m1.2.2.4.2">𝑠</ci><ci id="S2.E5.m1.2.2.4.3.cmml" xref="S2.E5.m1.2.2.4.3">𝑡</ci></apply><apply id="S2.E5.m1.2.2.2.cmml" xref="S2.E5.m1.2.2.2"><times id="S2.E5.m1.2.2.2.3.cmml" xref="S2.E5.m1.2.2.2.3"></times><ci id="S2.E5.m1.2.2.2.4.cmml" xref="S2.E5.m1.2.2.2.4">𝑅</ci><ci id="S2.E5.m1.2.2.2.5.cmml" xref="S2.E5.m1.2.2.2.5">𝑁</ci><apply id="S2.E5.m1.2.2.2.6.cmml" xref="S2.E5.m1.2.2.2.6"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.2.6.1.cmml" xref="S2.E5.m1.2.2.2.6">subscript</csymbol><ci id="S2.E5.m1.2.2.2.6.2.cmml" xref="S2.E5.m1.2.2.2.6.2">𝑁</ci><apply id="S2.E5.m1.2.2.2.6.3.cmml" xref="S2.E5.m1.2.2.2.6.3"><times id="S2.E5.m1.2.2.2.6.3.1.cmml" xref="S2.E5.m1.2.2.2.6.3.1"></times><ci id="S2.E5.m1.2.2.2.6.3.2.cmml" xref="S2.E5.m1.2.2.2.6.3.2">𝐷</ci><ci id="S2.E5.m1.2.2.2.6.3.3.cmml" xref="S2.E5.m1.2.2.2.6.3.3">𝐸</ci><ci id="S2.E5.m1.2.2.2.6.3.4.cmml" xref="S2.E5.m1.2.2.2.6.3.4">𝐶</ci></apply></apply><interval closure="open" id="S2.E5.m1.2.2.2.2.3.cmml" xref="S2.E5.m1.2.2.2.2.2"><apply id="S2.E5.m1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E5.m1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.1.1.1.1.1.1.2">𝑦</ci><apply id="S2.E5.m1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m1.1.1.1.1.1.1.3"><minus id="S2.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.1.1.1.1.1.1.3.1"></minus><ci id="S2.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.1.1.1.1.1.1.3.2">𝑡</ci><cn id="S2.E5.m1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S2.E5.m1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S2.E5.m1.2.2.2.2.2.2.cmml" xref="S2.E5.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.2.2.2.2.1.cmml" xref="S2.E5.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S2.E5.m1.2.2.2.2.2.2.2.cmml" xref="S2.E5.m1.2.2.2.2.2.2.2">𝑠</ci><apply id="S2.E5.m1.2.2.2.2.2.2.3.cmml" xref="S2.E5.m1.2.2.2.2.2.2.3"><minus id="S2.E5.m1.2.2.2.2.2.2.3.1.cmml" xref="S2.E5.m1.2.2.2.2.2.2.3.1"></minus><ci id="S2.E5.m1.2.2.2.2.2.2.3.2.cmml" xref="S2.E5.m1.2.2.2.2.2.2.3.2">𝑡</ci><cn id="S2.E5.m1.2.2.2.2.2.2.3.3.cmml" type="integer" xref="S2.E5.m1.2.2.2.2.2.2.3.3">1</cn></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.2c">s_{t}=RNN_{DEC}(y_{t-1},s_{t-1})</annotation><annotation encoding="application/x-llamapun" id="S2.E5.m1.2d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_R italic_N italic_N start_POSTSUBSCRIPT italic_D italic_E italic_C end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2 </span>Learning</h4>
<div class="ltx_para" id="S2.SS4.SSS2.p1">
<p class="ltx_p" id="S2.SS4.SSS2.p1.1">It is possible to optimize models using different types of training objectives, although maximum log-likelihood (MLE) is the most commonly used method. Given a set of training examples <math alttext="D=\{(x^{s},y^{s})\}_{s=1}^{S}" class="ltx_Math" display="inline" id="S2.SS4.SSS2.p1.1.m1.1"><semantics id="S2.SS4.SSS2.p1.1.m1.1a"><mrow id="S2.SS4.SSS2.p1.1.m1.1.1" xref="S2.SS4.SSS2.p1.1.m1.1.1.cmml"><mi id="S2.SS4.SSS2.p1.1.m1.1.1.3" xref="S2.SS4.SSS2.p1.1.m1.1.1.3.cmml">D</mi><mo id="S2.SS4.SSS2.p1.1.m1.1.1.2" xref="S2.SS4.SSS2.p1.1.m1.1.1.2.cmml">=</mo><msubsup id="S2.SS4.SSS2.p1.1.m1.1.1.1" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.cmml"><mrow id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.2.cmml"><mo id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.2.cmml">{</mo><mrow id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml"><mo id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml">(</mo><msup id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">s</mi></msup><mo id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.4" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml">,</mo><msup id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.3" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.3.cmml">s</mi></msup><mo id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.cmml"><mi id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.2" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.2.cmml">s</mi><mo id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.1" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.3" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS4.SSS2.p1.1.m1.1.1.1.3" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.3.cmml">S</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p1.1.m1.1b"><apply id="S2.SS4.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1"><eq id="S2.SS4.SSS2.p1.1.m1.1.1.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.2"></eq><ci id="S2.SS4.SSS2.p1.1.m1.1.1.3.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.3">𝐷</ci><apply id="S2.SS4.SSS2.p1.1.m1.1.1.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS2.p1.1.m1.1.1.1.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1">superscript</csymbol><apply id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1">subscript</csymbol><set id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1"><interval closure="open" id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2"><apply id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3">𝑠</ci></apply><apply id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.1.1.1.2.2.3">𝑠</ci></apply></interval></set><apply id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3"><eq id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.1"></eq><ci id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.2.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.2">𝑠</ci><cn id="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS4.SSS2.p1.1.m1.1.1.1.3.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1.1.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p1.1.m1.1c">D=\{(x^{s},y^{s})\}_{s=1}^{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS2.p1.1.m1.1d">italic_D = { ( italic_x start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT</annotation></semantics></math>, the MLE is maximised according to Equations (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E6" title="6 ‣ 2.4.2 Learning ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>) and (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E7" title="7 ‣ 2.4.2 Learning ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S2.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\boldsymbol{\hat{\theta}}_{MLE}=\arg\max_{\theta}\{\mathcal{L}(\theta)\}" class="ltx_Math" display="block" id="S2.E6.m1.3"><semantics id="S2.E6.m1.3a"><mrow id="S2.E6.m1.3.3" xref="S2.E6.m1.3.3.cmml"><msub id="S2.E6.m1.3.3.4" xref="S2.E6.m1.3.3.4.cmml"><mover accent="true" id="S2.E6.m1.3.3.4.2" xref="S2.E6.m1.3.3.4.2.cmml"><mi id="S2.E6.m1.3.3.4.2.2" xref="S2.E6.m1.3.3.4.2.2.cmml">𝜽</mi><mo id="S2.E6.m1.3.3.4.2.1" mathvariant="bold" xref="S2.E6.m1.3.3.4.2.1.cmml">^</mo></mover><mrow id="S2.E6.m1.3.3.4.3" xref="S2.E6.m1.3.3.4.3.cmml"><mi id="S2.E6.m1.3.3.4.3.2" xref="S2.E6.m1.3.3.4.3.2.cmml">M</mi><mo id="S2.E6.m1.3.3.4.3.1" xref="S2.E6.m1.3.3.4.3.1.cmml">⁢</mo><mi id="S2.E6.m1.3.3.4.3.3" xref="S2.E6.m1.3.3.4.3.3.cmml">L</mi><mo id="S2.E6.m1.3.3.4.3.1a" xref="S2.E6.m1.3.3.4.3.1.cmml">⁢</mo><mi id="S2.E6.m1.3.3.4.3.4" xref="S2.E6.m1.3.3.4.3.4.cmml">E</mi></mrow></msub><mo id="S2.E6.m1.3.3.3" xref="S2.E6.m1.3.3.3.cmml">=</mo><mrow id="S2.E6.m1.3.3.2" xref="S2.E6.m1.3.3.2.cmml"><mi id="S2.E6.m1.3.3.2.3" xref="S2.E6.m1.3.3.2.3.cmml">arg</mi><mo id="S2.E6.m1.3.3.2a" lspace="0.167em" xref="S2.E6.m1.3.3.2.cmml">⁡</mo><mrow id="S2.E6.m1.3.3.2.2.2" xref="S2.E6.m1.3.3.2.2.3.cmml"><munder id="S2.E6.m1.2.2.1.1.1.1" xref="S2.E6.m1.2.2.1.1.1.1.cmml"><mi id="S2.E6.m1.2.2.1.1.1.1.2" xref="S2.E6.m1.2.2.1.1.1.1.2.cmml">max</mi><mi id="S2.E6.m1.2.2.1.1.1.1.3" xref="S2.E6.m1.2.2.1.1.1.1.3.cmml">θ</mi></munder><mo id="S2.E6.m1.3.3.2.2.2a" xref="S2.E6.m1.3.3.2.2.3.cmml">⁡</mo><mrow id="S2.E6.m1.3.3.2.2.2.2" xref="S2.E6.m1.3.3.2.2.3.cmml"><mo id="S2.E6.m1.3.3.2.2.2.2.2" stretchy="false" xref="S2.E6.m1.3.3.2.2.3.cmml">{</mo><mrow id="S2.E6.m1.3.3.2.2.2.2.1" xref="S2.E6.m1.3.3.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E6.m1.3.3.2.2.2.2.1.2" xref="S2.E6.m1.3.3.2.2.2.2.1.2.cmml">ℒ</mi><mo id="S2.E6.m1.3.3.2.2.2.2.1.1" xref="S2.E6.m1.3.3.2.2.2.2.1.1.cmml">⁢</mo><mrow id="S2.E6.m1.3.3.2.2.2.2.1.3.2" xref="S2.E6.m1.3.3.2.2.2.2.1.cmml"><mo id="S2.E6.m1.3.3.2.2.2.2.1.3.2.1" stretchy="false" xref="S2.E6.m1.3.3.2.2.2.2.1.cmml">(</mo><mi id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml">θ</mi><mo id="S2.E6.m1.3.3.2.2.2.2.1.3.2.2" stretchy="false" xref="S2.E6.m1.3.3.2.2.2.2.1.cmml">)</mo></mrow></mrow><mo id="S2.E6.m1.3.3.2.2.2.2.3" stretchy="false" xref="S2.E6.m1.3.3.2.2.3.cmml">}</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m1.3b"><apply id="S2.E6.m1.3.3.cmml" xref="S2.E6.m1.3.3"><eq id="S2.E6.m1.3.3.3.cmml" xref="S2.E6.m1.3.3.3"></eq><apply id="S2.E6.m1.3.3.4.cmml" xref="S2.E6.m1.3.3.4"><csymbol cd="ambiguous" id="S2.E6.m1.3.3.4.1.cmml" xref="S2.E6.m1.3.3.4">subscript</csymbol><apply id="S2.E6.m1.3.3.4.2.cmml" xref="S2.E6.m1.3.3.4.2"><ci id="S2.E6.m1.3.3.4.2.1.cmml" xref="S2.E6.m1.3.3.4.2.1">bold-^</ci><ci id="S2.E6.m1.3.3.4.2.2.cmml" xref="S2.E6.m1.3.3.4.2.2">𝜽</ci></apply><apply id="S2.E6.m1.3.3.4.3.cmml" xref="S2.E6.m1.3.3.4.3"><times id="S2.E6.m1.3.3.4.3.1.cmml" xref="S2.E6.m1.3.3.4.3.1"></times><ci id="S2.E6.m1.3.3.4.3.2.cmml" xref="S2.E6.m1.3.3.4.3.2">𝑀</ci><ci id="S2.E6.m1.3.3.4.3.3.cmml" xref="S2.E6.m1.3.3.4.3.3">𝐿</ci><ci id="S2.E6.m1.3.3.4.3.4.cmml" xref="S2.E6.m1.3.3.4.3.4">𝐸</ci></apply></apply><apply id="S2.E6.m1.3.3.2.cmml" xref="S2.E6.m1.3.3.2"><arg id="S2.E6.m1.3.3.2.3.cmml" xref="S2.E6.m1.3.3.2.3"></arg><apply id="S2.E6.m1.3.3.2.2.3.cmml" xref="S2.E6.m1.3.3.2.2.2"><apply id="S2.E6.m1.2.2.1.1.1.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E6.m1.2.2.1.1.1.1.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1">subscript</csymbol><max id="S2.E6.m1.2.2.1.1.1.1.2.cmml" xref="S2.E6.m1.2.2.1.1.1.1.2"></max><ci id="S2.E6.m1.2.2.1.1.1.1.3.cmml" xref="S2.E6.m1.2.2.1.1.1.1.3">𝜃</ci></apply><apply id="S2.E6.m1.3.3.2.2.2.2.1.cmml" xref="S2.E6.m1.3.3.2.2.2.2.1"><times id="S2.E6.m1.3.3.2.2.2.2.1.1.cmml" xref="S2.E6.m1.3.3.2.2.2.2.1.1"></times><ci id="S2.E6.m1.3.3.2.2.2.2.1.2.cmml" xref="S2.E6.m1.3.3.2.2.2.2.1.2">ℒ</ci><ci id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1">𝜃</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.3c">\boldsymbol{\hat{\theta}}_{MLE}=\arg\max_{\theta}\{\mathcal{L}(\theta)\}</annotation><annotation encoding="application/x-llamapun" id="S2.E6.m1.3d">overbold_^ start_ARG bold_italic_θ end_ARG start_POSTSUBSCRIPT italic_M italic_L italic_E end_POSTSUBSCRIPT = roman_arg roman_max start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT { caligraphic_L ( italic_θ ) }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.SSS2.p3">
<table class="ltx_equation ltx_eqn_table" id="S2.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}(\theta)\ =\sum_{s=1}^{S}logP(y^{s}|x^{s});\;\theta)" class="ltx_math_unparsed" display="block" id="S2.E7.m1.2"><semantics id="S2.E7.m1.2a"><mrow id="S2.E7.m1.2b"><mi class="ltx_font_mathcaligraphic" id="S2.E7.m1.2.3">ℒ</mi><mrow id="S2.E7.m1.2.4"><mo id="S2.E7.m1.2.4.1" stretchy="false">(</mo><mi id="S2.E7.m1.1.1">θ</mi><mo id="S2.E7.m1.2.4.2" rspace="0.500em" stretchy="false">)</mo></mrow><mo id="S2.E7.m1.2.5" rspace="0.111em">=</mo><munderover id="S2.E7.m1.2.6"><mo id="S2.E7.m1.2.6.2.2" movablelimits="false">∑</mo><mrow id="S2.E7.m1.2.6.2.3"><mi id="S2.E7.m1.2.6.2.3.2">s</mi><mo id="S2.E7.m1.2.6.2.3.1">=</mo><mn id="S2.E7.m1.2.6.2.3.3">1</mn></mrow><mi id="S2.E7.m1.2.6.3">S</mi></munderover><mi id="S2.E7.m1.2.7">l</mi><mi id="S2.E7.m1.2.8">o</mi><mi id="S2.E7.m1.2.9">g</mi><mi id="S2.E7.m1.2.10">P</mi><mrow id="S2.E7.m1.2.11"><mo id="S2.E7.m1.2.11.1" stretchy="false">(</mo><msup id="S2.E7.m1.2.11.2"><mi id="S2.E7.m1.2.11.2.2">y</mi><mi id="S2.E7.m1.2.11.2.3">s</mi></msup><mo fence="false" id="S2.E7.m1.2.11.3" rspace="0.167em" stretchy="false">|</mo><msup id="S2.E7.m1.2.11.4"><mi id="S2.E7.m1.2.11.4.2">x</mi><mi id="S2.E7.m1.2.11.4.3">s</mi></msup><mo id="S2.E7.m1.2.11.5" stretchy="false">)</mo></mrow><mo id="S2.E7.m1.2.12" rspace="0.447em">;</mo><mi id="S2.E7.m1.2.2">θ</mi><mo id="S2.E7.m1.2.13" stretchy="false">)</mo></mrow><annotation encoding="application/x-tex" id="S2.E7.m1.2c">\mathcal{L}(\theta)\ =\sum_{s=1}^{S}logP(y^{s}|x^{s});\;\theta)</annotation><annotation encoding="application/x-llamapun" id="S2.E7.m1.2d">caligraphic_L ( italic_θ ) = ∑ start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT italic_l italic_o italic_g italic_P ( italic_y start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT | italic_x start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ) ; italic_θ )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.SSS2.p4">
<p class="ltx_p" id="S2.SS4.SSS2.p4.3">The gradient of <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S2.SS4.SSS2.p4.1.m1.1"><semantics id="S2.SS4.SSS2.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.SSS2.p4.1.m1.1.1" xref="S2.SS4.SSS2.p4.1.m1.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p4.1.m1.1b"><ci id="S2.SS4.SSS2.p4.1.m1.1.1.cmml" xref="S2.SS4.SSS2.p4.1.m1.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p4.1.m1.1c">\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS2.p4.1.m1.1d">caligraphic_L</annotation></semantics></math> with respect to <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS4.SSS2.p4.2.m2.1"><semantics id="S2.SS4.SSS2.p4.2.m2.1a"><mi id="S2.SS4.SSS2.p4.2.m2.1.1" xref="S2.SS4.SSS2.p4.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p4.2.m2.1b"><ci id="S2.SS4.SSS2.p4.2.m2.1.1.cmml" xref="S2.SS4.SSS2.p4.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p4.2.m2.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS2.p4.2.m2.1d">italic_θ</annotation></semantics></math> is calculated using back-propagation <cite class="ltx_cite ltx_citemacro_citep">(Rumelhart et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib45" title="">1986</a>)</cite> as an automatic differentiation algorithm for calculating gradients of the neural network weights, where <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS4.SSS2.p4.3.m3.1"><semantics id="S2.SS4.SSS2.p4.3.m3.1a"><mi id="S2.SS4.SSS2.p4.3.m3.1.1" xref="S2.SS4.SSS2.p4.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p4.3.m3.1b"><ci id="S2.SS4.SSS2.p4.3.m3.1.1.cmml" xref="S2.SS4.SSS2.p4.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p4.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS2.p4.3.m3.1d">italic_θ</annotation></semantics></math> is the set of model parameters.</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS2.p5">
<p class="ltx_p" id="S2.SS4.SSS2.p5.1">Many NMT approaches implement Stochastic Gradient Descent (SGD) as the optimization algorithm for minimising the loss of the predictive model with regard to the training data. For reasons of computational efficiency, SGD typically computes the loss function and gradients on a minibatch of the training set. The standard SGD optimizer updates parameters of an NMT model according to Equation (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E8" title="8 ‣ 2.4.2 Learning ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>), where the learning rate is specified by <math alttext="\alpha" class="ltx_Math" display="inline" id="S2.SS4.SSS2.p5.1.m1.1"><semantics id="S2.SS4.SSS2.p5.1.m1.1a"><mi id="S2.SS4.SSS2.p5.1.m1.1.1" xref="S2.SS4.SSS2.p5.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p5.1.m1.1b"><ci id="S2.SS4.SSS2.p5.1.m1.1.1.cmml" xref="S2.SS4.SSS2.p5.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p5.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS2.p5.1.m1.1d">italic_α</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S2.SS4.SSS2.p6">
<table class="ltx_equation ltx_eqn_table" id="S2.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\theta\leftarrow\theta-\alpha\bigtriangledown\mathcal{L}(\theta)" class="ltx_Math" display="block" id="S2.E8.m1.1"><semantics id="S2.E8.m1.1a"><mrow id="S2.E8.m1.1.2" xref="S2.E8.m1.1.2.cmml"><mi id="S2.E8.m1.1.2.2" xref="S2.E8.m1.1.2.2.cmml">θ</mi><mo id="S2.E8.m1.1.2.1" stretchy="false" xref="S2.E8.m1.1.2.1.cmml">←</mo><mrow id="S2.E8.m1.1.2.3" xref="S2.E8.m1.1.2.3.cmml"><mrow id="S2.E8.m1.1.2.3.2" xref="S2.E8.m1.1.2.3.2.cmml"><mi id="S2.E8.m1.1.2.3.2.2" xref="S2.E8.m1.1.2.3.2.2.cmml">θ</mi><mo id="S2.E8.m1.1.2.3.2.1" xref="S2.E8.m1.1.2.3.2.1.cmml">−</mo><mi id="S2.E8.m1.1.2.3.2.3" xref="S2.E8.m1.1.2.3.2.3.cmml">α</mi></mrow><mo id="S2.E8.m1.1.2.3.1" lspace="0.222em" rspace="0.222em" xref="S2.E8.m1.1.2.3.1.cmml">▽</mo><mrow id="S2.E8.m1.1.2.3.3" xref="S2.E8.m1.1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E8.m1.1.2.3.3.2" xref="S2.E8.m1.1.2.3.3.2.cmml">ℒ</mi><mo id="S2.E8.m1.1.2.3.3.1" xref="S2.E8.m1.1.2.3.3.1.cmml">⁢</mo><mrow id="S2.E8.m1.1.2.3.3.3.2" xref="S2.E8.m1.1.2.3.3.cmml"><mo id="S2.E8.m1.1.2.3.3.3.2.1" stretchy="false" xref="S2.E8.m1.1.2.3.3.cmml">(</mo><mi id="S2.E8.m1.1.1" xref="S2.E8.m1.1.1.cmml">θ</mi><mo id="S2.E8.m1.1.2.3.3.3.2.2" stretchy="false" xref="S2.E8.m1.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E8.m1.1b"><apply id="S2.E8.m1.1.2.cmml" xref="S2.E8.m1.1.2"><ci id="S2.E8.m1.1.2.1.cmml" xref="S2.E8.m1.1.2.1">←</ci><ci id="S2.E8.m1.1.2.2.cmml" xref="S2.E8.m1.1.2.2">𝜃</ci><apply id="S2.E8.m1.1.2.3.cmml" xref="S2.E8.m1.1.2.3"><ci id="S2.E8.m1.1.2.3.1.cmml" xref="S2.E8.m1.1.2.3.1">▽</ci><apply id="S2.E8.m1.1.2.3.2.cmml" xref="S2.E8.m1.1.2.3.2"><minus id="S2.E8.m1.1.2.3.2.1.cmml" xref="S2.E8.m1.1.2.3.2.1"></minus><ci id="S2.E8.m1.1.2.3.2.2.cmml" xref="S2.E8.m1.1.2.3.2.2">𝜃</ci><ci id="S2.E8.m1.1.2.3.2.3.cmml" xref="S2.E8.m1.1.2.3.2.3">𝛼</ci></apply><apply id="S2.E8.m1.1.2.3.3.cmml" xref="S2.E8.m1.1.2.3.3"><times id="S2.E8.m1.1.2.3.3.1.cmml" xref="S2.E8.m1.1.2.3.3.1"></times><ci id="S2.E8.m1.1.2.3.3.2.cmml" xref="S2.E8.m1.1.2.3.3.2">ℒ</ci><ci id="S2.E8.m1.1.1.cmml" xref="S2.E8.m1.1.1">𝜃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E8.m1.1c">\theta\leftarrow\theta-\alpha\bigtriangledown\mathcal{L}(\theta)</annotation><annotation encoding="application/x-llamapun" id="S2.E8.m1.1d">italic_θ ← italic_θ - italic_α ▽ caligraphic_L ( italic_θ )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<br class="ltx_break"/>
<p class="ltx_p" id="S2.SS4.SSS2.p6.1">There are several alternatives to using SGD for optimization, among which the ADAM optimizer has proven popular due to a reduction in training times <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Ba, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib25" title="">2014</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S2.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="229" id="S2.F5.g1" src="extracted/5447326/beamsearch.png" width="216"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F5.3.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S2.F5.4.2" style="font-size:80%;">Beam Search Algorithm <cite class="ltx_cite ltx_citemacro_citep">(Yang et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib58" title="">2020</a>)</cite> </span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S2.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.3 </span>Inference</h4>
<div class="ltx_para" id="S2.SS4.SSS3.p1">
<p class="ltx_p" id="S2.SS4.SSS3.p1.3">In the context of NMT, inference should ideally find the target translated sentence <math alttext="y" class="ltx_Math" display="inline" id="S2.SS4.SSS3.p1.1.m1.1"><semantics id="S2.SS4.SSS3.p1.1.m1.1a"><mi id="S2.SS4.SSS3.p1.1.m1.1.1" xref="S2.SS4.SSS3.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS3.p1.1.m1.1b"><ci id="S2.SS4.SSS3.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS3.p1.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS3.p1.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS3.p1.1.m1.1d">italic_y</annotation></semantics></math> from the source <math alttext="x" class="ltx_Math" display="inline" id="S2.SS4.SSS3.p1.2.m2.1"><semantics id="S2.SS4.SSS3.p1.2.m2.1a"><mi id="S2.SS4.SSS3.p1.2.m2.1.1" xref="S2.SS4.SSS3.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS3.p1.2.m2.1b"><ci id="S2.SS4.SSS3.p1.2.m2.1.1.cmml" xref="S2.SS4.SSS3.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS3.p1.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS3.p1.2.m2.1d">italic_x</annotation></semantics></math> which maximizes the model prediction <math alttext="P(y|x;\;\theta)" class="ltx_Math" display="inline" id="S2.SS4.SSS3.p1.3.m3.3"><semantics id="S2.SS4.SSS3.p1.3.m3.3a"><mrow id="S2.SS4.SSS3.p1.3.m3.3.3" xref="S2.SS4.SSS3.p1.3.m3.3.3.cmml"><mi id="S2.SS4.SSS3.p1.3.m3.3.3.3" xref="S2.SS4.SSS3.p1.3.m3.3.3.3.cmml">P</mi><mo id="S2.SS4.SSS3.p1.3.m3.3.3.2" xref="S2.SS4.SSS3.p1.3.m3.3.3.2.cmml">⁢</mo><mrow id="S2.SS4.SSS3.p1.3.m3.3.3.1.1" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.cmml"><mo id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.2" stretchy="false" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.cmml"><mi id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.2" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.1" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.1.cmml">|</mo><mrow id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.3.2" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.3.1.cmml"><mi id="S2.SS4.SSS3.p1.3.m3.1.1" xref="S2.SS4.SSS3.p1.3.m3.1.1.cmml">x</mi><mo id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.3.2.1" rspace="0.447em" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.3.1.cmml">;</mo><mi id="S2.SS4.SSS3.p1.3.m3.2.2" xref="S2.SS4.SSS3.p1.3.m3.2.2.cmml">θ</mi></mrow></mrow><mo id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.3" stretchy="false" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS3.p1.3.m3.3b"><apply id="S2.SS4.SSS3.p1.3.m3.3.3.cmml" xref="S2.SS4.SSS3.p1.3.m3.3.3"><times id="S2.SS4.SSS3.p1.3.m3.3.3.2.cmml" xref="S2.SS4.SSS3.p1.3.m3.3.3.2"></times><ci id="S2.SS4.SSS3.p1.3.m3.3.3.3.cmml" xref="S2.SS4.SSS3.p1.3.m3.3.3.3">𝑃</ci><apply id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.cmml" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1"><csymbol cd="latexml" id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.1.cmml" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.1">conditional</csymbol><ci id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.2.cmml" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.2">𝑦</ci><list id="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.3.1.cmml" xref="S2.SS4.SSS3.p1.3.m3.3.3.1.1.1.3.2"><ci id="S2.SS4.SSS3.p1.3.m3.1.1.cmml" xref="S2.SS4.SSS3.p1.3.m3.1.1">𝑥</ci><ci id="S2.SS4.SSS3.p1.3.m3.2.2.cmml" xref="S2.SS4.SSS3.p1.3.m3.2.2">𝜃</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS3.p1.3.m3.3c">P(y|x;\;\theta)</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.SSS3.p1.3.m3.3d">italic_P ( italic_y | italic_x ; italic_θ )</annotation></semantics></math>. However, in practice it is often difficult to find the translation with the highest probability due to the impractically large search space. Accordingly, to find a good but not necessarily the very ‘best’ (i.e. that with the highest probability given the model) translation, NMT usually relies instead on local search algorithms such as greedy search or beam search (cf. Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.F5" title="Figure 5 ‣ 2.4.2 Learning ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>). Translations are carried out by default using beam search, although the option exists to switch to greedy search if needed. This approach is consistent with many other NMT tools since beam search is a classic local search algorithm. Using a pre-defined beam width parameter K, the beam search algorithm keeps only the top-K possible translations as potential candidates. With each iteration, a new potential translation is formed by combining each candidate word with a new word. New candidate translations compete with each other using log probability values to obtain the new top-K most probable results. This process is continued until the end of the translation process, and the 1-best translation is output.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Subword Models</h3>
<div class="ltx_para" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.1">Translation by its very nature requires an open vocabulary, but restricted (e.g. 30k, 50k, or 70k) vocabularies are typically used for reasons of computational efficiency. However, the use of subword models aims to address this fixed vocabulary problem associated with NMT. The problem manifests itself in how previously unseen ‘out-of-vocabulary’ (OOV) words are handled. In such cases, a single ‘UNK’ (for ‘unknown’) token is used to ‘recognize’ the OOV word. Encoding rare and unknown words into sequences of subword units significantly reduces the problem and has thus given rise to a number of subword algorithms.</p>
</div>
<div class="ltx_para" id="S2.SS5.p2">
<p class="ltx_p" id="S2.SS5.p2.1">Optimally, this will be performed via morphological processing <cite class="ltx_cite ltx_citemacro_citep">(Passban et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib41" title="">2018</a>)</cite>, but good quality wide-coverage morphological analysers are not always available. Therefore it is common practice to use methods such as Byte Pair Encoding (BPE) <cite class="ltx_cite ltx_citemacro_citep">(Gage, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib18" title="">1994</a>)</cite> to break down rare and previously unseen words into subword models in order to significantly improve translation performance <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib50" title="">2016b</a>; Kudo, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib28" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS5.p3">
<p class="ltx_p" id="S2.SS5.p3.1">Designed for NMT, SentencePiece <cite class="ltx_cite ltx_citemacro_citep">(Kudo and Richardson, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib29" title="">2018</a>)</cite>, is a language-independent subword tokenizer that provides an open-source C++ and a Python implementation for subword units. An attractive feature of the tokenizer is that SentencePiece trains subword models directly from raw sentences.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6 </span>NMT Tools</h3>
<div class="ltx_para" id="S2.SS6.p1">
<p class="ltx_p" id="S2.SS6.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Kreutzer et al (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib27" title="">2019</a>)</cite> describe their Joey NMT platform<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/joeynmt/joeynmt" title="">https://github.com/joeynmt/joeynmt</a></span></span></span> as a minimalist NMT toolkit, based on PyTorch, which is designed especially for newcomers to the field. Joey NMT provides many popular NMT features in a simple code base enabling novice users to easily adapt the system to their particular requirements. The toolkit supports both RNN and Transformer architectures.</p>
</div>
<div class="ltx_para" id="S2.SS6.p2">
<p class="ltx_p" id="S2.SS6.p2.1">Given that adaptNMT is essentially an IPython wrapper layered on top of OpenNMT, it inherits all of OpenNMT’s features and continues to benefit from the work which goes into developing and maintaining its code base. adaptNMT offers a higher level of abstraction over OpenNMT where the focus is much more on usability, especially to newcomers to the field. Accordingly, it provides for easy and rapid deployment by enabling new features such as greater pre-processing, as well as GUI control over model building. It also contains green features in line with the current research drive towards smaller models with lower carbon footprints (cf. Sections <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.SS4" title="4.4 Environmental Impact ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4.4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S5" title="5 Discussion ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>). Such features make adaptNMT suitable for both educational and research environments. The key features differentiating adaptNMT from Joey NMT are outlined in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.T1" title="Table 1 ‣ 2.6 NMT Tools ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.2.1.1.1">adaptNMT is built upon OpenNMT and subsequently inherits all of its features.</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.2.2.1">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.2.2.2.1.1">
<tr class="ltx_tr" id="S2.T1.2.2.2.1.1.1">
<td class="ltx_td ltx_align_left" id="S2.T1.2.2.2.1.1.1.1">The interface is designed and fully implemented in Google Colab.</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.3.3.1">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.2.3.3.1.1">
<tr class="ltx_tr" id="S2.T1.2.3.3.1.1.1">
<td class="ltx_td ltx_align_left" id="S2.T1.2.3.3.1.1.1.1">Colab is easier to follow for practitioners since each step can be executed individually.</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.3.3.1.1.2">
<td class="ltx_td ltx_align_left" id="S2.T1.2.3.3.1.1.2.1">The approach is ideal in education since progression of the pipeline is demonstrated.</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.4.4.1">Training of models can be viewed and controlled using Colab Android or Apple apps.</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.5.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.5.5.1">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.2.5.5.1.1">
<tr class="ltx_tr" id="S2.T1.2.5.5.1.1.1">
<td class="ltx_td ltx_align_left" id="S2.T1.2.5.5.1.1.1.1">adaptNMT can be run in local mode enabling existing infrastructure to be utilised or in</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.5.5.1.1.2">
<td class="ltx_td ltx_align_left" id="S2.T1.2.5.5.1.1.2.1">hosted mode which allows rapid scaling of the infrastructure.</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.6.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.6.6.1">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.2.6.6.1.1">
<tr class="ltx_tr" id="S2.T1.2.6.6.1.1.1">
<td class="ltx_td ltx_align_left" id="S2.T1.2.6.6.1.1.1.1">Colab Pro+ provides individual researchers, or even small teams, the capacity to build</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.6.6.1.1.2">
<td class="ltx_td ltx_align_left" id="S2.T1.2.6.6.1.1.2.1">large models on an excellent infrastructure with very little resources.</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.7.7.1">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.2.7.7.1.1">
<tr class="ltx_tr" id="S2.T1.2.7.7.1.1.1">
<td class="ltx_td ltx_align_left" id="S2.T1.2.7.7.1.1.1.1">GUI controls can split a corpus into train, validation and test datasets.</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.8.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.8.8.1">GUI controls are available for hyperparameter customization in NMT training.</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.9.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.9.9.1">A green report outlines the country-specific kgCO<sub class="ltx_sub" id="S2.T1.2.9.9.1.1">2</sub> generated when training a model.</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.10.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.10.10.1">Autonotification notifies the user on completion of training.</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.11.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.2.11.11.1">A deploy function enables the immediate deployment of trained models.</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.12.12">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T1.2.12.12.1">The functionality of serverNMT is not available within Joey NMT.</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S2.T1.4.2" style="font-size:90%;">Key features differentiating adaptNMT from Joey NMT</span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS6.p3">
<p class="ltx_p" id="S2.SS6.p3.1">Other popular frameworks for NMT system-building include FAIRSEQ<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/facebookresearch/fairseq" title="">https://github.com/facebookresearch/fairseq</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Ott et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib39" title="">2019</a>)</cite>, an open-source sequence modelling toolkit based on PyTorch, that enables researchers to train models for translation, summarization and language modelling. Marian<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://marian-nmt.github.io" title="">https://marian-nmt.github.io</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Junczys-Dowmunt et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib24" title="">2018</a>)</cite>, developed using C++, is an NMT framework based on dynamic computation graphs. OpenNMT<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://opennmt.net" title="">https://opennmt.net</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Klein et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib26" title="">2017</a>)</cite> is an open-source NMT framework that has been widely adopted in the research community. The toolkit covers the entire MT workflow from the preparation of data to live inference.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.7 </span>Hyperparameter Optimization</h3>
<div class="ltx_para" id="S2.SS7.p1">
<p class="ltx_p" id="S2.SS7.p1.1">Hyperparameters are employed in order to customize machine learning models such as translation models. It has been shown that machine learning performance may be improved through hyperparameter optimization (HPO) rather than just using default settings <cite class="ltx_cite ltx_citemacro_citep">(Sanders and Giraud-Carrier, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib46" title="">2017</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS7.p2">
<p class="ltx_p" id="S2.SS7.p2.1">The principal methods of HPO are Grid Search <cite class="ltx_cite ltx_citemacro_citep">(Montgomery, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib36" title="">2019</a>)</cite> and Random Search <cite class="ltx_cite ltx_citemacro_citep">(Bergstra and Bengio, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib7" title="">2012</a>)</cite>. Grid search is an exhaustive technique which evaluates all parameter permutations. However, as the number of features grows, the amount of data permutations grows exponentially making optimization expensive in the context of developing translation models which require long build times. Accordingly, an effective, less computationally intensive alternative is to use random search which samples random configurations.</p>
</div>
<figure class="ltx_figure" id="S2.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="341" id="S2.F6.g1" src="extracted/5447326/autonmt_arch.png" width="471"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F6.3.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S2.F6.4.2" style="font-size:80%;">Proposed architecture for adaptNMT: a language-agnostic NMT development environment. The system is designed to run either in the cloud or using local infrastructure. Models are trained using parallel corpora. Visualization and extensive logging enable real-time monitoring. Models are developed using vanilla RNN-based NMT, Transformer-based approaches or (soon) transfer learning using a fine-tuning approach. Translation and evaluation can be carried out using either single models or ensembles.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Architecture of adaptNMT</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Having described the individual components of RNN- and Transformer-based NMT systems, we now present the adaptNMT tool itself, in which these components can be configured by the user. A high-level view of the system architecture of the platform is presented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.F6" title="Figure 6 ‣ 2.7 Hyperparameter Optimization ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>. Developed as an IPython notebook, the application uses the Pytorch implementation of <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">OpenNMT</span> for training models with SentencePiece used for training subword models. By using a Jupyter notebook, the application may be easily shared with others in the MT community. Furthermore, the difficulties involved in setting up the correct development environment have largely been removed since all required packages are downloaded on-the-fly as the application runs.</p>
</div>
<figure class="ltx_figure" id="S3.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S3.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="1741" id="S3.F6.sf1.g1" src="extracted/5447326/autoNMT_app.png" width="538"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F6.sf1.3.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S3.F6.sf1.4.2" style="font-size:80%;">Overview of adaptNMT. Key areas include initialization, pre-processing, environment setup, visualization, auto and custom NMT, training of subword model, training of main model, evaluation and deployment (cf. Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS1" title="3.1 adaptNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3.1</span></a>). </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S3.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="1625" id="S3.F6.sf2.g1" src="extracted/5447326/serverNMT_app.png" width="538"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F6.sf2.3.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S3.F6.sf2.4.2" style="font-size:80%;">Overview of serverNMT. Highlighted cells include initialization, environment setup, Anvil server, API functions, translation, model building, adaptNMT and running the server (cf. Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.SS2" title="3.2 serverNMT ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3.2</span></a>).</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S3.F7.3.2" style="font-size:90%;">adaptNMT and serverNMT</span></figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">There are options to run the system on local infrastructure or to run it as a Colab instance using Google Cloud. Translation models are developed using parallel text corpora of the source and target languages. A Tensorboard visualization provides a real-time graphical view of model training. The primary use-cases for the system are model building and a translation service, one or both of which can be selected at run-time. As illustrated in the system diagram in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.F6" title="Figure 6 ‣ 2.7 Hyperparameter Optimization ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>, generating an ensemble output while translating has also been facilitated. Models may also be deployed to a pre-configured location.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>adaptNMT</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The application may be run as an IPython Jupyter notebook or as a Google Colab application. Given the ease of integrating large Google drive storage into Colab, the application has been used exclusively as a Google Colab application for our own experiments, some of which are described in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4" title="4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>. The key features of the notebook are illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S3.F7" title="Figure 7 ‣ 3 Architecture of adaptNMT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Initialization and logging</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">Initialization enables connection to Google Drive to run experiments, automatic installation of Python, OpenNMT, SentencePiece, Pytorch and other applications. The visualization section enables real-time graphing of model development. All log files are stored and can be viewed to inspect training convergence, the model’s training and validation accuracy, changes in learning rates and cross entropy.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Modes of operation</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">There are two modes of operation: local or cloud. In local mode, the application is run so that models are built using the user’s local GPU resources. The option to use cloud mode enables users to develop models using Google’s GPU clusters. For shorter training times, the unpaid Colab option is adequate. However, for a small monthly subscription, the Google Colab Pro option is worthwhile since users have access to improved GPU and compute resources. Nevertheless, there are also environmental and running costs to consider (cf. Sections <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.SS4" title="4.4 Environmental Impact ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4.4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S5" title="5 Discussion ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>), although the Google Cloud is run on a platform which uses 100% renewables <cite class="ltx_cite ltx_citemacro_citep">(Lacoste et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib30" title="">2019</a>)</cite>. It is also a very cost-effective option for those working in the domain of low-resource languages since developing smaller models require shorter training times. However, users requiring long training times and very high compute resources will need to use their own hardware and run the application in local mode unless they have access to large budgets.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Customization of models</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">The system has been developed to allow users to select variations to the underlying model architecture. A vanilla RNN or Transformer approach may be selected to develop the NMT model. The customization mode enables users to specify the exact parameters required for the chosen approach. One of the features, AutoBuild, enables a user to build an NMT model in three simple steps: (i) upload source and target files, (ii) select RNN or Transformer, and (iii) click AutoBuild.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4 </span>Use of subword segmentation</h4>
<div class="ltx_para" id="S3.SS1.SSS4.p1">
<p class="ltx_p" id="S3.SS1.SSS4.p1.1">The type of optimizer to be used for learning can be specified, and users may also choose to employ different types of subword models when building the system. The subword model functionality allows the user to choose whether or not to use a subword model. Currently, the user specifies the vocabulary size and chooses either a SentencePiece unigram or a SentencePiece BPE subword model (cf. Section <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.SS5" title="2.5 Subword Models ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2.5</span></a>).</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS4.p2">
<p class="ltx_p" id="S3.SS1.SSS4.p2.1">A user may upload a dataset which includes the train, validation and test splits for both source and target languages. In cases where a user has not already created the required splits for model training, single source and target files may be uploaded. The splits needed to create the train, validation and test files are then automatically generated according to the user-specified split ratio. Given that building NMT models typically demands long training times, an automatic notification feature is incorporated that informs the user by email when model training has been completed.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.5 </span>Translation and evaluation</h4>
<div class="ltx_para" id="S3.SS1.SSS5.p1">
<p class="ltx_p" id="S3.SS1.SSS5.p1.1">In addition to supporting training of models, the application also allows for translation and evaluation of model performance. Translation using pre-built models is also parameterized. Users specify the name of the model as a hyperparameter which is then subsequently used to translate and evaluate the test files. The option for creating an ensemble output is also catered for, and users simply name the models which are to be used in generating the ensemble output.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS5.p2">
<p class="ltx_p" id="S3.SS1.SSS5.p2.1">Once the system has been built, the model to be used for translating the test set may be selected. To evaluate the quality of translation, humans usually provide the best insight, but they may not always be available, do not always agree, and are expensive to recruit for experiments. Accordingly, automatic evaluation metrics are typically used, especially by developers monitoring incremental progress of systems (cf. <cite class="ltx_cite ltx_citemacro_citet">Way (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib56" title="">2018</a>)</cite> for more on the pros and cons of human and automatic evaluation).</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS5.p3">
<p class="ltx_p" id="S3.SS1.SSS5.p3.1">Several automatic evaluation metrics provided by SacreBleu<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/mjpost/sacrebleu" title="">https://github.com/mjpost/sacrebleu</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Post, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib43" title="">2018</a>)</cite> are used: BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib40" title="">2002</a>)</cite>, TER <cite class="ltx_cite ltx_citemacro_citep">(Snover et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib51" title="">2006</a>)</cite> and ChrF <cite class="ltx_cite ltx_citemacro_citep">(Popović, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib42" title="">2015</a>)</cite>. Translation quality can also be evaluated using Meteor <cite class="ltx_cite ltx_citemacro_citep">(Denkowski and Lavie, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib16" title="">2014</a>)</cite> and F1 score <cite class="ltx_cite ltx_citemacro_citep">(Melamed et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib35" title="">2003</a>)</cite>. Note that BLEU, ChrF, Meteor and F1 are precision-based metrics, so higher scores are better, whereas TER is an error-based metric and lower scores indicate better translation quality. Evaluation options available include standard (truecase) and lowercase BLEU scores, a sentence-level BLEU score option, ChrF1 and ChrF3.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS5.p4">
<p class="ltx_p" id="S3.SS1.SSS5.p4.1">There are three levels of logging for model development, training and experimental results. A references section outlines resources which are relevant to developing, using and understanding adaptNMT. Validation during training is currently conducted using model accuracy and perplexity (PPL).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>serverNMT</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">A server application, serverNMT, was also developed and implemented as an IPython notebook. It can be configured to run either as a translation server or as a build server. A secure connection, implemented from serverNMT, can be made to websites hosting embedded web apps. At the core of serverNMT, there are two embedded Python web apps, one for translation services and another for developing models, both of which use the anvil.works platform.<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://anvil.works" title="">https://anvil.works</a></span></span></span></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">As a build server, serverNMT enables a window to the underlying cloud infrastructure in which NMT models can be trained. A web app hosted on another system may connect to this infrastructure made available by serverNMT.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Using an Anvil server embedded within serverNMT, the application continuously waits for communication to web apps and effectively enables a cloud infrastructure for NMT. Written as a REST server, it acts as an API for serving previously built models and facilities the integration of translation models with other systems.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Empirical Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Having described the theoretical background and the tool itself, we now evaluate the effectiveness of the adaptNMT approach by training models for English-Irish (EN-GA) and Irish-English (GA-EN) translation in the health domain using the <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">gaHealth</span> <cite class="ltx_cite ltx_citemacro_citep">(Lankford et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib33" title="">2022a</a>)</cite> corpus.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/seamusl/gaHealth" title="">https://github.com/seamusl/gaHealth</a></span></span></span> All experiments involved concatenating source and target corpora to create a shared vocabulary and a shared SentencePiece subword model. To benchmark the performance of our models, the EN-GA and GA-EN test datasets from the LoResMT2021 Shared Task<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/loresmt/loresmt-2021" title="">https://github.com/loresmt/loresmt-2021</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Ojha et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib38" title="">2021</a>)</cite> were used. These test datasets enabled the evaluation of the <span class="ltx_text ltx_font_italic" id="S4.p1.1.2">gaHealth</span> models since the shared task focused on an application of the health domain, namely the translation of Covid-related data. Furthermore, using an official test dataset from a shared task enables the direct comparison of our models’ performance with models entered by other teams, as well as future implementations.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The hyperparameters used for developing the models are outlined in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T2" title="Table 2 ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>. The details of the train, validation and test sets used by our NMT models are outlined in Tables <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T3" title="Table 3 ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T4" title="Table 4 ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>. In all cases, 502 lines were used from the LoResMT2021 validation dataset whereas the test dataset used 502 lines for EN-GA translation and 250 lines for GA-EN translation. Both were independent health-specific Covid test sets which were provided by LoResMT2021. There was one exception; due to a data overlap between the test and train datasets, a reduced test set was used when testing the <span class="ltx_text ltx_font_italic" id="S4.p2.1.1">gaHealth</span> en2ga* system.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">The results from the IIITT <cite class="ltx_cite ltx_citemacro_citep">(Puranik et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib44" title="">2021</a>)</cite> and UCF <cite class="ltx_cite ltx_citemacro_citep">(Chen and Fazio, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib13" title="">2021</a>)</cite> teams are included in Tables <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T5" title="Table 5 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T6" title="Table 6 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> so the performance of the <span class="ltx_text ltx_font_italic" id="S4.p3.1.1">gaHealth</span> models can be easily compared with the findings of the participating LoResMT2021 systems. IIITT fine-tuned an Opus MT model<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Helsinki-NLP/Opus-MT" title="">https://github.com/Helsinki-NLP/Opus-MT</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Tiedemann and Thottingal, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib54" title="">2020</a>)</cite> on the training dataset. UCF used transfer learning <cite class="ltx_cite ltx_citemacro_citep">(Zoph et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib59" title="">2016</a>)</cite>, unigram and subword segmentation methods for EN–GA and GA–EN translation.</p>
</div>
<figure class="ltx_table ltx_align_center" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.2.1.1.1.1">Hyperparameter</span></th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.2.1.1.2.1">Values</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.2.2.1">Learning rate</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.2.2.2">0.1, 0.01, 0.001, <span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.2.1">2</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.3.3.1">Batch size</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.3.3.2">1024, <span class="ltx_text ltx_font_bold" id="S4.T2.2.3.3.2.1">2048</span>, 4096, 8192</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.4.4.1">Attention heads</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.4.4.2">
<span class="ltx_text ltx_font_bold" id="S4.T2.2.4.4.2.1">2</span>, 4, <span class="ltx_text ltx_font_bold" id="S4.T2.2.4.4.2.2">8</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.5.5.1">Number of layers</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.5.5.2">5, <span class="ltx_text ltx_font_bold" id="S4.T2.2.5.5.2.1">6</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.6.6.1">Feed-forward dimension</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.6.6.2"><span class="ltx_text ltx_font_bold" id="S4.T2.2.6.6.2.1">2048</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.7.7.1">Embedding dimension</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.7.7.2">128, <span class="ltx_text ltx_font_bold" id="S4.T2.2.7.7.2.1">256</span>, 512</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.8.8.1">Label smoothing</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.8.8.2">
<span class="ltx_text ltx_font_bold" id="S4.T2.2.8.8.2.1">0.1</span>, 0.3</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.9.9.1">Dropout</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.9.9.2">0.1, <span class="ltx_text ltx_font_bold" id="S4.T2.2.9.9.2.1">0.3</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.10.10.1">Attention dropout</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.2.10.10.2"><span class="ltx_text ltx_font_bold" id="S4.T2.2.10.10.2.1">0.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" id="S4.T2.2.11.11.1">Average Decay</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S4.T2.2.11.11.2">0, <span class="ltx_text ltx_font_bold" id="S4.T2.2.11.11.2.1">0.0001</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.3.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.4.2" style="font-size:90%;">Hyperparameter Optimization for Transformer models. Optimal parameters are highlighted in bold <cite class="ltx_cite ltx_citemacro_citep">(Lankford et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib32" title="">2021b</a>)</cite>.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.2.1.1.1.1">Team</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.1.1.2.1">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.1.1.3.1">Train</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.2.1.1.4.1">Validation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.2.1.1.5.1">Test</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.2.2.1.1">adapt</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.1.2">covid_extended</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.1.3">13k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.1.4">502</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.1.5">500</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.3.2">
<td class="ltx_td ltx_align_left" id="S4.T3.2.3.2.1">adapt</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.2">combined_domains</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.3">65k</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.4">502</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.5">500</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.4.3">
<td class="ltx_td ltx_align_left" id="S4.T3.2.4.3.1">IIITT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.2">en2ga-b</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.3">8k</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.4">502</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.5">500</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.5.4">
<td class="ltx_td ltx_align_left" id="S4.T3.2.5.4.1">UCF</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.5.4.2">en2ga-a</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.5.4.3">8k</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.5.4.4">502</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.5.4.5">500</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.6.5">
<td class="ltx_td ltx_align_left" id="S4.T3.2.6.5.1"><span class="ltx_text ltx_font_italic" id="S4.T3.2.6.5.1.1">gaHealth</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.5.2">en2ga</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.5.3">24k</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.5.4">502</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.5.5">500</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.7.6">
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T3.2.7.6.1"><span class="ltx_text ltx_font_italic" id="S4.T3.2.7.6.1.1">gaHealth</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.2.7.6.2">en2ga*</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.2.7.6.3">24k</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.2.7.6.4">502</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.2.7.6.5">338</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.4.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.5.2" style="font-size:90%;">EN-GA train, validation and test dataset distributions. The baseline <span class="ltx_text ltx_font_italic" id="S4.T3.5.2.1">gaHealth</span> system was augmented with an 8k Covid dataset provided by LoResMT2021.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.1.1">Team</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.2.1">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.3.1">Train</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.4.1">Validation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.5.1">Test</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.2.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.2.2.1.1">IIITT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.2">ga2en-b</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.3">8k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.4">502</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.5">250</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.3.2">
<td class="ltx_td ltx_align_left" id="S4.T4.2.3.2.1">UCF</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.2">ga2en-b</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.3">8k</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.4">502</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.5">250</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.4.3">
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.2.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T4.2.4.3.1.1">gaHealth</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.2.4.3.2">ga2en</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.2.4.3.3">24k</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.2.4.3.4">502</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.2.4.3.5">250</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.6.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.7.2" style="font-size:90%;">GA-EN train, validation and test dataset distributions. The baseline <span class="ltx_text ltx_font_italic" id="S4.T4.7.2.1">gaHealth</span> system was augmented with an 8k Covid dataset provided by LoResMT2021. All overlaps were removed from the <span class="ltx_text ltx_font_italic" id="S4.T4.7.2.2">gaHealth</span> corpus prior to training the <span class="ltx_text ltx_font_italic" id="S4.T4.7.2.3">gaHealth</span> ga2en model.</span></figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Infrastructure</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Rapid prototype development was enabled through a Google Colab Pro subscription using NVIDIA Tesla P100 PCIe 16GB graphic cards and up to 27GB of memory when available <cite class="ltx_cite ltx_citemacro_citep">(Bisong, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib8" title="">2019</a>)</cite>. All <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">gaHealth</span> MT models were trained using <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">adaptNMT</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Metrics</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Automated metrics were used to determine the translation quality. In order to compare against our previous work, the performance of models is measured using three evaluation metrics, namely BLEU, TER and ChrF. These metrics indicate the accuracy of the translations derived from our NMT systems.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Case-insensitive BLEU scores at the corpus level are reported. Model training was stopped after 40k training steps or once an early stopping criterion of no improvement in validation accuracy for four consecutive iterations was recorded.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">PPL is often used to evaluate language models within NLP. It measures the effectiveness of a probability model in predicting a sample. As a metric for translation performance, it is important to keep low scores so that the number of alternative translations is reduced.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results: Automatic Evaluation</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The experimental results from LoResMT 2021 are summarized in Tables <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T5" title="Table 5 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T6" title="Table 6 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>. In the LoResMT2021 Shared Task, the highest-performing EN-GA system was submitted by the ADAPT team <cite class="ltx_cite ltx_citemacro_citep">(Lankford et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib31" title="">2021a</a>)</cite>. The system uses an extended Covid dataset, which is a combination of the 2021 MT Summit Covid baseline and a custom ADAPT Covid dataset. The model, developed within adaptNMT, uses a Transformer architecture with 2 heads. It performs well across all key translation metrics (BLEU: 36.0, TER: 0.531 and ChrF3: 0.6).The training of this EN-GA model is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.F8" title="Figure 8 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>.The model achieved a maximum validation accuracy of 30.0% and perplexity of 354 after 30k steps.</p>
</div>
<figure class="ltx_figure" id="S4.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_flex_size_2 ltx_img_landscape" height="111" id="S4.F8.g1" src="extracted/5447326/en-ga_acc_covid.png" width="155"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_flex_size_2 ltx_img_landscape" height="112" id="S4.F8.g2" src="extracted/5447326/en-ga_ppl_covid.png" width="155"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.3.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S4.F8.4.2" style="font-size:90%;"> <span class="ltx_text" id="S4.F8.4.2.1" style="font-size:89%;">adapt covid_extended system: training <span class="ltx_text ltx_font_italic" id="S4.F8.4.2.1.1">EN-GA</span> model with 13k lines consisting of the ADAPT 5k corpus and an 8k LoResMT2021 Covid corpus. The graph on the left illustrates OpenNMT accuracy and the graph on the right demonstrates perplexity.</span></span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T5.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T5.3.3.4.1">Team</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.3.3.5"><span class="ltx_text ltx_font_bold" id="S4.T5.3.3.5.1">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.m1.1a"><mo id="S4.T5.1.1.1.m1.1.1" stretchy="false" xref="S4.T5.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.1">TER</span> <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.2.2.2.m1.1"><semantics id="S4.T5.2.2.2.m1.1a"><mo id="S4.T5.2.2.2.m1.1.1" stretchy="false" xref="S4.T5.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.m1.1b"><ci id="S4.T5.2.2.2.m1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T5.3.3.3.1">ChrF3</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.3.3.3.m1.1"><semantics id="S4.T5.3.3.3.m1.1a"><mo id="S4.T5.3.3.3.m1.1.1" stretchy="false" xref="S4.T5.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.m1.1b"><ci id="S4.T5.3.3.3.m1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.3.4.1.1">UCF</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.2">en2ga-b</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.3">13.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.4">0.756</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.4.1.5">0.37</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.3.5.2.1">IIITT</th>
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.2">en2ga-b</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.3">25.8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.4">0.629</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.5.2.5">0.53</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.3.6.3.1">adapt</th>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.2">combined</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.3">32.8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.4">0.590</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.3.5">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.3.7.4.1"><span class="ltx_text ltx_font_italic" id="S4.T5.3.7.4.1.1">gaHealth</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.3.7.4.2">en2ga</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.7.4.3">33.3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.7.4.4">0.604</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.7.4.5">0.56</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.3.8.5.1">adapt</th>
<td class="ltx_td ltx_align_center" id="S4.T5.3.8.5.2">covid_extended</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.8.5.3">36.0</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.8.5.4">0.531</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.8.5.5">0.60</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T5.3.9.6.1"><span class="ltx_text ltx_font_italic" id="S4.T5.3.9.6.1.1">gaHealth</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.3.9.6.2">en2ga*</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.3.9.6.3"><span class="ltx_text ltx_font_bold" id="S4.T5.3.9.6.3.1">37.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.3.9.6.4">0.577</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.3.9.6.5">0.57</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.6.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S4.T5.7.2" style="font-size:90%;">EN-GA <span class="ltx_text ltx_font_italic" id="S4.T5.7.2.1">gaHealth</span> system compared with LoResMT 2021 EN-GA systems.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The results from the LoResMT2021 Shared Task were further improved by developing models using a bespoke health dataset, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.1">gaHealth</span>. Table <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T5" title="Table 5 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> shows an improvement of 1.6 BLEU points, a relative improvement of almost 4.5%, although TER and ChrF3 scores are a little worse. Validation accuracy and PPL in training the <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.2">gaHealth</span> models with adaptNMT are illustrated in Figures <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.F9" title="Figure 9 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">9</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.F10" title="Figure 10 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">10</span></a>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.F8" title="Figure 8 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates model training using the covid_extended dataset, also developed using adaptNMT. In training the <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.3">gaHealth</span> en2ga* system, as highlighted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.F9" title="Figure 9 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">9</span></a>, the EN-GA model was trained with the combined 16k <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.4">gaHealth</span> and 8k LoResMT2021 corpora. The model’s validation accuracy of 38.5% and perplexity of 113 achieved a BLEU score of 37.6 when evaluated with the test data.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">The training of the GA-EN <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.1">gaHealth</span> ga2en system with the combined 16k gaHealth corpus and 8k LoResMT2021 Covid corpus is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.F10" title="Figure 10 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">10</span></a>. This model achieves a validation accuracy of 39.5% and perplexity of 116 which results in a BLEU score of 57.6. This is significantly better (by 20 BLEU points) than for the reverse direction, as it is well-known that translating into a morphologically-rich language like Irish is always more difficult compared to when the same language acts as the source. This is confirmed by comparing the results for the UCF (13.5 vs. 21.3 BLEU) and IIITT (25.8 vs. 34.6) systems in Tables <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T5" title="Table 5 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T6" title="Table 6 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">Rapid convergence was observed while training the <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.1">gaHealth</span> models such that little accuracy improvement occurs after 30k steps, 10K fewer than for the reverse direction. Only marginal gains were achieved after this point and it actually declined in the case of the system trained using the covid_extended dataset, as the left-hand graph in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.F8" title="Figure 8 ‣ 4.3 Results: Automatic Evaluation ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a> shows.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">Of the models developed by the ADAPT team, the worst-performing model uses a larger 65k dataset. This is not surprising given that the dataset is from a generic domain of which only 20% is health related. The performance of this higher-resourced 65k line model lags behind the augmented <span class="ltx_text ltx_font_italic" id="S4.SS3.p5.1.1">gaHealth</span> model which was developed using just 24k lines.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T6.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T6.3.3.4.1">Team</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.3.3.5"><span class="ltx_text ltx_font_bold" id="S4.T6.3.3.5.1">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T6.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.1.1.1.m1.1"><semantics id="S4.T6.1.1.1.m1.1a"><mo id="S4.T6.1.1.1.m1.1.1" stretchy="false" xref="S4.T6.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.m1.1b"><ci id="S4.T6.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T6.2.2.2.1">TER</span> <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T6.2.2.2.m1.1"><semantics id="S4.T6.2.2.2.m1.1a"><mo id="S4.T6.2.2.2.m1.1.1" stretchy="false" xref="S4.T6.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.m1.1b"><ci id="S4.T6.2.2.2.m1.1.1.cmml" xref="S4.T6.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.2.2.2.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T6.3.3.3.1">ChrF3</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.3.3.3.m1.1"><semantics id="S4.T6.3.3.3.m1.1a"><mo id="S4.T6.3.3.3.m1.1.1" stretchy="false" xref="S4.T6.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.3.m1.1b"><ci id="S4.T6.3.3.3.m1.1.1.cmml" xref="S4.T6.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.3.4.1.1">UCF</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.3.4.1.2">ga2en-b</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.3.4.1.3">21.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.3.4.1.4">0.711</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.3.4.1.5">0.45</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.3.5.2.1">IIITT</th>
<td class="ltx_td ltx_align_center" id="S4.T6.3.5.2.2">ga2en-b</td>
<td class="ltx_td ltx_align_center" id="S4.T6.3.5.2.3">34.6</td>
<td class="ltx_td ltx_align_center" id="S4.T6.3.5.2.4">0.586</td>
<td class="ltx_td ltx_align_center" id="S4.T6.3.5.2.5">0.61</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T6.3.6.3.1"><span class="ltx_text ltx_font_italic" id="S4.T6.3.6.3.1.1">gaHealth</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.3.6.3.2">ga2en</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.3.6.3.3"><span class="ltx_text ltx_font_bold" id="S4.T6.3.6.3.3.1">57.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.3.6.3.4">0.385</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.3.6.3.5">0.71</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T6.6.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="S4.T6.7.2" style="font-size:90%;">GA-EN <span class="ltx_text ltx_font_italic" id="S4.T6.7.2.1">gaHealth</span> systems compared with LoResMT 2021 GA-EN systems.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.1">For translation in the GA-EN direction, the best-performing model for the LoResMT2021 Shared Task was developed by IIITT with a BLEU of 34.6, a TER of 0.586 and ChrF3 of 0.6. Accordingly, this serves as the baseline score by which our GA-EN model, developed using the <span class="ltx_text ltx_font_italic" id="S4.SS3.p6.1.1">gaHealth</span> corpus, can be benchmarked. The performance of the <span class="ltx_text ltx_font_italic" id="S4.SS3.p6.1.2">gaHealth</span> model offers an improvement across all metrics with a BLEU score of 57.6, a TER of 0.385 and a ChrF3 result of 0.71. In particular, the 66% relative improvement in BLEU score against the IIITT system is very significant.</p>
</div>
<figure class="ltx_figure" id="S4.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_flex_size_2 ltx_img_landscape" height="113" id="S4.F9.g1" src="extracted/5447326/en-ga_acc.png" width="155"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_flex_size_2 ltx_img_landscape" height="113" id="S4.F9.g2" src="extracted/5447326/en-ga_ppl.png" width="155"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F9.3.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text ltx_font_italic" id="S4.F9.4.2" style="font-size:80%;">gaHealth<span class="ltx_text ltx_font_upright" id="S4.F9.4.2.1"> en2ga* system: training </span>EN-GA<span class="ltx_text ltx_font_upright" id="S4.F9.4.2.2"> model with combined 16k gaHealth corpus and 8k LoResMT2021 Covid corpus. The graph on the left illustrates OpenNMT accuracy and the graph on the right demonstrates perplexity.</span></span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_flex_size_2 ltx_img_landscape" height="111" id="S4.F10.g1" src="extracted/5447326/ga-en_acc.png" width="155"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_flex_size_2 ltx_img_landscape" height="114" id="S4.F10.g2" src="extracted/5447326/ga-en_ppl.png" width="155"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F10.3.1.1" style="font-size:90%;">Figure 10</span>: </span><span class="ltx_text" id="S4.F10.4.2" style="font-size:80%;"> <span class="ltx_text ltx_font_italic" id="S4.F10.4.2.1">gaHealth</span> ga2en system: training <span class="ltx_text ltx_font_italic" id="S4.F10.4.2.2">GA-EN</span> model with combined 16k gaHealth corpus and 8k LoResMT2021 Covid corpus. The graph on the left illustrates OpenNMT accuracy and the graph on the right demonstrates perplexity. </span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Environmental Impact</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We were motivated by the findings of <cite class="ltx_cite ltx_citemacro_citet">Strubell et al (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib52" title="">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Bender et al (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib6" title="">2021</a>)</cite> to track the energy consumption required to train our models. Prototype model development used Colab Pro, which as part of Google Cloud is carbon neutral <cite class="ltx_cite ltx_citemacro_citep">(Lacoste et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib30" title="">2019</a>)</cite>. However, longer running Transformer experiments were conducted on local servers using 324 gCO<sub class="ltx_sub" id="S4.SS4.p1.1.1">2</sub> per kWh<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.seai.ie/publications/Energy-in-Ireland-2020.pdf" title="">https://www.seai.ie/publications/Energy-in-Ireland-2020.pdf</a></span></span></span><cite class="ltx_cite ltx_citemacro_citep">(SEAI, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib47" title="">2020</a>)</cite>. The net result was just under 10 kgCO<sub class="ltx_sub" id="S4.SS4.p1.1.2">2</sub> created for a full run of model development. Models developed during this study will be reused for ensemble experiments in the future so that work will have a life beyond this paper.
</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Stochastic Nuances</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">To evaluate the translation performance of an IPython-based application such as adaptNMT, a comparison with a Python script version of the same application, myNMT.py, was conducted. We built translation models in the EN-GA and the GA-EN directions using this script. The models developed with adaptNMT were trained on Google Colab using a 12GB Tesla K80 GPU, whereas the myNMT models were trained on a local machine using a 12GB Gigabyte 3060 graphics card. The results from evaluating these models are presented in Tables <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T7" title="Table 7 ‣ 4.5 Stochastic Nuances ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T8" title="Table 8 ‣ 4.5 Stochastic Nuances ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">Despite setting the same random seed, it is clear from Tables <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T7" title="Table 7 ‣ 4.5 Stochastic Nuances ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S4.T8" title="Table 8 ‣ 4.5 Stochastic Nuances ‣ 4 Empirical Evaluation ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a> that the translation performance of the adaptNMT models is better by 1.2 BLEU points (3.3% relative improvement) in the EN-GA direction and 1.0 BLEU point (1.8% relative improvement) in the GA-EN direction.</p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">Given the stochastic nature of machine learning, training models on different systems can give yield different results even with the same train, validation and test data. The performance differences can be attributed to the stochastic nature of the learning algorithm and evaluation procedure. Furthermore the platforms had different underlying system architectures which is another source of stochastic error.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T7.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T7.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T7.3.3.4.1">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T7.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.1.1.1.m1.1"><semantics id="S4.T7.1.1.1.m1.1a"><mo id="S4.T7.1.1.1.m1.1.1" stretchy="false" xref="S4.T7.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.1.1.1.m1.1b"><ci id="S4.T7.1.1.1.m1.1.1.cmml" xref="S4.T7.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T7.2.2.2.1">TER</span> <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T7.2.2.2.m1.1"><semantics id="S4.T7.2.2.2.m1.1a"><mo id="S4.T7.2.2.2.m1.1.1" stretchy="false" xref="S4.T7.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.2.2.2.m1.1b"><ci id="S4.T7.2.2.2.m1.1.1.cmml" xref="S4.T7.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.2.2.2.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T7.3.3.3.1">ChrF3</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.3.3.3.m1.1"><semantics id="S4.T7.3.3.3.m1.1a"><mo id="S4.T7.3.3.3.m1.1.1" stretchy="false" xref="S4.T7.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.3.3.3.m1.1b"><ci id="S4.T7.3.3.3.m1.1.1.cmml" xref="S4.T7.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.3.4.1.1">adaptNMT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.3.4.1.2">37.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.3.4.1.3">0.577</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.3.4.1.4">0.570</td>
</tr>
<tr class="ltx_tr" id="S4.T7.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T7.3.5.2.1">myNMT</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.3.5.2.2">36.4</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.3.5.2.3">0.622</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.3.5.2.4">0.56</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T7.5.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="S4.T7.6.2" style="font-size:90%;">Stochastic differences between EN-GA systems</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T8.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T8.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T8.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T8.3.3.4.1">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T8.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T8.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T8.1.1.1.m1.1"><semantics id="S4.T8.1.1.1.m1.1a"><mo id="S4.T8.1.1.1.m1.1.1" stretchy="false" xref="S4.T8.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.m1.1b"><ci id="S4.T8.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T8.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T8.2.2.2.1">TER</span> <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T8.2.2.2.m1.1"><semantics id="S4.T8.2.2.2.m1.1a"><mo id="S4.T8.2.2.2.m1.1.1" stretchy="false" xref="S4.T8.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.m1.1b"><ci id="S4.T8.2.2.2.m1.1.1.cmml" xref="S4.T8.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.2.2.2.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T8.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T8.3.3.3.1">ChrF3</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T8.3.3.3.m1.1"><semantics id="S4.T8.3.3.3.m1.1a"><mo id="S4.T8.3.3.3.m1.1.1" stretchy="false" xref="S4.T8.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.3.3.3.m1.1b"><ci id="S4.T8.3.3.3.m1.1.1.cmml" xref="S4.T8.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T8.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T8.3.4.1.1">adaptNMT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.3.4.1.2">57.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.3.4.1.3">0.385</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.3.4.1.4">0.71</td>
</tr>
<tr class="ltx_tr" id="S4.T8.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T8.3.5.2.1">myNMT</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T8.3.5.2.2">56.6</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T8.3.5.2.3">0.399</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T8.3.5.2.4">0.703</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T8.5.1.1" style="font-size:90%;">Table 8</span>: </span><span class="ltx_text" id="S4.T8.6.2" style="font-size:90%;">Stochastic differences between EN-GA systems</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The mathematical first principles governing NMT development were presented to demonstrate the mechanics of what happens during model training. Several parameters in Equations (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E2" title="2 ‣ 2.4.1 Modelling ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>)-(<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#S2.E8" title="8 ‣ 2.4.2 Learning ‣ 2.4 NMT ‣ 2 Neural Networks for MT ‣ adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>) are configurable within the adaptNMT application.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">The environmental impact of technology, and the measurement of its effects, has gained a lot of prominence in recent years <cite class="ltx_cite ltx_citemacro_citep">(Henderson et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib20" title="">2020</a>)</cite>. Indeed, this may be viewed as a natural response to truly massive NLP models which have been developed by large multinational corporations. In particular, HPO of NMT models can be particularly demanding if hyperparameter fine-tuning is conducted across a broad search space. As part of their work on NMT architectures, the Google Brain team required more than 250,000 GPU hours for NMT HPO <cite class="ltx_cite ltx_citemacro_citep">(Britz et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib11" title="">2017</a>)</cite>. Training of these models was conducted using Tesla K40m and Tesla K80 GPUs with maximum power consumption between 235W and 300W, giving rise to potentially in excess of 60 MWh of energy usage. Even though the Google Cloud is carbon neutral, one must consider the opportunity cost of this energy usage.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">A plethora of tools to evaluate the carbon footprint of NLP <cite class="ltx_cite ltx_citemacro_citep">(Bannour et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib5" title="">2021</a>)</cite> has subsequently been developed and the concept of sustainable NLP has become an important research track in its own right at many high profile conferences such as the EACL 2021 <span class="ltx_text ltx_font_italic" id="S5.p3.1.1">Green and Sustainable NLP</span> track.<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://2021.eacl.org/news/green-and-sustainable-nlp" title="">https://2021.eacl.org/news/green-and-sustainable-nlp</a></span></span></span>
In light of such developments, a ‘green report’ was incorporated into adaptNMT whereby the kgCO<sub class="ltx_sub" id="S5.p3.1.2">2</sub> generated during model development is logged. This is very much in line with the industry trend of quantifying the impact of NLP on the environment; indeed, <cite class="ltx_cite ltx_citemacro_citet">Jooste et al (<a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib22" title="">2022a</a>)</cite> have demonstrated that high-performing MT systems can be built with much lower footprints, which not only reduce emissions, but also in the post-deployment phase deliver savings of almost 50% in energy costs for a real translation company.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">To evaluate system performance in translating health data in the EN-GA direction, we used the adaptNMT application to develop an MT model for the LoResMT2021 Shared Task. The application was subsequently used to develop an MT model for translating in the GA-EN direction. In both cases, high-performing models achieving SOTA scores were achieved by using adaptNMT to develop Transformer models capable of generating high-quality output.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">The danger of relying on increasingly large language models has been well-documented in the literature. Such discussion focuses not just on the environmental impact but also highlights the impact of in-built bias and the inherent risks that large models pose for low-resource languages <cite class="ltx_cite ltx_citemacro_citep">(Bender et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib6" title="">2021</a>)</cite>. Using an easily-understood framework such as adaptNMT, the benefits of developing high-performing NMT models with smaller in-domain datasets should not be overlooked.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Work</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We introduced adaptNMT, an application for NMT which manages the complete workflow of model development, evaluation and deployment. The performance of the application was demonstrated in the context of generating an EN-GA translation model which ranked 1st in the LoResMT2021 shared task, and validated against a standalone reimplementation of both EN-GA and GA-EN systems outside the tool, where no drop-off in performance was seen.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">With regard to future work, development will focus more on tracking environmental costs and integrating new transfer learning methods. Modern zero-shot and few-shot approaches, adopted by GPT3 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib12" title="">2020</a>)</cite> and Facebook LASER <cite class="ltx_cite ltx_citemacro_citep">(Artetxe and Schwenk, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib3" title="">2019</a>)</cite> frameworks, will be integrated. Whereas the existing adaptNMT application focuses on customizing NMT models, a separate application adaptLLM will be developed to fine-tune large language models, in particular those that focus on low-resource language pairs such as NLLB <cite class="ltx_cite ltx_citemacro_citep">(Costa-jussà et al, <a class="ltx_ref" href="https://arxiv.org/html/2403.02367v1#bib.bib15" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">The green report embedded within the application is our first implementation of a sustainable NLP feature within adaptNMT. It is planned to develop this feature further to include an improved UI and user recommendations about how to develop greener models. As an open-source project, we hope the community will add to its development by contributing new ideas and improvements.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Declarations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This research is supported by Science Foundation Ireland through ADAPT Centre (Grant 13/RC/2106) (www.adaptcentre.ie) at Dublin City University. This research was also funded by the Munster Technological University and the National Relay Station (NRS) of Ireland.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
</ul>
<span class="ltx_ERROR undefined" id="bib.1">\bibcommenthead</span>
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Araabi and Monz (2020)</span>
<span class="ltx_bibblock">
Araabi A, Monz C (2020) Optimizing transformer for low-resource neural machine
translation. In: Proceedings of the 28th International Conference on
Computational Linguistics. International Committee on Computational
Linguistics, Barcelona, Spain (Online), pp 3429–3435,
<a class="ltx_ref" href="https:/doi.org/10.18653/v1/2020.coling-main.304" title="">10.18653/v1/2020.coling-main.304</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.coling-main.304" title="">https://aclanthology.org/2020.coling-main.304</a>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arrieta et al (2020)</span>
<span class="ltx_bibblock">
Arrieta AB, Díaz-Rodríguez N, Del Ser J, et al (2020) Explainable
artificial intelligence (XAI): Concepts, taxonomies, opportunities and
challenges toward responsible ai. Information Fusion 58:82–115

<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe and Schwenk (2019)</span>
<span class="ltx_bibblock">
Artetxe M, Schwenk H (2019) Massively multilingual sentence embeddings for
zero-shot cross-lingual transfer and beyond. Transactions of the Association
for Computational Linguistics 7:597–610

<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al (2014)</span>
<span class="ltx_bibblock">
Bahdanau D, Cho K, Bengio Y (2014) Neural machine translation by jointly
learning to align and translate. arXiv preprint arXiv:14090473

<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bannour et al (2021)</span>
<span class="ltx_bibblock">
Bannour N, Ghannay S, Névéol A, et al (2021) Evaluating the carbon
footprint of NLP methods: a survey and analysis of existing tools. In:
Proceedings of the Second Workshop on Simple and Efficient Natural Language
Processing. Association for Computational Linguistics, Virtual, pp 11–21,
<a class="ltx_ref" href="https:/doi.org/10.18653/v1/2021.sustainlp-1.2" title="">10.18653/v1/2021.sustainlp-1.2</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.sustainlp-1.2" title="">https://aclanthology.org/2021.sustainlp-1.2</a>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et al (2021)</span>
<span class="ltx_bibblock">
Bender EM, Gebru T, McMillan-Major A, et al (2021) On the dangers of stochastic
parrots: Can language models be too big? In: Proceedings of the 2021 ACM
Conference on Fairness, Accountability, and Transparency. Association for
Computing Machinery, New York, NY, USA, FAccT ’21, p 610–623,
<a class="ltx_ref" href="https:/doi.org/10.1145/3442188.3445922" title="">10.1145/3442188.3445922</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3442188.3445922" title="">https://doi.org/10.1145/3442188.3445922</a>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergstra and Bengio (2012)</span>
<span class="ltx_bibblock">
Bergstra J, Bengio Y (2012) Random search for hyper-parameter optimization.
Journal of machine learning research 13(2):281–305

<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bisong (2019)</span>
<span class="ltx_bibblock">
Bisong E (2019) Building Machine Learning and Deep Learning Models on Google
Cloud Platform: A Comprehensive Guide for Beginners. Apress, Berkeley, CA

<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojar et al (2017)</span>
<span class="ltx_bibblock">
Bojar O, Chatterjee R, Federmann C, et al (2017) Findings of the 2017
conference on machine translation (WMT17). In: Proceedings of the Second
Conference on Machine Translation. Association for Computational Linguistics,
Copenhagen, Denmark, pp 169–214, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/W17-4717" title="">10.18653/v1/W17-4717</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aclweb.org/anthology/W17-4717" title="">https://www.aclweb.org/anthology/W17-4717</a>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojar et al (2018)</span>
<span class="ltx_bibblock">
Bojar O, Federmann C, Fishel M, et al (2018) Findings of the 2018 conference on
machine translation (WMT18). In: Proceedings of the Third Conference on
Machine Translation: Shared Task Papers. Association for Computational
Linguistics, Belgium, Brussels, pp 272–303, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/W18-6401" title="">10.18653/v1/W18-6401</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aclweb.org/anthology/W18-6401" title="">https://www.aclweb.org/anthology/W18-6401</a>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Britz et al (2017)</span>
<span class="ltx_bibblock">
Britz D, Goldie A, Luong MT, et al (2017) Massive exploration of neural machine
translation architectures. In: Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Processing. Association for
Computational Linguistics, Copenhagen, Denmark, pp 1442–1451,
<a class="ltx_ref" href="https:/doi.org/10.18653/v1/D17-1151" title="">10.18653/v1/D17-1151</a>, URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D17-1151" title="">https://aclanthology.org/D17-1151</a>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al (2020)</span>
<span class="ltx_bibblock">
Brown T, Mann B, Ryder N, et al (2020) Language models are few-shot learners.
Advances in neural information processing systems 33:1877–1901

<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Fazio (2021)</span>
<span class="ltx_bibblock">
Chen W, Fazio B (2021) The UCF systems for the LoResMT 2021 machine
translation shared task. In: Proceedings of the 4th Workshop on Technologies
for MT of Low Resource Languages (LoResMT2021). Association for Machine
Translation in the Americas, Virtual, pp 129–133,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.mtsummit-loresmt.13" title="">https://aclanthology.org/2021.mtsummit-loresmt.13</a>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al (2014)</span>
<span class="ltx_bibblock">
Cho K, van Merriënboer B, Bahdanau D, et al (2014) On the properties of
neural machine translation: Encoder–decoder approaches. In: Proceedings of
SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical
Translation. Association for Computational Linguistics, Doha, Qatar, pp
103–111, <a class="ltx_ref" href="https:/doi.org/10.3115/v1/W14-4012" title="">10.3115/v1/W14-4012</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W14-4012" title="">https://aclanthology.org/W14-4012</a>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costa-jussà et al (2022)</span>
<span class="ltx_bibblock">
Costa-jussà MR, Cross J, Çelebi O, et al (2022) No language left
behind: Scaling human-centered machine translation. arXiv preprint
arXiv:220704672

<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Denkowski and Lavie (2014)</span>
<span class="ltx_bibblock">
Denkowski M, Lavie A (2014) Meteor universal: Language specific translation
evaluation for any target language. In: Proceedings of the Ninth Workshop on
Statistical Machine Translation. Association for Computational Linguistics,
Baltimore, Maryland, USA, pp 376–380, <a class="ltx_ref" href="https:/doi.org/10.3115/v1/W14-3348" title="">10.3115/v1/W14-3348</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W14-3348" title="">https://aclanthology.org/W14-3348</a>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Forcada (2017)</span>
<span class="ltx_bibblock">
Forcada ML (2017) Making sense of neural machine translation. Translation
Spaces 6(2):291–309

<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gage (1994)</span>
<span class="ltx_bibblock">
Gage P (1994) A new algorithm for data compression. C Users Journal
12(2):23–38

<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunning et al (2019)</span>
<span class="ltx_bibblock">
Gunning D, Stefik M, Choi J, et al (2019) Xai—explainable artificial
intelligence. Science Robotics 4(37):eaay7120

<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et al (2020)</span>
<span class="ltx_bibblock">
Henderson P, Hu J, Romoff J, et al (2020) Towards the systematic reporting of
the energy and carbon footprints of machine learning. Journal of Machine
Learning Research 21(248):1–43

<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hochreiter and Schmidhuber (1997)</span>
<span class="ltx_bibblock">
Hochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Computation
9(8):1735–1780

<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jooste et al (2022a)</span>
<span class="ltx_bibblock">
Jooste W, Haque R, Way A (2022a) Knowledge distillation: A method
for making neural machine translation more efficient. Information 13(2).
<a class="ltx_ref" href="https:/doi.org/10.3390/info13020088" title="">10.3390/info13020088</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mdpi.com/2078-2489/13/2/88" title="">https://www.mdpi.com/2078-2489/13/2/88</a>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jooste et al (2022b)</span>
<span class="ltx_bibblock">
Jooste W, Way A, Haque R, et al (2022b) Knowledge distillation for
sustainable neural machine translation. In: Proceedings of the 15th Biennial
Conference of the Association for Machine Translation in the Americas (Volume
2: Users and Providers Track and Government Track). Association for Machine
Translation in the Americas, Orlando, USA, pp 221–230,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.amta-upg.16" title="">https://aclanthology.org/2022.amta-upg.16</a>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Junczys-Dowmunt et al (2018)</span>
<span class="ltx_bibblock">
Junczys-Dowmunt M, Grundkiewicz R, Dwojak T, et al (2018) Marian: Fast neural
machine translation in C++. In: Proceedings of ACL 2018, System
Demonstrations. Association for Computational Linguistics, Melbourne,
Australia, pp 116–121, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/P18-4020" title="">10.18653/v1/P18-4020</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P18-4020" title="">https://aclanthology.org/P18-4020</a>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2014)</span>
<span class="ltx_bibblock">
Kingma DP, Ba J (2014) Adam: A method for stochastic optimization. arXiv
preprint arXiv:14126980

<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klein et al (2017)</span>
<span class="ltx_bibblock">
Klein G, Kim Y, Deng Y, et al (2017) OpenNMT: Open-source toolkit for
neural machine translation. In: Proceedings of ACL 2017, System
Demonstrations. Association for Computational Linguistics, Vancouver, Canada,
pp 67–72, URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P17-4012" title="">https://aclanthology.org/P17-4012</a>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kreutzer et al (2019)</span>
<span class="ltx_bibblock">
Kreutzer J, Bastings J, Riezler S (2019) Joey NMT: A minimalist NMT toolkit
for novices. In: Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP): System Demonstrations.
Association for Computational Linguistics, Hong Kong, China, pp 109–114,
<a class="ltx_ref" href="https:/doi.org/10.18653/v1/D19-3019" title="">10.18653/v1/D19-3019</a>, URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D19-3019" title="">https://aclanthology.org/D19-3019</a>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo (2018)</span>
<span class="ltx_bibblock">
Kudo T (2018) Subword regularization: Improving neural network translation
models with multiple subword candidates. arXiv preprint arXiv:180410959

<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo and Richardson (2018)</span>
<span class="ltx_bibblock">
Kudo T, Richardson J (2018) SentencePiece: A simple and language
independent subword tokenizer and detokenizer for neural text processing. In:
Proceedings of the 2018 Conference on Empirical Methods in Natural Language
Processing: System Demonstrations. Association for Computational Linguistics,
Brussels, Belgium, pp 66–71, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/D18-2012" title="">10.18653/v1/D18-2012</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D18-2012" title="">https://aclanthology.org/D18-2012</a>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lacoste et al (2019)</span>
<span class="ltx_bibblock">
Lacoste A, Luccioni A, Schmidt V, et al (2019) Quantifying the carbon emissions
of machine learning. arXiv preprint arXiv:191009700

<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lankford et al (2021a)</span>
<span class="ltx_bibblock">
Lankford S, Afli H, Way A (2021a) Machine translation in the covid
domain: an English-Irish case study for LoResMT 2021. In:
Proceedings of the 4th Workshop on Technologies for MT of Low Resource
Languages (LoResMT2021). Association for Machine Translation in the Americas,
Virtual, pp 144–150,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.mtsummit-loresmt.15" title="">https://aclanthology.org/2021.mtsummit-loresmt.15</a>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lankford et al (2021b)</span>
<span class="ltx_bibblock">
Lankford S, Afli H, Way A (2021b) Transformers for low-resource
languages: Is féidir linn! In: Proceedings of Machine Translation Summit
XVIII: Research Track. Association for Machine Translation in the Americas,
Virtual, pp 48–60,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.mtsummit-research.5" title="">https://aclanthology.org/2021.mtsummit-research.5</a>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lankford et al (2022a)</span>
<span class="ltx_bibblock">
Lankford S, Afli H, Ní Loinsigh Ó, et al (2022a)
gaHealth: An English–Irish bilingual corpus of health data. In:
Proceedings of the Thirteenth Language Resources and Evaluation Conference.
European Language Resources Association, Marseille, France, pp 6753–6758,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.lrec-1.727" title="">https://aclanthology.org/2022.lrec-1.727</a>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lankford et al (2022b)</span>
<span class="ltx_bibblock">
Lankford S, Afli H, Way A (2022b) Human evaluation of
English–Irish Transformer-Based NMT. Information 13(7):309. 19pp.

<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melamed et al (2003)</span>
<span class="ltx_bibblock">
Melamed ID, Green R, Turian JP (2003) Precision and recall of machine
translation. In: Companion Volume of the Proceedings of HLT-NAACL 2003 -
Short Papers, Edmonton, Canada, pp 61–63,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N03-2021" title="">https://aclanthology.org/N03-2021</a>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Montgomery (2019)</span>
<span class="ltx_bibblock">
Montgomery DC (2019) Design and analysis of experiments. Wiley, New York

<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Och and Ney (2003)</span>
<span class="ltx_bibblock">
Och FJ, Ney H (2003) A systematic comparison of various statistical alignment
models. Computational Linguistics 29(1):19–51.
<a class="ltx_ref" href="https:/doi.org/10.1162/089120103321337421" title="">10.1162/089120103321337421</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/J03-1002" title="">https://aclanthology.org/J03-1002</a>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ojha et al (2021)</span>
<span class="ltx_bibblock">
Ojha AK, Liu CH, Kann K, et al (2021) Findings of the LoResMT 2021 shared
task on COVID and sign language for low-resource languages. In: Proceedings
of the 4th Workshop on Technologies for MT of Low Resource Languages
(LoResMT2021). Association for Machine Translation in the Americas, Virtual,
pp 114–123,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.mtsummit-loresmt.11" title="">https://aclanthology.org/2021.mtsummit-loresmt.11</a>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ott et al (2019)</span>
<span class="ltx_bibblock">
Ott M, Edunov S, Baevski A, et al (2019) fairseq: A fast, extensible toolkit
for sequence modeling. In: Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics
(Demonstrations). Association for Computational Linguistics, Minneapolis,
Minnesota, pp 48–53, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/N19-4009" title="">10.18653/v1/N19-4009</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N19-4009" title="">https://aclanthology.org/N19-4009</a>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al (2002)</span>
<span class="ltx_bibblock">
Papineni K, Roukos S, Ward T, et al (2002) Bleu: a method for automatic
evaluation of machine translation. In: Proceedings of the 40th annual meeting
of the Association for Computational Linguistics, Philadelphia, PA, pp
311–318

<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Passban et al (2018)</span>
<span class="ltx_bibblock">
Passban P, Way A, Liu Q (2018) Tailoring neural architectures for translating
from morphologically rich languages. In: Proceedings of the 27th
International Conference on Computational Linguistics. Association for
Computational Linguistics, Santa Fe, New Mexico, USA, pp 3134–3145,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/C18-1265" title="">https://aclanthology.org/C18-1265</a>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popović (2015)</span>
<span class="ltx_bibblock">
Popović M (2015) chrF: character n-gram F-score for automatic MT
evaluation. In: Proceedings of the Tenth Workshop on Statistical Machine
Translation. Association for Computational Linguistics, Lisbon, Portugal, pp
392–395, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/W15-3049" title="">10.18653/v1/W15-3049</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W15-3049" title="">https://aclanthology.org/W15-3049</a>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post (2018)</span>
<span class="ltx_bibblock">
Post M (2018) A call for clarity in reporting BLEU scores. In: Proceedings of
the Third Conference on Machine Translation: Research Papers. Association for
Computational Linguistics, Brussels, Belgium, pp 186–191,
<a class="ltx_ref" href="https:/doi.org/10.18653/v1/W18-6319" title="">10.18653/v1/W18-6319</a>, URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W18-6319" title="">https://aclanthology.org/W18-6319</a>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puranik et al (2021)</span>
<span class="ltx_bibblock">
Puranik K, Hande A, Priyadharshini R, et al (2021) Attentive fine-tuning of
transformers for translation of low-resourced languages @LoResMT 2021.
In: Proceedings of the 4th Workshop on Technologies for MT of Low Resource
Languages (LoResMT2021). Association for Machine Translation in the Americas,
Virtual, pp 134–143,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.mtsummit-loresmt.14" title="">https://aclanthology.org/2021.mtsummit-loresmt.14</a>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rumelhart et al (1986)</span>
<span class="ltx_bibblock">
Rumelhart DE, Hinton GE, Williams RJ (1986) Learning representations by
back-propagating errors. Nature 323(6088):533–536

<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanders and Giraud-Carrier (2017)</span>
<span class="ltx_bibblock">
Sanders S, Giraud-Carrier C (2017) Informing the use of hyperparameter
optimization through metalearning. In: 2017 IEEE International Conference on
Data Mining (ICDM), IEEE, New Orleans, LA, USA, pp 1051–1056

<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">SEAI (2020)</span>
<span class="ltx_bibblock">
SEAI (2020) Sustainable Energy in Ireland.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.seai.ie/publications/Energy-in-Ireland-2020.pdf" title="">https://www.seai.ie/publications/Energy-in-Ireland-2020.pdf</a>, accessed:
2022-03-14

<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich and Zhang (2019)</span>
<span class="ltx_bibblock">
Sennrich R, Zhang B (2019) Revisiting low-resource neural machine translation:
A case study. In: Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics. Association for Computational Linguistics,
Florence, Italy, pp 211–221, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/P19-1021" title="">10.18653/v1/P19-1021</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P19-1021" title="">https://aclanthology.org/P19-1021</a>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al (2016a)</span>
<span class="ltx_bibblock">
Sennrich R, Haddow B, Birch A (2016a) Edinburgh neural machine
translation systems for WMT 16. In: Proceedings of the First Conference on
Machine Translation: Volume 2, Shared Task Papers. Association for
Computational Linguistics, Berlin, Germany, pp 371–376,
<a class="ltx_ref" href="https:/doi.org/10.18653/v1/W16-2323" title="">10.18653/v1/W16-2323</a>, URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W16-2323" title="">https://aclanthology.org/W16-2323</a>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al (2016b)</span>
<span class="ltx_bibblock">
Sennrich R, Haddow B, Birch A (2016b) Neural machine translation
of rare words with subword units. In: Proceedings of the 54th Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long Papers).
Association for Computational Linguistics, Berlin, Germany, pp 1715–1725,
<a class="ltx_ref" href="https:/doi.org/10.18653/v1/P16-1162" title="">10.18653/v1/P16-1162</a>, URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P16-1162" title="">https://aclanthology.org/P16-1162</a>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snover et al (2006)</span>
<span class="ltx_bibblock">
Snover M, Dorr B, Schwartz R, et al (2006) A study of translation edit rate
with targeted human annotation. In: Proceedings of the 7th Conference of the
Association for Machine Translation in the Americas: Technical Papers.
Association for Machine Translation in the Americas, Cambridge,
Massachusetts, USA, pp 223–231,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2006.amta-papers.25" title="">https://aclanthology.org/2006.amta-papers.25</a>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strubell et al (2019)</span>
<span class="ltx_bibblock">
Strubell E, Ganesh A, McCallum A (2019) Energy and policy considerations for
deep learning in NLP. In: Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics. Association for Computational
Linguistics, Florence, Italy, pp 3645–3650, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/P19-1355" title="">10.18653/v1/P19-1355</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P19-1355" title="">https://aclanthology.org/P19-1355</a>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutskever et al (2014)</span>
<span class="ltx_bibblock">
Sutskever I, Vinyals O, Le QV (2014) Sequence to sequence learning with neural
networks. In: Proceedings of Advances in Neural Information Processing
Systems, Montréal, Canada, 9pp.

<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann and Thottingal (2020)</span>
<span class="ltx_bibblock">
Tiedemann J, Thottingal S (2020) OPUS-MT – building open translation
services for the world. In: Proceedings of the 22nd Annual Conference of the
European Association for Machine Translation. European Association for
Machine Translation, Lisboa, Portugal, pp 479–480,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.eamt-1.61" title="">https://aclanthology.org/2020.eamt-1.61</a>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al (2017)</span>
<span class="ltx_bibblock">
Vaswani A, Shazeer N, Parmar N, et al (2017) Attention is all you need. In:
Proceedings of the 31st Conference on Neural Information Processing Systems
(NIPS 2017), Long Beach, CA, USA, 9pp.

<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Way (2018)</span>
<span class="ltx_bibblock">
Way A (2018) Quality expectations of machine translation. In: Moorkens J,
Castilho S, Gaspari F, et al (eds) Translation Quality Assessment: From
Principles to Practice. Springer, Cham, Switzerland, p 159–178

<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Way (2019)</span>
<span class="ltx_bibblock">
Way A (2019) Machine translation: Where are we at today? In: Angelone E, Massey
G, Ehrensberger-Dow M (eds) The Bloomsbury Companion to Language Industry
Studies. Bloomsbury, London, p 311—332

<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al (2020)</span>
<span class="ltx_bibblock">
Yang S, Wang Y, Chu X (2020) A survey of deep learning techniques for neural
machine translation. arXiv preprint arXiv:200207526

<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zoph et al (2016)</span>
<span class="ltx_bibblock">
Zoph B, Yuret D, May J, et al (2016) Transfer learning for low-resource neural
machine translation. In: Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing. Association for Computational
Linguistics, Austin, Texas, pp 1568–1575, <a class="ltx_ref" href="https:/doi.org/10.18653/v1/D16-1163" title="">10.18653/v1/D16-1163</a>,
URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D16-1163" title="">https://aclanthology.org/D16-1163</a>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</span>
</li>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Mar  4 11:56:52 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
