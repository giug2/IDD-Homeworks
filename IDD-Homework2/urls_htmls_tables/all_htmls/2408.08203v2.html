<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>From Clicks to Carbon: The Environmental Toll of Recommender Systems</title>
<!--Generated on Thu Aug 22 10:09:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Recommender Systems,  Reproducibility,  Carbon Footprint,  Deep Learning,  Energy Consumption,  Green Computing,  GreenRecSys" lang="en" name="keywords"/>
<base href="/html/2408.08203v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S1" title="In From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S2" title="In From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3" title="In From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Comparative Study: Recommender Systems Research in 2023 versus 2013</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3.SS0.SSS0.Px1" title="In 3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title">Hardware:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3.SS0.SSS0.Px2" title="In 3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title">Libraries:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3.SS0.SSS0.Px3" title="In 3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title">Experimental Pipeline:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3.SS0.SSS0.Px4" title="In 3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title">Open-Source Code:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3.SS0.SSS0.Px5" title="In 3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title">Datasets:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4" title="In From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS1" title="In 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Pipeline</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS1.SSS1" title="In 4.1. Experimental Pipeline ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Datasets:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS1.SSS2" title="In 4.1. Experimental Pipeline ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Algorithms:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS2" title="In 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Representative Pipelines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS3" title="In 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Calculating Greenhouse Gas Emission</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS3.SSS1" title="In 4.3. Calculating Greenhouse Gas Emission ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Measuring Electrical Energy Consumption</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS3.SSS2" title="In 4.3. Calculating Greenhouse Gas Emission ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Calculating Greenhouse Gas Emissions Based on Electricity Consumption</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.SS4" title="In 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Hardware</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5" title="In From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS1" title="In 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>The energy consumption of a 2023 recommender systems research paper</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS1.SSS1" title="In 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>The Energy Consumption of an Algorithm and Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS1.SSS2" title="In 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>The Energy Consumption of an Experimental Pipeline</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS1.SSS3" title="In 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>The Energy Consumption of a Paper</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS2" title="In 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Energy Consumption and Performance Trade-Off</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS3" title="In 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Carbon Footprint and Trends</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS3.SSS1" title="In 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.1 </span>The Carbon Footprint of Experiments at ACM Recsys 2023</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS3.SSS2" title="In 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.2 </span>The Geographical Impact on the Carbon Footprint</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS3.SSS3" title="In 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.3 </span>The Hardware Impact on the Carbon Footprint</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS3.SSS4" title="In 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.4 </span>The Carbon Footprint of Recommender Systems 2013 vs. 2023</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S6" title="In From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S7" title="In From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">From Clicks to Carbon: 
<br class="ltx_break"/>The Environmental Toll of Recommender Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tobias Vente
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:tobias.vente@uni-siegen.de">tobias.vente@uni-siegen.de</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0003-8881-2379" title="ORCID identifier">0009-0003-8881-2379</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Intelligent Systems Group, University of Siegen</span><span class="ltx_text ltx_affiliation_streetaddress" id="id2.2.id2">Adolf-Reichwein-Straße 2a</span><span class="ltx_text ltx_affiliation_city" id="id3.3.id3">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">Germany</span><span class="ltx_text ltx_affiliation_postcode" id="id5.5.id5">57076</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lukas Wegmeth
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:lukas.wegmeth@uni-siegen.de">lukas.wegmeth@uni-siegen.de</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-8848-9434" title="ORCID identifier">0000-0001-8848-9434</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.1.id1">Intelligent Systems Group, University of Siegen</span><span class="ltx_text ltx_affiliation_streetaddress" id="id7.2.id2">Adolf-Reichwein-Straße 2a</span><span class="ltx_text ltx_affiliation_city" id="id8.3.id3">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id9.4.id4">Germany</span><span class="ltx_text ltx_affiliation_postcode" id="id10.5.id5">57076</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alan Said
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:alan@gu.se">alan@gu.se</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-2929-0529" title="ORCID identifier">0000-0002-2929-0529</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">University of Gothenburg</span><span class="ltx_text ltx_affiliation_city" id="id12.2.id2">Gothenburg</span><span class="ltx_text ltx_affiliation_country" id="id13.3.id3">Sweden</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joeran Beel
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:joeran.beel@uni-siegen.de">joeran.beel@uni-siegen.de</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-4537-5573" title="ORCID identifier">0000-0002-4537-5573</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id14.1.id1">Intelligent Systems Group, University of Siegen</span><span class="ltx_text ltx_affiliation_streetaddress" id="id15.2.id2">Adolf-Reichwein-Straße 2a</span><span class="ltx_text ltx_affiliation_city" id="id16.3.id3">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id17.4.id4">Germany</span><span class="ltx_text ltx_affiliation_postcode" id="id18.5.id5">57076</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id19.id1">As global warming soars, the need to assess the environmental impact of research is becoming increasingly urgent.
Despite this, few recommender systems research papers address their environmental impact.
In this study, we estimate the environmental impact of recommender systems research by reproducing typical experimental pipelines.
Our analysis spans 79 full papers from the 2013 and 2023 ACM RecSys conferences, comparing traditional “good old-fashioned AI” algorithms with modern deep learning algorithms.
We designed and reproduced representative experimental pipelines for both years, measuring energy consumption with a hardware energy meter and converting it to CO<sub class="ltx_sub" id="id19.id1.1">2</sub> equivalents.
Our results show that papers using deep learning algorithms emit approximately 42 times more CO<sub class="ltx_sub" id="id19.id1.2">2</sub> equivalents than papers using traditional methods.
On average, a single deep learning-based paper generates 3,297 kilograms of CO<sub class="ltx_sub" id="id19.id1.3">2</sub> equivalents—more than the carbon emissions of one person flying from New York City to Melbourne or the amount of CO<sub class="ltx_sub" id="id19.id1.4">2</sub> one tree sequesters over 300 years.</p>
</div>
<div class="ltx_keywords">Recommender Systems, Reproducibility, Carbon Footprint, Deep Learning, Energy Consumption, Green Computing, GreenRecSys
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>18th ACM Conference on Recommender Systems; October 14–18, 2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>18th ACM Conference on Recommender Systems (RecSys ’24), October 14–18, 2024, Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3640457.3688074</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0505-2/24/10</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Hardware Impact on the environment</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Carbon emissions play a pivotal role in global warming by driving the greenhouse effect that leads to rising temperatures and extreme weather events <cite class="ltx_cite ltx_citemacro_citep">(Nukusheva et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib41" title="">2021</a>; Kweku et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib29" title="">2018</a>; Mitchell, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib38" title="">1989</a>; Hansen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib22" title="">2013</a>; Sinha and Chaturvedi, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib46" title="">2019</a>)</cite>.
With the ambitious goal of the <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">United Nations Framework Convention on Climate Change</em> to cap the global warming temperature increase at 1.5 degrees Celsius<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://unfccc.int/documents/184656" title="">https://unfccc.int/documents/184656</a></span></span></span>, reducing carbon emissions becomes crucial <cite class="ltx_cite ltx_citemacro_citep">(Hansen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib22" title="">2013</a>)</cite>.
Therefore, significant reductions in carbon emissions are urgently needed to meet the temperature target and mitigate the climate impact <cite class="ltx_cite ltx_citemacro_citep">(Hansen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib22" title="">2013</a>; Sinha and Chaturvedi, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib46" title="">2019</a>; Yoro and Daramola, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib58" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Concurrently, computationally heavy algorithms have become the norm for modern recommender systems, increasing the energy consumption of recommender systems experiments <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib11" title="">2020</a>)</cite>.
This trend is driven by a shift from traditional algorithms like <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">ItemKNN</em> (or so-called <em class="ltx_emph ltx_font_italic" id="S1.p2.1.2">good old-fashioned AI</em>) to more sophisticated deep learning techniques <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib62" title="">2019</a>; Mu, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib39" title="">2018</a>)</cite>.
The increased energy consumption of deep learning results in higher carbon emissions, further exacerbating environmental challenges.
With this backdrop, a relevant question is <em class="ltx_emph ltx_font_italic" id="S1.p2.1.3">what is the environmental toll of recommender systems experiments?</em></p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">However, the recommender systems community has paid little attention to the energy consumption and carbon emissions of their experiments <cite class="ltx_cite ltx_citemacro_citep">(Spillo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib47" title="">2023</a>)</cite>.
This oversight is increasingly concerning, given the global consensus on the urgent need for actions to mitigate carbon emissions <cite class="ltx_cite ltx_citemacro_citep">(Masson-Delmotte and on Climate Change, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib34" title="">2022</a>)</cite>.
As the recommender systems community strives to advance technologies that improve user experiences, it must also confront the environmental repercussions and their impact on climate change, especially during the current crisis.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Therefore, our interest is to answer the question: What are the ecological costs of recommender systems research, past and present?
In this paper, we answer the following research questions.</p>
</div>
<div class="ltx_para" id="S1.p5">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix1.1.1.1">RQ1:</span></span>
<div class="ltx_para" id="S1.I1.ix1.p1">
<p class="ltx_p" id="S1.I1.ix1.p1.1">How large is the energy consumption of a modern recommender systems research paper?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix2.1.1.1">RQ2:</span></span>
<div class="ltx_para" id="S1.I1.ix2.p1">
<p class="ltx_p" id="S1.I1.ix2.p1.1">How substantial is the energy consumption and performance trade-off between traditional and deep learning recommender system algorithms?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix3.1.1.1">RQ3:</span></span>
<div class="ltx_para" id="S1.I1.ix3.p1">
<p class="ltx_p" id="S1.I1.ix3.p1.1">How has the carbon footprint of recommender systems experiments changed with the transition from traditional to deep learning algorithms?</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In this work, we reproduce <em class="ltx_emph ltx_font_italic" id="S1.p6.1.1">representative</em> recommender systems experimental pipelines and show the extent of carbon emissions attributable to recommender systems experiments, providing a comparative analysis of recommender systems algorithms a decade apart.
Our analysis is based on 79 full papers from the ACM RecSys conference in 2013 and 2023, respectively.
Reproducing a representative experiment setup for each year enables us to conduct these experiments to directly measure their energy consumption and determine their carbon footprint across various hardware configurations, including laptops, workstations, and desktop PCs.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Our contribution is a comprehensive analysis of the carbon emissions associated with recommender system experiments and the reproduction of a representative recommender systems pipeline comparing 13 datasets and 23 algorithms from 2013 and 2023 on four hardware configurations.
Our results indicate that a recommender systems research paper utilizing deep learning algorithms produces, on average, 3,297 kilograms of CO<sub class="ltx_sub" id="S1.p7.1.1">2</sub> equivalents.
In contrast to a paper utilizing traditional algorithms from 2013, a 2023 research paper emits approximately 42 times more CO<sub class="ltx_sub" id="S1.p7.1.2">2</sub> equivalents.
Furthermore, we show that the geographical location, i.e., the means of energy production (fossil or renewable), can change the carbon footprint of recommender systems research experiments by up to 12 times.
Additionally, we found vast differences in the energy efficiency of different hardware configurations when performing recommender systems experiments, changing the carbon footprint of the same experiments by a factor of up to 10.
We highlight the energy consumption and carbon emissions of recommender system experiments to foster awareness and the development of more sustainable research practices in the field, ultimately contributing to more sustainable recommender systems experiments and research.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">The code used to execute and measure the experiments is publicly available in our GitHub<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ISG-Siegen/recsys-carbon-footprint" title="">https://github.com/ISG-Siegen/recsys-carbon-footprint</a></span></span></span> repository and further contains documentation to ensure the reproducibility of our experiments.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The impacts of greenhouse gases on the environment are extensively studied, with measurable effects seen in global warming and climate change.
This research underscores the importance of addressing greenhouse gases for the well-being of humanity and life on Earth.
According to meta-studies, scientists overwhelmingly agree that humans cause climate change <cite class="ltx_cite ltx_citemacro_citep">(Lynas et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib32" title="">2021</a>; Cook et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib14" title="">2016</a>)</cite>.
Additionally, tremendous efforts are being made to document the development of greenhouse gas emissions globally<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://edgar.jrc.ec.europa.eu/report_2023" title="">https://edgar.jrc.ec.europa.eu/report_2023</a></span></span></span>.
The greenhouse gas carbon dioxide (CO<sub class="ltx_sub" id="S2.p1.1.1">2</sub>) <cite class="ltx_cite ltx_citemacro_citep">(Cain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib8" title="">2019</a>)</cite> is emitted in the generation of electricity when using fossil fuels<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.iea.org/reports/co2-emissions-in-2022" title="">https://www.iea.org/reports/co2-emissions-in-2022</a></span></span></span>.
Particularly relevant to applied researchers, optimistic estimations forecast that more than 7% of global electricity demand will be attributed to computing by 2030 <cite class="ltx_cite ltx_citemacro_citep">(Gupta et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib21" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Electricity carries a direct monetary value and a cost associated with the damage caused by greenhouse gas emissions from its production, commonly referred to as <em class="ltx_emph ltx_font_italic" id="S2.p2.1.1">social cost</em> <cite class="ltx_cite ltx_citemacro_citep">(Ricke et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib44" title="">2018</a>)</cite>.
Hence, due to the harmful effects of fossil fuel electricity production, there is growing interest in green computing <cite class="ltx_cite ltx_citemacro_citep">(Paul et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib42" title="">2023</a>)</cite>.
In machine learning literature, energy consumption and carbon emissions from research experiments are well-known concerns <cite class="ltx_cite ltx_citemacro_citep">(Budennyy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib7" title="">2022</a>; Mehta et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib35" title="">2023</a>)</cite>.
Green computing in machine learning presents unique challenges <cite class="ltx_cite ltx_citemacro_citep">(Van Wynsberghe, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib50" title="">2021</a>)</cite>, particularly due to the shift to deep learning techniques, including, e.g., natural language processing <cite class="ltx_cite ltx_citemacro_citep">(Strubell et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib48" title="">2019</a>)</cite> and computer vision <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib65" title="">2023</a>)</cite>.
Natural language processing tasks are frequently solved with large language models in cutting-edge recommender systems research <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib55" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">The machine learning community actively provides guidelines and raises awareness for green and sustainable computing <cite class="ltx_cite ltx_citemacro_citep">(Lannelongue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib30" title="">2023</a>; Henderson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib24" title="">2020</a>)</cite>.
Numerous software libraries have also been published to measure the carbon footprint of existing experiments <cite class="ltx_cite ltx_citemacro_citep">(Jay et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib26" title="">2023</a>)</cite>.
However, despite these advancements, green and sustainable computing have yet to become established topics within recommender systems.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">To our knowledge, only one paper has directly examined the carbon footprint of recommender systems <cite class="ltx_cite ltx_citemacro_citep">(Spillo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib47" title="">2023</a>)</cite>.
This study, however, is limited to exploring the trade-off between algorithm performance and carbon footprint, relying on software-based power measurements rather than hardware-based analysis.
Research on automated recommender systems has considered computing power requirements <cite class="ltx_cite ltx_citemacro_citep">(Wegmeth and Beel, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib53" title="">2022</a>; Vente et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib51" title="">2023</a>)</cite>, significantly impacting energy consumption.
Additionally, another paper proposes an energy-efficient alternative to k-fold cross-validation <cite class="ltx_cite ltx_citemacro_citep">(Beel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib6" title="">2024</a>)</cite>, and recommender systems have been explored for their potential to enhance sustainability and energy efficiency in other domains <cite class="ltx_cite ltx_citemacro_citep">(Himeur et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib25" title="">2021</a>; Felfernig et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib19" title="">2023</a>)</cite>.
However, accurately estimating the global carbon footprint of recommender systems remains impossible without further research.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Our literature review reveals that current recommender systems papers do not openly disclose the estimated carbon footprint of their experiments.
Furthermore, to our knowledge, no recommender systems publication outlets publicly release statements regarding the carbon footprint of submissions.
An example of this in this area is ECIR 2024, which incorporated self-reported greenhouse gas emissions into its paper submissions, though no official results have been published yet.
We conclude that while awareness of the carbon footprint of recommender systems experiments is increasing, it remains insufficiently low to make a significant impact.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Comparative Study: Recommender Systems Research in 2023 versus 2013</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To answer our research questions, we reproduce measurements and estimations as accurately as possible.
Therefore, we summarize the historical development of recommender systems experiments by analyzing research papers from 2023 and 2013, reflected through peer-reviewed papers at a conference.
To this end, we present our analysis of all <em class="ltx_emph ltx_font_italic" id="S3.p1.1.1">full papers</em> accepted in the main track at ACM RecSys in 2013 (32 papers <cite class="ltx_cite ltx_citemacro_citep">(10., <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib2" title="">2013</a>)</cite>) and 2023 (47 papers <cite class="ltx_cite ltx_citemacro_citep">(10., <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib3" title="">2023</a>)</cite>).
All papers considered in this analysis are published in the ACM Digital Library.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">In the following paragraphs, we examine these recommender systems papers for <span class="ltx_text ltx_font_bold" id="S3.p2.1.1">hardware</span> specifications, software <span class="ltx_text ltx_font_bold" id="S3.p2.1.2">libraries</span>, design decisions in <span class="ltx_text ltx_font_bold" id="S3.p2.1.3">experimental pipelines</span>, the availability of <span class="ltx_text ltx_font_bold" id="S3.p2.1.4">open-source code</span> for reproducibility, and used <span class="ltx_text ltx_font_bold" id="S3.p2.1.5">datasets</span>.</p>
</div>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Hardware:</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">Only 15 (32%) full papers from ACM RecSys 2023 detail the hardware used for experiments, and consequently, 32 (68%) of the papers do not report this information.
All these 15 papers explicitly report usage of Nvidia GPUs, with seven specifically mentioning the Nvidia v100 GPU (released in 2017).</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p2.1">Looking back at papers published at ACM RecSys 2013, only 6 out of 32 (19%) contain information about the hardware used, meaning 26 (81%) do not contain hardware information.
Contrary to 2023, none of the papers from 2013 mention using a GPU.
However, all 6 papers that disclose their hardware utilize an Intel Xeon CPU.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Libraries:</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">At ACM RecSys 2023, 18 (38%) papers use PyTorch, and 6 (13%) papers use TensorFlow implementing deep learning recommender systems.
RecBole <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib56" title="">2023b</a>)</cite> is used by 5 (11%) papers, making it the most popular library designed explicitly for recommender systems.
While 13 (28%) papers from 2023 do not specify the library used, they all implement deep learning algorithms.
The remaining 5 (11%) papers report using one of the following libraries: Elliot <cite class="ltx_cite ltx_citemacro_citep">(Anelli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib4" title="">2021</a>)</cite>, ReChorus <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib52" title="">2020</a>)</cite>, Bambi <cite class="ltx_cite ltx_citemacro_citep">(Capretto et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib10" title="">2022</a>)</cite>, FuxiCTR <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib66" title="">2022</a>)</cite>, or CSRLab <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib64" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p2.1">This contrasts the patterns observed in ACM RecSys 2013 papers.
The majority of papers, 27 (84%) do not report using any open libraries.
Instead, they rely on private algorithm implementations.
Only 5 (16%) papers report using libraries, which include MyMediaLite <cite class="ltx_cite ltx_citemacro_citep">(Gantner et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib20" title="">2011</a>)</cite>, Apache Mahout <cite class="ltx_cite ltx_citemacro_citep">(Anil et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib5" title="">2020</a>)</cite>, InferNet <cite class="ltx_cite ltx_citemacro_citep">(Minka et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib37" title="">2018</a>)</cite>, and libpMF <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib59" title="">2012</a>)</cite>.
This shift highlights a considerable evolution in adopting standardized libraries within recommender systems over the past decade.
Arguably, the feasibility of reproducing a recommender systems paper has increased over time, at least in terms of software.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Experimental Pipeline:</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">Between papers from 2023 and 2013, the experimental pipeline remains consistent, but there are significant differences in the algorithms and datasets.
For instance, the holdout split is the most popular data splitting technique, used in 20 (42%) of the 2023 papers and 20 (63%) of the 2013 papers.
Grid search is also the favored optimization technique in both 2023 and 2013.
Additionally, 22 (47%) papers in 2023 and 20 (63%) in 2013 do not employ dataset pruning, although n-core pruning appears to have gained notable popularity, appearing in 19 (40%) papers in 2023.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p2.1">One of the most significant differences lies in the evaluation metrics used: nDCG is the predominant metric in 2023, used in 32 (68%) papers, whereas, in 2013, Precision is the most popular one, appearing in 13 (40%) papers, followed by RMSE and nDCG, each used in 5 (16%) papers.
This is partly because 44 (94%) of papers in 2023 focus on top-n ranking prediction tasks, while 18 (56%) of papers in 2013 focus on rating prediction tasks.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Open-Source Code:</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.1">Only 18 (38%) of ACM RecSys 2023 papers do not contain links to their source code.
On the other hand, 29 (62%) make their code available, with all but 2 hosting it on <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px4.p1.1.1">GitHub</em> and the remaining hosting it on their organization’s website.
However, 3 (6%) repositories linked in these papers are empty or unreachable.
Only 1 (3%) paper from ACM RecSys 2013 shares code.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Datasets:</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p1.1">On average, papers from ACM RecSys 2023 include three datasets.
The most frequent datasets are from the Amazon2018 series, appearing in 15 (32%) papers, followed by the MovieLens datasets, of which MovieLens-1M is used in 11 (23%) papers, while MovieLens-100K, MovieLens-10M, and MovieLens-20M are used in 2 (4%) papers.
Other commonly used datasets are LastFM in 6 (13%) papers, Yelp-2018 in 5 (11%) papers, and Gowalla in 5 (11%) papers.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p2.1">On average, papers at ACM RecSys 2013 include two distinct datasets in their experimental pipeline.
The most frequently used datasets are the MovieLens datasets, used in 10 (31%) papers.
Neither of the popular Amazon datasets were available in 2013.
Other commonly used datasets include the LastFM dataset, used in 4 (13%) papers, and the Netflix Prize dataset, used in 3 (9%) papers.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Method</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We measure the energy consumption of running 23 algorithms on 13 datasets with a smart power plug.
To assess the impact of hardware on energy efficiency, we run the experiments on four distinct computers.
We also estimate the carbon footprint by assessing the carbon emissions related to electricity generation in five locations.
Our experimental pipeline is based on our research papers analysis, ensuring representative data collection (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3" title="3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>). All design decisions are derived from this analysis unless otherwise specified.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Experimental Pipeline</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We randomly divide each of the 13 datasets into three splits, where 60% of the data is for training, 20% for validation, and 20% for testing.
Since our work focuses on energy consumption rather than maximizing performance and generalizability, we neither employ cross-validation nor repeat experiments.
While this decision comes at the cost of reliability and performance in terms of accuracy, our goal is not to optimize the recommender models to beat a baseline but to measure the power consumption of a characteristic recommender system experiment.
We measure performance by nDCG@10 for top-n ranking predictions and RMSE for rating predictions.
Furthermore, we use the default hyperparameter settings provided by the libraries instead of optimizing them.
We make these decisions to minimize unnecessary energy consumption.
All deep learning algorithms are trained for 200 epochs, with model validation after every fifth epoch to facilitate early stopping.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Datasets:</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">Based on our research paper analysis (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3" title="3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>), we include 13 datasets in our experiments and refer to <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.T1" title="In 4.1.1. Datasets: ‣ 4.1. Experimental Pipeline ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> for an overview.
For top-n prediction tasks, we convert rating prediction datasets according to practice that is common in our paper analysis <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib67" title="">2023</a>; Ma et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib33" title="">2023</a>; Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib12" title="">2023</a>; Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib57" title="">2023a</a>)</cite>.
Furthermore, we prune all datasets such that all included users and items have at least five interactions, commonly known as five-core pruning <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib49" title="">2019</a>; Yue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib60" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib61" title="">2022</a>)</cite>.
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.T1" title="In 4.1.1. Datasets: ‣ 4.1. Experimental Pipeline ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> shows the dataset statistics of all included datasets for the preprocessed datasets.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.2.1.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text" id="S4.T1.3.2" style="font-size:90%;">Basic information of the data sets used in our experiments after preprocessing.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T1.4" style="width:433.6pt;height:381.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-33.4pt,29.3pt) scale(0.866612563584641,0.866612563584641) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T1.4.1">
<tr class="ltx_tr" id="S4.T1.4.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T1.4.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Dataset Name</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T1.4.1.1.2" style="padding-top:1pt;padding-bottom:1pt;">Users</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T1.4.1.1.3" style="padding-top:1pt;padding-bottom:1pt;">Items</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T1.4.1.1.4" style="padding-top:1pt;padding-bottom:1pt;">Interactions</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T1.4.1.1.5" style="padding-top:1pt;padding-bottom:1pt;">Density</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.4.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.2.1.1"></span><span class="ltx_text" id="S4.T1.4.1.2.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.2.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.2.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Amazon2018<cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib40" title="">2019</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.2.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.2.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">Books</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.2.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.4.1.2.2" style="padding-top:1pt;padding-bottom:1pt;">105,436</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.4.1.2.3" style="padding-top:1pt;padding-bottom:1pt;">151,802</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.4.1.2.4" style="padding-top:1pt;padding-bottom:1pt;">1,724,703</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.4.1.2.5" style="padding-top:1pt;padding-bottom:1pt;">0.0108</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.3.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.3.1.1"></span><span class="ltx_text" id="S4.T1.4.1.3.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.3.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.3.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Amazon2018<cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib40" title="">2019</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.3.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">CDs-And-Vinyl</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.3.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.3.2" style="padding-top:1pt;padding-bottom:1pt;">71,943</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.3.3" style="padding-top:1pt;padding-bottom:1pt;">107,546</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.3.4" style="padding-top:1pt;padding-bottom:1pt;">1,377,008</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.3.5" style="padding-top:1pt;padding-bottom:1pt;">0.0178</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.4.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.4.1.1"></span><span class="ltx_text" id="S4.T1.4.1.4.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.4.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.4.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.4.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Amazon2018<cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib40" title="">2019</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.4.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.4.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">Electronics</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.4.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.4.2" style="padding-top:1pt;padding-bottom:1pt;">62,617</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.4.3" style="padding-top:1pt;padding-bottom:1pt;">187,288</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.4.4" style="padding-top:1pt;padding-bottom:1pt;">1,476,535</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.4.5" style="padding-top:1pt;padding-bottom:1pt;">0.0126</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.5.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.5.1.1"></span><span class="ltx_text" id="S4.T1.4.1.5.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.5.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.5.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.5.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Amazon2018<cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib40" title="">2019</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.5.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.5.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">Sports-And-Outdoors</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.5.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.5.2" style="padding-top:1pt;padding-bottom:1pt;">69,781</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.5.3" style="padding-top:1pt;padding-bottom:1pt;">185,024</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.5.4" style="padding-top:1pt;padding-bottom:1pt;">1,498,609</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.5.5" style="padding-top:1pt;padding-bottom:1pt;">0.0116</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.6.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.6.1.1"></span><span class="ltx_text" id="S4.T1.4.1.6.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.6.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.6.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.6.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Amazon2018<cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib40" title="">2019</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.6.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.6.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">Toys-And-Games</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.6.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.6.2" style="padding-top:1pt;padding-bottom:1pt;">75,856</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.6.3" style="padding-top:1pt;padding-bottom:1pt;">192,326</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.6.4" style="padding-top:1pt;padding-bottom:1pt;">1,686,250</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.6.5" style="padding-top:1pt;padding-bottom:1pt;">0.0116</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.7.1" style="padding-top:1pt;padding-bottom:1pt;">Gowalla<cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib13" title="">2011</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.7.2" style="padding-top:1pt;padding-bottom:1pt;">64,115</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.7.3" style="padding-top:1pt;padding-bottom:1pt;">164,532</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.7.4" style="padding-top:1pt;padding-bottom:1pt;">2,018,421</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.7.5" style="padding-top:1pt;padding-bottom:1pt;">0.0191</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.8.1" style="padding-top:1pt;padding-bottom:1pt;">Hetrec-LastFM<cite class="ltx_cite ltx_citemacro_citep">(Cantador et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib9" title="">2011</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.8.2" style="padding-top:1pt;padding-bottom:1pt;">1,090</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.8.3" style="padding-top:1pt;padding-bottom:1pt;">3,646</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.8.4" style="padding-top:1pt;padding-bottom:1pt;">52,551</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.8.5" style="padding-top:1pt;padding-bottom:1pt;">1.3223</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.9.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.9.1.1"></span><span class="ltx_text" id="S4.T1.4.1.9.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.9.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.9.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.9.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">MovieLens<cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib23" title="">2015</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.9.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.9.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">100K</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.9.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.9.2" style="padding-top:1pt;padding-bottom:1pt;">943</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.9.3" style="padding-top:1pt;padding-bottom:1pt;">1,349</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.9.4" style="padding-top:1pt;padding-bottom:1pt;">99,287</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.9.5" style="padding-top:1pt;padding-bottom:1pt;">7.8049</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.10.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.10.1.1"></span><span class="ltx_text" id="S4.T1.4.1.10.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.10.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.10.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.10.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">MovieLens<cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib23" title="">2015</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.10.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.10.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">1M</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.10.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.10.2" style="padding-top:1pt;padding-bottom:1pt;">6,040</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.10.3" style="padding-top:1pt;padding-bottom:1pt;">3,416</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.10.4" style="padding-top:1pt;padding-bottom:1pt;">999,611</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.10.5" style="padding-top:1pt;padding-bottom:1pt;">4.8448</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.11.1" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text" id="S4.T1.4.1.11.1.1"></span><span class="ltx_text" id="S4.T1.4.1.11.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T1.4.1.11.1.2.1">
<span class="ltx_tr" id="S4.T1.4.1.11.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.11.1.2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">MovieLens<cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib23" title="">2015</a>)</cite></span></span>
<span class="ltx_tr" id="S4.T1.4.1.11.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.4.1.11.1.2.1.2.1" style="padding-top:1pt;padding-bottom:1pt;">Latest-Small</span></span>
</span></span><span class="ltx_text" id="S4.T1.4.1.11.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.11.2" style="padding-top:1pt;padding-bottom:1pt;">610</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.11.3" style="padding-top:1pt;padding-bottom:1pt;">3,650</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.11.4" style="padding-top:1pt;padding-bottom:1pt;">90,274</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.11.5" style="padding-top:1pt;padding-bottom:1pt;">4.0545</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.12.1" style="padding-top:1pt;padding-bottom:1pt;">Netflix<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data" title="">https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data</a></span></span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.12.2" style="padding-top:1pt;padding-bottom:1pt;">11,927</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.12.3" style="padding-top:1pt;padding-bottom:1pt;">11,934</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.12.4" style="padding-top:1pt;padding-bottom:1pt;">5,850,559</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.12.5" style="padding-top:1pt;padding-bottom:1pt;">4.1103</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.13.1" style="padding-top:1pt;padding-bottom:1pt;">Retailrocket<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset" title="">https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset</a></span></span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.13.2" style="padding-top:1pt;padding-bottom:1pt;">22,178</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.13.3" style="padding-top:1pt;padding-bottom:1pt;">17,803</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.1.13.4" style="padding-top:1pt;padding-bottom:1pt;">240,938</td>
<td class="ltx_td ltx_align_left" id="S4.T1.4.1.13.5" style="padding-top:1pt;padding-bottom:1pt;">0.0610</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.14">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T1.4.1.14.1" style="padding-top:1pt;padding-bottom:1pt;">Yelp-2018<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.yelp.com/dataset" title="">https://www.yelp.com/dataset</a></span></span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T1.4.1.14.2" style="padding-top:1pt;padding-bottom:1pt;">213,170</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T1.4.1.14.3" style="padding-top:1pt;padding-bottom:1pt;">94,304</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T1.4.1.14.4" style="padding-top:1pt;padding-bottom:1pt;">3,277,931</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.4.1.14.5" style="padding-top:1pt;padding-bottom:1pt;">0.0163</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Algorithms:</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">Based on our research paper analysis (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3" title="3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>), we include 23 frequently used algorithms in our experiments.
The algorithm implementations are from RecBole <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib56" title="">2023b</a>)</cite> (indicated by <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p1.1.1">RB</em>), RecPack <cite class="ltx_cite ltx_citemacro_citep">(Michiels et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib36" title="">2022</a>)</cite> (indicated by <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p1.1.2">RP</em>) and LensKit <cite class="ltx_cite ltx_citemacro_citep">(Ekstrand, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib16" title="">2020</a>)</cite> (indicated by <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p1.1.3">LK</em>).
We run algorithms from RecBole on a GPU while we run algorithms from LensKit and RecPack on a CPU.
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.T2" title="In 4.1.2. Algorithms: ‣ 4.1. Experimental Pipeline ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a> shows all algorithm implementations used in our experiments.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.2.1.1" style="font-size:90%;">Table 2</span>. </span><span class="ltx_text" id="S4.T2.3.2" style="font-size:90%;">Algorithm implementations used in our experiments.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T2.4" style="width:433.6pt;height:178.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(44.1pt,-18.1pt) scale(1.25504869710238,1.25504869710238) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T2.4.1">
<tr class="ltx_tr" id="S4.T2.4.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T2.4.1.1.1">Library</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T2.4.1.1.2">Executed on</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.4.1.1.3">Algorithm</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.4.1.2.1">RecBole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.4.1.2.2">GPU</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.1.2.3">
<span class="ltx_text" id="S4.T2.4.1.2.3.1"></span><span class="ltx_text" id="S4.T2.4.1.2.3.2">
<span class="ltx_tabular ltx_align_top" id="S4.T2.4.1.2.3.2.1">
<span class="ltx_tr" id="S4.T2.4.1.2.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.1.2.3.2.1.1.1">BPR, DGCF, DMF, ItemKNN, LightGCN,</span></span>
<span class="ltx_tr" id="S4.T2.4.1.2.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.1.2.3.2.1.2.1">MacridVAE, MultiVAE, NAIS, NCL, NeuMF,</span></span>
<span class="ltx_tr" id="S4.T2.4.1.2.3.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.1.2.3.2.1.3.1">NGCF, Popularity, RecVAE, SGL</span></span>
</span></span><span class="ltx_text" id="S4.T2.4.1.2.3.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.4.1.3.1">RecPack</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.4.1.3.2">CPU</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.1.3.3">
<span class="ltx_text" id="S4.T2.4.1.3.3.1"></span><span class="ltx_text" id="S4.T2.4.1.3.3.2">
<span class="ltx_tabular ltx_align_top" id="S4.T2.4.1.3.3.2.1">
<span class="ltx_tr" id="S4.T2.4.1.3.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.1.3.3.2.1.1.1">ItemKNN, NMF, SVD</span></span>
</span></span><span class="ltx_text" id="S4.T2.4.1.3.3.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T2.4.1.4.1">LensKit</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T2.4.1.4.2">CPU</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.4.1.4.3">
<span class="ltx_text" id="S4.T2.4.1.4.3.1"></span><span class="ltx_text" id="S4.T2.4.1.4.3.2">
<span class="ltx_tabular ltx_align_top" id="S4.T2.4.1.4.3.2.1">
<span class="ltx_tr" id="S4.T2.4.1.4.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.1.4.3.2.1.1.1">ImplicitMF, ItemKNN, UserKNN, Popularity,</span></span>
<span class="ltx_tr" id="S4.T2.4.1.4.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.4.1.4.3.2.1.2.1">BiasedMF, FunkSVD</span></span>
</span></span><span class="ltx_text" id="S4.T2.4.1.4.3.3"></span></td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Representative Pipelines</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Our research paper study indicates that experimental pipelines from 2013 and 2023 exhibit notable differences (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3" title="3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>).
For instance, in 2023, all but one paper focused on top-n ranking prediction tasks, whereas in 2013, around half of the papers focused on rating prediction tasks.
Additionally, in 2023, experiments often utilize datasets from the <em class="ltx_emph ltx_font_italic" id="S4.SS2.p1.1.1">Amazon-2018</em> series, which were not available in 2013.
Consequently, we introduce three distinct representative pipelines to account for these differences.
<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.T3" title="In 4.2. Representative Pipelines ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> provides an overview of the algorithms and datasets used for specific pipelines.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.37.1.1" style="font-size:90%;">Table 3</span>. </span><span class="ltx_text" id="S4.T3.38.2" style="font-size:90%;">Representative pipelines used to run experiments.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T3.35" style="width:433.6pt;height:531.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(31.8pt,-39.0pt) scale(1.1717523989968,1.1717523989968) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.35.35">
<tr class="ltx_tr" id="S4.T3.35.35.36">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T3.35.35.36.1">
<span class="ltx_text" id="S4.T3.35.35.36.1.1"></span><span class="ltx_text" id="S4.T3.35.35.36.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T3.35.35.36.1.2.1">
<span class="ltx_tr" id="S4.T3.35.35.36.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.36.1.2.1.1.1">Year and</span></span>
<span class="ltx_tr" id="S4.T3.35.35.36.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.36.1.2.1.2.1">Prediction Type</span></span>
</span></span><span class="ltx_text" id="S4.T3.35.35.36.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T3.35.35.36.2">Algorithms</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.35.35.36.3">Datasets</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.4.4.4.5">
<span class="ltx_text" id="S4.T3.4.4.4.5.1"></span><span class="ltx_text" id="S4.T3.4.4.4.5.2">
<span class="ltx_tabular ltx_align_top" id="S4.T3.4.4.4.5.2.1">
<span class="ltx_tr" id="S4.T3.4.4.4.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.4.4.4.5.2.1.1.1">2013</span></span>
<span class="ltx_tr" id="S4.T3.4.4.4.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.4.4.4.5.2.1.2.1">Rating</span></span>
<span class="ltx_tr" id="S4.T3.4.4.4.5.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.4.4.4.5.2.1.3.1">Prediction</span></span>
</span></span><span class="ltx_text" id="S4.T3.4.4.4.5.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4">
<span class="ltx_text" id="S4.T3.4.4.4.4.5"></span><span class="ltx_text" id="S4.T3.4.4.4.4.4">
<span class="ltx_tabular ltx_align_top" id="S4.T3.4.4.4.4.4.4">
<span class="ltx_tr" id="S4.T3.2.2.2.2.2.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.2.2.2.2.2.2.2.2">ItemKNN<sup class="ltx_sup" id="S4.T3.2.2.2.2.2.2.2.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.2.2.2.2.2.1.1">LK</span></sup>, UserKNN<sup class="ltx_sup" id="S4.T3.2.2.2.2.2.2.2.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.2.2.2.2.2.2.1">LK</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.4.4.4.4.4.4.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.4.4.4.4.4.4.4.2">BiasedMF<sup class="ltx_sup" id="S4.T3.4.4.4.4.4.4.4.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.4.4.4.4.4.4.4.2.1.1">LK</span></sup>, FunkSVD<sup class="ltx_sup" id="S4.T3.4.4.4.4.4.4.4.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.4.4.4.4.4.4.4.2.2.1">LK</span></sup></span></span>
</span></span><span class="ltx_text" id="S4.T3.4.4.4.4.6"></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.4.4.4.6">
<span class="ltx_text" id="S4.T3.4.4.4.6.1"></span><span class="ltx_text" id="S4.T3.4.4.4.6.2">
<span class="ltx_tabular ltx_align_top" id="S4.T3.4.4.4.6.2.1">
<span class="ltx_tr" id="S4.T3.4.4.4.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.4.4.4.6.2.1.1.1">Movielens-100K,</span></span>
<span class="ltx_tr" id="S4.T3.4.4.4.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.4.4.4.6.2.1.2.1">Movielens-1M,</span></span>
<span class="ltx_tr" id="S4.T3.4.4.4.6.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.4.4.4.6.2.1.3.1">Netflix</span></span>
</span></span><span class="ltx_text" id="S4.T3.4.4.4.6.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.14.14.14">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.14.14.14.11">
<span class="ltx_text" id="S4.T3.14.14.14.11.1"></span><span class="ltx_text" id="S4.T3.14.14.14.11.2">
<span class="ltx_tabular ltx_align_top" id="S4.T3.14.14.14.11.2.1">
<span class="ltx_tr" id="S4.T3.14.14.14.11.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.11.2.1.1.1">2013</span></span>
<span class="ltx_tr" id="S4.T3.14.14.14.11.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.11.2.1.2.1">Top-N</span></span>
<span class="ltx_tr" id="S4.T3.14.14.14.11.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.11.2.1.3.1">Ranking</span></span>
<span class="ltx_tr" id="S4.T3.14.14.14.11.2.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.11.2.1.4.1">Prediction</span></span>
</span></span><span class="ltx_text" id="S4.T3.14.14.14.11.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.14.14.14.10">
<span class="ltx_text" id="S4.T3.14.14.14.10.11"></span><span class="ltx_text" id="S4.T3.14.14.14.10.10">
<span class="ltx_tabular ltx_align_top" id="S4.T3.14.14.14.10.10.10">
<span class="ltx_tr" id="S4.T3.6.6.6.2.2.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.6.6.6.2.2.2.2.2">ImplicitMF<sup class="ltx_sup" id="S4.T3.6.6.6.2.2.2.2.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.6.6.6.2.2.2.2.2.1.1">LK</span></sup>, ItemKNN<sup class="ltx_sup" id="S4.T3.6.6.6.2.2.2.2.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.6.6.6.2.2.2.2.2.2.1">LK</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.8.8.8.4.4.4.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.8.8.8.4.4.4.4.2">UserKNN<sup class="ltx_sup" id="S4.T3.8.8.8.4.4.4.4.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.8.8.8.4.4.4.4.2.1.1">LK</span></sup>, Popularity<sup class="ltx_sup" id="S4.T3.8.8.8.4.4.4.4.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.8.8.8.4.4.4.4.2.2.1">LK</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.11.11.11.7.7.7.7">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.11.11.11.7.7.7.7.3">ItemKNN<sup class="ltx_sup" id="S4.T3.11.11.11.7.7.7.7.3.1"><span class="ltx_text ltx_font_italic" id="S4.T3.11.11.11.7.7.7.7.3.1.1">RP</span></sup>, NMF<sup class="ltx_sup" id="S4.T3.11.11.11.7.7.7.7.3.2"><span class="ltx_text ltx_font_italic" id="S4.T3.11.11.11.7.7.7.7.3.2.1">RP</span></sup>, SVD<sup class="ltx_sup" id="S4.T3.11.11.11.7.7.7.7.3.3"><span class="ltx_text ltx_font_italic" id="S4.T3.11.11.11.7.7.7.7.3.3.1">RP</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.13.13.13.9.9.9.9">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.13.13.13.9.9.9.9.2">BPR<sup class="ltx_sup" id="S4.T3.13.13.13.9.9.9.9.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.13.13.13.9.9.9.9.2.1.1">RB</span></sup>, ItemKNN<sup class="ltx_sup" id="S4.T3.13.13.13.9.9.9.9.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.13.13.13.9.9.9.9.2.2.1">RB</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.14.14.14.10.10.10.10">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.10.10.10.10.1">Popularity<sup class="ltx_sup" id="S4.T3.14.14.14.10.10.10.10.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.14.14.14.10.10.10.10.1.1.1">RB</span></sup></span></span>
</span></span><span class="ltx_text" id="S4.T3.14.14.14.10.12"></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.14.14.14.12">
<span class="ltx_text" id="S4.T3.14.14.14.12.1"></span><span class="ltx_text" id="S4.T3.14.14.14.12.2">
<span class="ltx_tabular ltx_align_top" id="S4.T3.14.14.14.12.2.1">
<span class="ltx_tr" id="S4.T3.14.14.14.12.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.12.2.1.1.1">Hetrec-Lastfm,</span></span>
<span class="ltx_tr" id="S4.T3.14.14.14.12.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.12.2.1.2.1">Movielens-100K,</span></span>
<span class="ltx_tr" id="S4.T3.14.14.14.12.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.12.2.1.3.1">Movielens-1M,</span></span>
<span class="ltx_tr" id="S4.T3.14.14.14.12.2.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.14.14.14.12.2.1.4.1">Gowalla</span></span>
</span></span><span class="ltx_text" id="S4.T3.14.14.14.12.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.35.35.35">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.35.35.35.22">
<span class="ltx_text" id="S4.T3.35.35.35.22.1"></span><span class="ltx_text" id="S4.T3.35.35.35.22.2">
<span class="ltx_tabular ltx_align_top" id="S4.T3.35.35.35.22.2.1">
<span class="ltx_tr" id="S4.T3.35.35.35.22.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.22.2.1.1.1">2023</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.22.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.22.2.1.2.1">Top-N</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.22.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.22.2.1.3.1">Ranking</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.22.2.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.22.2.1.4.1">Prediction</span></span>
</span></span><span class="ltx_text" id="S4.T3.35.35.35.22.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.35.35.35.21">
<span class="ltx_text" id="S4.T3.35.35.35.21.22"></span><span class="ltx_text" id="S4.T3.35.35.35.21.21">
<span class="ltx_tabular ltx_align_top" id="S4.T3.35.35.35.21.21.21">
<span class="ltx_tr" id="S4.T3.16.16.16.2.2.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.16.16.16.2.2.2.2.2">ImplicitMF<sup class="ltx_sup" id="S4.T3.16.16.16.2.2.2.2.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.16.16.16.2.2.2.2.2.1.1">LK</span></sup>, ItemKNN<sup class="ltx_sup" id="S4.T3.16.16.16.2.2.2.2.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.16.16.16.2.2.2.2.2.2.1">LK</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.18.18.18.4.4.4.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.18.18.18.4.4.4.4.2">UserKNN<sup class="ltx_sup" id="S4.T3.18.18.18.4.4.4.4.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.18.18.18.4.4.4.4.2.1.1">LK</span></sup>, Popularity<sup class="ltx_sup" id="S4.T3.18.18.18.4.4.4.4.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.18.18.18.4.4.4.4.2.2.1">LK</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.21.21.21.7.7.7.7">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.21.21.21.7.7.7.7.3">ItemKNN<sup class="ltx_sup" id="S4.T3.21.21.21.7.7.7.7.3.1"><span class="ltx_text ltx_font_italic" id="S4.T3.21.21.21.7.7.7.7.3.1.1">RP</span></sup>, NMF<sup class="ltx_sup" id="S4.T3.21.21.21.7.7.7.7.3.2"><span class="ltx_text ltx_font_italic" id="S4.T3.21.21.21.7.7.7.7.3.2.1">RP</span></sup>, SVD<sup class="ltx_sup" id="S4.T3.21.21.21.7.7.7.7.3.3"><span class="ltx_text ltx_font_italic" id="S4.T3.21.21.21.7.7.7.7.3.3.1">RP</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.24.24.24.10.10.10.10">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.24.24.24.10.10.10.10.3">BPR<sup class="ltx_sup" id="S4.T3.24.24.24.10.10.10.10.3.1"><span class="ltx_text ltx_font_italic" id="S4.T3.24.24.24.10.10.10.10.3.1.1">RB</span></sup>, DGCF<sup class="ltx_sup" id="S4.T3.24.24.24.10.10.10.10.3.2"><span class="ltx_text ltx_font_italic" id="S4.T3.24.24.24.10.10.10.10.3.2.1">RB</span></sup>, DMF<sup class="ltx_sup" id="S4.T3.24.24.24.10.10.10.10.3.3"><span class="ltx_text ltx_font_italic" id="S4.T3.24.24.24.10.10.10.10.3.3.1">RB</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.26.26.26.12.12.12.12">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.26.26.26.12.12.12.12.2">ItemKNN<sup class="ltx_sup" id="S4.T3.26.26.26.12.12.12.12.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.26.26.26.12.12.12.12.2.1.1">RB</span></sup>, LightGCN<sup class="ltx_sup" id="S4.T3.26.26.26.12.12.12.12.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.26.26.26.12.12.12.12.2.2.1">RB</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.28.28.28.14.14.14.14">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.28.28.28.14.14.14.14.2">MacridVAE<sup class="ltx_sup" id="S4.T3.28.28.28.14.14.14.14.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.28.28.28.14.14.14.14.2.1.1">RB</span></sup>, MultiVAE<sup class="ltx_sup" id="S4.T3.28.28.28.14.14.14.14.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.28.28.28.14.14.14.14.2.2.1">RB</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.31.31.31.17.17.17.17">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.31.31.31.17.17.17.17.3">NAIS<sup class="ltx_sup" id="S4.T3.31.31.31.17.17.17.17.3.1"><span class="ltx_text ltx_font_italic" id="S4.T3.31.31.31.17.17.17.17.3.1.1">RB</span></sup>, NCL<sup class="ltx_sup" id="S4.T3.31.31.31.17.17.17.17.3.2"><span class="ltx_text ltx_font_italic" id="S4.T3.31.31.31.17.17.17.17.3.2.1">RB</span></sup>, NeuMF<sup class="ltx_sup" id="S4.T3.31.31.31.17.17.17.17.3.3"><span class="ltx_text ltx_font_italic" id="S4.T3.31.31.31.17.17.17.17.3.3.1">RB</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.33.33.33.19.19.19.19">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.33.33.33.19.19.19.19.2">NGCF<sup class="ltx_sup" id="S4.T3.33.33.33.19.19.19.19.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.33.33.33.19.19.19.19.2.1.1">RB</span></sup>, Popularity<sup class="ltx_sup" id="S4.T3.33.33.33.19.19.19.19.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.33.33.33.19.19.19.19.2.2.1">RB</span></sup>,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.21.21.21.21">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.21.21.21.21.2">RecVAE<sup class="ltx_sup" id="S4.T3.35.35.35.21.21.21.21.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.35.35.35.21.21.21.21.2.1.1">RB</span></sup>, SGL<sup class="ltx_sup" id="S4.T3.35.35.35.21.21.21.21.2.2"><span class="ltx_text ltx_font_italic" id="S4.T3.35.35.35.21.21.21.21.2.2.1">RB</span></sup></span></span>
</span></span><span class="ltx_text" id="S4.T3.35.35.35.21.23"></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T3.35.35.35.23">
<span class="ltx_text" id="S4.T3.35.35.35.23.1"></span><span class="ltx_text" id="S4.T3.35.35.35.23.2">
<span class="ltx_tabular ltx_align_top" id="S4.T3.35.35.35.23.2.1">
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.1.1">Gowalla,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.2.1">Hetrec-LastFM,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.3.1">MovieLens:</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.4.1">-100K,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.5">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.5.1">-1M,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.6">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.6.1">-Latest-Small,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.7">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.7.1">Amazon2018:</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.8">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.8.1">-Electronics,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.9">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.9.1">-Toys-And-Games,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.10">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.10.1">-CDs-And-Vinyl,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.11">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.11.1">-Sports-And-Outdoors,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.12">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.12.1">-Books,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.13">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.13.1">Yelp-2018,</span></span>
<span class="ltx_tr" id="S4.T3.35.35.35.23.2.1.14">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.35.35.35.23.2.1.14.1">Retailrocket</span></span>
</span></span><span class="ltx_text" id="S4.T3.35.35.35.23.3"></span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Calculating Greenhouse Gas Emission</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To calculate the greenhouse gas emissions from recommender systems experiments, we first record the electricity consumption and translate the consumption into equivalent emissions.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>Measuring Electrical Energy Consumption</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">To precisely measure the energy consumption of recommender system experiments, we equip each computer in our experimental setup with a commercially available off-the-shelf smart power plug<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.shelly.com/en-se/products/product-overview/shelly-plus-plug-s" title="">https://www.shelly.com/en-se/products/product-overview/shelly-plus-plug-s</a></span></span></span>.
This enables us to measure energy consumption in kilowatt-hours (<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p1.1.1">kWh</em>) at half-second intervals.
We then align the power plug’s measurements with the experiments based on timestamps.
Our measurements capture the entire hardware’s energy usage, covering components such as cooling, power supply, CPU, GPU, and memory.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Calculating Greenhouse Gas Emissions Based on Electricity Consumption</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">We convert the measured energy consumption in <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p1.1.1">kWh</em> into carbon dioxide equivalents (<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p1.1.2">CO<sub class="ltx_sub" id="S4.SS3.SSS2.p1.1.2.1">2</sub>e</em>) utilizing the comprehensive dataset provided by <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p1.1.3">Ember</em><span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ember-climate.org/" title="">https://ember-climate.org/</a></span></span></span>.
The Ember datasets merge data from the European Electricity Review and information from various original data providers into a singular dataset<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://docs.owid.io/projects/etl/" title="">https://docs.owid.io/projects/etl/</a></span></span></span>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p2">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1">The Ember dataset features a conversion rate from <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p2.1.1">kWh</em> to grams of carbon dioxide emissions equivalents (<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p2.1.2">gCO<sub class="ltx_sub" id="S4.SS3.SSS2.p2.1.2.1">2</sub>e</em>).
<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p2.1.3">CO<sub class="ltx_sub" id="S4.SS3.SSS2.p2.1.3.1">2</sub>e</em> represent the greenhouse gas emissions released and the overall environmental impact of electricity generation.
Since the hardware does not directly impact the environment by, e.g., emitting greenhouse gases, we utilize the carbon dioxide equivalents associated with the electricity generation process of the consumed energy.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p3">
<p class="ltx_p" id="S4.SS3.SSS2.p3.1">The <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p3.1.1">gCO<sub class="ltx_sub" id="S4.SS3.SSS2.p3.1.1.1">2</sub>e</em> conversion rate linked to electricity generation varies notably based on the method of production <cite class="ltx_cite ltx_citemacro_citep">(Kerem, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib27" title="">2022</a>)</cite>.
Electricity sourced from renewable energy, such as hydropower, typically has a lower carbon footprint than coal combustion.
Different regions employ diverse energy generation methods, so we use the global average conversion rate and compare various geographical locations.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Hardware</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We conduct all experiments across four computers with different hardware configurations from different years to assess the impact of hardware efficiency on energy consumption and, consequently, the carbon footprint.
Computer hardware has become increasingly efficient over the years <cite class="ltx_cite ltx_citemacro_citep">(Koomey et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib28" title="">2011</a>)</cite>.
We perform experiments on four computers spanning the last decade to evaluate the impact on hardware efficiency and whether the improvement can offset the energy demands of transitioning to deep learning.
We present the hardware specifications used in our experiments in <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S4.T4" title="In 4.4. Hardware ‣ 4. Method ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.2.1.1" style="font-size:90%;">Table 4</span>. </span><span class="ltx_text" id="S4.T4.3.2" style="font-size:90%;">Hardware used to compare hardware efficiency.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.4" style="width:433.6pt;height:284.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(31.8pt,-20.9pt) scale(1.17216442966862,1.17216442966862) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.4.1">
<tr class="ltx_tr" id="S4.T4.4.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T4.4.1.1.1">
<span class="ltx_text" id="S4.T4.4.1.1.1.1"></span><span class="ltx_text" id="S4.T4.4.1.1.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.1.1.2.1">
<span class="ltx_tr" id="S4.T4.4.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.1.1.2.1.1.1">Computer and</span></span>
<span class="ltx_tr" id="S4.T4.4.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.1.1.2.1.2.1">Year</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.1.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T4.4.1.1.2">CPU</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T4.4.1.1.3">GPU</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T4.4.1.1.4">
<span class="ltx_text" id="S4.T4.4.1.1.4.1"></span><span class="ltx_text" id="S4.T4.4.1.1.4.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.1.4.2.1">
<span class="ltx_tr" id="S4.T4.4.1.1.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.1.4.2.1.1.1">RAM</span></span>
<span class="ltx_tr" id="S4.T4.4.1.1.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.1.4.2.1.2.1">in GB</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.1.4.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T4.4.1.1.5">
<span class="ltx_text" id="S4.T4.4.1.1.5.1"></span><span class="ltx_text" id="S4.T4.4.1.1.5.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.1.5.2.1">
<span class="ltx_tr" id="S4.T4.4.1.1.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.1.5.2.1.1.1">Storage</span></span>
<span class="ltx_tr" id="S4.T4.4.1.1.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.1.5.2.1.2.1">in TB</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.1.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.2.1">
<span class="ltx_text" id="S4.T4.4.1.2.1.1"></span><span class="ltx_text" id="S4.T4.4.1.2.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.2.1.2.1">
<span class="ltx_tr" id="S4.T4.4.1.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.1.2.1.1.1">Modern Workstation</span></span>
<span class="ltx_tr" id="S4.T4.4.1.2.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.1.2.1.2.1">2023</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.2.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.2.2">
<span class="ltx_text" id="S4.T4.4.1.2.2.1"></span><span class="ltx_text" id="S4.T4.4.1.2.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.2.2.2.1">
<span class="ltx_tr" id="S4.T4.4.1.2.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.2.2.1.1.1">Intel Xeon</span></span>
<span class="ltx_tr" id="S4.T4.4.1.2.2.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.2.2.1.2.1">W-2255</span></span>
<span class="ltx_tr" id="S4.T4.4.1.2.2.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.2.2.1.3.1">@ 3.70 GHz</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.2.2.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.2.3">
<span class="ltx_text" id="S4.T4.4.1.2.3.1"></span><span class="ltx_text" id="S4.T4.4.1.2.3.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.2.3.2.1">
<span class="ltx_tr" id="S4.T4.4.1.2.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.3.2.1.1.1">NVIDIA</span></span>
<span class="ltx_tr" id="S4.T4.4.1.2.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.3.2.1.2.1">GeForce</span></span>
<span class="ltx_tr" id="S4.T4.4.1.2.3.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.2.3.2.1.3.1">RTX 3090</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.2.3.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.2.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.1.2.5">2</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.3.1">
<span class="ltx_text" id="S4.T4.4.1.3.1.1"></span><span class="ltx_text" id="S4.T4.4.1.3.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.3.1.2.1">
<span class="ltx_tr" id="S4.T4.4.1.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.3.1.2.1.1.1">Mac Studio</span></span>
<span class="ltx_tr" id="S4.T4.4.1.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.3.1.2.1.2.1">2022</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.3.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.3.2">M1 Ultra</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.3.3">M1 Ultra</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.3.4">64</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.1.3.5">1</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.4.1">
<span class="ltx_text" id="S4.T4.4.1.4.1.1"></span><span class="ltx_text" id="S4.T4.4.1.4.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.4.1.2.1">
<span class="ltx_tr" id="S4.T4.4.1.4.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.4.1.2.1.1.1">MacBook Pro</span></span>
<span class="ltx_tr" id="S4.T4.4.1.4.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.4.1.2.1.2.1">2020</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.4.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.4.2">M1</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.4.3">M1</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.1.4.4">16</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.1.4.5">1</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.4.1.5.1">
<span class="ltx_text" id="S4.T4.4.1.5.1.1"></span><span class="ltx_text" id="S4.T4.4.1.5.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.5.1.2.1">
<span class="ltx_tr" id="S4.T4.4.1.5.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.1.2.1.1.1">Legacy Workstation</span></span>
<span class="ltx_tr" id="S4.T4.4.1.5.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.1.2.1.2.1">2013</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.5.1.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.4.1.5.2">
<span class="ltx_text" id="S4.T4.4.1.5.2.1"></span><span class="ltx_text" id="S4.T4.4.1.5.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.5.2.2.1">
<span class="ltx_tr" id="S4.T4.4.1.5.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.2.2.1.1.1">Intel Core</span></span>
<span class="ltx_tr" id="S4.T4.4.1.5.2.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.2.2.1.2.1">i7-6700K</span></span>
<span class="ltx_tr" id="S4.T4.4.1.5.2.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.2.2.1.3.1">@ 4.00GHz</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.5.2.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.4.1.5.3">
<span class="ltx_text" id="S4.T4.4.1.5.3.1"></span><span class="ltx_text" id="S4.T4.4.1.5.3.2">
<span class="ltx_tabular ltx_align_top" id="S4.T4.4.1.5.3.2.1">
<span class="ltx_tr" id="S4.T4.4.1.5.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.3.2.1.1.1">NVIDIA</span></span>
<span class="ltx_tr" id="S4.T4.4.1.5.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.3.2.1.2.1">GeForce</span></span>
<span class="ltx_tr" id="S4.T4.4.1.5.3.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.4.1.5.3.2.1.3.1">GTX 980 Ti</span></span>
</span></span><span class="ltx_text" id="S4.T4.4.1.5.3.3"></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.4.1.5.4">128</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T4.4.1.5.5">1</td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our results demonstrate the energy consumption, the trade-offs between energy and performance, and the carbon footprint associated with the 2013 and 2023 ACM RecSys full paper experiments.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>The energy consumption of a 2023 recommender systems research paper</h3>
<figure class="ltx_figure" id="S5.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="922" id="S5.F1.sf1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.sf1.2.1.1" style="font-size:90%;">((a))</span> </span><span class="ltx_text" id="S5.F1.sf1.3.2" style="font-size:90%;">Energy Consumption for 16 Algorithms</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="755" id="S5.F1.sf2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.sf2.2.1.1" style="font-size:90%;">((b))</span> </span><span class="ltx_text" id="S5.F1.sf2.3.2" style="font-size:90%;">Energy Consumption for 12 Datasets</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F1.6.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S5.F1.7.2" style="font-size:90%;">Average power consumption of recommender system algorithms across twelve datasets, alongside the average consumption per dataset across sixteen algorithms. <em class="ltx_emph ltx_font_italic" id="S5.F1.7.2.1">Blue</em> vertical lines represent the average consumption in <em class="ltx_emph ltx_font_italic" id="S5.F1.7.2.2">kWh</em>. The upper x-axis displays the equivalent CO<sub class="ltx_sub" id="S5.F1.7.2.3">2</sub> emissions in grams (<em class="ltx_emph ltx_font_italic" id="S5.F1.7.2.4">gCO<sub class="ltx_sub" id="S5.F1.7.2.4.1">2</sub>e</em>), calculated based on the 2023 world average.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F1.8">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F1.9">[Test]Test</p>
</div>
</div>
</figure>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>The Energy Consumption of an Algorithm and Dataset</h4>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">Based on our experiments, we estimate the energy consumption of a single run of one recommender systems algorithm on one dataset to be, on average, 0.51 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p1.1.1">kWh</em> (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F1.sf1" title="In Figure 1 ‣ 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(a)</span></a>).</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS1.p2">
<p class="ltx_p" id="S5.SS1.SSS1.p2.1">Energy consumption varies among algorithms and datasets.
Relatively simple algorithms like <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.1">Popularity</em> and <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.2">ItemKNN</em> consume only 0.007 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.3">kWh</em> and 0.04 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.4">kWh</em>, respectively (average over twelve datasets used for experiments representing 2023).
Some recent deep learning algorithms consume a relatively low amount of energy, e.g., <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.5">DMF</em> and <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.6">LightCGN</em> consume 0.13 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.7">kWh</em> and 0.12 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.8">kWh</em>, respectively (average over twelve datasets used for 2023 experiments).
Contrasting, the most “expensive” algorithms – <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.9">MacridVAE</em> and <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.10">DCGF</em> consume, on average, 1.79 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.11">kWh</em> and 1.45 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.12">kWh</em>, respectively.
Consequently, the most expensive algorithm (MacridVAE), regarding electricity consumption, requires 257 times as much energy as the cheapest algorithm (Popularity).</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS1.p3">
<p class="ltx_p" id="S5.SS1.SSS1.p3.1">The energy consumption of individual algorithms on different datasets is even higher.
<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.1">Popularity</em> consumes only 0.000036 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.2">kWh</em> on <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.3">Movielens-Latest-Small</em> but 0.03 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.4">kWh</em> on the <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.5">Yelp-2018</em> dataset (factor 800).
The deep learning algorithm <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.6">DGCF</em> consumes 0.005 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.7">kWh</em> on <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.8">Hetrec-LastFM</em> but 6.6 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.9">kWh</em> on <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.10">Yelp-2018</em> (factor 1,444).</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS1.p4">
<p class="ltx_p" id="S5.SS1.SSS1.p4.1">When executing algorithms over larger datasets, energy consumption increases compared to executing the same algorithm on smaller data.
For example, the average recommender systems algorithm consumes 0.001 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p4.1.1">kWh</em> on <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p4.1.2">Hetrec-LastFM</em> with 53 thousand interactions and 1.56 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p4.1.3">kWh</em>, 1,560 times more energy, on <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p4.1.4">Yelp-2018</em> with 3.3 million interactions (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F1.sf2" title="In Figure 1 ‣ 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(b)</span></a>).</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS1.p5">
<p class="ltx_p" id="S5.SS1.SSS1.p5.1">However, the energy consumption per dataset is not solely dependent on the number of interactions.
Although <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.1">Amazon2018-Electronics</em> has ~25% fewer interactions than <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.2">Gowalla</em> (1.5M vs. 2M; <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F1.sf2" title="In Figure 1 ‣ 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(b)</span></a>), algorithms running on <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.3">Amazon2018-Electronics</em> consume, on average, 18% more energy (0.728 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.4">kWh</em>/0.617 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.5">kWh</em>).
Similarly, even though <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.6">Movielens-1M</em> includes around half the interactions of <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.7">Gowalla</em> (1M vs. 2M), algorithms on <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.8">Movielens-1M</em> consume only 10% of the energy <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.9">Gowalla</em> needs (0.06 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.10">kWh</em> vs. 0.6 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p5.1.11">kWh</em>).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>The Energy Consumption of an Experimental Pipeline</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">Based on our experiments, we estimate the energy consumption of a representative 2023 recommender systems experimental pipeline to be 171.36 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p1.1.1">kWh</em>.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS2.p2">
<p class="ltx_p" id="S5.SS1.SSS2.p2.1">Through the paper analysis described in <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3" title="3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>, we found that a 2023 recommender systems experimental pipeline includes, on average, seven recommender systems algorithms.
Additionally, the algorithm performance is, on average, evaluated on three datasets.
Furthermore, a representative experimental pipeline performs hyperparameter optimization through grid search on 16 configurations per algorithm.
Since one algorithm consumes, on average, 0.51 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.1">kWh</em> (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F1.sf2" title="In Figure 1 ‣ 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(b)</span></a>, left), the energy consumption of an experimental pipeline is calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="7\times 3\times 16\times 0.51\,\emph{kWh}=171.36\,\emph{kWh}." class="ltx_Math" display="block" id="S5.Ex1.m1.1"><semantics id="S5.Ex1.m1.1a"><mrow id="S5.Ex1.m1.1.1.1" xref="S5.Ex1.m1.1.1.1.1.cmml"><mrow id="S5.Ex1.m1.1.1.1.1" xref="S5.Ex1.m1.1.1.1.1.cmml"><mrow id="S5.Ex1.m1.1.1.1.1.2" xref="S5.Ex1.m1.1.1.1.1.2.cmml"><mrow id="S5.Ex1.m1.1.1.1.1.2.2" xref="S5.Ex1.m1.1.1.1.1.2.2.cmml"><mn id="S5.Ex1.m1.1.1.1.1.2.2.2" xref="S5.Ex1.m1.1.1.1.1.2.2.2.cmml">7</mn><mo id="S5.Ex1.m1.1.1.1.1.2.2.1" lspace="0.222em" rspace="0.222em" xref="S5.Ex1.m1.1.1.1.1.2.2.1.cmml">×</mo><mn id="S5.Ex1.m1.1.1.1.1.2.2.3" xref="S5.Ex1.m1.1.1.1.1.2.2.3.cmml">3</mn><mo id="S5.Ex1.m1.1.1.1.1.2.2.1a" lspace="0.222em" rspace="0.222em" xref="S5.Ex1.m1.1.1.1.1.2.2.1.cmml">×</mo><mn id="S5.Ex1.m1.1.1.1.1.2.2.4" xref="S5.Ex1.m1.1.1.1.1.2.2.4.cmml">16</mn><mo id="S5.Ex1.m1.1.1.1.1.2.2.1b" lspace="0.222em" rspace="0.222em" xref="S5.Ex1.m1.1.1.1.1.2.2.1.cmml">×</mo><mn id="S5.Ex1.m1.1.1.1.1.2.2.5" xref="S5.Ex1.m1.1.1.1.1.2.2.5.cmml">0.51</mn></mrow><mo id="S5.Ex1.m1.1.1.1.1.2.1" lspace="0.170em" xref="S5.Ex1.m1.1.1.1.1.2.1.cmml">⁢</mo><mtext class="ltx_mathvariant_italic" id="S5.Ex1.m1.1.1.1.1.2.3" xref="S5.Ex1.m1.1.1.1.1.2.3b.cmml"><em class="ltx_emph ltx_font_italic" id="S5.Ex1.m1.1.1.1.1.2.3.1nest">kWh</em></mtext></mrow><mo id="S5.Ex1.m1.1.1.1.1.1" xref="S5.Ex1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S5.Ex1.m1.1.1.1.1.3" xref="S5.Ex1.m1.1.1.1.1.3.cmml"><mn id="S5.Ex1.m1.1.1.1.1.3.2" xref="S5.Ex1.m1.1.1.1.1.3.2.cmml">171.36</mn><mo id="S5.Ex1.m1.1.1.1.1.3.1" lspace="0.170em" xref="S5.Ex1.m1.1.1.1.1.3.1.cmml">⁢</mo><mtext class="ltx_mathvariant_italic" id="S5.Ex1.m1.1.1.1.1.3.3" xref="S5.Ex1.m1.1.1.1.1.3.3b.cmml"><em class="ltx_emph ltx_font_italic" id="S5.Ex1.m1.1.1.1.1.3.3.1nest">kWh</em></mtext></mrow></mrow><mo id="S5.Ex1.m1.1.1.1.2" lspace="0em" xref="S5.Ex1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex1.m1.1b"><apply id="S5.Ex1.m1.1.1.1.1.cmml" xref="S5.Ex1.m1.1.1.1"><eq id="S5.Ex1.m1.1.1.1.1.1.cmml" xref="S5.Ex1.m1.1.1.1.1.1"></eq><apply id="S5.Ex1.m1.1.1.1.1.2.cmml" xref="S5.Ex1.m1.1.1.1.1.2"><times id="S5.Ex1.m1.1.1.1.1.2.1.cmml" xref="S5.Ex1.m1.1.1.1.1.2.1"></times><apply id="S5.Ex1.m1.1.1.1.1.2.2.cmml" xref="S5.Ex1.m1.1.1.1.1.2.2"><times id="S5.Ex1.m1.1.1.1.1.2.2.1.cmml" xref="S5.Ex1.m1.1.1.1.1.2.2.1"></times><cn id="S5.Ex1.m1.1.1.1.1.2.2.2.cmml" type="integer" xref="S5.Ex1.m1.1.1.1.1.2.2.2">7</cn><cn id="S5.Ex1.m1.1.1.1.1.2.2.3.cmml" type="integer" xref="S5.Ex1.m1.1.1.1.1.2.2.3">3</cn><cn id="S5.Ex1.m1.1.1.1.1.2.2.4.cmml" type="integer" xref="S5.Ex1.m1.1.1.1.1.2.2.4">16</cn><cn id="S5.Ex1.m1.1.1.1.1.2.2.5.cmml" type="float" xref="S5.Ex1.m1.1.1.1.1.2.2.5">0.51</cn></apply><ci id="S5.Ex1.m1.1.1.1.1.2.3b.cmml" xref="S5.Ex1.m1.1.1.1.1.2.3"><mtext class="ltx_mathvariant_italic" id="S5.Ex1.m1.1.1.1.1.2.3.cmml" xref="S5.Ex1.m1.1.1.1.1.2.3"><em class="ltx_emph ltx_font_italic" id="S5.Ex1.m1.1.1.1.1.2.3.1anest">kWh</em></mtext></ci></apply><apply id="S5.Ex1.m1.1.1.1.1.3.cmml" xref="S5.Ex1.m1.1.1.1.1.3"><times id="S5.Ex1.m1.1.1.1.1.3.1.cmml" xref="S5.Ex1.m1.1.1.1.1.3.1"></times><cn id="S5.Ex1.m1.1.1.1.1.3.2.cmml" type="float" xref="S5.Ex1.m1.1.1.1.1.3.2">171.36</cn><ci id="S5.Ex1.m1.1.1.1.1.3.3b.cmml" xref="S5.Ex1.m1.1.1.1.1.3.3"><mtext class="ltx_mathvariant_italic" id="S5.Ex1.m1.1.1.1.1.3.3.cmml" xref="S5.Ex1.m1.1.1.1.1.3.3"><em class="ltx_emph ltx_font_italic" id="S5.Ex1.m1.1.1.1.1.3.3.1anest">kWh</em></mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex1.m1.1c">7\times 3\times 16\times 0.51\,\emph{kWh}=171.36\,\emph{kWh}.</annotation><annotation encoding="application/x-llamapun" id="S5.Ex1.m1.1d">7 × 3 × 16 × 0.51 kWh = 171.36 kWh .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3. </span>The Energy Consumption of a Paper</h4>
<div class="ltx_para" id="S5.SS1.SSS3.p1">
<p class="ltx_p" id="S5.SS1.SSS3.p1.1">Based on experiments and our paper study (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S3" title="3. Comparative Study: Recommender Systems Research in 2023 versus 2013 ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>), we estimate the energy consumption of a representative 2023 paper to be 6,854.4 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS3.p1.1.1">kWh</em>.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p2">
<p class="ltx_p" id="S5.SS1.SSS3.p2.1">The energy consumption estimation of 171.36 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS3.p2.1.1">kWh</em> per recommender systems experimental pipeline only accounts for the direct energy consumption during the experimental run (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS1.SSS2" title="5.1.2. The Energy Consumption of an Experimental Pipeline ‣ 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.1.2</span></a>).
The estimation excludes energy costs for preliminary activities such as algorithm prototyping, initial test runs, data collection, data preprocessing, debugging, and potential re-running of experiments due to pipeline errors.
Therefore, to approximate the total energy impact of a recommender systems paper, we account for these additional energy costs by introducing an additional factor.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p3">
<p class="ltx_p" id="S5.SS1.SSS3.p3.1">We interviewed the authors of Elliot <cite class="ltx_cite ltx_citemacro_citep">(Anelli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib4" title="">2021</a>)</cite>, RecPack <cite class="ltx_cite ltx_citemacro_citep">(Michiels et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib36" title="">2022</a>)</cite>, LensKit <cite class="ltx_cite ltx_citemacro_citep">(Ekstrand, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib16" title="">2020</a>)</cite>, and recommender systems practitioners <cite class="ltx_cite ltx_citemacro_citep">(Falk and Arngren, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib18" title="">2023</a>)</cite> asking them to estimate a factor of the energy consumption overhead of a recommender systems paper compared to running the experimental pipeline once.
Their median answer was 40.
We multiplied the energy consumption of experimental pipelines accordingly.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p4">
<p class="ltx_p" id="S5.SS1.SSS3.p4.1">Following this, we estimate the energy consumption of experiments for the results presented in a recommender systems paper ranges to be 6,854.4 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS3.p4.1.1">kWh</em>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Energy Consumption and Performance Trade-Off</h3>
<figure class="ltx_figure" id="S5.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="830" id="S5.F2.g1" src="x3.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F2.8.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="S5.F2.9.2" style="font-size:90%;">Total energy consumption (in <em class="ltx_emph ltx_font_italic" id="S5.F2.9.2.1">kWh</em>) vs. averaged and normalized <em class="ltx_emph ltx_font_italic" id="S5.F2.9.2.2">nDCG@10</em> performance. Data points in <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S5.F2.9.2.3">blue</em> represent algorithms running on CPUs and <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S5.F2.9.2.4">red</em> for running on GPUs. A cross represents a traditional, and a dot is a deep learning algorithm. The <em class="ltx_emph ltx_font_italic" id="S5.F2.9.2.5">nDCG@10</em> is normalized within each dataset to ensure uniform impact and averaged across all twelve included datasets. The upper x-axis shows the <em class="ltx_emph ltx_font_italic" id="S5.F2.9.2.6">gCO<sub class="ltx_sub" id="S5.F2.9.2.6.1">2</sub>e</em> emissions, calculated using the 2023 world average.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F2.10">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F2.11">[Test]Test</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.3">Our results demonstrate that higher energy consumption does not necessarily lead to better performance (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F2" title="In 5.2. Energy Consumption and Performance Trade-Off ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>).
Two of the three top-performing algorithms (<em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.1">UserKNN<sup class="ltx_sup" id="S5.SS2.p1.1.1.1">LK</sup></em> and <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.2.2">ItemKNN<sup class="ltx_sup" id="S5.SS2.p1.2.2.1">RB</sup></em>) are traditional nearest neighbor algorithms that both consume on average around 0.040 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.3.4">kWh</em> for a single run on one dataset (average of twelve datasets used for 2023 experiments).
In contrast, the third, a deep learning algorithm (<em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.3.3">MacridVAE<sup class="ltx_sup" id="S5.SS2.p1.3.3.1">RB</sup></em>) consumes, on average, 45 times more energy at 1.8 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.3.5">kWh</em> per run on one dataset.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.3">In general, our results show that deep learning algorithms consume eight times more energy than traditional algorithms for a single run, on average, on one dataset (0.09 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.3.4">kWh</em> vs. 0.68 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.3.5">kWh</em>) without achieving a higher average and normalized <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.3.6">nDCG@10</em> score.
One comparison that further illustrates the energy consumption and performance trade-off between deep learning and traditional algorithms is the comparison between the <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.1.1">MacridVAE<sup class="ltx_sup" id="S5.SS2.p2.1.1.1">RB</sup></em> (deep learning) and the <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.2.2">UserKNN<sup class="ltx_sup" id="S5.SS2.p2.2.2.1">LK</sup></em> (traditional) algorithms.
While both algorithms achieve around the same normalized and averaged <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.3.7">nDCG@10</em> performance (1.8 vs 1.7), <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.3.3">MacridVAE<sup class="ltx_sup" id="S5.SS2.p2.3.3.1">RB</sup></em> consumes almost 60 times more energy (1.79 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.3.8">kWh</em> vs. 0.03 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.3.9">kWh</em>).</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.4">As widely known and highlighted by current research, hyperparameter optimization and randomness impacts the algorithm performance <cite class="ltx_cite ltx_citemacro_citep">(Shehzad and Jannach, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib45" title="">2023</a>; Wegmeth et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib54" title="">2023</a>)</cite>.
We acknowledge that tuning hyperparameters and repeating experiments could alter our results.
However, this would likely increase the energy consumption disparity between deep learning and traditional algorithms.
For instance, if we optimize the hyperparameters of <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.1.1">MacridVAE<sup class="ltx_sup" id="S5.SS2.p3.1.1.1">RB</sup></em> and <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.2">UserKNN<sup class="ltx_sup" id="S5.SS2.p3.2.2.1">LK</sup></em> through a grid search with 16 configurations and repeat the process with five different seeds, <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.3.3">MacridVAE<sup class="ltx_sup" id="S5.SS2.p3.3.3.1">RB</sup></em> would consume 143.2 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.4.5">kWh</em>, while <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.4.4">UserKNN<sup class="ltx_sup" id="S5.SS2.p3.4.4.1">LK</sup></em> would only use 2.4 <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.4.6">kWh</em> (factor of 60).</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">The energy consumption difference between deep learning and traditional algorithms is not solely due to GPU usage.
While GPUs consume more energy than CPUs, implementation and complexity also play a role.
For instance, <em class="ltx_emph ltx_font_italic" id="S5.SS2.p4.1.1">ItemKNN<sup class="ltx_sup" id="S5.SS2.p4.1.1.1">RB</sup></em> on a GPU consumes no significantly more energy than CPU-based <em class="ltx_emph ltx_font_italic" id="S5.SS2.p4.1.2">KNN</em> counterparts(<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F2" title="In 5.2. Energy Consumption and Performance Trade-Off ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Carbon Footprint and Trends</h3>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1. </span>The Carbon Footprint of Experiments at ACM Recsys 2023</h4>
<div class="ltx_para" id="S5.SS3.SSS1.p1">
<p class="ltx_p" id="S5.SS3.SSS1.p1.1">Based on our experiments, we estimate that running all ACM RecSys 2023 full paper experiments emitted 886.9 metric tonnes of <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p1.1.1">CO<sub class="ltx_sub" id="S5.SS3.SSS1.p1.1.1.1">2</sub></em> equivalents. Our <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p1.1.2">CO<sub class="ltx_sub" id="S5.SS3.SSS1.p1.1.2.1">2</sub>e</em> estimation is based on the number of submissions and the conversion factors from <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p1.1.3">kWh</em> to <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p1.1.4">gCO<sub class="ltx_sub" id="S5.SS3.SSS1.p1.1.4.1">2</sub>e</em>.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p2">
<p class="ltx_p" id="S5.SS3.SSS1.p2.1">The carbon footprint of all ACM RecSys 2023 full papers is closely tied to the number of submissions received.
The conference accepted 47 full papers out of 269 submissions.
Since the submissions involved running experiments, every submission added to the total carbon footprint of the ACM RecSys 2023 experiments.
Consequently, we account for all 269 submissions in our analysis.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p3">
<p class="ltx_p" id="S5.SS3.SSS1.p3.1">Our carbon footprint estimation is further based on the <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.1.1">world average</em> conversion factor of 481 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.1.2">gCO<sub class="ltx_sub" id="S5.SS3.SSS1.p3.1.2.1">2</sub>e</em> per <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.1.3">kWh</em> <cite class="ltx_cite ltx_citemacro_citep">(Ember and Institute, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib17" title="">2024</a>)</cite>.
We estimate that a full paper experimental pipeline consumes, on average, 6,854.4 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.1.4">kWh</em> (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.SS1" title="5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.1</span></a>).
With the conversion factor of 481 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.1.5">gCO<sub class="ltx_sub" id="S5.SS3.SSS1.p3.1.5.1">2</sub>e</em> per <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.1.6">kWh</em>, the carbon emissions of the 2023 ACM RecSys conference experiments in metric tonnes of <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.1.7">CO<sub class="ltx_sub" id="S5.SS3.SSS1.p3.1.7.1">2</sub>e</em> are calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="6,854.4\emph{kWh}\times 481\emph{gCO\textsubscript{2}e}\times 269\,(%
submissions)=886.9\,TCO\textsubscript{2}e" class="ltx_Math" display="block" id="S5.Ex2.m1.2"><semantics id="S5.Ex2.m1.2a"><mrow id="S5.Ex2.m1.2.2" xref="S5.Ex2.m1.2.2.cmml"><mrow id="S5.Ex2.m1.2.2.1.1" xref="S5.Ex2.m1.2.2.1.2.cmml"><mn id="S5.Ex2.m1.1.1" xref="S5.Ex2.m1.1.1.cmml">6</mn><mo id="S5.Ex2.m1.2.2.1.1.2" xref="S5.Ex2.m1.2.2.1.2.cmml">,</mo><mrow id="S5.Ex2.m1.2.2.1.1.1" xref="S5.Ex2.m1.2.2.1.1.1.cmml"><mrow id="S5.Ex2.m1.2.2.1.1.1.3" xref="S5.Ex2.m1.2.2.1.1.1.3.cmml"><mrow id="S5.Ex2.m1.2.2.1.1.1.3.2" xref="S5.Ex2.m1.2.2.1.1.1.3.2.cmml"><mrow id="S5.Ex2.m1.2.2.1.1.1.3.2.2" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.cmml"><mrow id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.cmml"><mn id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.2" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.2.cmml">854.4</mn><mo id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.1" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.1.cmml">⁢</mo><mtext class="ltx_mathvariant_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3b.cmml"><em class="ltx_emph ltx_font_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3.1nest">kWh</em></mtext></mrow><mo id="S5.Ex2.m1.2.2.1.1.1.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.1.cmml">×</mo><mn id="S5.Ex2.m1.2.2.1.1.1.3.2.2.3" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.3.cmml">481</mn></mrow><mo id="S5.Ex2.m1.2.2.1.1.1.3.2.1" xref="S5.Ex2.m1.2.2.1.1.1.3.2.1.cmml">⁢</mo><mrow id="S5.Ex2.m1.2.2.1.1.1.3.2.3" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3g.cmml"><mtext class="ltx_mathvariant_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3a" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3g.cmml"><em class="ltx_emph ltx_font_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3.1nest">gCO</em></mtext><mtext id="S5.Ex2.m1.2.2.1.1.1.3.2.3c" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3g.cmml"><sub class="ltx_sub" id="S5.Ex2.m1.2.2.1.1.1.3.2.3.2nest"><em class="ltx_emph ltx_font_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3.2.1nest">2</em></sub></mtext><mtext class="ltx_mathvariant_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3f" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3g.cmml">e</mtext></mrow></mrow><mo id="S5.Ex2.m1.2.2.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S5.Ex2.m1.2.2.1.1.1.3.1.cmml">×</mo><mn id="S5.Ex2.m1.2.2.1.1.1.3.3" xref="S5.Ex2.m1.2.2.1.1.1.3.3.cmml">269</mn></mrow><mo id="S5.Ex2.m1.2.2.1.1.1.2" lspace="0.170em" xref="S5.Ex2.m1.2.2.1.1.1.2.cmml">⁢</mo><mrow id="S5.Ex2.m1.2.2.1.1.1.1.1" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.cmml"><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.2" stretchy="false" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.Ex2.m1.2.2.1.1.1.1.1.1" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.2" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.2.cmml">s</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.3" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.3.cmml">u</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1a" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.4" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.4.cmml">b</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1b" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.5" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.5.cmml">m</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1c" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.6" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.6.cmml">i</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1d" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.7" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.7.cmml">s</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1e" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.8" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.8.cmml">s</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1f" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.9" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.9.cmml">i</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1g" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.10" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.10.cmml">o</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1h" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.11" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.11.cmml">n</mi><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1i" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.1.1.1.1.1.1.12" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.12.cmml">s</mi></mrow><mo id="S5.Ex2.m1.2.2.1.1.1.1.1.3" stretchy="false" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S5.Ex2.m1.2.2.2" xref="S5.Ex2.m1.2.2.2.cmml">=</mo><mrow id="S5.Ex2.m1.2.2.3" xref="S5.Ex2.m1.2.2.3.cmml"><mn id="S5.Ex2.m1.2.2.3.2" xref="S5.Ex2.m1.2.2.3.2.cmml">886.9</mn><mo id="S5.Ex2.m1.2.2.3.1" lspace="0.170em" xref="S5.Ex2.m1.2.2.3.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.3.3" xref="S5.Ex2.m1.2.2.3.3.cmml">T</mi><mo id="S5.Ex2.m1.2.2.3.1a" xref="S5.Ex2.m1.2.2.3.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.3.4" xref="S5.Ex2.m1.2.2.3.4.cmml">C</mi><mo id="S5.Ex2.m1.2.2.3.1b" xref="S5.Ex2.m1.2.2.3.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.3.5" xref="S5.Ex2.m1.2.2.3.5.cmml">O</mi><mo id="S5.Ex2.m1.2.2.3.1c" xref="S5.Ex2.m1.2.2.3.1.cmml">⁢</mo><mtext id="S5.Ex2.m1.2.2.3.6" xref="S5.Ex2.m1.2.2.3.6b.cmml"><sub class="ltx_sub" id="S5.Ex2.m1.2.2.3.6.1nest">2</sub></mtext><mo id="S5.Ex2.m1.2.2.3.1d" xref="S5.Ex2.m1.2.2.3.1.cmml">⁢</mo><mi id="S5.Ex2.m1.2.2.3.7" xref="S5.Ex2.m1.2.2.3.7.cmml">e</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex2.m1.2b"><apply id="S5.Ex2.m1.2.2.cmml" xref="S5.Ex2.m1.2.2"><eq id="S5.Ex2.m1.2.2.2.cmml" xref="S5.Ex2.m1.2.2.2"></eq><list id="S5.Ex2.m1.2.2.1.2.cmml" xref="S5.Ex2.m1.2.2.1.1"><cn id="S5.Ex2.m1.1.1.cmml" type="integer" xref="S5.Ex2.m1.1.1">6</cn><apply id="S5.Ex2.m1.2.2.1.1.1.cmml" xref="S5.Ex2.m1.2.2.1.1.1"><times id="S5.Ex2.m1.2.2.1.1.1.2.cmml" xref="S5.Ex2.m1.2.2.1.1.1.2"></times><apply id="S5.Ex2.m1.2.2.1.1.1.3.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3"><times id="S5.Ex2.m1.2.2.1.1.1.3.1.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.1"></times><apply id="S5.Ex2.m1.2.2.1.1.1.3.2.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2"><times id="S5.Ex2.m1.2.2.1.1.1.3.2.1.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.1"></times><apply id="S5.Ex2.m1.2.2.1.1.1.3.2.2.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2"><times id="S5.Ex2.m1.2.2.1.1.1.3.2.2.1.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.1"></times><apply id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2"><times id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.1.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.1"></times><cn id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.2.cmml" type="float" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.2">854.4</cn><ci id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3b.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3"><mtext class="ltx_mathvariant_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3"><em class="ltx_emph ltx_font_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.2.2.3.1anest">kWh</em></mtext></ci></apply><cn id="S5.Ex2.m1.2.2.1.1.1.3.2.2.3.cmml" type="integer" xref="S5.Ex2.m1.2.2.1.1.1.3.2.2.3">481</cn></apply><ci id="S5.Ex2.m1.2.2.1.1.1.3.2.3g.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3"><mrow id="S5.Ex2.m1.2.2.1.1.1.3.2.3.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3"><mtext class="ltx_mathvariant_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3a.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3"><em class="ltx_emph ltx_font_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3.1anest">gCO</em></mtext><mtext id="S5.Ex2.m1.2.2.1.1.1.3.2.3c.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3"><sub class="ltx_sub" id="S5.Ex2.m1.2.2.1.1.1.3.2.3.2anest"><em class="ltx_emph ltx_font_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3.2.1anest">2</em></sub></mtext><mtext class="ltx_mathvariant_italic" id="S5.Ex2.m1.2.2.1.1.1.3.2.3f.cmml" xref="S5.Ex2.m1.2.2.1.1.1.3.2.3">e</mtext></mrow></ci></apply><cn id="S5.Ex2.m1.2.2.1.1.1.3.3.cmml" type="integer" xref="S5.Ex2.m1.2.2.1.1.1.3.3">269</cn></apply><apply id="S5.Ex2.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1"><times id="S5.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.1"></times><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.2">𝑠</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.3">𝑢</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.4">𝑏</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.5.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.5">𝑚</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.6.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.6">𝑖</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.7.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.7">𝑠</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.8.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.8">𝑠</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.9.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.9">𝑖</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.10.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.10">𝑜</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.11.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.11">𝑛</ci><ci id="S5.Ex2.m1.2.2.1.1.1.1.1.1.12.cmml" xref="S5.Ex2.m1.2.2.1.1.1.1.1.1.12">𝑠</ci></apply></apply></list><apply id="S5.Ex2.m1.2.2.3.cmml" xref="S5.Ex2.m1.2.2.3"><times id="S5.Ex2.m1.2.2.3.1.cmml" xref="S5.Ex2.m1.2.2.3.1"></times><cn id="S5.Ex2.m1.2.2.3.2.cmml" type="float" xref="S5.Ex2.m1.2.2.3.2">886.9</cn><ci id="S5.Ex2.m1.2.2.3.3.cmml" xref="S5.Ex2.m1.2.2.3.3">𝑇</ci><ci id="S5.Ex2.m1.2.2.3.4.cmml" xref="S5.Ex2.m1.2.2.3.4">𝐶</ci><ci id="S5.Ex2.m1.2.2.3.5.cmml" xref="S5.Ex2.m1.2.2.3.5">𝑂</ci><ci id="S5.Ex2.m1.2.2.3.6b.cmml" xref="S5.Ex2.m1.2.2.3.6"><mtext id="S5.Ex2.m1.2.2.3.6.cmml" xref="S5.Ex2.m1.2.2.3.6"><sub class="ltx_sub" id="S5.Ex2.m1.2.2.3.6.1anest">2</sub></mtext></ci><ci id="S5.Ex2.m1.2.2.3.7.cmml" xref="S5.Ex2.m1.2.2.3.7">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex2.m1.2c">6,854.4\emph{kWh}\times 481\emph{gCO\textsubscript{2}e}\times 269\,(%
submissions)=886.9\,TCO\textsubscript{2}e</annotation><annotation encoding="application/x-llamapun" id="S5.Ex2.m1.2d">6 , 854.4 kWh × 481 gCO e × 269 ( italic_s italic_u italic_b italic_m italic_i italic_s italic_s italic_i italic_o italic_n italic_s ) = 886.9 italic_T italic_C italic_O italic_e</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS3.SSS1.p3.2">To illustrate, 886.9 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.2.1">TCO<sub class="ltx_sub" id="S5.SS3.SSS1.p3.2.1.1">2</sub>e</em> is the equivalent of 384 passenger flights from New York (USA) to Melbourne (Australia) <cite class="ltx_cite ltx_citemacro_citep">(Lannelongue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib31" title="">2021</a>)</cite>.
Or the amount of <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p3.2.2">CO<sub class="ltx_sub" id="S5.SS3.SSS1.p3.2.2.1">2</sub>e</em> that, on average, one tree sequesters in 80,600 years <cite class="ltx_cite ltx_citemacro_citep">(Department for Business, Energy &amp; Industrial Strategy, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib15" title="">2020</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2. </span>The Geographical Impact on the Carbon Footprint</h4>
<div class="ltx_para" id="S5.SS3.SSS2.p1">
<p class="ltx_p" id="S5.SS3.SSS2.p1.1">Variations in energy generation across different geographical locations affect carbon footprint by as much as 1200% (45 vs. 535 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p1.1.1">gCO<sub class="ltx_sub" id="S5.SS3.SSS2.p1.1.1.1">2</sub>e</em> ).</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p2">
<p class="ltx_p" id="S5.SS3.SSS2.p2.1">Each location has its own <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p2.1.1">kWh</em> to <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p2.1.2">gCO<sub class="ltx_sub" id="S5.SS3.SSS2.p2.1.2.1">2</sub>e</em> conversion factor, which reflects the carbon intensity of its electricity generation.
The conversion factor is based on the energy sources of the respective geographical location.
For instance, we ran our experiments in a geographical location that mainly utilizes renewable energy sources such as wind and hydropower <cite class="ltx_cite ltx_citemacro_citep">(Zhong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib63" title="">2021</a>)</cite>.
Unlike this geographical location, some regions in Asia
depend on coal <cite class="ltx_cite ltx_citemacro_citep">(Pressburger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib43" title="">2022</a>)</cite>.
As a result, our conversion factor from <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p2.1.3">kWh</em> to <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p2.1.4">gCO<sub class="ltx_sub" id="S5.SS3.SSS2.p2.1.4.1">2</sub></em> is twelve times lower than that of the Asian region (45 vs. 535 <cite class="ltx_cite ltx_citemacro_citep">(Ember and Institute, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib17" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p3">
<p class="ltx_p" id="S5.SS3.SSS2.p3.1">If all experiments from ACM RecSys 2023 had been conducted in Sweden, the carbon emission estimation would have been reduced to 83 metric tonnes (90% less than 886.9 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.1">TCO<sub class="ltx_sub" id="S5.SS3.SSS2.p3.1.1.1">2</sub>e</em>).
In contrast, running the experiments in Asia, our estimation would have increased our carbon emission estimation by 99.6 metric tonnes of <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.2">CO<sub class="ltx_sub" id="S5.SS3.SSS2.p3.1.2.1">2</sub>e</em> (886.9 vs. 986.5 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.3">TCO<sub class="ltx_sub" id="S5.SS3.SSS2.p3.1.3.1">2</sub>e</em>)
Since no paper from ACM RecSys 2023 reported the data center or location where the experiments were conducted, we used the <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.4">world average</em> conversion factor of 481 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.5">gCO<sub class="ltx_sub" id="S5.SS3.SSS2.p3.1.5.1">2</sub>e</em> per <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.6">kWh</em><cite class="ltx_cite ltx_citemacro_citep">(Ember and Institute, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib17" title="">2024</a>)</cite> to convert <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.7">kWh</em> to <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p3.1.8">gCO<sub class="ltx_sub" id="S5.SS3.SSS2.p3.1.8.1">2</sub>e</em> to estimate the carbon emissions.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p4">
<p class="ltx_p" id="S5.SS3.SSS2.p4.1">The amount of <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p4.1.1">CO<sub class="ltx_sub" id="S5.SS3.SSS2.p4.1.1.1">2</sub></em> emitted by experiments is not solely determined by the location.
Some data centers operate mainly on renewable energy regardless of their location.
For instance, <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p4.1.2">Amazon</em> reports that their data centers used for <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p4.1.3">AWS</em> cloud services predominantly utilize renewable sources<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://sustainability.aboutamazon.com/products-services/the-cloud" title="">https://sustainability.aboutamazon.com/products-services/the-cloud</a></span></span></span>.
Consequently, these specific data centers may have a conversion factor from <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p4.1.4">kWh</em> to <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p4.1.5">gCO<sub class="ltx_sub" id="S5.SS3.SSS2.p4.1.5.1">2</sub>e</em> that differs from the general rate of their location.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.3. </span>The Hardware Impact on the Carbon Footprint</h4>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="587" id="S5.F3.g1" src="x4.png" width="831"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.4.1.1" style="font-size:90%;">Figure 3</span>. </span><span class="ltx_text" id="S5.F3.5.2" style="font-size:90%;">The relationship between energy consumption (in <em class="ltx_emph ltx_font_italic" id="S5.F3.5.2.1">kWh</em>) and runtime, including training, prediction, and evaluation phases (in seconds). Each data point represents an algorithm applied to one of the twelve datasets. The linear functions illustrate the linear regression models for the respective groups of data points. The right-hand y-axis displays the corresponding <em class="ltx_emph ltx_font_italic" id="S5.F3.5.2.2">gCO<sub class="ltx_sub" id="S5.F3.5.2.2.1">2</sub>e</em> emissions, calculated using the 2023 world average.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F3.6">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F3.7">[Test]Test</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SS3.SSS3.p1">
<p class="ltx_p" id="S5.SS3.SSS3.p1.1">The <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS3.p1.1.1">CO<sub class="ltx_sub" id="S5.SS3.SSS3.p1.1.1.1">2</sub>e</em> emissions of recommender systems experiments are influenced by more than geographical location, energy sources, algorithm types, and dataset characteristics. The type of hardware executing experiments can also affect the <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS3.p1.1.2">CO<sub class="ltx_sub" id="S5.SS3.SSS3.p1.1.2.1">2</sub>e</em> emissions by a factor of up to ten. For example, the same experiments emit 14.4 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS3.p1.1.3">gCO<sub class="ltx_sub" id="S5.SS3.SSS3.p1.1.3.1">2</sub>e</em> when executed on an M1 MacBook Pro but 163.5 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS3.p1.1.4">gCO<sub class="ltx_sub" id="S5.SS3.SSS3.p1.1.4.1">2</sub>e</em> when executed on a modern workstation with an NVIDIA GPU.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p2">
<p class="ltx_p" id="S5.SS3.SSS3.p2.1">Various hardware components, architectures, and cooling methods affect the energy consumption of recommender system experiments.
Based on our experiments, a modern workstation with an NVIDIA GPU consumes, on average, five times more energy compared to an M1 Ultra Mac Studio (0.33 vs. 0.07 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS3.p2.1.1">kWh</em>) and ten times more energy compared to the M1 MacBook Pro (0.33 vs. 0.03 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS3.p2.1.2">kWh</em>).</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p3">
<p class="ltx_p" id="S5.SS3.SSS3.p3.1">Different hardware types do not only affect the energy consumption but also the running time of a recommender systems experiment.
For instance, while a modern workstation uses, on average, ten times more energy than an M1 MacBook Pro, it completes the experiments, on average, in only one-third of the time (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F3" title="In 5.3.3. The Hardware Impact on the Carbon Footprint ‣ 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>).
Therefore, it is possible to save energy by running an experiment on an M1 MacBook Pro if you accept an increase in running time.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p4">
<p class="ltx_p" id="S5.SS3.SSS3.p4.1">Overall, our results show a linear trend between energy consumption and runtime across various hardware types (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F3" title="In 5.3.3. The Hardware Impact on the Carbon Footprint ‣ 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>).
Although the slopes of the graphs vary, a consistent linear pattern is evident.
This relationship suggests that a longer runtime is associated with increased energy consumption.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p5">
<p class="ltx_p" id="S5.SS3.SSS3.p5.1">Even though a modern workstation consumes more energy, we run experiments on it because not all algorithms are compatible with Apple’s ARM architecture.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.4. </span>The Carbon Footprint of Recommender Systems 2013 vs. 2023</h4>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="738" id="S5.F4.g1" src="x5.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.6.1.1" style="font-size:90%;">Figure 4</span>. </span><span class="ltx_text" id="S5.F4.7.2" style="font-size:90%;">Average power consumption of traditional algorithms executed on 2013 hardware across seven datasets. The <em class="ltx_emph ltx_font_italic" id="S5.F4.7.2.1">orange</em> vertical line indicates the average energy consumption in <em class="ltx_emph ltx_font_italic" id="S5.F4.7.2.2">kWh</em> for ranking predictions and the <em class="ltx_emph ltx_font_italic" id="S5.F4.7.2.3">orange</em> for rating prediction tasks. The upper x-axis shows the <em class="ltx_emph ltx_font_italic" id="S5.F4.7.2.4">gCO<sub class="ltx_sub" id="S5.F4.7.2.4.1">2</sub>e</em> emissions, calculated using the 2023 world average. Not every algorithm is suited for rating- and ranking prediction tasks; therefore, not every algorithm displays two boxplots.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F4.8">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F4.9">[Test]Test</p>
</div>
</div>
</figure>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="738" id="S5.F5.g1" src="x6.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.2.1.1" style="font-size:90%;">Figure 5</span>. </span><span class="ltx_text" id="S5.F5.3.2" style="font-size:90%;">The regional variations in <em class="ltx_emph ltx_font_italic" id="S5.F5.3.2.1">gCO<sub class="ltx_sub" id="S5.F5.3.2.1.1">2</sub>e</em> per recommender system algorithm type. The x-axis displays the <em class="ltx_emph ltx_font_italic" id="S5.F5.3.2.2">gCO<sub class="ltx_sub" id="S5.F5.3.2.2.1">2</sub>e</em>, while the y-axis categorizes by region. Blue bars represent the emissions from a representative deep learning algorithm executed on the modern workstation hardware, and orange bars represent those from a traditional algorithm run on 2013 hardware. The <em class="ltx_emph ltx_font_italic" id="S5.F5.3.2.3">gCO<sub class="ltx_sub" id="S5.F5.3.2.3.1">2</sub>e</em> are calculated using the respective annual conversion factors, reflecting changes in <em class="ltx_emph ltx_font_italic" id="S5.F5.3.2.4">gCO<sub class="ltx_sub" id="S5.F5.3.2.4.1">2</sub></em> per <em class="ltx_emph ltx_font_italic" id="S5.F5.3.2.5">kWh</em> over the decade.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F5.4">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F5.5">[Test2]</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SS3.SSS4.p1">
<p class="ltx_p" id="S5.SS3.SSS4.p1.1">The carbon footprint of recommender systems experiments in 2023 compared to 2013 has, on average, increased by a factor of 42 (7.09 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p1.1.1">gCO<sub class="ltx_sub" id="S5.SS3.SSS4.p1.1.1.1">2</sub>e</em> in 2013 vs. 294,9 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p1.1.2">gCO<sub class="ltx_sub" id="S5.SS3.SSS4.p1.1.2.1">2</sub>e</em> in 2023, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F5" title="In 5.3.4. The Carbon Footprint of Recommender Systems 2013 vs. 2023 ‣ 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a>, World Average).</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p2">
<p class="ltx_p" id="S5.SS3.SSS4.p2.1">Simple ranking prediction algorithms used in 2013 recommender system experiments consumed, on average, five times less energy per run on one 2013 dataset using 2013 hardware (0.1 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p2.1.1">kWh</em>, see <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F4" title="In 5.3.4. The Carbon Footprint of Recommender Systems 2013 vs. 2023 ‣ 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>) compared to similar algorithms in 2023 executed on 2023 hardware (0.51 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p2.1.2">kWh</em>, see <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F1.sf2" title="In Figure 1 ‣ 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(b)</span></a>).
In 2013, no algorithm used, on average, more than 0.2 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p2.1.3">kWh</em> per run on one dataset using 2013 hardware (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F4" title="In 5.3.4. The Carbon Footprint of Recommender Systems 2013 vs. 2023 ‣ 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>).
In contrast, all deep learning algorithms in 2023 consume, on average, more than 0.2 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p2.1.4">kWh</em> per run on one dataset with 2023 hardware.
The most energy-intensive algorithms in 2023 use more than six <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p2.1.5">kWh</em> per run (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F1.sf2" title="In Figure 1 ‣ 5.1. The energy consumption of a 2023 recommender systems research paper ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(b)</span></a>).
While rating prediction was frequently used in 2013 recommender system experiments, the energy consumption for rating prediction is, due to prediction times, lower than for ranking prediction tasks (<a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F4" title="In 5.3.4. The Carbon Footprint of Recommender Systems 2013 vs. 2023 ‣ 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p3">
<p class="ltx_p" id="S5.SS3.SSS4.p3.1">The shift towards more complex deep learning algorithms such as <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.1">DGCF</em> or <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.2">MacridVAE</em> and larger datasets like <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.3">Yelp-2018</em>, compared to simpler algorithms like <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.4">Popularity</em> or <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.5">ItemKNN</em> and smaller datasets such as <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.6">Hetrec-LastFM</em> used in 2013, can, in the worst case, increase energy consumption of more than 100,000 times.
For example, running the <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.7">Popularity</em> algorithm on <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.8">Hetrec-LastFM</em> and hardware from 2013 requires only 0.000049 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.9">kWh</em> while running <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.10">DGCF</em> on dataset <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.11">Yelp-2018</em> required 6.6 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p3.1.12">kWh</em> on 2023 hardware, i.e., a factor of around 134,000.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p4">
<p class="ltx_p" id="S5.SS3.SSS4.p4.1">The increased usage of clean energy sources and improved hardware efficiency in 2023, compared to 2013, does not compensate for the increase in carbon emissions due to the use of deep learning algorithms and larger datasets.
A deep learning algorithm running on a 2023 dataset using 2023 hardware emits, on average, 42 times more <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p4.1.1">CO<sub class="ltx_sub" id="S5.SS3.SSS4.p4.1.1.1">2</sub>e</em> than a traditional algorithm on a 2013 dataset using 2013 hardware (7.09 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p4.1.2">gCO<sub class="ltx_sub" id="S5.SS3.SSS4.p4.1.2.1">2</sub>e</em> in 2013 vs. 294,9 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p4.1.3">gCO<sub class="ltx_sub" id="S5.SS3.SSS4.p4.1.3.1">2</sub>e</em> in 2023, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#S5.F5" title="In 5.3.4. The Carbon Footprint of Recommender Systems 2013 vs. 2023 ‣ 5.3. Carbon Footprint and Trends ‣ 5. Results ‣ From Clicks to Carbon: The Environmental Toll of Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a>, World Average).
This estimation already includes the benefit of a better <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p4.1.4">kWh</em> to <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p4.1.5">gCO<sub class="ltx_sub" id="S5.SS3.SSS4.p4.1.5.1">2</sub>e</em> conversion factors, improved by 62 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS4.p4.1.6">gCO<sub class="ltx_sub" id="S5.SS3.SSS4.p4.1.6.1">2</sub>e</em> due to the more frequent use of clean energy resources <cite class="ltx_cite ltx_citemacro_citep">(Ember and Institute, <a class="ltx_ref" href="https://arxiv.org/html/2408.08203v2#bib.bib17" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p5">
<p class="ltx_p" id="S5.SS3.SSS4.p5.1">It is important to highlight that our analysis used hardware and algorithms from 2013 but not the exact software implementations used in the original papers.
It was infeasible to retrieve old, unmaintained, non-centrally hosted software.
Consequently, many experiments likely used self-implemented algorithms.
Compared to self-implemented algorithms, standardized software libraries could potentially change the efficiency, suggesting that the observed disparity in energy consumption between traditional and deep learning models might diverge.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Discussion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our analysis highlights the significant environmental impact of full papers from the 2023 ACM Recommender Systems conference.
We found that deep learning algorithms, when compared to traditional machine learning, consume substantially more energy without necessarily delivering better performance.
Additionally, the carbon footprint and environmental impact of recommender systems experiments have dramatically increased over the past decade.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">We do not advocate abandoning deep learning algorithms but aim to raise awareness about the environmental impact of the trend toward deep learning-focused research.
We encourage researchers and practitioners to document the experimental pipelines, computational overheads, hardware, and energy consumption in their publications.
These details can help in understanding the environmental impact, highlight the energy demands, and reveal potential areas for energy efficiency improvements and reproducibility of recommender systems experiments.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Furthermore, we emphasize the importance of carefully selecting algorithms and datasets for recommender systems experiments. The environmental impact of deep learning algorithms can notably differ depending on the chosen algorithms and datasets.
Researchers can minimize unnecessary computations by using efficient hardware or designing experimental recommender systems pipelines and thus reduce their environmental impact.
We also draw attention to the impact of hardware and geographic location on recommender systems experiments.
If computers in different geographic locations are available, comparing the efficiency, hardware requirements, and energy source of the specific location can help reduce the environmental impact of running the experimental pipeline.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusions</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We reveal that the energy consumption of an average recommender systems research paper is approximately 6,854.4 <em class="ltx_emph ltx_font_italic" id="S7.p1.1.1">kWh</em> (<span class="ltx_text ltx_font_bold" id="S7.p1.1.2">RQ1</span>).
Deep learning algorithms consume, on average, eight times more energy than traditional algorithms without achieving higher performance (<span class="ltx_text ltx_font_bold" id="S7.p1.1.3">RQ2</span>).
The carbon footprint of recommender systems experiments has increased significantly, with experiments from 2023 emitting approximately 42 times more CO<sub class="ltx_sub" id="S7.p1.1.4">2</sub>e when compared to experimental pipelines from 2013 (<span class="ltx_text ltx_font_bold" id="S7.p1.1.5">RQ3</span>).</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">We want to raise awareness about the significant environmental impact of deep learning-focused research.
It is crucial that future publications include thorough documentation of the entire experimental pipeline, including computational overhead, hardware specifications, and energy consumption.
This transparency is not only essential for enhancing reproducibility but also for identifying potential areas for energy efficiency improvements.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">Moreover, careful selection of algorithms and datasets is crucial, as the environmental impact of deep learning algorithms can vary significantly.
Researchers can design more efficient experimental pipelines to minimize unnecessary computations and reduce environmental impact.
Additionally, considering the impact of hardware and geographic location on experiments is vital.
Comparing the efficiency, hardware requirements, and energy sources across different locations can further mitigate the environmental impact of experimental pipelines.
We conducted all our experiments in Sweden, utilizing approximately 6,000 kWh of electricity, which corresponds to about 271.6 kilograms of CO<sub class="ltx_sub" id="S7.p3.1.1">2</sub>e.
We planted 42 trees with One Tree Planted to offset our carbon emissions.</p>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1">Raising awareness about energy consumption and environmental impact can catalyze the development of more sustainable practices, benefiting the environment and recommender systems.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work was in part supported by: <span class="ltx_text ltx_font_bold" id="S7.1.1">(1)</span> funding from the Ministry of Culture and Science of the German State of North Rhine-Westphalia, grant no. 311-8.03.03.02-149514, and <span class="ltx_text ltx_font_bold" id="S7.2.2">(2)</span> two ERASMUS+ Short-Term Doctoral Mobility Traineeships from the European Commission.
Furthermore, we are grateful for the support of Moritz Baumgart.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">10. (2013)</span>
<span class="ltx_bibblock">
2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">RecSys ’13: Proceedings of the 7th ACM conference on Recommender systems</em> (Hong Kong, China). Association for Computing Machinery, New York, NY, USA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">10. (2023)</span>
<span class="ltx_bibblock">
2023.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">RecSys ’23: Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore). Association for Computing Machinery, New York, NY, USA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anelli et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Vito Walter Anelli, Alejandro Bellogín, Antonio Ferrara, Daniele Malitesta, Felice Antonio Merra, Claudio Pomo, Francesco Maria Donini, and Tommaso Di Noia. 2021.

</span>
<span class="ltx_bibblock">Elliot: A Comprehensive and Rigorous Framework for Reproducible Recommender Systems Evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">SIGIR ’21: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, Virtual Event, Canada, July 11-15, 2021</em>, Fernando Diaz, Chirag Shah, Torsten Suel, Pablo Castells, Rosie Jones, and Tetsuya Sakai (Eds.). ACM, 2405–2414.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3404835.3463245" title="">https://doi.org/10.1145/3404835.3463245</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Robin Anil, Gokhan Capan, Isabel Drost-Fromm, Ted Dunning, Ellen Friedman, Trevor Grant, Shannon Quinn, Paritosh Ranjan, Sebastian Schelter, and Özgür Yilmazel. 2020.

</span>
<span class="ltx_bibblock">Apache Mahout: machine learning on distributed dataflow systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">J. Mach. Learn. Res.</em> 21, 1, Article 127 (jan 2020), 6 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beel et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Joeran Beel, Lukas Wegmeth, and Tobias Vente. 2024.

</span>
<span class="ltx_bibblock">e-fold cross-validation: A computing and energy-efficient alternative to k-fold cross-validation with adaptive folds.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.31219/osf.io/exw3j" title="">https://doi.org/10.31219/osf.io/exw3j</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Budennyy et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Semen Andreevich Budennyy, Vladimir Dmitrievich Lazarev, Nikita Nikolaevich Zakharenko, Aleksei N Korovin, OA Plosskaya, Denis Valer’evich Dimitrov, VS Akhripkin, IV Pavlov, Ivan Valer’evich Oseledets, Ivan Segundovich Barsola, et al<span class="ltx_text" id="bib.bib7.3.1">.</span> 2022.

</span>
<span class="ltx_bibblock">Eco2ai: carbon emissions tracking of machine learning models as the first step towards sustainable ai. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.4.1">Doklady Mathematics</em>, Vol. 106. Springer, S118–S128.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cain et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Michelle Cain, John Lynch, Myles R. Allen, Jan S. Fuglestvedt, David J. Frame, and Adrian H Macey. 2019.

</span>
<span class="ltx_bibblock">Improved calculation of warming-equivalent emissions for short-lived climate pollutants.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">npj Climate and Atmospheric Science</em> 2, 1 (Sept. 2019).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/s41612-019-0086-4" title="">https://doi.org/10.1038/s41612-019-0086-4</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cantador et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Ivan Cantador, Peter Brusilovsky, and Tsvi Kuflik. 2011.

</span>
<span class="ltx_bibblock">Second Workshop on Information Heterogeneity and Fusion in Recommender Systems (HetRec2011). In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the Fifth ACM Conference on Recommender Systems</em> (Chicago, Illinois, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib9.4.2">(RecSys ’11)</em>. Association for Computing Machinery, New York, NY, USA, 387–388.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2043932.2044016" title="">https://doi.org/10.1145/2043932.2044016</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Capretto et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Tomás Capretto, Camen Piho, Ravin Kumar, Jacob Westfall, Tal Yarkoni, and Osvaldo A Martin. 2022.

</span>
<span class="ltx_bibblock">Bambi: A Simple Interface for Fitting Bayesian Linear Models in Python.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Journal of Statistical Software</em> 103, 15 (2022), 1–29.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18637/jss.v103.i15" title="">https://doi.org/10.18637/jss.v103.i15</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Chunlei Chen, Peng Zhang, Huixiang Zhang, Jiangyan Dai, Yugen Yi, Huihui Zhang, and Yonghui Zhang. 2020.

</span>
<span class="ltx_bibblock">Deep Learning on Computational-Resource-Limited Platforms: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Mobile Information Systems</em> 2020 (March 2020), 8454327.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1155/2020/8454327" title="">https://doi.org/10.1155/2020/8454327</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Huiyuan Chen, Xiaoting Li, Vivian Lai, Chin-Chia Michael Yeh, Yujie Fan, Yan Zheng, Mahashweta Das, and Hao Yang. 2023.

</span>
<span class="ltx_bibblock">Adversarial Collaborative Filtering for Free. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib12.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 245–255.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608771" title="">https://doi.org/10.1145/3604915.3608771</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Eunjoon Cho, Seth A. Myers, and Jure Leskovec. 2011.

</span>
<span class="ltx_bibblock">Friendship and Mobility: User Movement in Location-Based Social Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (San Diego, California, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib13.4.2">(KDD ’11)</em>. Association for Computing Machinery, New York, NY, USA, 1082–1090.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2020408.2020579" title="">https://doi.org/10.1145/2020408.2020579</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cook et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
John Cook, Naomi Oreskes, Peter T Doran, William R L Anderegg, Bart Verheggen, Ed W Maibach, J Stuart Carlton, Stephan Lewandowsky, Andrew G Skuce, Sarah A Green, Dana Nuccitelli, Peter Jacobs, Mark Richardson, B”arbel Winkler, Rob Painting, and Ken Rice. 2016.

</span>
<span class="ltx_bibblock">Consensus on consensus: a synthesis of consensus estimates on human-caused global warming.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Environmental Research Letters</em> 11, 4 (April 2016), 048002.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1088/1748-9326/11/4/048002" title="">https://doi.org/10.1088/1748-9326/11/4/048002</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Department for Business, Energy &amp; Industrial Strategy (2020)</span>
<span class="ltx_bibblock">
Department for Business, Energy &amp; Industrial Strategy. 2020.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Conversion Factors 2020 Methodology</em>.

</span>
<span class="ltx_bibblock">Technical Report. Government of the United Kingdom.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://assets.publishing.service.gov.uk/media/5f119b673a6f405c059f6060/conversion-factors-2020-methodology.pdf" title="">https://assets.publishing.service.gov.uk/media/5f119b673a6f405c059f6060/conversion-factors-2020-methodology.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekstrand (2020)</span>
<span class="ltx_bibblock">
Michael D. Ekstrand. 2020.

</span>
<span class="ltx_bibblock">LensKit for Python: Next-Generation Software for Recommender Systems Experiments. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em> (Virtual Event, Ireland) <em class="ltx_emph ltx_font_italic" id="bib.bib16.2.2">(CIKM ’20)</em>. Association for Computing Machinery, New York, NY, USA, 2999–3006.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3340531.3412778" title="">https://doi.org/10.1145/3340531.3412778</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ember and Institute (2024)</span>
<span class="ltx_bibblock">
Ember and Energy Institute. 2024.

</span>
<span class="ltx_bibblock">Carbon intensity of electricity generation – Ember and Energy Institute.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ourworldindata.org/grapher/carbon-intensity-electricity" title="">https://ourworldindata.org/grapher/carbon-intensity-electricity</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Yearly Electricity Data by Ember; Statistical Review of World Energy by Energy Institute. Dataset processed by Our World in Data.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Falk and Arngren (2023)</span>
<span class="ltx_bibblock">
Kim Falk and Morten Arngren. 2023.

</span>
<span class="ltx_bibblock">Recommenders In the wild - Practical Evaluation Methods. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib18.2.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 1.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3609498" title="">https://doi.org/10.1145/3604915.3609498</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Felfernig et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Alexander Felfernig, Manfred Wundara, Thi Ngoc Trang Tran, Seda Polat-Erdeniz, Sebastian Lubos, Merfat El Mansi, Damian Garber, and Viet Man Le. 2023.

</span>
<span class="ltx_bibblock">Recommender systems for sustainability: overview and research issues.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Frontiers in Big Data</em> 6 (30 Oct. 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3389/fdata.2023.1284511" title="">https://doi.org/10.3389/fdata.2023.1284511</a>
</span>
<span class="ltx_bibblock">Publisher Copyright: Copyright © 2023 Felfernig, Wundara, Tran, Polat-Erdeniz, Lubos, El Mansi, Garber and Le..

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gantner et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Zeno Gantner, Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2011.

</span>
<span class="ltx_bibblock">MyMediaLite: A Free Recommender System Library. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">5th ACM International Conference on Recommender Systems (RecSys 2011)</em> (Chicago, USA).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S. Lee, Gu-Yeon Wei, David Brooks, and Carole-Jean Wu. 2021.

</span>
<span class="ltx_bibblock">Chasing Carbon: The Elusive Environmental Footprint of Computing. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)</em>. 854–867.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/HPCA51647.2021.00076" title="">https://doi.org/10.1109/HPCA51647.2021.00076</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hansen et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
James Hansen, Pushker Kharecha, Makiko Sato, Valerie Masson-Delmotte, Frank Ackerman, David J Beerling, Paul J Hearty, Ove Hoegh-Guldberg, Shi-Ling Hsu, Camille Parmesan, et al<span class="ltx_text" id="bib.bib22.3.1">.</span> 2013.

</span>
<span class="ltx_bibblock">Assessing “dangerous climate change”: Required reduction of carbon emissions to protect young people, future generations and nature.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.4.1">PloS one</em> 8, 12 (2013), e81648.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harper and Konstan (2015)</span>
<span class="ltx_bibblock">
F. Maxwell Harper and Joseph A. Konstan. 2015.

</span>
<span class="ltx_bibblock">The MovieLens Datasets: History and Context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">ACM Trans. Interact. Intell. Syst.</em> 5, 4, Article 19 (dec 2015), 19 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2827872" title="">https://doi.org/10.1145/2827872</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Peter Henderson, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan Jurafsky, and Joelle Pineau. 2020.

</span>
<span class="ltx_bibblock">Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">Journal of Machine Learning Research</em> 21, 248 (2020), 1–43.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://jmlr.org/papers/v21/20-312.html" title="">http://jmlr.org/papers/v21/20-312.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Himeur et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Yassine Himeur, Abdullah Alsalemi, Ayman Al-Kababji, Faycal Bensaali, Abbes Amira, Christos Sardianos, George Dimitrakopoulos, and Iraklis Varlamis. 2021.

</span>
<span class="ltx_bibblock">A survey of recommender systems for energy efficiency in buildings: Principles, challenges and prospects.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Information Fusion</em> 72 (2021), 1–21.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.inffus.2021.02.002" title="">https://doi.org/10.1016/j.inffus.2021.02.002</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jay et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Mathilde Jay, Vladimir Ostapenco, Laurent Lefevre, Denis Trystram, Anne-Cécile Orgerie, and Benjamin Fichel. 2023.

</span>
<span class="ltx_bibblock">An experimental comparison of software-based power meters: focus on CPU and GPU. 106–118.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/CCGrid57682.2023.00020" title="">https://doi.org/10.1109/CCGrid57682.2023.00020</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kerem (2022)</span>
<span class="ltx_bibblock">
Alper Kerem. 2022.

</span>
<span class="ltx_bibblock">Investigation of carbon footprint effect of renewable power plants regarding energy production: A case study of a city in Turkey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Journal of the Air &amp; Waste Management Association</em> 72, 3 (2022), 294–307.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koomey et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Jonathan Koomey, Stephen Berard, Marla Sanchez, and Henry Wong. 2011.

</span>
<span class="ltx_bibblock">Implications of Historical Trends in the Electrical Efficiency of Computing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">IEEE Annals of the History of Computing</em> 33, 3 (2011), 46–54.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/MAHC.2010.28" title="">https://doi.org/10.1109/MAHC.2010.28</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kweku et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Darkwah Williams Kweku, Odum Bismark, Addae Maxwell, Koomson Ato Desmond, Kwakye Benjamin Danso, Ewurabena Asante Oti-Mensah, Asenso Theophilus Quachie, and Buanya Beryl Adormaa. 2018.

</span>
<span class="ltx_bibblock">Greenhouse effect: greenhouse gases and their impact on global warming.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Journal of Scientific research and reports</em> 17, 6 (2018), 1–9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lannelongue et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Loïc Lannelongue, Hans-Erik G. Aronson, Alex Bateman, Ewan Birney, Talia Caplan, Martin Juckes, Johanna McEntyre, Andrew D. Morris, Gerry Reilly, and Michael Inouye. 2023.

</span>
<span class="ltx_bibblock">GREENER principles for environmentally sustainable computational science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Nature Computational Science</em> 3, 6 (June 2023), 514–521.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/s43588-023-00461-y" title="">https://doi.org/10.1038/s43588-023-00461-y</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lannelongue et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Loïc Lannelongue, Jason Grealey, and Michael Inouye. 2021.

</span>
<span class="ltx_bibblock">Green Algorithms: Quantifying the Carbon Footprint of Computation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Advanced Science</em> 8, 12 (2021), 2100707.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1002/advs.202100707" title="">https://doi.org/10.1002/advs.202100707</a>
arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202100707

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lynas et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Mark Lynas, Benjamin Z Houlton, and Simon Perry. 2021.

</span>
<span class="ltx_bibblock">Greater than 99% consensus on human caused climate change in the peer-reviewed scientific literature.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Environmental Research Letters</em> 16, 11 (Oct. 2021), 114005.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1088/1748-9326/ac2966" title="">https://doi.org/10.1088/1748-9326/ac2966</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Haokai Ma, Ruobing Xie, Lei Meng, Xin Chen, Xu Zhang, Leyu Lin, and Jie Zhou. 2023.

</span>
<span class="ltx_bibblock">Exploring False Hard Negative Sample in Cross-Domain Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib33.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 502–514.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608791" title="">https://doi.org/10.1145/3604915.3608791</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masson-Delmotte and on Climate Change (2022)</span>
<span class="ltx_bibblock">
Valérie Masson-Delmotte and Intergovernmental Panel on Climate Change. 2022.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Global warming of 1.5°c : An IPCC Special Report on impacts of global warming of 1.5°c above pre-industrial levels and related global greenhouse gas emission pathways, in the contex of strengthening the global response to the thereat of blimate change, sustainable development, and efforts to eradicate poverty</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cir.nii.ac.jp/crid/1130574323982454028" title="">https://cir.nii.ac.jp/crid/1130574323982454028</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehta et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yukta Mehta, Rui Xu, Benjamin Lim, Jane Wu, and Jerry Gao. 2023.

</span>
<span class="ltx_bibblock">A Review for Green Energy Machine Learning and AI Services.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Energies</em> 16, 15 (2023), 5718.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Michiels et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Lien Michiels, Robin Verachtert, and Bart Goethals. 2022.

</span>
<span class="ltx_bibblock">RecPack: An(Other) Experimentation Toolkit for Top-N Recommendation Using Implicit Feedback Data. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">Proceedings of the 16th ACM Conference on Recommender Systems</em> (Seattle, WA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib36.4.2">(RecSys ’22)</em>. Association for Computing Machinery, New York, NY, USA, 648–651.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3551472" title="">https://doi.org/10.1145/3523227.3551472</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Minka et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
T. Minka, J.M. Winn, J.P. Guiver, Y. Zaykov, D. Fabian, and J. Bronskill. 2018.

</span>
<span class="ltx_bibblock">/Infer.NET 0.3.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Microsoft Research Cambridge. http://dotnet.github.io/infer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell (1989)</span>
<span class="ltx_bibblock">
John FB Mitchell. 1989.

</span>
<span class="ltx_bibblock">The “greenhouse” effect and climate change.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Reviews of Geophysics</em> 27, 1 (1989), 115–139.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mu (2018)</span>
<span class="ltx_bibblock">
Ruihui Mu. 2018.

</span>
<span class="ltx_bibblock">A Survey of Recommender Systems Based on Deep Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">IEEE Access</em> 6 (2018), 69009–69022.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2018.2880197" title="">https://doi.org/10.1109/ACCESS.2018.2880197</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019.

</span>
<span class="ltx_bibblock">Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>. Association for Computational Linguistics, Hong Kong, China, 188–197.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/D19-1018" title="">https://doi.org/10.18653/v1/D19-1018</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nukusheva et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Aigul Nukusheva, Gulzhazira Ilyassova, Dinara Rustembekova, Roza Zhamiyeva, and Leila Arenova. 2021.

</span>
<span class="ltx_bibblock">Global warming problem faced by the international community: international legal aspect.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">International Environmental Agreements: Politics, Law and Economics</em> 21 (2021), 219–233.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paul et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Showmick Guha Paul, Arpa Saha, Mohammad Shamsul Arefin, Touhid Bhuiyan, Al Amin Biswas, Ahmed Wasif Reza, Naif M. Alotaibi, Salem A. Alyami, and Mohammad Ali Moni. 2023.

</span>
<span class="ltx_bibblock">A Comprehensive Review of Green Computing: Past, Present, and Future Research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">IEEE Access</em> 11 (2023), 87445–87494.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2023.3304332" title="">https://doi.org/10.1109/ACCESS.2023.3304332</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pressburger et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Leeya D Pressburger, Meredydd Evans, Sha Yu, Yiyun Cui, Abhishek Somani, and Gokul C Iyer. 2022.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">A Comprehensive Economic Coal Transition in South Asia</em>.

</span>
<span class="ltx_bibblock">Technical Report. Pacific Northwest National Laboratory (PNNL), Richland, WA (United States).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ricke et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Katharine Ricke, Laurent Drouet, Ken Caldeira, and Massimo Tavoni. 2018.

</span>
<span class="ltx_bibblock">Country-level social cost of carbon.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Nature Climate Change</em> 8, 10 (Sept. 2018), 895–900.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/s41558-018-0282-y" title="">https://doi.org/10.1038/s41558-018-0282-y</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shehzad and Jannach (2023)</span>
<span class="ltx_bibblock">
Faisal Shehzad and Dietmar Jannach. 2023.

</span>
<span class="ltx_bibblock">Everyone’s a Winner! On Hyperparameter Tuning of Recommendation Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib45.2.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 652–657.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3609488" title="">https://doi.org/10.1145/3604915.3609488</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sinha and Chaturvedi (2019)</span>
<span class="ltx_bibblock">
Rakesh Kumar Sinha and Nitin Dutt Chaturvedi. 2019.

</span>
<span class="ltx_bibblock">A review on carbon emission reduction in industries and planning emission limits.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Renewable and Sustainable Energy Reviews</em> 114 (2019), 109304.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spillo et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Giuseppe Spillo, Allegra De Filippo, Cataldo Musto, Michela Milano, and Giovanni Semeraro. 2023.

</span>
<span class="ltx_bibblock">Towards Sustainability-aware Recommender Systems: Analyzing the Trade-off Between Algorithms Performance and Carbon Footprint. In <em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib47.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 856–862.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608840" title="">https://doi.org/10.1145/3604915.3608840</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strubell et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019.

</span>
<span class="ltx_bibblock">Energy and policy considerations for deep learning in NLP.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">arXiv preprint arXiv:1906.02243</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em> (Beijing, China) <em class="ltx_emph ltx_font_italic" id="bib.bib49.4.2">(CIKM ’19)</em>. Association for Computing Machinery, New York, NY, USA, 1441–1450.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3357384.3357895" title="">https://doi.org/10.1145/3357384.3357895</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Wynsberghe (2021)</span>
<span class="ltx_bibblock">
Aimee Van Wynsberghe. 2021.

</span>
<span class="ltx_bibblock">Sustainable AI: AI for sustainability and the sustainability of AI.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">AI and Ethics</em> 1, 3 (2021), 213–218.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vente et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tobias Vente, Michael Ekstrand, and Joeran Beel. 2023.

</span>
<span class="ltx_bibblock">Introducing lenskit-auto, an experimental automated recommender system (autorecsys) toolkit. In <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 1212–1216.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Chenyang Wang, Min Zhang, Weizhi Ma, Yiqun Liu, and Shaoping Ma. 2020.

</span>
<span class="ltx_bibblock">Make it a chorus: knowledge-and time-aware item modeling for sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 109–118.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wegmeth and Beel (2022)</span>
<span class="ltx_bibblock">
Lukas Wegmeth and Joeran Beel. 2022.

</span>
<span class="ltx_bibblock">CaMeLS: Cooperative meta-learning service for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Proceedings of the Perspectives on the Evaluation of Recommender Systems Workshop 2022</em>. CEUR-WS.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ceur-ws.org/Vol-3228/paper2.pdf" title="">https://ceur-ws.org/Vol-3228/paper2.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wegmeth et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Lukas Wegmeth, Tobias Vente, Lennart Purucker, and Joeran Beel. 2023.

</span>
<span class="ltx_bibblock">The Effect of Random Seeds for Data Splitting on Recommendation Accuracy. In <em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Proceedings of the 3rd Workshop Perspectives on the Evaluation of Recommender Systems 2023 co-located with the 17th ACM Conference on Recommender Systems (RecSys 2023), Singapore, Singapore, September 19, 2023</em> <em class="ltx_emph ltx_font_italic" id="bib.bib54.4.2">(CEUR Workshop Proceedings, Vol. 3476)</em>, Alan Said, Eva Zangerle, and Christine Bauer 0001 (Eds.). CEUR-WS.org.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ceur-ws.org/Vol-3476/paper4.pdf" title="">https://ceur-ws.org/Vol-3476/paper4.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, Hui Xiong, and Enhong Chen. 2023.

</span>
<span class="ltx_bibblock">A Survey on Large Language Models for Recommendation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2305.19860 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Lanling Xu, Zhen Tian, Gaowei Zhang, Junjie Zhang, Lei Wang, Bowen Zheng, Yifan Li, Jiakai Tang, Zeyu Zhang, Yupeng Hou, Xingyu Pan, Wayne Xin Zhao, Xu Chen, and Ji-Rong Wen. 2023b.

</span>
<span class="ltx_bibblock">Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">SIGIR</em>. ACM, 2837–2847.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Zitao Xu, Weike Pan, and Zhong Ming. 2023a.

</span>
<span class="ltx_bibblock">A Multi-view Graph Contrastive Learning Framework for Cross-Domain Sequential Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib57.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 491–501.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608785" title="">https://doi.org/10.1145/3604915.3608785</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoro and Daramola (2020)</span>
<span class="ltx_bibblock">
Kelvin O Yoro and Michael O Daramola. 2020.

</span>
<span class="ltx_bibblock">CO2 emission sources, greenhouse gases, and the global warming effect.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in carbon capture</em>. Elsevier, 3–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span class="ltx_text" id="bib.bib59.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Hsiang-Fu Yu, Cho-Jui Hsieh, Si Si, and Inderjit S. Dhillon. 2012.

</span>
<span class="ltx_bibblock">Scalable Coordinate Descent Approaches to Parallel Matrix Factorization for Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib59.3.1">IEEE International Conference of Data Mining</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al<span class="ltx_text" id="bib.bib60.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhenrui Yue, Zhankui He, Huimin Zeng, and Julian McAuley. 2021.

</span>
<span class="ltx_bibblock">Black-Box Attacks on Sequential Recommenders via Data-Free Model Extraction. In <em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">Proceedings of the 15th ACM Conference on Recommender Systems</em> (Amsterdam, Netherlands) <em class="ltx_emph ltx_font_italic" id="bib.bib60.4.2">(RecSys ’21)</em>. Association for Computing Machinery, New York, NY, USA, 44–54.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3460231.3474275" title="">https://doi.org/10.1145/3460231.3474275</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhenrui Yue, Huimin Zeng, Ziyi Kou, Lanyu Shang, and Dong Wang. 2022.

</span>
<span class="ltx_bibblock">Defending Substitution-Based Profile Pollution Attacks on Sequential Recommenders. In <em class="ltx_emph ltx_font_italic" id="bib.bib61.3.1">Proceedings of the 16th ACM Conference on Recommender Systems</em> (Seattle, WA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib61.4.2">(RecSys ’22)</em>. Association for Computing Machinery, New York, NY, USA, 59–70.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3546770" title="">https://doi.org/10.1145/3523227.3546770</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019.

</span>
<span class="ltx_bibblock">Deep Learning Based Recommender System: A Survey and New Perspectives.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">ACM Comput. Surv.</em> 52, 1, Article 5 (feb 2019), 38 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3285029" title="">https://doi.org/10.1145/3285029</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al<span class="ltx_text" id="bib.bib63.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jin Zhong, Math Bollen, and Sarah Rönnberg. 2021.

</span>
<span class="ltx_bibblock">Towards a 100% renewable energy electricity generation system in Sweden.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.3.1">Renewable Energy</em> 171 (2021), 812–824.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.renene.2021.02.153" title="">https://doi.org/10.1016/j.renene.2021.02.153</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span class="ltx_text" id="bib.bib64.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Kun Zhou, Xiaolei Wang, Yuanhang Zhou, Chenzhan Shang, Yuan Cheng, Wayne Xin Zhao, Yaliang Li, and Ji-Rong Wen. 2021.

</span>
<span class="ltx_bibblock">CRSLab: An Open-Source Toolkit for Building Conversational Recommender System. In <em class="ltx_emph ltx_font_italic" id="bib.bib64.3.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</em>, Heng Ji, Jong C. Park, and Rui Xia (Eds.). Association for Computational Linguistics, Online, 185–193.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2021.acl-demo.22" title="">https://doi.org/10.18653/v1/2021.acl-demo.22</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span class="ltx_text" id="bib.bib65.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
You Zhou, Xiujing Lin, Xiang Zhang, Maolin Wang, Gangwei Jiang, Huakang Lu, Yupeng Wu, Kai Zhang, Zhe Yang, Kehang Wang, Yongduo Sui, Fengwei Jia, Zuoli Tang, Yao Zhao, Hongxuan Zhang, Tiannuo Yang, Weibo Chen, Yunong Mao, Yi Li, De Bao, Yu Li, Hongrui Liao, Ting Liu, Jingwen Liu, Jinchi Guo, Xiangyu Zhao, Ying WEI, Hong Qian, Qi Liu, Xiang Wang, Wai Kin, Chan, Chenliang Li, Yusen Li,
Shiyu Yang, Jining Yan, Chao Mou, Shuai Han, Wuxia Jin, Guannan Zhang, and Xiaodong Zeng. 2023.

</span>
<span class="ltx_bibblock">On the Opportunities of Green Computing: A Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2311.00447" title="">https://doi.org/10.48550/ARXIV.2311.00447</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span class="ltx_text" id="bib.bib66.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jieming Zhu, Quanyu Dai, Liangcai Su, Rong Ma, Jinyang Liu, Guohao Cai, Xi Xiao, and Rui Zhang. 2022.

</span>
<span class="ltx_bibblock">BARS: Towards Open Benchmarking for Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib66.3.1">SIGIR ’22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022</em>, Enrique Amigó, Pablo Castells, Julio Gonzalo, Ben Carterette, J. Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 2912–2923.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3477495.3531723" title="">https://doi.org/10.1145/3477495.3531723</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span class="ltx_text" id="bib.bib67.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiajie Zhu, Yan Wang, Feng Zhu, and Zhu Sun. 2023.

</span>
<span class="ltx_bibblock">Domain Disentanglement with Interpolative Data Augmentation for Dual-Target Cross-Domain Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib67.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib67.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 515–527.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608802" title="">https://doi.org/10.1145/3604915.3608802</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Aug 22 10:09:42 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
