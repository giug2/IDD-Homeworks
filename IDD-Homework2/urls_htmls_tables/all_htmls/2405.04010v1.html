<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Explainability-Informed Targeted Malware Misclassification</title>
<!--Generated on Tue May  7 05:04:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Explainability,  Adversarial,  Dynamic Analysis,  Online Analysis,  White-box attacks,  Machine learning,  Robust,  Trustworthy
" lang="en" name="keywords"/>
<base href="/html/2405.04010v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S1" title="In Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S2" title="In Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3" title="In Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.SS1" title="In III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Dynamic Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.SS2" title="In III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Online Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.SS3" title="In III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Adversarial Approach</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4" title="In Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Results and Discussion</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.SS1" title="In IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Evaluation of Performance Metrics for classifier models</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.SS2" title="In IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Global Explanation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.SS3" title="In IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Targeted Misclassification</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S5" title="In Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Conclusion and Future Work</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Explainability-Informed Targeted 
<br class="ltx_break"/>Malware Misclassification</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Quincy Card, Kshitiz Aryal, Maanak Gupta
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id1.1.id1">Department of Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id2.2.id2">Tennessee Tech University,</span>
Cookeville, TN USA
<br class="ltx_break"/>qacard42@tntech.edu, karyal42@tntech.edu, mgupta@tntech.edu
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">In recent years, there has been a surge in malware attacks across critical infrastructures, requiring further research and development of appropriate response and remediation strategies in malware detection and classification. Several works have used machine learning models for malware classification into categories, and deep neural networks have shown promising results. However, these models have shown its vulnerabilities against intentionally crafted adversarial attacks, which yields misclassification of a malicious file. Our paper explores such adversarial vulnerabilities of neural network based malware classification system in the dynamic and online analysis environments. To evaluate our approach, we trained Feed Forward Neural Networks (FFNN) to classify malware categories based on features obtained from dynamic and online analysis environments. We use the state-of-the-art method, SHapley Additive exPlanations (SHAP), for the feature attribution for malware classification, to inform the adversarial attackers about the features with significant importance on classification decision. Using the explainability-informed features, we perform targeted misclassification adversarial white-box evasion attacks using the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks against the trained classifier. Our results demonstrated high evasion rate for some instances of attacks, showing a clear vulnerability of a malware classifier for such attacks. We offer recommendations for a balanced approach and a benchmark for much-needed future research into evasion attacks against malware classifiers, and develop more robust and trustworthy solutions.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Explainability, Adversarial, Dynamic Analysis, Online Analysis, White-box attacks, Machine learning, Robust, Trustworthy

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Malware poses a significant cybersecurity threat, demanding an effective classification system for swift remediation. The process of addressing malware that has invaded a computer system broadly involves detecting it, classifying it, and then addressing the malware based on this classification. Detection refers to identifying the presence or absence of malware. Detection problems are sometimes referred to as binary classifications. This study distinguishes detection from classification, which aims to discern between various types of malware samples. Classification categorizes malware into families or categories, with “family” referring to variants that share common characteristics, and “category” grouping malware based on their objectives (e.g., ransomware encrypting systems or files).</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Different types of malware necessitate tailored response plans, with adware requiring different treatment from trojans or ransomware. Machine learning-based classification methods have emerged to address this need <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib1" title="">1</a>]</cite>. These methods are broadly categorized into static <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib2" title="">2</a>]</cite>, dynamic <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib3" title="">3</a>]</cite>, and online analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib4" title="">4</a>]</cite>. Static analysis inspects dormant malicious files but is susceptible to obfuscation. Dynamic analysis executes malware in a controlled, simulated environment, while online analysis monitors systems in real time, preventing malware from detecting it is in a sandbox and remaining dormant. However, conducting online analysis can be resource-intensive, especially in preventing malware from accessing the internet in online environments.
Despite the importance of accurate malware classification, researchers often overlook the vulnerability of models to adversarial examples crafted to deceive trained models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib11" title="">11</a>]</cite>. Addressing this vulnerability is crucial for ensuring the reliability and robustness of classification systems, particularly in dynamic and online malware analysis where research is limited.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Explainable AI methods focus on feature attribution, elucidating model decisions and enhancing user trust. These explanations play a vital role in identifying crucial features for malware classification, empowering security analysts in countering threats. However, they can also inform the generation of adversarial evasion attacks as well <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib12" title="">12</a>]</cite>. By indicating which features are important to model decision-making, an adversary is able to create adversarial samples that are more effective at fooling the classifier into misclassification, thereby intentionally evading proper classification.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">White-box and black-box evasion attacks represent two distinct approaches to crafting adversarial examples to deceive machine learning models. In a white-box attack, the attacker has full access to the target model’s architecture, parameters, and training data, enabling them to directly manipulate the model’s input features to generate adversarial examples. Conversely, black-box attacks occur when the attacker has limited or no access to the target model’s internal structure or training data. In such cases, the attacker interacts with the model by querying it with inputs and observing the corresponding outputs. Despite their differences, both types of attacks aim to exploit vulnerabilities in machine learning models to undermine their performance and reliability.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S1.T1.21.2.1" style="font-size:90%;">TABLE I</span>: </span><span class="ltx_text" id="S1.T1.2.1" style="font-size:90%;">Related works compared. A <math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.2.1.m1.1"><semantics id="S1.T1.2.1.m1.1b"><mo id="S1.T1.2.1.m1.1.1" xref="S1.T1.2.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.2.1.m1.1c"><csymbol cd="latexml" id="S1.T1.2.1.m1.1.1.cmml" xref="S1.T1.2.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.1.m1.1d">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.2.1.m1.1e">√</annotation></semantics></math> indicates that a specific paper has this attribute, and a blank cell shows that this attribute or model does not exist.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S1.T1.19" style="width:754.7pt;height:148pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S1.T1.19.17"><span class="ltx_text" id="S1.T1.19.17.17">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.19.17.17.17">
<span class="ltx_tbody">
<span class="ltx_tr" id="S1.T1.19.17.17.17.18.1">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S1.T1.19.17.17.17.18.1.1"><span class="ltx_text" id="S1.T1.19.17.17.17.18.1.1.1">Paper</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S1.T1.19.17.17.17.18.1.2"><span class="ltx_text" id="S1.T1.19.17.17.17.18.1.2.1">Target Model</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3" id="S1.T1.19.17.17.17.18.1.3">Analysis</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2" id="S1.T1.19.17.17.17.18.1.4">Domain</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2" id="S1.T1.19.17.17.17.18.1.5">Platform</span></span>
<span class="ltx_tr" id="S1.T1.19.17.17.17.19.2">
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.19.2.1">Detection</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.19.2.2">Category Classification</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.19.2.3">Family Classification</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.19.2.4">Dynamic</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.19.2.5">Online</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.19.2.6">Android</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.19.2.7">Windows</span></span>
<span class="ltx_tr" id="S1.T1.5.3.3.3.3">
<span class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.5.3.3.3.3.4">Stokes et al. (2018) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib13" title="">13</a>]</cite></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.5.3.3.3.3.5">FFNN</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.1.1.1.1.1"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.3.1.1.1.1.1.m1.1"><semantics id="S1.T1.3.1.1.1.1.1.m1.1a"><mo id="S1.T1.3.1.1.1.1.1.m1.1.1" xref="S1.T1.3.1.1.1.1.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.3.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S1.T1.3.1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.3.1.1.1.1.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.3.1.1.1.1.1.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.3.1.1.1.1.1.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.5.3.3.3.3.6"></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.5.3.3.3.3.7"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.4.2.2.2.2.2"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.4.2.2.2.2.2.m1.1"><semantics id="S1.T1.4.2.2.2.2.2.m1.1a"><mo id="S1.T1.4.2.2.2.2.2.m1.1.1" xref="S1.T1.4.2.2.2.2.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.4.2.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S1.T1.4.2.2.2.2.2.m1.1.1.cmml" xref="S1.T1.4.2.2.2.2.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.4.2.2.2.2.2.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.4.2.2.2.2.2.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.5.3.3.3.3.8"></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.5.3.3.3.3.9"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.5.3.3.3.3.3"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.5.3.3.3.3.3.m1.1"><semantics id="S1.T1.5.3.3.3.3.3.m1.1a"><mo id="S1.T1.5.3.3.3.3.3.m1.1.1" xref="S1.T1.5.3.3.3.3.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.5.3.3.3.3.3.m1.1b"><csymbol cd="latexml" id="S1.T1.5.3.3.3.3.3.m1.1.1.cmml" xref="S1.T1.5.3.3.3.3.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.5.3.3.3.3.3.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.5.3.3.3.3.3.m1.1d">√</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S1.T1.8.6.6.6.6">
<span class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.8.6.6.6.6.4">Kucuk et al. (2020) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib14" title="">14</a>]</cite></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.8.6.6.6.6.5">Random Forest</span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.8.6.6.6.6.6"></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.8.6.6.6.6.7"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.6.4.4.4.4.1"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.6.4.4.4.4.1.m1.1"><semantics id="S1.T1.6.4.4.4.4.1.m1.1a"><mo id="S1.T1.6.4.4.4.4.1.m1.1.1" xref="S1.T1.6.4.4.4.4.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.6.4.4.4.4.1.m1.1b"><csymbol cd="latexml" id="S1.T1.6.4.4.4.4.1.m1.1.1.cmml" xref="S1.T1.6.4.4.4.4.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.6.4.4.4.4.1.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.6.4.4.4.4.1.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.7.5.5.5.5.2"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.7.5.5.5.5.2.m1.1"><semantics id="S1.T1.7.5.5.5.5.2.m1.1a"><mo id="S1.T1.7.5.5.5.5.2.m1.1.1" xref="S1.T1.7.5.5.5.5.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.7.5.5.5.5.2.m1.1b"><csymbol cd="latexml" id="S1.T1.7.5.5.5.5.2.m1.1.1.cmml" xref="S1.T1.7.5.5.5.5.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.7.5.5.5.5.2.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.7.5.5.5.5.2.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.8.6.6.6.6.8"></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.8.6.6.6.6.9"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.8.6.6.6.6.3"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.8.6.6.6.6.3.m1.1"><semantics id="S1.T1.8.6.6.6.6.3.m1.1a"><mo id="S1.T1.8.6.6.6.6.3.m1.1.1" xref="S1.T1.8.6.6.6.6.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.8.6.6.6.6.3.m1.1b"><csymbol cd="latexml" id="S1.T1.8.6.6.6.6.3.m1.1.1.cmml" xref="S1.T1.8.6.6.6.6.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.8.6.6.6.6.3.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.8.6.6.6.6.3.m1.1d">√</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S1.T1.11.9.9.9.9">
<span class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.11.9.9.9.9.4">Ahmed et al. (2022) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib15" title="">15</a>]</cite></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.11.9.9.9.9.5">Ensemble</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.9.7.7.7.7.1"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.9.7.7.7.7.1.m1.1"><semantics id="S1.T1.9.7.7.7.7.1.m1.1a"><mo id="S1.T1.9.7.7.7.7.1.m1.1.1" xref="S1.T1.9.7.7.7.7.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.9.7.7.7.7.1.m1.1b"><csymbol cd="latexml" id="S1.T1.9.7.7.7.7.1.m1.1.1.cmml" xref="S1.T1.9.7.7.7.7.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.9.7.7.7.7.1.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.9.7.7.7.7.1.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.11.9.9.9.9.6"></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.11.9.9.9.9.7"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.10.8.8.8.8.2"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.10.8.8.8.8.2.m1.1"><semantics id="S1.T1.10.8.8.8.8.2.m1.1a"><mo id="S1.T1.10.8.8.8.8.2.m1.1.1" xref="S1.T1.10.8.8.8.8.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.10.8.8.8.8.2.m1.1b"><csymbol cd="latexml" id="S1.T1.10.8.8.8.8.2.m1.1.1.cmml" xref="S1.T1.10.8.8.8.8.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.10.8.8.8.8.2.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.10.8.8.8.8.2.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.11.9.9.9.9.8"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.11.9.9.9.9.3"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.11.9.9.9.9.3.m1.1"><semantics id="S1.T1.11.9.9.9.9.3.m1.1a"><mo id="S1.T1.11.9.9.9.9.3.m1.1.1" xref="S1.T1.11.9.9.9.9.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.11.9.9.9.9.3.m1.1b"><csymbol cd="latexml" id="S1.T1.11.9.9.9.9.3.m1.1.1.cmml" xref="S1.T1.11.9.9.9.9.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.11.9.9.9.9.3.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.11.9.9.9.9.3.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.11.9.9.9.9.9"></span></span>
<span class="ltx_tr" id="S1.T1.14.12.12.12.12">
<span class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.14.12.12.12.12.4">Rafiq et al. (2023) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib16" title="">16</a>]</cite></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.14.12.12.12.12.5">AutoML</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.12.10.10.10.10.1"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.12.10.10.10.10.1.m1.1"><semantics id="S1.T1.12.10.10.10.10.1.m1.1a"><mo id="S1.T1.12.10.10.10.10.1.m1.1.1" xref="S1.T1.12.10.10.10.10.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.12.10.10.10.10.1.m1.1b"><csymbol cd="latexml" id="S1.T1.12.10.10.10.10.1.m1.1.1.cmml" xref="S1.T1.12.10.10.10.10.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.12.10.10.10.10.1.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.12.10.10.10.10.1.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.14.12.12.12.12.6"></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.14.12.12.12.12.7"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.13.11.11.11.11.2"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.13.11.11.11.11.2.m1.1"><semantics id="S1.T1.13.11.11.11.11.2.m1.1a"><mo id="S1.T1.13.11.11.11.11.2.m1.1.1" xref="S1.T1.13.11.11.11.11.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.13.11.11.11.11.2.m1.1b"><csymbol cd="latexml" id="S1.T1.13.11.11.11.11.2.m1.1.1.cmml" xref="S1.T1.13.11.11.11.11.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.13.11.11.11.11.2.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.13.11.11.11.11.2.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.14.12.12.12.12.8"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.14.12.12.12.12.3"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.14.12.12.12.12.3.m1.1"><semantics id="S1.T1.14.12.12.12.12.3.m1.1a"><mo id="S1.T1.14.12.12.12.12.3.m1.1.1" xref="S1.T1.14.12.12.12.12.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.14.12.12.12.12.3.m1.1b"><csymbol cd="latexml" id="S1.T1.14.12.12.12.12.3.m1.1.1.cmml" xref="S1.T1.14.12.12.12.12.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.14.12.12.12.12.3.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.14.12.12.12.12.3.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_r ltx_border_t" id="S1.T1.14.12.12.12.12.9"></span></span>
<span class="ltx_tr" id="S1.T1.19.17.17.17.17">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.17.6"><span class="ltx_text ltx_font_bold" id="S1.T1.19.17.17.17.17.6.1">Our Approach</span></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.17.7">FFNN</span>
<span class="ltx_td ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.17.8"></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.15.13.13.13.13.1"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.15.13.13.13.13.1.m1.1"><semantics id="S1.T1.15.13.13.13.13.1.m1.1a"><mo id="S1.T1.15.13.13.13.13.1.m1.1.1" xref="S1.T1.15.13.13.13.13.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.15.13.13.13.13.1.m1.1b"><csymbol cd="latexml" id="S1.T1.15.13.13.13.13.1.m1.1.1.cmml" xref="S1.T1.15.13.13.13.13.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.15.13.13.13.13.1.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.15.13.13.13.13.1.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.17.9"></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.16.14.14.14.14.2"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.16.14.14.14.14.2.m1.1"><semantics id="S1.T1.16.14.14.14.14.2.m1.1a"><mo id="S1.T1.16.14.14.14.14.2.m1.1.1" xref="S1.T1.16.14.14.14.14.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.16.14.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S1.T1.16.14.14.14.14.2.m1.1.1.cmml" xref="S1.T1.16.14.14.14.14.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.16.14.14.14.14.2.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.16.14.14.14.14.2.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.17.15.15.15.15.3"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.17.15.15.15.15.3.m1.1"><semantics id="S1.T1.17.15.15.15.15.3.m1.1a"><mo id="S1.T1.17.15.15.15.15.3.m1.1.1" xref="S1.T1.17.15.15.15.15.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.17.15.15.15.15.3.m1.1b"><csymbol cd="latexml" id="S1.T1.17.15.15.15.15.3.m1.1.1.cmml" xref="S1.T1.17.15.15.15.15.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.17.15.15.15.15.3.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.17.15.15.15.15.3.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.18.16.16.16.16.4"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.18.16.16.16.16.4.m1.1"><semantics id="S1.T1.18.16.16.16.16.4.m1.1a"><mo id="S1.T1.18.16.16.16.16.4.m1.1.1" xref="S1.T1.18.16.16.16.16.4.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.18.16.16.16.16.4.m1.1b"><csymbol cd="latexml" id="S1.T1.18.16.16.16.16.4.m1.1.1.cmml" xref="S1.T1.18.16.16.16.16.4.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.18.16.16.16.16.4.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.18.16.16.16.16.4.m1.1d">√</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.19.17.17.17.17.5"><math alttext="\surd" class="ltx_Math" display="inline" id="S1.T1.19.17.17.17.17.5.m1.1"><semantics id="S1.T1.19.17.17.17.17.5.m1.1a"><mo id="S1.T1.19.17.17.17.17.5.m1.1.1" xref="S1.T1.19.17.17.17.17.5.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S1.T1.19.17.17.17.17.5.m1.1b"><csymbol cd="latexml" id="S1.T1.19.17.17.17.17.5.m1.1.1.cmml" xref="S1.T1.19.17.17.17.17.5.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.19.17.17.17.17.5.m1.1c">\surd</annotation><annotation encoding="application/x-llamapun" id="S1.T1.19.17.17.17.17.5.m1.1d">√</annotation></semantics></math></span></span>
</span>
</span></span></p>
</span></div>
</figure>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This paper utilizes SHapley Additive exPlanations (SHAP) to interpret black-box model decisions, informing targeted malware misclassification attacks. A Feed Forward Neural Network (FFNN) based malware classifier is trained for both dynamic and online malware datasets, with <span class="ltx_text ltx_font_italic" id="S1.p5.1.1">DeepSHAP</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib17" title="">17</a>]</cite> providing global interpretations. These explanations informed the white-box Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks where we selected the Ransomware and Adware classes as our targets for the dynamic analysis and the Ransomware and PUA classes for the online analysis. In some instances of our attacks, we observed almost perfect evasion from the malware classifier, highlighting a clear vulnerability in this deep-learning model.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The main contributions of this work include:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We evaluate the effectiveness of deep learning models for classifying malware categories in both dynamic and an online malware analysis data set.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We extend this analysis by explaining model predictions on a global level using SHapley Additive exPlanations (SHAP).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We use these SHAP explanations to inform white-box evasion attacks on the deep learning models for targeted misclassification.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p6.2">The paper is organized as follows. Section <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S2" title="II Related Work ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">II</span></a> reviews related works in evasion attacks conducted in the sphere of dynamic analysis. Section <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3" title="III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">III</span></a> outlines the methodology and introduces the dynamic and online datasets. Results, model explanations, and evasion attacks for each dataset are presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4" title="IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">IV</span></a>. The paper concludes with a summary and discussion of future work in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S5" title="V Conclusion and Future Work ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The field of adversarial attacks in dynamic malware analysis is relatively new in academia, with limited prior research available. Existing studies primarily focus on targeted misclassification, which involves deliberately choosing incorrect labels and crafting adversarial examples to deceive classifiers into classifying them as such. This is not the same as untargeted misclassifications, where adversarial examples are crafted to cause models to misclassify input without aiming at specific classes with the aim of decreasing accuracy and trust in a model’s ability to classify correctly. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S1.T1" title="TABLE I ‣ I Introduction ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">I</span></a> summarizes relevant work, outlining features such as the domain, type of analysis, targeted models, and malware platform.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib13" title="">13</a>]</cite> utilized the Jacobian method to inform targeted misclassification attacks on an FFNN model detecting Windows malware. Similarly, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib15" title="">15</a>]</cite> conducted evasion attacks on an ensemble model detecting Android ransomware, employing information gain to guide the attacks. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib16" title="">16</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib14" title="">14</a>]</cite> also explored evasion attacks on machine learning models detecting Android malware and Windows malware families, respectively, with the latter being one of the few to delve into targeted misclassification using a Random Forest model.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Notably, none of the mentioned works specifically address targeted misclassification on deep-learning classifier models for dynamic or online malware categories, highlighting a gap in the literature that our work aims to fill. We propose using black-box models to classify malware categories in dynamic and online datasets, followed by using the SHAP explainability method to guide adversarial attacks and deceive the model into misclassifying samples as targeted categories.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methodology</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Our methodology can be divided into three major parts: 1) Data collection for online and dynamic malware analysis; 2) Training the malware classifier for each dataset; and 3) Targeted adversarial attacks on the trained malware classifiers. This section discusses our methodology for training our dynamic analysis, online analysis classifier model, and approach to adversarial attacks for targeted misclassification.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Dynamic Analysis</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For the dynamic malware analysis, we utilized the AndMal2020 dataset from the Canadian Center for Cybersecurity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib18" title="">18</a>]</cite>, containing 12 different Android malware classes. Each sample comprises 141 features across six categories: <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">memory</span>,<span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2"> API calls</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.3">network</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.4">battery</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.5">log writing</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.6">total processes</span>. The class distribution in this dynamic malware dataset is highly imbalanced, as seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.T2" title="TABLE II ‣ III-A Dynamic Analysis ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">II</span></a>. We attempted to address this imbalance by excluding minority classes and adjusting class weights; however, the SMOTE (Synthetic Minority Oversampling Technique) proved effective as it balanced the dataset by generating synthetic samples between real examples.
This resulted in 7261 samples per class, totalling 87132 samples. To train the classifier on this dynamic analysis dataset, we employed an FFNN, aiming for simplicity and establishing a baseline for future evasion attacks. The FFNN architecture included six hidden layers, two fully connected layers, and one dropout layer. The training was conducted on 80% of the dataset for 135 epochs with a batch size of 10 while using the remaining 20% for testing and validation.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.2.1.1" style="font-size:90%;">TABLE II</span>: </span><span class="ltx_text" id="S3.T2.3.2" style="font-size:90%;">All Classes of Dynamic Data Set</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.1.1">Category</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T2.4.1.1.2">Number of Samples</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.4.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.2.1.1">Riskware</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.2.1.2">7261</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.3.2.1">Adware</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.3.2.2">5838</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.4.3.1">Trojan</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.4.3.2">4412</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.5.4.1">Ransomware</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.5.4.2">1861</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.6.5.1">Trojan_Spy</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.6.5.2">1801</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.7.6.1">Trojan_SMS</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.7.6.2">1028</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.8.7.1">Trojan_Dropper</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.8.7.2">837</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.9.8.1">PUA</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.9.8.2">665</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.10.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.10.9.1">Backdoor</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.10.9.2">591</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.11.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.11.10.1">Scareware</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.11.10.2">462</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.12.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.12.11.1">FileInfector</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.4.12.11.2">129</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.13.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.13.12.1">Trojan_Banker</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.4.13.12.2">118</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Online Analysis</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">For online analysis, we utilized the RaDaR dataset from the Indian Institute Technology Madras <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib19" title="">19</a>]</cite>, capturing Windows malware behavior on a real-time physical testbed. This dataset enables analysis of modern malware that is capable of detecting sandbox environments and remaining dormant. However, this level of analysis requires significant resources compared to dynamic analysis, with increased computation times due to larger data volumes. This dataset comprises five malware classes and 55 hardware-level features. To address the class imbalance evident in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.T3" title="TABLE III ‣ III-B Online Analysis ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">III</span></a>, SMOTE was employed, resulting in 158158 samples per class, totalling 790790 samples. While we initially considered Long Short-Term Memory (LSTM) models for their time-series data advantages, we opted for FFNNs to maintain consistency across analyses. The FFNN architecture included five hidden layers with <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">ReLU</span> activation, two fully connected layers, one dropout layer, and <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.2">Softmax</span> activation for the output layer. Training utilized 80% of the data for 100 epochs with a batch size of 50, with testing on the remaining 20%.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T3.2.1.1" style="font-size:90%;">TABLE III</span>: </span><span class="ltx_text" id="S3.T3.3.2" style="font-size:90%;">All Classes of Online Data Set</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.1.1.1">Category</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T3.4.1.1.2">Number of Snapshots</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.4.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.2.1.1">Cryptominer</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.2.1.2">158158</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.3.2.1">Deceptor</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.3.2.2">99099</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.4.3.1">Ransomware</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.4.3.2">13013</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.5.4.1">PUA</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.5.4.2">3003</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.6.5.1">Backdoor</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.4.6.5.2">1001</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.4.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">Adversarial Approach</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">For targeted adversarial attacks on the trained classifiers, we chose the Fast Gradient Sign Method (FGSM) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib20" title="">20</a>]</cite> and Projected Gradient Descent (PGD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib21" title="">21</a>]</cite> attacks, both white-box attacks requiring knowledge of the target model architecture. These attacks were conducted as benchmarks for future research in dynamic and online malware classification, addressing the lack of existing work in targeted misclassification of black-box classified dynamic and online malware samples. Our attacks aim to generate adversarial examples that are misclassified as specific malware categories to assess the robustness of the models for classifying a particular malware class.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">To inform the attacks, we first needed to have SHAP identify which features were important to model decision-making. As opposed to the related works that focused on targeting a transparent model, our work targeted a black-box model that needs post-hoc explanations to identify which features would be most effective in perturbing. We used SHAP’s <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.1">DeepExplainer</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#bib.bib17" title="">17</a>]</cite> to compute the SHAP values we used to inform the attacks. We used a subsample of 1000 samples from the dynamic test data set and 10000 samples from the online test data set. This under-sampling is necessary due to the resource-intensive nature of computing SHAP values balanced with the need to create effective adversarial examples. Our work thus properly balances the level of analysis achieved from the online analysis with the more resource-efficient dynamic analysis.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.2">We performed a grid search to find the optimal set of hyperparameters for our misclassification attack. For adversarial evasion attacks in dynamic analysis, optimal hyperparameters for FGSM included an epsilon (<math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_ϵ</annotation></semantics></math>) of <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.1">1.0</span> and a step size of <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.2">0.8</span> with the <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.3">L2 norm</span> bound on the perturbation. At the same time, optimal hyperparameters for PGD were an epsilon (<math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">italic_ϵ</annotation></semantics></math>) of <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.4">1.0</span>, step size of<span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.5"> 0.8</span>, and maximum iterations of <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.6">50</span> with the <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.7">L-Infinity norm</span> bound for perturbation. In online analysis, optimal FGSM parameters were epsilon <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.8">1.0</span> and step size <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.9">0.5</span> with the<span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.10"> L2 norm</span> bound, while optimal PGD parameters were epsilon <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.11">1.0</span>, step size <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.12">0.5</span>, and maximum iterations <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.13">50</span> with the <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.2.14">L-infinity norm</span> bound. The evaluation focused on the success rate of attacks, indicating the ratio of successfully misclassified examples to total generated examples. Our methodology for generating adversarial examples and assessing their success is outlined in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#alg1" title="In III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_float ltx_algorithm" id="alg1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="alg1.6">
<div class="ltx_listingline" id="alg1.6.7">
</div>
<div class="ltx_listingline" id="alg1.4.4">
<span class="ltx_text ltx_font_bold" id="alg1.4.4.1">Input :</span> Classifier model <math alttext="C" class="ltx_Math" display="inline" id="alg1.1.1.m1.1"><semantics id="alg1.1.1.m1.1a"><mi id="alg1.1.1.m1.1.1" xref="alg1.1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.1.1.m1.1b"><ci id="alg1.1.1.m1.1.1.cmml" xref="alg1.1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="alg1.1.1.m1.1d">italic_C</annotation></semantics></math>, test malware data <math alttext="X" class="ltx_Math" display="inline" id="alg1.2.2.m2.1"><semantics id="alg1.2.2.m2.1a"><mi id="alg1.2.2.m2.1.1" xref="alg1.2.2.m2.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="alg1.2.2.m2.1b"><ci id="alg1.2.2.m2.1.1.cmml" xref="alg1.2.2.m2.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.2.m2.1c">X</annotation><annotation encoding="application/x-llamapun" id="alg1.2.2.m2.1d">italic_X</annotation></semantics></math>, number of features to perturb <math alttext="num\_features" class="ltx_Math" display="inline" id="alg1.3.3.m3.1"><semantics id="alg1.3.3.m3.1a"><mrow id="alg1.3.3.m3.1.1" xref="alg1.3.3.m3.1.1.cmml"><mi id="alg1.3.3.m3.1.1.2" xref="alg1.3.3.m3.1.1.2.cmml">n</mi><mo id="alg1.3.3.m3.1.1.1" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.3" xref="alg1.3.3.m3.1.1.3.cmml">u</mi><mo id="alg1.3.3.m3.1.1.1a" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.4" xref="alg1.3.3.m3.1.1.4.cmml">m</mi><mo id="alg1.3.3.m3.1.1.1b" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.5" mathvariant="normal" xref="alg1.3.3.m3.1.1.5.cmml">_</mi><mo id="alg1.3.3.m3.1.1.1c" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.6" xref="alg1.3.3.m3.1.1.6.cmml">f</mi><mo id="alg1.3.3.m3.1.1.1d" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.7" xref="alg1.3.3.m3.1.1.7.cmml">e</mi><mo id="alg1.3.3.m3.1.1.1e" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.8" xref="alg1.3.3.m3.1.1.8.cmml">a</mi><mo id="alg1.3.3.m3.1.1.1f" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.9" xref="alg1.3.3.m3.1.1.9.cmml">t</mi><mo id="alg1.3.3.m3.1.1.1g" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.10" xref="alg1.3.3.m3.1.1.10.cmml">u</mi><mo id="alg1.3.3.m3.1.1.1h" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.11" xref="alg1.3.3.m3.1.1.11.cmml">r</mi><mo id="alg1.3.3.m3.1.1.1i" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.12" xref="alg1.3.3.m3.1.1.12.cmml">e</mi><mo id="alg1.3.3.m3.1.1.1j" xref="alg1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="alg1.3.3.m3.1.1.13" xref="alg1.3.3.m3.1.1.13.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.3.3.m3.1b"><apply id="alg1.3.3.m3.1.1.cmml" xref="alg1.3.3.m3.1.1"><times id="alg1.3.3.m3.1.1.1.cmml" xref="alg1.3.3.m3.1.1.1"></times><ci id="alg1.3.3.m3.1.1.2.cmml" xref="alg1.3.3.m3.1.1.2">𝑛</ci><ci id="alg1.3.3.m3.1.1.3.cmml" xref="alg1.3.3.m3.1.1.3">𝑢</ci><ci id="alg1.3.3.m3.1.1.4.cmml" xref="alg1.3.3.m3.1.1.4">𝑚</ci><ci id="alg1.3.3.m3.1.1.5.cmml" xref="alg1.3.3.m3.1.1.5">_</ci><ci id="alg1.3.3.m3.1.1.6.cmml" xref="alg1.3.3.m3.1.1.6">𝑓</ci><ci id="alg1.3.3.m3.1.1.7.cmml" xref="alg1.3.3.m3.1.1.7">𝑒</ci><ci id="alg1.3.3.m3.1.1.8.cmml" xref="alg1.3.3.m3.1.1.8">𝑎</ci><ci id="alg1.3.3.m3.1.1.9.cmml" xref="alg1.3.3.m3.1.1.9">𝑡</ci><ci id="alg1.3.3.m3.1.1.10.cmml" xref="alg1.3.3.m3.1.1.10">𝑢</ci><ci id="alg1.3.3.m3.1.1.11.cmml" xref="alg1.3.3.m3.1.1.11">𝑟</ci><ci id="alg1.3.3.m3.1.1.12.cmml" xref="alg1.3.3.m3.1.1.12">𝑒</ci><ci id="alg1.3.3.m3.1.1.13.cmml" xref="alg1.3.3.m3.1.1.13">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.3.m3.1c">num\_features</annotation><annotation encoding="application/x-llamapun" id="alg1.3.3.m3.1d">italic_n italic_u italic_m _ italic_f italic_e italic_a italic_t italic_u italic_r italic_e italic_s</annotation></semantics></math>, SHAP values <math alttext="shap\_values" class="ltx_Math" display="inline" id="alg1.4.4.m4.1"><semantics id="alg1.4.4.m4.1a"><mrow id="alg1.4.4.m4.1.1" xref="alg1.4.4.m4.1.1.cmml"><mi id="alg1.4.4.m4.1.1.2" xref="alg1.4.4.m4.1.1.2.cmml">s</mi><mo id="alg1.4.4.m4.1.1.1" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.3" xref="alg1.4.4.m4.1.1.3.cmml">h</mi><mo id="alg1.4.4.m4.1.1.1a" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.4" xref="alg1.4.4.m4.1.1.4.cmml">a</mi><mo id="alg1.4.4.m4.1.1.1b" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.5" xref="alg1.4.4.m4.1.1.5.cmml">p</mi><mo id="alg1.4.4.m4.1.1.1c" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.6" mathvariant="normal" xref="alg1.4.4.m4.1.1.6.cmml">_</mi><mo id="alg1.4.4.m4.1.1.1d" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.7" xref="alg1.4.4.m4.1.1.7.cmml">v</mi><mo id="alg1.4.4.m4.1.1.1e" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.8" xref="alg1.4.4.m4.1.1.8.cmml">a</mi><mo id="alg1.4.4.m4.1.1.1f" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.9" xref="alg1.4.4.m4.1.1.9.cmml">l</mi><mo id="alg1.4.4.m4.1.1.1g" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.10" xref="alg1.4.4.m4.1.1.10.cmml">u</mi><mo id="alg1.4.4.m4.1.1.1h" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.11" xref="alg1.4.4.m4.1.1.11.cmml">e</mi><mo id="alg1.4.4.m4.1.1.1i" xref="alg1.4.4.m4.1.1.1.cmml">⁢</mo><mi id="alg1.4.4.m4.1.1.12" xref="alg1.4.4.m4.1.1.12.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.4.4.m4.1b"><apply id="alg1.4.4.m4.1.1.cmml" xref="alg1.4.4.m4.1.1"><times id="alg1.4.4.m4.1.1.1.cmml" xref="alg1.4.4.m4.1.1.1"></times><ci id="alg1.4.4.m4.1.1.2.cmml" xref="alg1.4.4.m4.1.1.2">𝑠</ci><ci id="alg1.4.4.m4.1.1.3.cmml" xref="alg1.4.4.m4.1.1.3">ℎ</ci><ci id="alg1.4.4.m4.1.1.4.cmml" xref="alg1.4.4.m4.1.1.4">𝑎</ci><ci id="alg1.4.4.m4.1.1.5.cmml" xref="alg1.4.4.m4.1.1.5">𝑝</ci><ci id="alg1.4.4.m4.1.1.6.cmml" xref="alg1.4.4.m4.1.1.6">_</ci><ci id="alg1.4.4.m4.1.1.7.cmml" xref="alg1.4.4.m4.1.1.7">𝑣</ci><ci id="alg1.4.4.m4.1.1.8.cmml" xref="alg1.4.4.m4.1.1.8">𝑎</ci><ci id="alg1.4.4.m4.1.1.9.cmml" xref="alg1.4.4.m4.1.1.9">𝑙</ci><ci id="alg1.4.4.m4.1.1.10.cmml" xref="alg1.4.4.m4.1.1.10">𝑢</ci><ci id="alg1.4.4.m4.1.1.11.cmml" xref="alg1.4.4.m4.1.1.11">𝑒</ci><ci id="alg1.4.4.m4.1.1.12.cmml" xref="alg1.4.4.m4.1.1.12">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.4.m4.1c">shap\_values</annotation><annotation encoding="application/x-llamapun" id="alg1.4.4.m4.1d">italic_s italic_h italic_a italic_p _ italic_v italic_a italic_l italic_u italic_e italic_s</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.6.8">
<span class="ltx_text ltx_font_bold" id="alg1.6.8.1">Output :</span> Attack success rate for FGSM and PGD
</div>
<div class="ltx_listingline" id="alg1.6.9">
</div>
<div class="ltx_listingline" id="alg1.5.5">
<span class="ltx_text ltx_font_bold" id="alg1.5.5.1">1.</span> Wrap the Classifier model <math alttext="C" class="ltx_Math" display="inline" id="alg1.5.5.m1.1"><semantics id="alg1.5.5.m1.1a"><mi id="alg1.5.5.m1.1.1" xref="alg1.5.5.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.5.5.m1.1b"><ci id="alg1.5.5.m1.1.1.cmml" xref="alg1.5.5.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.5.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="alg1.5.5.m1.1d">italic_C</annotation></semantics></math> with an ART estimator;
</div>
<div class="ltx_listingline" id="alg1.6.10">
<span class="ltx_text ltx_font_bold" id="alg1.6.10.1">2.</span> Configure attack parameters for targeted misclassification;
</div>
<div class="ltx_listingline" id="alg1.6.11">
<span class="ltx_text ltx_font_bold" id="alg1.6.11.1">3.</span> Specify the target class for each adversarial example;
</div>
<div class="ltx_listingline" id="alg1.6.6">
<span class="ltx_text ltx_font_bold" id="alg1.6.6.1">4.</span> Identify the most important features from <math alttext="shap\_values" class="ltx_Math" display="inline" id="alg1.6.6.m1.1"><semantics id="alg1.6.6.m1.1a"><mrow id="alg1.6.6.m1.1.1" xref="alg1.6.6.m1.1.1.cmml"><mi id="alg1.6.6.m1.1.1.2" xref="alg1.6.6.m1.1.1.2.cmml">s</mi><mo id="alg1.6.6.m1.1.1.1" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.3" xref="alg1.6.6.m1.1.1.3.cmml">h</mi><mo id="alg1.6.6.m1.1.1.1a" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.4" xref="alg1.6.6.m1.1.1.4.cmml">a</mi><mo id="alg1.6.6.m1.1.1.1b" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.5" xref="alg1.6.6.m1.1.1.5.cmml">p</mi><mo id="alg1.6.6.m1.1.1.1c" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.6" mathvariant="normal" xref="alg1.6.6.m1.1.1.6.cmml">_</mi><mo id="alg1.6.6.m1.1.1.1d" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.7" xref="alg1.6.6.m1.1.1.7.cmml">v</mi><mo id="alg1.6.6.m1.1.1.1e" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.8" xref="alg1.6.6.m1.1.1.8.cmml">a</mi><mo id="alg1.6.6.m1.1.1.1f" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.9" xref="alg1.6.6.m1.1.1.9.cmml">l</mi><mo id="alg1.6.6.m1.1.1.1g" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.10" xref="alg1.6.6.m1.1.1.10.cmml">u</mi><mo id="alg1.6.6.m1.1.1.1h" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.11" xref="alg1.6.6.m1.1.1.11.cmml">e</mi><mo id="alg1.6.6.m1.1.1.1i" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.12" xref="alg1.6.6.m1.1.1.12.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.6.6.m1.1b"><apply id="alg1.6.6.m1.1.1.cmml" xref="alg1.6.6.m1.1.1"><times id="alg1.6.6.m1.1.1.1.cmml" xref="alg1.6.6.m1.1.1.1"></times><ci id="alg1.6.6.m1.1.1.2.cmml" xref="alg1.6.6.m1.1.1.2">𝑠</ci><ci id="alg1.6.6.m1.1.1.3.cmml" xref="alg1.6.6.m1.1.1.3">ℎ</ci><ci id="alg1.6.6.m1.1.1.4.cmml" xref="alg1.6.6.m1.1.1.4">𝑎</ci><ci id="alg1.6.6.m1.1.1.5.cmml" xref="alg1.6.6.m1.1.1.5">𝑝</ci><ci id="alg1.6.6.m1.1.1.6.cmml" xref="alg1.6.6.m1.1.1.6">_</ci><ci id="alg1.6.6.m1.1.1.7.cmml" xref="alg1.6.6.m1.1.1.7">𝑣</ci><ci id="alg1.6.6.m1.1.1.8.cmml" xref="alg1.6.6.m1.1.1.8">𝑎</ci><ci id="alg1.6.6.m1.1.1.9.cmml" xref="alg1.6.6.m1.1.1.9">𝑙</ci><ci id="alg1.6.6.m1.1.1.10.cmml" xref="alg1.6.6.m1.1.1.10">𝑢</ci><ci id="alg1.6.6.m1.1.1.11.cmml" xref="alg1.6.6.m1.1.1.11">𝑒</ci><ci id="alg1.6.6.m1.1.1.12.cmml" xref="alg1.6.6.m1.1.1.12">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.6.m1.1c">shap\_values</annotation><annotation encoding="application/x-llamapun" id="alg1.6.6.m1.1d">italic_s italic_h italic_a italic_p _ italic_v italic_a italic_l italic_u italic_e italic_s</annotation></semantics></math>;
</div>
<div class="ltx_listingline" id="alg1.6.12">
<span class="ltx_text ltx_font_bold" id="alg1.6.12.1">5.</span> Generate adversarial examples using FGSM and PGD;
</div>
<div class="ltx_listingline" id="alg1.6.13">
<span class="ltx_text ltx_font_bold" id="alg1.6.13.1">6.</span> Evaluate the classifier on adversarial examples;
</div>
<div class="ltx_listingline" id="alg1.6.14">
<span class="ltx_text ltx_font_bold" id="alg1.6.14.1">7.</span> Calculate success rates of evasion for FGSM and PGD;
</div>
<div class="ltx_listingline" id="alg1.6.15">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.8.1.1">Algorithm 1</span> </span>Algorithm for Adversarial Attack</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="352" id="S3.F1.sf1.g1" src="x1.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="266" id="S3.F1.sf2.g1" src="x2.png" width="332"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S3.F1.3.2" style="font-size:90%;">Performance of models in Dynamic and Online Analysis</span></figcaption>
</figure>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T4.2.1.1" style="font-size:90%;">TABLE IV</span>: </span><span class="ltx_text" id="S3.T4.3.2" style="font-size:90%;">Performance Metrics for Dynamic Analysis and Class-Specific Metrics</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T4.4" style="width:368.3pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S3.T4.4.1"><span class="ltx_text" id="S3.T4.4.1.1">
<span class="ltx_tabular ltx_align_middle" id="S3.T4.4.1.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="S3.T4.4.1.1.1.1.1">
<span class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.1.1.1"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.1.1.2">Accuracy (%)</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.1.1.3">Precision (%)</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.1.1.4">Recall (%)</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.1.1.5">F1 (%)</span></span>
<span class="ltx_tr" id="S3.T4.4.1.1.1.2.2">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.2.2.1">FFNN without SMOTE</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.2.2.2">81.52</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.2.2.3">81.63</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.2.2.4">81.52</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.2.2.5">81.58</span></span>
<span class="ltx_tr" id="S3.T4.4.1.1.1.3.3">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.3.3.1">FFNN with SMOTE</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.3.3.2">91.01</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.3.3.3">91.06</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.3.3.4">91.01</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.3.3.5">91.03</span></span>
<span class="ltx_tr" id="S3.T4.4.1.1.1.4.4">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.4.4.1">Ransomware with Smote</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.4.4.2">86.09</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.4.4.3">82.84</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.4.4.4">86.09</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.4.4.5">84.43</span></span>
<span class="ltx_tr" id="S3.T4.4.1.1.1.5.5">
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.5.5.1">Adware with Smote</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.5.5.2">83.61</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.5.5.3">80.61</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.5.5.4">83.61</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.4.1.1.1.5.5.5">82.08</span></span>
</span>
</span></span></p>
</span></div>
</figure>
<figure class="ltx_table" id="S3.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T5.2.1.1" style="font-size:90%;">TABLE V</span>: </span><span class="ltx_text" id="S3.T5.3.2" style="font-size:90%;">Performance Metrics for Online Analysis and Class-Specific Metrics</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T5.4" style="width:368.3pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S3.T5.4.1"><span class="ltx_text" id="S3.T5.4.1.1">
<span class="ltx_tabular ltx_align_middle" id="S3.T5.4.1.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="S3.T5.4.1.1.1.1.1">
<span class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.1.1.1"></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.1.1.2">Accuracy (%)</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.1.1.3">Precision (%)</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.1.1.4">Recall (%)</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.1.1.5">F1 (%)</span></span>
<span class="ltx_tr" id="S3.T5.4.1.1.1.2.2">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.2.2.1">FFNN without SMOTE</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.2.2.2">77.59</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.2.2.3">78.37</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.2.2.4">77.59</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.2.2.5">77.98</span></span>
<span class="ltx_tr" id="S3.T5.4.1.1.1.3.3">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.3.3.1">FFNN with SMOTE</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.3.3.2">78.55</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.3.3.3">79.94</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.3.3.4">78.55</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.3.3.5">79.24</span></span>
<span class="ltx_tr" id="S3.T5.4.1.1.1.4.4">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.4.4.1">Ransomware with Smote</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.4.4.2">92.88</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.4.4.3">100.00</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.4.4.4">92.88</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.4.4.5">96.31</span></span>
<span class="ltx_tr" id="S3.T5.4.1.1.1.5.5">
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.5.5.1">PUA with Smote</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.5.5.2">84.07</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.5.5.3">100.00</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.5.5.4">84.07</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T5.4.1.1.1.5.5.5">91.35</span></span>
</span>
</span></span></p>
</span></div>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Results and Discussion</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Evaluation of Performance Metrics for classifier models</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The first part of our work is to train the classifier models on dynamic and online datasets. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.T4" title="TABLE IV ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">IV</span></a> provides performance metrics for overall model performance in dynamic analysis and for our target classes for attack: Ransomware and Adware. The comparison with and without SMOTE intervention indicates a notable performance increase with synthetic samples. The F1-score close to 91% for overall performance in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.T4" title="TABLE IV ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">IV</span></a> proves FFNN works well for all our scenarios. Despite Ransomware being a top majority class in the unaltered dataset, its relatively poor performance suggests potential overlap between SMOTE’s synthetic samples for minority classes and the decision boundary of majority classes, but we have concluded that using SMOTE is still viable due to the increased overall classifier performance.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Performance metrics for overall model performance for the online analysis before and after SMOTE intervention can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.T5" title="TABLE V ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">V</span></a>. Ransomware and PUA are our target classes for attacks, and the classifier’s performance in classifying these two classes is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.T5" title="TABLE V ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">V</span></a>. The FFNN model had an F1 score of 79.24%. This was likely because of not maintaining the time-series nature of the data and because of SMOTE’s synthetic samples, as evidenced by the majority classes being outperformed by the minority classes in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.F1" title="Figure 1 ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">1</span></a>. A marginal increase in performance is observed when using SMOTE. This decision to use SMOTE was motivated by the desire to maintain consistency with the methodology employed for dynamic analysis. Consequently, both the model and the dataset influenced by SMOTE were utilized for the generation of explanations and adversarial examples. This decision also aligns with how real-world professionals may choose to manage the imbalanced class distribution. After training the model, we explained the model’s predictions by applying SHAP.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="494" id="S4.F2.sf1.g1" src="x3.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="494" id="S4.F2.sf2.g1" src="x4.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">A stacked bar graph depicting the top 20 online features identified by SHAP in model decision making</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="247" id="S4.F3.sf1.g1" src="x5.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="237" id="S4.F3.sf2.g1" src="x6.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">Success rates for FGSM and PGD attacks in targeting dynamic Adware and Ransomware categories</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="359" id="S4.F4.sf1.g1" src="x7.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="354" id="S4.F4.sf2.g1" src="x8.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.3.2" style="font-size:90%;">Confusion matrices for FGSM and PGD attacks in targeting dynamic Adware</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="359" id="S4.F5.sf1.g1" src="x9.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="359" id="S4.F5.sf2.g1" src="x10.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.3.2" style="font-size:90%;">Confusion matrices for FGSM and PGD attacks in targeting dynamic Ransomware</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="248" id="S4.F6.sf1.g1" src="x11.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="237" id="S4.F6.sf2.g1" src="x12.png" width="415"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S4.F6.3.2" style="font-size:90%;">Success rates for FGSM and PGD attacks in targeting online PUA and Ransomware categories</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="265" id="S4.F7.sf1.g1" src="x13.png" width="332"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="265" id="S4.F7.sf2.g1" src="x14.png" width="332"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S4.F7.3.2" style="font-size:90%;">Confusion matrices for FGSM and PGD attacks in targeting online PUA</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="265" id="S4.F8.sf1.g1" src="x15.png" width="332"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="265" id="S4.F8.sf2.g1" src="x16.png" width="332"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S4.F8.3.2" style="font-size:90%;">Confusion matrices for FGSM and PGD attacks in targeting online Ransomware</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Global Explanation</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">With a reduced sample size, SHAP’s <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.1">DeepExplainer</span> computed SHAP values in 70 seconds the dynamic data set and about 15 minutes for the online data set. The summary plots in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F2" title="Figure 2 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">2</span></a> illustrate feature importance across categories for both data sets. The x-axis shows the average magnitude impact on model output, with features arranged by their effects’ magnitudes. Notably, the top features for the model trained on the dynamic data set were mostly API calls or Memory features, emphasizing their significance. We used the top 20 identified features for each respective data set to inform the targeted evasion attacks. We selected the Adware and Ransomware categories for the dynamic analysis and the PUA and Ransomware categories for the online analysis because they pose the highest potential damage if an adversary successfully misclassifies their malware. Misclassification as a less or more dangerous category than a sample’s ground truth could significantly undermine the effectiveness of the remediation plan.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.4.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.5.2">Targeted Misclassification</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">For the dynamic analysis, Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F3" title="Figure 3 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">3</span></a> shows the rate of adversarial examples that were successfully able to fool the classifier. On targeting Adware, the PGD attack reached an acceptable success rate at just 9 out of 141 features, while the success rate of the FGSM attack peaked at around 40% at 17 features being perturbed. For targeting Ransomware, the PGD attack required all 20 features to be perturbed to reach a success rate of 80%, while the FGSM attack peaked at just above 30% and then degraded in performance drastically, making this category comparatively worse at being targeted than Adware since it took more features for PGD and the FGSM’s peak success rate was less. When comparing the attacks just targeting the Ransomware class, the FGSM attack vastly under-performs compared to the PGD attack, and Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F5" title="Figure 5 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">5</span></a> shows that this may be because it’s targeting the incorrect class. For an untargeted misclassification problem, these results would still be promising as the model’s ability to correctly classify any samples has greatly decreased, as seen in how the expected darker colouring of the diagonal in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.F1" title="Figure 1 ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">1</span></a> is not present at all, indicating the classifier’s decreased ability to correctly predict a sample’s true label. This work, however, is concerned with successful targeting of a selected class. The more complex, iterative PGD attack is capable of targeted misclassification, as Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F5" title="Figure 5 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">5</span></a> shows a distinct, vertical line on the ”predicted Ransomware” column. There’s a less dark vertical line on the ”predicted Trojan_Spy” column, making this the reason why the the PGD attack targeting Ransomware had a poorer performance than the PGD attack targeting the Adware.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Similar to the attacks targeting the Ransomware category, the PGD attack when targeting the Adware class is much more effective than the FGSM attack, with Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F4" title="Figure 4 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">4</span></a> revealing this is also due to an error in targeting the incorrect class. The ”predicted Adware” column shows that this FGSM attack is somewhat working, but it is not overwhelmingly effective like the PGD attack. We hypothesize that if more features were selected to be perturbed the PGD attack targeting Ransomware could at some point reach a comparable success rate as the one targeting Adware, as seen in the general upward trend of the success rate. However, we believe perturbing any more than 20 features could affect the malware’s ability to function. Future work should investigate this.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">For the online analysis, Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F6" title="Figure 6 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">6</span></a> shows the rate of adversarial examples that were successfully able to fool the classifier. Similar to the dynamic analysis, for both targeted misclassifications, the more complex iterative PGD attack was more effective in creating examples that fooled the classifier than the simpler FGSM attack. Unlike the dynamic analysis, the success rate fluctuates in a more volatile fashion for the first few features. For targeting both selected categories, the PGD attack reached an acceptable success rate around 16 out of 55 features, with the FGSM attack doing better in successfully targeting Ransomware over PUA. Figures <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F7" title="Figure 7 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">7</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S4.F8" title="Figure 8 ‣ IV-A Evaluation of Performance Metrics for classifier models ‣ IV Results and Discussion ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">8</span></a> show the confusion matrices generated by the attacks for the feature amount that resulted in the highest success rate, revealing that for both the PUA and the Ransomware targeted attacks using FGSM the adversarial examples seem to be properly targeting the respective categories, but it’s not as effective as the PGD attacks. These FGSM attacks would be effective in untargeted misclassification as these Figures show the diagonal from Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.F1" title="Figure 1 ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">1</span></a> has been disrupted. It should be noted that the PGD attacks show a lot of misclassification of samples as other classes. Perhaps this is due to inefficiencies within the classifier, as seen how there were so many samples in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.04010v1#S3.F1" title="Figure 1 ‣ III-C Adversarial Approach ‣ III Methodology ‣ Explainability-Informed Targeted Malware Misclassification"><span class="ltx_text ltx_ref_tag">1</span></a> were already misclassified.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">Comparing the two levels of analysis, we have concluded that it is easier to create successful and properly effective targeted misclassification attacks for the dynamic model that did well, than it is for the online model which had trouble properly categorizing the malware from the beginning. The success rates for the attacks on the dynamic model were consistently less volatile than the attacks on the online model. These effective attacks were also the result of using considerably less samples to train the attacks for the dynamic model than what was necessary for the online model. The attacks on the online model were more successful in producing untargeted misclassification. This is noteworthy and should be investigated further.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Conclusion and Future Work</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we trained an FFNN malware classifier model for a dynamic and online analysis data set to classify malware categories. The imbalanced class distribution of dynamic dataset was partially overcome with the use of SMOTE, which slightly degraded model performance but not to an unacceptable degree. Future authors can also extend this work by investigating models that are adept at handling time-series data, explaining those models with methods more well-suited to time-series data, and investigating the performance of these models on different data sets. We used SHAP to explain these black-box models and then used those explanations to inform targeted misclassification white-box evasion attacks. We performed evasion attacks by targeting 3 different malware classes in particular: Ransomware, Adware and PUA, while using FGSM and PGD as algorithms for crafting attacks. We compared the performance of models on performing attacks different malware classes using the different number of features informed by SHAP. Our results showed the success rate of targeted misclassification attack is close to 100% in some of the attack instances, demonstrating the serious vulnerability of the classifier model.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In future research, we will extend this work by launching black-box attacks to generate adversarial examples, and map the changes made to the features to an actual malware. Future work should also investigate the possibility and use cases of untargeted misclassification, since the FGSM attacks we devised for this work were so effective in degrading model performance. Our findings can also contribute to creating more robust models through adversarial training, which would enhance real-world malware remediation, aiding cyber-analysts and strategists in efficiently categorizing and coordinating responses to malware threats.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work was supported by the NSF Scholarship for Service Program Award 2043324 and 2230609.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S. Tobiyama, Y. Yamaguchi, H. Shimada, T. Ikuse, and T. Yagi, “Malware detection with deep neural network using process behavior,” in <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)</em>, vol. 2, 2016, pp. 577–582.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Rahali and et al., “Didroid: Android malware classification and characterization using deep image learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">10th International Conference on Communication and Network Security (ICCNS2020)</em>, Tokyo, Japan, November 2020, pp. 70–82.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
D. S. Keyes, B. Li, G. Kaur, A. H. Lashkari <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">et al.</em>, “Entroplyzer: Android malware classification and characterization using entropy analysis of dynamic characteristics,” in <em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2">2021 Reconciling Data Analytics, Automation, Privacy, and Security: A Big Data Challenge (RDAAPS)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. C. Kimmell, M. Abdelsalam, and M. Gupta, “Analyzing machine learning approaches for online malware detection in cloud,” in <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">IEEE conference on smart computing (SMARTCOMP)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
L. Demetrio and et al., “Explaining vulnerabilities of deep learning to adversarial malware binaries,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:1901.03583</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
——, “Efficient black-box optimization of adversarial windows malware with constrained manipulations,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2003.13526</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Khormali and et al., “Copycat: practical adversarial attacks on visualization-based malware detection,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:1909.09735</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Yuste, E. G. Pardo, and J. Tapiador, “Optimization of code caves in malware binaries to evade machine learning detectors,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Computers &amp; Security</em>, vol. 116, p. 102643, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
K. Aryal, M. Gupta, and M. Abdelsalam, “Exploiting windows pe structure for adversarial malware evasion attacks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the Thirteenth ACM Conference on Data and Application Security and Privacy</em>, 2023, pp. 279–281.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
K. Aryal, M. Gupta, M. Abdelsalam, and M. Saleh, “Intra-section code cave injection for adversarial evasion attacks on windows pe malware file,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2403.06428</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K. Aryal, M. Gupta, and M. Abdelsalam, “A survey on adversarial attacks for malware analysis,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2111.08223</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. Demetrio, B. Biggio, G. Lagorio, F. Roli, and A. Armando, “Explaining vulnerabilities of deep learning to adversarial malware binaries,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:1901.03583</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. W. Stokes and et al., “Attack and defense of dynamic analysis-based, adversarial neural malware detection models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM)</em>, 2018, pp. 1–8.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Y. Kucuk and G. Yan, “Deceiving portable executable malware classifiers into targeted misclassification with practical adversarial examples,” in <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the tenth ACM conference on data and application security and privacy</em>, 2020, pp. 341–352.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
U. Ahmed, J. C.-W. Lin, and G. Srivastava, “Mitigating adversarial evasion attacks of ransomware using ensemble learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Computers and Electrical Engineering</em>, vol. 100, p. 107903, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
H. Rafiq and et al., “Mitigating malicious adversaries evasion attacks in industrial internet of things,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">IEEE Transactions on Industrial Informatics</em>, vol. 19, no. 1, pp. 960–968, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
S. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model predictions,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Advances in Neural Information Processing Systems</em>, vol. 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
C. C. for Cyber Security. (2020) CCCS-CIC-AndMal2020. [Online]. Available: https://www.unb.ca/cic/datasets/andmal2020.html

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
S. Karapoola, N. Singh, C. Rebeiro, and K. V., “Radar: A real-world dataset for ai powered run-time detection of cyber-attacks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</em>, 2022, pp. 3222–3232.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards deep learning models resistant to adversarial attacks,” 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue May  7 05:04:03 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
