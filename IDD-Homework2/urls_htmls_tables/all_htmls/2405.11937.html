<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation</title>
<!--Generated on Mon May 20 10:18:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2405.11937v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S1" title="In Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S2" title="In Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S2.SS0.SSS0.Px1" title="In 2 Related Work ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title">MBR and QE reranking with neural metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S2.SS0.SSS0.Px2" title="In 2 Related Work ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title">Model self-improvement</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S3" title="In Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiment Overview</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S3.SS1" title="In 3 Experiment Overview ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Model Self-Improvement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S3.SS2" title="In 3 Experiment Overview ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>English–German</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S3.SS3" title="In 3 Experiment Overview ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Czech–Ukrainian</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S3.SS4" title="In 3 Experiment Overview ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>English–Hausa</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S3.SS5" title="In 3 Experiment Overview ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Iterative MBR Self-Improvement</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4" title="In Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS1" title="In 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Data Filtering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS2" title="In 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Vocabulary</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS3" title="In 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Baseline Model Hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS4" title="In 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Evaluation metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS5" title="In 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>English to German</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS6" title="In 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>Czech to Ukrainian</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS7" title="In 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7 </span>English to Hausa</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5" title="In Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.SS1" title="In 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Number of translation samples and search algorithm</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.SS2" title="In 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>English to German</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.SS3" title="In 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Czech to Ukrainian</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.SS4" title="In 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>English to Hausa</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S6" title="In Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kamil Guttmann<sup class="ltx_sup ltx_markedasmath" id="id7.7.id1">* 1</sup>, Mikołaj Pokrywka<sup class="ltx_sup ltx_markedasmath" id="id8.8.id2">* 1</sup>, Adrian Charkiewicz<sup class="ltx_sup ltx_markedasmath" id="id9.9.id3">1</sup>, Artur Nowakowski <sup class="ltx_sup ltx_markedasmath" id="id10.10.id4">1,2</sup>
<br class="ltx_break"/><sup class="ltx_sup ltx_markedasmath" id="id11.11.id5">1</sup> Laniqo, Poznań, Poland 
<br class="ltx_break"/><sup class="ltx_sup ltx_markedasmath" id="id12.12.id6">2</sup> Faculty of Mathematics and Computer Science, Adam Mickiewicz University, Poznań, Poland 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id13.13.id7">{name}.{surname}@laniqo.com</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id14.id1">This paper explores Minimum Bayes Risk (MBR) decoding for self-improvement in machine translation (MT), particularly for domain adaptation and low-resource languages. We implement the self-improvement process by fine-tuning the model on its MBR-decoded forward translations. By employing COMET as the MBR utility metric, we aim to achieve the reranking of translations that better aligns with human preferences. The paper explores the iterative application of this approach and the potential need for language-specific MBR utility metrics. The results demonstrate significant enhancements in translation quality for all examined language pairs, including successful application to domain-adapted models and generalisation to low-resource settings. This highlights the potential of COMET-guided MBR for efficient MT self-improvement in various scenarios.</p>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>Equal contribution</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Machine translation (MT) bridges the gap between languages, fostering global communication and information exchange. However, achieving high-quality translations across diverse languages and domains remains a significant challenge, especially for low-resource languages where limited training data hinders model performance. Even in well-resourced settings, continuous improvement and adaptation to specific domains are ongoing research efforts.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">This paper explores the potential of Minimum Bayes Risk (MBR) decoding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx19" title="">Kumar and Byrne (2004</a>]</cite> as a self-improvement strategy for MT models. MBR decoding leverages the model’s predictions to select the best translation from a set of candidates, potentially improving overall translation quality.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We employ COMET <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx27" title="">Rei et al. (2020</a>]</cite> as the utility function in MBR decoding and rerank candidate translations generated by an MT model. This approach creates a synthetic parallel dataset from monolingual data in the source language, enabling further model self-improvement.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This study examines the effectiveness of MBR decoding for self-improvement in three language pairs: English–German (high-resource), Czech–Ukrainian (low-resource), and English–Hausa (low-resource). For English–German, the focus is on the biomedical domain, incorporating additional monolingual data, while for Czech–Ukrainian, self-improvement is explored using only the training data translated by the model and reranked through MBR decoding. We further investigate the potential of iterative self-improvement with MBR decoding in both English–German and Czech–Ukrainian language pairs. Finally, in the case of English–Hausa, we compare the use of COMET, a massively multilingual metric, with a metric specifically tailored to African languages i.e. AfriCOMET <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx37" title="">Wang et al. (2023</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To determine the optimal configuration for MBR decoding, we investigate two decoding algorithms and various numbers of translation candidates.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">MBR and QE reranking with neural metrics</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">MBR decoding, a technique commonly used in Statistical Machine Translation (SMT), has gained traction in Neural Machine Translation (NMT) in recent years.
<span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.1.1">?</span>) proposed using reference-based metrics, such as BLEURT  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx31" title="">Sellam et al. (2020a</a>]</cite> and Quality Estimation (QE) models, such as COMET-QE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx28" title="">Rei et al. (2021</a>]</cite> for reranking the set of hypotheses produced by the NMT model.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">Similar work by <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p2.1.1">?</span>) proposed <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p2.1.2">quality-aware decoding</span>. They explored various reranking strategies, including the well-performing pre-ranking of the set of hypotheses with QE models before passing them into MBR decoding. They found that using MERT-tuned <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx23" title="">Och (2003</a>]</cite> reranker, where multiple QE metrics and model log-likelihood scores are linearly combined with learned weights to maximize a reference-based metric on a validation set shows improvements over the baseline.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p3.1.1">?</span>) used MBR decoding to identify biases and weaknesses in COMET, where they found that the early COMET models are not sufficiently sensitive to discrepancies in numbers and named entities.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p4.1">MBR decoding performance is heavily dependent on the number of samples and the sampling strategy.
<span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p4.1.1">?</span>) investigated various sampling strategies and found that epsilon sampling outperformed others. This sampling method discards tokens with a probability below a certain threshold (epsilon), guaranteeing that each token in the final sample has a fair chance of being included. The approach is particularly effective when generating a large set of samples, as it inherently yields greater sample diversity compared to beam search.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p5">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p5.1.1">?</span>) introduced QE-fusion, a method that combines spans from different candidates sampled from a model using QE metrics. They found that the method consistently improves translation quality in terms of neural evaluation metrics, especially if applied to LLM due to their ability to generate diverse outputs.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p6">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p6.1">Due to its ease of implementation and use, MBR and QE reranking have been successfully applied in machine translation shared tasks, as demonstrated by the results in several studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx22" title="">Nowakowski et al. (2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx18" title="">Kudo et al. (2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx13" title="">Jon et al. (2023</a>]</cite>. This highlights its potential to significantly improve translation quality.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Model self-improvement</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Recent research has shown a growing interest in leveraging model outputs for self-improvement.
This approach holds significant promise in the case of machine translation, especially for low-resource and domain-specific translation scenarios, where there is access to the source-language data, but the corresponding target-language data is severely limited.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px2.p2.1.1">?</span>) describes reinforcement self-training (<span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p2.1.2">ReST</span>) method for language modeling.
The method is based on producing a dataset for fine-tuning by sampling from the model (LLM). The samples are then scored with a QE metric. Then, offline reinforcement learning algorithms are applied using a reward-weighted loss based on the QE scores. The method can be applied to all generative learning settings, but the authors focus on its application to machine translation, showing that the method increases translation quality.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p3.1">Concurrent work by <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px2.p3.1.1">?</span>) describes self-tuning NMT models on a set of hypotheses reranked using either MBR, QE, or a combination of the two methods.
They also experimented with using LLM as the teacher model, finding that it outperforms using a self-teacher and fine-tuning on references.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p4.1">Our research expands on recent developments in the field by investigating the use of MBR-based fine-tuning in three key areas. Firstly, we examine its applicability in domain-specific translation tasks, specifically focusing on English–German translation in the biomedical domain. Secondly, we investigate its effectiveness for low-resource translation directions, exemplified by the Czech–Ukrainian language pair. This broadens the scope beyond English-centric language pairs, thus contributing to a more comprehensive analysis of MBR performance across less-represented languages in neural evaluation metrics. Finally, we explore the use of neural QE metrics tailored for specific languages, using AfriCOMET <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx37" title="">Wang et al. (2023</a>]</cite> as an example.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiment Overview</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Model Self-Improvement</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The self-improvement process leverages MBR decoding to guide the model to select high-quality translations according to the utility function. The process consists of 3 steps:</p>
<dl class="ltx_description" id="S3.I1">
<dt class="ltx_item" id="S3.I1.ix1"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.ix1.1.1.1">Step 1: Sample Generation</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S3.I1.ix1.p1">
<p class="ltx_p" id="S3.I1.ix1.p1.1">Using beam search decoding with beam size equal to <span class="ltx_text ltx_font_typewriter" id="S3.I1.ix1.p1.1.1">N</span>, generate <span class="ltx_text ltx_font_typewriter" id="S3.I1.ix1.p1.1.2">N</span> translation candidates using the base model for each source sentence. While <span class="ltx_text ltx_font_bold" id="S3.I1.ix1.p1.1.3">?</span>) suggested that epsilon sampling might yield better results with MBR decoding, it typically requires reranking a significantly larger number of translation candidates, which becomes computationally expensive for processing large datasets. Beam search, on the other hand, allows for generating a smaller set of high-quality candidates while providing sufficient data for effective MBR decoding.</p>
</div>
</dd>
<dt class="ltx_item" id="S3.I1.ix2"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.ix2.1.1.1">Step 2: MBR Decoding</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S3.I1.ix2.p1">
<p class="ltx_p" id="S3.I1.ix2.p1.1">Select a single translation for each source sentence from the list of candidates through MBR decoding utilizing COMET to guide the selection towards high-quality translations. For an efficient implementation of the MBR decoding algorithm, we use the code<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/marian-nmt/marian-dev/tree/master/scripts/mbr</span></span></span></span> from the Marian <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx14" title="">Junczys-Dowmunt et al. (2018</a>]</cite> framework.</p>
</div>
</dd>
<dt class="ltx_item" id="S3.I1.ix3"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.ix3.1.1.1">Step 3: Model Fine-tuning</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S3.I1.ix3.p1">
<p class="ltx_p" id="S3.I1.ix3.p1.1">Fine-tune the base model on the synthetically created dataset. Use COMET as an early stopping metric during training to ensure fitting to this metric.</p>
</div>
</dd>
</dl>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>English–German</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The English–German experiment simulates a real-world domain adaptation scenario. In such settings, while a large general-purpose parallel corpus might be available, the specific domain often lacks extensive parallel data. To address this challenge, we leveraged both a smaller parallel dataset and a larger monolingual dataset in the source language containing biomedical terminology.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To leverage the monolingual data in the source language we propose a two-step approach:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1">Fine-Tuning: We fine-tune a general-purpose English–German model on a small parallel biomedical dataset.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1">Self-improvement: To enhance the model performance in the biomedical domain, we incorporate a larger monolingual biomedical dataset during the self-improvement process. This involves creating a synthetic parallel dataset via MBR decoding and subsequently fine-tuning the biomedical translation model on the generated data.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">To assess the robustness of the self-improvement method, we conducted an additional experiment in which we applied this method to a model that was fine-tuned to the biomedical domain using general domain data for MBR decoding. This evaluated whether the model would retain its translation capabilities in the biomedical domain despite improvements based solely on out-of-domain data.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Czech–Ukrainian</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The Czech–Ukrainian experiment addresses the challenge of machine translation between two low-resource languages. We aimed to evaluate whether self-improvement through MBR decoding leads to an increase in the overall translation quality when applied to language pairs that do not involve English, which typically dominate machine translation research.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">In this setting, we used only the parallel data set without incorporating any additional monolingual data. To employ MBR decoding in this data-scarce environment, we directly translated the entire source side of the parallel dataset using the baseline translation model. This created a set of synthetic candidate translations, which were then reranked through MBR decoding.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">In contrast to our English–German experiments where we incorporated external monolingual data, this setup explored self-improvement without relying on additional datasets. We achieved this by solely leveraging the information present within the data of the base model. This demonstrates the potential for self-improvement even in resource-constrained scenarios.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>English–Hausa</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">The English–Hausa experiment delves into the critical question of how the choice of a quality evaluation metric influences the effectiveness of self-improvement with MBR decoding. We explored the impact of language coverage in the evaluation metric by comparing two approaches:</p>
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1">MBR decoding with WMT22 COMET: utilizing the <span class="ltx_text ltx_font_italic" id="S3.I3.i1.p1.1.1">wmt22-comet-da</span> model, which has been trained on direct assessments between a diverse set of language pairs.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1">MBR decoding with AfriCOMET: using AfriCOMET-STL, a novel COMET-like metric specifically designed for evaluating translations to and from multiple African languages, including Hausa.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The objective of this study was to investigate the effect of language contribution in the neural evaluation metric on the quality of translations decoded using MBR. The comparison of these two approaches specifically addresses whether self-improvement guided by the WMT22 COMET metric, which is trained on a diverse range of language pairs, can effectively generalize to low-resource language pairs. Furthermore, we explore the potential need to use language-specific metrics, such as AfriCOMET-STL for Hausa, to achieve better performance in such scenarios.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Iterative MBR Self-Improvement</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">Following the initial self-improvement through MBR decoding, we explored the possibility of applying it iteratively to further enhance the model’s translation quality.</p>
</div>
<div class="ltx_para" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.1">We started each iteration by selecting the best model checkpoint based on the WMT22 COMET metric on the validation set. Next, we performed MBR decoding on the entire training set using this checkpoint, generating a new iteration of the synthetic training set. Finally, we resumed the training of the model using the new training set, starting from the previously selected checkpoint.</p>
</div>
<div class="ltx_para" id="S3.SS5.p3">
<p class="ltx_p" id="S3.SS5.p3.1">The iterative process was repeated until a decrease was observed in the evaluation scores of metrics other than WMT22 COMET. In the case of English–German biomedical translation, the process was continued until the model’s quality improved solely on an in-domain test set and decreased on a general domain test set, as this could indicate potential overfitting to the biomedical domain.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Data Filtering</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We filtered the general training data using the following heuristic filters:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">average length of words in each sentence (character-wise) <math alttext="\leq 15" class="ltx_Math" display="inline" id="S4.I1.i1.p1.1.m1.1"><semantics id="S4.I1.i1.p1.1.m1.1a"><mrow id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i1.p1.1.m1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.cmml">≤</mo><mn id="S4.I1.i1.p1.1.m1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><apply id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1"><leq id="S4.I1.i1.p1.1.m1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.I1.i1.p1.1.m1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.2">absent</csymbol><cn id="S4.I1.i1.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.I1.i1.p1.1.m1.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">\leq 15</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i1.p1.1.m1.1d">≤ 15</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">number of characters in each sentence <math alttext="\leq 500" class="ltx_Math" display="inline" id="S4.I1.i2.p1.1.m1.1"><semantics id="S4.I1.i2.p1.1.m1.1a"><mrow id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml"><mi id="S4.I1.i2.p1.1.m1.1.1.2" xref="S4.I1.i2.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i2.p1.1.m1.1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.1.cmml">≤</mo><mn id="S4.I1.i2.p1.1.m1.1.1.3" xref="S4.I1.i2.p1.1.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><apply id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1"><leq id="S4.I1.i2.p1.1.m1.1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.I1.i2.p1.1.m1.1.1.2.cmml" xref="S4.I1.i2.p1.1.m1.1.1.2">absent</csymbol><cn id="S4.I1.i2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.I1.i2.p1.1.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">\leq 500</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.1.m1.1d">≤ 500</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">digits in a sentence (character-wise) <math alttext="\leq 15\%" class="ltx_Math" display="inline" id="S4.I1.i3.p1.1.m1.1"><semantics id="S4.I1.i3.p1.1.m1.1a"><mrow id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml"><mi id="S4.I1.i3.p1.1.m1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i3.p1.1.m1.1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.1.cmml">≤</mo><mrow id="S4.I1.i3.p1.1.m1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.3.cmml"><mn id="S4.I1.i3.p1.1.m1.1.1.3.2" xref="S4.I1.i3.p1.1.m1.1.1.3.2.cmml">15</mn><mo id="S4.I1.i3.p1.1.m1.1.1.3.1" xref="S4.I1.i3.p1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b"><apply id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1"><leq id="S4.I1.i3.p1.1.m1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.I1.i3.p1.1.m1.1.1.2.cmml" xref="S4.I1.i3.p1.1.m1.1.1.2">absent</csymbol><apply id="S4.I1.i3.p1.1.m1.1.1.3.cmml" xref="S4.I1.i3.p1.1.m1.1.1.3"><csymbol cd="latexml" id="S4.I1.i3.p1.1.m1.1.1.3.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1.3.1">percent</csymbol><cn id="S4.I1.i3.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S4.I1.i3.p1.1.m1.1.1.3.2">15</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">\leq 15\%</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i3.p1.1.m1.1d">≤ 15 %</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">number of characters in the longest word <math alttext="\leq 28" class="ltx_Math" display="inline" id="S4.I1.i4.p1.1.m1.1"><semantics id="S4.I1.i4.p1.1.m1.1a"><mrow id="S4.I1.i4.p1.1.m1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.cmml"><mi id="S4.I1.i4.p1.1.m1.1.1.2" xref="S4.I1.i4.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i4.p1.1.m1.1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.1.cmml">≤</mo><mn id="S4.I1.i4.p1.1.m1.1.1.3" xref="S4.I1.i4.p1.1.m1.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.m1.1b"><apply id="S4.I1.i4.p1.1.m1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1"><leq id="S4.I1.i4.p1.1.m1.1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.I1.i4.p1.1.m1.1.1.2.cmml" xref="S4.I1.i4.p1.1.m1.1.1.2">absent</csymbol><cn id="S4.I1.i4.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.I1.i4.p1.1.m1.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.m1.1c">\leq 28</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i4.p1.1.m1.1d">≤ 28</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">number of words in sentence <math alttext="\leq 100" class="ltx_Math" display="inline" id="S4.I1.i5.p1.1.m1.1"><semantics id="S4.I1.i5.p1.1.m1.1a"><mrow id="S4.I1.i5.p1.1.m1.1.1" xref="S4.I1.i5.p1.1.m1.1.1.cmml"><mi id="S4.I1.i5.p1.1.m1.1.1.2" xref="S4.I1.i5.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i5.p1.1.m1.1.1.1" xref="S4.I1.i5.p1.1.m1.1.1.1.cmml">≤</mo><mn id="S4.I1.i5.p1.1.m1.1.1.3" xref="S4.I1.i5.p1.1.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.1.m1.1b"><apply id="S4.I1.i5.p1.1.m1.1.1.cmml" xref="S4.I1.i5.p1.1.m1.1.1"><leq id="S4.I1.i5.p1.1.m1.1.1.1.cmml" xref="S4.I1.i5.p1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.I1.i5.p1.1.m1.1.1.2.cmml" xref="S4.I1.i5.p1.1.m1.1.1.2">absent</csymbol><cn id="S4.I1.i5.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.I1.i5.p1.1.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.1.m1.1c">\leq 100</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i5.p1.1.m1.1d">≤ 100</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i6.p1">
<p class="ltx_p" id="S4.I1.i6.p1.1">Levenshtein distance between source and target sentences <math alttext="\geq 2" class="ltx_Math" display="inline" id="S4.I1.i6.p1.1.m1.1"><semantics id="S4.I1.i6.p1.1.m1.1a"><mrow id="S4.I1.i6.p1.1.m1.1.1" xref="S4.I1.i6.p1.1.m1.1.1.cmml"><mi id="S4.I1.i6.p1.1.m1.1.1.2" xref="S4.I1.i6.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i6.p1.1.m1.1.1.1" xref="S4.I1.i6.p1.1.m1.1.1.1.cmml">≥</mo><mn id="S4.I1.i6.p1.1.m1.1.1.3" xref="S4.I1.i6.p1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i6.p1.1.m1.1b"><apply id="S4.I1.i6.p1.1.m1.1.1.cmml" xref="S4.I1.i6.p1.1.m1.1.1"><geq id="S4.I1.i6.p1.1.m1.1.1.1.cmml" xref="S4.I1.i6.p1.1.m1.1.1.1"></geq><csymbol cd="latexml" id="S4.I1.i6.p1.1.m1.1.1.2.cmml" xref="S4.I1.i6.p1.1.m1.1.1.2">absent</csymbol><cn id="S4.I1.i6.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.I1.i6.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i6.p1.1.m1.1c">\geq 2</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i6.p1.1.m1.1d">≥ 2</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i7.p1">
<p class="ltx_p" id="S4.I1.i7.p1.1">number of characters in each sentence <math alttext="\geq 5" class="ltx_Math" display="inline" id="S4.I1.i7.p1.1.m1.1"><semantics id="S4.I1.i7.p1.1.m1.1a"><mrow id="S4.I1.i7.p1.1.m1.1.1" xref="S4.I1.i7.p1.1.m1.1.1.cmml"><mi id="S4.I1.i7.p1.1.m1.1.1.2" xref="S4.I1.i7.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i7.p1.1.m1.1.1.1" xref="S4.I1.i7.p1.1.m1.1.1.1.cmml">≥</mo><mn id="S4.I1.i7.p1.1.m1.1.1.3" xref="S4.I1.i7.p1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i7.p1.1.m1.1b"><apply id="S4.I1.i7.p1.1.m1.1.1.cmml" xref="S4.I1.i7.p1.1.m1.1.1"><geq id="S4.I1.i7.p1.1.m1.1.1.1.cmml" xref="S4.I1.i7.p1.1.m1.1.1.1"></geq><csymbol cd="latexml" id="S4.I1.i7.p1.1.m1.1.1.2.cmml" xref="S4.I1.i7.p1.1.m1.1.1.2">absent</csymbol><cn id="S4.I1.i7.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.I1.i7.p1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i7.p1.1.m1.1c">\geq 5</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i7.p1.1.m1.1d">≥ 5</annotation></semantics></math>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i8.p1">
<p class="ltx_p" id="S4.I1.i8.p1.1">probability that each sentence is in the correct language <math alttext="\geq 10\%" class="ltx_Math" display="inline" id="S4.I1.i8.p1.1.m1.1"><semantics id="S4.I1.i8.p1.1.m1.1a"><mrow id="S4.I1.i8.p1.1.m1.1.1" xref="S4.I1.i8.p1.1.m1.1.1.cmml"><mi id="S4.I1.i8.p1.1.m1.1.1.2" xref="S4.I1.i8.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.I1.i8.p1.1.m1.1.1.1" xref="S4.I1.i8.p1.1.m1.1.1.1.cmml">≥</mo><mrow id="S4.I1.i8.p1.1.m1.1.1.3" xref="S4.I1.i8.p1.1.m1.1.1.3.cmml"><mn id="S4.I1.i8.p1.1.m1.1.1.3.2" xref="S4.I1.i8.p1.1.m1.1.1.3.2.cmml">10</mn><mo id="S4.I1.i8.p1.1.m1.1.1.3.1" xref="S4.I1.i8.p1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i8.p1.1.m1.1b"><apply id="S4.I1.i8.p1.1.m1.1.1.cmml" xref="S4.I1.i8.p1.1.m1.1.1"><geq id="S4.I1.i8.p1.1.m1.1.1.1.cmml" xref="S4.I1.i8.p1.1.m1.1.1.1"></geq><csymbol cd="latexml" id="S4.I1.i8.p1.1.m1.1.1.2.cmml" xref="S4.I1.i8.p1.1.m1.1.1.2">absent</csymbol><apply id="S4.I1.i8.p1.1.m1.1.1.3.cmml" xref="S4.I1.i8.p1.1.m1.1.1.3"><csymbol cd="latexml" id="S4.I1.i8.p1.1.m1.1.1.3.1.cmml" xref="S4.I1.i8.p1.1.m1.1.1.3.1">percent</csymbol><cn id="S4.I1.i8.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S4.I1.i8.p1.1.m1.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i8.p1.1.m1.1c">\geq 10\%</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i8.p1.1.m1.1d">≥ 10 %</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">To ensure that each sentence is in the correct language, we have used the fastText LID-201 language identification model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx4" title="">Burchell et al. (2023</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">The Bicleaner-AI model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx38" title="">Zaragoza-Bernabeu et al. (2022</a>]</cite> is also used to filter the English–German dataset. This tool estimates the likelihood that a sentence pair constitutes a mutual translation. A threshold of 50% is established for the Bicleaner score within this language pair. Bicleaner-AI is not utilized for other language pairs due to the unavailability of open-source models for those languages.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Vocabulary</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We employed SentencePiece <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx17" title="">Kudo and Richardson (2018</a>]</cite>, a subword tokenization library, to train unigram tokenizers for each language pair in our experiments.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">For the English–German and English–Hausa setups, we created a joint vocabulary containing 32,000 subword tokens and tied all embeddings during the training of the MT model. In contrast, for Czech–Ukrainian, due to different scripts (Latin and Cyrillic), we created separate vocabularies of 32,000 subword tokens and tied only the target and output layer embeddings.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Baseline Model Hyperparameters</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">For all experiments, we trained Transformer (big) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx34" title="">Vaswani et al. (2017</a>]</cite> models using the Marian framework. These models were trained on four NVIDIA A100 GPUs, each equipped with 80GB of VRAM.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Hyperparameter Settings:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">learning rate: 2e-4;</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">learning rate warmup: 8000 updates;</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1">learning rate decay: inverse square root;</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1">mini-batch size determined automatically to fit GPU memory;</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i5.p1">
<p class="ltx_p" id="S4.I2.i5.p1.1">early stopping after 10 consecutive validations with no improvement in mean word cross-entropy score.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Evaluation metrics</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We use sacreBLEU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx26" title="">Post (2018</a>]</cite> to calculate BLEU<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>BLEU signature: nrefs:1<math alttext="|" class="ltx_Math" display="inline" id="footnote2.m1.1"><semantics id="footnote2.m1.1b"><mo fence="false" id="footnote2.m1.1.1" stretchy="false" xref="footnote2.m1.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><ci id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote2.m1.1e">|</annotation></semantics></math>case:mixed<math alttext="|" class="ltx_Math" display="inline" id="footnote2.m2.1"><semantics id="footnote2.m2.1b"><mo fence="false" id="footnote2.m2.1.1" stretchy="false" xref="footnote2.m2.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote2.m2.1c"><ci id="footnote2.m2.1.1.cmml" xref="footnote2.m2.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m2.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote2.m2.1e">|</annotation></semantics></math>eff:no<math alttext="|" class="ltx_Math" display="inline" id="footnote2.m3.1"><semantics id="footnote2.m3.1b"><mo fence="false" id="footnote2.m3.1.1" stretchy="false" xref="footnote2.m3.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote2.m3.1c"><ci id="footnote2.m3.1.1.cmml" xref="footnote2.m3.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m3.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote2.m3.1e">|</annotation></semantics></math>tok:13a<math alttext="|" class="ltx_Math" display="inline" id="footnote2.m4.1"><semantics id="footnote2.m4.1b"><mo fence="false" id="footnote2.m4.1.1" stretchy="false" xref="footnote2.m4.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote2.m4.1c"><ci id="footnote2.m4.1.1.cmml" xref="footnote2.m4.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m4.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote2.m4.1e">|</annotation></semantics></math>smooth:exp<math alttext="|" class="ltx_Math" display="inline" id="footnote2.m5.1"><semantics id="footnote2.m5.1b"><mo fence="false" id="footnote2.m5.1.1" stretchy="false" xref="footnote2.m5.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote2.m5.1c"><ci id="footnote2.m5.1.1.cmml" xref="footnote2.m5.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m5.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote2.m5.1e">|</annotation></semantics></math>version:2.3.1</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx24" title="">Papineni et al. (2002</a>]</cite> and chrF<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>chrF signature: nrefs:1<math alttext="|" class="ltx_Math" display="inline" id="footnote3.m1.1"><semantics id="footnote3.m1.1b"><mo fence="false" id="footnote3.m1.1.1" stretchy="false" xref="footnote3.m1.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote3.m1.1c"><ci id="footnote3.m1.1.1.cmml" xref="footnote3.m1.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m1.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote3.m1.1e">|</annotation></semantics></math>case:mixed<math alttext="|" class="ltx_Math" display="inline" id="footnote3.m2.1"><semantics id="footnote3.m2.1b"><mo fence="false" id="footnote3.m2.1.1" stretchy="false" xref="footnote3.m2.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote3.m2.1c"><ci id="footnote3.m2.1.1.cmml" xref="footnote3.m2.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m2.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote3.m2.1e">|</annotation></semantics></math>eff:yes<math alttext="|" class="ltx_Math" display="inline" id="footnote3.m3.1"><semantics id="footnote3.m3.1b"><mo fence="false" id="footnote3.m3.1.1" stretchy="false" xref="footnote3.m3.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote3.m3.1c"><ci id="footnote3.m3.1.1.cmml" xref="footnote3.m3.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m3.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote3.m3.1e">|</annotation></semantics></math>nc:6<math alttext="|" class="ltx_Math" display="inline" id="footnote3.m4.1"><semantics id="footnote3.m4.1b"><mo fence="false" id="footnote3.m4.1.1" stretchy="false" xref="footnote3.m4.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote3.m4.1c"><ci id="footnote3.m4.1.1.cmml" xref="footnote3.m4.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m4.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote3.m4.1e">|</annotation></semantics></math>nw:0<math alttext="|" class="ltx_Math" display="inline" id="footnote3.m5.1"><semantics id="footnote3.m5.1b"><mo fence="false" id="footnote3.m5.1.1" stretchy="false" xref="footnote3.m5.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote3.m5.1c"><ci id="footnote3.m5.1.1.cmml" xref="footnote3.m5.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m5.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote3.m5.1e">|</annotation></semantics></math>space:no<math alttext="|" class="ltx_Math" display="inline" id="footnote3.m6.1"><semantics id="footnote3.m6.1b"><mo fence="false" id="footnote3.m6.1.1" stretchy="false" xref="footnote3.m6.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="footnote3.m6.1c"><ci id="footnote3.m6.1.1.cmml" xref="footnote3.m6.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m6.1d">|</annotation><annotation encoding="application/x-llamapun" id="footnote3.m6.1e">|</annotation></semantics></math>version:2.3.1</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx25" title="">Popović (2015</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">We acknowledge the potential for overfitting to the WMT22 COMET<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/Unbabel/wmt22-comet-da</span></span></span></span> metric used for MBR decoding. Therefore, we extended the evaluation to also include CometKiwi<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/Unbabel/wmt22-cometkiwi-da</span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx29" title="">Rei et al. (2022</a>]</cite>, UniTE<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/Unbabel/unite-mup</span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx36" title="">Wan et al. (2022</a>]</cite>, UniTE-DA<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/Unbabel/wmt22-unite-da</span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx30" title="">Rei et al. (2023</a>]</cite> and BLEURT-20<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip</span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx32" title="">Sellam et al. (2020b</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">For the English–Hausa experiments, we additionally calculated scores using AfriCOMET-STL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx37" title="">Wang et al. (2023</a>]</cite>, which was specifically trained to evaluate translations involving certain African languages.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>English to German</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">To train the baseline model, we used all corpora from the MTData toolkit (version 0.4.0) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx11" title="">Gowda et al. (2021</a>]</cite>, excluding the validation sets and the test sets from the available datasets. Our filters described in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS1" title="4.1 Data Filtering ‣ 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4.1</span></a> reduced the dataset from approximately 800 million sentences to 400 million.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">In the context of domain adaptation, we employed the following list of domain data:</p>
<ol class="ltx_enumerate" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1">40 thousand sentences from biomedical-translation-corpora <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx20" title="">Neves et al. (2016</a>]</cite>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1">3 million sentences from Ufal medical corpus shared in WMT23 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx15" title="">Kocmi et al. (2023</a>]</cite>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I3.i3.p1">
<p class="ltx_p" id="S4.I3.i3.p1.1">2 million sentences from EMEA corpus downloaded from OPUS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx33" title="">Tiedemann and Nygaard (2004</a>]</cite>.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S4.SS5.p2.2">After deduplication, we were left with 3 million sentences which we split into two datasets. We considered a scenario with 1 million bilingual parallel sentences and approximately 2 million monolingual sentences in the source language. Khresmoi-dev <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx6" title="">Dušek et al. (2017</a>]</cite> concatenated with FLORES-200 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx21" title="">NLLB Team et al. (2022</a>]</cite> was utilized as the validation set during training. We did not apply any filtering to the domain data.</p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">We used the above data to train the following models:</p>
<ul class="ltx_itemize" id="S4.I4">
<li class="ltx_item" id="S4.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i1.p1">
<p class="ltx_p" id="S4.I4.i1.p1.1">Baseline (<span class="ltx_text ltx_font_bold" id="S4.I4.i1.p1.1.1">Baseline</span>) – model trained only on data from the MTdata toolkit.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i2.p1">
<p class="ltx_p" id="S4.I4.i2.p1.1">Baseline + mix-tuning (<span class="ltx_text ltx_font_bold" id="S4.I4.i2.p1.1.1">Mix-tune</span>) – fine-tuned <span class="ltx_text ltx_font_bold" id="S4.I4.i2.p1.1.2">Baseline</span> model on 1 million in-domain bilingual data concatenated with 1 million general-domain data randomly sampled from the <span class="ltx_text ltx_font_bold" id="S4.I4.i2.p1.1.3">Baseline</span> training set.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i3.p1">
<p class="ltx_p" id="S4.I4.i3.p1.1">Baseline + domain MBR (<span class="ltx_text ltx_font_bold" id="S4.I4.i3.p1.1.1">Base-domain-mbr</span>) – fine-tuned <span class="ltx_text ltx_font_bold" id="S4.I4.i3.p1.1.2">Baseline</span> model on 2 million domain-specific sentences from MBR-decoded forward translations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i4.p1">
<p class="ltx_p" id="S4.I4.i4.p1.1">Mix-tuned + domain MBR (<span class="ltx_text ltx_font_bold" id="S4.I4.i4.p1.1.1">Mix-tune-domain-mbr</span>) – fine-tuned <span class="ltx_text ltx_font_bold" id="S4.I4.i4.p1.1.2">Mix-tune</span> model on 2 million domain-specific sentences from MBR-decoded forward translations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i5.p1">
<p class="ltx_p" id="S4.I4.i5.p1.1">Mix-tuned + MBR-iteration2 (<span class="ltx_text ltx_font_bold" id="S4.I4.i5.p1.1.1">Mix-tune-domain-mbr-iter2</span>) – fine-tuned <span class="ltx_text ltx_font_bold" id="S4.I4.i5.p1.1.2">Mix-tune-domain-mbr</span> on the 2 million domain-specific sentences from MBR-decoded forward translations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i6.p1">
<p class="ltx_p" id="S4.I4.i6.p1.1">Mix tuned + general-MBR (<span class="ltx_text ltx_font_bold" id="S4.I4.i6.p1.1.1">Mix-tune-general-mbr</span>) – fine-tuned <span class="ltx_text ltx_font_bold" id="S4.I4.i6.p1.1.2">Mix-tune</span> model on 2 million sentences sampled from the general-domain corpora from the <span class="ltx_text ltx_font_bold" id="S4.I4.i6.p1.1.3">Baseline</span> training set as MBR-decoded forward translations.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS5.p3.2">When fine-tuning the <span class="ltx_text ltx_font_bold" id="S4.SS5.p3.2.1">Mix-tune</span> model, we tailor the learning rate setup to meet specific requirements: learn-rate: 1e-7, lr-decay-inv-sqrt: 16000, lr-warmup: 16000. All remaining fine-tuning procedures employ an adjusted learning rate set to <span class="ltx_text" id="S4.SS5.p3.2.2">5e-6</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Czech to Ukrainian</h3>
<div class="ltx_para" id="S4.SS6.p1">
<p class="ltx_p" id="S4.SS6.p1.1">We leveraged all of the Czech–Ukrainian parallel data from the WMT23 MTData recipe, resulting in approximately 8 million sentence pairs after filtering as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS1" title="4.1 Data Filtering ‣ 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4.1</span></a>. We did not include any additional monolingual data in this experiment.</p>
</div>
<div class="ltx_para" id="S4.SS6.p2">
<p class="ltx_p" id="S4.SS6.p2.1">We utilized the FLORES-200 dataset for validation during training, while the WMT22 test set served as an additional benchmark.</p>
</div>
<div class="ltx_para" id="S4.SS6.p3">
<p class="ltx_p" id="S4.SS6.p3.1">We trained the baseline model only on the parallel data, using hyperparameters as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS3" title="4.3 Baseline Model Hyperparameters ‣ 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a>. Next, we translated the source side of the parallel corpus used in training with our baseline model, saving a list of translation candidates. We performed MBR decoding, selecting the best translation of each set of candidate translations, resulting in a synthetic training dataset.</p>
</div>
<div class="ltx_para" id="S4.SS6.p4">
<p class="ltx_p" id="S4.SS6.p4.1">We investigated the following approaches to leverage the MBR-decoded data for model improvement:</p>
<ul class="ltx_itemize" id="S4.I5">
<li class="ltx_item" id="S4.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I5.i1.p1">
<p class="ltx_p" id="S4.I5.i1.p1.1">Standard fine-tuning (<span class="ltx_text ltx_font_bold" id="S4.I5.i1.p1.1.1">MBR-finetuned</span>) – we fine-tuned the baseline model on the MBR-decoded data, using a learning rate of  5e-6.</p>
</div>
</li>
<li class="ltx_item" id="S4.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I5.i2.p1">
<p class="ltx_p" id="S4.I5.i2.p1.1">Fine-tuning with a high learning rate (<span class="ltx_text ltx_font_bold" id="S4.I5.i2.p1.1.1">MBR-ft-high-lr</span>) – we fine-tune the baseline model on MBR-decoded data, using a learning rate of 2e-4.</p>
</div>
</li>
<li class="ltx_item" id="S4.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I5.i3.p1">
<p class="ltx_p" id="S4.I5.i3.p1.1">Resuming training with MBR-decoded data (<span class="ltx_text ltx_font_bold" id="S4.I5.i3.p1.1.1">MBR-resumed</span>) – we switched the training set to the MBR-decoded version and resumed training, restoring the optimizer state and effectively continuing its training with the improved data.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>English to Hausa</h3>
<div class="ltx_para" id="S4.SS7.p1">
<p class="ltx_p" id="S4.SS7.p1.1">To train the models in the English–Hausa direction, we used data from the WMT shared tasks from previous years. Specifically, we used:</p>
<ol class="ltx_enumerate" id="S4.I6">
<li class="ltx_item" id="S4.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I6.i1.p1">
<p class="ltx_p" id="S4.I6.i1.p1.1">7 million sentences from OPUS;</p>
</div>
</li>
<li class="ltx_item" id="S4.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I6.i2.p1">
<p class="ltx_p" id="S4.I6.i2.p1.1">2.4 million data from the WMT23 African MT Shared Task  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx15" title="">Kocmi et al. (2023</a>]</cite>;</p>
</div>
</li>
<li class="ltx_item" id="S4.I6.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I6.i3.p1">
<p class="ltx_p" id="S4.I6.i3.p1.1">150 thousand sentences from ParaCrawl v8.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx3" title="">Bañón et al. (2020</a>]</cite>.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S4.SS7.p1.2">The deduplication process reduced the data size to approximately 9 million sentences. Following the filtering criteria detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS1" title="4.1 Data Filtering ‣ 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4.1</span></a>, a total of 3.1 million sentences were retained. We used FLORES-200 for validation during training. After training, we evaluated the model on the FLORES-200 and NTREX test sets.</p>
</div>
<div class="ltx_para" id="S4.SS7.p2">
<p class="ltx_p" id="S4.SS7.p2.1">We took similar steps as in the Czech–Ukrainian experiment, training a baseline model with hyperparameters set as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS3" title="4.3 Baseline Model Hyperparameters ‣ 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a>. We conducted experiments employing MBR decoding, comparing its performance using two distinct metrics as the utility function:</p>
<ul class="ltx_itemize" id="S4.I7">
<li class="ltx_item" id="S4.I7.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I7.i1.p1">
<p class="ltx_p" id="S4.I7.i1.p1.1">WMT22 COMET – based on XLM-RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx5" title="">Conneau et al. (2020</a>]</cite>, covering a diverse set of 100 languages,</p>
</div>
</li>
<li class="ltx_item" id="S4.I7.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I7.i2.p1">
<p class="ltx_p" id="S4.I7.i2.p1.1">AfriCOMET-STL – based on AfroXLM-RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx1" title="">Alabi et al. (2022</a>]</cite>, covering 17 African languages and 3 high-resource languages.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS7.p3">
<p class="ltx_p" id="S4.SS7.p3.1">We investigated the impact of the chosen metric for MBR decoding by training two models using the refined translations:</p>
<ul class="ltx_itemize" id="S4.I8">
<li class="ltx_item" id="S4.I8.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I8.i1.p1">
<p class="ltx_p" id="S4.I8.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I8.i1.p1.1.1">MBR-COMET</span> – training resumed with the training set switched to the WMT22 COMET MBR-decoded version.</p>
</div>
</li>
<li class="ltx_item" id="S4.I8.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I8.i2.p1">
<p class="ltx_p" id="S4.I8.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I8.i2.p1.1.1">MBR-AfriCOMET</span> – training resumed with the training set switched to the AfriCOMET-STL MBR-decoded version.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The statistical significance of the evaluation results is assessed using a paired bootstrap resampling test <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#bib.bibx16" title="">Koehn (2004</a>]</cite>, involving 1000 resampling trials to confirm the statistical significance of the model improvements (<span class="ltx_text ltx_font_italic" id="S5.p1.1.1">p</span> <math alttext="&lt;0.05" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml"></mi><mo id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><lt id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">absent</csymbol><cn id="S5.p1.1.m1.1.1.3.cmml" type="float" xref="S5.p1.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">&lt; 0.05</annotation></semantics></math>).</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Number of translation samples and search algorithm</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">To determine the optimal setup for MBR decoding, we conducted experiments involving the translation and evaluation of chosen test sets with various MBR decoding sample sizes and two decoding algorithms. This approach offers the advantages of being both representative and computationally efficient compared to training MT models on the entire MBR-decoded training set.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">We evaluated two decoding algorithms – beam search and top-k. For the top-k setup, we experimented with temperature values of 0.1 and 1, keeping the <span class="ltx_text ltx_font_italic" id="S5.SS1.p2.1.1">k</span> parameter equal to 10. These choices were based on the work
done by <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.2">?</span>). To determine the best number of samples for MBR decoding we conducted experiments with the following numbers of samples: 10, 25, 50, 100, 200, 300, 400, 500.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">Firstly we noted that beam search is the preferred option, given its high scores and greater stability across different metric results, as observed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.F1" title="Figure 1 ‣ 5.1 Number of translation samples and search algorithm ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.F2" title="Figure 2 ‣ 5.1 Number of translation samples and search algorithm ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>. We provide more specific results in the Appendix Figures <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F4" title="Figure 4 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F5" title="Figure 5 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure class="ltx_figure" id="S5.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="427" id="S5.F1.g1" src="extracted/5606863/img/3_Krs-test-num-samples.png" width="300"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Comparison of beam search and top-k algorithms of the <span class="ltx_text ltx_font_bold" id="S5.F1.2.1">Mix-tune</span> English–German model for the khresmoi test set. Top-k algorithm with temperature 1.0 showed superior performance on neural metrics over top-k with temperature 0.1 and slightly better performance than beam search. However, beam search achieved the highest score on the chrF metric, while the top-k algorithm with temperature 1.0 had the lowest score (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="427" id="S5.F2.g1" src="extracted/5606863/img/3_Flores-test-num-samples.png" width="303"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparison of beam search and top-k algorithms of the <span class="ltx_text ltx_font_bold" id="S5.F2.3.1">baseline</span> Czech–Ukrainian model for the <span class="ltx_text" id="S5.F2.4.2">FLORES-200</span> test set. Beam search seems to be the superior option with the best performance on chrF and BLEURT metrics and slightly worse results on COMET over top-k with temperature 1.0 (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Secondly, we decided to train our models on MBR-decoded data from 50 candidates selected by the beam search decoding algorithm. We considered the balance between improvement in evaluation metrics based on neural language models, stability across lexical metrics, and the execution time of MBR decoding, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.F3" title="Figure 3 ‣ 5.1 Number of translation samples and search algorithm ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>. <span class="ltx_text" id="S5.SS1.p4.1.1"></span>We provide more detailed results in the Appendix Figures <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F6" title="Figure 6 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F7" title="Figure 7 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F8" title="Figure 8 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F9" title="Figure 9 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">9</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F10" title="Figure 10 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">10</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F11" title="Figure 11 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">11</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.F12" title="Figure 12 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">12</span></a>.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="S5.F3.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/beam_en_de_krs.png" width="626"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Comparison of beam search performance with a different number of samples of the <span class="ltx_text ltx_font_bold" id="S5.F3.2.1">Mix-tune</span> English–German model for the khresmoi test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains, and performance on the n-gram metrics deteriorated (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>English to German</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T1" title="Table 1 ‣ 5.2 English to German ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> shows the evaluation results on the in-domain test set khresmoi. All models self-improved with MBR decoding have shown enhanced performance. However, model <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Mix-tune-domain-mbr-iter2</span> did not exhibit improvement over its first iteration <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">Mix-tune-domain-mbr</span>, even on COMET, which was the utility metric of MBR decoding. <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.3">Mix-tune-general-mbr</span> model shows a slightly better performance on BLEURT metric compared to models fine-tuned on in-domain MBR-decoded forward translations.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.1" style="width:216.7pt;height:100.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.1pt,12.6pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T1.1.1">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.1.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.1.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.1.1.1.3">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.1.1.1.4">BLEURT</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.2.2">66.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.2.3">0.8653</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.2.4">0.7693</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.3">
<td class="ltx_td ltx_align_left" id="S5.T1.1.1.3.1">Mix-tune</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.3.2">66.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.3.3">0.8682</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.3.4">0.7749</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.4">
<td class="ltx_td ltx_align_left" id="S5.T1.1.1.4.1">Base-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.4.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.4.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.4.3">0.8711*</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.4.4">0.7755</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.5">
<td class="ltx_td ltx_align_left" id="S5.T1.1.1.5.1">Mix-tune-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.5.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.5.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.5.3">
<span class="ltx_text ltx_font_bold" id="S5.T1.1.1.5.3.1">0.8728</span>*</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.5.4">0.7792*</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.6">
<td class="ltx_td ltx_align_left" id="S5.T1.1.1.6.1">Mix-tune-domain-mbr-iter2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.6.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.6.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.6.3">0.8727*</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.1.6.4">0.7791*</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.1.7.1">Mix-tune-general-mbr</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.1.7.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.7.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.1.7.3">0.8720*</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.1.7.4">
<span class="ltx_text ltx_font_bold" id="S5.T1.1.1.7.4.1">0.7799</span>*</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>English–German khresmoi set results for the MBR self-improvement approaches. All models fine-tuned with MBR self-improvement technique have shown better performance over <span class="ltx_text ltx_font_bold" id="S5.T1.6.1">Baseline</span> and <span class="ltx_text ltx_font_bold" id="S5.T1.7.2">Mix-tune</span> models, including the <span class="ltx_text ltx_font_bold" id="S5.T1.8.3">Mix-tune-general-mbr</span> model, which was finetuned on general-domain MBR-decoded data. The results marked with an asterisk (*) are statistically significant compared to the <span class="ltx_text ltx_font_bold" id="S5.T1.9.4">Mix-tune</span> model.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T2" title="Table 2 ‣ 5.2 English to German ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a> presents the evaluation results on the FLORES-200 test set. Although chrF did not increase, the neural evaluation metrics showed improvement. Similar to the khresmoi test set, the <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">Mix-tune-domain-mbr-iter2</span> model showed a decrease in quality during the second iteration of self-improvement. <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.2">Mix-tune-general-mbr</span> showed superior performance over other models.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:216.7pt;height:100.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.1pt,12.6pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.1.1">
<tr class="ltx_tr" id="S5.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.1.3">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.1.4">BLEURT</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.2.1">67.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.2.3">0.8751</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.2.4">0.7735</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3">
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.3.1">Mix-tune</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.3.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.2.1">67.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.3.3">0.8756</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.3.4">0.7744</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4">
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.4.1">Base-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2">67.2</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.3">0.8772</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.4">0.7743</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5">
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.5.1">Mix-tune-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2">67.3</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.3">0.8787*</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.4">0.7766</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.6">
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.6.1">Mix-tune-domain-mbr-iter2</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.2">67.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3">0.8766</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.4">0.7748</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.1.1.7.1">Mix-tune-general-mbr</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.7.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.7.2.1">67.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.7.3">
<span class="ltx_text ltx_font_bold" id="S5.T2.1.1.7.3.1">0.8813</span>*</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.7.4">
<span class="ltx_text ltx_font_bold" id="S5.T2.1.1.7.4.1">0.7784</span>*</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>English–German FLORES-200 test set results for the MBR self-improvement approaches. <span class="ltx_text ltx_font_bold" id="S5.T2.4.1">Mix-tune-general-mbr</span> model has shown superior performance, however, models with domain-specific forward translation maintain performance. The results marked with an asterisk (*) are statistically significant compared to the <span class="ltx_text ltx_font_bold" id="S5.T2.5.2">Mix-tune</span> model.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">In summary, our findings demonstrate that applying MBR decoding significantly improves the performance of the high-resource English–German model for low-resource biomedical domain translation, particularly on neural network metrics. While lexical metrics show lower stability, they also hold potential for improvement.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">Experiments demonstrated the robustness of self-improving models with the MBR decoding technique. Model fine-tuned on general forward translation had great performance on the in-domain test set and the model fine-tuned on domain-specific forward translation maintained performance on the general domain test set. We provide a broader evaluation in the Appendix Tables <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T9" title="Table 9 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">9</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T10" title="Table 10 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">10</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T11" title="Table 11 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">11</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T12" title="Table 12 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">12</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Czech to Ukrainian</h3>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.1">
<tr class="ltx_tr" id="S5.T3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T3.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.3">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.4">BLEURT</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2">52.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.3">0.8779</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.4">0.7466</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3">
<td class="ltx_td ltx_align_left" id="S5.T3.1.3.1">MBR-finetuned</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2">52.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.3">0.8839</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.4">0.7522</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4">
<td class="ltx_td ltx_align_left" id="S5.T3.1.4.1">MBR-ft-high-lr</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.4.2.1">52.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.4.3.1">0.8869</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.4">0.7553</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T3.1.5.1">MBR-resumed</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.5.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.2.1">52.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.5.3">0.8864</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.5.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.4.1">0.7557</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Czech–Ukrainian FLORES-200 test set results for the three MBR self-improvement approaches. All self-improved models exhibit improvements on all metrics compared to the baseline model, regardless of the fine-tuning approach used. Notably, both <span class="ltx_text ltx_font_bold" id="S5.T3.5.1">MBR-ft-high-lr</span> and <span class="ltx_text ltx_font_bold" id="S5.T3.6.2">MBR-resumed</span> models achieve the highest gains, demonstrating comparable performance. All self-improved models show statistical significance compared to the <span class="ltx_text ltx_font_bold" id="S5.T3.7.3">Baseline</span> model.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.1">
<tr class="ltx_tr" id="S5.T4.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T4.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.3">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.4">BLEURT</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.2.2">58.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.2.3">0.8721</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.2.4">0.7498</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.3">
<td class="ltx_td ltx_align_left" id="S5.T4.1.3.1">MBR-finetuned</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.3.2">60.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.3.3">0.8803</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.3.4">0.7574</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4">
<td class="ltx_td ltx_align_left" id="S5.T4.1.4.1">MBR-ft-high-lr</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.4.2.1">60.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.3">0.8844</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.4">0.7619</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T4.1.5.1">MBR-resumed</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.5.2">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.5.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.3.1">0.8852</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.5.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.4.1">0.7639</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Czech–Ukrainian WMT22 test set results for the three MBR self-improvement approaches. Similar to the FLORES-200 results, all self-improved models exhibit improvements on all metrics compared to the baseline model. However, on the WMT22 test set, the neural metrics favour the <span class="ltx_text ltx_font_bold" id="S5.T4.5.1">MBR-resumed</span> model over the <span class="ltx_text ltx_font_bold" id="S5.T4.6.2">MBR-ft-high-lr</span> model. All self-improved models show statistical significance compared to the <span class="ltx_text ltx_font_bold" id="S5.T4.7.3">Baseline</span> model.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T5.1">
<tr class="ltx_tr" id="S5.T5.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T5.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">BLEURT</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">52.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.8779</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7466</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.3">
<td class="ltx_td ltx_align_left" id="S5.T5.1.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-resumed</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">52.7*</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.8864*</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7557*</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.4">
<td class="ltx_td ltx_align_left" id="S5.T5.1.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-resumed-iter2</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.4.2.1">52.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.8888*</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.4.4.1">0.7567</span></td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T5.1.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-resumed-iter3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">52.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.5.3.1">0.8901</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7557</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Czech–Ukrainian iterative self-improvement results on the FLORES-200 test set. While the COMET score consistently improves across all three iterations, the chrF and BLEURT scores show a decrease in the third iteration. This suggests that the model overfits to COMET, harming the quality of the translation. Results with an asterisk (*) are statistically significant in comparison with the model in the row directly above it.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T6.1">
<tr class="ltx_tr" id="S5.T6.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T6.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">BLEURT</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">58.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.8721</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7498</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.3">
<td class="ltx_td ltx_align_left" id="S5.T6.1.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-resumed</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">60.0*</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.8852*</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7639*</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.4">
<td class="ltx_td ltx_align_left" id="S5.T6.1.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-resumed-iter2</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text ltx_font_bold" id="S5.T6.1.4.2.1">60.3</span>*</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.8885*</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.4.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.4.4.1">0.7641</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T6.1.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-resumed-iter3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">60.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.5.3.1">0.8896</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7578</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Czech–Ukrainian iterative self-improvement results on the WMT22 test set. Consistent with the FLORES-200 results, the COMET score improves across all iterations, while other metrics show a decrease in the last iteration. Notably, the BLEURT score not only decreases but falls below the score achieved by the first self-improved model. Results with an asterisk (*) are statistically significant in comparison with the model in the row directly above it.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The results of the three MBR self-improvement approaches described in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S4.SS6" title="4.6 Czech to Ukrainian ‣ 4 Experimental Setup ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4.6</span></a> are presented in Tables <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T3" title="Table 3 ‣ 5.3 Czech to Ukrainian ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T4" title="Table 4 ‣ 5.3 Czech to Ukrainian ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a> for the FLORES-200 and WMT22 test sets, respectively.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">We find that standard fine-tuning of the baseline model with MBR-decoded data yields the smallest improvements across all metrics, suggesting its limited effectiveness in this context. We note that both fine-tuning with a higher learning rate and resuming the training exhibit comparable performance, with resumed training achieving slightly better results on the WMT22 test set. This may indicate that resuming training helps mitigate overfitting to the FLORES-200 validation set used during training.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">Tables <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T5" title="Table 5 ‣ 5.3 Czech to Ukrainian ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T6" title="Table 6 ‣ 5.3 Czech to Ukrainian ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> showcase the impact of iterative training with MBR decoding on the FLORES-200 and WMT22 test sets, respectively. The second iteration consistently improves scores across all metrics, demonstrating the effectiveness of the iterative self-improvement process in refining the model’s translation capabilities. However, the third iteration leads to a decrease in both chrF and BLEURT scores. This suggests potential overfitting to the MBR decoding utility metric, where the model prioritizes aspects that score well according to COMET but may not translate to overall translation quality.</p>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">We provide extended evaluations in the Appendix in Tables <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T13" title="Table 13 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">13</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T14" title="Table 14 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">14</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T15" title="Table 15 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">15</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T16" title="Table 16 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">16</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>English to Hausa</h3>
<figure class="ltx_table" id="S5.T7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T7.1" style="width:224.2pt;height:57.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.0pt,7.2pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T7.1.1">
<tr class="ltx_tr" id="S5.T7.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T7.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T7.1.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T7.1.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T7.1.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">BLEURT</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T7.1.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">AfriCOMET</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T7.1.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.1.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">49.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.1.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.7569</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.1.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7931</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.1.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">0.6984</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.1.3">
<td class="ltx_td ltx_align_left" id="S5.T7.1.1.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T7.1.1.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">50.9</td>
<td class="ltx_td ltx_align_center" id="S5.T7.1.1.3.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.3.3.1">0.7720</span></td>
<td class="ltx_td ltx_align_center" id="S5.T7.1.1.3.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.3.4.1">0.8083</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T7.1.1.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">0.7207</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T7.1.1.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-AfriCOMET</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.1.1.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.4.2.1">51.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.1.1.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.7692</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.1.1.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.8061</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T7.1.1.4.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.4.5.1">0.7239</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>English–Hausa FLORES-200 test set results for MBR self-improvement with different metrics. Both self-improved models achieve gains compared to the baseline model on all evaluation metrics. While the AfriCOMET-based model achieves a higher AfriCOMET score, reflecting its alignment with the specific evaluation metric, the COMET-based model surpasses it in both BLEURT and COMET scores, while showing a comparable gain on the AfriCOMET score. All self-improved models show statistical significance compared to the <span class="ltx_text ltx_font_bold" id="S5.T7.3.1">Baseline</span> model.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T8">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T8.1" style="width:224.2pt;height:57.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.0pt,7.2pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.1">
<tr class="ltx_tr" id="S5.T8.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T8.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.1.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.1.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.1.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">BLEURT</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T8.1.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">AfriCOMET</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.1.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">51.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.7596</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7791</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T8.1.1.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">0.6800</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.3">
<td class="ltx_td ltx_align_left" id="S5.T8.1.1.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.1.3.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.3.2.1">53.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.1.3.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.3.3.1">0.7752</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.1.3.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.3.4.1">0.7986</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">0.7046</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T8.1.1.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">MBR-AfriCOMET</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.1.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">53.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.1.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">0.7721</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.1.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">0.7956</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T8.1.1.4.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.4.5.1">0.7062</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>English–Hausa NTREX test set results for MBR self-improvement with different metrics. Similar to the FLORES-200 results, both self-improved models using MBR decoding demonstrate improvements over the baseline model on all evaluation metrics. All self-improved models show statistical significance compared to the <span class="ltx_text ltx_font_bold" id="S5.T8.3.1">Baseline</span> model.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">This section compares the performance of two MBR decoding self-improvement approaches for English–Hausa translation: one utilizing the WMT22 COMET model and another using the AfriCOMET model. The results are presented in Tables <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T7" title="Table 7 ‣ 5.4 English to Hausa ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#S5.T8" title="Table 8 ‣ 5.4 English to Hausa ‣ 5 Results ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a> for the FLORES-200 and NTREX test sets, respectively.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">We observe that the AfriCOMET MBR-tuned model achieves gains over the WMT22 COMET MBR-tuned model on chrF for the FLORES-200 test set, but this advantage is not replicated on the NTREX test set. Additionally, the gains from AfriCOMET MBR-tuning are mainly limited to the AfriCOMET metric.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">Our analysis reveals that the <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.1">MBR-AfriCOMET</span> model exhibits improvements over the <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.2">MBR-COMET</span> model primarily on lexical metrics in the case of the FLORES-200 test set, but not in the case of NTREX. The gains of the <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.3">MBR-AfriCOMET</span> model are mainly limited to AfriCOMET metrics, while other neural-based metrics consistently favour the <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.4">MBR-COMET</span> model.</p>
</div>
<div class="ltx_para" id="S5.SS4.p4">
<p class="ltx_p" id="S5.SS4.p4.1">While WMT22 COMET might exhibit a lower correlation with human judgment for the English–Hausa language pair than AfriCOMET, as reported by <span class="ltx_text ltx_font_bold" id="S5.SS4.p4.1.1">?</span>), both self-improved models achieved significant and comparable gains on AfriCOMET. This suggests that WMT22 COMET, can still correctly rerank translation candidates and effectively guide the self-improvement process, leading to improvements on AfriCOMET, a metric specifically designed for African languages. This finding suggests that self-improvement guided by WMT22 COMET, with its diverse language coverage, might be effective even in low-resource settings, potentially reducing the need for additional adaptation of neural evaluation models to individual languages.</p>
</div>
<div class="ltx_para" id="S5.SS4.p5">
<p class="ltx_p" id="S5.SS4.p5.1">Additional evaluations are provided in the Appendix in Tables <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T17" title="Table 17 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">17</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.11937v1#A0.T18" title="Table 18 ‣ Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation"><span class="ltx_text ltx_ref_tag">18</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This study demonstrated the effectiveness of model self-improvement through MBR decoding in improving translation quality. This approach proves beneficial for both high and low-resource languages, offering versatility in its application across diverse scenarios. Examples include domain-specific translation and the enhancement of general translation models.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">We conducted experiments with various sample sizes for MBR decoding, using two decoding algorithms: beam search and top-k. The aim was to find a balance between automatic metric gains and time efficiency. Our experiments have shown that the beam search algorithm with a beam size set to 50 is the optimal choice.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">In the field of high-resource English-to-German biomedical translation, we investigated the impact of domain adaptation using various self-improvement approaches on MBR-decoded forward-translated data. Experiments showed that all MBR-based fine-tuning, regardless of the domain of the test set, improved performance compared to the baseline model. This finding highlights the robustness of the self-improvement technique.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">Experiments on the Czech–Ukrainian language pair revealed that fine-tuning the MT model on MBR-decoded translations of the training data set significantly improves translation performance. Applying this process iteratively improves quality, but further iterations yield diminishing gains and at some point, the quality may even degrade due to overfitting to the MBR decoding utility metric.</p>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1">In the English–Hausa experiments, we employed two models for MBR decoding: WMT22 COMET and AfriCOMET. Both models yielded comparable and significant improvements in automatic metrics, indicating their effectiveness in guiding the self-improvement process. While AfriCOMET, specifically trained on African languages, might intuitively seem favourable for this language pair, the performance of the <span class="ltx_text ltx_font_bold" id="S6.p5.1.1">MBR-COMET</span> model highlights the potential of utilizing more widely applicable metrics like WMT22 COMET even for low-resource settings.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bibx1">
<span class="ltx_tag ltx_tag_bibitem">[Alabi et al. (2022] </span>
<span class="ltx_bibblock">
Alabi, Jesujoba O., David Ifeoluwa Adelani, Marius Mosbach, and Dietrich Klakow.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Adapting pre-trained language models to African languages via multilingual adaptive fine-tuning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx1.1.1">Proceedings of the 29th International Conference on Computational Linguistics</span>, pages 4336–4349, Gyeongju, Republic of Korea, October. International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx2">
<span class="ltx_tag ltx_tag_bibitem">[Amrhein and Sennrich (2022] </span>
<span class="ltx_bibblock">
Amrhein, Chantal and Rico Sennrich.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Identifying weaknesses in machine translation metrics through minimum Bayes risk decoding: A case study for COMET.

</span>
<span class="ltx_bibblock">In He, Yulan, Heng Ji, Sujian Li, Yang Liu, and Chua-Hui Chang, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx2.1.1">Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</span>, pages 1125–1141, Online only, November. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx3">
<span class="ltx_tag ltx_tag_bibitem">[Bañón et al. (2020] </span>
<span class="ltx_bibblock">
Bañón, Marta, Pinzhen Chen, Barry Haddow, Kenneth Heafield, Hieu Hoang, Miquel Esplà-Gomis, Mikel L. Forcada, Amir Kamran, Faheem Kirefu, Philipp Koehn, Sergio Ortiz Rojas, Leopoldo Pla Sempere, Gema Ramírez-Sánchez, Elsa Sarrías, Marek Strelec, Brian Thompson, William Waites, Dion Wiggins, and Jaume Zaragoza.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">ParaCrawl: Web-scale acquisition of parallel corpora.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx3.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</span>, pages 4555–4567, Online, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx4">
<span class="ltx_tag ltx_tag_bibitem">[Burchell et al. (2023] </span>
<span class="ltx_bibblock">
Burchell, Laurie, Alexandra Birch, Nikolay Bogoychev, and Kenneth Heafield.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">An open dataset and model for language identification.

</span>
<span class="ltx_bibblock">In Rogers, Anna, Jordan Boyd-Graber, and Naoaki Okazaki, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx4.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</span>, pages 865–879, Toronto, Canada, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx5">
<span class="ltx_tag ltx_tag_bibitem">[Conneau et al. (2020] </span>
<span class="ltx_bibblock">
Conneau, Alexis, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock">In Jurafsky, Dan, Joyce Chai, Natalie Schluter, and Joel Tetreault, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx5.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</span>, pages 8440–8451, Online, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx6">
<span class="ltx_tag ltx_tag_bibitem">[Dušek et al. (2017] </span>
<span class="ltx_bibblock">
Dušek, Ondřej, Jan Hajič, Jaroslava Hlaváčová, Jindřich Libovický, Pavel Pecina, Aleš Tamchyna, and Zdeňka Urešová.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">Khresmoi summary translation test data 2.0.

</span>
<span class="ltx_bibblock">LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics, Charles University.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx7">
<span class="ltx_tag ltx_tag_bibitem">[Fernandes et al. (2022] </span>
<span class="ltx_bibblock">
Fernandes, Patrick, António Farinhas, Ricardo Rei, José G. C. de Souza, Perez Ogayo, Graham Neubig, and Andre Martins.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Quality-aware decoding for neural machine translation.

</span>
<span class="ltx_bibblock">In Carpuat, Marine, Marie-Catherine de Marneffe, and Ivan Vladimir Meza Ruiz, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx7.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</span>, pages 1396–1412, Seattle, United States, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx8">
<span class="ltx_tag ltx_tag_bibitem">[Finkelstein et al. (2023] </span>
<span class="ltx_bibblock">
Finkelstein, Mara, Subhajit Naskar, Mehdi Mirzazadeh, Apurva Shah, and Markus Freitag.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Mbr and qe finetuning: Training-time distillation of the best and most expensive decoding methods.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx9">
<span class="ltx_tag ltx_tag_bibitem">[Freitag et al. (2022] </span>
<span class="ltx_bibblock">
Freitag, Markus, David Grangier, Qijun Tan, and Bowen Liang.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">High quality rather than high model probability: Minimum Bayes risk decoding with neural metrics.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx9.1.1">Transactions of the Association for Computational Linguistics</span>, 10:811–825.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx10">
<span class="ltx_tag ltx_tag_bibitem">[Freitag et al. (2023] </span>
<span class="ltx_bibblock">
Freitag, Markus, Behrooz Ghorbani, and Patrick Fernandes.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Epsilon sampling rocks: Investigating sampling strategies for<math alttext="\backslash" class="ltx_Math" display="inline" id="bib.bibx10.1.m1.1"><semantics id="bib.bibx10.1.m1.1a"><mo id="bib.bibx10.1.m1.1.1" xref="bib.bibx10.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="bib.bibx10.1.m1.1b"><ci id="bib.bibx10.1.m1.1.1.cmml" xref="bib.bibx10.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bibx10.1.m1.1c">\backslash</annotation><annotation encoding="application/x-llamapun" id="bib.bibx10.1.m1.1d">\</annotation></semantics></math><math alttext="\backslash" class="ltx_Math" display="inline" id="bib.bibx10.2.m2.1"><semantics id="bib.bibx10.2.m2.1a"><mo id="bib.bibx10.2.m2.1.1" xref="bib.bibx10.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="bib.bibx10.2.m2.1b"><ci id="bib.bibx10.2.m2.1.1.cmml" xref="bib.bibx10.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bibx10.2.m2.1c">\backslash</annotation><annotation encoding="application/x-llamapun" id="bib.bibx10.2.m2.1d">\</annotation></semantics></math>minimum bayes risk decoding for machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx10.3.1">arXiv preprint arXiv:2305.09860</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx11">
<span class="ltx_tag ltx_tag_bibitem">[Gowda et al. (2021] </span>
<span class="ltx_bibblock">
Gowda, Thamme, Zhao Zhang, Chris Mattmann, and Jonathan May.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Many-to-English machine translation tools, data, and pretrained models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx11.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</span>, pages 306–316, Online, August. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx12">
<span class="ltx_tag ltx_tag_bibitem">[Gulcehre et al. (2023] </span>
<span class="ltx_bibblock">
Gulcehre, Caglar, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, et al.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Reinforced self-training (rest) for language modeling.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx12.1.1">arXiv preprint arXiv:2308.08998</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx13">
<span class="ltx_tag ltx_tag_bibitem">[Jon et al. (2023] </span>
<span class="ltx_bibblock">
Jon, Josef, Martin Popel, and Ondřej Bojar.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">CUNI at WMT23 general translation task: MT and a genetic algorithm.

</span>
<span class="ltx_bibblock">In Koehn, Philipp, Barry Haddow, Tom Kocmi, and Christof Monz, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx13.1.1">Proceedings of the Eighth Conference on Machine Translation</span>, pages 119–127, Singapore, December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx14">
<span class="ltx_tag ltx_tag_bibitem">[Junczys-Dowmunt et al. (2018] </span>
<span class="ltx_bibblock">
Junczys-Dowmunt, Marcin, Roman Grundkiewicz, Tomasz Dwojak, Hieu Hoang, Kenneth Heafield, Tom Neckermann, Frank Seide, Ulrich Germann, Alham Fikri Aji, Nikolay Bogoychev, André F. T. Martins, and Alexandra Birch.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">Marian: Fast neural machine translation in C++.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx14.1.1">Proceedings of ACL 2018, System Demonstrations</span>, pages 116–121, Melbourne, Australia, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx15">
<span class="ltx_tag ltx_tag_bibitem">[Kocmi et al. (2023] </span>
<span class="ltx_bibblock">
Kocmi, Tom, Eleftherios Avramidis, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Markus Freitag, Thamme Gowda, Roman Grundkiewicz, Barry Haddow, Philipp Koehn, Benjamin Marie, Christof Monz, Makoto Morishita, Kenton Murray, Makoto Nagata, Toshiaki Nakazawa, Martin Popel, Maja Popović, and Mariya Shmatova.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Findings of the 2023 conference on machine translation (WMT23): LLMs are here but not quite there yet.

</span>
<span class="ltx_bibblock">In Koehn, Philipp, Barry Haddow, Tom Kocmi, and Christof Monz, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx15.1.1">Proceedings of the Eighth Conference on Machine Translation</span>, pages 1–42, Singapore, December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx16">
<span class="ltx_tag ltx_tag_bibitem">[Koehn (2004] </span>
<span class="ltx_bibblock">
Koehn, Philipp.

</span>
<span class="ltx_bibblock">2004.

</span>
<span class="ltx_bibblock">Statistical significance tests for machine translation evaluation.

</span>
<span class="ltx_bibblock">In Lin, Dekang and Dekai Wu, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx16.1.1">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</span>, pages 388–395, Barcelona, Spain, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx17">
<span class="ltx_tag ltx_tag_bibitem">[Kudo and Richardson (2018] </span>
<span class="ltx_bibblock">
Kudo, Taku and John Richardson.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing.

</span>
<span class="ltx_bibblock">In Blanco, Eduardo and Wei Lu, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx17.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</span>, pages 66–71, Brussels, Belgium, November. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx18">
<span class="ltx_tag ltx_tag_bibitem">[Kudo et al. (2023] </span>
<span class="ltx_bibblock">
Kudo, Keito, Takumi Ito, Makoto Morishita, and Jun Suzuki.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">SKIM at WMT 2023 general translation task.

</span>
<span class="ltx_bibblock">In Koehn, Philipp, Barry Haddow, Tom Kocmi, and Christof Monz, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx18.1.1">Proceedings of the Eighth Conference on Machine Translation</span>, pages 128–136, Singapore, December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx19">
<span class="ltx_tag ltx_tag_bibitem">[Kumar and Byrne (2004] </span>
<span class="ltx_bibblock">
Kumar, Shankar and William Byrne.

</span>
<span class="ltx_bibblock">2004.

</span>
<span class="ltx_bibblock">Minimum Bayes-risk decoding for statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx19.1.1">Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004</span>, pages 169–176, Boston, Massachusetts, USA, May 2 - May 7. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx20">
<span class="ltx_tag ltx_tag_bibitem">[Neves et al. (2016] </span>
<span class="ltx_bibblock">
Neves, Mariana, Antonio Jimeno Yepes, and Aurélie Névéol.

</span>
<span class="ltx_bibblock">2016.

</span>
<span class="ltx_bibblock">The scielo corpus: a parallel corpus of scientific publications for biomedicine.

</span>
<span class="ltx_bibblock">In Calzolari, Nicoletta, Khalid Choukri, Thierry Declerck, Sara Goggi, Marko Grobelnik, Bente Maegaard, Joseph Mariani, Helene Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx20.1.1">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16)</span>, pages 2942–2948, Portorož, Slovenia, May. European Language Resources Association (ELRA).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx21">
<span class="ltx_tag ltx_tag_bibitem">[NLLB Team et al. (2022] </span>
<span class="ltx_bibblock">
NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia-Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">No language left behind: Scaling human-centered machine translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx22">
<span class="ltx_tag ltx_tag_bibitem">[Nowakowski et al. (2022] </span>
<span class="ltx_bibblock">
Nowakowski, Artur, Gabriela Pałka, Kamil Guttmann, and Mikołaj Pokrywka.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Adam Mickiewicz University at WMT 2022: NER-assisted and quality-aware neural machine translation.

</span>
<span class="ltx_bibblock">In Koehn, Philipp, Loïc Barrault, Ondřej Bojar, Fethi Bougares, Rajen Chatterjee, Marta R. Costa-jussà, Christian Federmann, Mark Fishel, Alexander Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Tom Kocmi, André Martins, Makoto Morishita, Christof Monz, Masaaki Nagata, Toshiaki Nakazawa, Matteo Negri, Aurélie Névéol, Mariana Neves, Martin Popel, Marco Turchi, and Marcos Zampieri, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx22.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</span>, pages 326–334, Abu Dhabi, United Arab Emirates (Hybrid), December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx23">
<span class="ltx_tag ltx_tag_bibitem">[Och (2003] </span>
<span class="ltx_bibblock">
Och, Franz Josef.

</span>
<span class="ltx_bibblock">2003.

</span>
<span class="ltx_bibblock">Minimum error rate training in statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx23.1.1">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</span>, pages 160–167, Sapporo, Japan, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx24">
<span class="ltx_tag ltx_tag_bibitem">[Papineni et al. (2002] </span>
<span class="ltx_bibblock">
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">2002.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In Isabelle, Pierre, Eugene Charniak, and Dekang Lin, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx24.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</span>, pages 311–318, Philadelphia, Pennsylvania, USA, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx25">
<span class="ltx_tag ltx_tag_bibitem">[Popović (2015] </span>
<span class="ltx_bibblock">
Popović, Maja.

</span>
<span class="ltx_bibblock">2015.

</span>
<span class="ltx_bibblock">chrF: character n-gram F-score for automatic MT evaluation.

</span>
<span class="ltx_bibblock">In Bojar, Ondřej, Rajan Chatterjee, Christian Federmann, Barry Haddow, Chris Hokamp, Matthias Huck, Varvara Logacheva, and Pavel Pecina, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx25.1.1">Proceedings of the Tenth Workshop on Statistical Machine Translation</span>, pages 392–395, Lisbon, Portugal, September. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx26">
<span class="ltx_tag ltx_tag_bibitem">[Post (2018] </span>
<span class="ltx_bibblock">
Post, Matt.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">A call for clarity in reporting BLEU scores.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx26.1.1">Proceedings of the Third Conference on Machine Translation: Research Papers</span>, pages 186–191, Belgium, Brussels, October. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx27">
<span class="ltx_tag ltx_tag_bibitem">[Rei et al. (2020] </span>
<span class="ltx_bibblock">
Rei, Ricardo, Craig Stewart, Ana C Farinha, and Alon Lavie.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">COMET: A neural framework for MT evaluation.

</span>
<span class="ltx_bibblock">In Webber, Bonnie, Trevor Cohn, Yulan He, and Yang Liu, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx27.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</span>, pages 2685–2702, Online, November. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx28">
<span class="ltx_tag ltx_tag_bibitem">[Rei et al. (2021] </span>
<span class="ltx_bibblock">
Rei, Ricardo, Ana C Farinha, Chrysoula Zerva, Daan van Stigt, Craig Stewart, Pedro Ramos, Taisiya Glushkova, André F. T. Martins, and Alon Lavie.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Are references really needed? unbabel-IST 2021 submission for the metrics shared task.

</span>
<span class="ltx_bibblock">In Barrault, Loic, Ondrej Bojar, Fethi Bougares, Rajen Chatterjee, Marta R. Costa-jussa, Christian Federmann, Mark Fishel, Alexander Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Tom Kocmi, Andre Martins, Makoto Morishita, and Christof Monz, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx28.1.1">Proceedings of the Sixth Conference on Machine Translation</span>, pages 1030–1040, Online, November. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx29">
<span class="ltx_tag ltx_tag_bibitem">[Rei et al. (2022] </span>
<span class="ltx_bibblock">
Rei, Ricardo, Marcos Treviso, Nuno M. Guerreiro, Chrysoula Zerva, Ana C Farinha, Christine Maroti, José G. C. de Souza, Taisiya Glushkova, Duarte Alves, Luisa Coheur, Alon Lavie, and André F. T. Martins.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">CometKiwi: IST-unbabel 2022 submission for the quality estimation shared task.

</span>
<span class="ltx_bibblock">In Koehn, Philipp, Loïc Barrault, Ondřej Bojar, Fethi Bougares, Rajen Chatterjee, Marta R. Costa-jussà, Christian Federmann, Mark Fishel, Alexander Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Tom Kocmi, André Martins, Makoto Morishita, Christof Monz, Masaaki Nagata, Toshiaki Nakazawa, Matteo Negri, Aurélie Névéol, Mariana Neves, Martin Popel, Marco Turchi, and Marcos Zampieri, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx29.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</span>, pages 634–645, Abu Dhabi, United Arab Emirates (Hybrid), December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx30">
<span class="ltx_tag ltx_tag_bibitem">[Rei et al. (2023] </span>
<span class="ltx_bibblock">
Rei, Ricardo, Nuno M. Guerreiro, Marcos Treviso, Luisa Coheur, Alon Lavie, and André Martins.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">The inside story: Towards better understanding of machine translation neural evaluation metrics.

</span>
<span class="ltx_bibblock">In Rogers, Anna, Jordan Boyd-Graber, and Naoaki Okazaki, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx30.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</span>, pages 1089–1105, Toronto, Canada, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx31">
<span class="ltx_tag ltx_tag_bibitem">[Sellam et al. (2020a] </span>
<span class="ltx_bibblock">
Sellam, Thibault, Dipanjan Das, and Ankur Parikh.

</span>
<span class="ltx_bibblock">2020a.

</span>
<span class="ltx_bibblock">BLEURT: Learning robust metrics for text generation.

</span>
<span class="ltx_bibblock">In Jurafsky, Dan, Joyce Chai, Natalie Schluter, and Joel Tetreault, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx31.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</span>, pages 7881–7892, Online, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx32">
<span class="ltx_tag ltx_tag_bibitem">[Sellam et al. (2020b] </span>
<span class="ltx_bibblock">
Sellam, Thibault, Dipanjan Das, and Ankur P Parikh.

</span>
<span class="ltx_bibblock">2020b.

</span>
<span class="ltx_bibblock">Bleurt: Learning robust metrics for text generation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx32.1.1">Proceedings of ACL</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx33">
<span class="ltx_tag ltx_tag_bibitem">[Tiedemann and Nygaard (2004] </span>
<span class="ltx_bibblock">
Tiedemann, Jörg and Lars Nygaard.

</span>
<span class="ltx_bibblock">2004.

</span>
<span class="ltx_bibblock">The OPUS corpus - parallel and free: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://logos.uio.no/opus</span>.

</span>
<span class="ltx_bibblock">In Lino, Maria Teresa, Maria Francisca Xavier, Fátima Ferreira, Rute Costa, and Raquel Silva, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx33.1.1">Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04)</span>, Lisbon, Portugal, May. European Language Resources Association (ELRA).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx34">
<span class="ltx_tag ltx_tag_bibitem">[Vaswani et al. (2017] </span>
<span class="ltx_bibblock">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In Guyon, I., U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx34.1.1">Advances in Neural Information Processing Systems</span>, volume 30. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx35">
<span class="ltx_tag ltx_tag_bibitem">[Vernikos and Popescu-Belis (2024] </span>
<span class="ltx_bibblock">
Vernikos, Giorgos and Andrei Popescu-Belis.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">Don’t rank, combine! combining machine translation hypotheses using quality estimation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx36">
<span class="ltx_tag ltx_tag_bibitem">[Wan et al. (2022] </span>
<span class="ltx_bibblock">
Wan, Yu, Dayiheng Liu, Baosong Yang, Haibo Zhang, Boxing Chen, Derek Wong, and Lidia Chao.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">UniTE: Unified translation evaluation.

</span>
<span class="ltx_bibblock">In Muresan, Smaranda, Preslav Nakov, and Aline Villavicencio, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx36.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 8117–8127, Dublin, Ireland, May. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx37">
<span class="ltx_tag ltx_tag_bibitem">[Wang et al. (2023] </span>
<span class="ltx_bibblock">
Wang, Jiayi, David Ifeoluwa Adelani, Sweta Agrawal, Ricardo Rei, Eleftheria Briakou, Marine Carpuat, Marek Masiak, Xuanli He, Sofia Bourhim, Andiswa Bukula, Muhidin Mohamed, Temitayo Olatoye, Hamam Mokayede, Christine Mwase, Wangui Kimotho, Foutse Yuehgoh, Anuoluwapo Aremu, Jessica Ojo, Shamsuddeen Hassan Muhammad, Salomey Osei, Abdul-Hakeem Omotayo, Chiamaka Chukwuneke, Perez Ogayo, Oumaima Hourrane, Salma El Anigri, Lolwethu Ndolela, Thabiso Mangwana, Shafie Abdi Mohamed, Ayinde Hassan, Oluwabusayo Olufunke Awoyomi, Lama Alkhaled, Sana Al-Azzawi, Naome A. Etori, Millicent Ochieng, Clemencia Siro, Samuel Njoroge, Eric Muchiri, Wangari Kimotho, Lyse Naomi Wamba Momo, Daud Abolade, Simbiat Ajao, Tosin Adewumi, Iyanuoluwa Shode, Ricky Macharm, Ruqayya Nasir Iro, Saheed S. Abdullahi, Stephen E. Moore, Bernard Opoku, Zainab Akinjobi, Abeeb Afolabi, Nnaemeka Obiefuna, Onyekachi Raphael Ogbu, Sam Brian, Verrah Akinyi Otiende, Chinedu Emmanuel Mbonu, Sakayo Toadoum Sari, and Pontus Stenetorp.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Afrimte and africomet: Empowering comet to embrace under-resourced african languages.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx38">
<span class="ltx_tag ltx_tag_bibitem">[Zaragoza-Bernabeu et al. (2022] </span>
<span class="ltx_bibblock">
Zaragoza-Bernabeu, Jaume, Gema Ramírez-Sánchez, Marta Bañón, and Sergio Ortiz Rojas.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Bicleaner AI: Bicleaner goes neural.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx38.1.1">Proceedings of the Thirteenth Language Resources and Evaluation Conference</span>, pages 824–831, Marseille, France, June. European Language Resources Association.

</span>
</li>
</ul>
</section>
<figure class="ltx_table" id="A0.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A0.T9.1" style="width:450.2pt;height:120.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.8pt,3.1pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_align_middle" id="A0.T9.1.1">
<tr class="ltx_tr" id="A0.T9.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T9.1.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T9.1.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T9.1.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T9.1.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T9.1.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T9.1.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T9.1.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T9.1.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T9.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T9.1.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T9.1.1.2.2">66.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T9.1.1.2.3">35.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T9.1.1.2.4">0.8653</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T9.1.1.2.5">0.8373</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T9.1.1.2.6">0.6441</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T9.1.1.2.7">0.8574</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T9.1.1.2.8">0.7693</td>
</tr>
<tr class="ltx_tr" id="A0.T9.1.1.3">
<td class="ltx_td ltx_align_left" id="A0.T9.1.1.3.1">Mix-tune</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.3.2">66.8</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.3.3"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.3.3.1">35.9</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.3.4">0.8682</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.3.5">0.8397</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.3.6">0.6594</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.3.7">0.8602</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.3.8">0.7749</td>
</tr>
<tr class="ltx_tr" id="A0.T9.1.1.4">
<td class="ltx_td ltx_align_left" id="A0.T9.1.1.4.1">Base-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.4.2"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.4.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.4.3">35.7</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.4.4">0.8711</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.4.5">0.8416</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.4.6">0.6694</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.4.7">0.8621</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.4.8">0.7755</td>
</tr>
<tr class="ltx_tr" id="A0.T9.1.1.5">
<td class="ltx_td ltx_align_left" id="A0.T9.1.1.5.1">Mix-tune-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.5.2"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.5.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.5.3">35.8</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.5.4"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.5.4.1">0.8728</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.5.5"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.5.5.1">0.8423</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.5.6">0.6766</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.5.7">0.8631</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.5.8">0.7792</td>
</tr>
<tr class="ltx_tr" id="A0.T9.1.1.6">
<td class="ltx_td ltx_align_left" id="A0.T9.1.1.6.1">Mix-tune-domain-mbr-iter2</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.6.2"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.6.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.6.3">35.6</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.6.4">0.8727</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.6.5"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.6.5.1">0.8423</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.6.6">0.6757</td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.6.7"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.6.7.1">0.8633</span></td>
<td class="ltx_td ltx_align_center" id="A0.T9.1.1.6.8">0.7791</td>
</tr>
<tr class="ltx_tr" id="A0.T9.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T9.1.1.7.1">Mix-tune-general-mbr</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T9.1.1.7.2"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.7.2.1">66.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T9.1.1.7.3">35.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T9.1.1.7.4">0.8720</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T9.1.1.7.5">0.8422</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T9.1.1.7.6"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.7.6.1">0.6775</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T9.1.1.7.7">0.8631</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T9.1.1.7.8"><span class="ltx_text ltx_font_bold" id="A0.T9.1.1.7.8.1">0.7799</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>English–German khresmoi set results for the MBR self-improvement approaches. All models fine-tuned with MBR self-improvement technique have shown better performance over <span class="ltx_text ltx_font_bold" id="A0.T9.5.1">Baseline</span> and <span class="ltx_text ltx_font_bold" id="A0.T9.6.2">Mix-tune</span> models, even <span class="ltx_text ltx_font_bold" id="A0.T9.7.3">Mix-tune-general-mbr</span> model with general forward translations.</figcaption>
</figure>
<figure class="ltx_table" id="A0.T10">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A0.T10.1" style="width:450.2pt;height:120.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.8pt,3.1pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_align_middle" id="A0.T10.1.1">
<tr class="ltx_tr" id="A0.T10.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T10.1.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T10.1.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T10.1.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T10.1.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T10.1.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T10.1.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T10.1.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T10.1.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T10.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T10.1.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T10.1.1.2.2">63.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T10.1.1.2.3">35.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T10.1.1.2.4">0.8505</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T10.1.1.2.5">0.8336</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T10.1.1.2.6">0.5368</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T10.1.1.2.7">0.8470</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T10.1.1.2.8">0.7500</td>
</tr>
<tr class="ltx_tr" id="A0.T10.1.1.3">
<td class="ltx_td ltx_align_left" id="A0.T10.1.1.3.1">Mix-tune</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.3.2">63.5</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.3.3">35.6</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.3.4">0.8525</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.3.5">0.8360</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.3.6">0.5418</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.3.7">0.8495</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.3.8">0.7541</td>
</tr>
<tr class="ltx_tr" id="A0.T10.1.1.4">
<td class="ltx_td ltx_align_left" id="A0.T10.1.1.4.1">Base-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.4.2">63.5</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.4.3">35.8</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.4.4"><span class="ltx_text ltx_font_bold" id="A0.T10.1.1.4.4.1">0.8549</span></td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.4.5">0.8374</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.4.6">0.5549</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.4.7">0.8501</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.4.8">0.7522</td>
</tr>
<tr class="ltx_tr" id="A0.T10.1.1.5">
<td class="ltx_td ltx_align_left" id="A0.T10.1.1.5.1">Mix-tune-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.5.2">63.6</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.5.3">35.7</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.5.4">0.8540</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.5.5">0.8379</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.5.6">0.5552</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.5.7">0.8508</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.5.8">0.7530</td>
</tr>
<tr class="ltx_tr" id="A0.T10.1.1.6">
<td class="ltx_td ltx_align_left" id="A0.T10.1.1.6.1">Mix-tune-domain-mbr-iter2</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.6.2"><span class="ltx_text ltx_font_bold" id="A0.T10.1.1.6.2.1">63.7</span></td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.6.3"><span class="ltx_text ltx_font_bold" id="A0.T10.1.1.6.3.1">35.9</span></td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.6.4">0.8543</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.6.5"><span class="ltx_text ltx_font_bold" id="A0.T10.1.1.6.5.1">0.8383</span></td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.6.6">0.5575</td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.6.7"><span class="ltx_text ltx_font_bold" id="A0.T10.1.1.6.7.1">0.8510</span></td>
<td class="ltx_td ltx_align_center" id="A0.T10.1.1.6.8">0.7535</td>
</tr>
<tr class="ltx_tr" id="A0.T10.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T10.1.1.7.1">Mix-tune-general-mbr</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T10.1.1.7.2">63.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T10.1.1.7.3">35.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T10.1.1.7.4">0.8547</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T10.1.1.7.5">0.8378</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T10.1.1.7.6"><span class="ltx_text ltx_font_bold" id="A0.T10.1.1.7.6.1">0.5613</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T10.1.1.7.7">0.8501</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T10.1.1.7.8"><span class="ltx_text ltx_font_bold" id="A0.T10.1.1.7.8.1">0.7542</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>English–German WMT22-medline set results for the MBR self-improvement approaches. All models fine-tuned with MBR self-improvement technique have shown better performance over <span class="ltx_text ltx_font_bold" id="A0.T10.5.1">Mix-tune</span> model except on metric BLEURT. On this specific test set, <span class="ltx_text ltx_font_bold" id="A0.T10.6.2">Mix-tune-domain-mbr-iter2</span> outperformed the <span class="ltx_text ltx_font_bold" id="A0.T10.7.3">Mix-tune-domain-mbr</span> model, unlike the results observed on other test sets.</figcaption>
</figure>
<figure class="ltx_table" id="A0.T11">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A0.T11.1" style="width:450.2pt;height:120.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.8pt,3.1pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_align_middle" id="A0.T11.1.1">
<tr class="ltx_tr" id="A0.T11.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T11.1.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T11.1.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T11.1.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T11.1.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T11.1.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T11.1.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T11.1.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T11.1.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T11.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T11.1.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T11.1.1.2.2"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.2.2.1">67.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T11.1.1.2.3">42.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T11.1.1.2.4">0.8751</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T11.1.1.2.5">0.8454</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T11.1.1.2.6">0.6630</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T11.1.1.2.7">0.8614</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T11.1.1.2.8">0.7735</td>
</tr>
<tr class="ltx_tr" id="A0.T11.1.1.3">
<td class="ltx_td ltx_align_left" id="A0.T11.1.1.3.1">Mix-tune</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.3.2"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.3.2.1">67.5</span></td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.3.3"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.3.3.1">42.2</span></td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.3.4">0.8756</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.3.5">0.8457</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.3.6">0.6657</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.3.7">0.8617</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.3.8">0.7744</td>
</tr>
<tr class="ltx_tr" id="A0.T11.1.1.4">
<td class="ltx_td ltx_align_left" id="A0.T11.1.1.4.1">Base-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.4.2">67.2</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.4.3">41.7</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.4.4">0.8772</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.4.5">0.8469</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.4.6">0.6677</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.4.7">0.8632</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.4.8">0.7743</td>
</tr>
<tr class="ltx_tr" id="A0.T11.1.1.5">
<td class="ltx_td ltx_align_left" id="A0.T11.1.1.5.1">Mix-tune-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.5.2">67.3</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.5.3">41.7</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.5.4">0.8787</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.5.5">0.8477</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.5.6">0.6719</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.5.7">0.8641</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.5.8">0.7766</td>
</tr>
<tr class="ltx_tr" id="A0.T11.1.1.6">
<td class="ltx_td ltx_align_left" id="A0.T11.1.1.6.1">Mix-tune-domain-mbr-iter2</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.6.2">67.1</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.6.3">41.5</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.6.4">0.8766</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.6.5">0.8466</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.6.6">0.6653</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.6.7">0.8629</td>
<td class="ltx_td ltx_align_center" id="A0.T11.1.1.6.8">0.7748</td>
</tr>
<tr class="ltx_tr" id="A0.T11.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T11.1.1.7.1">Mix-tune-general-mbr</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T11.1.1.7.2"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.7.2.1">67.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T11.1.1.7.3">41.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T11.1.1.7.4"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.7.4.1">0.8813</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T11.1.1.7.5"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.7.5.1">0.8484</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T11.1.1.7.6"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.7.6.1">0.6824</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T11.1.1.7.7"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.7.7.1">0.8654</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T11.1.1.7.8"><span class="ltx_text ltx_font_bold" id="A0.T11.1.1.7.8.1">0.7784</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>English–German FLORES-200 test set results for the MBR self-improvement approaches. <span class="ltx_text ltx_font_bold" id="A0.T11.3.1">Mix-tune-general-mbr</span> model has shown superior performance, however, models with domain-specific forward translation maintain performance.</figcaption>
</figure>
<figure class="ltx_table" id="A0.T12">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A0.T12.1" style="width:450.2pt;height:120.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.8pt,3.1pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_align_middle" id="A0.T12.1.1">
<tr class="ltx_tr" id="A0.T12.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T12.1.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T12.1.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T12.1.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T12.1.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T12.1.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T12.1.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T12.1.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T12.1.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T12.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T12.1.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T12.1.1.2.2">63.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T12.1.1.2.3">36.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T12.1.1.2.4">0.8428</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T12.1.1.2.5">0.8328</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T12.1.1.2.6">0.5308</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T12.1.1.2.7">0.8420</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T12.1.1.2.8">0.7106</td>
</tr>
<tr class="ltx_tr" id="A0.T12.1.1.3">
<td class="ltx_td ltx_align_left" id="A0.T12.1.1.3.1">Mix-tune</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.3.2">63.7</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.3.3">36.5</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.3.4">0.8427</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.3.5">0.8322</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.3.6">0.5283</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.3.7">0.8414</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.3.8">0.7107</td>
</tr>
<tr class="ltx_tr" id="A0.T12.1.1.4">
<td class="ltx_td ltx_align_left" id="A0.T12.1.1.4.1">Base-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.4.2">63.3</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.4.3">35.8</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.4.4">0.8463</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.4.5">0.8359</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.4.6">0.5376</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.4.7">0.8454</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.4.8">0.7138</td>
</tr>
<tr class="ltx_tr" id="A0.T12.1.1.5">
<td class="ltx_td ltx_align_left" id="A0.T12.1.1.5.1">Mix-tune-domain-mbr</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.5.2">63.2</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.5.3">35.9</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.5.4">0.8468</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.5.5">0.8358</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.5.6">0.5404</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.5.7">0.8464</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.5.8">0.7132</td>
</tr>
<tr class="ltx_tr" id="A0.T12.1.1.6">
<td class="ltx_td ltx_align_left" id="A0.T12.1.1.6.1">Mix-tune-domain-mbr-iter2</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.6.2">63.0</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.6.3">35.5</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.6.4">0.8460</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.6.5">0.8345</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.6.6">0.5348</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.6.7">0.8455</td>
<td class="ltx_td ltx_align_center" id="A0.T12.1.1.6.8">0.7119</td>
</tr>
<tr class="ltx_tr" id="A0.T12.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T12.1.1.7.1">Mix-tune-general-mbr</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T12.1.1.7.2"><span class="ltx_text ltx_font_bold" id="A0.T12.1.1.7.2.1">64.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T12.1.1.7.3"><span class="ltx_text ltx_font_bold" id="A0.T12.1.1.7.3.1">36.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T12.1.1.7.4"><span class="ltx_text ltx_font_bold" id="A0.T12.1.1.7.4.1">0.8629</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T12.1.1.7.5"><span class="ltx_text ltx_font_bold" id="A0.T12.1.1.7.5.1">0.8399</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T12.1.1.7.6"><span class="ltx_text ltx_font_bold" id="A0.T12.1.1.7.6.1">0.5622</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T12.1.1.7.7"><span class="ltx_text ltx_font_bold" id="A0.T12.1.1.7.7.1">0.8492</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T12.1.1.7.8"><span class="ltx_text ltx_font_bold" id="A0.T12.1.1.7.8.1">0.7202</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>English–German Statmt test set results for the MBR self-improvement approaches. <span class="ltx_text ltx_font_bold" id="A0.T12.3.1">Mix-tune-general-mbr</span> model has shown significantly improved performance on every metric, however models with domain-specific forward translation maintain performance.</figcaption>
</figure>
<figure class="ltx_table" id="A0.T13">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A0.T13.1">
<tr class="ltx_tr" id="A0.T13.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T13.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T13.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T13.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T13.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T13.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T13.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T13.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T13.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T13.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T13.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T13.1.2.2">52.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T13.1.2.3">22.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T13.1.2.4">0.8779</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T13.1.2.5">0.8449</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T13.1.2.6">0.4441</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T13.1.2.7">0.9017</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T13.1.2.8">0.7466</td>
</tr>
<tr class="ltx_tr" id="A0.T13.1.3">
<td class="ltx_td ltx_align_left" id="A0.T13.1.3.1">MBR-finetuned</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.3.2">52.4</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.3.3">22.3</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.3.4">0.8839</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.3.5">0.8513</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.3.6">0.4715</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.3.7">0.9063</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.3.8">0.7522</td>
</tr>
<tr class="ltx_tr" id="A0.T13.1.4">
<td class="ltx_td ltx_align_left" id="A0.T13.1.4.1">MBR-ft-high-lr</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.4.2"><span class="ltx_text ltx_font_bold" id="A0.T13.1.4.2.1">52.7</span></td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.4.3">22.6</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.4.4"><span class="ltx_text ltx_font_bold" id="A0.T13.1.4.4.1">0.8869</span></td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.4.5"><span class="ltx_text ltx_font_bold" id="A0.T13.1.4.5.1">0.8543</span></td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.4.6"><span class="ltx_text ltx_font_bold" id="A0.T13.1.4.6.1">0.4829</span></td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.4.7">0.9085</td>
<td class="ltx_td ltx_align_center" id="A0.T13.1.4.8">0.7553</td>
</tr>
<tr class="ltx_tr" id="A0.T13.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T13.1.5.1">MBR-resumed</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T13.1.5.2"><span class="ltx_text ltx_font_bold" id="A0.T13.1.5.2.1">52.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T13.1.5.3"><span class="ltx_text ltx_font_bold" id="A0.T13.1.5.3.1">22.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T13.1.5.4">0.8864</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T13.1.5.5">0.8540</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T13.1.5.6">0.4824</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T13.1.5.7"><span class="ltx_text ltx_font_bold" id="A0.T13.1.5.7.1">0.9086</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T13.1.5.8"><span class="ltx_text ltx_font_bold" id="A0.T13.1.5.8.1">0.7557</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Extended Czech–Ukrainian FLORES-200 test set results for the three MBR self-improvement approaches. All approaches lead to an increase in evaluation scores. Both <span class="ltx_text ltx_font_bold" id="A0.T13.4.1">MBR-ft-high-lr</span> and <span class="ltx_text ltx_font_bold" id="A0.T13.5.2">MBR-resumed</span> models achieve the highest gains, demonstrating comparable performance. </figcaption>
</figure>
<figure class="ltx_table" id="A0.T14">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A0.T14.1">
<tr class="ltx_tr" id="A0.T14.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T14.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T14.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T14.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T14.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T14.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T14.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T14.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T14.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T14.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T14.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T14.1.2.2">58.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T14.1.2.3">31.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T14.1.2.4">0.8721</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T14.1.2.5">0.8046</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T14.1.2.6">0.3744</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T14.1.2.7">0.8795</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T14.1.2.8">0.7498</td>
</tr>
<tr class="ltx_tr" id="A0.T14.1.3">
<td class="ltx_td ltx_align_left" id="A0.T14.1.3.1">MBR-finetuned</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.3.2">60.0</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.3.3">32.3</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.3.4">0.8803</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.3.5">0.8121</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.3.6">0.4112</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.3.7">0.8846</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.3.8">0.7574</td>
</tr>
<tr class="ltx_tr" id="A0.T14.1.4">
<td class="ltx_td ltx_align_left" id="A0.T14.1.4.1">MBR-ft-high-lr</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.4.2"><span class="ltx_text ltx_font_bold" id="A0.T14.1.4.2.1">60.2</span></td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.4.3"><span class="ltx_text ltx_font_bold" id="A0.T14.1.4.3.1">33.2</span></td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.4.4">0.8844</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.4.5">0.8152</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.4.6"><span class="ltx_text ltx_font_bold" id="A0.T14.1.4.6.1">0.4246</span></td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.4.7">0.8880</td>
<td class="ltx_td ltx_align_center" id="A0.T14.1.4.8">0.7619</td>
</tr>
<tr class="ltx_tr" id="A0.T14.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T14.1.5.1">MBR-resumed</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T14.1.5.2">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T14.1.5.3">33.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T14.1.5.4"><span class="ltx_text ltx_font_bold" id="A0.T14.1.5.4.1">0.8852</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T14.1.5.5"><span class="ltx_text ltx_font_bold" id="A0.T14.1.5.5.1">0.8162</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T14.1.5.6">0.4236</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T14.1.5.7"><span class="ltx_text ltx_font_bold" id="A0.T14.1.5.7.1">0.8890</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T14.1.5.8"><span class="ltx_text ltx_font_bold" id="A0.T14.1.5.8.1">0.7639</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Extended Czech–Ukrainian WMT22 test set results for the three MBR self-improvement approaches. As in the case of evaluation results on the FLORES-200 test set, all approaches improve upon the baseline model, although <span class="ltx_text ltx_font_bold" id="A0.T14.3.1">MBR-resumed</span> stands out across all neural metrics apart from UniTE.</figcaption>
</figure>
<figure class="ltx_table" id="A0.T15">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A0.T15.1">
<tr class="ltx_tr" id="A0.T15.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T15.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T15.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T15.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T15.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T15.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T15.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T15.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T15.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T15.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T15.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T15.1.2.2">52.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T15.1.2.3">22.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T15.1.2.4">0.8779</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T15.1.2.5">0.8449</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T15.1.2.6">0.4441</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T15.1.2.7">0.9017</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T15.1.2.8">0.7466</td>
</tr>
<tr class="ltx_tr" id="A0.T15.1.3">
<td class="ltx_td ltx_align_left" id="A0.T15.1.3.1">MBR-resumed</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.3.2">52.7</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.3.3"><span class="ltx_text ltx_font_bold" id="A0.T15.1.3.3.1">22.8</span></td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.3.4">0.8864</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.3.5">0.8540</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.3.6">0.4824</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.3.7">0.9086</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.3.8">0.7557</td>
</tr>
<tr class="ltx_tr" id="A0.T15.1.4">
<td class="ltx_td ltx_align_left" id="A0.T15.1.4.1">MBR-resumed-iter2</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.4.2"><span class="ltx_text ltx_font_bold" id="A0.T15.1.4.2.1">52.8</span></td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.4.3">22.6</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.4.4">0.8888</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.4.5">0.8557</td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.4.6"><span class="ltx_text ltx_font_bold" id="A0.T15.1.4.6.1">0.4882</span></td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.4.7"><span class="ltx_text ltx_font_bold" id="A0.T15.1.4.7.1">0.9099</span></td>
<td class="ltx_td ltx_align_center" id="A0.T15.1.4.8"><span class="ltx_text ltx_font_bold" id="A0.T15.1.4.8.1">0.7567</span></td>
</tr>
<tr class="ltx_tr" id="A0.T15.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T15.1.5.1">MBR-resumed-iter3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T15.1.5.2">52.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T15.1.5.3">22.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T15.1.5.4"><span class="ltx_text ltx_font_bold" id="A0.T15.1.5.4.1">0.8901</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T15.1.5.5"><span class="ltx_text ltx_font_bold" id="A0.T15.1.5.5.1">0.8562</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T15.1.5.6">0.4873</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T15.1.5.7">0.9097</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T15.1.5.8">0.7557</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 15: </span>Extended Czech–Ukrainian iterative self-improvement results on the FLORES-200 test set. Models increase in quality across all neural metrics until the third iteration, when the quality measured by metrics other than COMET and CometKiwi decreases. It’s worth noticing that the BLEU score increases only in the first iteration and slowly degrades in consecutive iterations. </figcaption>
</figure>
<figure class="ltx_table" id="A0.T16">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A0.T16.1">
<tr class="ltx_tr" id="A0.T16.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T16.1.1.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T16.1.1.2">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T16.1.1.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T16.1.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T16.1.1.5">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T16.1.1.6">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T16.1.1.7">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T16.1.1.8">BLEURT</td>
</tr>
<tr class="ltx_tr" id="A0.T16.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T16.1.2.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T16.1.2.2">58.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T16.1.2.3">31.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T16.1.2.4">0.8721</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T16.1.2.5">0.8046</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T16.1.2.6">0.3744</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T16.1.2.7">0.8795</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T16.1.2.8">0.7498</td>
</tr>
<tr class="ltx_tr" id="A0.T16.1.3">
<td class="ltx_td ltx_align_left" id="A0.T16.1.3.1">MBR-resumed</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.3.2">60.0</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.3.3"><span class="ltx_text ltx_font_bold" id="A0.T16.1.3.3.1">33.0</span></td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.3.4">0.8852</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.3.5">0.8162</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.3.6">0.4236</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.3.7">0.8890</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.3.8">0.7639</td>
</tr>
<tr class="ltx_tr" id="A0.T16.1.4">
<td class="ltx_td ltx_align_left" id="A0.T16.1.4.1">MBR-resumed-iter2</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.4.2"><span class="ltx_text ltx_font_bold" id="A0.T16.1.4.2.1">60.3</span></td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.4.3">32.6</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.4.4">0.8885</td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.4.5"><span class="ltx_text ltx_font_bold" id="A0.T16.1.4.5.1">0.8183</span></td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.4.6"><span class="ltx_text ltx_font_bold" id="A0.T16.1.4.6.1">0.4349</span></td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.4.7"><span class="ltx_text ltx_font_bold" id="A0.T16.1.4.7.1">0.8900</span></td>
<td class="ltx_td ltx_align_center" id="A0.T16.1.4.8"><span class="ltx_text ltx_font_bold" id="A0.T16.1.4.8.1">0.7641</span></td>
</tr>
<tr class="ltx_tr" id="A0.T16.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T16.1.5.1">MBR-resumed-iter3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T16.1.5.2">60.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T16.1.5.3">31.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T16.1.5.4"><span class="ltx_text ltx_font_bold" id="A0.T16.1.5.4.1">0.8896</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T16.1.5.5">0.8174</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T16.1.5.6">0.4312</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T16.1.5.7">0.8887</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T16.1.5.8">0.7578</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 16: </span>Extended Czech–Ukrainian iterative self-improvement results on the WMT22 test set. Evaluations across all metrics show similar tendencies as in the case of FLORES-200, except for CometKiwi which also decreases in the third iteration.</figcaption>
</figure>
<figure class="ltx_table" id="A0.T17">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A0.T17.1">
<tr class="ltx_tr" id="A0.T17.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T17.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.4" style="padding-left:3.0pt;padding-right:3.0pt;">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.5" style="padding-left:3.0pt;padding-right:3.0pt;">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.6" style="padding-left:3.0pt;padding-right:3.0pt;">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.7" style="padding-left:3.0pt;padding-right:3.0pt;">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.8" style="padding-left:3.0pt;padding-right:3.0pt;">BLEURT</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T17.1.1.9" style="padding-left:3.0pt;padding-right:3.0pt;">AfriCOMET</td>
</tr>
<tr class="ltx_tr" id="A0.T17.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T17.1.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">49.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.3" style="padding-left:3.0pt;padding-right:3.0pt;">22.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.4" style="padding-left:3.0pt;padding-right:3.0pt;">0.7569</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.5" style="padding-left:3.0pt;padding-right:3.0pt;">0.5597</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.6" style="padding-left:3.0pt;padding-right:3.0pt;">-0.2297</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.7" style="padding-left:3.0pt;padding-right:3.0pt;">0.6082</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.8" style="padding-left:3.0pt;padding-right:3.0pt;">0.7931</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T17.1.2.9" style="padding-left:3.0pt;padding-right:3.0pt;">0.6984</td>
</tr>
<tr class="ltx_tr" id="A0.T17.1.3">
<td class="ltx_td ltx_align_left" id="A0.T17.1.3.1" style="padding-left:3.0pt;padding-right:3.0pt;">MBR-COMET</td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.2" style="padding-left:3.0pt;padding-right:3.0pt;">50.9</td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.3" style="padding-left:3.0pt;padding-right:3.0pt;">23.2</td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.3.4.1">0.7720</span></td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.3.5.1">0.5707</span></td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.3.6.1">-0.1777</span></td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.3.7.1">0.6233</span></td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.3.8.1">0.8083</span></td>
<td class="ltx_td ltx_align_center" id="A0.T17.1.3.9" style="padding-left:3.0pt;padding-right:3.0pt;">0.7207</td>
</tr>
<tr class="ltx_tr" id="A0.T17.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T17.1.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">MBR-AfriCOMET</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.4.2.1">51.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.4.3.1">23.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.4" style="padding-left:3.0pt;padding-right:3.0pt;">0.7692</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.5" style="padding-left:3.0pt;padding-right:3.0pt;">0.5638</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.6" style="padding-left:3.0pt;padding-right:3.0pt;">-0.1878</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.7" style="padding-left:3.0pt;padding-right:3.0pt;">0.6183</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.8" style="padding-left:3.0pt;padding-right:3.0pt;">0.8061</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T17.1.4.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T17.1.4.9.1">0.7239</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 17: </span>Extended English–Hausa results on the FLORES-200 test set. According to lexical metrics and AfriCOMET, the <span class="ltx_text ltx_font_bold" id="A0.T17.4.1">MBR-AfriCOMET</span> model shows the greatest improvement. However, other neural metrics suggest that the <span class="ltx_text ltx_font_bold" id="A0.T17.5.2">MBR-COMET</span> model is superior.</figcaption>
</figure>
<figure class="ltx_table" id="A0.T18">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A0.T18.1">
<tr class="ltx_tr" id="A0.T18.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T18.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.4" style="padding-left:3.0pt;padding-right:3.0pt;">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.5" style="padding-left:3.0pt;padding-right:3.0pt;">CometKiwi</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.6" style="padding-left:3.0pt;padding-right:3.0pt;">UniTE</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.7" style="padding-left:3.0pt;padding-right:3.0pt;">UniTE-DA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.8" style="padding-left:3.0pt;padding-right:3.0pt;">BLEURT</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T18.1.1.9" style="padding-left:3.0pt;padding-right:3.0pt;">AfriCOMET</td>
</tr>
<tr class="ltx_tr" id="A0.T18.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T18.1.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">51.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.3" style="padding-left:3.0pt;padding-right:3.0pt;">23.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.4" style="padding-left:3.0pt;padding-right:3.0pt;">0.7596</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.5" style="padding-left:3.0pt;padding-right:3.0pt;">0.5704</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.6" style="padding-left:3.0pt;padding-right:3.0pt;">-0.1763</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.7" style="padding-left:3.0pt;padding-right:3.0pt;">0.6294</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.8" style="padding-left:3.0pt;padding-right:3.0pt;">0.7791</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T18.1.2.9" style="padding-left:3.0pt;padding-right:3.0pt;">0.6800</td>
</tr>
<tr class="ltx_tr" id="A0.T18.1.3">
<td class="ltx_td ltx_align_left" id="A0.T18.1.3.1" style="padding-left:3.0pt;padding-right:3.0pt;">MBR-COMET</td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.3.2.1">53.1</span></td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.3.3.1">25.3</span></td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.3.4.1">0.7752</span></td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.3.5.1">0.5865</span></td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.3.6.1">-0.1051</span></td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.3.7.1">0.6484</span></td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.3.8.1">0.7986</span></td>
<td class="ltx_td ltx_align_center" id="A0.T18.1.3.9" style="padding-left:3.0pt;padding-right:3.0pt;">0.7046</td>
</tr>
<tr class="ltx_tr" id="A0.T18.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T18.1.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">MBR-AfriCOMET</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.2" style="padding-left:3.0pt;padding-right:3.0pt;">53.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.3" style="padding-left:3.0pt;padding-right:3.0pt;">24.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.4" style="padding-left:3.0pt;padding-right:3.0pt;">0.7721</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.5" style="padding-left:3.0pt;padding-right:3.0pt;">0.5803</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.6" style="padding-left:3.0pt;padding-right:3.0pt;">-0.1273</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.7" style="padding-left:3.0pt;padding-right:3.0pt;">0.6409</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.8" style="padding-left:3.0pt;padding-right:3.0pt;">0.7956</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T18.1.4.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="A0.T18.1.4.9.1">0.7062</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 18: </span>Extended English–Hausa results on the NTREX test set. In contrast to evaluations on the FLORES-200 test set, in this case only the AfriCOMET metric favours the <span class="ltx_text ltx_font_bold" id="A0.T18.3.1">MBR-AfriCOMET</span> model.</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="417" id="A0.F4.g1" src="extracted/5606863/img/appendix/bs_vs_topk/Krs-test-num-samples.png" width="621"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Comparison of beam search and top-k algorithms of the <span class="ltx_text ltx_font_bold" id="A0.F4.2.1">Mix-tune</span> English–German model for the khresmoi test set. Top-k algorithm with temperature 1.0 showed superior performance on neural metrics over top-k with temperature 0.1 and slightly better performance than beam search. However, beam search achieved the highest score on the chrF metric, while the top-k algorithm with temperature 1.0 had the lowest score for lexical metrics (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="417" id="A0.F5.g1" src="extracted/5606863/img/appendix/bs_vs_topk/Flores-test-num-samples.png" width="621"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Comparison of beam search and top-k algorithms of the <span class="ltx_text ltx_font_bold" id="A0.F5.2.1">baseline</span> Czech–Ukrainian model for the FLORES-200 test set. Beam search seems to be the superior option with the best performance on every metric except COMET (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A0.F6.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/beam_en_de_krs.png" width="626"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparison of beam search performance with a different number of samples of the <span class="ltx_text ltx_font_bold" id="A0.F6.2.1">Mix-tune</span> English–German model for the khresmoi test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains and performance on the n-gram metrics deteriorated (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="342" id="A0.F7.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/beam_en_de_flores.png" width="626"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Comparison of beam search performance with a different number of samples of the <span class="ltx_text ltx_font_bold" id="A0.F7.2.1">Mix-tune</span> English–German model for the FLORES-200 test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains and performance on the n-gram metrics deteriorated (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A0.F8.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/topk_en_de_krs_0_1.png" width="626"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Comparison of top-k performance (temperature 0.1, k=10) with different number of samples of the <span class="ltx_text ltx_font_bold" id="A0.F8.2.1">Mix-tune</span> English–German model for the khresmoi test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A0.F9.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/topk_en_de_krs_1_0.png" width="621"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Comparison of top-k performance (temperature 1.0, k=10) with different number of samples of the <span class="ltx_text ltx_font_bold" id="A0.F9.2.1">Mix-tune</span> English–German model for the khresmoi test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A0.F10.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/beam_cs_uk_flores.png" width="626"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Comparison of beam search performance with different number of samples of the <span class="ltx_text ltx_font_bold" id="A0.F10.2.1">Baseline</span> Czech–Ukrainian model for the FLORES-200 test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains and performance on the n-gram metrics deteriorated (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A0.F11.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/topk_cs_uk_flores_0_1.png" width="626"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Comparison of top-k performance (temperature 0.1, k=10) with different number of samples of the <span class="ltx_text ltx_font_bold" id="A0.F11.2.1">Baseline</span> Czech–Ukrainian model for the FLORES-200 test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A0.F12.g1" src="extracted/5606863/img/appendix/diffrent_mbr_sample/topk_cs_uk_flores_1_0.png" width="626"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Comparison of top-k performance (temperature 1.0, k=10) with different number of samples of the <span class="ltx_text ltx_font_bold" id="A0.F12.2.1">Baseline</span> Czech–Ukrainian model for the FLORES-200 test set. Initial increases in the number of samples for MBR decoding showed very rapid gains, but further increases no longer resulted in such large gains (translation without MBR decoding is represented on the chart as the number of translation candidates equal to 0).</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon May 20 10:18:59 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
