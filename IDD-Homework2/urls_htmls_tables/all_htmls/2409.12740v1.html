<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling</title>
<!--Generated on Thu Sep 19 13:02:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.12740v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S1" title="In HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S2" title="In HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S2.SSx1" title="In 2 Related Work ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Traditional Recommender Systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S2.SSx2" title="In 2 Related Work ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Recommendation with Language Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3" title="In HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.SSx1" title="In 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Problem Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.SSx2" title="In 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Hierarchical Large Language Model Architecture</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.SSx2.SSSx1" title="In Hierarchical Large Language Model Architecture ‣ 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Item LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.SSx2.SSSx2" title="In Hierarchical Large Language Model Architecture ‣ 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">User LLM</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.SSx3" title="In 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Training for Recommendation Objectives</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.SSx3.SSSx1" title="In Training for Recommendation Objectives ‣ 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Generative Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.SSx3.SSSx2" title="In Training for Recommendation Objectives ‣ 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Discriminative Recommendation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4" title="In HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.SSx1" title="In 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Datasets and Evaluation Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.SSx2" title="In 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Baselines and Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.SSx3" title="In 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Pre-training and Fine-tuning (RQ1)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.SSx4" title="In 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Scaling Up (RQ2)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.SSx5" title="In 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">HLLM vs. SOTA Methods (RQ3)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.SSx6" title="In 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Training and Serving Effeciency (RQ4)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.SSx7" title="In 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Online A/B Test</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S5" title="In HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1" title="In HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>More Experiments on Academic Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.SSx1" title="In Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Textual Input Length and Richness of Item LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.SSx2" title="In Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Method of Item LLM Feature Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.SSx3" title="In Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Sequence Length of User LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.SSx4" title="In Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Compatibility with ID-based Features</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2" title="In HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Scaling Up of HLLM on Industrial Dataset</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2.SSx1" title="In Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Sequence Length of User LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2.SSx2" title="In Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_title">Parameters of Item LLM and User LLM</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Junyi Chen,
Lu Chi<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>,
Bingyue Peng,
Zehuan Yuan<math alttext="{}^{\text{\textdagger}}" class="ltx_Math" display="inline" id="id2.2.m1.1"><semantics id="id2.2.m1.1a"><msup id="id2.2.m1.1.1" xref="id2.2.m1.1.1.cmml"><mi id="id2.2.m1.1.1a" xref="id2.2.m1.1.1.cmml"></mi><mtext id="id2.2.m1.1.1.1" xref="id2.2.m1.1.1.1a.cmml">†</mtext></msup><annotation-xml encoding="MathML-Content" id="id2.2.m1.1b"><apply id="id2.2.m1.1.1.cmml" xref="id2.2.m1.1.1"><ci id="id2.2.m1.1.1.1a.cmml" xref="id2.2.m1.1.1.1"><mtext id="id2.2.m1.1.1.1.cmml" mathsize="70%" xref="id2.2.m1.1.1.1">†</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m1.1c">{}^{\text{\textdagger}}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m1.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>
</span><span class="ltx_author_notes">Equal contribution. <math alttext="{}^{\text{\textdagger}}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><msup id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1a" xref="id1.1.m1.1.1.cmml"></mi><mtext id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1a.cmml">†</mtext></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><ci id="id1.1.m1.1.1.1a.cmml" xref="id1.1.m1.1.1.1"><mtext id="id1.1.m1.1.1.1.cmml" mathsize="70%" xref="id1.1.m1.1.1.1">†</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">{}^{\text{\textdagger}}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>Corresponding author.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Large Language Models (LLMs) have achieved remarkable success in various fields, prompting several studies to explore their potential in recommendation systems. However, these attempts have so far resulted in only modest improvements over traditional recommendation models. Moreover, three critical questions remain under-explored: firstly, the real value of LLMs’ pre-trained weights, often considered to encapsulate world knowledge; secondly, the necessity of fine-tuning for recommendation tasks; lastly, whether LLMs can exhibit the same scalability benefits in recommendation systems as they do in other domains.
In this paper, we propose a novel <span class="ltx_text ltx_font_bold" id="id3.id1.1">H</span>ierarchical <span class="ltx_text ltx_font_bold" id="id3.id1.2">L</span>arge <span class="ltx_text ltx_font_bold" id="id3.id1.3">L</span>anguage <span class="ltx_text ltx_font_bold" id="id3.id1.4">M</span>odel (HLLM) architecture designed to enhance sequential recommendation systems. Our approach employs a two-tier model: the first Item LLM extracts rich content features from the detailed text description of the item, while the second User LLM utilizes these features to predict users’ future interests based on their interaction history.
Extensive experiments demonstrate that our method effectively leverages the pre-trained capabilities of open-source LLMs, and further fine-tuning leads to significant performance boosts. Additionally, HLLM achieves excellent scalability, with the largest configuration utilizing 7B parameters for both item feature extraction and user interest modeling.
Moreover, HLLM offers excellent training and serving efficiency, making it practical in real-world applications.
Evaluations on two large-scale datasets, PixelRec and Amazon Reviews, show that HLLM achieves state-of-the-art results, outperforming traditional ID-based models by a wide margin.
In online A/B testing, HLLM showcases notable gains, validating its practical impact in real-world recommendation scenarios. Codes are available at <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/bytedance/HLLM</span>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The recommendation algorithm is a classic yet complex problem that requires understanding user interests to predict future behaviors across various items. The key to effective recommendation lies in accurately modeling both item and user features. Currently, mainstream approaches are predominantly ID-based, converting items and users into IDs and creating corresponding embedding tables for encoding <cite class="ltx_cite ltx_citemacro_citep">(Goldberg et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib9" title="">1992</a>; Koren, Bell, and Volinsky <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib15" title="">2009</a>; Sarwar et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib26" title="">2001</a>)</cite>.
To capture diverse and temporally varying user interests, several sequential modeling methods have been developed, demonstrating notable success in sequential recommendations <cite class="ltx_cite ltx_citemacro_citep">(Hidasi et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib11" title="">2015</a>; Zhou et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib44" title="">2018</a>; Kang and McAuley <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib13" title="">2018</a>; Sun et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib28" title="">2019</a>)</cite>. However, these methods are typically dominated by embedding parameters and have relatively small model sizes, leading to two major drawbacks: a heavy reliance on ID features which results in poor performance in cold-start scenarios, and relatively shallow neural networks find it difficult to model complex and diverse user interests.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">With the advent of ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib24" title="">2022</a>)</cite>, large language models (LLMs) have achieved significant breakthroughs across various domains, showcasing impressive world knowledge and reasoning capabilities <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib30" title="">2023</a>; Achiam et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib1" title="">2023</a>; Team et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib29" title="">2023</a>)</cite>. This success has spurred interest among researchers in exploring the integration of LLMs into recommendation systems <cite class="ltx_cite ltx_citemacro_citep">(Wu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib34" title="">2023</a>; Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib17" title="">2023b</a>)</cite>. These explorations can be broadly categorized into three approaches: (1). Utilizing LLMs to provide refined or supplementary information for recommendation systems <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib39" title="">2024a</a>; Ren et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib25" title="">2024</a>; Xi et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib35" title="">2023</a>)</cite>, such as summary of user behavior and item information expansion. (2). Transforming the recommendation system into a dialogue-driven format compatible with LLMs <cite class="ltx_cite ltx_citemacro_citep">(Bao et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib4" title="">2023</a>; Friedman et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib8" title="">2023</a>; Zhang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib40" title="">2023</a>; Yang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib36" title="">2023</a>; Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib38" title="">2023</a>)</cite>. (3). Modifying LLMs to handle recommendation tasks beyond just text input and output. This includes approaches that input ID features into LLMs <cite class="ltx_cite ltx_citemacro_citep">(Ning et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib22" title="">2024</a>; Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>; Liao et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib19" title="">2024</a>)</cite> and those that replace existing models with LLMs, optimizing directly for objectives like Click-Through Rate (CTR) <cite class="ltx_cite ltx_citemacro_citep">(Cui et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib6" title="">2022</a>; Kang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib14" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Despite these advancements, integrating LLMs with recommendation systems presents notable challenges in complexity and effectiveness. One issue is that inputting user behavior history as text to LLMs results in very long input sequences. Consequently, LLMs need longer sequences to represent the same time span of user behavior than ID-based methods, while the complexity of the self-attention module in LLMs scales quadratically with the sequence length.
Additionally, recommending a single item requires generating several text tokens, leading to multiple forwards and resulting in lower efficiency.
In terms of effectiveness, the performance improvements of existing LLM-based methods over traditional methods are not significant, raising questions about whether the potential of LLMs has been fully realized.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Moreover, some critical issues remain underexplored. Firstly, the actual value of pre-trained LLM weights, often regarded as encapsulating world knowledge, needs further investigation. While LLMs offer impressive zero-shot and few-shot capabilities, their value when training on large-scale recommendation data is unclear. Secondly, the necessity of fine-tuning for recommendation tasks is in question. LLMs pre-trained on massive corpora exhibit strong world knowledge, but whether further fine-tuning on recommendation tasks enhances or diminishes performance remains to be seen. Lastly, the scalability of LLMs, a hallmark characteristic with proven scaling laws in other domains, requires validation in the context of recommendation systems. While some studies have successfully validated the scaling laws in the recommendation domain <cite class="ltx_cite ltx_citemacro_citep">(Shin et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib27" title="">2023</a>; Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite>, these models have considerably fewer parameters compared to LLMs. Whether models exceeding 1 billion parameters exhibit good scalability in the recommendation domain remains an open question.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To address these challenges, this paper proposes the <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">H</span>ierarchical <span class="ltx_text ltx_font_bold" id="S1.p5.1.2">L</span>arge <span class="ltx_text ltx_font_bold" id="S1.p5.1.3">L</span>anguage <span class="ltx_text ltx_font_bold" id="S1.p5.1.4">M</span>odel (HLLM) architecture. The approach begins by using an LLM to extract item features. To empower the LLM to effectively extract these features, a special token is appended to the end of the detailed textual description of each item. This augmented description is then input into the LLM (referred to as the Item LLM), and the output corresponding to the special token is used as the item feature. These item features are then input into a second LLM (referred to as the User LLM) to model user interest and predict future behaviors. By transforming extensive item descriptions into concise embeddings, the length of behavior sequences is reduced to that of ID-based models, significantly lowering computational complexity compared to other text-based LLM recommendation models. We also verified that HLLM has a significant training efficiency advantage compared to ID-based models, as it can surpass ID-based models with only a small amount of training data.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Extensive experiments are conducted to explore the value of pre-training. Although the HLLM does not employ text interaction in the conventional manner of standard LLMs, such as the Item LLM being designed as a feature extractor, and both input and output of the User LLM being item embeddings, the pre-trained weights have proven beneficial for both types of LLMs. This demonstrates that the world knowledge embedded in LLMs is indeed valuable for recommendations. Nevertheless, this does not obviate the need for fine-tuning towards recommendation objectives. Conversely, our experiments indicate that such fine-tuning is crucial for surpassing traditional methods. To verify scalability, experiments on large academic datasets confirm that LLMs exhibit excellent scalability with performance improving as model parameters increase. Within the limited resources, models up to 7 billion parameters show consistent performance gains with increasing size.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Ultimately, the proposed HLLM architecture outperforms existing methods across multiple academic datasets, achieving state-of-the-art results. More importantly, the effectiveness of HLLM is also validated through real-world online A/B testing, confirming its practical applicability.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">Our main contributions can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">1) A novel hierarchical LLM (HLLM) framework is introduced for sequential recommendations. This approach significantly outperforms classical ID-based models on large-scale academic datasets and has been validated to yield tangible benefits in real-world industrial settings. Additionally, this method demonstrates excellent training and serving efficiency.</p>
</div>
<div class="ltx_para" id="S1.p10">
<p class="ltx_p" id="S1.p10.1">2) HLLM effectively transfers the world knowledge encoded during the LLM pre-training stage into the recommendation model, encompassing both item feature extraction and user interest modeling. Nevertheless, task-specific fine-tuning with recommendation objectives is essential.</p>
</div>
<div class="ltx_para" id="S1.p11">
<p class="ltx_p" id="S1.p11.1">3) HLLM exhibits excellent scalability, with performance continuously improving as the data volume and model parameters increase. This scalability highlights the potential of the proposed approach when applied to even larger datasets and model sizes.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Traditional Recommender Systems</h3>
<div class="ltx_para" id="S2.SSx1.p1">
<p class="ltx_p" id="S2.SSx1.p1.1">Traditional Recommender Systems predominantly rely on ID-based embeddings, and how to design feature interactions is an important topic. DeepFM <cite class="ltx_cite ltx_citemacro_citep">(Guo et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib10" title="">2017</a>)</cite> models low-order feature interactions with FM and models high-order feature interactions with DNN. DCN <cite class="ltx_cite ltx_citemacro_citep">(Wang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib32" title="">2017</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib33" title="">2021</a>)</cite> can model higher-order interactions by explicitly applying feature crossing at each layer. Besides, some researchers make efforts to model user interests from their historical behavior. For instance, DIN <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib44" title="">2018</a>)</cite> and DIEN <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib43" title="">2019</a>)</cite> introduce attention mechanisms to capture user’s diverse interests from historical behaviors. Inspired by transformer, SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib13" title="">2018</a>)</cite> applies self-attention
mechanisms to sequential recommendation. CLUE <cite class="ltx_cite ltx_citemacro_citep">(Shin et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib27" title="">2023</a>)</cite> and HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite> demonstrate that models with parameter counts within hundreds of millions adhere to the scaling law. Some works have also introduced content features into recommendation models, showing certain advantages in generalization <cite class="ltx_cite ltx_citemacro_citep">(Baltescu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib3" title="">2022</a>; Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib16" title="">2023a</a>; Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib5" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Recommendation with Language Models</h3>
<div class="ltx_para" id="S2.SSx2.p1">
<p class="ltx_p" id="S2.SSx2.p1.1">The success of LLMs has attracted many researchers to explore their applications in recommendation systems. These explorations can be categorized into three types. Firstly, LLMs are used for summarizing or supplementing information about users or items <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib39" title="">2024a</a>; Ren et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib25" title="">2024</a>; Xi et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib35" title="">2023</a>)</cite>. For example, RLMRec <cite class="ltx_cite ltx_citemacro_citep">(Ren et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib25" title="">2024</a>)</cite> develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework. LLMs are also employed to generate augmented training signals for coldstart items <cite class="ltx_cite ltx_citemacro_citep">(Wang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib31" title="">2024</a>)</cite>.
Secondly, some works adapt the recommendation domain data into conversational formats <cite class="ltx_cite ltx_citemacro_citep">(Bao et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib4" title="">2023</a>; Friedman et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib8" title="">2023</a>; Zhang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib40" title="">2023</a>; Yang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib36" title="">2023</a>; Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib38" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1094" id="S2.F1.g1" src="x1.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Architecture of Hierarchical Large Language Model.
HLLM consists of two LLMs with non-shared parameters: Item LLM and User LLM. The Item LLM takes the text description of an item as input, appended with a special token <span class="ltx_text ltx_font_typewriter" id="S2.F1.2.1">[ITEM]</span>, and outputs the item embedding. The User LLM inputs the item embeddings of the user’s historical interactions and predicts next item. All LLM parameters are trainable and optimized via next item prediction.
</figcaption>
</figure>
<div class="ltx_para" id="S2.SSx2.p2">
<p class="ltx_p" id="S2.SSx2.p2.1">Some approaches treat the recommendation task as a special form of instruction-following, inputting user historical behaviors in text form to the LLM to predict subsequent actions <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib18" title="">2024</a>)</cite>. Lastly, there are also some works that have adapted LLMs for recommendation tasks, allowing their inputs or outputs to go beyond just textual forms. LLaRA <cite class="ltx_cite ltx_citemacro_citep">(Liao et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib19" title="">2024</a>)</cite> proposed a novel hybrid prompting method that integrates ID-based item embeddings with textual item features. LEARN <cite class="ltx_cite ltx_citemacro_citep">(Jia et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib12" title="">2024</a>)</cite> utilizes pre-trained LLMs to extract item features. LLMs are also adapted to multi-class classification or regression for rating prediction <cite class="ltx_cite ltx_citemacro_citep">(Kang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib14" title="">2023</a>)</cite>. However, these methods offer limited improvements compared to traditional recommendation models.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we first introduce the problem formulation, and then propose <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">H</span>ierarchical <span class="ltx_text ltx_font_bold" id="S3.p1.1.2">L</span>arge <span class="ltx_text ltx_font_bold" id="S3.p1.1.3">L</span>anguage <span class="ltx_text ltx_font_bold" id="S3.p1.1.4">M</span>odel (HLLM) with a detailed explanation of how to adapt pre-trained large language models to recommendation systems, including item feature extraction and user interest modeling. Finally we discuss how to align HLLM with the objectives of recommendation systems, thereby significantly enhancing its performance on recommendation tasks.</p>
</div>
<section class="ltx_subsection" id="S3.SSx1">
<h3 class="ltx_title ltx_title_subsection">Problem Formulation</h3>
<div class="ltx_para" id="S3.SSx1.p1">
<p class="ltx_p" id="S3.SSx1.p1.8">We study the task of sequential recommendations, formulated as: Given a user <math alttext="u\in\mathcal{U}" class="ltx_Math" display="inline" id="S3.SSx1.p1.1.m1.1"><semantics id="S3.SSx1.p1.1.m1.1a"><mrow id="S3.SSx1.p1.1.m1.1.1" xref="S3.SSx1.p1.1.m1.1.1.cmml"><mi id="S3.SSx1.p1.1.m1.1.1.2" xref="S3.SSx1.p1.1.m1.1.1.2.cmml">u</mi><mo id="S3.SSx1.p1.1.m1.1.1.1" xref="S3.SSx1.p1.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SSx1.p1.1.m1.1.1.3" xref="S3.SSx1.p1.1.m1.1.1.3.cmml">𝒰</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.1.m1.1b"><apply id="S3.SSx1.p1.1.m1.1.1.cmml" xref="S3.SSx1.p1.1.m1.1.1"><in id="S3.SSx1.p1.1.m1.1.1.1.cmml" xref="S3.SSx1.p1.1.m1.1.1.1"></in><ci id="S3.SSx1.p1.1.m1.1.1.2.cmml" xref="S3.SSx1.p1.1.m1.1.1.2">𝑢</ci><ci id="S3.SSx1.p1.1.m1.1.1.3.cmml" xref="S3.SSx1.p1.1.m1.1.1.3">𝒰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.1.m1.1c">u\in\mathcal{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.1.m1.1d">italic_u ∈ caligraphic_U</annotation></semantics></math>, a sequence of user <math alttext="u" class="ltx_Math" display="inline" id="S3.SSx1.p1.2.m2.1"><semantics id="S3.SSx1.p1.2.m2.1a"><mi id="S3.SSx1.p1.2.m2.1.1" xref="S3.SSx1.p1.2.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.2.m2.1b"><ci id="S3.SSx1.p1.2.m2.1.1.cmml" xref="S3.SSx1.p1.2.m2.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.2.m2.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.2.m2.1d">italic_u</annotation></semantics></math>’s historical interactions <math alttext="U=\{I_{1},I_{2},\dots,I_{n}\}" class="ltx_Math" display="inline" id="S3.SSx1.p1.3.m3.4"><semantics id="S3.SSx1.p1.3.m3.4a"><mrow id="S3.SSx1.p1.3.m3.4.4" xref="S3.SSx1.p1.3.m3.4.4.cmml"><mi id="S3.SSx1.p1.3.m3.4.4.5" xref="S3.SSx1.p1.3.m3.4.4.5.cmml">U</mi><mo id="S3.SSx1.p1.3.m3.4.4.4" xref="S3.SSx1.p1.3.m3.4.4.4.cmml">=</mo><mrow id="S3.SSx1.p1.3.m3.4.4.3.3" xref="S3.SSx1.p1.3.m3.4.4.3.4.cmml"><mo id="S3.SSx1.p1.3.m3.4.4.3.3.4" stretchy="false" xref="S3.SSx1.p1.3.m3.4.4.3.4.cmml">{</mo><msub id="S3.SSx1.p1.3.m3.2.2.1.1.1" xref="S3.SSx1.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.SSx1.p1.3.m3.2.2.1.1.1.2" xref="S3.SSx1.p1.3.m3.2.2.1.1.1.2.cmml">I</mi><mn id="S3.SSx1.p1.3.m3.2.2.1.1.1.3" xref="S3.SSx1.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SSx1.p1.3.m3.4.4.3.3.5" xref="S3.SSx1.p1.3.m3.4.4.3.4.cmml">,</mo><msub id="S3.SSx1.p1.3.m3.3.3.2.2.2" xref="S3.SSx1.p1.3.m3.3.3.2.2.2.cmml"><mi id="S3.SSx1.p1.3.m3.3.3.2.2.2.2" xref="S3.SSx1.p1.3.m3.3.3.2.2.2.2.cmml">I</mi><mn id="S3.SSx1.p1.3.m3.3.3.2.2.2.3" xref="S3.SSx1.p1.3.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SSx1.p1.3.m3.4.4.3.3.6" xref="S3.SSx1.p1.3.m3.4.4.3.4.cmml">,</mo><mi id="S3.SSx1.p1.3.m3.1.1" mathvariant="normal" xref="S3.SSx1.p1.3.m3.1.1.cmml">…</mi><mo id="S3.SSx1.p1.3.m3.4.4.3.3.7" xref="S3.SSx1.p1.3.m3.4.4.3.4.cmml">,</mo><msub id="S3.SSx1.p1.3.m3.4.4.3.3.3" xref="S3.SSx1.p1.3.m3.4.4.3.3.3.cmml"><mi id="S3.SSx1.p1.3.m3.4.4.3.3.3.2" xref="S3.SSx1.p1.3.m3.4.4.3.3.3.2.cmml">I</mi><mi id="S3.SSx1.p1.3.m3.4.4.3.3.3.3" xref="S3.SSx1.p1.3.m3.4.4.3.3.3.3.cmml">n</mi></msub><mo id="S3.SSx1.p1.3.m3.4.4.3.3.8" stretchy="false" xref="S3.SSx1.p1.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.3.m3.4b"><apply id="S3.SSx1.p1.3.m3.4.4.cmml" xref="S3.SSx1.p1.3.m3.4.4"><eq id="S3.SSx1.p1.3.m3.4.4.4.cmml" xref="S3.SSx1.p1.3.m3.4.4.4"></eq><ci id="S3.SSx1.p1.3.m3.4.4.5.cmml" xref="S3.SSx1.p1.3.m3.4.4.5">𝑈</ci><set id="S3.SSx1.p1.3.m3.4.4.3.4.cmml" xref="S3.SSx1.p1.3.m3.4.4.3.3"><apply id="S3.SSx1.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SSx1.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SSx1.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SSx1.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SSx1.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.SSx1.p1.3.m3.2.2.1.1.1.2">𝐼</ci><cn id="S3.SSx1.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S3.SSx1.p1.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S3.SSx1.p1.3.m3.3.3.2.2.2.cmml" xref="S3.SSx1.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SSx1.p1.3.m3.3.3.2.2.2.1.cmml" xref="S3.SSx1.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.SSx1.p1.3.m3.3.3.2.2.2.2.cmml" xref="S3.SSx1.p1.3.m3.3.3.2.2.2.2">𝐼</ci><cn id="S3.SSx1.p1.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S3.SSx1.p1.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S3.SSx1.p1.3.m3.1.1.cmml" xref="S3.SSx1.p1.3.m3.1.1">…</ci><apply id="S3.SSx1.p1.3.m3.4.4.3.3.3.cmml" xref="S3.SSx1.p1.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SSx1.p1.3.m3.4.4.3.3.3.1.cmml" xref="S3.SSx1.p1.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S3.SSx1.p1.3.m3.4.4.3.3.3.2.cmml" xref="S3.SSx1.p1.3.m3.4.4.3.3.3.2">𝐼</ci><ci id="S3.SSx1.p1.3.m3.4.4.3.3.3.3.cmml" xref="S3.SSx1.p1.3.m3.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.3.m3.4c">U=\{I_{1},I_{2},\dots,I_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.3.m3.4d">italic_U = { italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> in chronological order, predict the next item <math alttext="I_{n+1}" class="ltx_Math" display="inline" id="S3.SSx1.p1.4.m4.1"><semantics id="S3.SSx1.p1.4.m4.1a"><msub id="S3.SSx1.p1.4.m4.1.1" xref="S3.SSx1.p1.4.m4.1.1.cmml"><mi id="S3.SSx1.p1.4.m4.1.1.2" xref="S3.SSx1.p1.4.m4.1.1.2.cmml">I</mi><mrow id="S3.SSx1.p1.4.m4.1.1.3" xref="S3.SSx1.p1.4.m4.1.1.3.cmml"><mi id="S3.SSx1.p1.4.m4.1.1.3.2" xref="S3.SSx1.p1.4.m4.1.1.3.2.cmml">n</mi><mo id="S3.SSx1.p1.4.m4.1.1.3.1" xref="S3.SSx1.p1.4.m4.1.1.3.1.cmml">+</mo><mn id="S3.SSx1.p1.4.m4.1.1.3.3" xref="S3.SSx1.p1.4.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.4.m4.1b"><apply id="S3.SSx1.p1.4.m4.1.1.cmml" xref="S3.SSx1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SSx1.p1.4.m4.1.1.1.cmml" xref="S3.SSx1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SSx1.p1.4.m4.1.1.2.cmml" xref="S3.SSx1.p1.4.m4.1.1.2">𝐼</ci><apply id="S3.SSx1.p1.4.m4.1.1.3.cmml" xref="S3.SSx1.p1.4.m4.1.1.3"><plus id="S3.SSx1.p1.4.m4.1.1.3.1.cmml" xref="S3.SSx1.p1.4.m4.1.1.3.1"></plus><ci id="S3.SSx1.p1.4.m4.1.1.3.2.cmml" xref="S3.SSx1.p1.4.m4.1.1.3.2">𝑛</ci><cn id="S3.SSx1.p1.4.m4.1.1.3.3.cmml" type="integer" xref="S3.SSx1.p1.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.4.m4.1c">I_{n+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.4.m4.1d">italic_I start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="n" class="ltx_Math" display="inline" id="S3.SSx1.p1.5.m5.1"><semantics id="S3.SSx1.p1.5.m5.1a"><mi id="S3.SSx1.p1.5.m5.1.1" xref="S3.SSx1.p1.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.5.m5.1b"><ci id="S3.SSx1.p1.5.m5.1.1.cmml" xref="S3.SSx1.p1.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.5.m5.1d">italic_n</annotation></semantics></math> is the length of <math alttext="U" class="ltx_Math" display="inline" id="S3.SSx1.p1.6.m6.1"><semantics id="S3.SSx1.p1.6.m6.1a"><mi id="S3.SSx1.p1.6.m6.1.1" xref="S3.SSx1.p1.6.m6.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.6.m6.1b"><ci id="S3.SSx1.p1.6.m6.1.1.cmml" xref="S3.SSx1.p1.6.m6.1.1">𝑈</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.6.m6.1c">U</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.6.m6.1d">italic_U</annotation></semantics></math> and <math alttext="I\in\mathcal{I}" class="ltx_Math" display="inline" id="S3.SSx1.p1.7.m7.1"><semantics id="S3.SSx1.p1.7.m7.1a"><mrow id="S3.SSx1.p1.7.m7.1.1" xref="S3.SSx1.p1.7.m7.1.1.cmml"><mi id="S3.SSx1.p1.7.m7.1.1.2" xref="S3.SSx1.p1.7.m7.1.1.2.cmml">I</mi><mo id="S3.SSx1.p1.7.m7.1.1.1" xref="S3.SSx1.p1.7.m7.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SSx1.p1.7.m7.1.1.3" xref="S3.SSx1.p1.7.m7.1.1.3.cmml">ℐ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.7.m7.1b"><apply id="S3.SSx1.p1.7.m7.1.1.cmml" xref="S3.SSx1.p1.7.m7.1.1"><in id="S3.SSx1.p1.7.m7.1.1.1.cmml" xref="S3.SSx1.p1.7.m7.1.1.1"></in><ci id="S3.SSx1.p1.7.m7.1.1.2.cmml" xref="S3.SSx1.p1.7.m7.1.1.2">𝐼</ci><ci id="S3.SSx1.p1.7.m7.1.1.3.cmml" xref="S3.SSx1.p1.7.m7.1.1.3">ℐ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.7.m7.1c">I\in\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.7.m7.1d">italic_I ∈ caligraphic_I</annotation></semantics></math>. Each item <math alttext="I" class="ltx_Math" display="inline" id="S3.SSx1.p1.8.m8.1"><semantics id="S3.SSx1.p1.8.m8.1a"><mi id="S3.SSx1.p1.8.m8.1.1" xref="S3.SSx1.p1.8.m8.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SSx1.p1.8.m8.1b"><ci id="S3.SSx1.p1.8.m8.1.1.cmml" xref="S3.SSx1.p1.8.m8.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx1.p1.8.m8.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SSx1.p1.8.m8.1d">italic_I</annotation></semantics></math> has its corresponding ID and text information (e.g. title, tag, etc.), but the method proposed in this paper uses only the text information.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SSx2">
<h3 class="ltx_title ltx_title_subsection">Hierarchical Large Language Model Architecture</h3>
<div class="ltx_para" id="S3.SSx2.p1">
<p class="ltx_p" id="S3.SSx2.p1.1">Currently, a considerable number of LLM-based recommendation models flatten users’ historical behaviors into plain text inputs for the LLM <cite class="ltx_cite ltx_citemacro_citep">(Kang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib14" title="">2023</a>; Yang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib36" title="">2023</a>; Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib18" title="">2024</a>)</cite>. This results in very long input sequences, and due to the self-attention module in LLMs, the complexity grows quadratically with the length of the input sequence. To reduce the burden of user sequence modeling, we adopt a hierarchical modeling approach called the <span class="ltx_text ltx_font_bold" id="S3.SSx2.p1.1.1">H</span>ierarchical <span class="ltx_text ltx_font_bold" id="S3.SSx2.p1.1.2">L</span>arge <span class="ltx_text ltx_font_bold" id="S3.SSx2.p1.1.3">L</span>anguage <span class="ltx_text ltx_font_bold" id="S3.SSx2.p1.1.4">M</span>odel (HLLM) that decouples item modeling from user modeling, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S2.F1" title="Figure 1 ‣ Recommendation with Language Models ‣ 2 Related Work ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>. Specifically, we first extract item features using the Item LLM, compressing the complex text descriptions into an embedding representation. Then, we model the user profile based on these item features with the User LLM. Additionally, to ensure better compatibility with pre-trained LLMs and to enhance scalability, we introduce minimal structural changes and design simple yet efficient training objectives. The following is a detailed introduction to item and user modeling.</p>
</div>
<section class="ltx_subsubsection" id="S3.SSx2.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Item LLM</h4>
<div class="ltx_para" id="S3.SSx2.SSSx1.p1">
<p class="ltx_p" id="S3.SSx2.SSSx1.p1.1">is proposed to extract item features. It takes as input the text description of an item and outputs an embedding representation. LLMs have demonstrated excellent performance in text comprehension, but their use has mostly been limited to text generation scenarios, with few works using them as feature extractors. Inspired by previous works <cite class="ltx_cite ltx_citemacro_citep">(Devlin <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib7" title="">2018</a>; Neelakantan et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib21" title="">2022</a>)</cite>, a special token <span class="ltx_text ltx_font_typewriter" id="S3.SSx2.SSSx1.p1.1.1">[ITEM]</span> is added at the end of the item’s text description to extract features.</p>
</div>
<div class="ltx_para" id="S3.SSx2.SSSx1.p2">
<p class="ltx_p" id="S3.SSx2.SSSx1.p2.4">Specifically, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S2.F1" title="Figure 1 ‣ Recommendation with Language Models ‣ 2 Related Work ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>, for Item <math alttext="I" class="ltx_Math" display="inline" id="S3.SSx2.SSSx1.p2.1.m1.1"><semantics id="S3.SSx2.SSSx1.p2.1.m1.1a"><mi id="S3.SSx2.SSSx1.p2.1.m1.1.1" xref="S3.SSx2.SSSx1.p2.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx1.p2.1.m1.1b"><ci id="S3.SSx2.SSSx1.p2.1.m1.1.1.cmml" xref="S3.SSx2.SSSx1.p2.1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx1.p2.1.m1.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx1.p2.1.m1.1d">italic_I</annotation></semantics></math> we first flatten its corresponding textual attributes into the sentence <math alttext="T" class="ltx_Math" display="inline" id="S3.SSx2.SSSx1.p2.2.m2.1"><semantics id="S3.SSx2.SSSx1.p2.2.m2.1a"><mi id="S3.SSx2.SSSx1.p2.2.m2.1.1" xref="S3.SSx2.SSSx1.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx1.p2.2.m2.1b"><ci id="S3.SSx2.SSSx1.p2.2.m2.1.1.cmml" xref="S3.SSx2.SSSx1.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx1.p2.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx1.p2.2.m2.1d">italic_T</annotation></semantics></math>, and prepend it with a fixed prompt.
After passing through the LLM tokenizer, we additionally append a special token <span class="ltx_text ltx_font_typewriter" id="S3.SSx2.SSSx1.p2.4.1">[ITEM]</span> at the end, thus the input token sequence for the Item LLM can be formulated as <math alttext="\{t_{1},t_{2},\dots,t_{m},\texttt{[ITEM]}\}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx1.p2.3.m3.5"><semantics id="S3.SSx2.SSSx1.p2.3.m3.5a"><mrow id="S3.SSx2.SSSx1.p2.3.m3.5.5.3" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml"><mo id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.4" stretchy="false" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml">{</mo><msub id="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1" xref="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.cmml"><mi id="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.2" xref="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.2.cmml">t</mi><mn id="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.3" xref="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.3.cmml">1</mn></msub><mo id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.5" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml">,</mo><msub id="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2" xref="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.cmml"><mi id="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.2" xref="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.2.cmml">t</mi><mn id="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.3" xref="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.3.cmml">2</mn></msub><mo id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.6" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml">,</mo><mi id="S3.SSx2.SSSx1.p2.3.m3.1.1" mathvariant="normal" xref="S3.SSx2.SSSx1.p2.3.m3.1.1.cmml">…</mi><mo id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.7" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml">,</mo><msub id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.cmml"><mi id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.2" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.2.cmml">t</mi><mi id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.3" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.3.cmml">m</mi></msub><mo id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.8" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml">,</mo><mtext class="ltx_mathvariant_monospace" id="S3.SSx2.SSSx1.p2.3.m3.2.2" xref="S3.SSx2.SSSx1.p2.3.m3.2.2a.cmml">[ITEM]</mtext><mo id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.9" stretchy="false" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx1.p2.3.m3.5b"><set id="S3.SSx2.SSSx1.p2.3.m3.5.5.4.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3"><apply id="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.1.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.2.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.2">𝑡</ci><cn id="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.3.cmml" type="integer" xref="S3.SSx2.SSSx1.p2.3.m3.3.3.1.1.3">1</cn></apply><apply id="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2"><csymbol cd="ambiguous" id="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.1.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2">subscript</csymbol><ci id="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.2.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.2">𝑡</ci><cn id="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.3.cmml" type="integer" xref="S3.SSx2.SSSx1.p2.3.m3.4.4.2.2.3">2</cn></apply><ci id="S3.SSx2.SSSx1.p2.3.m3.1.1.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.1.1">…</ci><apply id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3"><csymbol cd="ambiguous" id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.1.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3">subscript</csymbol><ci id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.2.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.2">𝑡</ci><ci id="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.3.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.5.5.3.3.3">𝑚</ci></apply><ci id="S3.SSx2.SSSx1.p2.3.m3.2.2a.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.SSx2.SSSx1.p2.3.m3.2.2.cmml" xref="S3.SSx2.SSSx1.p2.3.m3.2.2">[ITEM]</mtext></ci></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx1.p2.3.m3.5c">\{t_{1},t_{2},\dots,t_{m},\texttt{[ITEM]}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx1.p2.3.m3.5d">{ italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_t start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , [ITEM] }</annotation></semantics></math> where <math alttext="m" class="ltx_Math" display="inline" id="S3.SSx2.SSSx1.p2.4.m4.1"><semantics id="S3.SSx2.SSSx1.p2.4.m4.1a"><mi id="S3.SSx2.SSSx1.p2.4.m4.1.1" xref="S3.SSx2.SSSx1.p2.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx1.p2.4.m4.1b"><ci id="S3.SSx2.SSSx1.p2.4.m4.1.1.cmml" xref="S3.SSx2.SSSx1.p2.4.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx1.p2.4.m4.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx1.p2.4.m4.1d">italic_m</annotation></semantics></math> represents the length of text tokens. The hidden state from the last layer corresponding to the special token <span class="ltx_text ltx_font_typewriter" id="S3.SSx2.SSSx1.p2.4.2">[ITEM]</span> is considered as the item embedding.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SSx2.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">User LLM</h4>
<div class="ltx_para" id="S3.SSx2.SSSx2.p1">
<p class="ltx_p" id="S3.SSx2.SSSx2.p1.7">is designed to model user interests which is another key aspect of recommendation systems.
The original user history sequence <math alttext="U=\{I_{1},I_{2},\dots,I_{n}\}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx2.p1.1.m1.4"><semantics id="S3.SSx2.SSSx2.p1.1.m1.4a"><mrow id="S3.SSx2.SSSx2.p1.1.m1.4.4" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.cmml"><mi id="S3.SSx2.SSSx2.p1.1.m1.4.4.5" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.5.cmml">U</mi><mo id="S3.SSx2.SSSx2.p1.1.m1.4.4.4" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.4.cmml"><mo id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.4.cmml">{</mo><msub id="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1" xref="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.2" xref="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.2.cmml">I</mi><mn id="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.3" xref="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.5" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2" xref="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.2" xref="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.2.cmml">I</mi><mn id="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.3" xref="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.6" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SSx2.SSSx2.p1.1.m1.1.1" mathvariant="normal" xref="S3.SSx2.SSSx2.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.7" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.cmml"><mi id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.2" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.2.cmml">I</mi><mi id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.3" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.3.cmml">n</mi></msub><mo id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx2.p1.1.m1.4b"><apply id="S3.SSx2.SSSx2.p1.1.m1.4.4.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4"><eq id="S3.SSx2.SSSx2.p1.1.m1.4.4.4.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.4"></eq><ci id="S3.SSx2.SSSx2.p1.1.m1.4.4.5.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.5">𝑈</ci><set id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.4.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3"><apply id="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.2">𝐼</ci><cn id="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SSx2.SSSx2.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.2">𝐼</ci><cn id="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SSx2.SSSx2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SSx2.SSSx2.p1.1.m1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.1.1">…</ci><apply id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.2">𝐼</ci><ci id="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.SSx2.SSSx2.p1.1.m1.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx2.p1.1.m1.4c">U=\{I_{1},I_{2},\dots,I_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx2.p1.1.m1.4d">italic_U = { italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> can be transformed into a historical feature sequence <math alttext="\{E_{1},E_{2},\dots,E_{n}\}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx2.p1.2.m2.4"><semantics id="S3.SSx2.SSSx2.p1.2.m2.4a"><mrow id="S3.SSx2.SSSx2.p1.2.m2.4.4.3" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.4.cmml"><mo id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.4" stretchy="false" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.4.cmml">{</mo><msub id="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1" xref="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.cmml"><mi id="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.2" xref="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.2.cmml">E</mi><mn id="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.3" xref="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.5" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.4.cmml">,</mo><msub id="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2" xref="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.cmml"><mi id="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.2" xref="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.2.cmml">E</mi><mn id="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.3" xref="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.6" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.4.cmml">,</mo><mi id="S3.SSx2.SSSx2.p1.2.m2.1.1" mathvariant="normal" xref="S3.SSx2.SSSx2.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.7" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.4.cmml">,</mo><msub id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.cmml"><mi id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.2" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.2.cmml">E</mi><mi id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.3" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.3.cmml">n</mi></msub><mo id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.8" stretchy="false" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx2.p1.2.m2.4b"><set id="S3.SSx2.SSSx2.p1.2.m2.4.4.4.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3"><apply id="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.2.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.2">𝐸</ci><cn id="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.3.cmml" type="integer" xref="S3.SSx2.SSSx2.p1.2.m2.2.2.1.1.3">1</cn></apply><apply id="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.1.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.2">𝐸</ci><cn id="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.3.cmml" type="integer" xref="S3.SSx2.SSSx2.p1.2.m2.3.3.2.2.3">2</cn></apply><ci id="S3.SSx2.SSSx2.p1.2.m2.1.1.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.1.1">…</ci><apply id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.1.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.2.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.2">𝐸</ci><ci id="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SSx2.SSSx2.p1.2.m2.4.4.3.3.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx2.p1.2.m2.4c">\{E_{1},E_{2},\dots,E_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx2.p1.2.m2.4d">{ italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_E start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> through the Item LLM, where <math alttext="E_{i}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx2.p1.3.m3.1"><semantics id="S3.SSx2.SSSx2.p1.3.m3.1a"><msub id="S3.SSx2.SSSx2.p1.3.m3.1.1" xref="S3.SSx2.SSSx2.p1.3.m3.1.1.cmml"><mi id="S3.SSx2.SSSx2.p1.3.m3.1.1.2" xref="S3.SSx2.SSSx2.p1.3.m3.1.1.2.cmml">E</mi><mi id="S3.SSx2.SSSx2.p1.3.m3.1.1.3" xref="S3.SSx2.SSSx2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx2.p1.3.m3.1b"><apply id="S3.SSx2.SSSx2.p1.3.m3.1.1.cmml" xref="S3.SSx2.SSSx2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.3.m3.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.3.m3.1.1.2.cmml" xref="S3.SSx2.SSSx2.p1.3.m3.1.1.2">𝐸</ci><ci id="S3.SSx2.SSSx2.p1.3.m3.1.1.3.cmml" xref="S3.SSx2.SSSx2.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx2.p1.3.m3.1c">E_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx2.p1.3.m3.1d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the item embedding of <math alttext="I_{i}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx2.p1.4.m4.1"><semantics id="S3.SSx2.SSSx2.p1.4.m4.1a"><msub id="S3.SSx2.SSSx2.p1.4.m4.1.1" xref="S3.SSx2.SSSx2.p1.4.m4.1.1.cmml"><mi id="S3.SSx2.SSSx2.p1.4.m4.1.1.2" xref="S3.SSx2.SSSx2.p1.4.m4.1.1.2.cmml">I</mi><mi id="S3.SSx2.SSSx2.p1.4.m4.1.1.3" xref="S3.SSx2.SSSx2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx2.p1.4.m4.1b"><apply id="S3.SSx2.SSSx2.p1.4.m4.1.1.cmml" xref="S3.SSx2.SSSx2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.4.m4.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.4.m4.1.1.2.cmml" xref="S3.SSx2.SSSx2.p1.4.m4.1.1.2">𝐼</ci><ci id="S3.SSx2.SSSx2.p1.4.m4.1.1.3.cmml" xref="S3.SSx2.SSSx2.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx2.p1.4.m4.1c">I_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx2.p1.4.m4.1d">italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
The User LLM takes this historical feature sequence as input and predict next item embedding based on a sequence of previous interactions. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S2.F1" title="Figure 1 ‣ Recommendation with Language Models ‣ 2 Related Work ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>, the output of the User LLM corresponding to <math alttext="E_{i}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx2.p1.5.m5.1"><semantics id="S3.SSx2.SSSx2.p1.5.m5.1a"><msub id="S3.SSx2.SSSx2.p1.5.m5.1.1" xref="S3.SSx2.SSSx2.p1.5.m5.1.1.cmml"><mi id="S3.SSx2.SSSx2.p1.5.m5.1.1.2" xref="S3.SSx2.SSSx2.p1.5.m5.1.1.2.cmml">E</mi><mi id="S3.SSx2.SSSx2.p1.5.m5.1.1.3" xref="S3.SSx2.SSSx2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx2.p1.5.m5.1b"><apply id="S3.SSx2.SSSx2.p1.5.m5.1.1.cmml" xref="S3.SSx2.SSSx2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.5.m5.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.5.m5.1.1.2.cmml" xref="S3.SSx2.SSSx2.p1.5.m5.1.1.2">𝐸</ci><ci id="S3.SSx2.SSSx2.p1.5.m5.1.1.3.cmml" xref="S3.SSx2.SSSx2.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx2.p1.5.m5.1c">E_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx2.p1.5.m5.1d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is <math alttext="E_{i+1}^{\prime}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx2.p1.6.m6.1"><semantics id="S3.SSx2.SSSx2.p1.6.m6.1a"><msubsup id="S3.SSx2.SSSx2.p1.6.m6.1.1" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.cmml"><mi id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.2" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.2.cmml">E</mi><mrow id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.cmml"><mi id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.2" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.2.cmml">i</mi><mo id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.1" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.1.cmml">+</mo><mn id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.3" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.3.cmml">1</mn></mrow><mo id="S3.SSx2.SSSx2.p1.6.m6.1.1.3" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx2.p1.6.m6.1b"><apply id="S3.SSx2.SSSx2.p1.6.m6.1.1.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.6.m6.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1">superscript</csymbol><apply id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.1.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.2.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.2">𝐸</ci><apply id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3"><plus id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.1.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.1"></plus><ci id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.2.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.2">𝑖</ci><cn id="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.3.cmml" type="integer" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.2.3.3">1</cn></apply></apply><ci id="S3.SSx2.SSSx2.p1.6.m6.1.1.3.cmml" xref="S3.SSx2.SSSx2.p1.6.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx2.p1.6.m6.1c">E_{i+1}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx2.p1.6.m6.1d">italic_E start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, which is expected to be the embedding of <math alttext="I_{i+1}" class="ltx_Math" display="inline" id="S3.SSx2.SSSx2.p1.7.m7.1"><semantics id="S3.SSx2.SSSx2.p1.7.m7.1a"><msub id="S3.SSx2.SSSx2.p1.7.m7.1.1" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.cmml"><mi id="S3.SSx2.SSSx2.p1.7.m7.1.1.2" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.2.cmml">I</mi><mrow id="S3.SSx2.SSSx2.p1.7.m7.1.1.3" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3.cmml"><mi id="S3.SSx2.SSSx2.p1.7.m7.1.1.3.2" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3.2.cmml">i</mi><mo id="S3.SSx2.SSSx2.p1.7.m7.1.1.3.1" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3.1.cmml">+</mo><mn id="S3.SSx2.SSSx2.p1.7.m7.1.1.3.3" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SSx2.SSSx2.p1.7.m7.1b"><apply id="S3.SSx2.SSSx2.p1.7.m7.1.1.cmml" xref="S3.SSx2.SSSx2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SSx2.SSSx2.p1.7.m7.1.1.1.cmml" xref="S3.SSx2.SSSx2.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SSx2.SSSx2.p1.7.m7.1.1.2.cmml" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.2">𝐼</ci><apply id="S3.SSx2.SSSx2.p1.7.m7.1.1.3.cmml" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3"><plus id="S3.SSx2.SSSx2.p1.7.m7.1.1.3.1.cmml" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3.1"></plus><ci id="S3.SSx2.SSSx2.p1.7.m7.1.1.3.2.cmml" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3.2">𝑖</ci><cn id="S3.SSx2.SSSx2.p1.7.m7.1.1.3.3.cmml" type="integer" xref="S3.SSx2.SSSx2.p1.7.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx2.SSSx2.p1.7.m7.1c">I_{i+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx2.SSSx2.p1.7.m7.1d">italic_I start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SSx2.SSSx2.p2">
<p class="ltx_p" id="S3.SSx2.SSSx2.p2.1">Unlike traditional LLMs with text-in and text-out formats, here both the input and output of the User LLM are item embeddings. Therefore, we discard the word embeddings from the pre-trained LLM but retain all other pre-trained weights. Experiments show that these pre-trained weights are very helpful for reasoning user interests.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SSx3">
<h3 class="ltx_title ltx_title_subsection">Training for Recommendation Objectives</h3>
<div class="ltx_para" id="S3.SSx3.p1">
<p class="ltx_p" id="S3.SSx3.p1.1">Existing LLMs are all pre-trained using general natural language corpora. Although they possess a wealth of world knowledge and strong reasoning abilities, there remains a considerable gap between their capabilities and those required by recommendation systems. Following the best practices of other works <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib42" title="">2024</a>; Touvron et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib30" title="">2023</a>)</cite>, we adopt supervised fine-tuning on top of the pre-trained LLM.</p>
</div>
<div class="ltx_para" id="S3.SSx3.p2">
<p class="ltx_p" id="S3.SSx3.p2.1">Recommendation systems can be divided into two categories, generative and discriminative recommendation. It is noteworthy that the proposed HLLM architecture is applicable to both types, requiring only appropriate adjustments to the training objectives. The following sections provide a detailed introduction to the training objectives for both categories.</p>
</div>
<section class="ltx_subsubsection" id="S3.SSx3.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Generative Recommendation</h4>
<div class="ltx_para" id="S3.SSx3.SSSx1.p1">
<p class="ltx_p" id="S3.SSx3.SSSx1.p1.1">Recent work <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite> has provided a successful generative recommendation solution, including both retrieval and ranking. Our approach differs from it in two major ways: the model architecture is upgraded to large language models with pre-trained weights, and the input features are changed from IDs to text-input LLM features. The above differences have minimal impact on the training and serving strategies, therefore, we largely follow approaches proposed in <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SSx3.SSSx1.p2">
<p class="ltx_p" id="S3.SSx3.SSSx1.p2.2">For the training objective of generative recommendation, next item prediction is adopted, which aims to generate the embedding of the next item given the embeddings of the previous items in the user’s history.
Specifically, the InfoNCE loss <cite class="ltx_cite ltx_citemacro_citep">(Oord, Li, and Vinyals <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib23" title="">2018</a>)</cite> is used during training.
For any prediction <math alttext="E_{i}^{\prime}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.1.m1.1"><semantics id="S3.SSx3.SSSx1.p2.1.m1.1a"><msubsup id="S3.SSx3.SSSx1.p2.1.m1.1.1" xref="S3.SSx3.SSSx1.p2.1.m1.1.1.cmml"><mi id="S3.SSx3.SSSx1.p2.1.m1.1.1.2.2" xref="S3.SSx3.SSSx1.p2.1.m1.1.1.2.2.cmml">E</mi><mi id="S3.SSx3.SSSx1.p2.1.m1.1.1.2.3" xref="S3.SSx3.SSSx1.p2.1.m1.1.1.2.3.cmml">i</mi><mo id="S3.SSx3.SSSx1.p2.1.m1.1.1.3" xref="S3.SSx3.SSSx1.p2.1.m1.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.1.m1.1b"><apply id="S3.SSx3.SSSx1.p2.1.m1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.1.m1.1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.1.m1.1.1">superscript</csymbol><apply id="S3.SSx3.SSSx1.p2.1.m1.1.1.2.cmml" xref="S3.SSx3.SSSx1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.1.m1.1.1.2.1.cmml" xref="S3.SSx3.SSSx1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SSx3.SSSx1.p2.1.m1.1.1.2.2.cmml" xref="S3.SSx3.SSSx1.p2.1.m1.1.1.2.2">𝐸</ci><ci id="S3.SSx3.SSSx1.p2.1.m1.1.1.2.3.cmml" xref="S3.SSx3.SSSx1.p2.1.m1.1.1.2.3">𝑖</ci></apply><ci id="S3.SSx3.SSSx1.p2.1.m1.1.1.3.cmml" xref="S3.SSx3.SSSx1.p2.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.1.m1.1c">E_{i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> in the output sequence of the User LLM, the positive sample is <math alttext="E_{i}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.2.m2.1"><semantics id="S3.SSx3.SSSx1.p2.2.m2.1a"><msub id="S3.SSx3.SSSx1.p2.2.m2.1.1" xref="S3.SSx3.SSSx1.p2.2.m2.1.1.cmml"><mi id="S3.SSx3.SSSx1.p2.2.m2.1.1.2" xref="S3.SSx3.SSSx1.p2.2.m2.1.1.2.cmml">E</mi><mi id="S3.SSx3.SSSx1.p2.2.m2.1.1.3" xref="S3.SSx3.SSSx1.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.2.m2.1b"><apply id="S3.SSx3.SSSx1.p2.2.m2.1.1.cmml" xref="S3.SSx3.SSSx1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.2.m2.1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SSx3.SSSx1.p2.2.m2.1.1.2.cmml" xref="S3.SSx3.SSSx1.p2.2.m2.1.1.2">𝐸</ci><ci id="S3.SSx3.SSSx1.p2.2.m2.1.1.3.cmml" xref="S3.SSx3.SSSx1.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.2.m2.1c">E_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, and the negative samples are randomly sampled from the dataset excluding the current user sequence. The loss function can be formulated as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{gen}=-\sum_{j=1}^{b}\sum_{i=2}^{n}\log\dfrac{e^{s(E_{j,i}^{\prime%
},E_{j,i})}}{e^{s(E_{j,i}^{\prime},E_{j,i)}}+\sum_{k}^{N}e^{s(E_{j,i}^{\prime}%
,E_{j,i,k})}}" class="ltx_math_unparsed" display="block" id="S3.E1.m1.17"><semantics id="S3.E1.m1.17a"><mrow id="S3.E1.m1.17.18"><msub id="S3.E1.m1.17.18.2"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.17.18.2.2">ℒ</mi><mrow id="S3.E1.m1.17.18.2.3"><mi id="S3.E1.m1.17.18.2.3.2">g</mi><mo id="S3.E1.m1.17.18.2.3.1">⁢</mo><mi id="S3.E1.m1.17.18.2.3.3">e</mi><mo id="S3.E1.m1.17.18.2.3.1a">⁢</mo><mi id="S3.E1.m1.17.18.2.3.4">n</mi></mrow></msub><mo id="S3.E1.m1.17.18.1">=</mo><mrow id="S3.E1.m1.17.18.3"><mo id="S3.E1.m1.17.18.3a">−</mo><mrow id="S3.E1.m1.17.18.3.2"><munderover id="S3.E1.m1.17.18.3.2.1"><mo id="S3.E1.m1.17.18.3.2.1.2.2" movablelimits="false" rspace="0em">∑</mo><mrow id="S3.E1.m1.17.18.3.2.1.2.3"><mi id="S3.E1.m1.17.18.3.2.1.2.3.2">j</mi><mo id="S3.E1.m1.17.18.3.2.1.2.3.1">=</mo><mn id="S3.E1.m1.17.18.3.2.1.2.3.3">1</mn></mrow><mi id="S3.E1.m1.17.18.3.2.1.3">b</mi></munderover><mrow id="S3.E1.m1.17.18.3.2.2"><munderover id="S3.E1.m1.17.18.3.2.2.1"><mo id="S3.E1.m1.17.18.3.2.2.1.2.2" movablelimits="false">∑</mo><mrow id="S3.E1.m1.17.18.3.2.2.1.2.3"><mi id="S3.E1.m1.17.18.3.2.2.1.2.3.2">i</mi><mo id="S3.E1.m1.17.18.3.2.2.1.2.3.1">=</mo><mn id="S3.E1.m1.17.18.3.2.2.1.2.3.3">2</mn></mrow><mi id="S3.E1.m1.17.18.3.2.2.1.3">n</mi></munderover><mrow id="S3.E1.m1.17.18.3.2.2.2"><mi id="S3.E1.m1.17.18.3.2.2.2.1">log</mi><mo id="S3.E1.m1.17.18.3.2.2.2a" lspace="0.167em">⁡</mo><mfrac id="S3.E1.m1.17.17"><msup id="S3.E1.m1.6.6.6"><mi id="S3.E1.m1.6.6.6.8">e</mi><mrow id="S3.E1.m1.6.6.6.6.6"><mi id="S3.E1.m1.6.6.6.6.6.8">s</mi><mo id="S3.E1.m1.6.6.6.6.6.7">⁢</mo><mrow id="S3.E1.m1.6.6.6.6.6.6.2"><mo id="S3.E1.m1.6.6.6.6.6.6.2.3" stretchy="false">(</mo><msubsup id="S3.E1.m1.5.5.5.5.5.5.1.1"><mi id="S3.E1.m1.5.5.5.5.5.5.1.1.2.2">E</mi><mrow id="S3.E1.m1.2.2.2.2.2.2.2.4"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1">j</mi><mo id="S3.E1.m1.2.2.2.2.2.2.2.4.1">,</mo><mi id="S3.E1.m1.2.2.2.2.2.2.2.2">i</mi></mrow><mo id="S3.E1.m1.5.5.5.5.5.5.1.1.3">′</mo></msubsup><mo id="S3.E1.m1.6.6.6.6.6.6.2.4">,</mo><msub id="S3.E1.m1.6.6.6.6.6.6.2.2"><mi id="S3.E1.m1.6.6.6.6.6.6.2.2.2">E</mi><mrow id="S3.E1.m1.4.4.4.4.4.4.2.4"><mi id="S3.E1.m1.3.3.3.3.3.3.1.1">j</mi><mo id="S3.E1.m1.4.4.4.4.4.4.2.4.1">,</mo><mi id="S3.E1.m1.4.4.4.4.4.4.2.2">i</mi></mrow></msub><mo id="S3.E1.m1.6.6.6.6.6.6.2.5" stretchy="false">)</mo></mrow></mrow></msup><mrow id="S3.E1.m1.17.17.17"><msup id="S3.E1.m1.17.17.17.13"><mi id="S3.E1.m1.17.17.17.13.2">e</mi><mrow id="S3.E1.m1.10.10.10.4.4"><mi id="S3.E1.m1.10.10.10.4.4.5">s</mi><mrow id="S3.E1.m1.10.10.10.4.4.6"><mo id="S3.E1.m1.10.10.10.4.4.6.1" stretchy="false">(</mo><msubsup id="S3.E1.m1.10.10.10.4.4.6.2"><mi id="S3.E1.m1.10.10.10.4.4.6.2.2.2">E</mi><mrow id="S3.E1.m1.8.8.8.2.2.2.2.4"><mi id="S3.E1.m1.7.7.7.1.1.1.1.1">j</mi><mo id="S3.E1.m1.8.8.8.2.2.2.2.4.1">,</mo><mi id="S3.E1.m1.8.8.8.2.2.2.2.2">i</mi></mrow><mo id="S3.E1.m1.10.10.10.4.4.6.2.3">′</mo></msubsup><mo id="S3.E1.m1.10.10.10.4.4.6.3">,</mo><msub id="S3.E1.m1.10.10.10.4.4.6.4"><mi id="S3.E1.m1.10.10.10.4.4.6.4.2">E</mi><mrow id="S3.E1.m1.10.10.10.4.4.4.2"><mi id="S3.E1.m1.9.9.9.3.3.3.1.1">j</mi><mo id="S3.E1.m1.10.10.10.4.4.4.2.3">,</mo><mi id="S3.E1.m1.10.10.10.4.4.4.2.2">i</mi><mo id="S3.E1.m1.10.10.10.4.4.4.2.4" stretchy="false">)</mo></mrow></msub></mrow></mrow></msup><mo id="S3.E1.m1.17.17.17.12" rspace="0.055em">+</mo><mrow id="S3.E1.m1.17.17.17.14"><msubsup id="S3.E1.m1.17.17.17.14.1"><mo id="S3.E1.m1.17.17.17.14.1.2.2">∑</mo><mi id="S3.E1.m1.17.17.17.14.1.2.3">k</mi><mi id="S3.E1.m1.17.17.17.14.1.3">N</mi></msubsup><msup id="S3.E1.m1.17.17.17.14.2"><mi id="S3.E1.m1.17.17.17.14.2.2">e</mi><mrow id="S3.E1.m1.17.17.17.11.7"><mi id="S3.E1.m1.17.17.17.11.7.9">s</mi><mo id="S3.E1.m1.17.17.17.11.7.8">⁢</mo><mrow id="S3.E1.m1.17.17.17.11.7.7.2"><mo id="S3.E1.m1.17.17.17.11.7.7.2.3" stretchy="false">(</mo><msubsup id="S3.E1.m1.16.16.16.10.6.6.1.1"><mi id="S3.E1.m1.16.16.16.10.6.6.1.1.2.2">E</mi><mrow id="S3.E1.m1.12.12.12.6.2.2.2.4"><mi id="S3.E1.m1.11.11.11.5.1.1.1.1">j</mi><mo id="S3.E1.m1.12.12.12.6.2.2.2.4.1">,</mo><mi id="S3.E1.m1.12.12.12.6.2.2.2.2">i</mi></mrow><mo id="S3.E1.m1.16.16.16.10.6.6.1.1.3">′</mo></msubsup><mo id="S3.E1.m1.17.17.17.11.7.7.2.4">,</mo><msub id="S3.E1.m1.17.17.17.11.7.7.2.2"><mi id="S3.E1.m1.17.17.17.11.7.7.2.2.2">E</mi><mrow id="S3.E1.m1.15.15.15.9.5.5.3.5"><mi id="S3.E1.m1.13.13.13.7.3.3.1.1">j</mi><mo id="S3.E1.m1.15.15.15.9.5.5.3.5.1">,</mo><mi id="S3.E1.m1.14.14.14.8.4.4.2.2">i</mi><mo id="S3.E1.m1.15.15.15.9.5.5.3.5.2">,</mo><mi id="S3.E1.m1.15.15.15.9.5.5.3.3">k</mi></mrow></msub><mo id="S3.E1.m1.17.17.17.11.7.7.2.5" stretchy="false">)</mo></mrow></mrow></msup></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.E1.m1.17b">\mathcal{L}_{gen}=-\sum_{j=1}^{b}\sum_{i=2}^{n}\log\dfrac{e^{s(E_{j,i}^{\prime%
},E_{j,i})}}{e^{s(E_{j,i}^{\prime},E_{j,i)}}+\sum_{k}^{N}e^{s(E_{j,i}^{\prime}%
,E_{j,i,k})}}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.17c">caligraphic_L start_POSTSUBSCRIPT italic_g italic_e italic_n end_POSTSUBSCRIPT = - ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_i = 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_log divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_E start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_E start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_E start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_E start_POSTSUBSCRIPT italic_j , italic_i ) end_POSTSUBSCRIPT end_POSTSUPERSCRIPT + ∑ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT italic_s ( italic_E start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_E start_POSTSUBSCRIPT italic_j , italic_i , italic_k end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SSx3.SSSx1.p2.10">where <math alttext="s" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.3.m1.1"><semantics id="S3.SSx3.SSSx1.p2.3.m1.1a"><mi id="S3.SSx3.SSSx1.p2.3.m1.1.1" xref="S3.SSx3.SSSx1.p2.3.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.3.m1.1b"><ci id="S3.SSx3.SSSx1.p2.3.m1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.3.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.3.m1.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.3.m1.1d">italic_s</annotation></semantics></math> is the similarity function with a learnable temperature parameter, <math alttext="E_{j,i}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.4.m2.2"><semantics id="S3.SSx3.SSSx1.p2.4.m2.2a"><msub id="S3.SSx3.SSSx1.p2.4.m2.2.3" xref="S3.SSx3.SSSx1.p2.4.m2.2.3.cmml"><mi id="S3.SSx3.SSSx1.p2.4.m2.2.3.2" xref="S3.SSx3.SSSx1.p2.4.m2.2.3.2.cmml">E</mi><mrow id="S3.SSx3.SSSx1.p2.4.m2.2.2.2.4" xref="S3.SSx3.SSSx1.p2.4.m2.2.2.2.3.cmml"><mi id="S3.SSx3.SSSx1.p2.4.m2.1.1.1.1" xref="S3.SSx3.SSSx1.p2.4.m2.1.1.1.1.cmml">j</mi><mo id="S3.SSx3.SSSx1.p2.4.m2.2.2.2.4.1" xref="S3.SSx3.SSSx1.p2.4.m2.2.2.2.3.cmml">,</mo><mi id="S3.SSx3.SSSx1.p2.4.m2.2.2.2.2" xref="S3.SSx3.SSSx1.p2.4.m2.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.4.m2.2b"><apply id="S3.SSx3.SSSx1.p2.4.m2.2.3.cmml" xref="S3.SSx3.SSSx1.p2.4.m2.2.3"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.4.m2.2.3.1.cmml" xref="S3.SSx3.SSSx1.p2.4.m2.2.3">subscript</csymbol><ci id="S3.SSx3.SSSx1.p2.4.m2.2.3.2.cmml" xref="S3.SSx3.SSSx1.p2.4.m2.2.3.2">𝐸</ci><list id="S3.SSx3.SSSx1.p2.4.m2.2.2.2.3.cmml" xref="S3.SSx3.SSSx1.p2.4.m2.2.2.2.4"><ci id="S3.SSx3.SSSx1.p2.4.m2.1.1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.4.m2.1.1.1.1">𝑗</ci><ci id="S3.SSx3.SSSx1.p2.4.m2.2.2.2.2.cmml" xref="S3.SSx3.SSSx1.p2.4.m2.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.4.m2.2c">E_{j,i}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.4.m2.2d">italic_E start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes the i-th item embedding produced by the Item LLM in the j-th user’s history interaction and <math alttext="E_{j,i}^{\prime}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.5.m3.2"><semantics id="S3.SSx3.SSSx1.p2.5.m3.2a"><msubsup id="S3.SSx3.SSSx1.p2.5.m3.2.3" xref="S3.SSx3.SSSx1.p2.5.m3.2.3.cmml"><mi id="S3.SSx3.SSSx1.p2.5.m3.2.3.2.2" xref="S3.SSx3.SSSx1.p2.5.m3.2.3.2.2.cmml">E</mi><mrow id="S3.SSx3.SSSx1.p2.5.m3.2.2.2.4" xref="S3.SSx3.SSSx1.p2.5.m3.2.2.2.3.cmml"><mi id="S3.SSx3.SSSx1.p2.5.m3.1.1.1.1" xref="S3.SSx3.SSSx1.p2.5.m3.1.1.1.1.cmml">j</mi><mo id="S3.SSx3.SSSx1.p2.5.m3.2.2.2.4.1" xref="S3.SSx3.SSSx1.p2.5.m3.2.2.2.3.cmml">,</mo><mi id="S3.SSx3.SSSx1.p2.5.m3.2.2.2.2" xref="S3.SSx3.SSSx1.p2.5.m3.2.2.2.2.cmml">i</mi></mrow><mo id="S3.SSx3.SSSx1.p2.5.m3.2.3.3" xref="S3.SSx3.SSSx1.p2.5.m3.2.3.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.5.m3.2b"><apply id="S3.SSx3.SSSx1.p2.5.m3.2.3.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.3"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.5.m3.2.3.1.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.3">superscript</csymbol><apply id="S3.SSx3.SSSx1.p2.5.m3.2.3.2.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.3"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.5.m3.2.3.2.1.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.3">subscript</csymbol><ci id="S3.SSx3.SSSx1.p2.5.m3.2.3.2.2.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.3.2.2">𝐸</ci><list id="S3.SSx3.SSSx1.p2.5.m3.2.2.2.3.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.2.2.4"><ci id="S3.SSx3.SSSx1.p2.5.m3.1.1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.1.1.1.1">𝑗</ci><ci id="S3.SSx3.SSSx1.p2.5.m3.2.2.2.2.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.2.2.2">𝑖</ci></list></apply><ci id="S3.SSx3.SSSx1.p2.5.m3.2.3.3.cmml" xref="S3.SSx3.SSSx1.p2.5.m3.2.3.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.5.m3.2c">E_{j,i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.5.m3.2d">italic_E start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> denotes the i-th item embedding predicted by the User LLM for the j-th user. <math alttext="N" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.6.m4.1"><semantics id="S3.SSx3.SSSx1.p2.6.m4.1a"><mi id="S3.SSx3.SSSx1.p2.6.m4.1.1" xref="S3.SSx3.SSSx1.p2.6.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.6.m4.1b"><ci id="S3.SSx3.SSSx1.p2.6.m4.1.1.cmml" xref="S3.SSx3.SSSx1.p2.6.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.6.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.6.m4.1d">italic_N</annotation></semantics></math> is the number of negative samples, <math alttext="E_{j,i,k}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.7.m5.3"><semantics id="S3.SSx3.SSSx1.p2.7.m5.3a"><msub id="S3.SSx3.SSSx1.p2.7.m5.3.4" xref="S3.SSx3.SSSx1.p2.7.m5.3.4.cmml"><mi id="S3.SSx3.SSSx1.p2.7.m5.3.4.2" xref="S3.SSx3.SSSx1.p2.7.m5.3.4.2.cmml">E</mi><mrow id="S3.SSx3.SSSx1.p2.7.m5.3.3.3.5" xref="S3.SSx3.SSSx1.p2.7.m5.3.3.3.4.cmml"><mi id="S3.SSx3.SSSx1.p2.7.m5.1.1.1.1" xref="S3.SSx3.SSSx1.p2.7.m5.1.1.1.1.cmml">j</mi><mo id="S3.SSx3.SSSx1.p2.7.m5.3.3.3.5.1" xref="S3.SSx3.SSSx1.p2.7.m5.3.3.3.4.cmml">,</mo><mi id="S3.SSx3.SSSx1.p2.7.m5.2.2.2.2" xref="S3.SSx3.SSSx1.p2.7.m5.2.2.2.2.cmml">i</mi><mo id="S3.SSx3.SSSx1.p2.7.m5.3.3.3.5.2" xref="S3.SSx3.SSSx1.p2.7.m5.3.3.3.4.cmml">,</mo><mi id="S3.SSx3.SSSx1.p2.7.m5.3.3.3.3" xref="S3.SSx3.SSSx1.p2.7.m5.3.3.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.7.m5.3b"><apply id="S3.SSx3.SSSx1.p2.7.m5.3.4.cmml" xref="S3.SSx3.SSSx1.p2.7.m5.3.4"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.7.m5.3.4.1.cmml" xref="S3.SSx3.SSSx1.p2.7.m5.3.4">subscript</csymbol><ci id="S3.SSx3.SSSx1.p2.7.m5.3.4.2.cmml" xref="S3.SSx3.SSSx1.p2.7.m5.3.4.2">𝐸</ci><list id="S3.SSx3.SSSx1.p2.7.m5.3.3.3.4.cmml" xref="S3.SSx3.SSSx1.p2.7.m5.3.3.3.5"><ci id="S3.SSx3.SSSx1.p2.7.m5.1.1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.7.m5.1.1.1.1">𝑗</ci><ci id="S3.SSx3.SSSx1.p2.7.m5.2.2.2.2.cmml" xref="S3.SSx3.SSSx1.p2.7.m5.2.2.2.2">𝑖</ci><ci id="S3.SSx3.SSSx1.p2.7.m5.3.3.3.3.cmml" xref="S3.SSx3.SSSx1.p2.7.m5.3.3.3.3">𝑘</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.7.m5.3c">E_{j,i,k}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.7.m5.3d">italic_E start_POSTSUBSCRIPT italic_j , italic_i , italic_k end_POSTSUBSCRIPT</annotation></semantics></math> represents the k-th negative embedding of <math alttext="E_{j,i}^{\prime}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.8.m6.2"><semantics id="S3.SSx3.SSSx1.p2.8.m6.2a"><msubsup id="S3.SSx3.SSSx1.p2.8.m6.2.3" xref="S3.SSx3.SSSx1.p2.8.m6.2.3.cmml"><mi id="S3.SSx3.SSSx1.p2.8.m6.2.3.2.2" xref="S3.SSx3.SSSx1.p2.8.m6.2.3.2.2.cmml">E</mi><mrow id="S3.SSx3.SSSx1.p2.8.m6.2.2.2.4" xref="S3.SSx3.SSSx1.p2.8.m6.2.2.2.3.cmml"><mi id="S3.SSx3.SSSx1.p2.8.m6.1.1.1.1" xref="S3.SSx3.SSSx1.p2.8.m6.1.1.1.1.cmml">j</mi><mo id="S3.SSx3.SSSx1.p2.8.m6.2.2.2.4.1" xref="S3.SSx3.SSSx1.p2.8.m6.2.2.2.3.cmml">,</mo><mi id="S3.SSx3.SSSx1.p2.8.m6.2.2.2.2" xref="S3.SSx3.SSSx1.p2.8.m6.2.2.2.2.cmml">i</mi></mrow><mo id="S3.SSx3.SSSx1.p2.8.m6.2.3.3" xref="S3.SSx3.SSSx1.p2.8.m6.2.3.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.8.m6.2b"><apply id="S3.SSx3.SSSx1.p2.8.m6.2.3.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.3"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.8.m6.2.3.1.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.3">superscript</csymbol><apply id="S3.SSx3.SSSx1.p2.8.m6.2.3.2.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.3"><csymbol cd="ambiguous" id="S3.SSx3.SSSx1.p2.8.m6.2.3.2.1.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.3">subscript</csymbol><ci id="S3.SSx3.SSSx1.p2.8.m6.2.3.2.2.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.3.2.2">𝐸</ci><list id="S3.SSx3.SSSx1.p2.8.m6.2.2.2.3.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.2.2.4"><ci id="S3.SSx3.SSSx1.p2.8.m6.1.1.1.1.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.1.1.1.1">𝑗</ci><ci id="S3.SSx3.SSSx1.p2.8.m6.2.2.2.2.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.2.2.2">𝑖</ci></list></apply><ci id="S3.SSx3.SSSx1.p2.8.m6.2.3.3.cmml" xref="S3.SSx3.SSSx1.p2.8.m6.2.3.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.8.m6.2c">E_{j,i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.8.m6.2d">italic_E start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>. <math alttext="b" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.9.m7.1"><semantics id="S3.SSx3.SSSx1.p2.9.m7.1a"><mi id="S3.SSx3.SSSx1.p2.9.m7.1.1" xref="S3.SSx3.SSSx1.p2.9.m7.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.9.m7.1b"><ci id="S3.SSx3.SSSx1.p2.9.m7.1.1.cmml" xref="S3.SSx3.SSSx1.p2.9.m7.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.9.m7.1c">b</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.9.m7.1d">italic_b</annotation></semantics></math> represents the total number of users within the batch, <math alttext="n" class="ltx_Math" display="inline" id="S3.SSx3.SSSx1.p2.10.m8.1"><semantics id="S3.SSx3.SSSx1.p2.10.m8.1a"><mi id="S3.SSx3.SSSx1.p2.10.m8.1.1" xref="S3.SSx3.SSSx1.p2.10.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx1.p2.10.m8.1b"><ci id="S3.SSx3.SSSx1.p2.10.m8.1.1.cmml" xref="S3.SSx3.SSSx1.p2.10.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx1.p2.10.m8.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx1.p2.10.m8.1d">italic_n</annotation></semantics></math> is the length of user history interactions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SSx3.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Discriminative Recommendation</h4>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="435" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Two User LLM variants for discriminative recommendations.</figcaption>
</figure>
<div class="ltx_para" id="S3.SSx3.SSSx2.p1">
<p class="ltx_p" id="S3.SSx3.SSSx2.p1.2">Since discriminative recommendation models still dominate in the industry, we also present an application scheme for HLLM under discriminative recommendation models. The optimization objective of discriminative models is to judge, given a user sequence <math alttext="U" class="ltx_Math" display="inline" id="S3.SSx3.SSSx2.p1.1.m1.1"><semantics id="S3.SSx3.SSSx2.p1.1.m1.1a"><mi id="S3.SSx3.SSSx2.p1.1.m1.1.1" xref="S3.SSx3.SSSx2.p1.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx2.p1.1.m1.1b"><ci id="S3.SSx3.SSSx2.p1.1.m1.1.1.cmml" xref="S3.SSx3.SSSx2.p1.1.m1.1.1">𝑈</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx2.p1.1.m1.1c">U</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx2.p1.1.m1.1d">italic_U</annotation></semantics></math> and a target item <math alttext="I_{\text{tgt}}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx2.p1.2.m2.1"><semantics id="S3.SSx3.SSSx2.p1.2.m2.1a"><msub id="S3.SSx3.SSSx2.p1.2.m2.1.1" xref="S3.SSx3.SSSx2.p1.2.m2.1.1.cmml"><mi id="S3.SSx3.SSSx2.p1.2.m2.1.1.2" xref="S3.SSx3.SSSx2.p1.2.m2.1.1.2.cmml">I</mi><mtext id="S3.SSx3.SSSx2.p1.2.m2.1.1.3" xref="S3.SSx3.SSSx2.p1.2.m2.1.1.3a.cmml">tgt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx2.p1.2.m2.1b"><apply id="S3.SSx3.SSSx2.p1.2.m2.1.1.cmml" xref="S3.SSx3.SSSx2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SSx3.SSSx2.p1.2.m2.1.1.1.cmml" xref="S3.SSx3.SSSx2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SSx3.SSSx2.p1.2.m2.1.1.2.cmml" xref="S3.SSx3.SSSx2.p1.2.m2.1.1.2">𝐼</ci><ci id="S3.SSx3.SSSx2.p1.2.m2.1.1.3a.cmml" xref="S3.SSx3.SSSx2.p1.2.m2.1.1.3"><mtext id="S3.SSx3.SSSx2.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SSx3.SSSx2.p1.2.m2.1.1.3">tgt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx2.p1.2.m2.1c">I_{\text{tgt}}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx2.p1.2.m2.1d">italic_I start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT</annotation></semantics></math>, whether the user is interested in the target item (e.g., by clicking, liking, purchasing, etc.).</p>
</div>
<div class="ltx_para" id="S3.SSx3.SSSx2.p2">
<p class="ltx_p" id="S3.SSx3.SSSx2.p2.2">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S3.F2" title="Figure 2 ‣ Discriminative Recommendation ‣ Training for Recommendation Objectives ‣ 3 Method ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">2</span></a>, there are two User LLM variants for discriminative recommendation, while keeping the Item LLM unchanged. <span class="ltx_text ltx_font_bold" id="S3.SSx3.SSSx2.p2.2.1">Early fusion</span> appends the target item embedding <math alttext="E_{\text{tgt}}" class="ltx_Math" display="inline" id="S3.SSx3.SSSx2.p2.1.m1.1"><semantics id="S3.SSx3.SSSx2.p2.1.m1.1a"><msub id="S3.SSx3.SSSx2.p2.1.m1.1.1" xref="S3.SSx3.SSSx2.p2.1.m1.1.1.cmml"><mi id="S3.SSx3.SSSx2.p2.1.m1.1.1.2" xref="S3.SSx3.SSSx2.p2.1.m1.1.1.2.cmml">E</mi><mtext id="S3.SSx3.SSSx2.p2.1.m1.1.1.3" xref="S3.SSx3.SSSx2.p2.1.m1.1.1.3a.cmml">tgt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx2.p2.1.m1.1b"><apply id="S3.SSx3.SSSx2.p2.1.m1.1.1.cmml" xref="S3.SSx3.SSSx2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SSx3.SSSx2.p2.1.m1.1.1.1.cmml" xref="S3.SSx3.SSSx2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SSx3.SSSx2.p2.1.m1.1.1.2.cmml" xref="S3.SSx3.SSSx2.p2.1.m1.1.1.2">𝐸</ci><ci id="S3.SSx3.SSSx2.p2.1.m1.1.1.3a.cmml" xref="S3.SSx3.SSSx2.p2.1.m1.1.1.3"><mtext id="S3.SSx3.SSSx2.p2.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SSx3.SSSx2.p2.1.m1.1.1.3">tgt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx2.p2.1.m1.1c">E_{\text{tgt}}</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx2.p2.1.m1.1d">italic_E start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT</annotation></semantics></math> to the end of the user’s historical sequence, then produces a high-order cross feature through User LLM, and finally inputs this cross feature into the prediction head to generate the final logits.
<span class="ltx_text ltx_font_bold" id="S3.SSx3.SSSx2.p2.2.2">Late fusion</span>, on the other hand, first uses the User LLM to extract user features, which are independent of the target item, in a manner similar to the Item LLM feature extraction. A special token <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S3.SSx3.SSSx2.p2.2.3">[USER]</span> is added to the end of the user sequence to extract user representation.
The user embedding and the target item embedding are then input together into the prediction head to predict the final logits.
Early fusion, due to its deep integration of user interests and the target item, tends to perform better but is challenging to apply simultaneously across numerous candidates; conversely, late fusion is more efficient since different candidates share the same user features, but typically sees a performance decline.</p>
</div>
<div class="ltx_para" id="S3.SSx3.SSSx2.p3">
<p class="ltx_p" id="S3.SSx3.SSSx2.p3.3">The training objective of discriminative recommendation is usually a classification task, such as predicting whether a user will click, etc. For the binary classification example, the training loss is as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{cls}=-\left(y\cdot\log(x)+(1-y)\cdot\log(1-x)\right)" class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><msub id="S3.E2.m1.4.4.3" xref="S3.E2.m1.4.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.4.4.3.2" xref="S3.E2.m1.4.4.3.2.cmml">ℒ</mi><mrow id="S3.E2.m1.4.4.3.3" xref="S3.E2.m1.4.4.3.3.cmml"><mi id="S3.E2.m1.4.4.3.3.2" xref="S3.E2.m1.4.4.3.3.2.cmml">c</mi><mo id="S3.E2.m1.4.4.3.3.1" xref="S3.E2.m1.4.4.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.4.4.3.3.3" xref="S3.E2.m1.4.4.3.3.3.cmml">l</mi><mo id="S3.E2.m1.4.4.3.3.1a" xref="S3.E2.m1.4.4.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.4.4.3.3.4" xref="S3.E2.m1.4.4.3.3.4.cmml">s</mi></mrow></msub><mo id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml">=</mo><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.cmml"><mo id="S3.E2.m1.4.4.1a" xref="S3.E2.m1.4.4.1.cmml">−</mo><mrow id="S3.E2.m1.4.4.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.cmml"><mo id="S3.E2.m1.4.4.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.4.4.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1.4" xref="S3.E2.m1.4.4.1.1.1.1.4.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.4.2" xref="S3.E2.m1.4.4.1.1.1.1.4.2.cmml">y</mi><mo id="S3.E2.m1.4.4.1.1.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.4.4.1.1.1.1.4.1.cmml">⋅</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.4.3.2" xref="S3.E2.m1.4.4.1.1.1.1.4.3.1.cmml"><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">log</mi><mo id="S3.E2.m1.4.4.1.1.1.1.4.3.2a" xref="S3.E2.m1.4.4.1.1.1.1.4.3.1.cmml">⁡</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.4.3.2.1" xref="S3.E2.m1.4.4.1.1.1.1.4.3.1.cmml"><mo id="S3.E2.m1.4.4.1.1.1.1.4.3.2.1.1" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.4.3.1.cmml">(</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">x</mi><mo id="S3.E2.m1.4.4.1.1.1.1.4.3.2.1.2" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.4.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.4.4.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.3.cmml">+</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.2.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.4.4.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo id="S3.E2.m1.4.4.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E2.m1.4.4.1.1.1.1.2.3" rspace="0.222em" xref="S3.E2.m1.4.4.1.1.1.1.2.3.cmml">⋅</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.2.2.1" xref="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">log</mi><mo id="S3.E2.m1.4.4.1.1.1.1.2.2.1a" xref="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml">⁡</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1" xref="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml"><mo id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml">(</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.cmml"><mn id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.1.cmml">−</mo><mi id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.3" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.4.4.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><eq id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"></eq><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.1.cmml" xref="S3.E2.m1.4.4.3">subscript</csymbol><ci id="S3.E2.m1.4.4.3.2.cmml" xref="S3.E2.m1.4.4.3.2">ℒ</ci><apply id="S3.E2.m1.4.4.3.3.cmml" xref="S3.E2.m1.4.4.3.3"><times id="S3.E2.m1.4.4.3.3.1.cmml" xref="S3.E2.m1.4.4.3.3.1"></times><ci id="S3.E2.m1.4.4.3.3.2.cmml" xref="S3.E2.m1.4.4.3.3.2">𝑐</ci><ci id="S3.E2.m1.4.4.3.3.3.cmml" xref="S3.E2.m1.4.4.3.3.3">𝑙</ci><ci id="S3.E2.m1.4.4.3.3.4.cmml" xref="S3.E2.m1.4.4.3.3.4">𝑠</ci></apply></apply><apply id="S3.E2.m1.4.4.1.cmml" xref="S3.E2.m1.4.4.1"><minus id="S3.E2.m1.4.4.1.2.cmml" xref="S3.E2.m1.4.4.1"></minus><apply id="S3.E2.m1.4.4.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1"><plus id="S3.E2.m1.4.4.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3"></plus><apply id="S3.E2.m1.4.4.1.1.1.1.4.cmml" xref="S3.E2.m1.4.4.1.1.1.1.4"><ci id="S3.E2.m1.4.4.1.1.1.1.4.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.4.1">⋅</ci><ci id="S3.E2.m1.4.4.1.1.1.1.4.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.4.2">𝑦</ci><apply id="S3.E2.m1.4.4.1.1.1.1.4.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.4.3.2"><log id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"></log><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝑥</ci></apply></apply><apply id="S3.E2.m1.4.4.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2"><ci id="S3.E2.m1.4.4.1.1.1.1.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.3">⋅</ci><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1"><minus id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1"></minus><cn id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3">𝑦</ci></apply><apply id="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1"><log id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"></log><apply id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1"><minus id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.1"></minus><cn id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.2.cmml" type="integer" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.2">1</cn><ci id="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2.1.1.1.3">𝑥</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\mathcal{L}_{cls}=-\left(y\cdot\log(x)+(1-y)\cdot\log(1-x)\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT = - ( italic_y ⋅ roman_log ( italic_x ) + ( 1 - italic_y ) ⋅ roman_log ( 1 - italic_x ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SSx3.SSSx2.p3.2">where <math alttext="y" class="ltx_Math" display="inline" id="S3.SSx3.SSSx2.p3.1.m1.1"><semantics id="S3.SSx3.SSSx2.p3.1.m1.1a"><mi id="S3.SSx3.SSSx2.p3.1.m1.1.1" xref="S3.SSx3.SSSx2.p3.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx2.p3.1.m1.1b"><ci id="S3.SSx3.SSSx2.p3.1.m1.1.1.cmml" xref="S3.SSx3.SSSx2.p3.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx2.p3.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx2.p3.1.m1.1d">italic_y</annotation></semantics></math> denotes the label of the training sample and <math alttext="x" class="ltx_Math" display="inline" id="S3.SSx3.SSSx2.p3.2.m2.1"><semantics id="S3.SSx3.SSSx2.p3.2.m2.1a"><mi id="S3.SSx3.SSSx2.p3.2.m2.1.1" xref="S3.SSx3.SSSx2.p3.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx2.p3.2.m2.1b"><ci id="S3.SSx3.SSSx2.p3.2.m2.1.1.cmml" xref="S3.SSx3.SSSx2.p3.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx2.p3.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx2.p3.2.m2.1d">italic_x</annotation></semantics></math> denotes the predicted logit.</p>
</div>
<div class="ltx_para" id="S3.SSx3.SSSx2.p4">
<p class="ltx_p" id="S3.SSx3.SSSx2.p4.1">Empirically, next item prediction can also be used as an auxiliary loss in discriminative models to further enhance performance. Hence, the final loss can be formulated as follows:</p>
</div>
<div class="ltx_para" id="S3.SSx3.SSSx2.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{dis}=\lambda\mathcal{L}_{gen}+\mathcal{L}_{cls}" class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><msub id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.2.2" xref="S3.E3.m1.1.1.2.2.cmml">ℒ</mi><mrow id="S3.E3.m1.1.1.2.3" xref="S3.E3.m1.1.1.2.3.cmml"><mi id="S3.E3.m1.1.1.2.3.2" xref="S3.E3.m1.1.1.2.3.2.cmml">d</mi><mo id="S3.E3.m1.1.1.2.3.1" xref="S3.E3.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.2.3.3" xref="S3.E3.m1.1.1.2.3.3.cmml">i</mi><mo id="S3.E3.m1.1.1.2.3.1a" xref="S3.E3.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.2.3.4" xref="S3.E3.m1.1.1.2.3.4.cmml">s</mi></mrow></msub><mo id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml"><mrow id="S3.E3.m1.1.1.3.2" xref="S3.E3.m1.1.1.3.2.cmml"><mi id="S3.E3.m1.1.1.3.2.2" xref="S3.E3.m1.1.1.3.2.2.cmml">λ</mi><mo id="S3.E3.m1.1.1.3.2.1" xref="S3.E3.m1.1.1.3.2.1.cmml">⁢</mo><msub id="S3.E3.m1.1.1.3.2.3" xref="S3.E3.m1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.3.2.3.2" xref="S3.E3.m1.1.1.3.2.3.2.cmml">ℒ</mi><mrow id="S3.E3.m1.1.1.3.2.3.3" xref="S3.E3.m1.1.1.3.2.3.3.cmml"><mi id="S3.E3.m1.1.1.3.2.3.3.2" xref="S3.E3.m1.1.1.3.2.3.3.2.cmml">g</mi><mo id="S3.E3.m1.1.1.3.2.3.3.1" xref="S3.E3.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.3.2.3.3.3" xref="S3.E3.m1.1.1.3.2.3.3.3.cmml">e</mi><mo id="S3.E3.m1.1.1.3.2.3.3.1a" xref="S3.E3.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.3.2.3.3.4" xref="S3.E3.m1.1.1.3.2.3.3.4.cmml">n</mi></mrow></msub></mrow><mo id="S3.E3.m1.1.1.3.1" xref="S3.E3.m1.1.1.3.1.cmml">+</mo><msub id="S3.E3.m1.1.1.3.3" xref="S3.E3.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.3.3.2" xref="S3.E3.m1.1.1.3.3.2.cmml">ℒ</mi><mrow id="S3.E3.m1.1.1.3.3.3" xref="S3.E3.m1.1.1.3.3.3.cmml"><mi id="S3.E3.m1.1.1.3.3.3.2" xref="S3.E3.m1.1.1.3.3.3.2.cmml">c</mi><mo id="S3.E3.m1.1.1.3.3.3.1" xref="S3.E3.m1.1.1.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.3.3.3.3" xref="S3.E3.m1.1.1.3.3.3.3.cmml">l</mi><mo id="S3.E3.m1.1.1.3.3.3.1a" xref="S3.E3.m1.1.1.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.3.3.3.4" xref="S3.E3.m1.1.1.3.3.3.4.cmml">s</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"></eq><apply id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.2.2">ℒ</ci><apply id="S3.E3.m1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.2.3"><times id="S3.E3.m1.1.1.2.3.1.cmml" xref="S3.E3.m1.1.1.2.3.1"></times><ci id="S3.E3.m1.1.1.2.3.2.cmml" xref="S3.E3.m1.1.1.2.3.2">𝑑</ci><ci id="S3.E3.m1.1.1.2.3.3.cmml" xref="S3.E3.m1.1.1.2.3.3">𝑖</ci><ci id="S3.E3.m1.1.1.2.3.4.cmml" xref="S3.E3.m1.1.1.2.3.4">𝑠</ci></apply></apply><apply id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3"><plus id="S3.E3.m1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.3.1"></plus><apply id="S3.E3.m1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.3.2"><times id="S3.E3.m1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.3.2.1"></times><ci id="S3.E3.m1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.3.2.2">𝜆</ci><apply id="S3.E3.m1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.3.1.cmml" xref="S3.E3.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E3.m1.1.1.3.2.3.2.cmml" xref="S3.E3.m1.1.1.3.2.3.2">ℒ</ci><apply id="S3.E3.m1.1.1.3.2.3.3.cmml" xref="S3.E3.m1.1.1.3.2.3.3"><times id="S3.E3.m1.1.1.3.2.3.3.1.cmml" xref="S3.E3.m1.1.1.3.2.3.3.1"></times><ci id="S3.E3.m1.1.1.3.2.3.3.2.cmml" xref="S3.E3.m1.1.1.3.2.3.3.2">𝑔</ci><ci id="S3.E3.m1.1.1.3.2.3.3.3.cmml" xref="S3.E3.m1.1.1.3.2.3.3.3">𝑒</ci><ci id="S3.E3.m1.1.1.3.2.3.3.4.cmml" xref="S3.E3.m1.1.1.3.2.3.3.4">𝑛</ci></apply></apply></apply><apply id="S3.E3.m1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.3.3.2">ℒ</ci><apply id="S3.E3.m1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.3.3.3"><times id="S3.E3.m1.1.1.3.3.3.1.cmml" xref="S3.E3.m1.1.1.3.3.3.1"></times><ci id="S3.E3.m1.1.1.3.3.3.2.cmml" xref="S3.E3.m1.1.1.3.3.3.2">𝑐</ci><ci id="S3.E3.m1.1.1.3.3.3.3.cmml" xref="S3.E3.m1.1.1.3.3.3.3">𝑙</ci><ci id="S3.E3.m1.1.1.3.3.3.4.cmml" xref="S3.E3.m1.1.1.3.3.3.4">𝑠</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\mathcal{L}_{dis}=\lambda\mathcal{L}_{gen}+\mathcal{L}_{cls}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">caligraphic_L start_POSTSUBSCRIPT italic_d italic_i italic_s end_POSTSUBSCRIPT = italic_λ caligraphic_L start_POSTSUBSCRIPT italic_g italic_e italic_n end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SSx3.SSSx2.p5.1">where <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SSx3.SSSx2.p5.1.m1.1"><semantics id="S3.SSx3.SSSx2.p5.1.m1.1a"><mi id="S3.SSx3.SSSx2.p5.1.m1.1.1" xref="S3.SSx3.SSSx2.p5.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SSx3.SSSx2.p5.1.m1.1b"><ci id="S3.SSx3.SSSx2.p5.1.m1.1.1.cmml" xref="S3.SSx3.SSSx2.p5.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SSx3.SSSx2.p5.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SSx3.SSSx2.p5.1.m1.1d">italic_λ</annotation></semantics></math> controls the weight of the auxiliary loss.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we first introduce the basic experimental settings, and then numerous experiments are conducted to address the following research questions:</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">RQ1: Does the general pre-training of the LLM and the fine-tuning with recommendation objectives improve the final recommendation performance?</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">RQ2: Does HLLM have good scalability?</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">RQ3: Are the advantages of HLLM significant compared with other state-of-the-art models?</p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">RQ4: How does the training and serving efficiency compare with ID-based models?</p>
</div>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1">Finally, we demonstrate how to deploy HLLM in online scenarios and achieve real-world benefits.</p>
</div>
<section class="ltx_subsection" id="S4.SSx1">
<h3 class="ltx_title ltx_title_subsection">Datasets and Evaluation Setup</h3>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.1.1.1.1">Dataset</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.2">#User</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.3">#Item</th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.4">#Interaction</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.2.1.1">Pixel200K</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.2">200,000</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.3">96,282</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T1.1.2.1.4">3,965,656</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.3.2.1">Pixel1M</th>
<td class="ltx_td ltx_align_right" id="S4.T1.1.3.2.2">1,001,822</td>
<td class="ltx_td ltx_align_right" id="S4.T1.1.3.2.3">100,541</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T1.1.3.2.4">19,886,579</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.4.3.1">Pixel8M</th>
<td class="ltx_td ltx_align_right" id="S4.T1.1.4.3.2">8,886,078</td>
<td class="ltx_td ltx_align_right" id="S4.T1.1.4.3.3">407,082</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T1.1.4.3.4">158,488,652</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.1.5.4.1">Books</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.5.4.2">694,898</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.5.4.3">686,624</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T1.1.5.4.4">10,053,086</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Statics of PixelRec and Amazon Book Reviews.</figcaption>
</figure>
<div class="ltx_para" id="S4.SSx1.p1">
<p class="ltx_p" id="S4.SSx1.p1.1">For offline experiments, we evaluate HLLM on two large-scale datasets: PixelRec (including three subsets: 200K, 1M, and 8M) <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib5" title="">2024</a>)</cite>, and Amazon Book Reviews (Books) <cite class="ltx_cite ltx_citemacro_citep">(McAuley et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib20" title="">2015</a>)</cite>. Consistent with previous works <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib5" title="">2024</a>; Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite>, we adopt the same data preprocessing and evaluation protocols to ensure a fair comparison. A more detailed analysis of these datasets after preprocessing is presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T1" title="Table 1 ‣ Datasets and Evaluation Setup ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">1</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2.F5" title="Figure 5 ‣ Parameters of Item LLM and User LLM ‣ Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">5</span></a>. We utilize a leave-one-out approach to split the data into training, validation, and testing sets. Performance is measured using the metrics Recall@K (R@K) and NDCG@K (N@K). All open-source datasets are employed solely for training and evaluating in offline experiments.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1">Item LLM</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.2">User LLM</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.3">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.4">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.5">N@5</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.6">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.2.1.1">Scratch</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.2.1.2">Scratch</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.2.1.3">3.330</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.2.1.4">5.063</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.2.1.5">2.199</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T2.1.2.1.6">2.755</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<td class="ltx_td ltx_align_left" id="S4.T2.1.3.2.1">Scratch</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.2.2.1">Pre-trained</span></td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.3.2.3">3.556</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.3.2.4">5.416</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.3.2.5">2.371</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.1.3.2.6">2.969</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<td class="ltx_td ltx_align_left" id="S4.T2.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.4.3.1.1">Pre-trained</span></td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.4.3.2">Scratch</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.4.3.3">3.521</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.4.3.4">5.331</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.4.3.5">2.358</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.1.4.3.6">2.940</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.1.1">Pre-trained</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.5.4.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.2.1">Pre-trained</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.5.4.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.3.1">3.755</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.5.4.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.4.1">5.581</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.5.4.5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.5.1">2.513</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S4.T2.1.5.4.6"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.6.1">3.100</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ablation studies of pre-training on Pixel200K with HLLM-1B.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SSx2">
<h3 class="ltx_title ltx_title_subsection">Baselines and Training</h3>
<div class="ltx_para" id="S4.SSx2.p1">
<p class="ltx_p" id="S4.SSx2.p1.1">For baselines, we use two ID-based sequential recommenders SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib13" title="">2018</a>)</cite>, and HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite>. They are all aimed at industrial applications and boast state-of-the-art performance.</p>
</div>
<div class="ltx_para" id="S4.SSx2.p2">
<p class="ltx_p" id="S4.SSx2.p2.1">For offline experiments, the generative recommendation is used to stay consistent with other methods. For the online A/B test, discriminative recommendation is used to better align with the online system<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Experiments demonstrated that most conclusions drawn from the academic dataset still hold true on large-scale industrial benchmarks. </span></span></span>.</p>
</div>
<div class="ltx_para" id="S4.SSx2.p3">
<p class="ltx_p" id="S4.SSx2.p3.1">In HLLM-1B, we use TinyLlama-1.1B <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib41" title="">2024b</a>)</cite> for both Item LLM and User LLM. Correspondingly, in HLLM-7B, we utilize Baichuan2-7B <cite class="ltx_cite ltx_citemacro_citep">(Baichuan <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib2" title="">2023</a>)</cite> for both.
Due to resource constraints, HLLMs are trained only 5 epochs on PixelRec and Amazon Reviews while other models are trained 50 and 200 epochs, respectively. The learning rate is set to 1e-4. Each item’s text length is truncated to a maximum of 256.
On PixelRec, following PixelNet <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib5" title="">2024</a>)</cite>, we utilize a batch size of 512. The maximum sequence length is set to 10, and the ratio of positive to negative samples is 1:5632.
On Books, we utilize a batch size of 128, set a maximum sequence length of 50, and the number of negative samples is 512.</p>
</div>
<div class="ltx_para" id="S4.SSx2.p4">
<p class="ltx_p" id="S4.SSx2.p4.1">For a fair comparison, we also implemented SASRec-1B (replacing its network structure with TinyLlama-1.1B) and HSTU-1B, which uses the same hidden size and number of layers as TinyLlama-1.1B but has only 462M parameters due to the elimination of the traditional FFN.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SSx3">
<h3 class="ltx_title ltx_title_subsection">Pre-training and Fine-tuning (RQ1)</h3>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.2">#Tokens</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.3">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.4">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.5">N@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.6">N@10</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1">CSR <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.1">0T</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.2">3.330</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.3">5.047</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.4">2.199</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.5">2.755</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T3.1.2.1.6">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.1">0.1T</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.2">3.539</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.3">5.142</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.4">2.399</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.5">2.915</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.1.3.2.6">46.11</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<td class="ltx_td ltx_align_left" id="S4.T3.1.4.3.1">1T</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.4.3.2">3.613</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.4.3.3">5.409</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.4.3.4">2.414</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.4.3.5">2.993</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.1.4.3.6">50.22</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<td class="ltx_td ltx_align_left" id="S4.T3.1.5.4.1">1T+chat</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.5.4.2">3.610</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.5.4.3">5.387</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.5.4.4">2.411</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.5.4.5">2.984</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.1.5.4.6">51.36</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.5">
<td class="ltx_td ltx_align_left" id="S4.T3.1.6.5.1">2T</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.6.5.2">3.650</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.6.5.3">5.510</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.6.5.4">2.466</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.6.5.5">3.063</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.1.6.5.6">51.64</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.7.6.1">3T</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.7.6.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.2.1">3.755</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.7.6.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.3.1">5.581</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.7.6.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.4.1">2.513</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.7.6.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.5.1">3.100</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S4.T3.1.7.6.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.6.1">52.99</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The impact of different pre-training token counts on Pixel200K with HLLM-1B. “+chat” means SFT on conversation data.
The CSR metric is the average performance on the common sense reasoning tasks.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.1">Item LLM</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.2">User LLM</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.3">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.4">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.5">N@5</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.6">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.1">Frozen</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.2.1.2.1">Learnable</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.3">0.588</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.4">0.945</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.5">0.372</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T4.1.2.1.6">0.486</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.3.2">
<td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.1.3.2.1.1">Learnable</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.2">Frozen</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.3">1.619</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.4">2.470</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.5">1.070</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.3.2.6">1.343</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.4.3">
<td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T4.1.4.3.1.1">Learnable</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.4.3.2.1">Learnable</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T4.1.4.3.3.1">3.755</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T4.1.4.3.4.1">5.581</span></td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T4.1.4.3.5.1">2.513</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.4.3.6"><span class="ltx_text ltx_font_bold" id="S4.T4.1.4.3.6.1">3.100</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" colspan="2" id="S4.T4.1.5.4.1">SASRec-1B</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T4.1.5.4.2">1.973</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T4.1.5.4.3">2.868</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T4.1.5.4.4">1.352</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t" id="S4.T4.1.5.4.5">1.640</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation studies of fine-tuning on Pixel200K with HLLM-1B.</figcaption>
</figure>
<div class="ltx_para" id="S4.SSx3.p1">
<p class="ltx_p" id="S4.SSx3.p1.1">As clearly seen from Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T2" title="Table 2 ‣ Datasets and Evaluation Setup ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">2</span></a>, pre-trained weights are beneficial for HLLM, including both item feature extraction and user interest modeling. Furthermore, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T3" title="Table 3 ‣ Pre-training and Fine-tuning (RQ1) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">3</span></a>, the performance is positively correlated with the number of pre-trained tokens, indicating that the quality of pre-trained weights also impacts the recommendation task.
However, supervised fine-tuning (SFT) on conversation data can result in slight negative effects, probably because world knowledge is primarily acquired during the pre-training stage, and SFT mainly enhances instruction-following abilities, which do not aid in recommendation tasks <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib42" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SSx3.p2">
<p class="ltx_p" id="S4.SSx3.p2.1">It is also evident that fine-tuning both the Item LLM and User LLM is crucial for outperforming ID-based models, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T4" title="Table 4 ‣ Pre-training and Fine-tuning (RQ1) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">4</span></a>.
When we freeze the Item LLM and only fine-tune the User LLM, using mean pooling of all token outputs in the last layer of TinyLlama-1.1B as item features, we find that the performance is very poor. This indicates that LLMs trained on predicting the next token are not directly suitable as feature extractors.
Similarly, when we use an Item LLM that has been fine-tuned on Pixel200K and freeze the pre-trained User LLM, the performance remains critically low.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SSx4">
<h3 class="ltx_title ltx_title_subsection">Scaling Up (RQ2)</h3>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.1">Item Model</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.2">#Params</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.3">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.4">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.5">N@5</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.6">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.2.1.1">BERT-Base</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.2.1.2">110M</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.2.1.3">2.576</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.2.1.4">4.020</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.2.1.5">1.694</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T5.1.2.1.6">2.158</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.3.2">
<td class="ltx_td ltx_align_left" id="S4.T5.1.3.2.1">BERT-Large</td>
<td class="ltx_td ltx_align_left" id="S4.T5.1.3.2.2">340M</td>
<td class="ltx_td ltx_align_left" id="S4.T5.1.3.2.3">3.032</td>
<td class="ltx_td ltx_align_left" id="S4.T5.1.3.2.4">4.635</td>
<td class="ltx_td ltx_align_left" id="S4.T5.1.3.2.5">1.993</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T5.1.3.2.6">2.508</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T5.1.4.3.1">TinyLlama</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T5.1.4.3.2">1.1B</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T5.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T5.1.4.3.3.1">3.484</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T5.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T5.1.4.3.4.1">5.239</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T5.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T5.1.4.3.5.1">2.319</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S4.T5.1.4.3.6"><span class="ltx_text ltx_font_bold" id="S4.T5.1.4.3.6.1">2.883</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Experiments with different sizes of the item model on Pixel200K. SASRec is used as the user model for all.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.1">User Model</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.2">#Params</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.3">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.4">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.5">N@5</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.6">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.2.1.1">SASRec</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.2.1.2">4M</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.2.1.3">3.484</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.2.1.4">5.239</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.2.1.5">2.319</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T6.1.2.1.6">2.883</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.3.2">
<td class="ltx_td ltx_align_left" id="S4.T6.1.3.2.1">Llama-2L</td>
<td class="ltx_td ltx_align_left" id="S4.T6.1.3.2.2">0.1B</td>
<td class="ltx_td ltx_align_left" id="S4.T6.1.3.2.3">3.494</td>
<td class="ltx_td ltx_align_left" id="S4.T6.1.3.2.4">5.233</td>
<td class="ltx_td ltx_align_left" id="S4.T6.1.3.2.5">2.338</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.3.2.6">2.898</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T6.1.4.3.1">TinyLlama</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T6.1.4.3.2">1.1B</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T6.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T6.1.4.3.3.1">3.521</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T6.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T6.1.4.3.4.1">5.331</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T6.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T6.1.4.3.5.1">2.358</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S4.T6.1.4.3.6"><span class="ltx_text ltx_font_bold" id="S4.T6.1.4.3.6.1">2.940</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Experiments with different sizes of the user model on Pixel200K. Llama-2L maintains the same architecture as Llama but uses only 2 decoder layers. TinyLlama-1.1B is used as the item model for all. All user models are trained from scratch.</figcaption>
</figure>
<div class="ltx_para" id="S4.SSx4.p1">
<p class="ltx_p" id="S4.SSx4.p1.1">The experimental results for increasing the model’s parameter count are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T5" title="Table 5 ‣ Scaling Up (RQ2) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">5</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T6" title="Table 6 ‣ Scaling Up (RQ2) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">6</span></a>. It can be observed that the growth in the number of parameters for both Item LLM and User LLM consistently leads to performance improvements.
Finally, we scale up both the Item LLM and User LLM from 1 billion parameters to 7 billion parameters on the Amazon Books. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T7" title="Table 7 ‣ HLLM vs. SOTA Methods (RQ3) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">7</span></a>, this leads to further performance improvements, demonstrating that HLLM has excellent scalability.</p>
</div>
<div class="ltx_para" id="S4.SSx4.p2">
<p class="ltx_p" id="S4.SSx4.p2.1">To explore scalability of data volume, we sampled multiple different scales of data from Pixel8M for training, ranging from 0.1M to 8M in size.
From Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.F3" title="Figure 3 ‣ HLLM vs. SOTA Methods (RQ3) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">3</span></a>, it is evident that HLLM demonstrates remarkable scalability across various data volumes. With increasing data, significant enhancements in performance are observed, and no performance bottlenecks are observed at the current data scale.</p>
</div>
<div class="ltx_para" id="S4.SSx4.p3">
<p class="ltx_p" id="S4.SSx4.p3.1">We also conducted more comprehensive ablation experiments related to scaling up on a large-scale industrial recommendation dataset to demonstrate the scalability of the HLLM architecture, with detailed experimental results presented in the appendix.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SSx5">
<h3 class="ltx_title ltx_title_subsection">HLLM vs. SOTA Methods (RQ3)</h3>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.1" style="width:212.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="624" id="S4.F3.1.g1" src="x3.png" width="969"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.2" style="width:212.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="604" id="S4.F3.2.g1" src="x4.png" width="968"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Experiments of HLLM’s performance at various data scales. Recall@5 and NDCG@5 are reported.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T7.13">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.13.14.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T7.13.14.1.1">Dataset</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T7.13.14.1.2">Method</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T7.13.14.1.3">R@10</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T7.13.14.1.4">R@50</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T7.13.14.1.5">R@200</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T7.13.14.1.6">N@10</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T7.13.14.1.7">N@50</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T7.13.14.1.8">N@200</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T7.13.14.1.9">Impv. (avg)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.1.1.2" rowspan="6"><span class="ltx_text" id="S4.T7.1.1.2.1">Pixel8M</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.1.1.1">
<math alttext="\text{SASRec}_{\text{vit}}" class="ltx_Math" display="inline" id="S4.T7.1.1.1.m1.1"><semantics id="S4.T7.1.1.1.m1.1a"><msub id="S4.T7.1.1.1.m1.1.1" xref="S4.T7.1.1.1.m1.1.1.cmml"><mtext id="S4.T7.1.1.1.m1.1.1.2" xref="S4.T7.1.1.1.m1.1.1.2a.cmml">SASRec</mtext><mtext id="S4.T7.1.1.1.m1.1.1.3" xref="S4.T7.1.1.1.m1.1.1.3a.cmml">vit</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T7.1.1.1.m1.1b"><apply id="S4.T7.1.1.1.m1.1.1.cmml" xref="S4.T7.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.1.1.1.m1.1.1.1.cmml" xref="S4.T7.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T7.1.1.1.m1.1.1.2a.cmml" xref="S4.T7.1.1.1.m1.1.1.2"><mtext id="S4.T7.1.1.1.m1.1.1.2.cmml" xref="S4.T7.1.1.1.m1.1.1.2">SASRec</mtext></ci><ci id="S4.T7.1.1.1.m1.1.1.3a.cmml" xref="S4.T7.1.1.1.m1.1.1.3"><mtext id="S4.T7.1.1.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.T7.1.1.1.m1.1.1.3">vit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.1.1.1.m1.1c">\text{SASRec}_{\text{vit}}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.1.1.1.m1.1d">SASRec start_POSTSUBSCRIPT vit end_POSTSUBSCRIPT</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib5" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.1.1.3">3.589</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.1.1.4">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.1.1.5">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.1.1.6">1.941</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.1.1.7">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.1.1.8">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.1.1.9">-27.72%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.2.2.1">HSTU<sup class="ltx_sup" id="S4.T7.2.2.1.1">∗</sup> <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.2.2.2">4.848</td>
<td class="ltx_td ltx_align_right" id="S4.T7.2.2.3">10.315</td>
<td class="ltx_td ltx_align_right" id="S4.T7.2.2.4">18.327</td>
<td class="ltx_td ltx_align_right" id="S4.T7.2.2.5">2.752</td>
<td class="ltx_td ltx_align_right" id="S4.T7.2.2.6">3.939</td>
<td class="ltx_td ltx_align_right" id="S4.T7.2.2.7">5.135</td>
<td class="ltx_td ltx_align_right" id="S4.T7.2.2.8">+0.0%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.3.3.1">SASRec<sup class="ltx_sup" id="S4.T7.3.3.1.1">∗</sup>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.3.3.2">5.083</td>
<td class="ltx_td ltx_align_right" id="S4.T7.3.3.3">10.667</td>
<td class="ltx_td ltx_align_right" id="S4.T7.3.3.4">18.754</td>
<td class="ltx_td ltx_align_right" id="S4.T7.3.3.5">2.911</td>
<td class="ltx_td ltx_align_right" id="S4.T7.3.3.6">4.123</td>
<td class="ltx_td ltx_align_right" id="S4.T7.3.3.7">5.331</td>
<td class="ltx_td ltx_align_right" id="S4.T7.3.3.8">+3.82%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.4.4.1">HSTU-1B<sup class="ltx_sup" id="S4.T7.4.4.1.1">∗</sup>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.4.4.2">5.120</td>
<td class="ltx_td ltx_align_right" id="S4.T7.4.4.3">11.010</td>
<td class="ltx_td ltx_align_right" id="S4.T7.4.4.4">19.393</td>
<td class="ltx_td ltx_align_right" id="S4.T7.4.4.5">2.879</td>
<td class="ltx_td ltx_align_right" id="S4.T7.4.4.6">4.159</td>
<td class="ltx_td ltx_align_right" id="S4.T7.4.4.7">5.411</td>
<td class="ltx_td ltx_align_right" id="S4.T7.4.4.8">+5.37%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.5.5.1">SASRec-1B<sup class="ltx_sup" id="S4.T7.5.5.1.1">∗</sup>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.5.5.2">5.142</td>
<td class="ltx_td ltx_align_right" id="S4.T7.5.5.3">10.899</td>
<td class="ltx_td ltx_align_right" id="S4.T7.5.5.4">19.044</td>
<td class="ltx_td ltx_align_right" id="S4.T7.5.5.5">2.915</td>
<td class="ltx_td ltx_align_right" id="S4.T7.5.5.6">4.166</td>
<td class="ltx_td ltx_align_right" id="S4.T7.5.5.7">5.383</td>
<td class="ltx_td ltx_align_right" id="S4.T7.5.5.8">+4.83%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.13.15.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.13.15.1.1">HLLM-1B (Ours)</th>
<td class="ltx_td ltx_align_right" id="S4.T7.13.15.1.2"><span class="ltx_text ltx_font_bold" id="S4.T7.13.15.1.2.1">6.129</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.15.1.3"><span class="ltx_text ltx_font_bold" id="S4.T7.13.15.1.3.1">12.475</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.15.1.4"><span class="ltx_text ltx_font_bold" id="S4.T7.13.15.1.4.1">21.179</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.15.1.5"><span class="ltx_text ltx_font_bold" id="S4.T7.13.15.1.5.1">3.539</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.15.1.6"><span class="ltx_text ltx_font_bold" id="S4.T7.13.15.1.6.1">4.919</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.15.1.7"><span class="ltx_text ltx_font_bold" id="S4.T7.13.15.1.7.1">6.221</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.15.1.8"><span class="ltx_text ltx_font_bold" id="S4.T7.13.15.1.8.1">+22.93%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.13.16.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T7.13.16.2.1" rowspan="12"><span class="ltx_text" id="S4.T7.13.16.2.1.1">Amazon Books</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.13.16.2.2">SASRec <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib13" title="">2018</a>)</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.13.16.2.3">3.06</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.13.16.2.4">7.54</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.13.16.2.5">14.31</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.13.16.2.6">1.64</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.13.16.2.7">2.60</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.13.16.2.8">3.62</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.13.16.2.9">+0.0%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.13.17.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.13.17.3.1">LEARN <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib12" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.13.17.3.2">4.07</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.17.3.3">9.79</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.17.3.4">18.74</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.17.3.5">2.24</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.17.3.6">3.71</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.17.3.7">4.83</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.17.3.8">+34.42%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.13.18.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.13.18.4.1">HSTU-large <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.13.18.4.2">4.78</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.18.4.3">10.82</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.18.4.4">19.08</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.18.4.5">2.62</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.18.4.6">3.93</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.18.4.7">5.17</td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.18.4.8">+47.80%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.6.6.1">SASRec<sup class="ltx_sup" id="S4.T7.6.6.1.1">∗</sup>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.6.6.2">5.35</td>
<td class="ltx_td ltx_align_right" id="S4.T7.6.6.3">11.91</td>
<td class="ltx_td ltx_align_right" id="S4.T7.6.6.4">21.02</td>
<td class="ltx_td ltx_align_right" id="S4.T7.6.6.5">2.98</td>
<td class="ltx_td ltx_align_right" id="S4.T7.6.6.6">4.40</td>
<td class="ltx_td ltx_align_right" id="S4.T7.6.6.7">5.76</td>
<td class="ltx_td ltx_align_right" id="S4.T7.6.6.8">+64.96%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.7.7.1">SASRec-1B<sup class="ltx_sup" id="S4.T7.7.7.1.1">∗</sup>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.7.7.2">5.09</td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.7.3">11.11</td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.7.4">19.45</td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.7.5">2.86</td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.7.6">4.17</td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.7.7">5.42</td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.7.8">+55.68%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.8.8.1">HSTU-large<sup class="ltx_sup" id="S4.T7.8.8.1.1">∗</sup>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.8.8.2">5.00</td>
<td class="ltx_td ltx_align_right" id="S4.T7.8.8.3">11.29</td>
<td class="ltx_td ltx_align_right" id="S4.T7.8.8.4">20.13</td>
<td class="ltx_td ltx_align_right" id="S4.T7.8.8.5">2.78</td>
<td class="ltx_td ltx_align_right" id="S4.T7.8.8.6">4.14</td>
<td class="ltx_td ltx_align_right" id="S4.T7.8.8.7">5.47</td>
<td class="ltx_td ltx_align_right" id="S4.T7.8.8.8">+55.61%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.9.9.1">HSTU-1B<sup class="ltx_sup" id="S4.T7.9.9.1.1">∗</sup>
</th>
<td class="ltx_td ltx_align_right" id="S4.T7.9.9.2">5.25</td>
<td class="ltx_td ltx_align_right" id="S4.T7.9.9.3">12.03</td>
<td class="ltx_td ltx_align_right" id="S4.T7.9.9.4">21.60</td>
<td class="ltx_td ltx_align_right" id="S4.T7.9.9.5">2.89</td>
<td class="ltx_td ltx_align_right" id="S4.T7.9.9.6">4.36</td>
<td class="ltx_td ltx_align_right" id="S4.T7.9.9.7">5.80</td>
<td class="ltx_td ltx_align_right" id="S4.T7.9.9.8">+64.37%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.13.19.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.13.19.5.1">HLLM-1B (Ours)</th>
<td class="ltx_td ltx_align_right" id="S4.T7.13.19.5.2"><span class="ltx_text ltx_font_bold" id="S4.T7.13.19.5.2.1">6.97</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.19.5.3"><span class="ltx_text ltx_font_bold" id="S4.T7.13.19.5.3.1">14.61</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.19.5.4"><span class="ltx_text ltx_font_bold" id="S4.T7.13.19.5.4.1">24.78</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.19.5.5"><span class="ltx_text ltx_font_bold" id="S4.T7.13.19.5.5.1">3.98</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.19.5.6"><span class="ltx_text ltx_font_bold" id="S4.T7.13.19.5.6.1">5.64</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.19.5.7"><span class="ltx_text ltx_font_bold" id="S4.T7.13.19.5.7.1">7.16</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.13.19.5.8"><span class="ltx_text ltx_font_bold" id="S4.T7.13.19.5.8.1">+108.68%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.10.10.1">HSTU-large<sup class="ltx_sup" id="S4.T7.10.10.1.1"><span class="ltx_text ltx_font_italic" id="S4.T7.10.10.1.1.1">†∗</span></sup>
</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.10.10.2">6.49</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.10.10.3">12.22</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.10.10.4">19.81</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.10.10.5">3.99</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.10.10.6">5.24</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.10.10.7">6.38</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.10.10.8">+88.94%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.11.11.1">HLLM-1B-Scratch<sup class="ltx_sup" id="S4.T7.11.11.1.1">†</sup> (Ours)</th>
<td class="ltx_td ltx_align_right" id="S4.T7.11.11.2">6.85</td>
<td class="ltx_td ltx_align_right" id="S4.T7.11.11.3">13.95</td>
<td class="ltx_td ltx_align_right" id="S4.T7.11.11.4">23.19</td>
<td class="ltx_td ltx_align_right" id="S4.T7.11.11.5">4.02</td>
<td class="ltx_td ltx_align_right" id="S4.T7.11.11.6">5.56</td>
<td class="ltx_td ltx_align_right" id="S4.T7.11.11.7">6.95</td>
<td class="ltx_td ltx_align_right" id="S4.T7.11.11.8">+103.65%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.12.12.1">HLLM-1B<sup class="ltx_sup" id="S4.T7.12.12.1.1">†</sup> (Ours)</th>
<td class="ltx_td ltx_align_right" id="S4.T7.12.12.2">9.28</td>
<td class="ltx_td ltx_align_right" id="S4.T7.12.12.3">17.34</td>
<td class="ltx_td ltx_align_right" id="S4.T7.12.12.4">27.22</td>
<td class="ltx_td ltx_align_right" id="S4.T7.12.12.5">5.65</td>
<td class="ltx_td ltx_align_right" id="S4.T7.12.12.6">7.41</td>
<td class="ltx_td ltx_align_right" id="S4.T7.12.12.7">8.89</td>
<td class="ltx_td ltx_align_right" id="S4.T7.12.12.8">+166.42%</td>
</tr>
<tr class="ltx_tr" id="S4.T7.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T7.13.13.1">HLLM-7B<sup class="ltx_sup" id="S4.T7.13.13.1.1">†</sup> (Ours)</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.13.13.2"><span class="ltx_text ltx_font_bold" id="S4.T7.13.13.2.1">9.39</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.13.13.3"><span class="ltx_text ltx_font_bold" id="S4.T7.13.13.3.1">17.65</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.13.13.4"><span class="ltx_text ltx_font_bold" id="S4.T7.13.13.4.1">27.59</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.13.13.5"><span class="ltx_text ltx_font_bold" id="S4.T7.13.13.5.1">5.69</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.13.13.6"><span class="ltx_text ltx_font_bold" id="S4.T7.13.13.6.1">7.50</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.13.13.7"><span class="ltx_text ltx_font_bold" id="S4.T7.13.13.7.1">8.99</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.13.13.8"><span class="ltx_text ltx_font_bold" id="S4.T7.13.13.8.1">+169.58%</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance comparison of HLLM with SOTA models. <math alttext="\text{SASRec}_{\text{vit}}" class="ltx_Math" display="inline" id="S4.T7.17.m1.1"><semantics id="S4.T7.17.m1.1b"><msub id="S4.T7.17.m1.1.1" xref="S4.T7.17.m1.1.1.cmml"><mtext id="S4.T7.17.m1.1.1.2" xref="S4.T7.17.m1.1.1.2a.cmml">SASRec</mtext><mtext id="S4.T7.17.m1.1.1.3" xref="S4.T7.17.m1.1.1.3a.cmml">vit</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T7.17.m1.1c"><apply id="S4.T7.17.m1.1.1.cmml" xref="S4.T7.17.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.17.m1.1.1.1.cmml" xref="S4.T7.17.m1.1.1">subscript</csymbol><ci id="S4.T7.17.m1.1.1.2a.cmml" xref="S4.T7.17.m1.1.1.2"><mtext id="S4.T7.17.m1.1.1.2.cmml" xref="S4.T7.17.m1.1.1.2">SASRec</mtext></ci><ci id="S4.T7.17.m1.1.1.3a.cmml" xref="S4.T7.17.m1.1.1.3"><mtext id="S4.T7.17.m1.1.1.3.cmml" mathsize="70%" xref="S4.T7.17.m1.1.1.3">vit</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.17.m1.1d">\text{SASRec}_{\text{vit}}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.17.m1.1e">SASRec start_POSTSUBSCRIPT vit end_POSTSUBSCRIPT</annotation></semantics></math> means SASRec uses the ViT as an image encoder for item encoding and trained by BCE loss from <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib5" title="">2024</a>)</cite>. <math alttext="*" class="ltx_Math" display="inline" id="S4.T7.18.m2.1"><semantics id="S4.T7.18.m2.1b"><mo id="S4.T7.18.m2.1.1" xref="S4.T7.18.m2.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S4.T7.18.m2.1c"><times id="S4.T7.18.m2.1.1.cmml" xref="S4.T7.18.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.18.m2.1d">*</annotation><annotation encoding="application/x-llamapun" id="S4.T7.18.m2.1e">∗</annotation></semantics></math> indicates the result is reproduced by us.
<math alttext="\dagger" class="ltx_Math" display="inline" id="S4.T7.19.m3.1"><semantics id="S4.T7.19.m3.1b"><mo id="S4.T7.19.m3.1.1" xref="S4.T7.19.m3.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T7.19.m3.1c"><ci id="S4.T7.19.m3.1.1.cmml" xref="S4.T7.19.m3.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.19.m3.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="S4.T7.19.m3.1e">†</annotation></semantics></math> indicates the number of negative samples and the batch size are increased from 512 and 128 to 28k and 512, respectively.
“Scratch” indicates both Item LLM and User LLM are trained from scratch.</figcaption>
</figure>
<div class="ltx_para" id="S4.SSx5.p1">
<p class="ltx_p" id="S4.SSx5.p1.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T7" title="Table 7 ‣ HLLM vs. SOTA Methods (RQ3) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">7</span></a>, we compare the performance of HLLM with the current state-of-the-art models, including ID-based models such as SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib13" title="">2018</a>)</cite> and HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib37" title="">2024</a>)</cite>, as well as the text-based model LEARN <cite class="ltx_cite ltx_citemacro_citep">(Jia et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#bib.bib12" title="">2024</a>)</cite> on the Pixel8M and Amazon Book Reviews datasets. They all exhibit excellent performance and are dedicated to industrial practice.</p>
</div>
<div class="ltx_para" id="S4.SSx5.p2">
<p class="ltx_p" id="S4.SSx5.p2.1">It’s clear that HLLM holds a significant performance advantage, decisively outperforming other models on all metrics across all datasets.
Under the same experimental settings, compared to the lowest-performing baseline, HLLM-1B shows an average improvement of <span class="ltx_text ltx_font_bold" id="S4.SSx5.p2.1.1">22.93%</span> on Pixel8M, and an even more significant average improvement of <span class="ltx_text ltx_font_bold" id="S4.SSx5.p2.1.2">108.68%</span> on Books. In contrast, ID-based models only show a maximum improvement of 5.37% on Pixel8M and 64.96% on Books.</p>
</div>
<div class="ltx_para" id="S4.SSx5.p3">
<p class="ltx_p" id="S4.SSx5.p3.1">Furthermore, it is notable that when ID-based models increase the number of negative samples and batch size, the performance improvements are relatively modest, especially in R@200 where HSTU-large only increases by <span class="ltx_text ltx_font_bold" id="S4.SSx5.p3.1.1">0.76</span>, while HLLM-1B increases by <span class="ltx_text ltx_font_bold" id="S4.SSx5.p3.1.2">2.44</span> under the same setting.
By further increasing the model’s parameters, HLLM-7B achieves a significant improvement of <span class="ltx_text ltx_font_bold" id="S4.SSx5.p3.1.3">169.58%</span> compared to the baseline, which is highly impressive.</p>
</div>
<div class="ltx_para" id="S4.SSx5.p4">
<p class="ltx_p" id="S4.SSx5.p4.1">The table also shows that even with fully converged ID-based models, the gains from increasing parameters are minimal.
On Pixel8M, both SASRec-1B and HSTU-1B show relatively modest improvements compared to smaller sizes, while on Books, SASRec-1B even experiences a decline in all metrics.
In contrast, for HLLM, scaling up from HLLM-1B to HLLM-7B still results in corresponding performance improvements on recommendation tasks, demonstrating the superiority of the HLLM architecture.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SSx6">
<h3 class="ltx_title ltx_title_subsection">Training and Serving Effeciency (RQ4)</h3>
<figure class="ltx_table" id="S4.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T8.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T8.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T8.1.2.1.1">Method</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.2.1.2">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.2.1.3">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.2.1.4">N@5</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.2.1.5">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T8.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T8.1.3.1.1">HSTU-1B</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T8.1.3.1.2">3.501</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T8.1.3.1.3">5.120</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T8.1.3.1.4">2.358</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T8.1.3.1.5">2.879</td>
</tr>
<tr class="ltx_tr" id="S4.T8.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T8.1.1.1"><math alttext="\text{HLLM-1B}_{\text{cache}}" class="ltx_Math" display="inline" id="S4.T8.1.1.1.m1.1"><semantics id="S4.T8.1.1.1.m1.1a"><msub id="S4.T8.1.1.1.m1.1.1" xref="S4.T8.1.1.1.m1.1.1.cmml"><mtext id="S4.T8.1.1.1.m1.1.1.2" xref="S4.T8.1.1.1.m1.1.1.2a.cmml">HLLM-1B</mtext><mtext id="S4.T8.1.1.1.m1.1.1.3" xref="S4.T8.1.1.1.m1.1.1.3a.cmml">cache</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.m1.1b"><apply id="S4.T8.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.1.1.1.m1.1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T8.1.1.1.m1.1.1.2a.cmml" xref="S4.T8.1.1.1.m1.1.1.2"><mtext id="S4.T8.1.1.1.m1.1.1.2.cmml" xref="S4.T8.1.1.1.m1.1.1.2">HLLM-1B</mtext></ci><ci id="S4.T8.1.1.1.m1.1.1.3a.cmml" xref="S4.T8.1.1.1.m1.1.1.3"><mtext id="S4.T8.1.1.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.T8.1.1.1.m1.1.1.3">cache</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.m1.1c">\text{HLLM-1B}_{\text{cache}}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.1.1.1.m1.1d">HLLM-1B start_POSTSUBSCRIPT cache end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_left" id="S4.T8.1.1.2">3.585</td>
<td class="ltx_td ltx_align_left" id="S4.T8.1.1.3">5.218</td>
<td class="ltx_td ltx_align_left" id="S4.T8.1.1.4">2.432</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.1.1.5">2.958</td>
</tr>
<tr class="ltx_tr" id="S4.T8.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T8.1.4.2.1">HLLM-1B</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T8.1.4.2.2"><span class="ltx_text ltx_font_bold" id="S4.T8.1.4.2.2.1">4.278</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T8.1.4.2.3"><span class="ltx_text ltx_font_bold" id="S4.T8.1.4.2.3.1">6.106</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T8.1.4.2.4"><span class="ltx_text ltx_font_bold" id="S4.T8.1.4.2.4.1">2.935</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S4.T8.1.4.2.5"><span class="ltx_text ltx_font_bold" id="S4.T8.1.4.2.5.1">3.524</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Experiments on the effectiveness of item caching. <math alttext="\text{HLLM-1B}_{\text{cache}}" class="ltx_Math" display="inline" id="S4.T8.3.m1.1"><semantics id="S4.T8.3.m1.1b"><msub id="S4.T8.3.m1.1.1" xref="S4.T8.3.m1.1.1.cmml"><mtext id="S4.T8.3.m1.1.1.2" xref="S4.T8.3.m1.1.1.2a.cmml">HLLM-1B</mtext><mtext id="S4.T8.3.m1.1.1.3" xref="S4.T8.3.m1.1.1.3a.cmml">cache</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T8.3.m1.1c"><apply id="S4.T8.3.m1.1.1.cmml" xref="S4.T8.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.3.m1.1.1.1.cmml" xref="S4.T8.3.m1.1.1">subscript</csymbol><ci id="S4.T8.3.m1.1.1.2a.cmml" xref="S4.T8.3.m1.1.1.2"><mtext id="S4.T8.3.m1.1.1.2.cmml" xref="S4.T8.3.m1.1.1.2">HLLM-1B</mtext></ci><ci id="S4.T8.3.m1.1.1.3a.cmml" xref="S4.T8.3.m1.1.1.3"><mtext id="S4.T8.3.m1.1.1.3.cmml" mathsize="70%" xref="S4.T8.3.m1.1.1.3">cache</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.m1.1d">\text{HLLM-1B}_{\text{cache}}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.3.m1.1e">HLLM-1B start_POSTSUBSCRIPT cache end_POSTSUBSCRIPT</annotation></semantics></math> utilizes a pre-trained item HLLM to extract item features, but the parameters are frozen.</figcaption>
</figure>
<div class="ltx_para" id="S4.SSx6.p1">
<p class="ltx_p" id="S4.SSx6.p1.1">Firstly, HLLM shows better training data efficiency than ID-based models. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.F3" title="Figure 3 ‣ HLLM vs. SOTA Methods (RQ3) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">3</span></a>, HLLM requires only one-sixth to one-fourth of the data volume to achieve performance on par with ID-based methods.</p>
</div>
<div class="ltx_para" id="S4.SSx6.p2">
<p class="ltx_p" id="S4.SSx6.p2.1">Previous extensive experiments have shown that fully fine-tuning the entire HLLM significantly improves performance but requires real-time encoding of all items during inference, which is inefficient. Thanks to the decoupling of item and user encoding in HLLM, our architecture can reduce computational complexity by caching item embeddings in advance.
To demonstrate the feasibility of item caching, we pre-trained HLLM on sequences longer than 10 from the Pixel8M dataset, truncating sequences at the tenth position to avoid data leakage, covering 3 million users. Based on this pre-trained HLLM, we freeze the Item LLM and fine-tune only the User LLM on Pixel8M. Results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.T8" title="Table 8 ‣ Training and Serving Effeciency (RQ4) ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">8</span></a> show that while freezing the Item LLM leads to some metric decreases, performance still exceeds ID-based models, proving item caching is more effective. Given that user behaviors in industrial scenarios far exceed the number of items, HLLM’s training and serving costs can match those of ID-based models.
Notably, our pre-training data constitutes less than half of Pixel8M, with some items not appearing in the pre-training data, yet we still achieve respectable performance. Experiments on industrial data show that as the amount of pre-training data increases, the gap between the item caching and the full fine-tuning is largely narrowed.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SSx7">
<h3 class="ltx_title ltx_title_subsection">Online A/B Test</h3>
<div class="ltx_para" id="S4.SSx7.p1">
<p class="ltx_p" id="S4.SSx7.p1.1">Apart from offline experiments, HLLM is also targeted at and successfully applied in real-world industrial practices.
For simplicity, flexibility, and to better align with the online system, we adopted HLLM-1B, using the discriminative recommendation approach with the late fusion variant for optimization.
Considering the balance between performance and efficiency, our training process is divided into the following three stages:</p>
</div>
<div class="ltx_para" id="S4.SSx7.p2">
<p class="ltx_p" id="S4.SSx7.p2.1">Stage I: End-to-end training of all HLLM parameters, including Item LLM and User LLM with discriminative loss.
The user history sequence length is truncated to 150 to accelerate training.</p>
</div>
<div class="ltx_para" id="S4.SSx7.p3">
<p class="ltx_p" id="S4.SSx7.p3.1">Stage II: We first use the Item LLM trained in Stage I to encode and store the embeddings of all items in the recommendation system.
We then continue to train only the User LLM by retrieving the necessary item embeddings from storage.
Since this stage only trains the User LLM, it significantly reduces the training demand, allowing us to extend the user sequence length from 150 to 1000, further enhancing the effectiveness of the User LLM.</p>
</div>
<div class="ltx_para" id="S4.SSx7.p4">
<p class="ltx_p" id="S4.SSx7.p4.1">Stage III: After extensive data training in the first two stages, the HLLM model parameters are no longer updated. We extract features for all users which are then combined with item LLM embeddings and other existing features and fed into the online recommendation model for training.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="269" id="S4.F4.g1" src="x5.png" width="829"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An overview of the online system.</figcaption>
</figure>
<div class="ltx_para" id="S4.SSx7.p5">
<p class="ltx_p" id="S4.SSx7.p5.1">Regarding serving, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#S4.F4" title="Figure 4 ‣ Online A/B Test ‣ 4 Experiments ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">4</span></a>, item embeddings are extracted when they are created, and user embeddings are updated on a daily basis only for users who had activity the previous day. Embeddings of items and users are stored for online model training and serving. Under this approach, the inference time of the online recommendation system is virtually unchanged.</p>
</div>
<div class="ltx_para" id="S4.SSx7.p6">
<p class="ltx_p" id="S4.SSx7.p6.1">Finally, we test HLLM in online A/B experiments of the ranking task. Key metrics have shown a significant increase of <span class="ltx_text ltx_font_bold" id="S4.SSx7.p6.1.1">0.705%</span>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we propose a novel Hierarchical Large Language Model (HLLM) architecture designed to enhance sequential recommendations. HLLM leverages LLMs to extract item features and model user interests, effectively integrating pre-training knowledge into the recommendation system, and it is proved that fine-tuning with recommendation objectives is essential. HLLM exhibited excellent scalability with larger model parameters. Experiments demonstrated that HLLM outperforms traditional ID-based models, achieving state-of-the-art results on academic datasets. Real-world online A/B testing further validated HLLM’s practical efficiency and applicability, marking a significant advancement in the field of recommendation systems.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Achiam, J.; Adler, S.; Agarwal, S.; Ahmad, L.; Akkaya, I.; Aleman, F. L.; Almeida, D.; Altenschmidt, J.; Altman, S.; Anadkat, S.; et al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baichuan (2023)</span>
<span class="ltx_bibblock">
Baichuan. 2023.

</span>
<span class="ltx_bibblock">Baichuan 2: Open Large-scale Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2309.10305</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baltescu et al. (2022)</span>
<span class="ltx_bibblock">
Baltescu, P.; Chen, H.; Pancha, N.; Zhai, A.; Leskovec, J.; and Rosenberg, C. 2022.

</span>
<span class="ltx_bibblock">Itemsage: Learning product embeddings for shopping recommendations at pinterest.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2703–2711.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al. (2023)</span>
<span class="ltx_bibblock">
Bao, K.; Zhang, J.; Zhang, Y.; Wang, W.; Feng, F.; and He, X. 2023.

</span>
<span class="ltx_bibblock">Tallrec: An effective and efficient tuning framework to align large language model with recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>, 1007–1014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2024)</span>
<span class="ltx_bibblock">
Cheng, Y.; Pan, Y.; Zhang, J.; Ni, Y.; Sun, A.; and Yuan, F. 2024.

</span>
<span class="ltx_bibblock">An Image Dataset for Benchmarking Recommender Systems with Raw Pixels.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2024 SIAM International Conference on Data Mining (SDM)</em>, 418–426. SIAM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al. (2022)</span>
<span class="ltx_bibblock">
Cui, Z.; Ma, J.; Zhou, C.; Zhou, J.; and Yang, H. 2022.

</span>
<span class="ltx_bibblock">M6-rec: Generative pretrained language models are open-ended recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2205.08084</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin (2018)</span>
<span class="ltx_bibblock">
Devlin, J. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:1810.04805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Friedman et al. (2023)</span>
<span class="ltx_bibblock">
Friedman, L.; Ahuja, S.; Allen, D.; Tan, Z.; Sidahmed, H.; Long, C.; Xie, J.; Schubiner, G.; Patel, A.; Lara, H.; et al. 2023.

</span>
<span class="ltx_bibblock">Leveraging large language models in conversational recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2305.07961</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goldberg et al. (1992)</span>
<span class="ltx_bibblock">
Goldberg, D.; Nichols, D.; Oki, B. M.; and Terry, D. 1992.

</span>
<span class="ltx_bibblock">Using collaborative filtering to weave an information tapestry.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Communications of the ACM</em>, 35(12): 61–70.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2017)</span>
<span class="ltx_bibblock">
Guo, H.; Tang, R.; Ye, Y.; Li, Z.; and He, X. 2017.

</span>
<span class="ltx_bibblock">DeepFM: a factorization-machine based neural network for CTR prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:1703.04247</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hidasi et al. (2015)</span>
<span class="ltx_bibblock">
Hidasi, B.; Karatzoglou, A.; Baltrunas, L.; and Tikk, D. 2015.

</span>
<span class="ltx_bibblock">Session-based recommendations with recurrent neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:1511.06939</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2024)</span>
<span class="ltx_bibblock">
Jia, J.; Wang, Y.; Li, Y.; Chen, H.; Bai, X.; Liu, Z.; Liang, J.; Chen, Q.; Li, H.; Jiang, P.; et al. 2024.

</span>
<span class="ltx_bibblock">Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2405.03988</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Kang, W.-C.; and McAuley, J. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2018 IEEE international conference on data mining (ICDM)</em>, 197–206. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al. (2023)</span>
<span class="ltx_bibblock">
Kang, W.-C.; Ni, J.; Mehta, N.; Sathiamoorthy, M.; Hong, L.; Chi, E.; and Cheng, D. Z. 2023.

</span>
<span class="ltx_bibblock">Do llms understand user preferences? evaluating llms on user rating prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2305.06474</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koren, Bell, and Volinsky (2009)</span>
<span class="ltx_bibblock">
Koren, Y.; Bell, R.; and Volinsky, C. 2009.

</span>
<span class="ltx_bibblock">Matrix factorization techniques for recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Computer</em>, 42(8): 30–37.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
Li, J.; Wang, M.; Li, J.; Fu, J.; Shen, X.; Shang, J.; and McAuley, J. 2023a.

</span>
<span class="ltx_bibblock">Text is all you need: Learning language representations for sequential recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 1258–1267.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
Li, L.; Zhang, Y.; Liu, D.; and Chen, L. 2023b.

</span>
<span class="ltx_bibblock">Large language models for generative recommendation: A survey and visionary discussions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2309.01157</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Li, Y.; Zhai, X.; Alzantot, M.; Yu, K.; Vulić, I.; Korhonen, A.; and Hammad, M. 2024.

</span>
<span class="ltx_bibblock">CALRec: Contrastive Alignment of Generative LLMs For Sequential Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2405.02429</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao et al. (2024)</span>
<span class="ltx_bibblock">
Liao, J.; Li, S.; Yang, Z.; Wu, J.; Yuan, Y.; Wang, X.; and He, X. 2024.

</span>
<span class="ltx_bibblock">Llara: Large language-recommendation assistant.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, 1785–1795.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McAuley et al. (2015)</span>
<span class="ltx_bibblock">
McAuley, J.; Targett, C.; Shi, Q.; and Van Den Hengel, A. 2015.

</span>
<span class="ltx_bibblock">Image-based recommendations on styles and substitutes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval</em>, 43–52.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neelakantan et al. (2022)</span>
<span class="ltx_bibblock">
Neelakantan, A.; Xu, T.; Puri, R.; Radford, A.; Han, J. M.; Tworek, J.; Yuan, Q.; Tezak, N.; Kim, J. W.; Hallacy, C.; et al. 2022.

</span>
<span class="ltx_bibblock">Text and code embeddings by contrastive pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2201.10005</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ning et al. (2024)</span>
<span class="ltx_bibblock">
Ning, L.; Liu, L.; Wu, J.; Wu, N.; Berlowitz, D.; Prakash, S.; Green, B.; O’Banion, S.; and Xie, J. 2024.

</span>
<span class="ltx_bibblock">User-LLM: Efficient LLM Contextualization with User Embeddings.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2402.13598</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord, Li, and Vinyals (2018)</span>
<span class="ltx_bibblock">
Oord, A. v. d.; Li, Y.; and Vinyals, O. 2018.

</span>
<span class="ltx_bibblock">Representation learning with contrastive predictive coding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:1807.03748</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock">Introducing ChatGPT.

</span>
<span class="ltx_bibblock"><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://openai.com/blog/chatgpt</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. (2024)</span>
<span class="ltx_bibblock">
Ren, X.; Wei, W.; Xia, L.; Su, L.; Cheng, S.; Wang, J.; Yin, D.; and Huang, C. 2024.

</span>
<span class="ltx_bibblock">Representation learning with large language models for recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the ACM on Web Conference 2024</em>, 3464–3475.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarwar et al. (2001)</span>
<span class="ltx_bibblock">
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2001.

</span>
<span class="ltx_bibblock">Item-based collaborative filtering recommendation algorithms.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 10th international conference on World Wide Web</em>, 285–295.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shin et al. (2023)</span>
<span class="ltx_bibblock">
Shin, K.; Kwak, H.; Kim, S. Y.; Ramström, M. N.; Jeong, J.; Ha, J.-W.; and Kim, K.-M. 2023.

</span>
<span class="ltx_bibblock">Scaling law for recommendation models: Towards general-purpose user representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 37, 4596–4604.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2019)</span>
<span class="ltx_bibblock">
Sun, F.; Liu, J.; Wu, J.; Pei, C.; Lin, X.; Ou, W.; and Jiang, P. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 28th ACM international conference on information and knowledge management</em>, 1441–1450.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2023)</span>
<span class="ltx_bibblock">
Team, G.; Anil, R.; Borgeaud, S.; Wu, Y.; Alayrac, J.-B.; Yu, J.; Soricut, R.; Schalkwyk, J.; Dai, A. M.; Hauth, A.; et al. 2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; et al. 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
Wang, J.; Lu, H.; Caverlee, J.; Chi, E. H.; and Chen, M. 2024.

</span>
<span class="ltx_bibblock">Large Language Models as Data Augmenters for Cold-Start Item Recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Companion Proceedings of the ACM on Web Conference 2024</em>, 726–729.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2017)</span>
<span class="ltx_bibblock">
Wang, R.; Fu, B.; Fu, G.; and Wang, M. 2017.

</span>
<span class="ltx_bibblock">Deep &amp; cross network for ad click predictions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the ADKDD’17</em>, 1–7.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Wang, R.; Shivanna, R.; Cheng, D.; Jain, S.; Lin, D.; Hong, L.; and Chi, E. 2021.

</span>
<span class="ltx_bibblock">Dcn v2: Improved deep &amp; cross network and practical lessons for web-scale learning to rank systems.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the web conference 2021</em>, 1785–1797.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Wu, L.; Zheng, Z.; Qiu, Z.; Wang, H.; Gu, H.; Shen, T.; Qin, C.; Zhu, C.; Zhu, H.; Liu, Q.; et al. 2023.

</span>
<span class="ltx_bibblock">A survey on large language models for recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2305.19860</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xi et al. (2023)</span>
<span class="ltx_bibblock">
Xi, Y.; Liu, W.; Lin, J.; Cai, X.; Zhu, H.; Zhu, J.; Chen, B.; Tang, R.; Zhang, W.; Zhang, R.; et al. 2023.

</span>
<span class="ltx_bibblock">Towards open-world recommendation with knowledge augmentation from large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2306.10933</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023)</span>
<span class="ltx_bibblock">
Yang, F.; Chen, Z.; Jiang, Z.; Cho, E.; Huang, X.; and Lu, Y. 2023.

</span>
<span class="ltx_bibblock">Palr: Personalization aware llms for recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2305.07622</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhai et al. (2024)</span>
<span class="ltx_bibblock">
Zhai, J.; Liao, L.; Liu, X.; Wang, Y.; Li, R.; Cao, X.; Gao, L.; Gong, Z.; Gu, F.; He, M.; et al. 2024.

</span>
<span class="ltx_bibblock">Actions speak louder than words: Trillion-parameter sequential transducers for generative recommendations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2402.17152</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhai et al. (2023)</span>
<span class="ltx_bibblock">
Zhai, J.; Zheng, X.; Wang, C.-D.; Li, H.; and Tian, Y. 2023.

</span>
<span class="ltx_bibblock">Knowledge prompt-tuning for sequential recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 31st ACM International Conference on Multimedia</em>, 6451–6461.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024a)</span>
<span class="ltx_bibblock">
Zhang, C.; Sun, Y.; Chen, J.; Lei, J.; Abdul-Mageed, M.; Wang, S.; Jin, R.; Park, S.; Yao, N.; and Long, B. 2024a.

</span>
<span class="ltx_bibblock">SPAR: Personalized Content-Based Recommendation via Long Engagement Attention.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2402.10555</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Zhang, J.; Xie, R.; Hou, Y.; Zhao, W. X.; Lin, L.; and Wen, J.-R. 2023.

</span>
<span class="ltx_bibblock">Recommendation as instruction following: A large language model empowered recommendation approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2305.07001</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024b)</span>
<span class="ltx_bibblock">
Zhang, P.; Zeng, G.; Wang, T.; and Lu, W. 2024b.

</span>
<span class="ltx_bibblock">Tinyllama: An open-source small language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2401.02385</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Zhou, C.; Liu, P.; Xu, P.; Iyer, S.; Sun, J.; Mao, Y.; Ma, X.; Efrat, A.; Yu, P.; Yu, L.; et al. 2024.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2019)</span>
<span class="ltx_bibblock">
Zhou, G.; Mou, N.; Fan, Y.; Pi, Q.; Bian, W.; Zhou, C.; Zhu, X.; and Gai, K. 2019.

</span>
<span class="ltx_bibblock">Deep interest evolution network for click-through rate prediction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, volume 33, 5941–5948.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2018)</span>
<span class="ltx_bibblock">
Zhou, G.; Zhu, X.; Song, C.; Fan, Y.; Zhu, H.; Ma, X.; Yan, Y.; Jin, J.; Li, H.; and Gai, K. 2018.

</span>
<span class="ltx_bibblock">Deep interest network for click-through rate prediction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</em>, 1059–1068.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>More Experiments on Academic Datasets</h2>
<section class="ltx_subsection" id="A1.SSx1">
<h3 class="ltx_title ltx_title_subsection">Textual Input Length and Richness of Item LLM</h3>
<figure class="ltx_table" id="A1.T9">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A1.T9.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T9.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.1">Tag</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.2">Title</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.3">Description</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.4">Length</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.5">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.6">R@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T9.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T9.1.2.1.1">
<span class="ltx_ERROR undefined" id="A1.T9.1.2.1.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_border_t" id="A1.T9.1.2.1.2"></td>
<td class="ltx_td ltx_border_t" id="A1.T9.1.2.1.3"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.1.2.1.4">64</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.1.2.1.5">0.082</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.1.2.1.6">0.196</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.3.2">
<td class="ltx_td" id="A1.T9.1.3.2.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T9.1.3.2.2">
<span class="ltx_ERROR undefined" id="A1.T9.1.3.2.2.1">\usym</span>2713</td>
<td class="ltx_td" id="A1.T9.1.3.2.3"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.3.2.4">64</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.3.2.5">3.520</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.3.2.6">5.317</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.4.3">
<td class="ltx_td ltx_align_center" id="A1.T9.1.4.3.1">
<span class="ltx_ERROR undefined" id="A1.T9.1.4.3.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="A1.T9.1.4.3.2">
<span class="ltx_ERROR undefined" id="A1.T9.1.4.3.2.1">\usym</span>2713</td>
<td class="ltx_td" id="A1.T9.1.4.3.3"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.4.3.4">64</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.4.3.5">3.610</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.4.3.6">5.439</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.5.4">
<td class="ltx_td ltx_align_center" id="A1.T9.1.5.4.1">
<span class="ltx_ERROR undefined" id="A1.T9.1.5.4.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="A1.T9.1.5.4.2">
<span class="ltx_ERROR undefined" id="A1.T9.1.5.4.2.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="A1.T9.1.5.4.3">
<span class="ltx_ERROR undefined" id="A1.T9.1.5.4.3.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.5.4.4">64</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.5.4.5">3.647</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.5.4.6">5.502</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.6.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.1.6.5.1">
<span class="ltx_ERROR undefined" id="A1.T9.1.6.5.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.1.6.5.2">
<span class="ltx_ERROR undefined" id="A1.T9.1.6.5.2.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.1.6.5.3">
<span class="ltx_ERROR undefined" id="A1.T9.1.6.5.3.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T9.1.6.5.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T9.1.6.5.5"><span class="ltx_text ltx_font_bold" id="A1.T9.1.6.5.5.1">3.755</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T9.1.6.5.6"><span class="ltx_text ltx_font_bold" id="A1.T9.1.6.5.6.1">5.581</span></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A1.T9.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T9.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T9.2.1.1.1">Tag</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T9.2.1.1.2">Title</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T9.2.1.1.3">Description</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T9.2.1.1.4">Length</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T9.2.1.1.5">N@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T9.2.1.1.6">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T9.2.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T9.2.2.1.1">
<span class="ltx_ERROR undefined" id="A1.T9.2.2.1.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_border_t" id="A1.T9.2.2.1.2"></td>
<td class="ltx_td ltx_border_t" id="A1.T9.2.2.1.3"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.2.2.1.4">64</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.2.2.1.5">0.049</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.2.2.1.6">0.086</td>
</tr>
<tr class="ltx_tr" id="A1.T9.2.3.2">
<td class="ltx_td" id="A1.T9.2.3.2.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T9.2.3.2.2">
<span class="ltx_ERROR undefined" id="A1.T9.2.3.2.2.1">\usym</span>2713</td>
<td class="ltx_td" id="A1.T9.2.3.2.3"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.3.2.4">64</td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.3.2.5">2.348</td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.3.2.6">2.926</td>
</tr>
<tr class="ltx_tr" id="A1.T9.2.4.3">
<td class="ltx_td ltx_align_center" id="A1.T9.2.4.3.1">
<span class="ltx_ERROR undefined" id="A1.T9.2.4.3.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="A1.T9.2.4.3.2">
<span class="ltx_ERROR undefined" id="A1.T9.2.4.3.2.1">\usym</span>2713</td>
<td class="ltx_td" id="A1.T9.2.4.3.3"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.4.3.4">64</td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.4.3.5">2.415</td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.4.3.6">3.003</td>
</tr>
<tr class="ltx_tr" id="A1.T9.2.5.4">
<td class="ltx_td ltx_align_center" id="A1.T9.2.5.4.1">
<span class="ltx_ERROR undefined" id="A1.T9.2.5.4.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="A1.T9.2.5.4.2">
<span class="ltx_ERROR undefined" id="A1.T9.2.5.4.2.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="A1.T9.2.5.4.3">
<span class="ltx_ERROR undefined" id="A1.T9.2.5.4.3.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.5.4.4">64</td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.5.4.5">2.430</td>
<td class="ltx_td ltx_align_left" id="A1.T9.2.5.4.6">3.026</td>
</tr>
<tr class="ltx_tr" id="A1.T9.2.6.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.2.6.5.1">
<span class="ltx_ERROR undefined" id="A1.T9.2.6.5.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.2.6.5.2">
<span class="ltx_ERROR undefined" id="A1.T9.2.6.5.2.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.2.6.5.3">
<span class="ltx_ERROR undefined" id="A1.T9.2.6.5.3.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T9.2.6.5.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T9.2.6.5.5"><span class="ltx_text ltx_font_bold" id="A1.T9.2.6.5.5.1">2.513</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T9.2.6.5.6"><span class="ltx_text ltx_font_bold" id="A1.T9.2.6.5.6.1">3.099</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Ablation studies of text length and richness on Pixel200K.</figcaption>
</figure>
<div class="ltx_para" id="A1.SSx1.p1">
<p class="ltx_p" id="A1.SSx1.p1.1">By default, we input all types of text information with a length of 256. Here, we conduct ablation experiments on text length and richness.
Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.T9" title="Table 9 ‣ Textual Input Length and Richness of Item LLM ‣ Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">9</span></a> shows that the text content has a significant impact on the final performance. Richer text content and longer text lengths allow the Item LLM to extract more detailed item features, better differentiate between items, and more effectively aid the User LLM in modeling user interests.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SSx2">
<h3 class="ltx_title ltx_title_subsection">Method of Item LLM Feature Extraction</h3>
<figure class="ltx_table" id="A1.T10">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T10.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T10.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A1.T10.1.2.1.1">Method</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T10.1.2.1.2">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T10.1.2.1.3">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T10.1.2.1.4">N@5</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T10.1.2.1.5">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T10.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T10.1.3.1.1">Mean Pooling</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T10.1.3.1.2">3.386</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T10.1.3.1.3">5.159</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T10.1.3.1.4">2.257</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="A1.T10.1.3.1.5">2.826</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A1.T10.1.1.1">
<span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="A1.T10.1.1.1.1">[ITEM]</span> Token</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T10.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T10.1.1.2.1">3.484</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T10.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T10.1.1.3.1">5.239</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T10.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T10.1.1.4.1">2.319</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="A1.T10.1.1.5"><span class="ltx_text ltx_font_bold" id="A1.T10.1.1.5.1">2.883</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Ablation studies of Item LLM feature extraction method on Pixel200K. Mean pooling refers to using the mean pooling of hidden states from the last layer of the Item LLM as the item features. SASRec is used as the user model.</figcaption>
</figure>
<div class="ltx_para" id="A1.SSx2.p1">
<p class="ltx_p" id="A1.SSx2.p1.2">To enable LLMs trained on next token prediction to have feature extraction capabilities, we add a special token <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="A1.SSx2.p1.2.1">[ITEM]</span> at the end of the text input. Another feasible feature extraction approach is to take the average of the hidden states from the final layer of the LLM to represent the features of the entire sentence. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.T10" title="Table 10 ‣ Method of Item LLM Feature Extraction ‣ Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">10</span></a> shows the comparison results of these two methods.
As can be seen, using the <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="A1.SSx2.p1.2.2">[ITEM]</span> token is better than mean pooling.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SSx3">
<h3 class="ltx_title ltx_title_subsection">Sequence Length of User LLM</h3>
<div class="ltx_para" id="A1.SSx3.p1">
<p class="ltx_p" id="A1.SSx3.p1.1">We explore the impact of input sequence length of User LLM on HLLM’s recommendation performance in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.T11" title="Table 11 ‣ Sequence Length of User LLM ‣ Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">11</span></a>. Similar to other sequential recommenders, HLLM can also benefit from expanding the length of the input sequence. Although the table shows only modest performance gains with increasing sequence length, we suspect this is likely because user sequence lengths are generally quite short in the academic dataset as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2.F5" title="Figure 5 ‣ Parameters of Item LLM and User LLM ‣ Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">5</span></a>.
As shown in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2" title="Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">B</span></a>, in the real-world industrial systems, where user behavior sequences are typically very long, extending the sequence length allows HLLM to achieve stable performance improvement.</p>
</div>
<figure class="ltx_table" id="A1.T11">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A1.T11.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T11.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A1.T11.1.1.1.1">Length</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.1.1.1.2">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.1.1.1.3">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.1.1.1.4">R@50</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.1.1.1.5">R@200</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T11.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="A1.T11.1.2.1.1">10</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.1.2.1.2">5.201</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.1.2.1.3">7.564</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.1.2.1.4">16.220</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.1.2.1.5">28.776</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="A1.T11.1.3.2.1">30</th>
<td class="ltx_td ltx_align_left" id="A1.T11.1.3.2.2">5.235</td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.3.2.3">7.605</td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.3.2.4">16.293</td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.3.2.5">28.837</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="A1.T11.1.4.3.1">50</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.1.4.3.2"><span class="ltx_text ltx_font_bold" id="A1.T11.1.4.3.2.1">5.238</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.1.4.3.3"><span class="ltx_text ltx_font_bold" id="A1.T11.1.4.3.3.1">7.631</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.1.4.3.4"><span class="ltx_text ltx_font_bold" id="A1.T11.1.4.3.4.1">16.416</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.1.4.3.5"><span class="ltx_text ltx_font_bold" id="A1.T11.1.4.3.5.1">28.959</span></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A1.T11.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T11.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A1.T11.2.1.1.1">Length</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.2.1.1.2">N@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.2.1.1.3">N@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.2.1.1.4">N@50</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T11.2.1.1.5">N@200</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T11.2.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="A1.T11.2.2.1.1">10</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.2.2.1.2">3.538</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.2.2.1.3">4.299</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.2.2.1.4">6.176</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.2.2.1.5">8.052</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="A1.T11.2.3.2.1">30</th>
<td class="ltx_td ltx_align_left" id="A1.T11.2.3.2.2">3.556</td>
<td class="ltx_td ltx_align_left" id="A1.T11.2.3.2.3">4.319</td>
<td class="ltx_td ltx_align_left" id="A1.T11.2.3.2.4">6.205</td>
<td class="ltx_td ltx_align_left" id="A1.T11.2.3.2.5">8.081</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="A1.T11.2.4.3.1">50</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.2.4.3.2"><span class="ltx_text ltx_font_bold" id="A1.T11.2.4.3.2.1">3.568</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.2.4.3.3"><span class="ltx_text ltx_font_bold" id="A1.T11.2.4.3.3.1">4.338</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.2.4.3.4"><span class="ltx_text ltx_font_bold" id="A1.T11.2.4.3.4.1">6.244</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.2.4.3.5"><span class="ltx_text ltx_font_bold" id="A1.T11.2.4.3.5.1">8.119</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Experiments on the sequence length of User LLM on Pixel1M.</figcaption>
</figure>
<figure class="ltx_table" id="A1.T12">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T12.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T12.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T12.1.1.1.1">Input Features</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T12.1.1.1.2">R@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T12.1.1.1.3">R@10</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T12.1.1.1.4">N@5</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T12.1.1.1.5">N@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T12.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.1.2.1.1">Item ID</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.1.2.1.2">4.105</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.1.2.1.3">6.082</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.1.2.1.4">2.773</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.1.2.1.5">3.409</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.3.2">
<td class="ltx_td ltx_align_left" id="A1.T12.1.3.2.1">LLM Emb</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.3.2.2">5.201</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.3.2.3">7.564</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.3.2.4">3.538</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.3.2.5">4.299</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.4.3">
<td class="ltx_td ltx_align_left" id="A1.T12.1.4.3.1">LLM Emb + Item ID</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.4.3.2">5.154</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.4.3.3">7.501</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.4.3.4">3.504</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.4.3.5">4.260</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T12.1.5.4.1">LLM Emb + Timestamp</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T12.1.5.4.2"><span class="ltx_text ltx_font_bold" id="A1.T12.1.5.4.2.1">5.779</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T12.1.5.4.3"><span class="ltx_text ltx_font_bold" id="A1.T12.1.5.4.3.1">8.319</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T12.1.5.4.4"><span class="ltx_text ltx_font_bold" id="A1.T12.1.5.4.4.1">3.953</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T12.1.5.4.5"><span class="ltx_text ltx_font_bold" id="A1.T12.1.5.4.5.1">4.770</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Ablation studies of input features of User LLM on Pixel1M. LLM Emb represents the item features extracted using the Item LLM based on textual descriptions.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SSx4">
<h3 class="ltx_title ltx_title_subsection">Compatibility with ID-based Features</h3>
<div class="ltx_para" id="A1.SSx4.p1">
<p class="ltx_p" id="A1.SSx4.p1.1">In the previous sections, we primarily modeled item and user features based on the textual descriptions of items. Most current recommendation systems, however, still rely on ID features, including not only Item IDs but also features like actions, timestamps, and item categories in ID form. Here, we present a compatibility solution for integrating HLLM with ID features, and demonstrate that complementary ID features, when combined with item descriptions, can indeed bring significant improvements to HLLM, further highlighting its application value in industrial environments.</p>
</div>
<div class="ltx_para" id="A1.SSx4.p2">
<p class="ltx_p" id="A1.SSx4.p2.1">Here, we choose the raw item IDs and timestamps as ID features for validation.
The item IDs are transformed into id embeddings through an embedding lookup table.
The behavior’s timestamp is first split into specific year, month, day, hour, minute, and second components, obtaining the timestamp embedding as Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#alg1" title="Algorithm 1 ‣ Parameters of Item LLM and User LLM ‣ Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>.
We perform sum pooling with the ID features and item LLM embeddings before inputting them into the User LLM.
The prediction target during training remains the item embedding extracted by the Item LLM, and the experimental results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A1.T12" title="Table 12 ‣ Sequence Length of User LLM ‣ Appendix A More Experiments on Academic Datasets ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">12</span></a>.
The introduction of item IDs actually results in a slight decrease in performance, likely because the item IDs do not provide incremental information beyond what is already captured by the textual descriptions, which comprehensively describe the item’s characteristics and are sufficiently extracted by the Item LLM.
However, the improvement resulting from the introduction of timestamps is very pronounced, as timestamps complement the textual descriptions. This also demonstrates that our method can be compatible with ID-based features.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Scaling Up of HLLM on Industrial Dataset</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">More extensive experiments are conducted on a large-scale industrial dataset to evaluate the scalability of HLLM.</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">Douyin has a vast number of users and recommendation candidates, with extensive records of user behavior. We construct a dataset comprising 30 million samples from the past 3 years’ logs. Each sample includes only the user’s historical click sequence, the target item, and a label indicating whether the item was clicked or not. We validate the effectiveness of HLLM in a discriminative recommendation system, using AUC as the evaluation metric, and verifying scalability from two aspects: the sequence length of User LLM, and the parameters of both Item LLM and User LLM.</p>
</div>
<figure class="ltx_table" id="A2.T13">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T13.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T13.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A2.T13.1.1.1.1">Sequence Length</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A2.T13.1.1.1.2">AUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T13.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T13.1.2.1.1">200</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T13.1.2.1.2">0.7429</td>
</tr>
<tr class="ltx_tr" id="A2.T13.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T13.1.3.2.1">500</th>
<td class="ltx_td ltx_align_left" id="A2.T13.1.3.2.2">0.7446</td>
</tr>
<tr class="ltx_tr" id="A2.T13.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A2.T13.1.4.3.1">1,000</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T13.1.4.3.2"><span class="ltx_text ltx_font_bold" id="A2.T13.1.4.3.2.1">0.7458</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Experiments on the sequence length of User LLM on the industrial dataset.</figcaption>
</figure>
<figure class="ltx_table" id="A2.T14">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T14.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T14.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A2.T14.1.1.1.1">Item LLM</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A2.T14.1.1.1.2">User LLM</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A2.T14.1.1.1.3">AUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T14.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T14.1.2.1.1">1B</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T14.1.2.1.2">1B</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T14.1.2.1.3">0.7458</td>
</tr>
<tr class="ltx_tr" id="A2.T14.1.3.2">
<td class="ltx_td ltx_align_left" id="A2.T14.1.3.2.1">1B</td>
<td class="ltx_td ltx_align_left" id="A2.T14.1.3.2.2">7B</td>
<td class="ltx_td ltx_align_left" id="A2.T14.1.3.2.3">0.7498</td>
</tr>
<tr class="ltx_tr" id="A2.T14.1.4.3">
<td class="ltx_td ltx_align_left" id="A2.T14.1.4.3.1">7B</td>
<td class="ltx_td ltx_align_left" id="A2.T14.1.4.3.2">1B</td>
<td class="ltx_td ltx_align_left" id="A2.T14.1.4.3.3">0.7517</td>
</tr>
<tr class="ltx_tr" id="A2.T14.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T14.1.5.4.1">7B</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T14.1.5.4.2">7B</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T14.1.5.4.3"><span class="ltx_text ltx_font_bold" id="A2.T14.1.5.4.3.1">0.7533</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Experiments with different sizes of Item LLM and User LLM on the industrial dataset.</figcaption>
</figure>
<section class="ltx_subsection" id="A2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Sequence Length of User LLM</h3>
<div class="ltx_para" id="A2.SSx1.p1">
<p class="ltx_p" id="A2.SSx1.p1.1">The length of user behavior sequences in the industrial dataset is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2.F5" title="Figure 5 ‣ Parameters of Item LLM and User LLM ‣ Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">5</span></a>.
And table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2.T13" title="Table 13 ‣ Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">13</span></a> shows the impact of user sequence length, with HLLM’s performance steadily increasing as the sequence length grows. This illustrates HLLM’s substantial potential in modeling users with longer sequences.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Parameters of Item LLM and User LLM</h3>
<div class="ltx_para" id="A2.SSx2.p1">
<p class="ltx_p" id="A2.SSx2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12740v1#A2.T14" title="Table 14 ‣ Appendix B Scaling Up of HLLM on Industrial Dataset ‣ HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling"><span class="ltx_text ltx_ref_tag">14</span></a> illustrates the impact of the parameters of HLLM in industrial scenario. For both Item LLM and User LLM, AUC consistently increases with the growth in the number of parameters.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Pseudo code of timestamp processing in a PyTorch-like style.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_listing ltx_figure_panel ltx_lst_language_python ltx_lst_numbers_left ltx_lstlisting ltx_listing" id="alg1.3" style="background-color:#FFFFFF;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,Y2xhc3MgVFNFbWJlZGRpbmcobm4uTW9kdWxlKToKICAgIGRlZiBfX2luaXRfXyhzZWxmLCB0aW1lX251bT02LCB0aW1lX2RpbT01MTIsIHVzZXJfZGltPTIwNDgpOgogICAgICAgIHN1cGVyKCkuX19pbml0X18oKQogICAgICAgICMgQ29udHJvbCB0aGUgcHJlY2lzaW9uIG9mIHRpbWUsIHN1Y2ggYXMgNCB0byB0aGUgaG91ciwgYW5kIDYgdG8gdGhlIHNlY29uZC4KICAgICAgICBzZWxmLnRpbWVfbnVtID0gdGltZV9udW0KICAgICAgICBzZWxmLnRpbWVfZW1iZWRkaW5ncyA9IG5uLk1vZHVsZUxpc3Qobm4uRW1iZWRkaW5nKHgsIHRpbWVfZGltKSBmb3IgeCBpbiBbMjEwMCwgMTMsIDMyLCAyNCwgNjAsIDYwXSkKICAgICAgICAjIFByb2plY3Rpb24gZnJvbSB0aW1lX2RpbSB0byB1c2VyX2RpbQogICAgICAgIHNlbGYubWVyZ2VfdGltZSA9IE1MUCh0aW1lX2RpbSAqIHRpbWVfbnVtLCB1c2VyX2RpbSkKCiAgICBkZWYgc3BsaXRfdGltZShzZWxmLCB0aW1lc3RhbXBzOiBMaXN0KSAtPiBMaXN0OgogICAgICAgICMgU3BsaXQgdGltZXN0YW1wcyBpbnRvIHNwZWNpZmljIGNvbXBvbmVudHMuCiAgICAgICAgIyAoc2VxKSAtPiAoc2VxLCA2KQogICAgICAgIHNwbGl0X3RpbWUgPSBbXQogICAgICAgIGZvciB0aW1lIGluIHRpbWVzdGFtcHM6CiAgICAgICAgICAgIGR0ID0gZGF0ZXRpbWUuZGF0ZXRpbWUuZnJvbXRpbWVzdGFtcCh0aW1lKQogICAgICAgICAgICBzcGxpdF90aW1lLmFwcGVuZChbZHQueWVhciwgZHQubW9udGgsIGR0LmRheSwgZHQuaG91ciwgZHQubWludXRlLCBkdC5zZWNvbmRdKQogICAgICAgIHJldHVybiBzcGxpdF90aW1lCgogICAgZGVmIGZvcndhcmQoc2VsZiwgdGltZXN0YW1wczogTGlzdCkgLT4gdG9yY2gudGVuc29yOgogICAgICAgICMgVGltZXM6IHRpbWVzdGFtcCBvZiBlYWNoIGl0ZW0gaW4gTGlzdCBmb3JtYXQgKGJzLCBzZXEpCiAgICAgICAgIyAoYnMsIHNlcSkgLT4gKGJzLCBzZXEsIDYpCiAgICAgICAgdGltZV9zZXEgPSB0b3JjaC50ZW5zb3IoW3NlbGYuc3BsaXRfdGltZSh4KSBmb3IgeCBpbiB0aW1lc3RhbXBzXSkKICAgICAgICAjIChicywgc2VxLCA2KSAtPiBbKGJzLCBzZXEsIHRpbWVfZGltKV0gKiB0aW1lX251bQogICAgICAgIHRpbWVfZW1iID0gW3NlbGYudGltZV9lbWJlZGRpbmdzW2ldKHRpbWVfc2VxWy4uLixpXSkgZm9yIGkgaW4gcmFuZ2Uoc2VsZi50aW1lX251bSldCiAgICAgICAgIyBbKGJzLCBzZXEsIHRpbWVfZGltKV0gKiB0aW1lX251bSAtPiAoYnMsIHNlcSwgdGltZV9kaW0gKiB0aW1lX251bSkKICAgICAgICB0aW1lX2VtYiA9IHRvcmNoLmNhdCh0aW1lX2VtYiwgZGltPS0xKQogICAgICAgICMgKGJzLCBzZXEsIHRpbWVfZGltICogdGltZV9udW0pIC0+IChicywgc2VxLCB1c2VyX2RpbSkKICAgICAgICB0aW1lX2VtYiA9IHNlbGYubWVyZ2VfdGltZSh0aW1lX2VtYikKICAgICAgICByZXR1cm4gdGltZV9lbWI=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_tag ltx_tag_listingline">1</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx1.1">class</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.3">TSEmbedding</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.4">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.5">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.6">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.7">Module</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.8">):</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_tag ltx_tag_listingline">2</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx2.2">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.4">__init__</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.5">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.6">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.7">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.9">time_num</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.10">=6,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.12">time_dim</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.13">=512,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.15">user_dim</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.16">=2048):</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_tag ltx_tag_listingline">3</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.1"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx3.2">super</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.3">().</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.4">__init__</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.5">()</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_tag ltx_tag_listingline">4</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx4.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.1"> </span>Control<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.2"> </span>the<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.3"> </span>precision<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.4"> </span>of<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.5"> </span>time,<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.6"> </span>such<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.7"> </span>as<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.8"> </span>4<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.9"> </span>to<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.10"> </span>the<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.11"> </span>hour,<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.12"> </span>and<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.13"> </span>6<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.14"> </span>to<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.15"> </span>the<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.16"> </span>second.</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_tag ltx_tag_listingline">5</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.2">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.3">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.4">time_num</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.6">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.8">time_num</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_tag ltx_tag_listingline">6</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.2">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.3">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.4">time_embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.6">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.8">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.9">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.10">ModuleList</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.11">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.12">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.13">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.14">Embedding</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.15">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.16">x</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.17">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.19">time_dim</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.20">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.21"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx6.22">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.24">x</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.25"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx6.26">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.27"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.28">[2100,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.29"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.30">13,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.31"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.32">32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.33"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.34">24,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.35"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.36">60,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.37"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.38">60])</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_tag ltx_tag_listingline">7</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx7.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx7.2.1"> </span>Projection<span class="ltx_text ltx_lst_space" id="lstnumberx7.2.2"> </span>from<span class="ltx_text ltx_lst_space" id="lstnumberx7.2.3"> </span>time_dim<span class="ltx_text ltx_lst_space" id="lstnumberx7.2.4"> </span>to<span class="ltx_text ltx_lst_space" id="lstnumberx7.2.5"> </span>user_dim</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_tag ltx_tag_listingline">8</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.2">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.3">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.4">merge_time</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.6">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.8">MLP</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.9">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.10">time_dim</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.11"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.12">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.14">time_num</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.15">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.17">user_dim</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.18">)</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_tag ltx_tag_listingline">9</span>
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_tag ltx_tag_listingline">10</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx10.2">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.4">split_time</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.5">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.6">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.7">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.9">timestamps</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.10">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.12">List</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.13">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.14"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.15">-&gt;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.17">List</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.18">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_tag ltx_tag_listingline">11</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx11.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx11.2.1"> </span>Split<span class="ltx_text ltx_lst_space" id="lstnumberx11.2.2"> </span>timestamps<span class="ltx_text ltx_lst_space" id="lstnumberx11.2.3"> </span>into<span class="ltx_text ltx_lst_space" id="lstnumberx11.2.4"> </span>specific<span class="ltx_text ltx_lst_space" id="lstnumberx11.2.5"> </span>components.</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_tag ltx_tag_listingline">12</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx12.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx12.2.1"> </span>(seq)<span class="ltx_text ltx_lst_space" id="lstnumberx12.2.2"> </span>-&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx12.2.3"> </span>(seq,<span class="ltx_text ltx_lst_space" id="lstnumberx12.2.4"> </span>6)</span>
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_tag ltx_tag_listingline">13</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.2">split_time</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.6">[]</span>
</div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_tag ltx_tag_listingline">14</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx14.2">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.4">time</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.5"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx14.6">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.8">timestamps</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.9">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_tag ltx_tag_listingline">15</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.2">dt</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.6">datetime</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.7">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.8">datetime</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.9">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.10">fromtimestamp</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.11">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.12">time</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.13">)</span>
</div>
<div class="ltx_listingline" id="lstnumberx16">
<span class="ltx_tag ltx_tag_listingline">16</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.2">split_time</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.3">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.4">append</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.5">([</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.6">dt</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.7">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.8">year</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.9">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.11">dt</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.12">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.13">month</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.14">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.16">dt</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.17">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.18">day</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.19">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.21">dt</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.22">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.23">hour</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.24">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.26">dt</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.27">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.28">minute</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.29">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.30"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.31">dt</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.32">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.33">second</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.34">])</span>
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_tag ltx_tag_listingline">17</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx17.2">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.4">split_time</span>
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_tag ltx_tag_listingline">18</span>
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_tag ltx_tag_listingline">19</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx19.2">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.4">forward</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.5">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.6">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.7">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.9">timestamps</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.10">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.12">List</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.13">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.14"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.15">-&gt;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.17">torch</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.18">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.19">tensor</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.20">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_tag ltx_tag_listingline">20</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx20.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.1"> </span>Times:<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.2"> </span>timestamp<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.3"> </span>of<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.4"> </span>each<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.5"> </span>item<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.6"> </span>in<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.7"> </span>List<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.8"> </span>format<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.9"> </span>(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx20.2.10"> </span>seq)</span>
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_tag ltx_tag_listingline">21</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx21.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx21.2.1"> </span>(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx21.2.2"> </span>seq)<span class="ltx_text ltx_lst_space" id="lstnumberx21.2.3"> </span>-&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx21.2.4"> </span>(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx21.2.5"> </span>seq,<span class="ltx_text ltx_lst_space" id="lstnumberx21.2.6"> </span>6)</span>
</div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_tag ltx_tag_listingline">22</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.2">time_seq</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.6">torch</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.7">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.8">tensor</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.9">([</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.10">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.11">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.12">split_time</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.13">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.14">x</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.15">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.16"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx22.17">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.19">x</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.20"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx22.21">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.23">timestamps</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.24">])</span>
</div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_tag ltx_tag_listingline">23</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx23.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.1"> </span>(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.2"> </span>seq,<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.3"> </span>6)<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.4"> </span>-&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.5"> </span>[(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.6"> </span>seq,<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.7"> </span>time_dim)]<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.8"> </span>*<span class="ltx_text ltx_lst_space" id="lstnumberx23.2.9"> </span>time_num</span>
</div>
<div class="ltx_listingline" id="lstnumberx24">
<span class="ltx_tag ltx_tag_listingline">24</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.2">time_emb</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.6">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.7">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.8">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.9">time_embeddings</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.10">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.11">i</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.12">](</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.13">time_seq</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.14">[...,</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.15">i</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.16">])</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.17"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx24.18">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.20">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.21"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx24.22">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.23"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx24.24">range</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.25">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.26">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.27">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.28">time_num</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.29">)]</span>
</div>
<div class="ltx_listingline" id="lstnumberx25">
<span class="ltx_tag ltx_tag_listingline">25</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx25.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.1"> </span>[(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.2"> </span>seq,<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.3"> </span>time_dim)]<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.4"> </span>*<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.5"> </span>time_num<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.6"> </span>-&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.7"> </span>(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.8"> </span>seq,<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.9"> </span>time_dim<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.10"> </span>*<span class="ltx_text ltx_lst_space" id="lstnumberx25.2.11"> </span>time_num)</span>
</div>
<div class="ltx_listingline" id="lstnumberx26">
<span class="ltx_tag ltx_tag_listingline">26</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.2">time_emb</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.6">torch</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.7">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.8">cat</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.9">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.10">time_emb</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.11">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.13">dim</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.14">=-1)</span>
</div>
<div class="ltx_listingline" id="lstnumberx27">
<span class="ltx_tag ltx_tag_listingline">27</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx27.2" style="color:#408080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.1"> </span>(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.2"> </span>seq,<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.3"> </span>time_dim<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.4"> </span>*<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.5"> </span>time_num)<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.6"> </span>-&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.7"> </span>(bs,<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.8"> </span>seq,<span class="ltx_text ltx_lst_space" id="lstnumberx27.2.9"> </span>user_dim)</span>
</div>
<div class="ltx_listingline" id="lstnumberx28">
<span class="ltx_tag ltx_tag_listingline">28</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.2">time_emb</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.6">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.7">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.8">merge_time</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.9">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.10">time_emb</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.11">)</span>
</div>
<div class="ltx_listingline" id="lstnumberx29">
<span class="ltx_tag ltx_tag_listingline">29</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx29.2">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.4">time_emb</span>
</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="alg1.4"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
</div>
</figure>
<figure class="ltx_figure" id="A2.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A2.F5.1" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="499" id="A2.F5.1.g1" src="x6.png" width="969"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A2.F5.2" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="511" id="A2.F5.2.g1" src="x7.png" width="968"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A2.F5.3" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="499" id="A2.F5.3.g1" src="x8.png" width="969"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Distribution of textual descriptions (flattening all attributes) and sequence lengths in Pixel200K, Pixel1M, Pixel8M, Amazon Book Reviews and industrial scenario. Since Pixel200K is randomly sampled from Pixel1M, their distributions are consistent. We truncate the sequence length to a maximum of 2,000 for industrial data, hence p90 is exactly 2,000.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 19 13:02:47 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
