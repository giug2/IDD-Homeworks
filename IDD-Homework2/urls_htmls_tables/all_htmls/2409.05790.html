<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks</title>
<!--Generated on Mon Sep  9 16:45:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.05790v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S1" title="In Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S2" title="In Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>The CHF Experimental Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3" title="In Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodologies</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3.SS1" title="In 3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>DNNs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3.SS2" title="In 3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>VAEs and CVAEs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4" title="In Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>The Generative and Predictive ML Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4.SS1" title="In 4 The Generative and Predictive ML Models ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>The CVAE Generative Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4.SS2" title="In 4 The Generative and Predictive ML Models ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>The DNN Predictive Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4.SS3" title="In 4 The Generative and Predictive ML Models ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>UQ of the ML Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4.SS4" title="In 4 The Generative and Predictive ML Models ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Domain Generalization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5" title="In Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.SS1" title="In 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Results of CHF Generation and Prediction using CVAE and DNN</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.SS2" title="In 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Results of UQ</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.SS3" title="In 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Results of Domain Generalization Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S6" title="In Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S7" title="In Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document" style="font-size:120%;">Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Farah Alsafadi
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aidan Furlong
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xu Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:xwu27@ncsu.edu">xwu27@ncsu.edu</a>
</span>
<span class="ltx_contact ltx_role_address">Department of Nuclear Engineering, North Carolina State University 
<br class="ltx_break"/>Burlington Engineering Laboratories, 2500 Stinson Drive, Raleigh, NC 27695 
<br class="ltx_break"/>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Deep generative models (DGMs) have proven to be powerful in generating realistic data samples. Their capability to learn the underlying distribution of a dataset enable them to generate synthetic data samples that closely resemble the original training dataset, thus addressing the challenge of data scarcity. In this work, we investigated the capabilities of DGMs by developing a conditional variational autoencoder (CVAE) model to augment the critical heat flux (CHF) measurement data that was used to generate the 2006 Groeneveld lookup table. To determine how this approach compared to traditional methods, a fine-tuned deep neural network (DNN) regression model was created and evaluated with the same dataset. Both the CVAE and DNN models achieved small mean absolute relative errors, with the CVAE model maintaining more favorable results. To quantify the uncertainty in the model’s predictions, uncertainty quantification (UQ) was performed with repeated sampling of the CVAE model and ensembling of the DNN model. Following UQ, the DNN ensemble notably improved performance when compared to the baseline DNN model, while the CVAE model achieved similar results to its non-UQ results. The CVAE model was shown to have significantly less variability and a higher confidence after assessment of the prediction-wise relative standard deviations. Evaluating domain generalization, both models achieved small mean error values when predicting both inside and outside the training domain, with predictions outside the training domain showing slightly larger errors. Overall, the CVAE model was comparable to the DNN regression model in predicting CHF values but with better uncertainty behavior.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Critical heat flux , Conditional variational autoencoders , Deep neural networks , Uncertainty quantification

</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journal" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>Elsevier</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Deep generative learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib1" title="">1</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib2" title="">2</a>]</cite> is a branch of deep learning that utilizes unsupervised learning to learn complex data distributions. It is capable of capturing the underlying structures and patterns within the training data. The learned data distributions can be leveraged to generate synthetic data samples that closely resemble the original training dataset for data augmentation. Since most data-driven machine learning (ML) models rely on “big data” to achieve a favorable accuracy, expanding smaller datasets enables better performance of the data-driven ML models trained with the expanded datasets. This is particularly beneficial in addressing the “data scarcity” challenge in fields like nuclear engineering, where limited data availability restricts the application of ML models in many problems.
Deep generative models (DGMs) offer a promising solution to the data scarcity issue. By utilizing well-trained DGM, one can significantly expand an existing dataset. Among the most widely used DGMs are generative adversarial networks (GANs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib3" title="">3</a>]</cite>, variational autoencoders (VAEs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib4" title="">4</a>]</cite>, normalizing flows <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib5" title="">5</a>]</cite>, and diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib6" title="">6</a>]</cite>. These models adopt different approaches in learning the training data distribution and in generating new synthetic data.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">VAEs, introduced by Kingma and Welling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib4" title="">4</a>]</cite>, adopt a unique approach to learn the underlying data distribution using variational inference <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib7" title="">7</a>]</cite>. A VAE model, just like a traditional autoencoder model, consists of three main components: the <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">encoder</span>, the <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">latent space</span>, and the <span class="ltx_text ltx_font_italic" id="S1.p2.1.3">decoder</span>. VAEs differ from traditional autoencoders in the encoding process. Instead of encoding data as deterministic values in the latent space, VAEs encode data as distributions, making them well-suited for data augmentation because one can simply sample from the latent space distributions and obtain new samples through the decoding process.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">VAEs have demonstrated successes in data augmentation across various domains, including acoustic modeling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib8" title="">8</a>]</cite> and clinical studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib9" title="">9</a>]</cite>. They were also used to address the data scarcity challenge in healthcare domain by augmenting the Gram-stained smear images dataset, which improved the classification accuracy of the bacteria detection framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib10" title="">10</a>]</cite>. In the realm of the industrial internet of things, VAEs were employed to address data imbalance, significantly improving the Macro-F1-scores of deep-learning-based intrusion detection systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib11" title="">11</a>]</cite>. Additionally, VAEs prove effective in enhancing product quality prediction through the generation of artificial quality values for training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib12" title="">12</a>]</cite>. They are also frequently applied in computer vision tasks, such as generating static images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib13" title="">13</a>]</cite> and enhancing image super resolution <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib14" title="">14</a>]</cite>. Additionally, VAEs were used to generate synthetic vortex-induced vibrations data that was employed to train a transformer model for forecasting vibrations in time-space using sparse observations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib15" title="">15</a>]</cite>. They were also utilized to generate temperature, velocity, and species mass fraction predictions within a computational fluid dynamics (CFD) data-driven surrogate model, allowing for predicting CFD data fields with reasonable accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib16" title="">16</a>]</cite>. In nuclear engineering, a convolutional variational autoencoding gradient-penalty Wasserstein generative adversarial network with random forest (CVGR) was proposed to mitigate imbalance data problem in fault diagnosis of nuclear power plants <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib17" title="">17</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">However, a basic VAE model can only generate synthetic samples <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">randomly</span> instead of producing specific data instances, for example, data samples at conditions and domains desired by the user. To address this limitation, the conditional VAE (CVAE) model was proposed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib18" title="">18</a>]</cite>. CVAEs operate similarly to VAEs but utilize additional data for conditioning. During the training phase, instead of solely relying on the training data, CVAEs incorporate labels alongside the data to train both the encoder and the decoder. This incorporation of labels enables the decoder to learn how to generate data that corresponds to specific labels, allowing for targeted data generation. CVAEs have been applied in various domains, such as enhancing spectral data augmentation in practical spectroscopy measurements with limited labeled samples <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib19" title="">19</a>]</cite> and improving few-shot classification tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib20" title="">20</a>]</cite>. They were also applied in energy systems fault detection and diagnosis, where CVAE was combined with GAN to address the issue of imbalanced samples by generating synthetic fault samples to balance the training dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib21" title="">21</a>]</cite>.
However, their application in nuclear engineering datasets has been rare. In a previous study, we investigated the effectiveness of CVAEs among other DGMs for data augmentation of void fraction simulations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib22" title="">22</a>]</cite>, demonstrating that CVAEs have a good potential in this field.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this work, we will present a detailed investigation of using CVAE models to augment an important set of experimental data in nuclear engineering thermal-hydraulics (TH), the critical heat flux (CHF).
Critical boiling transition is a transition from a boiling flow regime that has a higher heat transfer rate to a flow regime that has a significantly lower heat transfer rate, which may result in fuel damage. Therefore, CHF has been one of the most concerned nuclear reactor operational characteristics. The design, evaluation, licensing and reliable operation of innovative reactor designs, such as advanced light water-cooled reactors, require a very good understanding of the critical boiling transition behavior. However, There is a critical lack of experimental data across a wide range of flow boiling conditions for CHF due to the time-consuming and costly nature of such experiments.
Recently, a database used to develop the widely known 2006 Groeneveld CHF lookup table <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib23" title="">23</a>]</cite> was published by the U. S. Nuclear Regulatory Commission (NRC) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib24" title="">24</a>]</cite>. This database (hereafter referred as the “NRC CHF dataset”), consisting of nearly 25,000 data points, is the largest known CHF dataset publicly available worldwide with measurements in vertical uniformly-heated water-cooled cylindrical tubes.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In this study, we developed a CVAE-based DGM for data augmentation of the NRC CHF dataset. One may wonder that <math alttext="\sim" class="ltx_Math" display="inline" id="S1.p6.1.m1.1"><semantics id="S1.p6.1.m1.1a"><mo id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><csymbol cd="latexml" id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S1.p6.1.m1.1d">∼</annotation></semantics></math> 25,000 CHF data points seem to be a good amount of training data for ML tasks, why is DGM necessary in this case? We argue that after considering the wide ranges of reactor operating conditions, geometries and reactor types, the CHF data points are rather scarce and unbalanced, making data augmentation necessary, especially for heavily parameterized predictive ML models such as neural networks.
In order to assess the performance of the CVAE generative model, we directly compared it with a regular deep neural network (DNN) model. DNN models have proven to be powerful for regression tasks by directly learning the mapping between inputs and outputs in the training data. Both the CVAE and fine-tuned DNN models were trained and tested using the same datasets to generate CHF data under the same specified conditions, with the results subsequently compared. Uncertainty quantification (UQ) analysis was then applied via sampling of the CVAE model and ensembling of the DNN model. Domain generalization analysis was also performed for both models to assess their ability in extrapolating to new, unseen domains.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Several metrics were applied to assess the performance of the models. Comparison with true holdout values showed close alignment, indicating a low level of error in the generated and predicted CHF values. UQ results showed that the CVAE model has very small uncertainties in the generation of CHF values, whereas higher values were observed for the DNN model. Both the CVAE and DNN models showed similar behavior in their ability to generalize beyond their training domain, achieving small mean absolute relative errors. Both models have proven to be reliable in generating and predicting CHF values outside the training domain. The mean relative absolute errors were slightly smaller when predicting within the training domain, compared to predicting outside the training domain. The findings from this work show that the CVAE and DNN models were successful at generating and predicting CHF values with a high degree of accuracy, with the CVAE demonstrating a significantly more favorable uncertainty behavior.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">The remainder of this paper is structured as follows: in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S2" title="2 The CHF Experimental Dataset ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>, we present the training data details. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3" title="3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">3</span></a> introduces the methodologies for the CVAE generative model and DNN regression model. The models’ specifications along with UQ and domain generalization methods are presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4" title="4 The Generative and Predictive ML Models ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">4</span></a>. The results of this work are presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5" title="5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">5</span></a>, including uncertainty estimates and model domain generalization. Further discussions on this work are provided in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S6" title="6 Discussions ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">6</span></a>. Finally, our findings and conclusions are summarized in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S7" title="7 Conclusions ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>The CHF Experimental Dataset</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.7">CHF, also known as departure from nucleate boiling, is a critical phenomenon in heat transfer. It occurs when a heated surface reaches a point where it can no longer efficiently transfer heat to the surrounding fluid. In nuclear reactors, exceeding the CHF limit could potentially lead to fuel rod failure, which is a significant safety concern especially for pressurized water reactors. Therefore, it is essential to limit the heat flux of the fuel rods to a value below the CHF threshold. The collection of CHF measurement data can be challenging due to the nature of the experiments. Recently, the US NRC has published the largest known CHF dataset publicly available <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib24" title="">24</a>]</cite>. It consists of nearly 25,000 CHF measurements in vertical uniformly-heated water-cooled cylindrical tubes, gathered over a span of 60 years from 59 different sources. In these experiments, CHF values were measured at various TH initial/boundary conditions: pressure (<math alttext="P" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">italic_P</annotation></semantics></math>), mass flux (<math alttext="G" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">G</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">italic_G</annotation></semantics></math>), inlet temperature (<math alttext="T_{\text{in}}" class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><msub id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">T</mi><mtext id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">𝑇</ci><ci id="S2.p1.3.m3.1.1.3a.cmml" xref="S2.p1.3.m3.1.1.3"><mtext id="S2.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S2.p1.3.m3.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">T_{\text{in}}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">italic_T start_POSTSUBSCRIPT in end_POSTSUBSCRIPT</annotation></semantics></math>), as well as geometrical parameters like test section diameter (<math alttext="D" class="ltx_Math" display="inline" id="S2.p1.4.m4.1"><semantics id="S2.p1.4.m4.1a"><mi id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><ci id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m4.1d">italic_D</annotation></semantics></math>), and heated length (<math alttext="L" class="ltx_Math" display="inline" id="S2.p1.5.m5.1"><semantics id="S2.p1.5.m5.1a"><mi id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><ci id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.p1.5.m5.1d">italic_L</annotation></semantics></math>). Additionally, the dataset contains calculated parameters derived from measurements and water properties, including outlet equilibrium quality (<math alttext="X" class="ltx_Math" display="inline" id="S2.p1.6.m6.1"><semantics id="S2.p1.6.m6.1a"><mi id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><ci id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">X</annotation><annotation encoding="application/x-llamapun" id="S2.p1.6.m6.1d">italic_X</annotation></semantics></math>), and inlet enthalpy (<math alttext="\Delta h_{\text{in}}" class="ltx_Math" display="inline" id="S2.p1.7.m7.1"><semantics id="S2.p1.7.m7.1a"><mrow id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml"><mi id="S2.p1.7.m7.1.1.2" mathvariant="normal" xref="S2.p1.7.m7.1.1.2.cmml">Δ</mi><mo id="S2.p1.7.m7.1.1.1" xref="S2.p1.7.m7.1.1.1.cmml">⁢</mo><msub id="S2.p1.7.m7.1.1.3" xref="S2.p1.7.m7.1.1.3.cmml"><mi id="S2.p1.7.m7.1.1.3.2" xref="S2.p1.7.m7.1.1.3.2.cmml">h</mi><mtext id="S2.p1.7.m7.1.1.3.3" xref="S2.p1.7.m7.1.1.3.3a.cmml">in</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><apply id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1"><times id="S2.p1.7.m7.1.1.1.cmml" xref="S2.p1.7.m7.1.1.1"></times><ci id="S2.p1.7.m7.1.1.2.cmml" xref="S2.p1.7.m7.1.1.2">Δ</ci><apply id="S2.p1.7.m7.1.1.3.cmml" xref="S2.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.3.1.cmml" xref="S2.p1.7.m7.1.1.3">subscript</csymbol><ci id="S2.p1.7.m7.1.1.3.2.cmml" xref="S2.p1.7.m7.1.1.3.2">ℎ</ci><ci id="S2.p1.7.m7.1.1.3.3a.cmml" xref="S2.p1.7.m7.1.1.3.3"><mtext id="S2.p1.7.m7.1.1.3.3.cmml" mathsize="70%" xref="S2.p1.7.m7.1.1.3.3">in</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">\Delta h_{\text{in}}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.7.m7.1d">roman_Δ italic_h start_POSTSUBSCRIPT in end_POSTSUBSCRIPT</annotation></semantics></math>). The distributions of the values of these parameters, along with their pair-wise correlations, are illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S2.F1" title="Figure 1 ‣ 2 The CHF Experimental Dataset ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="562" id="S2.F1.g1" src="extracted/5843326/figures/CHF_data_8_parameters.png" width="568"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">The distributions and correlations of the TH conditions and CHF values in the NRC CHF dataset.</span></figcaption>
</figure>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.3">Several ML approaches have been attempted in the prediction of CHF, including the use of DNNs and GANs. These studies have used a variety of datasets and input combinations including those not included in the public CHF database such as wall thickness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib25" title="">25</a>]</cite>, Reynolds’ number <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib26" title="">26</a>]</cite>, and fluid densities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib27" title="">27</a>]</cite>. Different ML methods have been proposed among these pre-existing works, ranging from purely DNN models to those incorporating physics-based knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib28" title="">28</a>]</cite>. The results of these approaches range widely, with reported root mean square error values ranging from <math alttext="0.16\%" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mrow id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mn id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml">0.16</mn><mo id="S2.p2.1.m1.1.1.1" xref="S2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><csymbol cd="latexml" id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1.1">percent</csymbol><cn id="S2.p2.1.m1.1.1.2.cmml" type="float" xref="S2.p2.1.m1.1.1.2">0.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">0.16\%</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">0.16 %</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib29" title="">29</a>]</cite> to <math alttext="26.58\%" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><mrow id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml"><mn id="S2.p2.2.m2.1.1.2" xref="S2.p2.2.m2.1.1.2.cmml">26.58</mn><mo id="S2.p2.2.m2.1.1.1" xref="S2.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><apply id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1"><csymbol cd="latexml" id="S2.p2.2.m2.1.1.1.cmml" xref="S2.p2.2.m2.1.1.1">percent</csymbol><cn id="S2.p2.2.m2.1.1.2.cmml" type="float" xref="S2.p2.2.m2.1.1.2">26.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">26.58\%</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.1d">26.58 %</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib27" title="">27</a>]</cite> in different parameter configurations and methods. The authors are not aware of any presently-released studies attempting to use CVAEs. Another outstanding question is how the use of a far larger dataset such as the nearly <math alttext="25{,}000" class="ltx_Math" display="inline" id="S2.p2.3.m3.2"><semantics id="S2.p2.3.m3.2a"><mrow id="S2.p2.3.m3.2.3.2" xref="S2.p2.3.m3.2.3.1.cmml"><mn id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">25</mn><mo id="S2.p2.3.m3.2.3.2.1" xref="S2.p2.3.m3.2.3.1.cmml">,</mo><mn id="S2.p2.3.m3.2.2" xref="S2.p2.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.2b"><list id="S2.p2.3.m3.2.3.1.cmml" xref="S2.p2.3.m3.2.3.2"><cn id="S2.p2.3.m3.1.1.cmml" type="integer" xref="S2.p2.3.m3.1.1">25</cn><cn id="S2.p2.3.m3.2.2.cmml" type="integer" xref="S2.p2.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.2c">25{,}000</annotation><annotation encoding="application/x-llamapun" id="S2.p2.3.m3.2d">25 , 000</annotation></semantics></math>-entry public CHF compilation impacts the performance of DNN methods, and as such how it compares to the proposed CVAE generative model.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodologies</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>DNNs</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The use of DNNs has become widespread in multiple fields of nuclear engineering as a fast-and-accurate approach to create surrogate models, including in the prediction of CHF as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S2" title="2 The CHF Experimental Dataset ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>. DNNs are based on the transformation of a set of input values to produce a set of outputs (or single output) using a network of multiplying weights and additive biases. These are located on neurons, with an activation function applied to each of their outputs to introduce non-linearity. An objective function, typically the mean-squared error (<span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">MSE</span>), then evaluates how different the predicted outputs are from the true values. This value is then used to adjust the weights via backpropagation, which will minimize the objective function over a series of iterations through a section of the original dataset known as the training set. Once the surrogate model is fully trained, it is evaluated with a testing dataset that the model has never seen during training, providing a true estimate of the model’s ability to generalize to new data.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.15">In a regular feed-forward architecture, the mathematical expression of a DNN can be briefly defined as below:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Input layer:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\mathcal{Y}^{0}(\mathbf{x})=\mathbf{x}\in\mathbb{R}^{d_{\text{in}}}" class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.2" xref="S3.E1.m1.1.2.cmml"><mrow id="S3.E1.m1.1.2.2" xref="S3.E1.m1.1.2.2.cmml"><msup id="S3.E1.m1.1.2.2.2" xref="S3.E1.m1.1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.2.2.2.2" xref="S3.E1.m1.1.2.2.2.2.cmml">𝒴</mi><mn id="S3.E1.m1.1.2.2.2.3" xref="S3.E1.m1.1.2.2.2.3.cmml">0</mn></msup><mo id="S3.E1.m1.1.2.2.1" xref="S3.E1.m1.1.2.2.1.cmml">⁢</mo><mrow id="S3.E1.m1.1.2.2.3.2" xref="S3.E1.m1.1.2.2.cmml"><mo id="S3.E1.m1.1.2.2.3.2.1" stretchy="false" xref="S3.E1.m1.1.2.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">𝐱</mi><mo id="S3.E1.m1.1.2.2.3.2.2" stretchy="false" xref="S3.E1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.1.2.3" xref="S3.E1.m1.1.2.3.cmml">=</mo><mi id="S3.E1.m1.1.2.4" xref="S3.E1.m1.1.2.4.cmml">𝐱</mi><mo id="S3.E1.m1.1.2.5" xref="S3.E1.m1.1.2.5.cmml">∈</mo><msup id="S3.E1.m1.1.2.6" xref="S3.E1.m1.1.2.6.cmml"><mi id="S3.E1.m1.1.2.6.2" xref="S3.E1.m1.1.2.6.2.cmml">ℝ</mi><msub id="S3.E1.m1.1.2.6.3" xref="S3.E1.m1.1.2.6.3.cmml"><mi id="S3.E1.m1.1.2.6.3.2" xref="S3.E1.m1.1.2.6.3.2.cmml">d</mi><mtext id="S3.E1.m1.1.2.6.3.3" xref="S3.E1.m1.1.2.6.3.3a.cmml">in</mtext></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.2.cmml" xref="S3.E1.m1.1.2"><and id="S3.E1.m1.1.2a.cmml" xref="S3.E1.m1.1.2"></and><apply id="S3.E1.m1.1.2b.cmml" xref="S3.E1.m1.1.2"><eq id="S3.E1.m1.1.2.3.cmml" xref="S3.E1.m1.1.2.3"></eq><apply id="S3.E1.m1.1.2.2.cmml" xref="S3.E1.m1.1.2.2"><times id="S3.E1.m1.1.2.2.1.cmml" xref="S3.E1.m1.1.2.2.1"></times><apply id="S3.E1.m1.1.2.2.2.cmml" xref="S3.E1.m1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.2.2.2.1.cmml" xref="S3.E1.m1.1.2.2.2">superscript</csymbol><ci id="S3.E1.m1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.2.2.2.2">𝒴</ci><cn id="S3.E1.m1.1.2.2.2.3.cmml" type="integer" xref="S3.E1.m1.1.2.2.2.3">0</cn></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝐱</ci></apply><ci id="S3.E1.m1.1.2.4.cmml" xref="S3.E1.m1.1.2.4">𝐱</ci></apply><apply id="S3.E1.m1.1.2c.cmml" xref="S3.E1.m1.1.2"><in id="S3.E1.m1.1.2.5.cmml" xref="S3.E1.m1.1.2.5"></in><share href="https://arxiv.org/html/2409.05790v1#S3.E1.m1.1.2.4.cmml" id="S3.E1.m1.1.2d.cmml" xref="S3.E1.m1.1.2"></share><apply id="S3.E1.m1.1.2.6.cmml" xref="S3.E1.m1.1.2.6"><csymbol cd="ambiguous" id="S3.E1.m1.1.2.6.1.cmml" xref="S3.E1.m1.1.2.6">superscript</csymbol><ci id="S3.E1.m1.1.2.6.2.cmml" xref="S3.E1.m1.1.2.6.2">ℝ</ci><apply id="S3.E1.m1.1.2.6.3.cmml" xref="S3.E1.m1.1.2.6.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.2.6.3.1.cmml" xref="S3.E1.m1.1.2.6.3">subscript</csymbol><ci id="S3.E1.m1.1.2.6.3.2.cmml" xref="S3.E1.m1.1.2.6.3.2">𝑑</ci><ci id="S3.E1.m1.1.2.6.3.3a.cmml" xref="S3.E1.m1.1.2.6.3.3"><mtext id="S3.E1.m1.1.2.6.3.3.cmml" mathsize="50%" xref="S3.E1.m1.1.2.6.3.3">in</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathcal{Y}^{0}(\mathbf{x})=\mathbf{x}\in\mathbb{R}^{d_{\text{in}}}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">caligraphic_Y start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( bold_x ) = bold_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT in end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Hidden layer:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\mathcal{Y}^{l}(\mathbf{x})=\sigma\left(\mathbf{W}_{l}\mathcal{Y}^{l-1}(%
\mathbf{x})+\mathbf{b}_{l}\right)\in\mathbb{R}^{d_{l}},\text{for }1\leq l\leq L-1" class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.3.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.3.cmml"><msup id="S3.E2.m1.3.3.1.1.3.2" xref="S3.E2.m1.3.3.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.1.3.2.2" xref="S3.E2.m1.3.3.1.1.3.2.2.cmml">𝒴</mi><mi id="S3.E2.m1.3.3.1.1.3.2.3" xref="S3.E2.m1.3.3.1.1.3.2.3.cmml">l</mi></msup><mo id="S3.E2.m1.3.3.1.1.3.1" xref="S3.E2.m1.3.3.1.1.3.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.3.3.2" xref="S3.E2.m1.3.3.1.1.3.cmml"><mo id="S3.E2.m1.3.3.1.1.3.3.2.1" stretchy="false" xref="S3.E2.m1.3.3.1.1.3.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">𝐱</mi><mo id="S3.E2.m1.3.3.1.1.3.3.2.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.4" xref="S3.E2.m1.3.3.1.1.4.cmml">=</mo><mrow id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.3.cmml">σ</mi><mo id="S3.E2.m1.3.3.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.cmml">𝐖</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.3.cmml">l</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.1.cmml">⁢</mo><msup id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2.cmml">𝒴</mi><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.2.cmml">l</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></msup><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.1a" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.2.4.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.4.2.1" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">𝐱</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.4.2.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml">𝐛</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml">l</mi></msub></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.5" xref="S3.E2.m1.3.3.1.1.5.cmml">∈</mo><msup id="S3.E2.m1.3.3.1.1.6" xref="S3.E2.m1.3.3.1.1.6.cmml"><mi id="S3.E2.m1.3.3.1.1.6.2" xref="S3.E2.m1.3.3.1.1.6.2.cmml">ℝ</mi><msub id="S3.E2.m1.3.3.1.1.6.3" xref="S3.E2.m1.3.3.1.1.6.3.cmml"><mi id="S3.E2.m1.3.3.1.1.6.3.2" xref="S3.E2.m1.3.3.1.1.6.3.2.cmml">d</mi><mi id="S3.E2.m1.3.3.1.1.6.3.3" xref="S3.E2.m1.3.3.1.1.6.3.3.cmml">l</mi></msub></msup></mrow><mo id="S3.E2.m1.4.4.2.3" xref="S3.E2.m1.4.4.3a.cmml">,</mo><mrow id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml"><mrow id="S3.E2.m1.4.4.2.2.2" xref="S3.E2.m1.4.4.2.2.2.cmml"><mtext id="S3.E2.m1.4.4.2.2.2.2" xref="S3.E2.m1.4.4.2.2.2.2a.cmml">for </mtext><mo id="S3.E2.m1.4.4.2.2.2.1" xref="S3.E2.m1.4.4.2.2.2.1.cmml">⁢</mo><mn id="S3.E2.m1.4.4.2.2.2.3" xref="S3.E2.m1.4.4.2.2.2.3.cmml">1</mn></mrow><mo id="S3.E2.m1.4.4.2.2.3" xref="S3.E2.m1.4.4.2.2.3.cmml">≤</mo><mi id="S3.E2.m1.4.4.2.2.4" xref="S3.E2.m1.4.4.2.2.4.cmml">l</mi><mo id="S3.E2.m1.4.4.2.2.5" xref="S3.E2.m1.4.4.2.2.5.cmml">≤</mo><mrow id="S3.E2.m1.4.4.2.2.6" xref="S3.E2.m1.4.4.2.2.6.cmml"><mi id="S3.E2.m1.4.4.2.2.6.2" xref="S3.E2.m1.4.4.2.2.6.2.cmml">L</mi><mo id="S3.E2.m1.4.4.2.2.6.1" xref="S3.E2.m1.4.4.2.2.6.1.cmml">−</mo><mn id="S3.E2.m1.4.4.2.2.6.3" xref="S3.E2.m1.4.4.2.2.6.3.cmml">1</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3a.cmml" xref="S3.E2.m1.4.4.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1.1"><and id="S3.E2.m1.3.3.1.1a.cmml" xref="S3.E2.m1.3.3.1.1"></and><apply id="S3.E2.m1.3.3.1.1b.cmml" xref="S3.E2.m1.3.3.1.1"><eq id="S3.E2.m1.3.3.1.1.4.cmml" xref="S3.E2.m1.3.3.1.1.4"></eq><apply id="S3.E2.m1.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.3"><times id="S3.E2.m1.3.3.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3.1"></times><apply id="S3.E2.m1.3.3.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.3.2.1.cmml" xref="S3.E2.m1.3.3.1.1.3.2">superscript</csymbol><ci id="S3.E2.m1.3.3.1.1.3.2.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2">𝒴</ci><ci id="S3.E2.m1.3.3.1.1.3.2.3.cmml" xref="S3.E2.m1.3.3.1.1.3.2.3">𝑙</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝐱</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2"></times><ci id="S3.E2.m1.3.3.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.3">𝜎</ci><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"><plus id="S3.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1"></plus><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2"><times id="S3.E2.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.1"></times><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2">𝐖</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.3">𝑙</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3">superscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.2">𝒴</ci><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3"><minus id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.1"></minus><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.2">𝑙</ci><cn id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.3.cmml" type="integer" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.3.3">1</cn></apply></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝐱</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.2">𝐛</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.3">𝑙</ci></apply></apply></apply></apply><apply id="S3.E2.m1.3.3.1.1c.cmml" xref="S3.E2.m1.3.3.1.1"><in id="S3.E2.m1.3.3.1.1.5.cmml" xref="S3.E2.m1.3.3.1.1.5"></in><share href="https://arxiv.org/html/2409.05790v1#S3.E2.m1.3.3.1.1.1.cmml" id="S3.E2.m1.3.3.1.1d.cmml" xref="S3.E2.m1.3.3.1.1"></share><apply id="S3.E2.m1.3.3.1.1.6.cmml" xref="S3.E2.m1.3.3.1.1.6"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.6.1.cmml" xref="S3.E2.m1.3.3.1.1.6">superscript</csymbol><ci id="S3.E2.m1.3.3.1.1.6.2.cmml" xref="S3.E2.m1.3.3.1.1.6.2">ℝ</ci><apply id="S3.E2.m1.3.3.1.1.6.3.cmml" xref="S3.E2.m1.3.3.1.1.6.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.6.3.1.cmml" xref="S3.E2.m1.3.3.1.1.6.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.6.3.2.cmml" xref="S3.E2.m1.3.3.1.1.6.3.2">𝑑</ci><ci id="S3.E2.m1.3.3.1.1.6.3.3.cmml" xref="S3.E2.m1.3.3.1.1.6.3.3">𝑙</ci></apply></apply></apply></apply><apply id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2"><and id="S3.E2.m1.4.4.2.2a.cmml" xref="S3.E2.m1.4.4.2.2"></and><apply id="S3.E2.m1.4.4.2.2b.cmml" xref="S3.E2.m1.4.4.2.2"><leq id="S3.E2.m1.4.4.2.2.3.cmml" xref="S3.E2.m1.4.4.2.2.3"></leq><apply id="S3.E2.m1.4.4.2.2.2.cmml" xref="S3.E2.m1.4.4.2.2.2"><times id="S3.E2.m1.4.4.2.2.2.1.cmml" xref="S3.E2.m1.4.4.2.2.2.1"></times><ci id="S3.E2.m1.4.4.2.2.2.2a.cmml" xref="S3.E2.m1.4.4.2.2.2.2"><mtext id="S3.E2.m1.4.4.2.2.2.2.cmml" xref="S3.E2.m1.4.4.2.2.2.2">for </mtext></ci><cn id="S3.E2.m1.4.4.2.2.2.3.cmml" type="integer" xref="S3.E2.m1.4.4.2.2.2.3">1</cn></apply><ci id="S3.E2.m1.4.4.2.2.4.cmml" xref="S3.E2.m1.4.4.2.2.4">𝑙</ci></apply><apply id="S3.E2.m1.4.4.2.2c.cmml" xref="S3.E2.m1.4.4.2.2"><leq id="S3.E2.m1.4.4.2.2.5.cmml" xref="S3.E2.m1.4.4.2.2.5"></leq><share href="https://arxiv.org/html/2409.05790v1#S3.E2.m1.4.4.2.2.4.cmml" id="S3.E2.m1.4.4.2.2d.cmml" xref="S3.E2.m1.4.4.2.2"></share><apply id="S3.E2.m1.4.4.2.2.6.cmml" xref="S3.E2.m1.4.4.2.2.6"><minus id="S3.E2.m1.4.4.2.2.6.1.cmml" xref="S3.E2.m1.4.4.2.2.6.1"></minus><ci id="S3.E2.m1.4.4.2.2.6.2.cmml" xref="S3.E2.m1.4.4.2.2.6.2">𝐿</ci><cn id="S3.E2.m1.4.4.2.2.6.3.cmml" type="integer" xref="S3.E2.m1.4.4.2.2.6.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\mathcal{Y}^{l}(\mathbf{x})=\sigma\left(\mathbf{W}_{l}\mathcal{Y}^{l-1}(%
\mathbf{x})+\mathbf{b}_{l}\right)\in\mathbb{R}^{d_{l}},\text{for }1\leq l\leq L-1</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">caligraphic_Y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT ( bold_x ) = italic_σ ( bold_W start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT caligraphic_Y start_POSTSUPERSCRIPT italic_l - 1 end_POSTSUPERSCRIPT ( bold_x ) + bold_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT end_POSTSUPERSCRIPT , for 1 ≤ italic_l ≤ italic_L - 1</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Output layer:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\mathcal{Y}^{L}(\mathbf{x})=\sigma\left(\mathbf{W}_{L}\mathcal{Y}^{L-1}(%
\mathbf{x})+\mathbf{b}_{L}\right)\in\mathbb{R}^{d_{\text{out}}}" class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mrow id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml"><msup id="S3.E3.m1.3.3.3.2" xref="S3.E3.m1.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.3.2.2" xref="S3.E3.m1.3.3.3.2.2.cmml">𝒴</mi><mi id="S3.E3.m1.3.3.3.2.3" xref="S3.E3.m1.3.3.3.2.3.cmml">L</mi></msup><mo id="S3.E3.m1.3.3.3.1" xref="S3.E3.m1.3.3.3.1.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.3.3.2" xref="S3.E3.m1.3.3.3.cmml"><mo id="S3.E3.m1.3.3.3.3.2.1" stretchy="false" xref="S3.E3.m1.3.3.3.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">𝐱</mi><mo id="S3.E3.m1.3.3.3.3.2.2" stretchy="false" xref="S3.E3.m1.3.3.3.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.4" xref="S3.E3.m1.3.3.4.cmml">=</mo><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml"><mi id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.3.3.1.3.cmml">σ</mi><mo id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.2.2.2" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml">𝐖</mi><mi id="S3.E3.m1.3.3.1.1.1.1.2.2.3" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3.cmml">L</mi></msub><mo id="S3.E3.m1.3.3.1.1.1.1.2.1" xref="S3.E3.m1.3.3.1.1.1.1.2.1.cmml">⁢</mo><msup id="S3.E3.m1.3.3.1.1.1.1.2.3" xref="S3.E3.m1.3.3.1.1.1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.1.1.1.2.3.2" xref="S3.E3.m1.3.3.1.1.1.1.2.3.2.cmml">𝒴</mi><mrow id="S3.E3.m1.3.3.1.1.1.1.2.3.3" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.2.3.3.2" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.2.cmml">L</mi><mo id="S3.E3.m1.3.3.1.1.1.1.2.3.3.1" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="S3.E3.m1.3.3.1.1.1.1.2.3.3.3" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></msup><mo id="S3.E3.m1.3.3.1.1.1.1.2.1a" xref="S3.E3.m1.3.3.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.2.4.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.2.4.2.1" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">𝐱</mi><mo id="S3.E3.m1.3.3.1.1.1.1.2.4.2.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml">+</mo><msub id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.2.cmml">𝐛</mi><mi id="S3.E3.m1.3.3.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.1.1.3.3.cmml">L</mi></msub></mrow><mo id="S3.E3.m1.3.3.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.5" xref="S3.E3.m1.3.3.5.cmml">∈</mo><msup id="S3.E3.m1.3.3.6" xref="S3.E3.m1.3.3.6.cmml"><mi id="S3.E3.m1.3.3.6.2" xref="S3.E3.m1.3.3.6.2.cmml">ℝ</mi><msub id="S3.E3.m1.3.3.6.3" xref="S3.E3.m1.3.3.6.3.cmml"><mi id="S3.E3.m1.3.3.6.3.2" xref="S3.E3.m1.3.3.6.3.2.cmml">d</mi><mtext id="S3.E3.m1.3.3.6.3.3" xref="S3.E3.m1.3.3.6.3.3a.cmml">out</mtext></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><and id="S3.E3.m1.3.3a.cmml" xref="S3.E3.m1.3.3"></and><apply id="S3.E3.m1.3.3b.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.4.cmml" xref="S3.E3.m1.3.3.4"></eq><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"><times id="S3.E3.m1.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.1"></times><apply id="S3.E3.m1.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.2.1.cmml" xref="S3.E3.m1.3.3.3.2">superscript</csymbol><ci id="S3.E3.m1.3.3.3.2.2.cmml" xref="S3.E3.m1.3.3.3.2.2">𝒴</ci><ci id="S3.E3.m1.3.3.3.2.3.cmml" xref="S3.E3.m1.3.3.3.2.3">𝐿</ci></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝐱</ci></apply><apply id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1"><times id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.2"></times><ci id="S3.E3.m1.3.3.1.3.cmml" xref="S3.E3.m1.3.3.1.3">𝜎</ci><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"><plus id="S3.E3.m1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1"></plus><apply id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"><times id="S3.E3.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.1"></times><apply id="S3.E3.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2">𝐖</ci><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3">𝐿</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3">superscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3.2">𝒴</ci><apply id="S3.E3.m1.3.3.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3"><minus id="S3.E3.m1.3.3.1.1.1.1.2.3.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.1"></minus><ci id="S3.E3.m1.3.3.1.1.1.1.2.3.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.2">𝐿</ci><cn id="S3.E3.m1.3.3.1.1.1.1.2.3.3.3.cmml" type="integer" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.3">1</cn></apply></apply><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝐱</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2">𝐛</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3">𝐿</ci></apply></apply></apply></apply><apply id="S3.E3.m1.3.3c.cmml" xref="S3.E3.m1.3.3"><in id="S3.E3.m1.3.3.5.cmml" xref="S3.E3.m1.3.3.5"></in><share href="https://arxiv.org/html/2409.05790v1#S3.E3.m1.3.3.1.cmml" id="S3.E3.m1.3.3d.cmml" xref="S3.E3.m1.3.3"></share><apply id="S3.E3.m1.3.3.6.cmml" xref="S3.E3.m1.3.3.6"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.6.1.cmml" xref="S3.E3.m1.3.3.6">superscript</csymbol><ci id="S3.E3.m1.3.3.6.2.cmml" xref="S3.E3.m1.3.3.6.2">ℝ</ci><apply id="S3.E3.m1.3.3.6.3.cmml" xref="S3.E3.m1.3.3.6.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.6.3.1.cmml" xref="S3.E3.m1.3.3.6.3">subscript</csymbol><ci id="S3.E3.m1.3.3.6.3.2.cmml" xref="S3.E3.m1.3.3.6.3.2">𝑑</ci><ci id="S3.E3.m1.3.3.6.3.3a.cmml" xref="S3.E3.m1.3.3.6.3.3"><mtext id="S3.E3.m1.3.3.6.3.3.cmml" mathsize="50%" xref="S3.E3.m1.3.3.6.3.3">out</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mathcal{Y}^{L}(\mathbf{x})=\sigma\left(\mathbf{W}_{L}\mathcal{Y}^{L-1}(%
\mathbf{x})+\mathbf{b}_{L}\right)\in\mathbb{R}^{d_{\text{out}}}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">caligraphic_Y start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT ( bold_x ) = italic_σ ( bold_W start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT caligraphic_Y start_POSTSUPERSCRIPT italic_L - 1 end_POSTSUPERSCRIPT ( bold_x ) + bold_b start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT out end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS1.p2.14">where <math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">bold_x</annotation></semantics></math> is the input vector with dimension <math alttext="d_{\text{in}}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">d</mi><mtext id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑑</ci><ci id="S3.SS1.p2.2.m2.1.1.3a.cmml" xref="S3.SS1.p2.2.m2.1.1.3"><mtext id="S3.SS1.p2.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p2.2.m2.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">d_{\text{in}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_d start_POSTSUBSCRIPT in end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="\mathcal{Y}^{l}(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.2" xref="S3.SS1.p2.3.m3.1.2.cmml"><msup id="S3.SS1.p2.3.m3.1.2.2" xref="S3.SS1.p2.3.m3.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.1.2.2.2" xref="S3.SS1.p2.3.m3.1.2.2.2.cmml">𝒴</mi><mi id="S3.SS1.p2.3.m3.1.2.2.3" xref="S3.SS1.p2.3.m3.1.2.2.3.cmml">l</mi></msup><mo id="S3.SS1.p2.3.m3.1.2.1" xref="S3.SS1.p2.3.m3.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p2.3.m3.1.2.3.2" xref="S3.SS1.p2.3.m3.1.2.cmml"><mo id="S3.SS1.p2.3.m3.1.2.3.2.1" stretchy="false" xref="S3.SS1.p2.3.m3.1.2.cmml">(</mo><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">𝐱</mi><mo id="S3.SS1.p2.3.m3.1.2.3.2.2" stretchy="false" xref="S3.SS1.p2.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.2.cmml" xref="S3.SS1.p2.3.m3.1.2"><times id="S3.SS1.p2.3.m3.1.2.1.cmml" xref="S3.SS1.p2.3.m3.1.2.1"></times><apply id="S3.SS1.p2.3.m3.1.2.2.cmml" xref="S3.SS1.p2.3.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.2.2.1.cmml" xref="S3.SS1.p2.3.m3.1.2.2">superscript</csymbol><ci id="S3.SS1.p2.3.m3.1.2.2.2.cmml" xref="S3.SS1.p2.3.m3.1.2.2.2">𝒴</ci><ci id="S3.SS1.p2.3.m3.1.2.2.3.cmml" xref="S3.SS1.p2.3.m3.1.2.2.3">𝑙</ci></apply><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathcal{Y}^{l}(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">caligraphic_Y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT ( bold_x )</annotation></semantics></math> is the activation of the <math alttext="l^{\text{th}}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msup id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">l</mi><mtext id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3a.cmml">th</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝑙</ci><ci id="S3.SS1.p2.4.m4.1.1.3a.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><mtext id="S3.SS1.p2.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p2.4.m4.1.1.3">th</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">l^{\text{th}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_l start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT</annotation></semantics></math> hidden layer with dimension <math alttext="d_{l}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">d</mi><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝑑</ci><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">d_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_d start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="\mathcal{Y}^{L}(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.2" xref="S3.SS1.p2.6.m6.1.2.cmml"><msup id="S3.SS1.p2.6.m6.1.2.2" xref="S3.SS1.p2.6.m6.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.6.m6.1.2.2.2" xref="S3.SS1.p2.6.m6.1.2.2.2.cmml">𝒴</mi><mi id="S3.SS1.p2.6.m6.1.2.2.3" xref="S3.SS1.p2.6.m6.1.2.2.3.cmml">L</mi></msup><mo id="S3.SS1.p2.6.m6.1.2.1" xref="S3.SS1.p2.6.m6.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p2.6.m6.1.2.3.2" xref="S3.SS1.p2.6.m6.1.2.cmml"><mo id="S3.SS1.p2.6.m6.1.2.3.2.1" stretchy="false" xref="S3.SS1.p2.6.m6.1.2.cmml">(</mo><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">𝐱</mi><mo id="S3.SS1.p2.6.m6.1.2.3.2.2" stretchy="false" xref="S3.SS1.p2.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.2.cmml" xref="S3.SS1.p2.6.m6.1.2"><times id="S3.SS1.p2.6.m6.1.2.1.cmml" xref="S3.SS1.p2.6.m6.1.2.1"></times><apply id="S3.SS1.p2.6.m6.1.2.2.cmml" xref="S3.SS1.p2.6.m6.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.2.2.1.cmml" xref="S3.SS1.p2.6.m6.1.2.2">superscript</csymbol><ci id="S3.SS1.p2.6.m6.1.2.2.2.cmml" xref="S3.SS1.p2.6.m6.1.2.2.2">𝒴</ci><ci id="S3.SS1.p2.6.m6.1.2.2.3.cmml" xref="S3.SS1.p2.6.m6.1.2.2.3">𝐿</ci></apply><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\mathcal{Y}^{L}(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">caligraphic_Y start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT ( bold_x )</annotation></semantics></math> is the prediction in the output layer with dimension <math alttext="d_{\text{out}}" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m7.1"><semantics id="S3.SS1.p2.7.m7.1a"><msub id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">d</mi><mtext id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">𝑑</ci><ci id="S3.SS1.p2.7.m7.1.1.3a.cmml" xref="S3.SS1.p2.7.m7.1.1.3"><mtext id="S3.SS1.p2.7.m7.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p2.7.m7.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">d_{\text{out}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m7.1d">italic_d start_POSTSUBSCRIPT out end_POSTSUBSCRIPT</annotation></semantics></math>. <math alttext="L" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m8.1"><semantics id="S3.SS1.p2.8.m8.1a"><mi id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><ci id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.8.m8.1d">italic_L</annotation></semantics></math> is the depth of the neural network, including (<math alttext="L-1" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m9.1"><semantics id="S3.SS1.p2.9.m9.1a"><mrow id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml"><mi id="S3.SS1.p2.9.m9.1.1.2" xref="S3.SS1.p2.9.m9.1.1.2.cmml">L</mi><mo id="S3.SS1.p2.9.m9.1.1.1" xref="S3.SS1.p2.9.m9.1.1.1.cmml">−</mo><mn id="S3.SS1.p2.9.m9.1.1.3" xref="S3.SS1.p2.9.m9.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><apply id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1"><minus id="S3.SS1.p2.9.m9.1.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1.1"></minus><ci id="S3.SS1.p2.9.m9.1.1.2.cmml" xref="S3.SS1.p2.9.m9.1.1.2">𝐿</ci><cn id="S3.SS1.p2.9.m9.1.1.3.cmml" type="integer" xref="S3.SS1.p2.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.9.m9.1d">italic_L - 1</annotation></semantics></math>) hidden layers and one output layer. <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS1.p2.10.m10.1"><semantics id="S3.SS1.p2.10.m10.1a"><mi id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><ci id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.10.m10.1d">italic_σ</annotation></semantics></math> is the activation function. <math alttext="\mathbf{W}_{l}" class="ltx_Math" display="inline" id="S3.SS1.p2.11.m11.1"><semantics id="S3.SS1.p2.11.m11.1a"><msub id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml"><mi id="S3.SS1.p2.11.m11.1.1.2" xref="S3.SS1.p2.11.m11.1.1.2.cmml">𝐖</mi><mi id="S3.SS1.p2.11.m11.1.1.3" xref="S3.SS1.p2.11.m11.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.1b"><apply id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.11.m11.1.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p2.11.m11.1.1.2.cmml" xref="S3.SS1.p2.11.m11.1.1.2">𝐖</ci><ci id="S3.SS1.p2.11.m11.1.1.3.cmml" xref="S3.SS1.p2.11.m11.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.1c">\mathbf{W}_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.11.m11.1d">bold_W start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> is the matrix of weights for the <math alttext="l^{\text{th}}" class="ltx_Math" display="inline" id="S3.SS1.p2.12.m12.1"><semantics id="S3.SS1.p2.12.m12.1a"><msup id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml"><mi id="S3.SS1.p2.12.m12.1.1.2" xref="S3.SS1.p2.12.m12.1.1.2.cmml">l</mi><mtext id="S3.SS1.p2.12.m12.1.1.3" xref="S3.SS1.p2.12.m12.1.1.3a.cmml">th</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.1b"><apply id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">superscript</csymbol><ci id="S3.SS1.p2.12.m12.1.1.2.cmml" xref="S3.SS1.p2.12.m12.1.1.2">𝑙</ci><ci id="S3.SS1.p2.12.m12.1.1.3a.cmml" xref="S3.SS1.p2.12.m12.1.1.3"><mtext id="S3.SS1.p2.12.m12.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p2.12.m12.1.1.3">th</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.1c">l^{\text{th}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.12.m12.1d">italic_l start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT</annotation></semantics></math> hidden layer. <math alttext="\mathbf{b}_{l}" class="ltx_Math" display="inline" id="S3.SS1.p2.13.m13.1"><semantics id="S3.SS1.p2.13.m13.1a"><msub id="S3.SS1.p2.13.m13.1.1" xref="S3.SS1.p2.13.m13.1.1.cmml"><mi id="S3.SS1.p2.13.m13.1.1.2" xref="S3.SS1.p2.13.m13.1.1.2.cmml">𝐛</mi><mi id="S3.SS1.p2.13.m13.1.1.3" xref="S3.SS1.p2.13.m13.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.1b"><apply id="S3.SS1.p2.13.m13.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1">subscript</csymbol><ci id="S3.SS1.p2.13.m13.1.1.2.cmml" xref="S3.SS1.p2.13.m13.1.1.2">𝐛</ci><ci id="S3.SS1.p2.13.m13.1.1.3.cmml" xref="S3.SS1.p2.13.m13.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.1c">\mathbf{b}_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.13.m13.1d">bold_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> is the vector of bias for the <math alttext="l^{\text{th}}" class="ltx_Math" display="inline" id="S3.SS1.p2.14.m14.1"><semantics id="S3.SS1.p2.14.m14.1a"><msup id="S3.SS1.p2.14.m14.1.1" xref="S3.SS1.p2.14.m14.1.1.cmml"><mi id="S3.SS1.p2.14.m14.1.1.2" xref="S3.SS1.p2.14.m14.1.1.2.cmml">l</mi><mtext id="S3.SS1.p2.14.m14.1.1.3" xref="S3.SS1.p2.14.m14.1.1.3a.cmml">th</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m14.1b"><apply id="S3.SS1.p2.14.m14.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.14.m14.1.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1">superscript</csymbol><ci id="S3.SS1.p2.14.m14.1.1.2.cmml" xref="S3.SS1.p2.14.m14.1.1.2">𝑙</ci><ci id="S3.SS1.p2.14.m14.1.1.3a.cmml" xref="S3.SS1.p2.14.m14.1.1.3"><mtext id="S3.SS1.p2.14.m14.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p2.14.m14.1.1.3">th</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.14.m14.1c">l^{\text{th}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.14.m14.1d">italic_l start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT</annotation></semantics></math> hidden layer.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">A DNN model is designed with weights organized into successive layers, with every neuron of one layer connected to every neuron in the subsequent layer. The depth of these models influence the complexity of information gained from the training set, with early layers extracting coarse features with the finer features extracted in deeper layers. Several hyperparameters influence the performance of a given model, such as the number of neurons per layer, the rate at which the weights are modified, and the choice of activation functions. As such, the optimization of these hyperparameters are necessary to ensure maximal performance of a given architecture. When a model is finished training and frozen, it is completely deterministic and will produce an identical output when given an identical input.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>VAEs and CVAEs</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">VAEs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib4" title="">4</a>]</cite> are a family of DGMs that was introduced to learn the data distribution uniquely through variational inference (VI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib7" title="">7</a>]</cite>. A VAE model consists of three main components: the encoder, latent space, and decoder, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3.F2" title="Figure 2 ‣ 3.2 VAEs and CVAEs ‣ 3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>. By passing the input to the encoder, it encodes it as a distribution in the latent space. Hence, the latent space consists of two vectors that represent the mean value and standard deviation of the encoded distribution. The decoder utilizes the encoded information to reconstruct the input by reversing the encoding process. This approach creates a structured latent space that can be effectively utilized for data generation. Once the model is trained, the decoder can be used to generate new samples by taking a vector from the latent space.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="S3.F2.g1" src="x1.png" width="581"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Illustration of the structure of a CVAE generative model.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">This process does not allow for generating targeted samples, since the only input passed to the decoder is a random vector from the latent space. To enable targeted data generation, a CVAE is employed. CVAEs are a variant of VAEs that use labels or conditions for targeted data generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib18" title="">18</a>]</cite>. Generating targeted data is achieved by passing specified conditions (vector <math alttext="\mathbf{c}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathbf{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">bold_c</annotation></semantics></math>) to the decoder as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3.F2" title="Figure 2 ‣ 3.2 VAEs and CVAEs ‣ 3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.10">The loss function optimized during the training process is constructed by utilizing VI. Let <math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">bold_x</annotation></semantics></math> be a set of observed variables with a distribution denoted as <math alttext="p(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.2" xref="S3.SS2.p3.2.m2.1.2.cmml"><mi id="S3.SS2.p3.2.m2.1.2.2" xref="S3.SS2.p3.2.m2.1.2.2.cmml">p</mi><mo id="S3.SS2.p3.2.m2.1.2.1" xref="S3.SS2.p3.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.p3.2.m2.1.2.3.2" xref="S3.SS2.p3.2.m2.1.2.cmml"><mo id="S3.SS2.p3.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS2.p3.2.m2.1.2.cmml">(</mo><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">𝐱</mi><mo id="S3.SS2.p3.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS2.p3.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.2.cmml" xref="S3.SS2.p3.2.m2.1.2"><times id="S3.SS2.p3.2.m2.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.2.1"></times><ci id="S3.SS2.p3.2.m2.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.2.2">𝑝</ci><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">p(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_p ( bold_x )</annotation></semantics></math>, and <math alttext="\mathbf{z}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathbf{z}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">bold_z</annotation></semantics></math> be a set of latent variables with a joint distribution <math alttext="p(\mathbf{z},\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.2"><semantics id="S3.SS2.p3.4.m4.2a"><mrow id="S3.SS2.p3.4.m4.2.3" xref="S3.SS2.p3.4.m4.2.3.cmml"><mi id="S3.SS2.p3.4.m4.2.3.2" xref="S3.SS2.p3.4.m4.2.3.2.cmml">p</mi><mo id="S3.SS2.p3.4.m4.2.3.1" xref="S3.SS2.p3.4.m4.2.3.1.cmml">⁢</mo><mrow id="S3.SS2.p3.4.m4.2.3.3.2" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml"><mo id="S3.SS2.p3.4.m4.2.3.3.2.1" stretchy="false" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">𝐳</mi><mo id="S3.SS2.p3.4.m4.2.3.3.2.2" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p3.4.m4.2.2" xref="S3.SS2.p3.4.m4.2.2.cmml">𝐱</mi><mo id="S3.SS2.p3.4.m4.2.3.3.2.3" stretchy="false" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.2b"><apply id="S3.SS2.p3.4.m4.2.3.cmml" xref="S3.SS2.p3.4.m4.2.3"><times id="S3.SS2.p3.4.m4.2.3.1.cmml" xref="S3.SS2.p3.4.m4.2.3.1"></times><ci id="S3.SS2.p3.4.m4.2.3.2.cmml" xref="S3.SS2.p3.4.m4.2.3.2">𝑝</ci><interval closure="open" id="S3.SS2.p3.4.m4.2.3.3.1.cmml" xref="S3.SS2.p3.4.m4.2.3.3.2"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝐳</ci><ci id="S3.SS2.p3.4.m4.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2">𝐱</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.2c">p(\mathbf{z},\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.2d">italic_p ( bold_z , bold_x )</annotation></semantics></math>. The conditional probability <math alttext="p(\mathbf{z}|\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mrow id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">p</mi><mo id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.5.m5.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.5.m5.1.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.2" xref="S3.SS2.p3.5.m5.1.1.1.1.1.2.cmml">𝐳</mi><mo fence="false" id="S3.SS2.p3.5.m5.1.1.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.3" xref="S3.SS2.p3.5.m5.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S3.SS2.p3.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><times id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2"></times><ci id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3">𝑝</ci><apply id="S3.SS2.p3.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.2">𝐳</ci><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.3">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">p(\mathbf{z}|\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_p ( bold_z | bold_x )</annotation></semantics></math> can be found by applying the Bayes’ rule, <math alttext="p(\mathbf{z}|\mathbf{x})=p(\mathbf{x}|\mathbf{z})p(\mathbf{z})/p(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.4"><semantics id="S3.SS2.p3.6.m6.4a"><mrow id="S3.SS2.p3.6.m6.4.4" xref="S3.SS2.p3.6.m6.4.4.cmml"><mrow id="S3.SS2.p3.6.m6.3.3.1" xref="S3.SS2.p3.6.m6.3.3.1.cmml"><mi id="S3.SS2.p3.6.m6.3.3.1.3" xref="S3.SS2.p3.6.m6.3.3.1.3.cmml">p</mi><mo id="S3.SS2.p3.6.m6.3.3.1.2" xref="S3.SS2.p3.6.m6.3.3.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.6.m6.3.3.1.1.1" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.cmml"><mo id="S3.SS2.p3.6.m6.3.3.1.1.1.2" stretchy="false" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.6.m6.3.3.1.1.1.1" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.cmml"><mi id="S3.SS2.p3.6.m6.3.3.1.1.1.1.2" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.2.cmml">𝐳</mi><mo fence="false" id="S3.SS2.p3.6.m6.3.3.1.1.1.1.1" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.6.m6.3.3.1.1.1.1.3" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S3.SS2.p3.6.m6.3.3.1.1.1.3" stretchy="false" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.6.m6.4.4.3" xref="S3.SS2.p3.6.m6.4.4.3.cmml">=</mo><mrow id="S3.SS2.p3.6.m6.4.4.2" xref="S3.SS2.p3.6.m6.4.4.2.cmml"><mrow id="S3.SS2.p3.6.m6.4.4.2.1" xref="S3.SS2.p3.6.m6.4.4.2.1.cmml"><mrow id="S3.SS2.p3.6.m6.4.4.2.1.1" xref="S3.SS2.p3.6.m6.4.4.2.1.1.cmml"><mi id="S3.SS2.p3.6.m6.4.4.2.1.1.3" xref="S3.SS2.p3.6.m6.4.4.2.1.1.3.cmml">p</mi><mo id="S3.SS2.p3.6.m6.4.4.2.1.1.2" xref="S3.SS2.p3.6.m6.4.4.2.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.2" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.2.cmml">𝐱</mi><mo fence="false" id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.1" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.3" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.3.cmml">𝐳</mi></mrow><mo id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.p3.6.m6.4.4.2.1.1.2a" xref="S3.SS2.p3.6.m6.4.4.2.1.1.2.cmml">⁢</mo><mi id="S3.SS2.p3.6.m6.4.4.2.1.1.4" xref="S3.SS2.p3.6.m6.4.4.2.1.1.4.cmml">p</mi><mo id="S3.SS2.p3.6.m6.4.4.2.1.1.2b" xref="S3.SS2.p3.6.m6.4.4.2.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.6.m6.4.4.2.1.1.5.2" xref="S3.SS2.p3.6.m6.4.4.2.1.1.cmml"><mo id="S3.SS2.p3.6.m6.4.4.2.1.1.5.2.1" stretchy="false" xref="S3.SS2.p3.6.m6.4.4.2.1.1.cmml">(</mo><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">𝐳</mi><mo id="S3.SS2.p3.6.m6.4.4.2.1.1.5.2.2" stretchy="false" xref="S3.SS2.p3.6.m6.4.4.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.6.m6.4.4.2.1.2" xref="S3.SS2.p3.6.m6.4.4.2.1.2.cmml">/</mo><mi id="S3.SS2.p3.6.m6.4.4.2.1.3" xref="S3.SS2.p3.6.m6.4.4.2.1.3.cmml">p</mi></mrow><mo id="S3.SS2.p3.6.m6.4.4.2.2" xref="S3.SS2.p3.6.m6.4.4.2.2.cmml">⁢</mo><mrow id="S3.SS2.p3.6.m6.4.4.2.3.2" xref="S3.SS2.p3.6.m6.4.4.2.cmml"><mo id="S3.SS2.p3.6.m6.4.4.2.3.2.1" stretchy="false" xref="S3.SS2.p3.6.m6.4.4.2.cmml">(</mo><mi id="S3.SS2.p3.6.m6.2.2" xref="S3.SS2.p3.6.m6.2.2.cmml">𝐱</mi><mo id="S3.SS2.p3.6.m6.4.4.2.3.2.2" stretchy="false" xref="S3.SS2.p3.6.m6.4.4.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.4b"><apply id="S3.SS2.p3.6.m6.4.4.cmml" xref="S3.SS2.p3.6.m6.4.4"><eq id="S3.SS2.p3.6.m6.4.4.3.cmml" xref="S3.SS2.p3.6.m6.4.4.3"></eq><apply id="S3.SS2.p3.6.m6.3.3.1.cmml" xref="S3.SS2.p3.6.m6.3.3.1"><times id="S3.SS2.p3.6.m6.3.3.1.2.cmml" xref="S3.SS2.p3.6.m6.3.3.1.2"></times><ci id="S3.SS2.p3.6.m6.3.3.1.3.cmml" xref="S3.SS2.p3.6.m6.3.3.1.3">𝑝</ci><apply id="S3.SS2.p3.6.m6.3.3.1.1.1.1.cmml" xref="S3.SS2.p3.6.m6.3.3.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.6.m6.3.3.1.1.1.1.1.cmml" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.6.m6.3.3.1.1.1.1.2.cmml" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.2">𝐳</ci><ci id="S3.SS2.p3.6.m6.3.3.1.1.1.1.3.cmml" xref="S3.SS2.p3.6.m6.3.3.1.1.1.1.3">𝐱</ci></apply></apply><apply id="S3.SS2.p3.6.m6.4.4.2.cmml" xref="S3.SS2.p3.6.m6.4.4.2"><times id="S3.SS2.p3.6.m6.4.4.2.2.cmml" xref="S3.SS2.p3.6.m6.4.4.2.2"></times><apply id="S3.SS2.p3.6.m6.4.4.2.1.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1"><divide id="S3.SS2.p3.6.m6.4.4.2.1.2.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.2"></divide><apply id="S3.SS2.p3.6.m6.4.4.2.1.1.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1"><times id="S3.SS2.p3.6.m6.4.4.2.1.1.2.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1.2"></times><ci id="S3.SS2.p3.6.m6.4.4.2.1.1.3.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1.3">𝑝</ci><apply id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.2">𝐱</ci><ci id="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1.1.1.1.3">𝐳</ci></apply><ci id="S3.SS2.p3.6.m6.4.4.2.1.1.4.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.1.4">𝑝</ci><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">𝐳</ci></apply><ci id="S3.SS2.p3.6.m6.4.4.2.1.3.cmml" xref="S3.SS2.p3.6.m6.4.4.2.1.3">𝑝</ci></apply><ci id="S3.SS2.p3.6.m6.2.2.cmml" xref="S3.SS2.p3.6.m6.2.2">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.4c">p(\mathbf{z}|\mathbf{x})=p(\mathbf{x}|\mathbf{z})p(\mathbf{z})/p(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.4d">italic_p ( bold_z | bold_x ) = italic_p ( bold_x | bold_z ) italic_p ( bold_z ) / italic_p ( bold_x )</annotation></semantics></math>.
Calculating <math alttext="p(\mathbf{z}|\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><mrow id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">p</mi><mo id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.7.m7.1.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.7.m7.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.7.m7.1.1.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.1.1.1.2" xref="S3.SS2.p3.7.m7.1.1.1.1.1.2.cmml">𝐳</mi><mo fence="false" id="S3.SS2.p3.7.m7.1.1.1.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.7.m7.1.1.1.1.1.3" xref="S3.SS2.p3.7.m7.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S3.SS2.p3.7.m7.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><times id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2"></times><ci id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3">𝑝</ci><apply id="S3.SS2.p3.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1.1.2">𝐳</ci><ci id="S3.SS2.p3.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1.1.3">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">p(\mathbf{z}|\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_p ( bold_z | bold_x )</annotation></semantics></math> is challenging due to the intractable integral <math alttext="p(\mathbf{x})=\int p(\mathbf{x}|\mathbf{z})p(\mathbf{z})d\mathbf{z}" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m8.3"><semantics id="S3.SS2.p3.8.m8.3a"><mrow id="S3.SS2.p3.8.m8.3.3" xref="S3.SS2.p3.8.m8.3.3.cmml"><mrow id="S3.SS2.p3.8.m8.3.3.3" xref="S3.SS2.p3.8.m8.3.3.3.cmml"><mi id="S3.SS2.p3.8.m8.3.3.3.2" xref="S3.SS2.p3.8.m8.3.3.3.2.cmml">p</mi><mo id="S3.SS2.p3.8.m8.3.3.3.1" xref="S3.SS2.p3.8.m8.3.3.3.1.cmml">⁢</mo><mrow id="S3.SS2.p3.8.m8.3.3.3.3.2" xref="S3.SS2.p3.8.m8.3.3.3.cmml"><mo id="S3.SS2.p3.8.m8.3.3.3.3.2.1" stretchy="false" xref="S3.SS2.p3.8.m8.3.3.3.cmml">(</mo><mi id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml">𝐱</mi><mo id="S3.SS2.p3.8.m8.3.3.3.3.2.2" stretchy="false" xref="S3.SS2.p3.8.m8.3.3.3.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.8.m8.3.3.2" rspace="0.111em" xref="S3.SS2.p3.8.m8.3.3.2.cmml">=</mo><mrow id="S3.SS2.p3.8.m8.3.3.1" xref="S3.SS2.p3.8.m8.3.3.1.cmml"><mo id="S3.SS2.p3.8.m8.3.3.1.2" xref="S3.SS2.p3.8.m8.3.3.1.2.cmml">∫</mo><mrow id="S3.SS2.p3.8.m8.3.3.1.1" xref="S3.SS2.p3.8.m8.3.3.1.1.cmml"><mi id="S3.SS2.p3.8.m8.3.3.1.1.3" xref="S3.SS2.p3.8.m8.3.3.1.1.3.cmml">p</mi><mo id="S3.SS2.p3.8.m8.3.3.1.1.2" xref="S3.SS2.p3.8.m8.3.3.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.8.m8.3.3.1.1.1.1" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.8.m8.3.3.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.2" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.2.cmml">𝐱</mi><mo fence="false" id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.1" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.3" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.3.cmml">𝐳</mi></mrow><mo id="S3.SS2.p3.8.m8.3.3.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.p3.8.m8.3.3.1.1.2a" xref="S3.SS2.p3.8.m8.3.3.1.1.2.cmml">⁢</mo><mi id="S3.SS2.p3.8.m8.3.3.1.1.4" xref="S3.SS2.p3.8.m8.3.3.1.1.4.cmml">p</mi><mo id="S3.SS2.p3.8.m8.3.3.1.1.2b" xref="S3.SS2.p3.8.m8.3.3.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.8.m8.3.3.1.1.5.2" xref="S3.SS2.p3.8.m8.3.3.1.1.cmml"><mo id="S3.SS2.p3.8.m8.3.3.1.1.5.2.1" stretchy="false" xref="S3.SS2.p3.8.m8.3.3.1.1.cmml">(</mo><mi id="S3.SS2.p3.8.m8.2.2" xref="S3.SS2.p3.8.m8.2.2.cmml">𝐳</mi><mo id="S3.SS2.p3.8.m8.3.3.1.1.5.2.2" stretchy="false" xref="S3.SS2.p3.8.m8.3.3.1.1.cmml">)</mo></mrow><mo id="S3.SS2.p3.8.m8.3.3.1.1.2c" lspace="0em" xref="S3.SS2.p3.8.m8.3.3.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.8.m8.3.3.1.1.6" xref="S3.SS2.p3.8.m8.3.3.1.1.6.cmml"><mo id="S3.SS2.p3.8.m8.3.3.1.1.6.1" rspace="0em" xref="S3.SS2.p3.8.m8.3.3.1.1.6.1.cmml">𝑑</mo><mi id="S3.SS2.p3.8.m8.3.3.1.1.6.2" xref="S3.SS2.p3.8.m8.3.3.1.1.6.2.cmml">𝐳</mi></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.3b"><apply id="S3.SS2.p3.8.m8.3.3.cmml" xref="S3.SS2.p3.8.m8.3.3"><eq id="S3.SS2.p3.8.m8.3.3.2.cmml" xref="S3.SS2.p3.8.m8.3.3.2"></eq><apply id="S3.SS2.p3.8.m8.3.3.3.cmml" xref="S3.SS2.p3.8.m8.3.3.3"><times id="S3.SS2.p3.8.m8.3.3.3.1.cmml" xref="S3.SS2.p3.8.m8.3.3.3.1"></times><ci id="S3.SS2.p3.8.m8.3.3.3.2.cmml" xref="S3.SS2.p3.8.m8.3.3.3.2">𝑝</ci><ci id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">𝐱</ci></apply><apply id="S3.SS2.p3.8.m8.3.3.1.cmml" xref="S3.SS2.p3.8.m8.3.3.1"><int id="S3.SS2.p3.8.m8.3.3.1.2.cmml" xref="S3.SS2.p3.8.m8.3.3.1.2"></int><apply id="S3.SS2.p3.8.m8.3.3.1.1.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1"><times id="S3.SS2.p3.8.m8.3.3.1.1.2.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.2"></times><ci id="S3.SS2.p3.8.m8.3.3.1.1.3.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.3">𝑝</ci><apply id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.2">𝐱</ci><ci id="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.1.1.1.3">𝐳</ci></apply><ci id="S3.SS2.p3.8.m8.3.3.1.1.4.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.4">𝑝</ci><ci id="S3.SS2.p3.8.m8.2.2.cmml" xref="S3.SS2.p3.8.m8.2.2">𝐳</ci><apply id="S3.SS2.p3.8.m8.3.3.1.1.6.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.6"><csymbol cd="latexml" id="S3.SS2.p3.8.m8.3.3.1.1.6.1.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.6.1">differential-d</csymbol><ci id="S3.SS2.p3.8.m8.3.3.1.1.6.2.cmml" xref="S3.SS2.p3.8.m8.3.3.1.1.6.2">𝐳</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.3c">p(\mathbf{x})=\int p(\mathbf{x}|\mathbf{z})p(\mathbf{z})d\mathbf{z}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m8.3d">italic_p ( bold_x ) = ∫ italic_p ( bold_x | bold_z ) italic_p ( bold_z ) italic_d bold_z</annotation></semantics></math>. VI is used to approximate <math alttext="p(\mathbf{z}|\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.9.m9.1"><semantics id="S3.SS2.p3.9.m9.1a"><mrow id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml"><mi id="S3.SS2.p3.9.m9.1.1.3" xref="S3.SS2.p3.9.m9.1.1.3.cmml">p</mi><mo id="S3.SS2.p3.9.m9.1.1.2" xref="S3.SS2.p3.9.m9.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.9.m9.1.1.1.1" xref="S3.SS2.p3.9.m9.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.9.m9.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.9.m9.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.9.m9.1.1.1.1.1" xref="S3.SS2.p3.9.m9.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.9.m9.1.1.1.1.1.2" xref="S3.SS2.p3.9.m9.1.1.1.1.1.2.cmml">𝐳</mi><mo fence="false" id="S3.SS2.p3.9.m9.1.1.1.1.1.1" xref="S3.SS2.p3.9.m9.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.9.m9.1.1.1.1.1.3" xref="S3.SS2.p3.9.m9.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S3.SS2.p3.9.m9.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.9.m9.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><apply id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1"><times id="S3.SS2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.p3.9.m9.1.1.2"></times><ci id="S3.SS2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3">𝑝</ci><apply id="S3.SS2.p3.9.m9.1.1.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.9.m9.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.9.m9.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.9.m9.1.1.1.1.1.2">𝐳</ci><ci id="S3.SS2.p3.9.m9.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.9.m9.1.1.1.1.1.3">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">p(\mathbf{z}|\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.9.m9.1d">italic_p ( bold_z | bold_x )</annotation></semantics></math> with a simpler distribution <math alttext="q(\mathbf{z}|\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.10.m10.1"><semantics id="S3.SS2.p3.10.m10.1a"><mrow id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml"><mi id="S3.SS2.p3.10.m10.1.1.3" xref="S3.SS2.p3.10.m10.1.1.3.cmml">q</mi><mo id="S3.SS2.p3.10.m10.1.1.2" xref="S3.SS2.p3.10.m10.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.10.m10.1.1.1.1" xref="S3.SS2.p3.10.m10.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.10.m10.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.10.m10.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.10.m10.1.1.1.1.1" xref="S3.SS2.p3.10.m10.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.10.m10.1.1.1.1.1.2" xref="S3.SS2.p3.10.m10.1.1.1.1.1.2.cmml">𝐳</mi><mo fence="false" id="S3.SS2.p3.10.m10.1.1.1.1.1.1" xref="S3.SS2.p3.10.m10.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.10.m10.1.1.1.1.1.3" xref="S3.SS2.p3.10.m10.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S3.SS2.p3.10.m10.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.10.m10.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><apply id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1"><times id="S3.SS2.p3.10.m10.1.1.2.cmml" xref="S3.SS2.p3.10.m10.1.1.2"></times><ci id="S3.SS2.p3.10.m10.1.1.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3">𝑞</ci><apply id="S3.SS2.p3.10.m10.1.1.1.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.10.m10.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.10.m10.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.10.m10.1.1.1.1.1.2">𝐳</ci><ci id="S3.SS2.p3.10.m10.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.10.m10.1.1.1.1.1.3">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">q(\mathbf{z}|\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.10.m10.1d">italic_q ( bold_z | bold_x )</annotation></semantics></math>, often chosen as Gaussian in practice. Afterwards, the differences between the two distributions is minimized via minimizing the Kullback–Leibler (KL) divergence. With this the loss function for VAEs can be written as follows:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E4">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E4X">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}(\bm{\theta},\bm{\phi})" class="ltx_Math" display="inline" id="S3.E4X.2.1.1.m1.2"><semantics id="S3.E4X.2.1.1.m1.2a"><mrow id="S3.E4X.2.1.1.m1.2.3" xref="S3.E4X.2.1.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4X.2.1.1.m1.2.3.2" xref="S3.E4X.2.1.1.m1.2.3.2.cmml">ℒ</mi><mo id="S3.E4X.2.1.1.m1.2.3.1" xref="S3.E4X.2.1.1.m1.2.3.1.cmml">⁢</mo><mrow id="S3.E4X.2.1.1.m1.2.3.3.2" xref="S3.E4X.2.1.1.m1.2.3.3.1.cmml"><mo id="S3.E4X.2.1.1.m1.2.3.3.2.1" stretchy="false" xref="S3.E4X.2.1.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.E4X.2.1.1.m1.1.1" xref="S3.E4X.2.1.1.m1.1.1.cmml">𝜽</mi><mo id="S3.E4X.2.1.1.m1.2.3.3.2.2" xref="S3.E4X.2.1.1.m1.2.3.3.1.cmml">,</mo><mi class="ltx_mathvariant_bold-italic" id="S3.E4X.2.1.1.m1.2.2" mathvariant="bold-italic" xref="S3.E4X.2.1.1.m1.2.2.cmml">ϕ</mi><mo id="S3.E4X.2.1.1.m1.2.3.3.2.3" stretchy="false" xref="S3.E4X.2.1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4X.2.1.1.m1.2b"><apply id="S3.E4X.2.1.1.m1.2.3.cmml" xref="S3.E4X.2.1.1.m1.2.3"><times id="S3.E4X.2.1.1.m1.2.3.1.cmml" xref="S3.E4X.2.1.1.m1.2.3.1"></times><ci id="S3.E4X.2.1.1.m1.2.3.2.cmml" xref="S3.E4X.2.1.1.m1.2.3.2">ℒ</ci><interval closure="open" id="S3.E4X.2.1.1.m1.2.3.3.1.cmml" xref="S3.E4X.2.1.1.m1.2.3.3.2"><ci id="S3.E4X.2.1.1.m1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1">𝜽</ci><ci id="S3.E4X.2.1.1.m1.2.2.cmml" xref="S3.E4X.2.1.1.m1.2.2">bold-italic-ϕ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4X.2.1.1.m1.2c">\displaystyle\mathcal{L}(\bm{\theta},\bm{\phi})</annotation><annotation encoding="application/x-llamapun" id="S3.E4X.2.1.1.m1.2d">caligraphic_L ( bold_italic_θ , bold_italic_ϕ )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=-\log(p_{\bm{\theta}}(\mathbf{x}))+\mathcal{D}_{\text{KL}}(q_{%
\bm{\phi}}(\mathbf{z}|\mathbf{x})||p_{\bm{\theta}}(\mathbf{z}|\mathbf{x}))" class="ltx_math_unparsed" display="inline" id="S3.E4X.3.2.2.m1.2"><semantics id="S3.E4X.3.2.2.m1.2a"><mrow id="S3.E4X.3.2.2.m1.2b"><mo id="S3.E4X.3.2.2.m1.2.3" rspace="0em">=</mo><mo id="S3.E4X.3.2.2.m1.2.4" lspace="0em">−</mo><mi id="S3.E4X.3.2.2.m1.2.2">log</mi><mrow id="S3.E4X.3.2.2.m1.2.5"><mo id="S3.E4X.3.2.2.m1.2.5.1" stretchy="false">(</mo><msub id="S3.E4X.3.2.2.m1.2.5.2"><mi id="S3.E4X.3.2.2.m1.2.5.2.2">p</mi><mi id="S3.E4X.3.2.2.m1.2.5.2.3">𝜽</mi></msub><mrow id="S3.E4X.3.2.2.m1.2.5.3"><mo id="S3.E4X.3.2.2.m1.2.5.3.1" stretchy="false">(</mo><mi id="S3.E4X.3.2.2.m1.1.1">𝐱</mi><mo id="S3.E4X.3.2.2.m1.2.5.3.2" stretchy="false">)</mo></mrow><mo id="S3.E4X.3.2.2.m1.2.5.4" stretchy="false">)</mo></mrow><mo id="S3.E4X.3.2.2.m1.2.6">+</mo><msub id="S3.E4X.3.2.2.m1.2.7"><mi class="ltx_font_mathcaligraphic" id="S3.E4X.3.2.2.m1.2.7.2">𝒟</mi><mtext id="S3.E4X.3.2.2.m1.2.7.3">KL</mtext></msub><mrow id="S3.E4X.3.2.2.m1.2.8"><mo id="S3.E4X.3.2.2.m1.2.8.1" stretchy="false">(</mo><msub id="S3.E4X.3.2.2.m1.2.8.2"><mi id="S3.E4X.3.2.2.m1.2.8.2.2">q</mi><mi class="ltx_mathvariant_bold-italic" id="S3.E4X.3.2.2.m1.2.8.2.3" mathvariant="bold-italic">ϕ</mi></msub><mrow id="S3.E4X.3.2.2.m1.2.8.3"><mo id="S3.E4X.3.2.2.m1.2.8.3.1" stretchy="false">(</mo><mi id="S3.E4X.3.2.2.m1.2.8.3.2">𝐳</mi><mo fence="false" id="S3.E4X.3.2.2.m1.2.8.3.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E4X.3.2.2.m1.2.8.3.4">𝐱</mi><mo id="S3.E4X.3.2.2.m1.2.8.3.5" stretchy="false">)</mo></mrow><mo fence="false" id="S3.E4X.3.2.2.m1.2.8.4" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S3.E4X.3.2.2.m1.2.8.5" rspace="0.167em" stretchy="false">|</mo><msub id="S3.E4X.3.2.2.m1.2.8.6"><mi id="S3.E4X.3.2.2.m1.2.8.6.2">p</mi><mi id="S3.E4X.3.2.2.m1.2.8.6.3">𝜽</mi></msub><mrow id="S3.E4X.3.2.2.m1.2.8.7"><mo id="S3.E4X.3.2.2.m1.2.8.7.1" stretchy="false">(</mo><mi id="S3.E4X.3.2.2.m1.2.8.7.2">𝐳</mi><mo fence="false" id="S3.E4X.3.2.2.m1.2.8.7.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E4X.3.2.2.m1.2.8.7.4">𝐱</mi><mo id="S3.E4X.3.2.2.m1.2.8.7.5" stretchy="false">)</mo></mrow><mo id="S3.E4X.3.2.2.m1.2.8.8" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E4X.3.2.2.m1.2c">\displaystyle=-\log(p_{\bm{\theta}}(\mathbf{x}))+\mathcal{D}_{\text{KL}}(q_{%
\bm{\phi}}(\mathbf{z}|\mathbf{x})||p_{\bm{\theta}}(\mathbf{z}|\mathbf{x}))</annotation><annotation encoding="application/x-llamapun" id="S3.E4X.3.2.2.m1.2d">= - roman_log ( italic_p start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_x ) ) + caligraphic_D start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT bold_italic_ϕ end_POSTSUBSCRIPT ( bold_z | bold_x ) | | italic_p start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_z | bold_x ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="2"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E4Xa">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=-\mathbb{E}_{\mathbf{z}\sim q_{\bm{\phi}}(\mathbf{z}|\mathbf{x})%
}\left[\log(p_{\bm{\theta}}(\mathbf{x}|\mathbf{z}))\right]+\mathcal{D}_{\text{%
KL}}(q_{\bm{\phi}}(\mathbf{z}|\mathbf{x})||p_{\bm{\theta}}(\mathbf{z}))" class="ltx_math_unparsed" display="inline" id="S3.E4Xa.2.1.1.m1.3"><semantics id="S3.E4Xa.2.1.1.m1.3a"><mrow id="S3.E4Xa.2.1.1.m1.3b"><mo id="S3.E4Xa.2.1.1.m1.3.4" rspace="0em">=</mo><mo id="S3.E4Xa.2.1.1.m1.3.5" lspace="0em">−</mo><msub id="S3.E4Xa.2.1.1.m1.3.6"><mi id="S3.E4Xa.2.1.1.m1.3.6.2">𝔼</mi><mrow id="S3.E4Xa.2.1.1.m1.1.1.1"><mi id="S3.E4Xa.2.1.1.m1.1.1.1.3">𝐳</mi><mo id="S3.E4Xa.2.1.1.m1.1.1.1.2">∼</mo><mrow id="S3.E4Xa.2.1.1.m1.1.1.1.1"><msub id="S3.E4Xa.2.1.1.m1.1.1.1.1.3"><mi id="S3.E4Xa.2.1.1.m1.1.1.1.1.3.2">q</mi><mi class="ltx_mathvariant_bold-italic" id="S3.E4Xa.2.1.1.m1.1.1.1.1.3.3" mathvariant="bold-italic">ϕ</mi></msub><mo id="S3.E4Xa.2.1.1.m1.1.1.1.1.2">⁢</mo><mrow id="S3.E4Xa.2.1.1.m1.1.1.1.1.1.1"><mo id="S3.E4Xa.2.1.1.m1.1.1.1.1.1.1.2" stretchy="false">(</mo><mrow id="S3.E4Xa.2.1.1.m1.1.1.1.1.1.1.1"><mi id="S3.E4Xa.2.1.1.m1.1.1.1.1.1.1.1.2">𝐳</mi><mo fence="false" id="S3.E4Xa.2.1.1.m1.1.1.1.1.1.1.1.1">|</mo><mi id="S3.E4Xa.2.1.1.m1.1.1.1.1.1.1.1.3">𝐱</mi></mrow><mo id="S3.E4Xa.2.1.1.m1.1.1.1.1.1.1.3" stretchy="false">)</mo></mrow></mrow></mrow></msub><mrow id="S3.E4Xa.2.1.1.m1.3.7"><mo id="S3.E4Xa.2.1.1.m1.3.7.1">[</mo><mi id="S3.E4Xa.2.1.1.m1.2.2">log</mi><mrow id="S3.E4Xa.2.1.1.m1.3.7.2"><mo id="S3.E4Xa.2.1.1.m1.3.7.2.1" stretchy="false">(</mo><msub id="S3.E4Xa.2.1.1.m1.3.7.2.2"><mi id="S3.E4Xa.2.1.1.m1.3.7.2.2.2">p</mi><mi id="S3.E4Xa.2.1.1.m1.3.7.2.2.3">𝜽</mi></msub><mrow id="S3.E4Xa.2.1.1.m1.3.7.2.3"><mo id="S3.E4Xa.2.1.1.m1.3.7.2.3.1" stretchy="false">(</mo><mi id="S3.E4Xa.2.1.1.m1.3.7.2.3.2">𝐱</mi><mo fence="false" id="S3.E4Xa.2.1.1.m1.3.7.2.3.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E4Xa.2.1.1.m1.3.7.2.3.4">𝐳</mi><mo id="S3.E4Xa.2.1.1.m1.3.7.2.3.5" stretchy="false">)</mo></mrow><mo id="S3.E4Xa.2.1.1.m1.3.7.2.4" stretchy="false">)</mo></mrow><mo id="S3.E4Xa.2.1.1.m1.3.7.3">]</mo></mrow><mo id="S3.E4Xa.2.1.1.m1.3.8">+</mo><msub id="S3.E4Xa.2.1.1.m1.3.9"><mi class="ltx_font_mathcaligraphic" id="S3.E4Xa.2.1.1.m1.3.9.2">𝒟</mi><mtext id="S3.E4Xa.2.1.1.m1.3.9.3">KL</mtext></msub><mrow id="S3.E4Xa.2.1.1.m1.3.10"><mo id="S3.E4Xa.2.1.1.m1.3.10.1" stretchy="false">(</mo><msub id="S3.E4Xa.2.1.1.m1.3.10.2"><mi id="S3.E4Xa.2.1.1.m1.3.10.2.2">q</mi><mi class="ltx_mathvariant_bold-italic" id="S3.E4Xa.2.1.1.m1.3.10.2.3" mathvariant="bold-italic">ϕ</mi></msub><mrow id="S3.E4Xa.2.1.1.m1.3.10.3"><mo id="S3.E4Xa.2.1.1.m1.3.10.3.1" stretchy="false">(</mo><mi id="S3.E4Xa.2.1.1.m1.3.10.3.2">𝐳</mi><mo fence="false" id="S3.E4Xa.2.1.1.m1.3.10.3.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E4Xa.2.1.1.m1.3.10.3.4">𝐱</mi><mo id="S3.E4Xa.2.1.1.m1.3.10.3.5" stretchy="false">)</mo></mrow><mo fence="false" id="S3.E4Xa.2.1.1.m1.3.10.4" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S3.E4Xa.2.1.1.m1.3.10.5" rspace="0.167em" stretchy="false">|</mo><msub id="S3.E4Xa.2.1.1.m1.3.10.6"><mi id="S3.E4Xa.2.1.1.m1.3.10.6.2">p</mi><mi id="S3.E4Xa.2.1.1.m1.3.10.6.3">𝜽</mi></msub><mrow id="S3.E4Xa.2.1.1.m1.3.10.7"><mo id="S3.E4Xa.2.1.1.m1.3.10.7.1" stretchy="false">(</mo><mi id="S3.E4Xa.2.1.1.m1.3.3">𝐳</mi><mo id="S3.E4Xa.2.1.1.m1.3.10.7.2" stretchy="false">)</mo></mrow><mo id="S3.E4Xa.2.1.1.m1.3.10.8" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E4Xa.2.1.1.m1.3c">\displaystyle=-\mathbb{E}_{\mathbf{z}\sim q_{\bm{\phi}}(\mathbf{z}|\mathbf{x})%
}\left[\log(p_{\bm{\theta}}(\mathbf{x}|\mathbf{z}))\right]+\mathcal{D}_{\text{%
KL}}(q_{\bm{\phi}}(\mathbf{z}|\mathbf{x})||p_{\bm{\theta}}(\mathbf{z}))</annotation><annotation encoding="application/x-llamapun" id="S3.E4Xa.2.1.1.m1.3d">= - blackboard_E start_POSTSUBSCRIPT bold_z ∼ italic_q start_POSTSUBSCRIPT bold_italic_ϕ end_POSTSUBSCRIPT ( bold_z | bold_x ) end_POSTSUBSCRIPT [ roman_log ( italic_p start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_x | bold_z ) ) ] + caligraphic_D start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT bold_italic_ϕ end_POSTSUBSCRIPT ( bold_z | bold_x ) | | italic_p start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_z ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.14">Here, the approximation of the encoder is denoted by <math alttext="q_{\bm{\phi}}(\mathbf{z}|\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS2.p3.11.m1.1"><semantics id="S3.SS2.p3.11.m1.1a"><mrow id="S3.SS2.p3.11.m1.1.1" xref="S3.SS2.p3.11.m1.1.1.cmml"><msub id="S3.SS2.p3.11.m1.1.1.3" xref="S3.SS2.p3.11.m1.1.1.3.cmml"><mi id="S3.SS2.p3.11.m1.1.1.3.2" xref="S3.SS2.p3.11.m1.1.1.3.2.cmml">q</mi><mi class="ltx_mathvariant_bold-italic" id="S3.SS2.p3.11.m1.1.1.3.3" mathvariant="bold-italic" xref="S3.SS2.p3.11.m1.1.1.3.3.cmml">ϕ</mi></msub><mo id="S3.SS2.p3.11.m1.1.1.2" xref="S3.SS2.p3.11.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.11.m1.1.1.1.1" xref="S3.SS2.p3.11.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.11.m1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.11.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.11.m1.1.1.1.1.1" xref="S3.SS2.p3.11.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.11.m1.1.1.1.1.1.2" xref="S3.SS2.p3.11.m1.1.1.1.1.1.2.cmml">𝐳</mi><mo fence="false" id="S3.SS2.p3.11.m1.1.1.1.1.1.1" xref="S3.SS2.p3.11.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.11.m1.1.1.1.1.1.3" xref="S3.SS2.p3.11.m1.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S3.SS2.p3.11.m1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.11.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m1.1b"><apply id="S3.SS2.p3.11.m1.1.1.cmml" xref="S3.SS2.p3.11.m1.1.1"><times id="S3.SS2.p3.11.m1.1.1.2.cmml" xref="S3.SS2.p3.11.m1.1.1.2"></times><apply id="S3.SS2.p3.11.m1.1.1.3.cmml" xref="S3.SS2.p3.11.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.11.m1.1.1.3.1.cmml" xref="S3.SS2.p3.11.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.11.m1.1.1.3.2.cmml" xref="S3.SS2.p3.11.m1.1.1.3.2">𝑞</ci><ci id="S3.SS2.p3.11.m1.1.1.3.3.cmml" xref="S3.SS2.p3.11.m1.1.1.3.3">bold-italic-ϕ</ci></apply><apply id="S3.SS2.p3.11.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.11.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.11.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.11.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.11.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.11.m1.1.1.1.1.1.2">𝐳</ci><ci id="S3.SS2.p3.11.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.11.m1.1.1.1.1.1.3">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m1.1c">q_{\bm{\phi}}(\mathbf{z}|\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.11.m1.1d">italic_q start_POSTSUBSCRIPT bold_italic_ϕ end_POSTSUBSCRIPT ( bold_z | bold_x )</annotation></semantics></math>, and the decoder as <math alttext="p_{\bm{\theta}}(\mathbf{x}|\mathbf{z})" class="ltx_Math" display="inline" id="S3.SS2.p3.12.m2.1"><semantics id="S3.SS2.p3.12.m2.1a"><mrow id="S3.SS2.p3.12.m2.1.1" xref="S3.SS2.p3.12.m2.1.1.cmml"><msub id="S3.SS2.p3.12.m2.1.1.3" xref="S3.SS2.p3.12.m2.1.1.3.cmml"><mi id="S3.SS2.p3.12.m2.1.1.3.2" xref="S3.SS2.p3.12.m2.1.1.3.2.cmml">p</mi><mi id="S3.SS2.p3.12.m2.1.1.3.3" xref="S3.SS2.p3.12.m2.1.1.3.3.cmml">𝜽</mi></msub><mo id="S3.SS2.p3.12.m2.1.1.2" xref="S3.SS2.p3.12.m2.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.12.m2.1.1.1.1" xref="S3.SS2.p3.12.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.12.m2.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.12.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.12.m2.1.1.1.1.1" xref="S3.SS2.p3.12.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.12.m2.1.1.1.1.1.2" xref="S3.SS2.p3.12.m2.1.1.1.1.1.2.cmml">𝐱</mi><mo fence="false" id="S3.SS2.p3.12.m2.1.1.1.1.1.1" xref="S3.SS2.p3.12.m2.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p3.12.m2.1.1.1.1.1.3" xref="S3.SS2.p3.12.m2.1.1.1.1.1.3.cmml">𝐳</mi></mrow><mo id="S3.SS2.p3.12.m2.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.12.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m2.1b"><apply id="S3.SS2.p3.12.m2.1.1.cmml" xref="S3.SS2.p3.12.m2.1.1"><times id="S3.SS2.p3.12.m2.1.1.2.cmml" xref="S3.SS2.p3.12.m2.1.1.2"></times><apply id="S3.SS2.p3.12.m2.1.1.3.cmml" xref="S3.SS2.p3.12.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.12.m2.1.1.3.1.cmml" xref="S3.SS2.p3.12.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.12.m2.1.1.3.2.cmml" xref="S3.SS2.p3.12.m2.1.1.3.2">𝑝</ci><ci id="S3.SS2.p3.12.m2.1.1.3.3.cmml" xref="S3.SS2.p3.12.m2.1.1.3.3">𝜽</ci></apply><apply id="S3.SS2.p3.12.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.12.m2.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.12.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.12.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p3.12.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.12.m2.1.1.1.1.1.2">𝐱</ci><ci id="S3.SS2.p3.12.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.12.m2.1.1.1.1.1.3">𝐳</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m2.1c">p_{\bm{\theta}}(\mathbf{x}|\mathbf{z})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.12.m2.1d">italic_p start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_x | bold_z )</annotation></semantics></math>. The parameters <math alttext="\bm{\phi}" class="ltx_Math" display="inline" id="S3.SS2.p3.13.m3.1"><semantics id="S3.SS2.p3.13.m3.1a"><mi class="ltx_mathvariant_bold-italic" id="S3.SS2.p3.13.m3.1.1" mathvariant="bold-italic" xref="S3.SS2.p3.13.m3.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m3.1b"><ci id="S3.SS2.p3.13.m3.1.1.cmml" xref="S3.SS2.p3.13.m3.1.1">bold-italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m3.1c">\bm{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.13.m3.1d">bold_italic_ϕ</annotation></semantics></math> and <math alttext="\bm{\theta}" class="ltx_Math" display="inline" id="S3.SS2.p3.14.m4.1"><semantics id="S3.SS2.p3.14.m4.1a"><mi id="S3.SS2.p3.14.m4.1.1" xref="S3.SS2.p3.14.m4.1.1.cmml">𝜽</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.14.m4.1b"><ci id="S3.SS2.p3.14.m4.1.1.cmml" xref="S3.SS2.p3.14.m4.1.1">𝜽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.14.m4.1c">\bm{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.14.m4.1d">bold_italic_θ</annotation></semantics></math> represent the variational and generative parameters that undergo optimization during the training of the VAEs model.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">The loss function in Equation (<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3.E4" title="In 3.2 VAEs and CVAEs ‣ 3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">4</span></a>) does not incorporate conditions, hence it is used to train the VAEs model. The CVAE’s loss function can be constructed by conditioning the VAEs loss function on the conditions <math alttext="\mathbf{c}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathbf{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">bold_c</annotation></semantics></math> as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\mathcal{L}(\bm{\theta},\bm{\phi})=-\mathbb{E}_{\mathbf{z}\sim q_{\bm{\phi}}(%
\mathbf{z}|\mathbf{x},\mathbf{c})}\left[\log(p_{\bm{\theta}}(\mathbf{x}|%
\mathbf{z},\mathbf{c}))\right]+\mathcal{D}_{\text{KL}}(q_{\bm{\phi}}(\mathbf{z%
}|\mathbf{x},\mathbf{c})||p_{\bm{\theta}}(\mathbf{z}|\mathbf{c}))" class="ltx_math_unparsed" display="block" id="S3.E5.m1.10"><semantics id="S3.E5.m1.10a"><mrow id="S3.E5.m1.10b"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.10.11">ℒ</mi><mrow id="S3.E5.m1.10.12"><mo id="S3.E5.m1.10.12.1" stretchy="false">(</mo><mi id="S3.E5.m1.4.4">𝜽</mi><mo id="S3.E5.m1.10.12.2">,</mo><mi class="ltx_mathvariant_bold-italic" id="S3.E5.m1.5.5" mathvariant="bold-italic">ϕ</mi><mo id="S3.E5.m1.10.12.3" stretchy="false">)</mo></mrow><mo id="S3.E5.m1.10.13" rspace="0em">=</mo><mo id="S3.E5.m1.10.14" lspace="0em">−</mo><msub id="S3.E5.m1.10.15"><mi id="S3.E5.m1.10.15.2">𝔼</mi><mrow id="S3.E5.m1.3.3.3"><mi id="S3.E5.m1.3.3.3.5">𝐳</mi><mo id="S3.E5.m1.3.3.3.4">∼</mo><mrow id="S3.E5.m1.3.3.3.3"><msub id="S3.E5.m1.3.3.3.3.3"><mi id="S3.E5.m1.3.3.3.3.3.2">q</mi><mi class="ltx_mathvariant_bold-italic" id="S3.E5.m1.3.3.3.3.3.3" mathvariant="bold-italic">ϕ</mi></msub><mo id="S3.E5.m1.3.3.3.3.2">⁢</mo><mrow id="S3.E5.m1.3.3.3.3.1.1"><mo id="S3.E5.m1.3.3.3.3.1.1.2" stretchy="false">(</mo><mrow id="S3.E5.m1.3.3.3.3.1.1.1"><mi id="S3.E5.m1.3.3.3.3.1.1.1.2">𝐳</mi><mo fence="false" id="S3.E5.m1.3.3.3.3.1.1.1.1">|</mo><mrow id="S3.E5.m1.3.3.3.3.1.1.1.3.2"><mi id="S3.E5.m1.1.1.1.1">𝐱</mi><mo id="S3.E5.m1.3.3.3.3.1.1.1.3.2.1">,</mo><mi id="S3.E5.m1.2.2.2.2">𝐜</mi></mrow></mrow><mo id="S3.E5.m1.3.3.3.3.1.1.3" stretchy="false">)</mo></mrow></mrow></mrow></msub><mrow id="S3.E5.m1.10.16"><mo id="S3.E5.m1.10.16.1">[</mo><mi id="S3.E5.m1.8.8">log</mi><mrow id="S3.E5.m1.10.16.2"><mo id="S3.E5.m1.10.16.2.1" stretchy="false">(</mo><msub id="S3.E5.m1.10.16.2.2"><mi id="S3.E5.m1.10.16.2.2.2">p</mi><mi id="S3.E5.m1.10.16.2.2.3">𝜽</mi></msub><mrow id="S3.E5.m1.10.16.2.3"><mo id="S3.E5.m1.10.16.2.3.1" stretchy="false">(</mo><mi id="S3.E5.m1.10.16.2.3.2">𝐱</mi><mo fence="false" id="S3.E5.m1.10.16.2.3.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E5.m1.6.6">𝐳</mi><mo id="S3.E5.m1.10.16.2.3.4">,</mo><mi id="S3.E5.m1.7.7">𝐜</mi><mo id="S3.E5.m1.10.16.2.3.5" stretchy="false">)</mo></mrow><mo id="S3.E5.m1.10.16.2.4" stretchy="false">)</mo></mrow><mo id="S3.E5.m1.10.16.3">]</mo></mrow><mo id="S3.E5.m1.10.17">+</mo><msub id="S3.E5.m1.10.18"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.10.18.2">𝒟</mi><mtext id="S3.E5.m1.10.18.3">KL</mtext></msub><mrow id="S3.E5.m1.10.19"><mo id="S3.E5.m1.10.19.1" stretchy="false">(</mo><msub id="S3.E5.m1.10.19.2"><mi id="S3.E5.m1.10.19.2.2">q</mi><mi class="ltx_mathvariant_bold-italic" id="S3.E5.m1.10.19.2.3" mathvariant="bold-italic">ϕ</mi></msub><mrow id="S3.E5.m1.10.19.3"><mo id="S3.E5.m1.10.19.3.1" stretchy="false">(</mo><mi id="S3.E5.m1.10.19.3.2">𝐳</mi><mo fence="false" id="S3.E5.m1.10.19.3.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E5.m1.9.9">𝐱</mi><mo id="S3.E5.m1.10.19.3.4">,</mo><mi id="S3.E5.m1.10.10">𝐜</mi><mo id="S3.E5.m1.10.19.3.5" stretchy="false">)</mo></mrow><mo fence="false" id="S3.E5.m1.10.19.4" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S3.E5.m1.10.19.5" rspace="0.167em" stretchy="false">|</mo><msub id="S3.E5.m1.10.19.6"><mi id="S3.E5.m1.10.19.6.2">p</mi><mi id="S3.E5.m1.10.19.6.3">𝜽</mi></msub><mrow id="S3.E5.m1.10.19.7"><mo id="S3.E5.m1.10.19.7.1" stretchy="false">(</mo><mi id="S3.E5.m1.10.19.7.2">𝐳</mi><mo fence="false" id="S3.E5.m1.10.19.7.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E5.m1.10.19.7.4">𝐜</mi><mo id="S3.E5.m1.10.19.7.5" stretchy="false">)</mo></mrow><mo id="S3.E5.m1.10.19.8" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E5.m1.10c">\mathcal{L}(\bm{\theta},\bm{\phi})=-\mathbb{E}_{\mathbf{z}\sim q_{\bm{\phi}}(%
\mathbf{z}|\mathbf{x},\mathbf{c})}\left[\log(p_{\bm{\theta}}(\mathbf{x}|%
\mathbf{z},\mathbf{c}))\right]+\mathcal{D}_{\text{KL}}(q_{\bm{\phi}}(\mathbf{z%
}|\mathbf{x},\mathbf{c})||p_{\bm{\theta}}(\mathbf{z}|\mathbf{c}))</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.10d">caligraphic_L ( bold_italic_θ , bold_italic_ϕ ) = - blackboard_E start_POSTSUBSCRIPT bold_z ∼ italic_q start_POSTSUBSCRIPT bold_italic_ϕ end_POSTSUBSCRIPT ( bold_z | bold_x , bold_c ) end_POSTSUBSCRIPT [ roman_log ( italic_p start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_x | bold_z , bold_c ) ) ] + caligraphic_D start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT bold_italic_ϕ end_POSTSUBSCRIPT ( bold_z | bold_x , bold_c ) | | italic_p start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_z | bold_c ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">Here, the KL divergence term is called the regularization term, which ensures that the learned distributions closely match the assumed Gaussian prior. The expectation term represents the reconstruction loss, which encourages the decoder to learn to reconstruct the data. Minimizing the loss function is equivalent to maximizing the lower bound of the probability of generating real data samples.</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1">Generating new samples using CVAEs is done by passing a random vector from the latent space along with specified conditions to the decoder. This process yields different outputs, even when provided with the same conditions vector. This is due to the variability in the latent space inputs. The resulting variability can be used to estimate uncertainties in the model’s predictions at any specific conditions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib30" title="">30</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>The Generative and Predictive ML Models</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This work will make use of two ML models: a CVAE generative model and a DNN predictive model. In brief, the CVAE generative model tries to learn the underlying distribution of the NRC CHF dataset in order to generate synthetic samples at specific TH conditions. The DNN predictive model tries to learn the mapping between the inputs (TH conditions) and the output (CHF value) from the NRC CHF dataset in the format of regression. Once trained, the DNN model can also be evaluated at specific TH conditions, producing the corresponding CHF values. Their major differences can be summarized as: the CVAE model learns the underlying probabilistic distribution of the training dataset in an unsupervised way, while the DNN model constructs a black-box surrogate model of the training dataset without considering the data distribution in a supervised way.
If both models are good enough, the generated and predicted CHF values at the targeted TH conditions should be close to the real experimental data. In this section, we will present the details of the model architectures, as well as explain how to use UQ and domain generalization to compare the performance of these two ML models.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>The CVAE Generative Model</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.8">The CVAE generative model will be used to approximate the underlying distribution of the NRC CHF dataset to generate new CHF values under specific TH conditions. The vector of TH conditions consists of seven parameters: <math alttext="P" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_P</annotation></semantics></math>, <math alttext="G" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">G</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_G</annotation></semantics></math>, <math alttext="T_{\text{in}}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">T</mi><mtext id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝑇</ci><ci id="S4.SS1.p1.3.m3.1.1.3a.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><mtext id="S4.SS1.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S4.SS1.p1.3.m3.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">T_{\text{in}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_T start_POSTSUBSCRIPT in end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="D" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><mi id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">D</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_D</annotation></semantics></math>, <math alttext="L" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_L</annotation></semantics></math>, <math alttext="X" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><mi id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><ci id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">X</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">italic_X</annotation></semantics></math>, and <math alttext="\Delta h_{\text{in}}" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1"><semantics id="S4.SS1.p1.7.m7.1a"><mrow id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml"><mi id="S4.SS1.p1.7.m7.1.1.2" mathvariant="normal" xref="S4.SS1.p1.7.m7.1.1.2.cmml">Δ</mi><mo id="S4.SS1.p1.7.m7.1.1.1" xref="S4.SS1.p1.7.m7.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml"><mi id="S4.SS1.p1.7.m7.1.1.3.2" xref="S4.SS1.p1.7.m7.1.1.3.2.cmml">h</mi><mtext id="S4.SS1.p1.7.m7.1.1.3.3" xref="S4.SS1.p1.7.m7.1.1.3.3a.cmml">in</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1"><times id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1.1"></times><ci id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2">Δ</ci><apply id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.3.1.cmml" xref="S4.SS1.p1.7.m7.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.3.2.cmml" xref="S4.SS1.p1.7.m7.1.1.3.2">ℎ</ci><ci id="S4.SS1.p1.7.m7.1.1.3.3a.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3"><mtext id="S4.SS1.p1.7.m7.1.1.3.3.cmml" mathsize="70%" xref="S4.SS1.p1.7.m7.1.1.3.3">in</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">\Delta h_{\text{in}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">roman_Δ italic_h start_POSTSUBSCRIPT in end_POSTSUBSCRIPT</annotation></semantics></math>, as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S2" title="2 The CHF Experimental Dataset ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>. During the training process, these seven parameters were provided to the model as conditions, that is, the vector <math alttext="\mathbf{c}" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.1"><semantics id="S4.SS1.p1.8.m8.1a"><mi id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><ci id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">\mathbf{c}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m8.1d">bold_c</annotation></semantics></math> in Equation (<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3.E5" title="In 3.2 VAEs and CVAEs ‣ 3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">5</span></a>) and Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S3.F2" title="Figure 2 ‣ 3.2 VAEs and CVAEs ‣ 3 Methodologies ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>, allowing it to learn how to generate CHF values under user desired conditions.
If a conventional VAE generative model were to be trained, one would not condition the model on the vector of TH parameters. In this case, the trained VAE model can only generate synthetic samples randomly, making it difficult to evaluate its performance by comparing with the real experimental data, since it is almost impossible for the random samples to have TH conditions that exactly match the real experimental data.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">The model architecture was optimized by performing hyperparameter tuning for 400 iterations. Both the encoder and decoder networks were constructed with four fully connected layers. Training was conducted over around 230 epochs with a batch size of 76. Prior to training, the data underwent shuffling and standardization. The model was trained on 80% of the NRC CHF dataset, while the remaining 20% was reserved for the testing and validation, where the validation set was used for hyperparameter tuning. TensorFlow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib31" title="">31</a>]</cite> was used to build the CVAE model. Once the model was trained, the decoder was used to generate CHF values under specific TH conditions in the testing dataset. Subsequently, the generated CHF values were compared with the corresponding experimental CHF values in the testing dataset to evaluate their accuracy.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>The DNN Predictive Model</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.4">The DNN predictive model was also constructed in TensorFlow using eight hidden layers to transform the <math alttext="7" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn id="S4.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">7</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">7</annotation></semantics></math> input parameters listed in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4.SS1" title="4.1 The CVAE Generative Model ‣ 4 The Generative and Predictive ML Models ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">4.1</span></a>. The network depth, number of neurons per layer, activation functions, and learning rate were optimized using RayTune <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib32" title="">32</a>]</cite> using <math alttext="1000" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn id="S4.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">1000</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">1000</annotation></semantics></math> hyperparameter configurations in a random search. This tuning process was performed using the validation partition of the dataset. The training, validation, and testing datasets used between the CVAE and DNN were identical to ensure an accurate and fair comparison between the two methods. Once the hyperparameters were set, the model was trained for a total of <math alttext="500" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><cn id="S4.SS2.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS2.p1.3.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">500</annotation></semantics></math> epochs with an exponential learning decay rate of <math alttext="0.96" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mn id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">0.96</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><cn id="S4.SS2.p1.4.m4.1.1.cmml" type="float" xref="S4.SS2.p1.4.m4.1.1">0.96</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">0.96</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">0.96</annotation></semantics></math>. The fully trained network was then evaluated against the testing set using the set of metrics provided in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5" title="5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">5</span></a>. The DNN model is much more straightforward to train since it only builds a black-box surrogate model of the training dataset without considering the data distribution. Our goal is to use such a fine tuned DNN model to “benchmark” the performance of the CVAE generative model using a comprehensive collection of metrics presented in the following sections.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>UQ of the ML Models</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">DNN models are often referred to as being “black box” due to their lack of interpretability as the dimensionality of the problem increases. In critical applications, such as safety analysis in a nuclear setting, it is imperative to quantify the level of uncertainty in a model’s predictions to verify its trustworthiness. One such method commonly applied in DNN approaches is known as ensembling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib33" title="">33</a>]</cite>, which relies on the idea that the consensus of several slightly-different networks will yield more reliable predictions than a single model. The multiple unique outputs per input set of an ensemble also allows for their treatment as a distribution, which can be assessed using traditional statistics such as standard deviation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib34" title="">34</a>]</cite>. One of the simplest methods, albeit computationally intensive, to accomplish this is in the perturbation of the model’s initializations.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The initialization of the weights and biases of a model, typically chosen at random, can significantly change its behavior. A given initialization will place the model at a specific starting point in the parameter space. The optimization process will then minimize the loss/objective function, potentially converging to a local minimum rather than a global minimum. This often leads to different weight configurations, which then leads to different outputs when comparing identical models with different initializations. This concept forms the basis of the initialization-based ensemble approach, where the random seeds are modified to produce slightly different models which produce slightly different outputs during testing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#bib.bib35" title="">35</a>]</cite>. To implement this strategy, a total of 20 otherwise identical DNNs were trained, with different initialization random seeds, and their test outputs were collected. For each of the input entries in the testing set, there were now 20 unique CHF predictions, the mean and standard deviation of which were taken to obtain an estimation of the CHF prediction and its associated uncertainty.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.4">Quantifying uncertainties in the generated samples by the CVAE model was done by utilizing the inherent variability in the generation process. Recall that the latent space in the CVAE model consists of two vectors that represent the mean value and standard deviation of the encoded distribution, which is usually assumed to be Gaussian.
We first obtained 200 samples from the latent space distribution. Each of the latent vector samples is then combined with an input TH condition vector (the conditioning vector <math alttext="\mathbf{c}" class="ltx_Math" display="inline" id="S4.SS3.p3.1.m1.1"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">\mathbf{c}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.1.m1.1d">bold_c</annotation></semantics></math>). The combined vector will be fed into the decoder to produce a CHF value. A different CHF value will be generated each time the decoder takes the same TH condition but different latent vector. This process was repeated for all TH conditions in the testing dataset. Afterwards, the mean <math alttext="\mu_{\text{samples}}" class="ltx_Math" display="inline" id="S4.SS3.p3.2.m2.1"><semantics id="S4.SS3.p3.2.m2.1a"><msub id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mi id="S4.SS3.p3.2.m2.1.1.2" xref="S4.SS3.p3.2.m2.1.1.2.cmml">μ</mi><mtext id="S4.SS3.p3.2.m2.1.1.3" xref="S4.SS3.p3.2.m2.1.1.3a.cmml">samples</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p3.2.m2.1.1.2.cmml" xref="S4.SS3.p3.2.m2.1.1.2">𝜇</ci><ci id="S4.SS3.p3.2.m2.1.1.3a.cmml" xref="S4.SS3.p3.2.m2.1.1.3"><mtext id="S4.SS3.p3.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.SS3.p3.2.m2.1.1.3">samples</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">\mu_{\text{samples}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.2.m2.1d">italic_μ start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT</annotation></semantics></math> and standard deviation <math alttext="\sigma_{\text{samples}}" class="ltx_Math" display="inline" id="S4.SS3.p3.3.m3.1"><semantics id="S4.SS3.p3.3.m3.1a"><msub id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml"><mi id="S4.SS3.p3.3.m3.1.1.2" xref="S4.SS3.p3.3.m3.1.1.2.cmml">σ</mi><mtext id="S4.SS3.p3.3.m3.1.1.3" xref="S4.SS3.p3.3.m3.1.1.3a.cmml">samples</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><apply id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.3.m3.1.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p3.3.m3.1.1.2.cmml" xref="S4.SS3.p3.3.m3.1.1.2">𝜎</ci><ci id="S4.SS3.p3.3.m3.1.1.3a.cmml" xref="S4.SS3.p3.3.m3.1.1.3"><mtext id="S4.SS3.p3.3.m3.1.1.3.cmml" mathsize="70%" xref="S4.SS3.p3.3.m3.1.1.3">samples</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">\sigma_{\text{samples}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.3.m3.1d">italic_σ start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT</annotation></semantics></math> were computed among the 200 samples for each TH condition. <math alttext="\sigma_{\text{samples}}" class="ltx_Math" display="inline" id="S4.SS3.p3.4.m4.1"><semantics id="S4.SS3.p3.4.m4.1a"><msub id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml"><mi id="S4.SS3.p3.4.m4.1.1.2" xref="S4.SS3.p3.4.m4.1.1.2.cmml">σ</mi><mtext id="S4.SS3.p3.4.m4.1.1.3" xref="S4.SS3.p3.4.m4.1.1.3a.cmml">samples</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><apply id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.4.m4.1.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS3.p3.4.m4.1.1.2.cmml" xref="S4.SS3.p3.4.m4.1.1.2">𝜎</ci><ci id="S4.SS3.p3.4.m4.1.1.3a.cmml" xref="S4.SS3.p3.4.m4.1.1.3"><mtext id="S4.SS3.p3.4.m4.1.1.3.cmml" mathsize="70%" xref="S4.SS3.p3.4.m4.1.1.3">samples</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">\sigma_{\text{samples}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.4.m4.1d">italic_σ start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT</annotation></semantics></math> will be used to represent the uncertainty in the generated samples. It also indicates how sensitive the model predictions are to changes in the latent vector.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Domain Generalization</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">An important factor in ML model evaluation is assessing the model’s ability to generalize to data outside the training domain. This involved assessing how accurately can the model extrapolate to new regions with unseen data. To this end, we employed the concept of a convex hull to evaluate both the CVAE and DNN models. The convex hull is the smallest convex set that includes all points in a given dataset.
In order to determine whether the point we are predicting at is inside or outside the training domain, we first construct a convex hull based on the training dataset. Afterwards, the points in the testing dataset are classified into two categories; inside the convex hull or outside the convex hull. This is done by examining each testing data point to ascertain whether it falls within or outside the convex hull. If inside, the points are deemed to be within the domain covered by the training data; if outside, then the point is not represented in the space covered by the training data.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">In this study, our testing dataset comprises 2,458 data points (10% of the NRC CHF dataset). Of these, 1,047 points fall within the convex hull defined by the training dataset, while 1,411 points lie outside. Evaluating the two models’ performance on generated/predicted CHF values for the 1,411 points outside the convex hull allows us to assess its capability for domain generalization.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Results of CHF Generation and Prediction using CVAE and DNN</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">In this subsection, the generated CHF values using the CVAE model and the predicted CHF values using the DNN model at the TH conditions of the testing dataset will be directly compared to the true experimental CHF values. This is done by calculating the relative errors in the generated/predicted CHF values with respect to the true CHF values. Note that at this step we will not consider whether a sample in the testing dataset is inside or outside of the training domain.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.2">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F3.sf1" title="In Figure 3 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">3(a)</span></a> shows a comparison of the distributions of the relative errors from the CVAE and DNN models. Both models have most of the relative error values concentrated around zero, indicating that the models were successful in generating and predicting CHF values that closely align with the true values. The CVAE’s error distribution is observed to have a slightly smaller mean value and standard deviation. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F3.sf2" title="In Figure 3 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">3(b)</span></a> shows a direct comparison of the true CHF values with those generated by the CVAE model and those predicted by the DNN model, with a <math alttext="\pm 10\%" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mo id="S5.SS1.p2.1.m1.1.1a" xref="S5.SS1.p2.1.m1.1.1.cmml">±</mo><mrow id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml"><mn id="S5.SS1.p2.1.m1.1.1.2.2" xref="S5.SS1.p2.1.m1.1.1.2.2.cmml">10</mn><mo id="S5.SS1.p2.1.m1.1.1.2.1" xref="S5.SS1.p2.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">plus-or-minus</csymbol><apply id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2"><csymbol cd="latexml" id="S5.SS1.p2.1.m1.1.1.2.1.cmml" xref="S5.SS1.p2.1.m1.1.1.2.1">percent</csymbol><cn id="S5.SS1.p2.1.m1.1.1.2.2.cmml" type="integer" xref="S5.SS1.p2.1.m1.1.1.2.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">\pm 10\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">± 10 %</annotation></semantics></math> error bounds. The results show a strong agreement with the true CHF values, with a slight increase in deviation observed after CHF value above 6,000 <math alttext="\mathrm{kW}\text{\,}{\mathrm{m}}^{-2}" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.3"><semantics id="S5.SS1.p2.2.m2.3a"><mrow id="S5.SS1.p2.2.m2.3.3" xref="S5.SS1.p2.2.m2.3.3.cmml"><mi class="ltx_unit" id="S5.SS1.p2.2.m2.1.1.1.1.1.1" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.cmml">kW</mi><mtext id="S5.SS1.p2.2.m2.2.2.2.2.2.2" xref="S5.SS1.p2.2.m2.2.2.2.2.2.2.cmml"> </mtext><msup id="S5.SS1.p2.2.m2.3.3.3.3.3.3" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S5.SS1.p2.2.m2.3.3.3.3.3.3.2" mathvariant="normal" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.2.cmml">m</mi><mrow id="S5.SS1.p2.2.m2.3.3.3.3.3.3.3" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.cmml"><mo id="S5.SS1.p2.2.m2.3.3.3.3.3.3.3a" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.cmml">−</mo><mn id="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.2" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.3b"><apply id="S5.SS1.p2.2.m2.3.3.cmml" xref="S5.SS1.p2.2.m2.3.3"><csymbol cd="latexml" id="S5.SS1.p2.2.m2.2.2.2.2.2.2.cmml" xref="S5.SS1.p2.2.m2.2.2.2.2.2.2">times</csymbol><csymbol cd="latexml" id="S5.SS1.p2.2.m2.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1">kilowatt</csymbol><apply id="S5.SS1.p2.2.m2.3.3.3.3.3.3.cmml" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3"><power id="S5.SS1.p2.2.m2.3.3.3.3.3.3.1.cmml" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3"></power><csymbol cd="latexml" id="S5.SS1.p2.2.m2.3.3.3.3.3.3.2.cmml" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.2">meter</csymbol><apply id="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.cmml" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.3"><minus id="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.1.cmml" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.3"></minus><cn id="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.2.cmml" type="integer" xref="S5.SS1.p2.2.m2.3.3.3.3.3.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.3c">\mathrm{kW}\text{\,}{\mathrm{m}}^{-2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.3d">start_ARG roman_kW end_ARG start_ARG times end_ARG start_ARG power start_ARG roman_m end_ARG start_ARG - 2 end_ARG end_ARG</annotation></semantics></math>. It is also noticeable that there are very few points having relative errors greater than 10%.</p>
</div>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="561" id="S5.F3.sf1.g1" src="x2.png" width="781"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S5.F3.sf1.3.2" style="font-size:90%;">Relative error distribution</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="401" id="S5.F3.sf2.g1" src="extracted/5843326/figures/fig_CHF_comparison_True_vs_Predicted.png" width="592"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S5.F3.sf2.3.2" style="font-size:90%;">True vs. generated and predicted CHF values</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S5.F3.3.2" style="font-size:90%;">Performance comparison of the DNN and CVAE models.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T1" title="Table 1 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">1</span></a> includes statistical metrics calculated based on the absolute relative errors and the <math alttext="R^{2}" class="ltx_Math" display="inline" id="S5.SS1.p3.1.m1.1"><semantics id="S5.SS1.p3.1.m1.1a"><msup id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mi id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">R</mi><mn id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">𝑅</ci><cn id="S5.SS1.p3.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p3.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> metric for both models. It provides the mean, maximum, and standard deviations of the absolute relative error values, along with the fraction of testing points resulting in an absolute relative error value greater than 10%. The statistical metrics show that both models were able to predict CHF values accurately, with mean absolute relative error values of 1.4907% for the CVAE model and 1.8473% for the DNN model. The maximum error values were significantly higher than the mean values, however, it is reassuring to note that only 1.34% of the points in the testing data resulted in an absolute relative error greater than 10% for the DNN model compared to 0.56% for the CVAE model.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T1.7.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S5.T1.8.2" style="font-size:90%;">Statistical metrics for the absolute relative errors.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T1.5.6.1.1">Metric</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.5.6.1.2">DNN</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.5.6.1.3">CVAE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.1.1.1"><math alttext="\mu_{\text{error}}" class="ltx_Math" display="inline" id="S5.T1.1.1.1.m1.1"><semantics id="S5.T1.1.1.1.m1.1a"><msub id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml"><mi id="S5.T1.1.1.1.m1.1.1.2" xref="S5.T1.1.1.1.m1.1.1.2.cmml">μ</mi><mtext id="S5.T1.1.1.1.m1.1.1.3" xref="S5.T1.1.1.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><apply id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.1.1.1.m1.1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T1.1.1.1.m1.1.1.2.cmml" xref="S5.T1.1.1.1.m1.1.1.2">𝜇</ci><ci id="S5.T1.1.1.1.m1.1.1.3a.cmml" xref="S5.T1.1.1.1.m1.1.1.3"><mtext id="S5.T1.1.1.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T1.1.1.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">\mu_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.1.1.1.m1.1d">italic_μ start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.2">1.8473 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.3">1.4907 %</td>
</tr>
<tr class="ltx_tr" id="S5.T1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.2.2.1"><math alttext="\text{Max}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T1.2.2.1.m1.1"><semantics id="S5.T1.2.2.1.m1.1a"><msub id="S5.T1.2.2.1.m1.1.1" xref="S5.T1.2.2.1.m1.1.1.cmml"><mtext id="S5.T1.2.2.1.m1.1.1.2" xref="S5.T1.2.2.1.m1.1.1.2a.cmml">Max</mtext><mtext id="S5.T1.2.2.1.m1.1.1.3" xref="S5.T1.2.2.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.1.m1.1b"><apply id="S5.T1.2.2.1.m1.1.1.cmml" xref="S5.T1.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.2.2.1.m1.1.1.1.cmml" xref="S5.T1.2.2.1.m1.1.1">subscript</csymbol><ci id="S5.T1.2.2.1.m1.1.1.2a.cmml" xref="S5.T1.2.2.1.m1.1.1.2"><mtext id="S5.T1.2.2.1.m1.1.1.2.cmml" xref="S5.T1.2.2.1.m1.1.1.2">Max</mtext></ci><ci id="S5.T1.2.2.1.m1.1.1.3a.cmml" xref="S5.T1.2.2.1.m1.1.1.3"><mtext id="S5.T1.2.2.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T1.2.2.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.1.m1.1c">\text{Max}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.2.2.1.m1.1d">Max start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.2.2.2">31.056 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.2.2.3">24.962 %</td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.3.3.1"><math alttext="\text{Std}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T1.3.3.1.m1.1"><semantics id="S5.T1.3.3.1.m1.1a"><msub id="S5.T1.3.3.1.m1.1.1" xref="S5.T1.3.3.1.m1.1.1.cmml"><mtext id="S5.T1.3.3.1.m1.1.1.2" xref="S5.T1.3.3.1.m1.1.1.2a.cmml">Std</mtext><mtext id="S5.T1.3.3.1.m1.1.1.3" xref="S5.T1.3.3.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.1.m1.1b"><apply id="S5.T1.3.3.1.m1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.3.3.1.m1.1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1">subscript</csymbol><ci id="S5.T1.3.3.1.m1.1.1.2a.cmml" xref="S5.T1.3.3.1.m1.1.1.2"><mtext id="S5.T1.3.3.1.m1.1.1.2.cmml" xref="S5.T1.3.3.1.m1.1.1.2">Std</mtext></ci><ci id="S5.T1.3.3.1.m1.1.1.3a.cmml" xref="S5.T1.3.3.1.m1.1.1.3"><mtext id="S5.T1.3.3.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T1.3.3.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.1.m1.1c">\text{Std}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.3.3.1.m1.1d">Std start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.3.2">2.4065 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.3.3">1.8593 %</td>
</tr>
<tr class="ltx_tr" id="S5.T1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.4.4.1"><math alttext="F_{\text{error}}&gt;10\%" class="ltx_Math" display="inline" id="S5.T1.4.4.1.m1.1"><semantics id="S5.T1.4.4.1.m1.1a"><mrow id="S5.T1.4.4.1.m1.1.1" xref="S5.T1.4.4.1.m1.1.1.cmml"><msub id="S5.T1.4.4.1.m1.1.1.2" xref="S5.T1.4.4.1.m1.1.1.2.cmml"><mi id="S5.T1.4.4.1.m1.1.1.2.2" xref="S5.T1.4.4.1.m1.1.1.2.2.cmml">F</mi><mtext id="S5.T1.4.4.1.m1.1.1.2.3" xref="S5.T1.4.4.1.m1.1.1.2.3a.cmml">error</mtext></msub><mo id="S5.T1.4.4.1.m1.1.1.1" xref="S5.T1.4.4.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S5.T1.4.4.1.m1.1.1.3" xref="S5.T1.4.4.1.m1.1.1.3.cmml"><mn id="S5.T1.4.4.1.m1.1.1.3.2" xref="S5.T1.4.4.1.m1.1.1.3.2.cmml">10</mn><mo id="S5.T1.4.4.1.m1.1.1.3.1" xref="S5.T1.4.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.1.m1.1b"><apply id="S5.T1.4.4.1.m1.1.1.cmml" xref="S5.T1.4.4.1.m1.1.1"><gt id="S5.T1.4.4.1.m1.1.1.1.cmml" xref="S5.T1.4.4.1.m1.1.1.1"></gt><apply id="S5.T1.4.4.1.m1.1.1.2.cmml" xref="S5.T1.4.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T1.4.4.1.m1.1.1.2.1.cmml" xref="S5.T1.4.4.1.m1.1.1.2">subscript</csymbol><ci id="S5.T1.4.4.1.m1.1.1.2.2.cmml" xref="S5.T1.4.4.1.m1.1.1.2.2">𝐹</ci><ci id="S5.T1.4.4.1.m1.1.1.2.3a.cmml" xref="S5.T1.4.4.1.m1.1.1.2.3"><mtext id="S5.T1.4.4.1.m1.1.1.2.3.cmml" mathsize="70%" xref="S5.T1.4.4.1.m1.1.1.2.3">error</mtext></ci></apply><apply id="S5.T1.4.4.1.m1.1.1.3.cmml" xref="S5.T1.4.4.1.m1.1.1.3"><csymbol cd="latexml" id="S5.T1.4.4.1.m1.1.1.3.1.cmml" xref="S5.T1.4.4.1.m1.1.1.3.1">percent</csymbol><cn id="S5.T1.4.4.1.m1.1.1.3.2.cmml" type="integer" xref="S5.T1.4.4.1.m1.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.1.m1.1c">F_{\text{error}}&gt;10\%</annotation><annotation encoding="application/x-llamapun" id="S5.T1.4.4.1.m1.1d">italic_F start_POSTSUBSCRIPT error end_POSTSUBSCRIPT &gt; 10 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.4.4.2">1.3426 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.4.4.3">0.5695 %</td>
</tr>
<tr class="ltx_tr" id="S5.T1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S5.T1.5.5.1"><math alttext="\text{R}^{2}" class="ltx_Math" display="inline" id="S5.T1.5.5.1.m1.1"><semantics id="S5.T1.5.5.1.m1.1a"><msup id="S5.T1.5.5.1.m1.1.1" xref="S5.T1.5.5.1.m1.1.1.cmml"><mtext id="S5.T1.5.5.1.m1.1.1.2" xref="S5.T1.5.5.1.m1.1.1.2a.cmml">R</mtext><mn id="S5.T1.5.5.1.m1.1.1.3" xref="S5.T1.5.5.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.1.m1.1b"><apply id="S5.T1.5.5.1.m1.1.1.cmml" xref="S5.T1.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.5.5.1.m1.1.1.1.cmml" xref="S5.T1.5.5.1.m1.1.1">superscript</csymbol><ci id="S5.T1.5.5.1.m1.1.1.2a.cmml" xref="S5.T1.5.5.1.m1.1.1.2"><mtext id="S5.T1.5.5.1.m1.1.1.2.cmml" xref="S5.T1.5.5.1.m1.1.1.2">R</mtext></ci><cn id="S5.T1.5.5.1.m1.1.1.3.cmml" type="integer" xref="S5.T1.5.5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.1.m1.1c">\text{R}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.5.5.1.m1.1d">R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T1.5.5.2">0.9990</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T1.5.5.3">0.9987</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">The small standard deviation values for both models indicate that the errors are not widely spread from the mean, suggesting that most predictions are close to the actual CHF values. Furthermore, both networks are observed with an <math alttext="R^{2}" class="ltx_Math" display="inline" id="S5.SS1.p4.1.m1.1"><semantics id="S5.SS1.p4.1.m1.1a"><msup id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml"><mi id="S5.SS1.p4.1.m1.1.1.2" xref="S5.SS1.p4.1.m1.1.1.2.cmml">R</mi><mn id="S5.SS1.p4.1.m1.1.1.3" xref="S5.SS1.p4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><apply id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.1.m1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.p4.1.m1.1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.1.2">𝑅</ci><cn id="S5.SS1.p4.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p4.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> value above 0.99 indicating a very high degree of correlation between true and generated/predicted values. Overall, these results show that both models perform well in generating and predicting CHF values, with the CVAE having more favorable values across all error metrics.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1">The last row in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S2.F1" title="Figure 1 ‣ 2 The CHF Experimental Dataset ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">1</span></a> presents the pair-wise correlations between the measured CHF values and each of the seven parameters in the vector of TH conditions. It is desirable to maintain such correlations in the generated and predicted CHF data.
The correlations between the predicted and generated CHF values and the TH parameters in the testing dataset were compared with the real data to determine whether the models can learn and preserve these correlations. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F4" title="Figure 4 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">4</span></a> compares the correlations of the TH parameters with the true CHF values and the generated CHF values using the CVAE model. Similarly, Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F5" title="Figure 5 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">5</span></a> compares the correlations of the TH parameters with the true CHF values and the predicted CHF values using the DNN model. These figures also illustrate the TH parameter ranges in the testing dataset.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="306" id="S5.F4.g1" src="extracted/5843326/figures/fig_CHF_CVAE_True_vs_Generated_Correlation_7_parameters.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S5.F4.3.2" style="font-size:90%;">Comparison of the CHF-TH-parameter pairwise correlations between the real data and the CVAE generated data.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="306" id="S5.F5.g1" src="extracted/5843326/figures/fig_CHF_DNN_True_vs_Generated_Correlation_7_parameters_80_grey.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S5.F5.3.2" style="font-size:90%;">Comparison of the CHF-TH-parameter pairwise correlations between the real data and the DNN predicted data.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.5">Figures <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F4" title="Figure 4 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F5" title="Figure 5 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">5</span></a> show that the correlations between the TH parameters and the generated/predicted CHF values align closely with those found in the real data. Both models have consistent behavior in terms of the correlations. While largest relative absolute error is observed at smaller CHF values, the largest absolute deviations from the true values are observed at higher CHF values, which are associated with smaller values of <math alttext="D" class="ltx_Math" display="inline" id="S5.SS1.p6.1.m1.1"><semantics id="S5.SS1.p6.1.m1.1a"><mi id="S5.SS1.p6.1.m1.1.1" xref="S5.SS1.p6.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.1.m1.1b"><ci id="S5.SS1.p6.1.m1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.1.m1.1c">D</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.1.m1.1d">italic_D</annotation></semantics></math>, <math alttext="L" class="ltx_Math" display="inline" id="S5.SS1.p6.2.m2.1"><semantics id="S5.SS1.p6.2.m2.1a"><mi id="S5.SS1.p6.2.m2.1.1" xref="S5.SS1.p6.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.2.m2.1b"><ci id="S5.SS1.p6.2.m2.1.1.cmml" xref="S5.SS1.p6.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.2.m2.1c">L</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.2.m2.1d">italic_L</annotation></semantics></math>, <math alttext="P" class="ltx_Math" display="inline" id="S5.SS1.p6.3.m3.1"><semantics id="S5.SS1.p6.3.m3.1a"><mi id="S5.SS1.p6.3.m3.1.1" xref="S5.SS1.p6.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.3.m3.1b"><ci id="S5.SS1.p6.3.m3.1.1.cmml" xref="S5.SS1.p6.3.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.3.m3.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.3.m3.1d">italic_P</annotation></semantics></math> and <math alttext="T_{\text{in}}" class="ltx_Math" display="inline" id="S5.SS1.p6.4.m4.1"><semantics id="S5.SS1.p6.4.m4.1a"><msub id="S5.SS1.p6.4.m4.1.1" xref="S5.SS1.p6.4.m4.1.1.cmml"><mi id="S5.SS1.p6.4.m4.1.1.2" xref="S5.SS1.p6.4.m4.1.1.2.cmml">T</mi><mtext id="S5.SS1.p6.4.m4.1.1.3" xref="S5.SS1.p6.4.m4.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.4.m4.1b"><apply id="S5.SS1.p6.4.m4.1.1.cmml" xref="S5.SS1.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.p6.4.m4.1.1.1.cmml" xref="S5.SS1.p6.4.m4.1.1">subscript</csymbol><ci id="S5.SS1.p6.4.m4.1.1.2.cmml" xref="S5.SS1.p6.4.m4.1.1.2">𝑇</ci><ci id="S5.SS1.p6.4.m4.1.1.3a.cmml" xref="S5.SS1.p6.4.m4.1.1.3"><mtext id="S5.SS1.p6.4.m4.1.1.3.cmml" mathsize="70%" xref="S5.SS1.p6.4.m4.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.4.m4.1c">T_{\text{in}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.4.m4.1d">italic_T start_POSTSUBSCRIPT in end_POSTSUBSCRIPT</annotation></semantics></math>, subcooled coolant conditions, and high <math alttext="G" class="ltx_Math" display="inline" id="S5.SS1.p6.5.m5.1"><semantics id="S5.SS1.p6.5.m5.1a"><mi id="S5.SS1.p6.5.m5.1.1" xref="S5.SS1.p6.5.m5.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.5.m5.1b"><ci id="S5.SS1.p6.5.m5.1.1.cmml" xref="S5.SS1.p6.5.m5.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.5.m5.1c">G</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.5.m5.1d">italic_G</annotation></semantics></math> values. It is important to note that these regions contain fewer data points in both training and testing datasets, resulting in the model’s deviations from the true values under these conditions. However, these deviations are not significant and do not heavily influence the error distributions, as these CHF conditions are less common in practical applications and thus in the CHF dataset.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results of UQ</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">To quantify the model uncertainty, 200 unique samples were computed for each of the testing set’s input entries using the trained CVAE model. From these, the means and standard deviations of these samples were taken for each of these input entries. The ensemble approach described in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S4.SS3" title="4.3 UQ of the ML Models ‣ 4 The Generative and Predictive ML Models ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">4.3</span></a> was then implemented using <math alttext="n=20" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">n</mi><mo id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><eq id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></eq><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">𝑛</ci><cn id="S5.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">n=20</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_n = 20</annotation></semantics></math> models each initialized with a different random seed. Each of these models were identical with the exception of the initialization. As with the CVAE model, the means and standard deviations were computed along the 200 samples for each input vector of the testing set. The standard deviations were then taken to compute the relative standard deviation using Equation <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.E6" title="In 5.2 Results of UQ ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">6</span></a>. This metric standardizes the uncertainty measure by expressing the standard deviation as a percentage of the mean, making it easier to interpret and to compare across different scales of the outputs.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S5.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\text{Relative Std (\%)}=\frac{\sigma_{\text{samples}}}{\mu_{\text{samples}}}%
\times 100\%" class="ltx_Math" display="block" id="S5.E6.m1.1"><semantics id="S5.E6.m1.1a"><mrow id="S5.E6.m1.1.1" xref="S5.E6.m1.1.1.cmml"><mtext id="S5.E6.m1.1.1.2" xref="S5.E6.m1.1.1.2a.cmml">Relative Std (%)</mtext><mo id="S5.E6.m1.1.1.1" xref="S5.E6.m1.1.1.1.cmml">=</mo><mrow id="S5.E6.m1.1.1.3" xref="S5.E6.m1.1.1.3.cmml"><mfrac id="S5.E6.m1.1.1.3.2" xref="S5.E6.m1.1.1.3.2.cmml"><msub id="S5.E6.m1.1.1.3.2.2" xref="S5.E6.m1.1.1.3.2.2.cmml"><mi id="S5.E6.m1.1.1.3.2.2.2" xref="S5.E6.m1.1.1.3.2.2.2.cmml">σ</mi><mtext id="S5.E6.m1.1.1.3.2.2.3" xref="S5.E6.m1.1.1.3.2.2.3a.cmml">samples</mtext></msub><msub id="S5.E6.m1.1.1.3.2.3" xref="S5.E6.m1.1.1.3.2.3.cmml"><mi id="S5.E6.m1.1.1.3.2.3.2" xref="S5.E6.m1.1.1.3.2.3.2.cmml">μ</mi><mtext id="S5.E6.m1.1.1.3.2.3.3" xref="S5.E6.m1.1.1.3.2.3.3a.cmml">samples</mtext></msub></mfrac><mo id="S5.E6.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S5.E6.m1.1.1.3.1.cmml">×</mo><mrow id="S5.E6.m1.1.1.3.3" xref="S5.E6.m1.1.1.3.3.cmml"><mn id="S5.E6.m1.1.1.3.3.2" xref="S5.E6.m1.1.1.3.3.2.cmml">100</mn><mo id="S5.E6.m1.1.1.3.3.1" xref="S5.E6.m1.1.1.3.3.1.cmml">%</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E6.m1.1b"><apply id="S5.E6.m1.1.1.cmml" xref="S5.E6.m1.1.1"><eq id="S5.E6.m1.1.1.1.cmml" xref="S5.E6.m1.1.1.1"></eq><ci id="S5.E6.m1.1.1.2a.cmml" xref="S5.E6.m1.1.1.2"><mtext id="S5.E6.m1.1.1.2.cmml" xref="S5.E6.m1.1.1.2">Relative Std (%)</mtext></ci><apply id="S5.E6.m1.1.1.3.cmml" xref="S5.E6.m1.1.1.3"><times id="S5.E6.m1.1.1.3.1.cmml" xref="S5.E6.m1.1.1.3.1"></times><apply id="S5.E6.m1.1.1.3.2.cmml" xref="S5.E6.m1.1.1.3.2"><divide id="S5.E6.m1.1.1.3.2.1.cmml" xref="S5.E6.m1.1.1.3.2"></divide><apply id="S5.E6.m1.1.1.3.2.2.cmml" xref="S5.E6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.3.2.2.1.cmml" xref="S5.E6.m1.1.1.3.2.2">subscript</csymbol><ci id="S5.E6.m1.1.1.3.2.2.2.cmml" xref="S5.E6.m1.1.1.3.2.2.2">𝜎</ci><ci id="S5.E6.m1.1.1.3.2.2.3a.cmml" xref="S5.E6.m1.1.1.3.2.2.3"><mtext id="S5.E6.m1.1.1.3.2.2.3.cmml" mathsize="70%" xref="S5.E6.m1.1.1.3.2.2.3">samples</mtext></ci></apply><apply id="S5.E6.m1.1.1.3.2.3.cmml" xref="S5.E6.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.3.2.3.1.cmml" xref="S5.E6.m1.1.1.3.2.3">subscript</csymbol><ci id="S5.E6.m1.1.1.3.2.3.2.cmml" xref="S5.E6.m1.1.1.3.2.3.2">𝜇</ci><ci id="S5.E6.m1.1.1.3.2.3.3a.cmml" xref="S5.E6.m1.1.1.3.2.3.3"><mtext id="S5.E6.m1.1.1.3.2.3.3.cmml" mathsize="70%" xref="S5.E6.m1.1.1.3.2.3.3">samples</mtext></ci></apply></apply><apply id="S5.E6.m1.1.1.3.3.cmml" xref="S5.E6.m1.1.1.3.3"><csymbol cd="latexml" id="S5.E6.m1.1.1.3.3.1.cmml" xref="S5.E6.m1.1.1.3.3.1">percent</csymbol><cn id="S5.E6.m1.1.1.3.3.2.cmml" type="integer" xref="S5.E6.m1.1.1.3.3.2">100</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E6.m1.1c">\text{Relative Std (\%)}=\frac{\sigma_{\text{samples}}}{\mu_{\text{samples}}}%
\times 100\%</annotation><annotation encoding="application/x-llamapun" id="S5.E6.m1.1d">Relative Std (%) = divide start_ARG italic_σ start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT end_ARG start_ARG italic_μ start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT end_ARG × 100 %</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.6">This process resulted in a relative standard deviation value for each of the output means, providing quantification of the model’s uncertainty. By comparing the relative standard deviations from the CVAE to those of the ensemble of DNNs, we can assess the effectiveness of each approach in capturing the uncertainty associated with the model predictions. This is done using the 6 metrics reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T2" title="Table 2 ‣ 5.2 Results of UQ ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>, which also include the standard deviation of the error across all prediction means, as was done in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.SS1" title="5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">5.1</span></a>. In terms of error values, the DNN achieves a significantly smaller mean relative error of <math alttext="0.8868\%" class="ltx_Math" display="inline" id="S5.SS2.p3.1.m1.1"><semantics id="S5.SS2.p3.1.m1.1a"><mrow id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml"><mn id="S5.SS2.p3.1.m1.1.1.2" xref="S5.SS2.p3.1.m1.1.1.2.cmml">0.8868</mn><mo id="S5.SS2.p3.1.m1.1.1.1" xref="S5.SS2.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><apply id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.p3.1.m1.1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1.1">percent</csymbol><cn id="S5.SS2.p3.1.m1.1.1.2.cmml" type="float" xref="S5.SS2.p3.1.m1.1.1.2">0.8868</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">0.8868\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.1.m1.1d">0.8868 %</annotation></semantics></math> when compared to the <math alttext="1.4797\%" class="ltx_Math" display="inline" id="S5.SS2.p3.2.m2.1"><semantics id="S5.SS2.p3.2.m2.1a"><mrow id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml"><mn id="S5.SS2.p3.2.m2.1.1.2" xref="S5.SS2.p3.2.m2.1.1.2.cmml">1.4797</mn><mo id="S5.SS2.p3.2.m2.1.1.1" xref="S5.SS2.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><apply id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS2.p3.2.m2.1.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1.1">percent</csymbol><cn id="S5.SS2.p3.2.m2.1.1.2.cmml" type="float" xref="S5.SS2.p3.2.m2.1.1.2">1.4797</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">1.4797\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.2.m2.1d">1.4797 %</annotation></semantics></math> of the CVAE. The standard deviation of this error distribution is also tighter in the DNN’s case, <math alttext="1.5364\%" class="ltx_Math" display="inline" id="S5.SS2.p3.3.m3.1"><semantics id="S5.SS2.p3.3.m3.1a"><mrow id="S5.SS2.p3.3.m3.1.1" xref="S5.SS2.p3.3.m3.1.1.cmml"><mn id="S5.SS2.p3.3.m3.1.1.2" xref="S5.SS2.p3.3.m3.1.1.2.cmml">1.5364</mn><mo id="S5.SS2.p3.3.m3.1.1.1" xref="S5.SS2.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.3.m3.1b"><apply id="S5.SS2.p3.3.m3.1.1.cmml" xref="S5.SS2.p3.3.m3.1.1"><csymbol cd="latexml" id="S5.SS2.p3.3.m3.1.1.1.cmml" xref="S5.SS2.p3.3.m3.1.1.1">percent</csymbol><cn id="S5.SS2.p3.3.m3.1.1.2.cmml" type="float" xref="S5.SS2.p3.3.m3.1.1.2">1.5364</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.3.m3.1c">1.5364\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.3.m3.1d">1.5364 %</annotation></semantics></math> versus <math alttext="1.8496\%" class="ltx_Math" display="inline" id="S5.SS2.p3.4.m4.1"><semantics id="S5.SS2.p3.4.m4.1a"><mrow id="S5.SS2.p3.4.m4.1.1" xref="S5.SS2.p3.4.m4.1.1.cmml"><mn id="S5.SS2.p3.4.m4.1.1.2" xref="S5.SS2.p3.4.m4.1.1.2.cmml">1.8496</mn><mo id="S5.SS2.p3.4.m4.1.1.1" xref="S5.SS2.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.4.m4.1b"><apply id="S5.SS2.p3.4.m4.1.1.cmml" xref="S5.SS2.p3.4.m4.1.1"><csymbol cd="latexml" id="S5.SS2.p3.4.m4.1.1.1.cmml" xref="S5.SS2.p3.4.m4.1.1.1">percent</csymbol><cn id="S5.SS2.p3.4.m4.1.1.2.cmml" type="float" xref="S5.SS2.p3.4.m4.1.1.2">1.8496</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.4.m4.1c">1.8496\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.4.m4.1d">1.8496 %</annotation></semantics></math>, but with generally comparable values when considering their small magnitudes. The DNN’s maximum value of the error distribution, <math alttext="37.307\%" class="ltx_Math" display="inline" id="S5.SS2.p3.5.m5.1"><semantics id="S5.SS2.p3.5.m5.1a"><mrow id="S5.SS2.p3.5.m5.1.1" xref="S5.SS2.p3.5.m5.1.1.cmml"><mn id="S5.SS2.p3.5.m5.1.1.2" xref="S5.SS2.p3.5.m5.1.1.2.cmml">37.307</mn><mo id="S5.SS2.p3.5.m5.1.1.1" xref="S5.SS2.p3.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.5.m5.1b"><apply id="S5.SS2.p3.5.m5.1.1.cmml" xref="S5.SS2.p3.5.m5.1.1"><csymbol cd="latexml" id="S5.SS2.p3.5.m5.1.1.1.cmml" xref="S5.SS2.p3.5.m5.1.1.1">percent</csymbol><cn id="S5.SS2.p3.5.m5.1.1.2.cmml" type="float" xref="S5.SS2.p3.5.m5.1.1.2">37.307</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.5.m5.1c">37.307\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.5.m5.1d">37.307 %</annotation></semantics></math>, is observed to be significantly larger than the CVAE’s of <math alttext="22.334\%" class="ltx_Math" display="inline" id="S5.SS2.p3.6.m6.1"><semantics id="S5.SS2.p3.6.m6.1a"><mrow id="S5.SS2.p3.6.m6.1.1" xref="S5.SS2.p3.6.m6.1.1.cmml"><mn id="S5.SS2.p3.6.m6.1.1.2" xref="S5.SS2.p3.6.m6.1.1.2.cmml">22.334</mn><mo id="S5.SS2.p3.6.m6.1.1.1" xref="S5.SS2.p3.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.6.m6.1b"><apply id="S5.SS2.p3.6.m6.1.1.cmml" xref="S5.SS2.p3.6.m6.1.1"><csymbol cd="latexml" id="S5.SS2.p3.6.m6.1.1.1.cmml" xref="S5.SS2.p3.6.m6.1.1.1">percent</csymbol><cn id="S5.SS2.p3.6.m6.1.1.2.cmml" type="float" xref="S5.SS2.p3.6.m6.1.1.2">22.334</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.6.m6.1c">22.334\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.6.m6.1d">22.334 %</annotation></semantics></math>. Both of these maximum values are located at relatively small CHF values near the origin.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.6.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S5.T2.7.2" style="font-size:90%;">Statistical metrics for the absolute relative errors with UQ.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T2.4.5.1.1">Metric</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.4.5.1.2">DNN</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.4.5.1.3">CVAE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.1.1"><math alttext="\mu_{\text{error}}" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.m1.1a"><msub id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml"><mi id="S5.T2.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.m1.1.1.2.cmml">μ</mi><mtext id="S5.T2.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><apply id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T2.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.m1.1.1.2">𝜇</ci><ci id="S5.T2.1.1.1.m1.1.1.3a.cmml" xref="S5.T2.1.1.1.m1.1.1.3"><mtext id="S5.T2.1.1.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T2.1.1.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">\mu_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.m1.1d">italic_μ start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.2">0.8868 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3">1.4797 %</td>
</tr>
<tr class="ltx_tr" id="S5.T2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.2.2.1"><math alttext="\text{Max}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T2.2.2.1.m1.1"><semantics id="S5.T2.2.2.1.m1.1a"><msub id="S5.T2.2.2.1.m1.1.1" xref="S5.T2.2.2.1.m1.1.1.cmml"><mtext id="S5.T2.2.2.1.m1.1.1.2" xref="S5.T2.2.2.1.m1.1.1.2a.cmml">Max</mtext><mtext id="S5.T2.2.2.1.m1.1.1.3" xref="S5.T2.2.2.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.1.m1.1b"><apply id="S5.T2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.2.2.1.m1.1.1.1.cmml" xref="S5.T2.2.2.1.m1.1.1">subscript</csymbol><ci id="S5.T2.2.2.1.m1.1.1.2a.cmml" xref="S5.T2.2.2.1.m1.1.1.2"><mtext id="S5.T2.2.2.1.m1.1.1.2.cmml" xref="S5.T2.2.2.1.m1.1.1.2">Max</mtext></ci><ci id="S5.T2.2.2.1.m1.1.1.3a.cmml" xref="S5.T2.2.2.1.m1.1.1.3"><mtext id="S5.T2.2.2.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T2.2.2.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.1.m1.1c">\text{Max}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.1.m1.1d">Max start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.2.2.2">37.307 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.2.2.3">22.334 %</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.3.3.1"><math alttext="\text{Std}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T2.3.3.1.m1.1"><semantics id="S5.T2.3.3.1.m1.1a"><msub id="S5.T2.3.3.1.m1.1.1" xref="S5.T2.3.3.1.m1.1.1.cmml"><mtext id="S5.T2.3.3.1.m1.1.1.2" xref="S5.T2.3.3.1.m1.1.1.2a.cmml">Std</mtext><mtext id="S5.T2.3.3.1.m1.1.1.3" xref="S5.T2.3.3.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.1.m1.1b"><apply id="S5.T2.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.3.3.1.m1.1.1.1.cmml" xref="S5.T2.3.3.1.m1.1.1">subscript</csymbol><ci id="S5.T2.3.3.1.m1.1.1.2a.cmml" xref="S5.T2.3.3.1.m1.1.1.2"><mtext id="S5.T2.3.3.1.m1.1.1.2.cmml" xref="S5.T2.3.3.1.m1.1.1.2">Std</mtext></ci><ci id="S5.T2.3.3.1.m1.1.1.3a.cmml" xref="S5.T2.3.3.1.m1.1.1.3"><mtext id="S5.T2.3.3.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T2.3.3.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.1.m1.1c">\text{Std}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.1.m1.1d">Std start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.3.2">1.5364 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.3.3">1.8496%</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.4.6.1.1">Mean relative std</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.6.1.2">1.8023 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.6.1.3">0.2579 %</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.4.7.2.1">Max relative std</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.7.2.2">29.651 %</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.7.2.3">5.5714 %</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S5.T2.4.4.1"><math alttext="F_{\text{error}}&gt;10\%" class="ltx_Math" display="inline" id="S5.T2.4.4.1.m1.1"><semantics id="S5.T2.4.4.1.m1.1a"><mrow id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml"><msub id="S5.T2.4.4.1.m1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.2.cmml"><mi id="S5.T2.4.4.1.m1.1.1.2.2" xref="S5.T2.4.4.1.m1.1.1.2.2.cmml">F</mi><mtext id="S5.T2.4.4.1.m1.1.1.2.3" xref="S5.T2.4.4.1.m1.1.1.2.3a.cmml">error</mtext></msub><mo id="S5.T2.4.4.1.m1.1.1.1" xref="S5.T2.4.4.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S5.T2.4.4.1.m1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.3.cmml"><mn id="S5.T2.4.4.1.m1.1.1.3.2" xref="S5.T2.4.4.1.m1.1.1.3.2.cmml">10</mn><mo id="S5.T2.4.4.1.m1.1.1.3.1" xref="S5.T2.4.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b"><apply id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1"><gt id="S5.T2.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1.1"></gt><apply id="S5.T2.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T2.4.4.1.m1.1.1.2.1.cmml" xref="S5.T2.4.4.1.m1.1.1.2">subscript</csymbol><ci id="S5.T2.4.4.1.m1.1.1.2.2.cmml" xref="S5.T2.4.4.1.m1.1.1.2.2">𝐹</ci><ci id="S5.T2.4.4.1.m1.1.1.2.3a.cmml" xref="S5.T2.4.4.1.m1.1.1.2.3"><mtext id="S5.T2.4.4.1.m1.1.1.2.3.cmml" mathsize="70%" xref="S5.T2.4.4.1.m1.1.1.2.3">error</mtext></ci></apply><apply id="S5.T2.4.4.1.m1.1.1.3.cmml" xref="S5.T2.4.4.1.m1.1.1.3"><csymbol cd="latexml" id="S5.T2.4.4.1.m1.1.1.3.1.cmml" xref="S5.T2.4.4.1.m1.1.1.3.1">percent</csymbol><cn id="S5.T2.4.4.1.m1.1.1.3.2.cmml" type="integer" xref="S5.T2.4.4.1.m1.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">F_{\text{error}}&gt;10\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.1.m1.1d">italic_F start_POSTSUBSCRIPT error end_POSTSUBSCRIPT &gt; 10 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.4.4.2">0.3662 %</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.4.4.3">0.5695 %</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.5">Now considering the distribution of relative standard deviations, the CVAE’s results report significantly smaller mean and maximum relative Std values compared to the DNN’s. The mean relative standard deviation of the DNN (<math alttext="1.8023\%" class="ltx_Math" display="inline" id="S5.SS2.p4.1.m1.1"><semantics id="S5.SS2.p4.1.m1.1a"><mrow id="S5.SS2.p4.1.m1.1.1" xref="S5.SS2.p4.1.m1.1.1.cmml"><mn id="S5.SS2.p4.1.m1.1.1.2" xref="S5.SS2.p4.1.m1.1.1.2.cmml">1.8023</mn><mo id="S5.SS2.p4.1.m1.1.1.1" xref="S5.SS2.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p4.1.m1.1b"><apply id="S5.SS2.p4.1.m1.1.1.cmml" xref="S5.SS2.p4.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.p4.1.m1.1.1.1.cmml" xref="S5.SS2.p4.1.m1.1.1.1">percent</csymbol><cn id="S5.SS2.p4.1.m1.1.1.2.cmml" type="float" xref="S5.SS2.p4.1.m1.1.1.2">1.8023</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p4.1.m1.1c">1.8023\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p4.1.m1.1d">1.8023 %</annotation></semantics></math>) is over seven times greater than that of the CVAE (<math alttext="0.2579\%" class="ltx_Math" display="inline" id="S5.SS2.p4.2.m2.1"><semantics id="S5.SS2.p4.2.m2.1a"><mrow id="S5.SS2.p4.2.m2.1.1" xref="S5.SS2.p4.2.m2.1.1.cmml"><mn id="S5.SS2.p4.2.m2.1.1.2" xref="S5.SS2.p4.2.m2.1.1.2.cmml">0.2579</mn><mo id="S5.SS2.p4.2.m2.1.1.1" xref="S5.SS2.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p4.2.m2.1b"><apply id="S5.SS2.p4.2.m2.1.1.cmml" xref="S5.SS2.p4.2.m2.1.1"><csymbol cd="latexml" id="S5.SS2.p4.2.m2.1.1.1.cmml" xref="S5.SS2.p4.2.m2.1.1.1">percent</csymbol><cn id="S5.SS2.p4.2.m2.1.1.2.cmml" type="float" xref="S5.SS2.p4.2.m2.1.1.2">0.2579</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p4.2.m2.1c">0.2579\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p4.2.m2.1d">0.2579 %</annotation></semantics></math>), indicating that the CVAE is more confident in its predictions with less variability in its outputs. This is similarly mirrored in their maximum values, where the DNN has a value of nearly <math alttext="30\%" class="ltx_Math" display="inline" id="S5.SS2.p4.3.m3.1"><semantics id="S5.SS2.p4.3.m3.1a"><mrow id="S5.SS2.p4.3.m3.1.1" xref="S5.SS2.p4.3.m3.1.1.cmml"><mn id="S5.SS2.p4.3.m3.1.1.2" xref="S5.SS2.p4.3.m3.1.1.2.cmml">30</mn><mo id="S5.SS2.p4.3.m3.1.1.1" xref="S5.SS2.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p4.3.m3.1b"><apply id="S5.SS2.p4.3.m3.1.1.cmml" xref="S5.SS2.p4.3.m3.1.1"><csymbol cd="latexml" id="S5.SS2.p4.3.m3.1.1.1.cmml" xref="S5.SS2.p4.3.m3.1.1.1">percent</csymbol><cn id="S5.SS2.p4.3.m3.1.1.2.cmml" type="integer" xref="S5.SS2.p4.3.m3.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p4.3.m3.1c">30\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p4.3.m3.1d">30 %</annotation></semantics></math> with the CVAE reporting <math alttext="5.5714\%" class="ltx_Math" display="inline" id="S5.SS2.p4.4.m4.1"><semantics id="S5.SS2.p4.4.m4.1a"><mrow id="S5.SS2.p4.4.m4.1.1" xref="S5.SS2.p4.4.m4.1.1.cmml"><mn id="S5.SS2.p4.4.m4.1.1.2" xref="S5.SS2.p4.4.m4.1.1.2.cmml">5.5714</mn><mo id="S5.SS2.p4.4.m4.1.1.1" xref="S5.SS2.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p4.4.m4.1b"><apply id="S5.SS2.p4.4.m4.1.1.cmml" xref="S5.SS2.p4.4.m4.1.1"><csymbol cd="latexml" id="S5.SS2.p4.4.m4.1.1.1.cmml" xref="S5.SS2.p4.4.m4.1.1.1">percent</csymbol><cn id="S5.SS2.p4.4.m4.1.1.2.cmml" type="float" xref="S5.SS2.p4.4.m4.1.1.2">5.5714</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p4.4.m4.1c">5.5714\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p4.4.m4.1d">5.5714 %</annotation></semantics></math>. The final metric, the fraction of predictions with relative errors above <math alttext="10\%" class="ltx_Math" display="inline" id="S5.SS2.p4.5.m5.1"><semantics id="S5.SS2.p4.5.m5.1a"><mrow id="S5.SS2.p4.5.m5.1.1" xref="S5.SS2.p4.5.m5.1.1.cmml"><mn id="S5.SS2.p4.5.m5.1.1.2" xref="S5.SS2.p4.5.m5.1.1.2.cmml">10</mn><mo id="S5.SS2.p4.5.m5.1.1.1" xref="S5.SS2.p4.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p4.5.m5.1b"><apply id="S5.SS2.p4.5.m5.1.1.cmml" xref="S5.SS2.p4.5.m5.1.1"><csymbol cd="latexml" id="S5.SS2.p4.5.m5.1.1.1.cmml" xref="S5.SS2.p4.5.m5.1.1.1">percent</csymbol><cn id="S5.SS2.p4.5.m5.1.1.2.cmml" type="integer" xref="S5.SS2.p4.5.m5.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p4.5.m5.1c">10\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p4.5.m5.1d">10 %</annotation></semantics></math>, has comparable values between the two models. Considering the combination of the metrics in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T2" title="Table 2 ‣ 5.2 Results of UQ ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>, the CVAE outputs are shown to have similar performance compared to a DNN ensemble while achieving model uncertainties significantly smaller.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results of Domain Generalization Analysis</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">In this subsection, we will evaluate the performance of the CVAE generative model and DNN predictive model under conditions outside the training data domain. This was done by comparing the errors in their outputs based on conditions from both inside and outside the training data domain. The testing set used in this work consist of 2,458 data points, with 1,047 points falling within the training data domain and the remaining 1,411 points falling outside the domain, as determined by the convex hull defined by the training dataset. The domain generalization analysis was performed using the mean CHF values obtained from the ensemble of DNNs and, for the CVAE, the mean value from generating multiple outputs. The relative error between <math alttext="\mu_{\text{samples}}" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><msub id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mi id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml">μ</mi><mtext id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3a.cmml">samples</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2">𝜇</ci><ci id="S5.SS3.p1.1.m1.1.1.3a.cmml" xref="S5.SS3.p1.1.m1.1.1.3"><mtext id="S5.SS3.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p1.1.m1.1.1.3">samples</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">\mu_{\text{samples}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">italic_μ start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT</annotation></semantics></math> and the true value was calculated for the points falling inside and outside the training domain. The distributions of the relative errors for these two subsets and two models are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F6" title="Figure 6 ‣ 5.3 Results of Domain Generalization Analysis ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_figure" id="S5.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="559" id="S5.F6.sf1.g1" src="x3.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S5.F6.sf1.3.2" style="font-size:90%;">The CVAE generative model.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="561" id="S5.F6.sf2.g1" src="x4.png" width="780"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S5.F6.sf2.3.2" style="font-size:90%;">The DNN predictive model.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.4.2.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S5.F6.2.1" style="font-size:90%;">Distribution of the relative errors between <math alttext="\mu_{\text{samples}}" class="ltx_Math" display="inline" id="S5.F6.2.1.m1.1"><semantics id="S5.F6.2.1.m1.1b"><msub id="S5.F6.2.1.m1.1.1" xref="S5.F6.2.1.m1.1.1.cmml"><mi id="S5.F6.2.1.m1.1.1.2" xref="S5.F6.2.1.m1.1.1.2.cmml">μ</mi><mtext id="S5.F6.2.1.m1.1.1.3" xref="S5.F6.2.1.m1.1.1.3a.cmml">samples</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.F6.2.1.m1.1c"><apply id="S5.F6.2.1.m1.1.1.cmml" xref="S5.F6.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.F6.2.1.m1.1.1.1.cmml" xref="S5.F6.2.1.m1.1.1">subscript</csymbol><ci id="S5.F6.2.1.m1.1.1.2.cmml" xref="S5.F6.2.1.m1.1.1.2">𝜇</ci><ci id="S5.F6.2.1.m1.1.1.3a.cmml" xref="S5.F6.2.1.m1.1.1.3"><mtext id="S5.F6.2.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.F6.2.1.m1.1.1.3">samples</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.2.1.m1.1d">\mu_{\text{samples}}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.2.1.m1.1e">italic_μ start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT</annotation></semantics></math> and the true CHF values, for testing points inside and outside the convex hull.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.F6" title="Figure 6 ‣ 5.3 Results of Domain Generalization Analysis ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">6</span></a>, the error distributions for the two subsets (inside and outside the convex hull) behave similarly, with small deviations observed in the mean and standard deviation values. The maximum error values occur when predictions were made under conditions outside the training data domain. This applies to both the CVAE and DNN models. The mean, maximum and standard deviation values were calculated for the absolute relative errors for both models and subsets. These values, along with the fraction of points with error values greater than 10% in each subset are listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T3" title="Table 3 ‣ 5.3 Results of Domain Generalization Analysis ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.10.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S5.T3.11.2" style="font-size:90%;">Statistics of the absolute relative errors for testing samples inside and outside the convex hull for the DNN and CVAE models.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T3.8.9.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.8.9.1.1.1">Statistic</span></th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T3.8.9.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.8.9.1.2.1">Inside training domain</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T3.8.9.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.8.9.1.3.1">Outside training domain</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.8.10.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3" id="S5.T3.8.10.2.1"><span class="ltx_text ltx_font_bold" id="S5.T3.8.10.2.1.1">CVAE</span></th>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.1.1"><math alttext="\mu_{\text{error}}" class="ltx_Math" display="inline" id="S5.T3.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.m1.1a"><msub id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml"><mi id="S5.T3.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.m1.1.1.2.cmml">μ</mi><mtext id="S5.T3.1.1.1.m1.1.1.3" xref="S5.T3.1.1.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T3.1.1.1.m1.1.1.2.cmml" xref="S5.T3.1.1.1.m1.1.1.2">𝜇</ci><ci id="S5.T3.1.1.1.m1.1.1.3a.cmml" xref="S5.T3.1.1.1.m1.1.1.3"><mtext id="S5.T3.1.1.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T3.1.1.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">\mu_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.m1.1d">italic_μ start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.2">1.2295 %</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.3">1.6653 %</td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.2.2.1"><math alttext="\text{Max}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T3.2.2.1.m1.1"><semantics id="S5.T3.2.2.1.m1.1a"><msub id="S5.T3.2.2.1.m1.1.1" xref="S5.T3.2.2.1.m1.1.1.cmml"><mtext id="S5.T3.2.2.1.m1.1.1.2" xref="S5.T3.2.2.1.m1.1.1.2a.cmml">Max</mtext><mtext id="S5.T3.2.2.1.m1.1.1.3" xref="S5.T3.2.2.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.1.m1.1b"><apply id="S5.T3.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.2.2.1.m1.1.1.1.cmml" xref="S5.T3.2.2.1.m1.1.1">subscript</csymbol><ci id="S5.T3.2.2.1.m1.1.1.2a.cmml" xref="S5.T3.2.2.1.m1.1.1.2"><mtext id="S5.T3.2.2.1.m1.1.1.2.cmml" xref="S5.T3.2.2.1.m1.1.1.2">Max</mtext></ci><ci id="S5.T3.2.2.1.m1.1.1.3a.cmml" xref="S5.T3.2.2.1.m1.1.1.3"><mtext id="S5.T3.2.2.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T3.2.2.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.1.m1.1c">\text{Max}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.1.m1.1d">Max start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right" id="S5.T3.2.2.2">9.8421 %</td>
<td class="ltx_td ltx_align_right" id="S5.T3.2.2.3">22.334 %</td>
</tr>
<tr class="ltx_tr" id="S5.T3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.3.3.1"><math alttext="\text{Std}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T3.3.3.1.m1.1"><semantics id="S5.T3.3.3.1.m1.1a"><msub id="S5.T3.3.3.1.m1.1.1" xref="S5.T3.3.3.1.m1.1.1.cmml"><mtext id="S5.T3.3.3.1.m1.1.1.2" xref="S5.T3.3.3.1.m1.1.1.2a.cmml">Std</mtext><mtext id="S5.T3.3.3.1.m1.1.1.3" xref="S5.T3.3.3.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.1.m1.1b"><apply id="S5.T3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.3.3.1.m1.1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1">subscript</csymbol><ci id="S5.T3.3.3.1.m1.1.1.2a.cmml" xref="S5.T3.3.3.1.m1.1.1.2"><mtext id="S5.T3.3.3.1.m1.1.1.2.cmml" xref="S5.T3.3.3.1.m1.1.1.2">Std</mtext></ci><ci id="S5.T3.3.3.1.m1.1.1.3a.cmml" xref="S5.T3.3.3.1.m1.1.1.3"><mtext id="S5.T3.3.3.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T3.3.3.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.1.m1.1c">\text{Std}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.1.m1.1d">Std start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right" id="S5.T3.3.3.2">1.1734 %</td>
<td class="ltx_td ltx_align_right" id="S5.T3.3.3.3">2.2038 %</td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.1"><math alttext="F_{\text{error}}&gt;10\%" class="ltx_Math" display="inline" id="S5.T3.4.4.1.m1.1"><semantics id="S5.T3.4.4.1.m1.1a"><mrow id="S5.T3.4.4.1.m1.1.1" xref="S5.T3.4.4.1.m1.1.1.cmml"><msub id="S5.T3.4.4.1.m1.1.1.2" xref="S5.T3.4.4.1.m1.1.1.2.cmml"><mi id="S5.T3.4.4.1.m1.1.1.2.2" xref="S5.T3.4.4.1.m1.1.1.2.2.cmml">F</mi><mtext id="S5.T3.4.4.1.m1.1.1.2.3" xref="S5.T3.4.4.1.m1.1.1.2.3a.cmml">error</mtext></msub><mo id="S5.T3.4.4.1.m1.1.1.1" xref="S5.T3.4.4.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S5.T3.4.4.1.m1.1.1.3" xref="S5.T3.4.4.1.m1.1.1.3.cmml"><mn id="S5.T3.4.4.1.m1.1.1.3.2" xref="S5.T3.4.4.1.m1.1.1.3.2.cmml">10</mn><mo id="S5.T3.4.4.1.m1.1.1.3.1" xref="S5.T3.4.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.1.m1.1b"><apply id="S5.T3.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1"><gt id="S5.T3.4.4.1.m1.1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1.1"></gt><apply id="S5.T3.4.4.1.m1.1.1.2.cmml" xref="S5.T3.4.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T3.4.4.1.m1.1.1.2.1.cmml" xref="S5.T3.4.4.1.m1.1.1.2">subscript</csymbol><ci id="S5.T3.4.4.1.m1.1.1.2.2.cmml" xref="S5.T3.4.4.1.m1.1.1.2.2">𝐹</ci><ci id="S5.T3.4.4.1.m1.1.1.2.3a.cmml" xref="S5.T3.4.4.1.m1.1.1.2.3"><mtext id="S5.T3.4.4.1.m1.1.1.2.3.cmml" mathsize="70%" xref="S5.T3.4.4.1.m1.1.1.2.3">error</mtext></ci></apply><apply id="S5.T3.4.4.1.m1.1.1.3.cmml" xref="S5.T3.4.4.1.m1.1.1.3"><csymbol cd="latexml" id="S5.T3.4.4.1.m1.1.1.3.1.cmml" xref="S5.T3.4.4.1.m1.1.1.3.1">percent</csymbol><cn id="S5.T3.4.4.1.m1.1.1.3.2.cmml" type="integer" xref="S5.T3.4.4.1.m1.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.1.m1.1c">F_{\text{error}}&gt;10\%</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.1.m1.1d">italic_F start_POSTSUBSCRIPT error end_POSTSUBSCRIPT &gt; 10 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right" id="S5.T3.4.4.2">0.0 %</td>
<td class="ltx_td ltx_align_right" id="S5.T3.4.4.3">0.9922 %</td>
</tr>
<tr class="ltx_tr" id="S5.T3.8.11.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3" id="S5.T3.8.11.3.1"><span class="ltx_text ltx_font_bold" id="S5.T3.8.11.3.1.1">DNN</span></th>
</tr>
<tr class="ltx_tr" id="S5.T3.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.5.5.1"><math alttext="\mu_{\text{error}}" class="ltx_Math" display="inline" id="S5.T3.5.5.1.m1.1"><semantics id="S5.T3.5.5.1.m1.1a"><msub id="S5.T3.5.5.1.m1.1.1" xref="S5.T3.5.5.1.m1.1.1.cmml"><mi id="S5.T3.5.5.1.m1.1.1.2" xref="S5.T3.5.5.1.m1.1.1.2.cmml">μ</mi><mtext id="S5.T3.5.5.1.m1.1.1.3" xref="S5.T3.5.5.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.1.m1.1b"><apply id="S5.T3.5.5.1.m1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.5.5.1.m1.1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1">subscript</csymbol><ci id="S5.T3.5.5.1.m1.1.1.2.cmml" xref="S5.T3.5.5.1.m1.1.1.2">𝜇</ci><ci id="S5.T3.5.5.1.m1.1.1.3a.cmml" xref="S5.T3.5.5.1.m1.1.1.3"><mtext id="S5.T3.5.5.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T3.5.5.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.1.m1.1c">\mu_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.5.1.m1.1d">italic_μ start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.5.5.2">0.7364 %</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.5.5.3">0.9983 %</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.6.6.1"><math alttext="\text{Max}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T3.6.6.1.m1.1"><semantics id="S5.T3.6.6.1.m1.1a"><msub id="S5.T3.6.6.1.m1.1.1" xref="S5.T3.6.6.1.m1.1.1.cmml"><mtext id="S5.T3.6.6.1.m1.1.1.2" xref="S5.T3.6.6.1.m1.1.1.2a.cmml">Max</mtext><mtext id="S5.T3.6.6.1.m1.1.1.3" xref="S5.T3.6.6.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.1.m1.1b"><apply id="S5.T3.6.6.1.m1.1.1.cmml" xref="S5.T3.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.6.6.1.m1.1.1.1.cmml" xref="S5.T3.6.6.1.m1.1.1">subscript</csymbol><ci id="S5.T3.6.6.1.m1.1.1.2a.cmml" xref="S5.T3.6.6.1.m1.1.1.2"><mtext id="S5.T3.6.6.1.m1.1.1.2.cmml" xref="S5.T3.6.6.1.m1.1.1.2">Max</mtext></ci><ci id="S5.T3.6.6.1.m1.1.1.3a.cmml" xref="S5.T3.6.6.1.m1.1.1.3"><mtext id="S5.T3.6.6.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T3.6.6.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.1.m1.1c">\text{Max}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.6.6.1.m1.1d">Max start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right" id="S5.T3.6.6.2">7.143 %</td>
<td class="ltx_td ltx_align_right" id="S5.T3.6.6.3">37.31 %</td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.7.7.1"><math alttext="\text{Std}_{\text{error}}" class="ltx_Math" display="inline" id="S5.T3.7.7.1.m1.1"><semantics id="S5.T3.7.7.1.m1.1a"><msub id="S5.T3.7.7.1.m1.1.1" xref="S5.T3.7.7.1.m1.1.1.cmml"><mtext id="S5.T3.7.7.1.m1.1.1.2" xref="S5.T3.7.7.1.m1.1.1.2a.cmml">Std</mtext><mtext id="S5.T3.7.7.1.m1.1.1.3" xref="S5.T3.7.7.1.m1.1.1.3a.cmml">error</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.1.m1.1b"><apply id="S5.T3.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.7.7.1.m1.1.1.1.cmml" xref="S5.T3.7.7.1.m1.1.1">subscript</csymbol><ci id="S5.T3.7.7.1.m1.1.1.2a.cmml" xref="S5.T3.7.7.1.m1.1.1.2"><mtext id="S5.T3.7.7.1.m1.1.1.2.cmml" xref="S5.T3.7.7.1.m1.1.1.2">Std</mtext></ci><ci id="S5.T3.7.7.1.m1.1.1.3a.cmml" xref="S5.T3.7.7.1.m1.1.1.3"><mtext id="S5.T3.7.7.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.T3.7.7.1.m1.1.1.3">error</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.1.m1.1c">\text{Std}_{\text{error}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.7.7.1.m1.1d">Std start_POSTSUBSCRIPT error end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right" id="S5.T3.7.7.2">0.8139 %</td>
<td class="ltx_td ltx_align_right" id="S5.T3.7.7.3">1.8407 %</td>
</tr>
<tr class="ltx_tr" id="S5.T3.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T3.8.8.1"><math alttext="F_{\text{error}}&gt;10\%" class="ltx_Math" display="inline" id="S5.T3.8.8.1.m1.1"><semantics id="S5.T3.8.8.1.m1.1a"><mrow id="S5.T3.8.8.1.m1.1.1" xref="S5.T3.8.8.1.m1.1.1.cmml"><msub id="S5.T3.8.8.1.m1.1.1.2" xref="S5.T3.8.8.1.m1.1.1.2.cmml"><mi id="S5.T3.8.8.1.m1.1.1.2.2" xref="S5.T3.8.8.1.m1.1.1.2.2.cmml">F</mi><mtext id="S5.T3.8.8.1.m1.1.1.2.3" xref="S5.T3.8.8.1.m1.1.1.2.3a.cmml">error</mtext></msub><mo id="S5.T3.8.8.1.m1.1.1.1" xref="S5.T3.8.8.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S5.T3.8.8.1.m1.1.1.3" xref="S5.T3.8.8.1.m1.1.1.3.cmml"><mn id="S5.T3.8.8.1.m1.1.1.3.2" xref="S5.T3.8.8.1.m1.1.1.3.2.cmml">10</mn><mo id="S5.T3.8.8.1.m1.1.1.3.1" xref="S5.T3.8.8.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.1.m1.1b"><apply id="S5.T3.8.8.1.m1.1.1.cmml" xref="S5.T3.8.8.1.m1.1.1"><gt id="S5.T3.8.8.1.m1.1.1.1.cmml" xref="S5.T3.8.8.1.m1.1.1.1"></gt><apply id="S5.T3.8.8.1.m1.1.1.2.cmml" xref="S5.T3.8.8.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T3.8.8.1.m1.1.1.2.1.cmml" xref="S5.T3.8.8.1.m1.1.1.2">subscript</csymbol><ci id="S5.T3.8.8.1.m1.1.1.2.2.cmml" xref="S5.T3.8.8.1.m1.1.1.2.2">𝐹</ci><ci id="S5.T3.8.8.1.m1.1.1.2.3a.cmml" xref="S5.T3.8.8.1.m1.1.1.2.3"><mtext id="S5.T3.8.8.1.m1.1.1.2.3.cmml" mathsize="70%" xref="S5.T3.8.8.1.m1.1.1.2.3">error</mtext></ci></apply><apply id="S5.T3.8.8.1.m1.1.1.3.cmml" xref="S5.T3.8.8.1.m1.1.1.3"><csymbol cd="latexml" id="S5.T3.8.8.1.m1.1.1.3.1.cmml" xref="S5.T3.8.8.1.m1.1.1.3.1">percent</csymbol><cn id="S5.T3.8.8.1.m1.1.1.3.2.cmml" type="integer" xref="S5.T3.8.8.1.m1.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.1.m1.1c">F_{\text{error}}&gt;10\%</annotation><annotation encoding="application/x-llamapun" id="S5.T3.8.8.1.m1.1d">italic_F start_POSTSUBSCRIPT error end_POSTSUBSCRIPT &gt; 10 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.8.8.2">0.0 %</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.8.8.3">0.6442 %</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">Comparing the mean error inside and outside the training domain, one can observe that there is an increase in the mean relative error for both models. However, the increase is not significant, with mean error values remaining less than 1.7% for both models and both subsets. A similar trend is observed for the standard deviation and the maximum of the relative errors. This behaviour is expected since extrapolation is being performed to unseen data domains. Notably, both models demonstrate favorable performance in predicting inside and outside the training domain. When predicting inside the training domain, none of the predictions resulted in errors greater than 10%, and only a minimal fraction of points have errors greater than 10% when predicting outside the training domain. This indicates that both models perform well in extrapolating to new domains, maintaining acceptable error values with mean errors smaller than 1.7%.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The difference between the CVAE generative model and the DNN predictive model lies in their distinct approaches: DNN learns the input-output mapping of the training data in a supervised way, while CVAE learns the underlying distribution of the training data in an unsupervised way and generates synthetic data by sampling from the learned distribution. Since CVAE does not learn direct mapping between the input and output, one would expect it to perform less accurate when compared to a fine-tuned DNN model that is trained for regression tasks. However, our findings showed that the CVAE generative model can be powerful in generating synthetic CHF values, even when compared to DNN. The CVAE model maintained favorable values in all error metrics when compared to the results of a single DNN model.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The UQ analysis of the CVAE model showed that its generative predictions have small variations at a specific input. This is demonstrated by the very small mean relative standard deviations of its predictions, which is 0.2579%. Additionally, changes in all metric values were very small when comparing the UQ and non-UQ resuts, as shown in Tables <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T1" title="Table 1 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T2" title="Table 2 ‣ 5.2 Results of UQ ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>. These indicate that the CVAE model has low sensitivity to the random samples from the latent vector during the generation process. The CVAE model is thus robust, consistently maintaining similar error behavior across multiple predictions. This consistency indicates that, although the model produces slightly different outputs each time, the predictions will remain within the quantified error ranges, ensuring reliable performance even with variations in the latent vectors.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">On the other hand, quantifying uncertainties for the DNN model requires training multiple DNNs and measuring the variations between their predictions, which is more laborious than the CVAE model. The ensembled results showed significant improvement in all error metrics, except for the maximum error value, as shown in Tables <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T1" title="Table 1 ‣ 5.1 Results of CHF Generation and Prediction using CVAE and DNN ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.05790v1#S5.T2" title="Table 2 ‣ 5.2 Results of UQ ‣ 5 Results ‣ Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">This improvement can be attributed to the DNN model’s high sensitivity to weight initialization during training. Averaging over an ensemble of DNNs can thus produce more accurate predictions.</p>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1">A ML model is generally expected to perform well for interpolation tasks, that is, when the model is applied to cases within the training domain. The ability of a ML model to extrapolate to new domains is important, especially if we aim to expand an existing dataset or test new experimental conditions.</p>
</div>
<div class="ltx_para" id="S6.p6">
<p class="ltx_p" id="S6.p6.1">The domain generalization analysis showed that the CVAE and DNN models are reliable in generating and predicting CHF values outside the training domain. Both models showed consistent results when predicting both inside and outside the training domain. The mean relative absolute errors were smaller when predicting within the training domain, with a slight increase when predicting outside the training domain. The maximum relative absolute errors occurred when predicting outside the training domain. However, both models maintained their favorable performance in predicting CHF values within and outside the domain. With no predicted points having an absolute relative error greater than 10% within the training domain for both models, and less than 1% of points having an error greater than 10% when predicting outside the training domain. This indicates that both models were successful in extrapolating to new, unseen domains.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This study investigated the use of a Conditional Variational Autoencoders (CVAE) model in generation of critical heat flux (CHF) values and compared its performance with a traditional deep neural network (DNN) predictive model. This work was performed using the publicly-available CHF dataset used to construct the 2006 Groeneveld lookup table, consisting of nearly <math alttext="25{,}000" class="ltx_Math" display="inline" id="S7.p1.1.m1.2"><semantics id="S7.p1.1.m1.2a"><mrow id="S7.p1.1.m1.2.3.2" xref="S7.p1.1.m1.2.3.1.cmml"><mn id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml">25</mn><mo id="S7.p1.1.m1.2.3.2.1" xref="S7.p1.1.m1.2.3.1.cmml">,</mo><mn id="S7.p1.1.m1.2.2" xref="S7.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.2b"><list id="S7.p1.1.m1.2.3.1.cmml" xref="S7.p1.1.m1.2.3.2"><cn id="S7.p1.1.m1.1.1.cmml" type="integer" xref="S7.p1.1.m1.1.1">25</cn><cn id="S7.p1.1.m1.2.2.cmml" type="integer" xref="S7.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.2c">25{,}000</annotation><annotation encoding="application/x-llamapun" id="S7.p1.1.m1.2d">25 , 000</annotation></semantics></math> data points. Both the CVAE and DNN models were trained and tested using identical data partitions to ensure a direct comparison between them. The CVAE generative model demonstrated favorable test results across all error metrics when compared to a standalone DNN predictive model.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Uncertainty quantification (UQ) was then performed for both models to evaluate their robustness and consistency. For the CVAE model, we generated 200 samples from the latent vector and combined them with each input entry in the testing dataset before entering the decoder to generate a CHF value. In this way, the CVAE model produces 200 CHF values for each data point in the testing dataset, which can be used to get the uncertainty in the CVAE generated data and provide insight into the variability of the model’s predictions.
For the DNN model, an ensemble was created by training 20 models of identical architecture with different initializations of the weights and biases. Similar to the CVAE, this produces a set of 20 “samples” for each data point in the testing dataset. The means and relative standard deviations were then taken along the samples of each testing data point.
The UQ analysis revealed that the CVAE model had significantly smaller relative standard deviations when compared to the DNN ensemble. The CVAE generative model thus has a higher confidence and lower variability in its outputs than the DNN predictive model.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.6">In the subsequent domain generalization analysis, the sampled CVAE and DNN ensemble’s outputs were then segmented into those inside and outside of the training set’s domain to evaluate how their performance changes when extrapolating. Both CVAE and DNN models exhibited strong extrapolation capabilities to the data outside the training domain. Inside the training domain, the mean error for the CVAE was <math alttext="1.23" class="ltx_Math" display="inline" id="S7.p3.1.m1.1"><semantics id="S7.p3.1.m1.1a"><mn id="S7.p3.1.m1.1.1" xref="S7.p3.1.m1.1.1.cmml">1.23</mn><annotation-xml encoding="MathML-Content" id="S7.p3.1.m1.1b"><cn id="S7.p3.1.m1.1.1.cmml" type="float" xref="S7.p3.1.m1.1.1">1.23</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.1.m1.1c">1.23</annotation><annotation encoding="application/x-llamapun" id="S7.p3.1.m1.1d">1.23</annotation></semantics></math>%, and for DNN ensemble, it was <math alttext="0.74" class="ltx_Math" display="inline" id="S7.p3.2.m2.1"><semantics id="S7.p3.2.m2.1a"><mn id="S7.p3.2.m2.1.1" xref="S7.p3.2.m2.1.1.cmml">0.74</mn><annotation-xml encoding="MathML-Content" id="S7.p3.2.m2.1b"><cn id="S7.p3.2.m2.1.1.cmml" type="float" xref="S7.p3.2.m2.1.1">0.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.2.m2.1c">0.74</annotation><annotation encoding="application/x-llamapun" id="S7.p3.2.m2.1d">0.74</annotation></semantics></math>%. Outside the training domain, the mean error increased to <math alttext="1.67" class="ltx_Math" display="inline" id="S7.p3.3.m3.1"><semantics id="S7.p3.3.m3.1a"><mn id="S7.p3.3.m3.1.1" xref="S7.p3.3.m3.1.1.cmml">1.67</mn><annotation-xml encoding="MathML-Content" id="S7.p3.3.m3.1b"><cn id="S7.p3.3.m3.1.1.cmml" type="float" xref="S7.p3.3.m3.1.1">1.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.3.m3.1c">1.67</annotation><annotation encoding="application/x-llamapun" id="S7.p3.3.m3.1d">1.67</annotation></semantics></math>% for the CVAE model and <math alttext="1.00" class="ltx_Math" display="inline" id="S7.p3.4.m4.1"><semantics id="S7.p3.4.m4.1a"><mn id="S7.p3.4.m4.1.1" xref="S7.p3.4.m4.1.1.cmml">1.00</mn><annotation-xml encoding="MathML-Content" id="S7.p3.4.m4.1b"><cn id="S7.p3.4.m4.1.1.cmml" type="float" xref="S7.p3.4.m4.1.1">1.00</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.4.m4.1c">1.00</annotation><annotation encoding="application/x-llamapun" id="S7.p3.4.m4.1d">1.00</annotation></semantics></math>% for the DNN ensemble. Both models performed generally well, with no predictions exceeding a <math alttext="10" class="ltx_Math" display="inline" id="S7.p3.5.m5.1"><semantics id="S7.p3.5.m5.1a"><mn id="S7.p3.5.m5.1.1" xref="S7.p3.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S7.p3.5.m5.1b"><cn id="S7.p3.5.m5.1.1.cmml" type="integer" xref="S7.p3.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.5.m5.1c">10</annotation><annotation encoding="application/x-llamapun" id="S7.p3.5.m5.1d">10</annotation></semantics></math>% absolute relative error within the training domain and less than <math alttext="1" class="ltx_Math" display="inline" id="S7.p3.6.m6.1"><semantics id="S7.p3.6.m6.1a"><mn id="S7.p3.6.m6.1.1" xref="S7.p3.6.m6.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S7.p3.6.m6.1b"><cn id="S7.p3.6.m6.1.1.cmml" type="integer" xref="S7.p3.6.m6.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.6.m6.1c">1</annotation><annotation encoding="application/x-llamapun" id="S7.p3.6.m6.1d">1</annotation></semantics></math>% of predictions exceeding this threshold outside the training domain.</p>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1">Overall, the CVAE generative model has proved to be an effective and reliable approach for generating CHF values, with low variability in predictions and consistent performance even when extrapolating to new domains. The UQ capabilities of CVAE are built-in with relative ease in creating multiple samples per input, especially when compared to the multimodel requirements of a DNN ensemble. These findings highlight the potential of CVAE for data augmentation applications in nuclear engineering and other fields requiring accurate and reliable predictions with quantified uncertainty. In future work, we intend to investigate the potential enhancement of CVAE performance in new domains through the use of transfer learning. It may also be worthwhile to explore the application of other deep generative techniques, such as diffusion models, for data augmentation.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work was funded by the U.S. Department of Energy (DOE) Office of Nuclear Energy Distinguished Early Career Program (DECP) under award number DE-NE0009467. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the U.S. DOE.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
L. Ruthotto, E. Haber, An introduction to deep generative modeling, GAMM-Mitteilungen 44 (2) (2021) e202100008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
R. Salakhutdinov, Learning deep generative models, Annual Review of Statistics and Its Application 2 (1) (2015) 361–385.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, Generative adversarial nets, Advances in neural information processing systems 27.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
D. P. Kingma, M. Welling, Auto-encoding variational bayes, arXiv preprint arXiv:1312.6114.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
D. Rezende, S. Mohamed, Variational inference with normalizing flows, in: International conference on machine learning, PMLR, 2015, pp. 1530–1538.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, S. Ganguli, Deep unsupervised learning using nonequilibrium thermodynamics, in: International conference on machine learning, PMLR, 2015, pp. 2256–2265.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
D. M. Blei, A. Kucukelbir, J. D. McAuliffe, Variational inference: A review for statisticians, Journal of the American statistical Association 112 (518) (2017) 859–877.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H. Nishizaki, Data augmentation and feature extraction using variational autoencoder for acoustic modeling, in: 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), IEEE, 2017, pp. 1222–1227.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
D. Papadopoulos, V. D. Karalis, Variational autoencoders for data augmentation in clinical studies, Applied Sciences 13 (15) (2023) 8793.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
V. Shwetha, K. Prasad, C. Mukhopadhyay, B. Banerjee, Data augmentation for gram-stained smear images based on vector quantized variational autoencoder, Neurocomputing (2024) 128123.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
C. Liu, R. Antypenko, I. Sushko, O. Zakharchenko, Intrusion detection system after data augmentation schemes based on the vae and cvae, IEEE Transactions on Reliability 71 (2) (2022) 1000–1010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y. S. Lee, J. Chen, Developing semi-supervised latent dynamic variational autoencoders to enhance prediction performance of product quality, Chemical Engineering Science 265 (2023) 118192.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Walker, C. Doersch, A. Gupta, M. Hebert, An uncertain future: Forecasting from static images using variational autoencoders, in: European Conference on Computer Vision, Springer, 2016, pp. 835–851.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
C. K. Sønderby, J. Caballero, L. Theis, W. Shi, F. Huszár, Amortised map inference for image super-resolution, arXiv preprint arXiv:1610.04490.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. P. Mentzelopoulos, D. Fan, T. P. Sapsis, M. S. Triantafyllou, Variational autoencoders and transformers for multivariate time-series generative modeling and forecasting: Applications to vortex-induced vibrations, Ocean Engineering 310 (2024) 118639.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
R. Laubscher, P. Rousseau, Application of generative deep learning to predict temperature, flow and species distributions using simulation data of a methane combustor, International Journal of Heat and Mass Transfer 163 (2020) 120417.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Guo, Y. Wang, X. Sun, S. Liu, B. Du, Imbalanced data fault diagnosis method for nuclear power plants based on convolutional variational autoencoding wasserstein generative adversarial network and random forest, Nuclear Engineering and Technology.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
K. Sohn, H. Lee, X. Yan, Learning structured output representation using deep conditional generative models, Advances in neural information processing systems 28.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
G. Mu, J. Chen, Developing a conditional variational autoencoder to guide spectral data augmentation for calibration modeling, IEEE Transactions on Instrumentation and Measurement 71 (2022) 1–8.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Y. Zhang, S. Huang, X. Peng, D. Yang, Dizygotic conditional variational autoencoder for multi-modal and partial modality absent few-shot learning, arXiv preprint arXiv:2106.14467.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y. Ruan, M. Zheng, F. Qian, H. Meng, J. Yao, T. Xu, D. Pei, Fault detection and diagnosis of energy system based on deep learning image recognition model under the condition of imbalanced samples, Applied Thermal Engineering 238 (2024) 122051.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
F. Alsafadi, X. Wu, Deep generative modeling-based data augmentation with demonstration using the bfbt benchmark void fraction datasets, Nuclear Engineering and Design 415 (2023) 112712.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D. Groeneveld, J. Shan, A. Vasić, L. Leung, A. Durmayaz, J. Yang, S. Cheng, A. Tanase, The 2006 chf look-up table, Nuclear engineering and design 237 (15-17) (2007) 1909–1922.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D. C. Groeneveld, Critical heat flux data used to generate the 2006 groeneveld lookup tables, Tech. rep., NUREG/KM-0011, Office of Nuclear Regulatory Research, U.S. Nuclear Regulatory Commission (NRC) (2019).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
A. S. Nafey, Neural network based correlation for critical heat flux in steam-water flows in pipes, International Journal of Thermal Sciences 48 (12) (2009) 2264–2270.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T. Xie, S. Ghiaasiaan, S. Karrila, T. McDonough, Hybrid neural network-first principles modeling of critical heat flux in a thin annular channel, in: ASME International Mechanical Engineering Congress and Exposition, Vol. 36347, 2002, pp. 227–236.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Y. H. Lee, W.-P. Baek, S. H. Chang, A correction method for heated length effect in critical heat flux prediction, Nuclear engineering and design 199 (1-2) (2000) 1–11.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
X. Zhao, K. Shirvan, R. K. Salko, F. Guo, On the prediction of critical heat flux using a physics-informed machine learning-aided framework, Applied Thermal Engineering 164 (2020) 114540.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
N. Vaziri, A. Hojabri, A. Erfani, M. Monsefi, B. Nilforooshan, Critical heat flux prediction by using radial basis function and multilayer perceptron neural networks: a comparison study, Nuclear engineering and design 237 (4) (2007) 377–385.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
K. Gundersen, A. Oleynik, N. Blaser, G. Alendal, Semi-conditional variational auto-encoder for flow reconstruction and uncertainty quantification from limited observations, Physics of Fluids 33 (1).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
M. Abadi, A. Agarwal, P. Barham, et al., Tensorflow: Large-scale machine learning on heterogeneous distributed systems, arXiv preprint arXiv:1603.04467.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
R. Liaw, E. Liang, R. Nishihara, P. Moritz, J. E. Gonzalez, I. Stoica, Tune: A research platform for distributed model selection and training, arXiv preprint arXiv:1807.05118.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J. Gawlikowski, C. R. N. Tassi, M. Ali, J. Lee, M. Humt, J. Feng, A. Kruspe, R. Triebel, P. Jung, R. Roscher, et al., A survey of uncertainty in deep neural networks, Artificial Intelligence Review 56 (Suppl 1) (2023) 1513–1589.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
B. Lakshminarayanan, A. Pritzel, C. Blundell, Simple and scalable predictive uncertainty estimation using deep ensembles, Advances in neural information processing systems 30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Y. LeCun, Y. Bengio, G. Hinton, Deep learning, nature 521 (7553) (2015) 436–444.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep  9 16:45:48 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
