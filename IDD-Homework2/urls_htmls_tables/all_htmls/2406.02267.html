<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation</title>
<!--Generated on Tue Jun  4 12:42:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.02267v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S1" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S2" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Prior Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S3" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data and Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S4" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Feedback Collection</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S4.SS1" title="In 4 Feedback Collection ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Human Annotation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S4.SS2" title="In 4 Feedback Collection ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Annotation Statistics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S5" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S5.SS1" title="In 5 Experiments ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S5.SS2" title="In 5 Experiments ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S6" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S7" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S8" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Acknowledgements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#A1" title="In Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#A1.SS1" title="In Appendix A Appendix ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Example Prompts</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nathaniel Berger<sup class="ltx_sup" id="id8.8.id1"><span class="ltx_text ltx_font_italic" id="id8.8.id1.1">a</span></sup>  and Stefan Riezler<sup class="ltx_sup" id="id9.9.id2"><span class="ltx_text ltx_font_italic" id="id9.9.id2.1">ab</span></sup>
<br class="ltx_break"/>Computational Linguistics<sup class="ltx_sup" id="id10.10.id3"><span class="ltx_text ltx_font_italic" id="id10.10.id3.1">a</span></sup> &amp; IWR<sup class="ltx_sup" id="id11.11.id4"><span class="ltx_text ltx_font_italic" id="id11.11.id4.1">b</span></sup>
<br class="ltx_break"/>Heidelberg University 
<br class="ltx_break"/>69120 Heidelberg, Germany 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id12.12.id5">berger@cl.uni-heidelberg.de</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id13.13.id6">riezler@cl.uni-heidelberg.de</span> &amp;Miriam Exel<sup class="ltx_sup" id="id14.14.id7"><span class="ltx_text ltx_font_italic" id="id14.14.id7.1">c</span></sup> and Matthias Huck<sup class="ltx_sup" id="id15.15.id8"><span class="ltx_text ltx_font_italic" id="id15.15.id8.1">c</span></sup>
<br class="ltx_break"/>SAP SE<sup class="ltx_sup" id="id16.16.id9"><span class="ltx_text ltx_font_italic" id="id16.16.id9.1">c</span></sup>
<br class="ltx_break"/>Dietmar-Hopp-Allee 16 
<br class="ltx_break"/>69190 Walldorf, Germany 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id17.17.id10">miriam.exel@sap.com
<br class="ltx_break"/>matthias.huck@sap.com</span>
</span><span class="ltx_author_notes">  The work was done as part of an SAP sponsored PhD project of the first author.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id18.id1">While large language models (LLMs) pre-trained on massive amounts of unpaired language data have reached the state-of-the-art in machine translation (MT) of general domain texts, post-editing (PE) is still required to correct errors and to enhance term translation quality in specialized domains. In this paper we present a pilot study of enhancing translation memories (TM) produced by PE (source segments, machine translations, and reference translations, henceforth called PE-TM) for the needs of correct and consistent term translation in technical domains.</p>
<p class="ltx_p" id="id19.id2">We investigate a light-weight two-step scenario where, at inference time, a human translator marks errors in the first translation step, and in a second step a few similar examples are extracted from the PE-TM to prompt an LLM. Our experiment shows that the additional effort of augmenting translations with human error markings guides the LLM to focus on a correction of the marked errors, yielding consistent improvements over automatic PE (APE) and MT from scratch.</p>
</div>
<figure class="ltx_figure" id="S0.F1"><svg class="ltx_picture" height="305.53" id="S0.F1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,305.53) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 0 L 0 305.53 L 600 305.53 L 600 0 Z" style="stroke:none"></path></g><g fill="#BFBFBF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 303.56 L 598.03 303.56 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="277.97" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20" style="width:402.3pt;">
<span class="ltx_p" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.21">Read the English text and the German translation hypothesis and then correct the output.</span>
<span class="ltx_p" id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4">Incorrect words are inside of tags ’<math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><lt id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1"><semantics id="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1a"><mo id="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1.1" xref="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1b"><gt id="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1.1.cmml" xref="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.m1.1d">&gt;</annotation></semantics></math> <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1"><semantics id="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1a"><mo id="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1.1" xref="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1b"><lt id="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1.1.cmml" xref="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2.m2.1d">&lt;</annotation></semantics></math>/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1"><semantics id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1a"><mo id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1.1" xref="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1b"><gt id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1.1.cmml" xref="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.3.m3.1d">&gt;</annotation></semantics></math></span>’. Please use this feedback in your correction.</span>
<span class="ltx_p" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.22">If the hypothesis is already correct, do not make any changes.</span>
<span class="ltx_p" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.23">English: This environment variable can also be used to make sure that other operations are working on uploaded files, as well.</span>
<span class="ltx_p" id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16">Hypothesis: Dieses <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1"><semantics id="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1a"><mo id="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1" xref="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1b"><lt id="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1"><semantics id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1a"><mo id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1" xref="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1b"><gt id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.cmml" xref="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1d">&gt;</annotation></semantics></math></span> Umweltvariable <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1"><semantics id="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1a"><mo id="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1" xref="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1b"><lt id="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1.cmml" xref="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1"><semantics id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1a"><mo id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1" xref="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1b"><gt id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1.cmml" xref="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1d">&gt;</annotation></semantics></math></span> kann auch verwendet werden , um sicherzustellen , dass andere <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1"><semantics id="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1a"><mo id="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1" xref="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1b"><lt id="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1.cmml" xref="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1"><semantics id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1a"><mo id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1.1" xref="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1b"><gt id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1.1.cmml" xref="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.3.m1.1d">&gt;</annotation></semantics></math></span> Operationen auf <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1"><semantics id="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1a"><mo id="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1.1" xref="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1b"><lt id="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1.1.cmml" xref="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m4.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1"><semantics id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1a"><mo id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1.1" xref="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1b"><gt id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1.1.cmml" xref="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.4.m1.1d">&gt;</annotation></semantics></math></span> hochgeladene Dateien <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1"><semantics id="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1a"><mo id="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1" xref="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1b"><lt id="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1.cmml" xref="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1"><semantics id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1a"><mo id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1.1" xref="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1b"><gt id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1.1.cmml" xref="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.5.m1.1d">&gt;</annotation></semantics></math></span> arbeiten <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1"><semantics id="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1a"><mo id="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1.1" xref="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1b"><lt id="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1.1.cmml" xref="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m6.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1"><semantics id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1a"><mo id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1.1" xref="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1b"><gt id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1.1.cmml" xref="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.6.m1.1d">&gt;</annotation></semantics></math></span> .</span>
<span class="ltx_p" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.24">German: Mittels dieser Umgebungsvariable kann auch sichergestellt werden, dass auch andere Operationen an hochgeladenen Dateien arbeiten können.</span>
<span class="ltx_p" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.25">English: Some important environment variables used by KDE</span>
<span class="ltx_p" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20">Hypothesis: Einige wichtige <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1"><semantics id="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1a"><mo id="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1" xref="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1b"><lt id="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1.cmml" xref="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1"><semantics id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1a"><mo id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1" xref="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1b"><gt id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1.cmml" xref="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1d">&gt;</annotation></semantics></math></span> Umweltvariablen <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1"><semantics id="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1a"><mo id="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1" xref="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1b"><lt id="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1.cmml" xref="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1"><semantics id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1a"><mo id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1" xref="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1b"><gt id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1.cmml" xref="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1d">&gt;</annotation></semantics></math></span> , die von KDE verwendet werden</span>
<span class="ltx_p" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.26"><span class="ltx_text ltx_font_bold" id="S0.F1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.26.1">German: Einige wichtige Umgebungsvariablen, die von KDE verwendet werden
<br class="ltx_break"/></span></span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example of a 1-shot prompt for English-to-German Translation. Error markings are inside bold faced tags <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.5.m1.1"><semantics id="S0.F1.5.m1.1b"><mo id="S0.F1.5.m1.1.1" xref="S0.F1.5.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.5.m1.1c"><lt id="S0.F1.5.m1.1.1.cmml" xref="S0.F1.5.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.5.m1.1d">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.5.m1.1e">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S0.F1.8.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.6.1.m1.1"><semantics id="S0.F1.6.1.m1.1b"><mo id="S0.F1.6.1.m1.1.1" xref="S0.F1.6.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.6.1.m1.1c"><gt id="S0.F1.6.1.m1.1.1.cmml" xref="S0.F1.6.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.6.1.m1.1d">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.6.1.m1.1e">&gt;</annotation></semantics></math> <math alttext="&lt;" class="ltx_Math" display="inline" id="S0.F1.7.2.m2.1"><semantics id="S0.F1.7.2.m2.1b"><mo id="S0.F1.7.2.m2.1.1" xref="S0.F1.7.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.7.2.m2.1c"><lt id="S0.F1.7.2.m2.1.1.cmml" xref="S0.F1.7.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.7.2.m2.1d">&lt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.7.2.m2.1e">&lt;</annotation></semantics></math>/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S0.F1.8.3.m3.1"><semantics id="S0.F1.8.3.m3.1b"><mo id="S0.F1.8.3.m3.1.1" xref="S0.F1.8.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S0.F1.8.3.m3.1c"><gt id="S0.F1.8.3.m3.1.1.cmml" xref="S0.F1.8.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.8.3.m3.1d">&gt;</annotation><annotation encoding="application/x-llamapun" id="S0.F1.8.3.m3.1e">&gt;</annotation></semantics></math></span>. The demonstration example consists of a source segment in English (in green), a translation hypothesis in German (in blue), and a correction (in red). The test example shows a correction of the translation of ”environment variable” from ”Umweltvariable” into ”Umgebungsvariable” learned by the LLM (in bold-faced red).</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Technical translation at large enterprises involves a large number of translation domains, for which translation memories and terminologies need to be maintained to support multi-domain MT systems and human post-editors in producing contextually adequate and consistent translation of technical terms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx3" title="">Exel et al., 2020</a>]</cite>. In this paper, we ask if ongoing human post-editing efforts that produce large databases consisting of source segments, machine translations, and reference translations, can be enhanced by light-weight human error markings.
This could then be used to teach a translation system a focused self-correction of marked erroneous tokens from similar examples with error markings and corrections found in the PE-TM. Such a setup could complement translation memories and terminology databases by up-to-date and domain-specific information in the PE-TM, and be used in a scenario where a user marks errors in MT hypotheses. In-context examples with high source-side similarity are then extracted from the PE-TM to prompt an LLM to focus on a correction of the marked error interactively.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">We present a pilot study where we construct a PE-TM for the IT domain, which is augmented by human error markings on machine translations. While for training purposes, error markings for the PE-TM could be obtained by automatic matching against human post-edits, this cannot be done at test time. We envisage a scenario where the error markings in the PE-TM are obtained by direct human annotation, simulating a realistic setup where a user only performs the light-weight task of error marking at test time.
Such a scenario could be feedback collection in the publishing of raw-MT. Raw-MT could be shown to end-users who, if they notice an error in the translation, proceed to annotate tokens in the translation they perceive to be incorrect. The translation would then be flagged for review by a human translator, who then post-edits the translation and publishes their correction. This process results in the creation of (source, hypothesis, post-edit) triples with annotations for the PE-TM.
This PE-TM is used to provide in-context examples for LLM correction of annotated translation hypotheses. For example, the end-user who annotates raw-MT could then immediately be shown a new translation that takes the error markings into account.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The results of our study show that selecting in-context examples based on similarity of source-side embeddings and providing error markings on hypotheses lets the LLM infer focused corrections of marked errors. Furthermore, overall translation quality is improved over few-shot prompt-based translation and over automatic post-editing. An example 1-shot prompt and error-marked output is given in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S0.F1" title="Figure 1 ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Prior Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The last year has seen a progression of the translation capabilities of decoder-only LLMs, pre-trained on unpaired language data, from lagging behind supervised systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx30" title="">Vilar et al., 2023</a>]</cite> to matching their translation quality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx4" title="">Garcia et al., 2023</a>]</cite>, with only 5 examples of high-quality translation data used for in-context learning. However, MT in specialized domains still requires translation post-editing in order to correct errors and to enhance term translation quality. Raunak et al., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx22" title="">Raunak et al., 2023</a>]</cite> recently showed that very large LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx17" title="">OpenAI, 2023</a>]</cite> can perform zero-shot automatic translation post-editing for general domain data, at the price of hallucinated edits. This makes this setup impractical if high precision in domain-specific translation is key. For these purposes, manually crafted glossaries <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx29" title="">Vidal et al., 2022</a>]</cite>, dictionaries extracted in a separate step of unsupervised word-alignment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx5" title="">Ghazvininejad et al., 2023</a>]</cite>, or translation memories accessed with fuzzy matching <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx16" title="">Moslem et al., 2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx8" title="">Hoang et al., 2023</a>]</cite>, have been used to aid prompt-based MT. Our approach combines PE-TMs with light-weight human error markings, achieving improvements over both APE and MT from scratch.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The standard paradigm to incorporate token-level human error markings as learning signal is an adaptation of supervised learning from post-edits (see, for example, <span class="ltx_text ltx_font_bold" id="S2.p2.1.1">?</span>)) by penalizing erroneous tokens and rewarding correct tokens in a weighted maximum-likelihood objective
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx15" title="">Marie and Max, 2015</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx2" title="">Domingo et al., 2017</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx20" title="">Petrushkov et al., 2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx13" title="">Lam et al., 2019</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx11" title="">Kreutzer et al., 2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx1" title="">Berger et al., 2023</a>]</cite>. Most approaches are conceptualized as fine-tuning applications, with error markings obtained by automatic matching against human post-edits or by direct human annotation. The approach that is closest to our work is QuickEdit <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx7" title="">Grangier and Auli, 2018</a>]</cite>. They train a model with separate encoders for source and error-marked hypothesis in order to improve upon the initial hypothesis by avoiding the marked tokens. Similar to our approach, QuickEdit requires error-markings at inference time.
While QuickEdit relies on supervised learning, our approach succeeds in teaching an LLM to avoid marked tokens from a few demonstration examples of similar error patterns.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">More recent work by Xu et al., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx32" title="">Xu et al., 2023</a>]</cite> successfully uses feedback in form of error type and location that is predicted by a learned error pinpoint model. Their work focuses on general domain translation and quality-estimation type feedback, in difference to the focused error markings on technical terms that we are interested in. We plan an extension of our work in the direction of using learned error markings in future work.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Our work is furthermore related to the more general issue of self-correction capabilities of LLMs. Similar to the findings of Huang et al., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx9" title="">Huang et al., 2023</a>]</cite>, our work shows that in order to qualify as a correction rather than a mere change, automatic self-correction in LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx14" title="">Madaan et al., 2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx18" title="">Pan et al., 2023</a>]</cite> needs to be guided by an oracle.
In our case, the oracle consists of feedback on the errors in translation outputs of an LLM, combined with a few examples of similar errors and their reference translations.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data and Models</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We collected English and German parallel data from open source software documentation and localization available on OPUS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx26" title="">Tiedemann, 2012</a>]</cite>, as this data comes closest to our domain of interest. We concatenated data from <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">GNOME</span>, <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">KDE4</span>, <span class="ltx_text ltx_font_italic" id="S3.p1.1.3">KDEdoc</span>, <span class="ltx_text ltx_font_italic" id="S3.p1.1.4">PHP</span>, and <span class="ltx_text ltx_font_italic" id="S3.p1.1.5">Ubuntu</span> to create our data set and filtered them with the following methods: we removed those segments containing fewer than five words or more than 25, those identified by fastText <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx10" title="">Joulin et al., 2017</a>]</cite> as the wrong language, those with more than 20% of characters being non-alphanumeric, and those containing personally identifiable information. Of the remaining data, we selected a subset of <math alttext="1,500" class="ltx_Math" display="inline" id="S3.p1.1.m1.2"><semantics id="S3.p1.1.m1.2a"><mrow id="S3.p1.1.m1.2.3.2" xref="S3.p1.1.m1.2.3.1.cmml"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">1</mn><mo id="S3.p1.1.m1.2.3.2.1" xref="S3.p1.1.m1.2.3.1.cmml">,</mo><mn id="S3.p1.1.m1.2.2" xref="S3.p1.1.m1.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.2b"><list id="S3.p1.1.m1.2.3.1.cmml" xref="S3.p1.1.m1.2.3.2"><cn id="S3.p1.1.m1.1.1.cmml" type="integer" xref="S3.p1.1.m1.1.1">1</cn><cn id="S3.p1.1.m1.2.2.cmml" type="integer" xref="S3.p1.1.m1.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.2c">1,500</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.2d">1 , 500</annotation></semantics></math> examples.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">For the purposes of this experiment, we were interested in models that support prompt-based interaction. Furthermore, we are interested in the scenario where users use their judgment to guide a model towards a better translation based upon its original translation. Large language models lend themselves well to this interaction because the same model can be used with prompt-based interaction to produce the original translations as well as for providing extra information to aid in correction. These considerations decide in favor of using an LLM over a traditional encoder-decoder based model typically used in production scenarios. Therefore, we examine if the model that produced the hypothesis, Llama 13B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx27" title="">Touvron et al., 2023</a>]</cite>, can leverage feedback to correct its own mistakes. In addition to choosing this model because it supports prompting, it runs on a single GPU<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>For all Llama 13B experiments, we use a single Nvidia A40 GPU with 48GB VRAM on a shared server</span></span></span>, and the model will remain available in the future for reproducibility. The Llama model was converted to Huggingface Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx31" title="">Wolf et al., 2020</a>]</cite> format for inference. We found that Llama 13B frequently copies hypotheses including the error tags to its output as it was instructed not to make changes if the hypothesis is acceptable as-is. We therefore post-processed outputs by removing tags by regex.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Additionally, we test GPT-3.5<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>GPT-3.5-Turbo-0613 was used for all experiments involving OpenAI’s GPT models in this paper</span></span></span> in order to test a model larger than we can locally run. We use the ”ChatCompletion” API, send the query as the ’user’ message, and set the temperature to <math alttext="0" class="ltx_Math" display="inline" id="S3.p3.1.m1.1"><semantics id="S3.p3.1.m1.1a"><mn id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><cn id="S3.p3.1.m1.1.1.cmml" type="integer" xref="S3.p3.1.m1.1.1">0</cn></annotation-xml></semantics></math>. All hypotheses were generated with the above models using greedy decoding.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><svg class="ltx_picture" height="369.03" id="S3.F2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,369.03) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 0 L 0 369.03 L 600 369.03 L 600 0 Z" style="stroke:none"></path></g><g fill="#BFBFBF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 367.06 L 598.03 367.06 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="341.47" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.F2.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S3.F2.pic1.1.1.1.1.1.1">You will receive an annotation task called “Error Annotation”; the goal of this task is to mark each word in the machine translation as correct or incorrect. By default, all words are considered correct. By clicking on target words, they are marked as incorrect.</span>
<span class="ltx_p" id="S3.F2.pic1.1.1.1.1.1.2">Here are the instructions in more detail:</span>
<span class="ltx_p" id="S3.F2.pic1.1.1.1.1.1.3">You will be shown an English source sentence above and its machine translation into German below.</span>
<span class="ltx_itemize" id="S3.I1">
<span class="ltx_item" id="S3.I1.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i1.p1">
<span class="ltx_p" id="S3.I1.i1.p1.1">Begin by reading the source sentence and then reading the translation.</span>
</span></span>
<span class="ltx_item" id="S3.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i2.p1">
<span class="ltx_p" id="S3.I1.i2.p1.1">Consider which words would need to be deleted or changed in order to arrive at a correct translation.</span>
</span></span>
<span class="ltx_item" id="S3.I1.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i3.p1">
<span class="ltx_p" id="S3.I1.i3.p1.1">Mark the incorrect words of the translation by clicking on them.</span>
</span></span>
<span class="ltx_item" id="S3.I1.i4" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i4.p1">
<span class="ltx_p" id="S3.I1.i4.p1.1">Clicking on the word causes a blue border to appear around the word. This word is now marked as incorrect.</span>
</span></span>
<span class="ltx_item" id="S3.I1.i5" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i5.p1">
<span class="ltx_p" id="S3.I1.i5.p1.1">Clicking a second time will remove the blue border and it is now marked correct.</span>
</span></span>
<span class="ltx_item" id="S3.I1.i6" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i6.p1">
<span class="ltx_p" id="S3.I1.i6.p1.1">Once all the incorrect words have a blue border, click on the “Next” button near the top of the page.</span>
</span></span>
<span class="ltx_item" id="S3.I1.i7" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i7.p1">
<span class="ltx_p" id="S3.I1.i7.p1.1">Markings should be kept minimal. Mark only those terms that you would edit or delete in a post-editing scenario.</span>
</span></span>
<span class="ltx_item" id="S3.I1.i8" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S3.I1.i8.p1">
<span class="ltx_p" id="S3.I1.i8.p1.1">If you would have to move a word to a different location, such as shifting a verb to the end of the sentence, mark it as incorrect.</span>
</span></span>
</span>
<span class="ltx_p" id="S3.F2.pic1.1.1.1.1.1.4">If the translation contains no correct words or the source words are translated word by word but do not make sense together, mark them all as incorrect.</span>
<span class="ltx_p" id="S3.F2.pic1.1.1.1.1.1.5">If the translation is correct as-is, proceed to the next annotation item.</span>
<span class="ltx_p" id="S3.F2.pic1.1.1.1.1.1.6">If you cannot judge the quality of the translation because the source sentence is not comprehensible, or you are lacking domain knowledge to annotate wrong words, click the Skip button (to the right of the “Next” button) and then proceed to the next sentence.</span>
<span class="ltx_p" id="S3.F2.pic1.1.1.1.1.1.7">The source sentences are taken from open-source software projects and documentation while the translations are produced by a generic machine translation system.</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Instructions given to annotators on how to mark errors in sentences, including how to use the interface and desired marking behavior</figcaption>
</figure>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Feedback Collection</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In order to simulate the previously proposed scenario of an end-user who annotates raw-MT errors, we turn to paid annotators. We generate translations of English source sentences and provide them with only the source and the hypothesis, as would be the case when getting feedback on raw-MT. These are then paired with references to create our PE-TM.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Human Annotation</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We hired three professional translators with expertise in the IT domain as annotators to provide token-level feedback on the translation hypotheses. Token-level feedback consisted of per-token binary quality judgements, OK/BAD. Annotators were provided English source sentences and German hypothesis translations in a custom annotation interface. Each token in the hypothesis was a button in the annotation interface and annotators were instructed to click on incorrect tokens to mark errors. Unmarked tokens were assumed OK. Additionally, they were instructed to keep markings minimal and only mark tokens that would be edited or deleted during post-editing.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Complete instructions are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S3.F2" title="Figure 2 ‣ 3 Data and Models ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>. Annotators could skip examples but must provide a reason. Reasons for skipping examples were ”Source Incomprehensible”, ”Source Ambiguous”, ”Missing Knowledge”, and ”Other”.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Annotation was split into two phases. Phase one was a trial run where all three annotators annotated the same 50 examples. In phase two, each annotator was given their own non-overlapping block of 500 source and hypothesis pairs. The phase one examples were used to compute summary statistics of annotation behavior, agreement coefficients, and to calibrate our instructions.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">After phase two, filtering out skipped examples or those without any BAD markings yields a data set of 982 examples. We split this data set into two subsets; one set of size 492 for in-context examples and a set of 490 for test examples.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Annotation Statistics</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Annotator 1 selected ”Source Ambiguous” as the reason for skipping once and ”Missing Knowledge” the other six times. Annotator 2 selected ”Source Incomprehensible” for their skip.
After removing the items skipped by any annotator, we have 43 examples that were annotated by all three.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Using the remaining common examples from phase one, we calculate the percentage of tokens marked per sentence and use that as a sentence-level quality judgment. This is then used to calculate Krippendorff’s alpha <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx12" title="">Krippendorff, 2004</a>]</cite> to determine if our annotators agree on overall translation quality. We also calculate alpha on the token level OK/BAD annotations.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.1">Annotator</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.2">1</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.3">2</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.4">3</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.1">Percent Marked on Average</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.2">0.25</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.3">0.17</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.4">0.17</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.3.2.1">SD of Percent Marked</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.3.2.2">0.28</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.3.2.3">0.18</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.3.2.4">0.19</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Marking behaviors of each annotator in terms of percent of tokens marked in the trial annotation.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.1.2.1.1">Annotator</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.2.1.2">2</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.2.1.3">3</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.3.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.3.1.1">1</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.1.3.1.2">0.258</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.1.3.1.3">0.481</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="S4.T2.1.1.2">2</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.1.1.1"><math alttext="\emptyset" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><mi id="S4.T2.1.1.1.m1.1.1" mathvariant="normal" xref="S4.T2.1.1.1.m1.1.1.cmml">∅</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><emptyset id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\emptyset</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.m1.1d">∅</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.1.1.3">0.222</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Inter-annotator agreement for percentage marked per sentence, given by Krippendorff’s Alpha.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T3.1.2.1.1">Annotator</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.2.1.2">2</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.2.1.3">3</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.3.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.3.1.1">1</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.1.2">0.445</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.1.3">0.531</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="S4.T3.1.1.2">2</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.1.1"><math alttext="\emptyset" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mi id="S4.T3.1.1.1.m1.1.1" mathvariant="normal" xref="S4.T3.1.1.1.m1.1.1.cmml">∅</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><emptyset id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\emptyset</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">∅</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.1.3">0.433</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Inter-annotator agreement for token classification, given by Krippendorff’s Alpha.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.2">We calculated pair-wise Krippendorff’s alpha in addition to the average agreement for both the sentence-level percentage marked and token-level annotations. The average amount of tokens marked for the unskipped sentences is visible in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S4.T1" title="Table 1 ‣ 4.2 Annotation Statistics ‣ 4 Feedback Collection ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>. Pairwise Krippendorff’s alphas for percentage marked is visible in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S4.T2" title="Table 2 ‣ 4.2 Annotation Statistics ‣ 4 Feedback Collection ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, while pairwise agreement for token classification is in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S4.T3" title="Table 3 ‣ 4.2 Annotation Statistics ‣ 4 Feedback Collection ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>. Average agreement for the percentage marked is <math alttext="\alpha=0.306" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">α</mi><mo id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">0.306</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><eq id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1"></eq><ci id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">𝛼</ci><cn id="S4.SS2.p3.1.m1.1.1.3.cmml" type="float" xref="S4.SS2.p3.1.m1.1.1.3">0.306</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\alpha=0.306</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">italic_α = 0.306</annotation></semantics></math> and for token classification <math alttext="\alpha=0.466" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">α</mi><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">0.466</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><eq id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"></eq><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">𝛼</ci><cn id="S4.SS2.p3.2.m2.1.1.3.cmml" type="float" xref="S4.SS2.p3.2.m2.1.1.3">0.466</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\alpha=0.466</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">italic_α = 0.466</annotation></semantics></math>. This suggests that, while agreement about overall sentence quality is not high, the reliability of classifying each token in the hypothesis is higher. These results were used to calibrate with the annotators after looking over the annotations made by each individual.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">After calibration, we then assigned each annotator their block of 500 examples to annotate. Annotator 1 skipped 6 of the 500 sentences and annotator 2 skipped 20. Percentage marked was lower for annotators 1 and 3 during the full annotation as more sentences were left completely unmarked. Annotator 1 left 36% of sentences unmarked; annotator 2 left 23%; and annotator 3 left 38%. The percentage that was marked per sentence was also reduced after calibration, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S4.T4" title="Table 4 ‣ 4.2 Annotation Statistics ‣ 4 Feedback Collection ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.1">Annotator</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.2">1</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.3">2</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.4">3</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.2.1">
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.1.2.1.1">Percent Marked on Average</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.1.2.1.2">0.10</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.1.2.1.3">0.19</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.1.2.1.4">0.09</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.3.2">
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T4.1.3.2.1">SD of Percent Marked</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T4.1.3.2.2">0.10</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T4.1.3.2.3">0.15</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S4.T4.1.3.2.4">0.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Marking behaviors of each annotator in terms of percent of tokens marked in the final annotation.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental Setup</h3>
<figure class="ltx_table" id="S5.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.1.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T5.1.1.1.1">Condition</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.2">BLEU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.3">TER</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.4">ME</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.5">UE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.6">% Correct ME</th>
</tr>
<tr class="ltx_tr" id="S5.T5.1.2.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S5.T5.1.2.2.1">Original Hyps</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.2">28.92</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.3">55.12</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.4">N.A.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.5">N.A.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.6">N.A.</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.1.3.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T5.1.3.1.1">MT (Llama/GPT)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.2">29.83/38.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.3">55.97/49.21</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.4">N.A.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.5">N.A.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.6">N.A.</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.4.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T5.1.4.2.1">APE (Llama/GPT)</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.2">29.79/39.09</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.3">54.56/48.37</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.4">7.30/76.70</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.5">1.76/15.85</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.6">32% / N.A.</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.5.3">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T5.1.5.3.1">MRK (Llama/GPT)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.3.2">30.09/39.31</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.3.3">54.70/48.32</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.3.4">14.76/78.36</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.3.5">3.60/13.90</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.5.3.6">67% / N.A.</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Results for both Llama 13B and GPT 3.5 across all metrics and translation scenarios (ME = Marking Edits, UE = Unmarking Edits, % Correct ME = Percentage of correct ME in manual evaluation).</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Using the annotated data, we considered three machine translation tasks: Machine translation from scratch (<span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.1">MT</span>); Automatic Post-editing (<span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.2">APE</span>); and Post-Editing with error markings (<span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.3">MRK</span>). Instructions were written for the LLM for each task and, for each example in the inference set, five examples were retrieved from the in-context example pool. We retrieve the most similar examples by using cosine similarity over SentenceTransformers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx24" title="">Reimers and Gurevych, 2019</a>]</cite> embeddings computed on source sentences only<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We used the model <span class="ltx_text ltx_font_italic" id="footnote3.1">all-MiniLM-L6-v2</span> and retrieved the examples with the highest cosine similarity.</span></span></span>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">In <span class="ltx_text ltx_font_italic" id="S5.SS1.p2.1.1">MT</span>, models were prompted to</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<blockquote class="ltx_quote ltx_displayquote" id="S5.SS1.p3.1">
<p class="ltx_p" id="S5.SS1.p3.1.1"><span class="ltx_text ltx_inline-quote" id="S5.SS1.p3.1.1.1">Translate English to German.</span></p>
</blockquote>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">and were shown five (source, reference) pairs. Full prompts can be found in the appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#A1.SS1" title="A.1 Example Prompts ‣ Appendix A Appendix ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">A.1</span></a>. For the <span class="ltx_text ltx_font_italic" id="S5.SS1.p4.1.1">APE</span> task, models were prompted to</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<blockquote class="ltx_quote ltx_displayquote" id="S5.SS1.p5.1">
<p class="ltx_p" id="S5.SS1.p5.1.1"><span class="ltx_text ltx_inline-quote" id="S5.SS1.p5.1.1.1">Read the English text and the German translation hypothesis and then correct the output. If the hypothesis is already correct, do not make any changes.</span></p>
</blockquote>
</div>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.1">With this prompt, the models were given triples of (source, hypothesis, reference) with the hypothesis from our annotated data set and the reference coming from the parallel data.</p>
</div>
<div class="ltx_para" id="S5.SS1.p7">
<p class="ltx_p" id="S5.SS1.p7.1">In the <span class="ltx_text ltx_font_italic" id="S5.SS1.p7.1.1">MRK</span> scenario, models were prompted to</p>
</div>
<div class="ltx_para" id="S5.SS1.p8">
<blockquote class="ltx_quote ltx_displayquote" id="S5.SS1.p8.4">
<p class="ltx_p" id="S5.SS1.p8.4.4"><span class="ltx_text ltx_inline-quote" id="S5.SS1.p8.4.4.4">Read the English text and the German translation hypothesis and then correct the output. Incorrect words are inside of tags ’<math alttext="&lt;" class="ltx_Math" display="inline" id="S5.SS1.p8.1.1.1.m1.1"><semantics id="S5.SS1.p8.1.1.1.m1.1a"><mo id="S5.SS1.p8.1.1.1.m1.1.1" xref="S5.SS1.p8.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p8.1.1.1.m1.1b"><lt id="S5.SS1.p8.1.1.1.m1.1.1.cmml" xref="S5.SS1.p8.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p8.1.1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p8.1.1.1.m1.1d">&lt;</annotation></semantics></math>bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S5.SS1.p8.2.2.2.m2.1"><semantics id="S5.SS1.p8.2.2.2.m2.1a"><mo id="S5.SS1.p8.2.2.2.m2.1.1" xref="S5.SS1.p8.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p8.2.2.2.m2.1b"><gt id="S5.SS1.p8.2.2.2.m2.1.1.cmml" xref="S5.SS1.p8.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p8.2.2.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p8.2.2.2.m2.1d">&gt;</annotation></semantics></math> <math alttext="&lt;" class="ltx_Math" display="inline" id="S5.SS1.p8.3.3.3.m3.1"><semantics id="S5.SS1.p8.3.3.3.m3.1a"><mo id="S5.SS1.p8.3.3.3.m3.1.1" xref="S5.SS1.p8.3.3.3.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p8.3.3.3.m3.1b"><lt id="S5.SS1.p8.3.3.3.m3.1.1.cmml" xref="S5.SS1.p8.3.3.3.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p8.3.3.3.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p8.3.3.3.m3.1d">&lt;</annotation></semantics></math>/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S5.SS1.p8.4.4.4.m4.1"><semantics id="S5.SS1.p8.4.4.4.m4.1a"><mo id="S5.SS1.p8.4.4.4.m4.1.1" xref="S5.SS1.p8.4.4.4.m4.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p8.4.4.4.m4.1b"><gt id="S5.SS1.p8.4.4.4.m4.1.1.cmml" xref="S5.SS1.p8.4.4.4.m4.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p8.4.4.4.m4.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p8.4.4.4.m4.1d">&gt;</annotation></semantics></math>’. Please use this feedback in your correction. If the hypothesis is already correct, do not make any changes.</span></p>
</blockquote>
</div>
<div class="ltx_para" id="S5.SS1.p9">
<p class="ltx_p" id="S5.SS1.p9.4">As with the <span class="ltx_text ltx_font_italic" id="S5.SS1.p9.4.4">APE</span> prompt, models were given (source, hypothesis, reference) triples with the tokens that were marked as bad during annotation inside of XML-style tags, <math alttext="&lt;" class="ltx_Math" display="inline" id="S5.SS1.p9.1.m1.1"><semantics id="S5.SS1.p9.1.m1.1a"><mo id="S5.SS1.p9.1.m1.1.1" xref="S5.SS1.p9.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p9.1.m1.1b"><lt id="S5.SS1.p9.1.m1.1.1.cmml" xref="S5.SS1.p9.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p9.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p9.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="S5.SS1.p9.4.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S5.SS1.p9.2.1.m1.1"><semantics id="S5.SS1.p9.2.1.m1.1a"><mo id="S5.SS1.p9.2.1.m1.1.1" xref="S5.SS1.p9.2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p9.2.1.m1.1b"><gt id="S5.SS1.p9.2.1.m1.1.1.cmml" xref="S5.SS1.p9.2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p9.2.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p9.2.1.m1.1d">&gt;</annotation></semantics></math><math alttext="&lt;" class="ltx_Math" display="inline" id="S5.SS1.p9.3.2.m2.1"><semantics id="S5.SS1.p9.3.2.m2.1a"><mo id="S5.SS1.p9.3.2.m2.1.1" xref="S5.SS1.p9.3.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p9.3.2.m2.1b"><lt id="S5.SS1.p9.3.2.m2.1.1.cmml" xref="S5.SS1.p9.3.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p9.3.2.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p9.3.2.m2.1d">&lt;</annotation></semantics></math>/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="S5.SS1.p9.4.3.m3.1"><semantics id="S5.SS1.p9.4.3.m3.1a"><mo id="S5.SS1.p9.4.3.m3.1.1" xref="S5.SS1.p9.4.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p9.4.3.m3.1b"><gt id="S5.SS1.p9.4.3.m3.1.1.cmml" xref="S5.SS1.p9.4.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p9.4.3.m3.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p9.4.3.m3.1d">&gt;</annotation></semantics></math></span>. We decided that giving the error markings as in-line tags would be easier for the model to parse and integrate in its output than including another line where errors would be indicated further away from the corresponding tokens.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Metrics</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We evaluate the models’ new hypotheses with a suite of metrics to check for token level matches, semantic similarity, and error marking usage. We use the token based metrics BLEU<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>BLEU signature: <span class="ltx_text ltx_font_typewriter" id="footnote4.1">nrefs:1 | case:mixed | eff:no | tok:13a | smooth:exp | version:2.4.0</span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx19" title="">Papineni et al., 2002</a>]</cite> and TER<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>TER Signature <span class="ltx_text ltx_font_typewriter" id="footnote5.1">nrefs:1 | case:lc | tok:tercom | norm:no | punct:yes | asian:no | version:2.4.0</span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx25" title="">Snover et al., 2006</a>]</cite> as implemented in SacreBLEU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx21" title="">Post, 2018</a>]</cite>. We did not include the popular neural metric COMET <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx23" title="">Rei et al., 2020</a>]</cite> since is not sensitive to the individual token changes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#bib.bibx6" title="">Glushkova et al., 2023</a>]</cite> that we ask the LLMs to perform.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">In addition to these metrics, we also implement our own to see how well the models are at recognizing and making edits to errors. These are called <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.1.1">marking edit</span> (ME) and <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.1.2">unmarking edit</span> (UE). We perform a word-level diff in order to see which words need to be edited or deleted in the original hypothesis to arrive at the new hypothesis. Combining this with the error markings allows us to examine if edits were made to the tokens error-marked by the annotators (ME), or if tokens that were otherwise OK were changed (UE).</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">The ME and UE metrics, however, cannot tell if the edits were correct, only that they were made. To determine if the edits correctly fix the errors, we performed a manual evaluation on the marking edits produced by Llama 13B in both the <span class="ltx_text ltx_font_italic" id="S5.SS2.p3.1.1">APE</span> and <span class="ltx_text ltx_font_italic" id="S5.SS2.p3.1.2">MRK</span> settings.
Three of the authors contributed to the evaluation. Two are native speakers of German and fluent in English while one is a native speaker of English and fluent in German. We selected 100 sentences with the most marking edits. Edits were evaluated in terms of their correctness, with a subjective yes or no answer given for the entire sentence.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.2">We show results across metrics for Llama 13B and GPT-3.5 in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#S5.T5" title="Table 5 ‣ 5.1 Experimental Setup ‣ 5 Experiments ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>. Including error markings as input increases the frequency with which the models edits the marked tokens. For Llama 13B, we see editing rates for marked tokens double from <math alttext="7.30" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><mn id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">7.30</mn><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><cn id="S6.p1.1.m1.1.1.cmml" type="float" xref="S6.p1.1.m1.1.1">7.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">7.30</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.m1.1d">7.30</annotation></semantics></math> to <math alttext="14.76" class="ltx_Math" display="inline" id="S6.p1.2.m2.1"><semantics id="S6.p1.2.m2.1a"><mn id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml">14.76</mn><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><cn id="S6.p1.2.m2.1.1.cmml" type="float" xref="S6.p1.2.m2.1.1">14.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">14.76</annotation><annotation encoding="application/x-llamapun" id="S6.p1.2.m2.1d">14.76</annotation></semantics></math>. This suggests that, even after being asked to correct the hypotheses, Llama 13B finds its own outputs as acceptable translations. When errors are specifically pointed out to the model, it is much more capable of self-correcting errors.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.4">Llama 13B nominally improves BLEU scores over the original hypotheses score (<math alttext="28.92" class="ltx_Math" display="inline" id="S6.p2.1.m1.1"><semantics id="S6.p2.1.m1.1a"><mn id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">28.92</mn><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><cn id="S6.p2.1.m1.1.1.cmml" type="float" xref="S6.p2.1.m1.1.1">28.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">28.92</annotation><annotation encoding="application/x-llamapun" id="S6.p2.1.m1.1d">28.92</annotation></semantics></math>) in all scenarios with <span class="ltx_text ltx_font_italic" id="S6.p2.4.1">MRK</span> in the lead with <math alttext="30.09" class="ltx_Math" display="inline" id="S6.p2.2.m2.1"><semantics id="S6.p2.2.m2.1a"><mn id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml">30.09</mn><annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b"><cn id="S6.p2.2.m2.1.1.cmml" type="float" xref="S6.p2.2.m2.1.1">30.09</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">30.09</annotation><annotation encoding="application/x-llamapun" id="S6.p2.2.m2.1d">30.09</annotation></semantics></math>, <span class="ltx_text ltx_font_italic" id="S6.p2.4.2">MT</span> in second with <math alttext="29.83" class="ltx_Math" display="inline" id="S6.p2.3.m3.1"><semantics id="S6.p2.3.m3.1a"><mn id="S6.p2.3.m3.1.1" xref="S6.p2.3.m3.1.1.cmml">29.83</mn><annotation-xml encoding="MathML-Content" id="S6.p2.3.m3.1b"><cn id="S6.p2.3.m3.1.1.cmml" type="float" xref="S6.p2.3.m3.1.1">29.83</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.3.m3.1c">29.83</annotation><annotation encoding="application/x-llamapun" id="S6.p2.3.m3.1d">29.83</annotation></semantics></math><span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><span class="ltx_text ltx_font_italic" id="footnote6.1">MT</span> is able to surpass the original hypotheses with Llama 13B because the annotated hypotheses were generated with the same 5 examples for all inference segments while <span class="ltx_text ltx_font_italic" id="footnote6.2">MT</span> retrieved similar examples for each test segment.</span></span></span> and <span class="ltx_text ltx_font_italic" id="S6.p2.4.3">APE</span> with <math alttext="29.79" class="ltx_Math" display="inline" id="S6.p2.4.m4.1"><semantics id="S6.p2.4.m4.1a"><mn id="S6.p2.4.m4.1.1" xref="S6.p2.4.m4.1.1.cmml">29.79</mn><annotation-xml encoding="MathML-Content" id="S6.p2.4.m4.1b"><cn id="S6.p2.4.m4.1.1.cmml" type="float" xref="S6.p2.4.m4.1.1">29.79</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.4.m4.1c">29.79</annotation><annotation encoding="application/x-llamapun" id="S6.p2.4.m4.1d">29.79</annotation></semantics></math>. Nominal improvements over the original hypotheses are also found according to the TER metric, albeit only for <span class="ltx_text ltx_font_italic" id="S6.p2.4.4">APE</span> and <span class="ltx_text ltx_font_italic" id="S6.p2.4.5">MRK</span> scenarios.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.6">The GPT model is already quite capable of finding errors in the hypotheses without error markings and the <span class="ltx_text ltx_font_italic" id="S6.p3.6.1">APE</span> outputs achieve marking edits of <math alttext="76.70" class="ltx_Math" display="inline" id="S6.p3.1.m1.1"><semantics id="S6.p3.1.m1.1a"><mn id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml">76.70</mn><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><cn id="S6.p3.1.m1.1.1.cmml" type="float" xref="S6.p3.1.m1.1.1">76.70</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">76.70</annotation><annotation encoding="application/x-llamapun" id="S6.p3.1.m1.1d">76.70</annotation></semantics></math> while <span class="ltx_text ltx_font_italic" id="S6.p3.6.2">MRK</span> has a slight improvement of <math alttext="78.36" class="ltx_Math" display="inline" id="S6.p3.2.m2.1"><semantics id="S6.p3.2.m2.1a"><mn id="S6.p3.2.m2.1.1" xref="S6.p3.2.m2.1.1.cmml">78.36</mn><annotation-xml encoding="MathML-Content" id="S6.p3.2.m2.1b"><cn id="S6.p3.2.m2.1.1.cmml" type="float" xref="S6.p3.2.m2.1.1">78.36</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.2.m2.1c">78.36</annotation><annotation encoding="application/x-llamapun" id="S6.p3.2.m2.1d">78.36</annotation></semantics></math>. Worth noting is the reduction in unmarking edits when prompting GPT with <span class="ltx_text ltx_font_italic" id="S6.p3.6.3">MRK</span>. <span class="ltx_text ltx_font_italic" id="S6.p3.6.4">MRK</span> reduces unmarking edits to <math alttext="13.90" class="ltx_Math" display="inline" id="S6.p3.3.m3.1"><semantics id="S6.p3.3.m3.1a"><mn id="S6.p3.3.m3.1.1" xref="S6.p3.3.m3.1.1.cmml">13.90</mn><annotation-xml encoding="MathML-Content" id="S6.p3.3.m3.1b"><cn id="S6.p3.3.m3.1.1.cmml" type="float" xref="S6.p3.3.m3.1.1">13.90</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.3.m3.1c">13.90</annotation><annotation encoding="application/x-llamapun" id="S6.p3.3.m3.1d">13.90</annotation></semantics></math> from <math alttext="15.85" class="ltx_Math" display="inline" id="S6.p3.4.m4.1"><semantics id="S6.p3.4.m4.1a"><mn id="S6.p3.4.m4.1.1" xref="S6.p3.4.m4.1.1.cmml">15.85</mn><annotation-xml encoding="MathML-Content" id="S6.p3.4.m4.1b"><cn id="S6.p3.4.m4.1.1.cmml" type="float" xref="S6.p3.4.m4.1.1">15.85</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.4.m4.1c">15.85</annotation><annotation encoding="application/x-llamapun" id="S6.p3.4.m4.1d">15.85</annotation></semantics></math> with <span class="ltx_text ltx_font_italic" id="S6.p3.6.5">APE</span>. This means that indicating specific errors can constrain the number of edits that the GPT model makes. Additionally, nominal improvements of BLEU and TER scores are found in the <span class="ltx_text ltx_font_italic" id="S6.p3.6.6">APE</span> and <span class="ltx_text ltx_font_italic" id="S6.p3.6.7">MRK</span> scenarios over <span class="ltx_text ltx_font_italic" id="S6.p3.6.8">MT</span> with GPT 3.5 as well. <span class="ltx_text ltx_font_italic" id="S6.p3.6.9">MRK</span> improves BLEU to <math alttext="39.31" class="ltx_Math" display="inline" id="S6.p3.5.m5.1"><semantics id="S6.p3.5.m5.1a"><mn id="S6.p3.5.m5.1.1" xref="S6.p3.5.m5.1.1.cmml">39.31</mn><annotation-xml encoding="MathML-Content" id="S6.p3.5.m5.1b"><cn id="S6.p3.5.m5.1.1.cmml" type="float" xref="S6.p3.5.m5.1.1">39.31</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.5.m5.1c">39.31</annotation><annotation encoding="application/x-llamapun" id="S6.p3.5.m5.1d">39.31</annotation></semantics></math> from <span class="ltx_text ltx_font_italic" id="S6.p3.6.10">MT</span>’s <math alttext="38.61" class="ltx_Math" display="inline" id="S6.p3.6.m6.1"><semantics id="S6.p3.6.m6.1a"><mn id="S6.p3.6.m6.1.1" xref="S6.p3.6.m6.1.1.cmml">38.61</mn><annotation-xml encoding="MathML-Content" id="S6.p3.6.m6.1b"><cn id="S6.p3.6.m6.1.1.cmml" type="float" xref="S6.p3.6.m6.1.1">38.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.6.m6.1c">38.61</annotation><annotation encoding="application/x-llamapun" id="S6.p3.6.m6.1d">38.61</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.2">In the manual evaluation of marking edits, we found that <span class="ltx_text ltx_font_italic" id="S6.p4.2.1">APE</span> made correct edits 32% of the time on average, while either making incorrect edits or not editing the rest. <span class="ltx_text ltx_font_italic" id="S6.p4.2.2">MRK</span> on the other hand was judged correct 67% of the time on average. Agreement in terms of Krippendorff’s Alpha for sentence level ratings of <span class="ltx_text ltx_font_italic" id="S6.p4.2.3">APE</span> is <math alttext="\alpha=0.82" class="ltx_Math" display="inline" id="S6.p4.1.m1.1"><semantics id="S6.p4.1.m1.1a"><mrow id="S6.p4.1.m1.1.1" xref="S6.p4.1.m1.1.1.cmml"><mi id="S6.p4.1.m1.1.1.2" xref="S6.p4.1.m1.1.1.2.cmml">α</mi><mo id="S6.p4.1.m1.1.1.1" xref="S6.p4.1.m1.1.1.1.cmml">=</mo><mn id="S6.p4.1.m1.1.1.3" xref="S6.p4.1.m1.1.1.3.cmml">0.82</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p4.1.m1.1b"><apply id="S6.p4.1.m1.1.1.cmml" xref="S6.p4.1.m1.1.1"><eq id="S6.p4.1.m1.1.1.1.cmml" xref="S6.p4.1.m1.1.1.1"></eq><ci id="S6.p4.1.m1.1.1.2.cmml" xref="S6.p4.1.m1.1.1.2">𝛼</ci><cn id="S6.p4.1.m1.1.1.3.cmml" type="float" xref="S6.p4.1.m1.1.1.3">0.82</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p4.1.m1.1c">\alpha=0.82</annotation><annotation encoding="application/x-llamapun" id="S6.p4.1.m1.1d">italic_α = 0.82</annotation></semantics></math>, while for <span class="ltx_text ltx_font_italic" id="S6.p4.2.4">MRK</span> <math alttext="\alpha=0.55" class="ltx_Math" display="inline" id="S6.p4.2.m2.1"><semantics id="S6.p4.2.m2.1a"><mrow id="S6.p4.2.m2.1.1" xref="S6.p4.2.m2.1.1.cmml"><mi id="S6.p4.2.m2.1.1.2" xref="S6.p4.2.m2.1.1.2.cmml">α</mi><mo id="S6.p4.2.m2.1.1.1" xref="S6.p4.2.m2.1.1.1.cmml">=</mo><mn id="S6.p4.2.m2.1.1.3" xref="S6.p4.2.m2.1.1.3.cmml">0.55</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p4.2.m2.1b"><apply id="S6.p4.2.m2.1.1.cmml" xref="S6.p4.2.m2.1.1"><eq id="S6.p4.2.m2.1.1.1.cmml" xref="S6.p4.2.m2.1.1.1"></eq><ci id="S6.p4.2.m2.1.1.2.cmml" xref="S6.p4.2.m2.1.1.2">𝛼</ci><cn id="S6.p4.2.m2.1.1.3.cmml" type="float" xref="S6.p4.2.m2.1.1.3">0.55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p4.2.m2.1c">\alpha=0.55</annotation><annotation encoding="application/x-llamapun" id="S6.p4.2.m2.1d">italic_α = 0.55</annotation></semantics></math>.
As <span class="ltx_text ltx_font_italic" id="S6.p4.2.5">APE</span> makes fewer edits overall, it is easier to classify as incorrect or not editing. For <span class="ltx_text ltx_font_italic" id="S6.p4.2.6">MRK</span> there was disagreement on how to handle partial edits or if not all markings were edited, requiring individual judgement by each evaluator.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We presented a pilot study to investigate the potential of augmenting a so-called PE-TM resource consisting of sources, machine translations, and human references, with human error markings in order to guide an LLM to self-correct marked erroneous term translations. We find that the LLM that produced the translation hypotheses identifies its own translations as correct, and therefore does not act on the instructions to correct errors. However, when prompted with error markings, the LLM learns to act on them, doubling the number of edits to marked tokens, with nearly 70% of the edits being correct according to a human evaluation.
In sum, our pilot study shows that the additional effort of error marking a machine translation at test time allows an LLM translation system to learn focused corrections on marked errors from similar examples extracted from a PE-TM, leading to
improved translation quality over APE and MT. In future work, we will investigate learned models for error markings. These require larger TMs for reliable training of markings estimators, but also bear the promise of improved retrieval augmentation.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Acknowledgements</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">The second author acknowledges support by the state of Baden-Württemberg through bwHPC
and the German Research Foundation (DFG) through grant INST 35/1597-1 FUGG.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bibx1">
<span class="ltx_tag ltx_tag_bibitem">[Berger et al., 2023] </span>
<span class="ltx_bibblock">
Berger, Nathaniel, Miriam Exel, Matthias Huck, and Stefan Riezler.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Enhancing supervised learning with contrastive markings in neural
machine translation training.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx1.1.1">Proceedings of the 24th Annual Conference of The European
Association for Machine Translation (EAMT)</span>, Tampere, Finland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx2">
<span class="ltx_tag ltx_tag_bibitem">[Domingo et al., 2017] </span>
<span class="ltx_bibblock">
Domingo, Miguel, Álvaro Peris, and Francisco Casacuberta.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">Segment-based interactive-predictive machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx2.1.1">Machine Translation</span>, 31(4):163–185.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx3">
<span class="ltx_tag ltx_tag_bibitem">[Exel et al., 2020] </span>
<span class="ltx_bibblock">
Exel, Miriam, Bianka Buschbeck, Lauritz Brandt, and Simona Doneva.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">Terminology-constrained neural machine translation at SAP.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx3.1.1">Proceedings of the 22nd Annual Conference of the European
Association for Machine Translation (EAMT)</span>, Lisboa, Portugal.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx4">
<span class="ltx_tag ltx_tag_bibitem">[Garcia et al., 2023] </span>
<span class="ltx_bibblock">
Garcia, Xavier, Yamini Bansal, Colin Cherry, George Foster, Maxim Krikun,
Melvin Johnson, and Orhan Firat.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">The unreasonable effectiveness of few-shot learning for machine
translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx4.1.1">Proceedings of the 40th International Conference on Machine
Learning (ICML)</span>, Hanolulu, Hawaii, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx5">
<span class="ltx_tag ltx_tag_bibitem">[Ghazvininejad et al., 2023] </span>
<span class="ltx_bibblock">
Ghazvininejad, Marjan, Hila Gonen, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Dictionary-based phrase-level prompting of large language models for
machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx5.1.1">arXiv</span>, abs/2302.07856.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx6">
<span class="ltx_tag ltx_tag_bibitem">[Glushkova et al., 2023] </span>
<span class="ltx_bibblock">
Glushkova, Taisiya, Chrysoula Zerva, and André F. T. Martins.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">BLEU meets COMET: Combining lexical and neural metrics towards
robust machine translation evaluation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx6.1.1">Proceedings of the 24th Annual Conference of the European
Association for Machine Translation (EACL)</span>, Tampere, Finland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx7">
<span class="ltx_tag ltx_tag_bibitem">[Grangier and Auli, 2018] </span>
<span class="ltx_bibblock">
Grangier, David and Michael Auli.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">QuickEdit: Editing text &amp; translations by crossing words out.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx7.1.1">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies (NAACL:HLT)</span>, New Orleans, Louisiana.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx8">
<span class="ltx_tag ltx_tag_bibitem">[Hoang et al., 2023] </span>
<span class="ltx_bibblock">
Hoang, Cuong, Devendra Sachan, Prashant Mathur, Brian Thompson, and Marcello
Federico.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Improving retrieval augmented neural machine translation by
controlling source and fuzzy-match interactions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx8.1.1">Findings of the Association for Computational Linguistics:
EACL 2023</span>, Dubrovnik, Croatia.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx9">
<span class="ltx_tag ltx_tag_bibitem">[Huang et al., 2023] </span>
<span class="ltx_bibblock">
Huang, Jie, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu,
Xinying Song, and Denny Zhou.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Large language models cannot self-correct reasoning yet.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx9.1.1">arXiv</span>, abs/2310.01798.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx10">
<span class="ltx_tag ltx_tag_bibitem">[Joulin et al., 2017] </span>
<span class="ltx_bibblock">
Joulin, Armand, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">Bag of tricks for efficient text classification.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx10.1.1">Proceedings of the 15th Conference of the European Chapter
of the Association for Computational Linguistics (EACL)</span>, Valencia, Spain.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx11">
<span class="ltx_tag ltx_tag_bibitem">[Kreutzer et al., 2020] </span>
<span class="ltx_bibblock">
Kreutzer, Julia, Nathaniel Berger, and Stefan Riezler.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">Correct me if you can: Learning from error corrections and markings.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx11.1.1">Proceedings of the 22nd Annual Conference of the European
Association for Machine Translation (EAMT)</span>, Lisbon, Portugal.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx12">
<span class="ltx_tag ltx_tag_bibitem">[Krippendorff, 2004] </span>
<span class="ltx_bibblock">
Krippendorff, Klaus.

</span>
<span class="ltx_bibblock">2004.

</span>
<span class="ltx_bibblock">Reliability in content analysis: Some common misconceptions and
recommendations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx12.1.1">Human Communication Research</span>, 30(3):411–433.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx13">
<span class="ltx_tag ltx_tag_bibitem">[Lam et al., 2019] </span>
<span class="ltx_bibblock">
Lam, Tsz Kin, Shigehiko Schamoni, and Stefan Riezler.

</span>
<span class="ltx_bibblock">2019.

</span>
<span class="ltx_bibblock">Interactive-predictive neural machine translation through
reinforcement and imitation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx13.1.1">Proceedings of the Machine Translation Summit (MTSUMMIT
XVII)</span>, Dublin, Ireland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx14">
<span class="ltx_tag ltx_tag_bibitem">[Madaan et al., 2023] </span>
<span class="ltx_bibblock">
Madaan, Aman, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean
Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, and
Peter Clark.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Self-refine: Iterative refinement with self-feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx14.1.1">arXiv</span>, abs/2303.17651.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx15">
<span class="ltx_tag ltx_tag_bibitem">[Marie and Max, 2015] </span>
<span class="ltx_bibblock">
Marie, Benjamin and Aurélien Max.

</span>
<span class="ltx_bibblock">2015.

</span>
<span class="ltx_bibblock">Touch-based pre-post-editing of machine translation output.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx15.1.1">Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP)</span>, Lisbon, Portugal.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx16">
<span class="ltx_tag ltx_tag_bibitem">[Moslem et al., 2023] </span>
<span class="ltx_bibblock">
Moslem, Yasmin, Rejwanul Haque, John D. Kelleher, and Andy Way.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Adaptive machine translation with large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx16.1.1">Proceedings of the 24th Annual Conference of the European
Association for Machine Translation (EAMT)</span>, Tampere, Finland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx17">
<span class="ltx_tag ltx_tag_bibitem">[OpenAI, 2023] </span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">GPT-4 technical report.

</span>
<span class="ltx_bibblock">Technical report, OpenAI.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx18">
<span class="ltx_tag ltx_tag_bibitem">[Pan et al., 2023] </span>
<span class="ltx_bibblock">
Pan, Liangming, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, and
William Yang Wang.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Automatically correcting large language models: Surveying the
landscape of diverse self-correction strategies.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx18.1.1">arXiv</span>, abs/2308.03188.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx19">
<span class="ltx_tag ltx_tag_bibitem">[Papineni et al., 2002] </span>
<span class="ltx_bibblock">
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">2002.

</span>
<span class="ltx_bibblock">BLEU: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx19.1.1">Proceedings of the 40th Annual Meeting on Association for
Computational Linguistics (ACL)</span>, Philadelphia, PA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx20">
<span class="ltx_tag ltx_tag_bibitem">[Petrushkov et al., 2018] </span>
<span class="ltx_bibblock">
Petrushkov, Pavel, Shahram Khadivi, and Evgeny Matusov.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">Learning from chunk-based feedback in neural machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx20.1.1">Proceedings of the 56th Annual Meeting of the Association for
Computational Linguistics (ACL)</span>, Melbourne, Australia.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx21">
<span class="ltx_tag ltx_tag_bibitem">[Post, 2018] </span>
<span class="ltx_bibblock">
Post, Matt.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">A call for clarity in reporting BLEU scores.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx21.1.1">Proceedings of the 3rd Conference on Machine Translation
(WMT)</span>, Brussels, Belgium.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx22">
<span class="ltx_tag ltx_tag_bibitem">[Raunak et al., 2023] </span>
<span class="ltx_bibblock">
Raunak, Vikas, Amr Sharaf, Yiren Wang, Hany Hassan Awadallah, and Arul Menezes.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Leveraging GPT-4 for automatic translation post-editing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx22.1.1">Findings of the 2023 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</span>, Singapore.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx23">
<span class="ltx_tag ltx_tag_bibitem">[Rei et al., 2020] </span>
<span class="ltx_bibblock">
Rei, Ricardo, Craig Stewart, Ana C Farinha, and Alon Lavie.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">COMET: A neural framework for MT evaluation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx23.1.1">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</span>, Online.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx24">
<span class="ltx_tag ltx_tag_bibitem">[Reimers and Gurevych, 2019] </span>
<span class="ltx_bibblock">
Reimers, Nils and Iryna Gurevych.

</span>
<span class="ltx_bibblock">2019.

</span>
<span class="ltx_bibblock">Sentence-bert: Sentence embeddings using siamese bert-networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx24.1.1">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</span>, Hong King, China.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx25">
<span class="ltx_tag ltx_tag_bibitem">[Snover et al., 2006] </span>
<span class="ltx_bibblock">
Snover, Matthew, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John
Makhoul.

</span>
<span class="ltx_bibblock">2006.

</span>
<span class="ltx_bibblock">A study of translation edit rate with targeted human annotation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx25.1.1">Proceedings of the 7th Conference of the Association for
Machine Translation in the Americas (AMTA’06)</span>, Cambridge, MA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx26">
<span class="ltx_tag ltx_tag_bibitem">[Tiedemann, 2012] </span>
<span class="ltx_bibblock">
Tiedemann, Jörg.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Parallel data, tools and interfaces in OPUS.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx26.1.1">Proceedings of the Eighth International Conference on
Language Resources and Evaluation (LREC’12)</span>, Istanbul, Turkey.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx27">
<span class="ltx_tag ltx_tag_bibitem">[Touvron et al., 2023] </span>
<span class="ltx_bibblock">
Touvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume
Lample.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">LLaMA: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx27.1.1">arXiv</span>, abs/2302.13971.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx28">
<span class="ltx_tag ltx_tag_bibitem">[Turchi et al., 2017] </span>
<span class="ltx_bibblock">
Turchi, Marco, Matteo Negri, M. Amin Farajian, and Marcello Federico.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">Continuous learning from human post-edits for neural machine
translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx28.1.1">The Prague Bulletin of Mathematical Linguistics (PBML)</span>,
1(108):233–244.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx29">
<span class="ltx_tag ltx_tag_bibitem">[Vidal et al., 2022] </span>
<span class="ltx_bibblock">
Vidal, Blanca, Albert Llorens, and Juan Alonso.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Automatic post-editing of MT output using large language models.

</span>
<span class="ltx_bibblock">In Campbell, Janice, Stephen Larocca, Jay Marciano, Konstantin
Savenkov, and Alex Yanishevsky, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx29.1.1">Proceedings of the 15th
Biennial Conference of the Association for Machine Translation in the
Americas (AMTA)</span>, Orlando, Florida, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx30">
<span class="ltx_tag ltx_tag_bibitem">[Vilar et al., 2023] </span>
<span class="ltx_bibblock">
Vilar, David, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, and
George Foster.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Prompting PaLM for translation: Assessing strategies and
performance.

</span>
<span class="ltx_bibblock">In Rogers, Anna, Jordan Boyd-Graber, and Naoaki Okazaki, editors,
<span class="ltx_text ltx_font_italic" id="bib.bibx30.1.1">Proceedings of the 61st Annual Meeting of the Association for
Computational Linguistics (ACL)</span>, Toronto, Canada.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx31">
<span class="ltx_tag ltx_tag_bibitem">[Wolf et al., 2020] </span>
<span class="ltx_bibblock">
Wolf, Thomas, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe
Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander Rush.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx31.1.1">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing: System Demonstrations</span>, Online.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx32">
<span class="ltx_tag ltx_tag_bibitem">[Xu et al., 2023] </span>
<span class="ltx_bibblock">
Xu, Wenda, Daniel Deutsch, Mara Finkelstein, Juraj Juraska, Biao Zhang,
Zhongtao Liu, William Yang Wang, Lei Li, and Markus Freitag.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Pinpoint, not criticize: Refining large language models via
fine-grained actionable feedback.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Example Prompts</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">An example of a prompt for <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.1">MT</span>, <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.2">APE</span>, and <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.3">MRK</span> are in Figures <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#A1.F3" title="Figure 3 ‣ A.1 Example Prompts ‣ Appendix A Appendix ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#A1.F4" title="Figure 4 ‣ A.1 Example Prompts ‣ Appendix A Appendix ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2406.02267v1#A1.F5" title="Figure 5 ‣ A.1 Example Prompts ‣ Appendix A Appendix ‣ Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>, respectively.</p>
</div>
<figure class="ltx_figure" id="A1.F3"><svg class="ltx_picture" height="326.44" id="A1.F3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,326.44) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 0 L 0 326.44 L 600 326.44 L 600 0 Z" style="stroke:none"></path></g><g fill="#BFBFBF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 324.47 L 598.03 324.47 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="298.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F3.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.1">Translate English to German.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.2">English: Cookies are part of the HTTP header, so setcookie() must be called before any output is sent to the browser.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.3">German: Sie sind Bestandteil des HTTP-Headers, was bedeutet, dass die Funktion setcookie() aufgerufen werden muss, bevor irgendeine Ausgabe an den Browser erfolgt.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.4">English: session.use_only_cookies specifies whether the module will only use cookies to store the session id on the client side.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.5">German: session.use_only_cookies spezifiziert, ob das Modul nur Cookies verwendet, um die Session-ID clientseitig zu speichern.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.6">English: Note that SID is only defined if the client didn’t send the right cookie.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.7">German: Beachten Sie, dass SID nur definiert ist, wenn vom Client nicht das richtige Cookie gesendet wurde.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.8">English: The server does not support the request type of the body.</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.9">German: Der Server unterstützt den angeforderten Typ nicht.%1: request type</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.10">English: Must be in active session on local console</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.11">German: Nur in aktiver Sitzung auf lokaler Konsole</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.12">English: Like other headers, cookies must be sent before any output from your script (this is a protocol restriction).</span>
<span class="ltx_p" id="A1.F3.pic1.1.1.1.1.1.13">German:</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Example of 5-shot prompt for English-to-German Translation. Each demonstration example consists of a source segment in English (in green), and a reference translation (in red).</figcaption>
</figure>
<figure class="ltx_figure" id="A1.F4"><svg class="ltx_picture" height="525.69" id="A1.F4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,525.69) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 0 L 0 525.69 L 600 525.69 L 600 0 Z" style="stroke:none"></path></g><g fill="#BFBFBF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 523.72 L 598.03 523.72 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="498.13" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F4.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.1">Read the English text and the German translation hypothesis and then correct the output. If the hypothesis is already correct, do not make any changes.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.2">English: Cookies are part of the HTTP header, so setcookie() must be called before any output is sent to the browser.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.3">Hypothesis: Cookies sind Teil des HTTP-Headers , deshalb muss setcookie() vor jedem Ausgabe-Output an den Browser aufgerufen werden .</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.4">German: Sie sind Bestandteil des HTTP-Headers, was bedeutet, dass die Funktion setcookie() aufgerufen werden muss, bevor irgendeine Ausgabe an den Browser erfolgt.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.5">English: session.use_only_cookies specifies whether the module will only use cookies to store the session id on the client side.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.6">Hypothesis: session .use_only_cookies bestimmt , ob das Modul nur mit Cookies die Session-ID auf dem Client-Betriebssystem speichert .</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.7">German: session.use_only_cookies spezifiziert, ob das Modul nur Cookies verwendet, um die Session-ID clientseitig zu speichern.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.8">English: Note that SID is only defined if the client didn’t send the right cookie.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.9">Hypothesis: Beachtet , dass SID nur definiert ist , wenn der Client nicht den richtigen Cookie gesendet hat .</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.10">German: Beachten Sie, dass SID nur definiert ist, wenn vom Client nicht das richtige Cookie gesendet wurde.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.11">English: The server does not support the request type of the body.</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.12">Hypothesis: Der Server unterstützt nicht die Anforderungstyp der Body .</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.13">German: Der Server unterstützt den angeforderten Typ nicht.%1: request type</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.14">English: Must be in &amp; active session on local console</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.15">Hypothesis: Muss in &amp; aktiver Sitzung auf dem lokalen Konsole</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.16">German: Nur in &amp; aktiver Sitzung auf lokaler Konsole</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.17">English: Like other headers, cookies must be sent before any output from your script (this is a protocol restriction).</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.18">Hypothesis: Wie andere Headern müssen Cookies vor jedem Ausgabe-Output ( dies ist eine Protokoll-Einschränkung ) gesendet werden .</span>
<span class="ltx_p" id="A1.F4.pic1.1.1.1.1.1.19">German:</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Example of 5-shot prompt for English-to-German Automatic Post-Editing (<span class="ltx_text ltx_font_italic" id="A1.F4.2.1">APE</span>). Each demonstration example consists of a source segment in English (in green), a translation hypothesis in German (in blue), and a reference translation (in red).</figcaption>
</figure>
<figure class="ltx_figure" id="A1.F5"><svg class="ltx_picture" height="558.9" id="A1.F5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,558.9) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 0 L 0 558.9 L 600 558.9 L 600 0 Z" style="stroke:none"></path></g><g fill="#BFBFBF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 556.93 L 598.03 556.93 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="531.34" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44" style="width:402.3pt;">
<span class="ltx_p" id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4">Read the English text and the German translation hypothesis and then correct the output. Incorrect words are inside of tags ’<math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><lt id="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">&lt;</annotation></semantics></math>bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1"><semantics id="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mo id="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><gt id="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1d">&gt;</annotation></semantics></math> <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1"><semantics id="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1a"><mo id="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" xref="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b"><lt id="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1d">&lt;</annotation></semantics></math>/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1"><semantics id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1a"><mo id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1" xref="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1b"><gt id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml" xref="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1d">&gt;</annotation></semantics></math>’. Please use this feedback in your correction. If the hypothesis is already correct, do not make any changes.</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.45">English: Cookies are part of the HTTP header, so setcookie() must be called before any output is sent to the browser.</span>
<span class="ltx_p" id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8">Hypothesis: Cookies sind Teil des HTTP-Headers , deshalb muss setcookie() vor jedem <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1"><semantics id="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1a"><mo id="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1" xref="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1b"><lt id="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1"><semantics id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1a"><mo id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1" xref="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1b"><gt id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.cmml" xref="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1d">&gt;</annotation></semantics></math></span> Ausgabe-Output <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1"><semantics id="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1a"><mo id="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1" xref="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1b"><lt id="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1.cmml" xref="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1"><semantics id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1a"><mo id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1" xref="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1b"><gt id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1.cmml" xref="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.2.m1.1d">&gt;</annotation></semantics></math></span> an den Browser aufgerufen werden .</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.46">German: Sie sind Bestandteil des HTTP-Headers, was bedeutet, dass die Funktion setcookie() aufgerufen werden muss, bevor irgendeine Ausgabe an den Browser erfolgt.</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.47">English: session.use_only_cookies specifies whether the module will only use cookies to store the session id on the client side.</span>
<span class="ltx_p" id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16">Hypothesis: session .use_only_cookies bestimmt , ob das Modul nur <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1"><semantics id="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1a"><mo id="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1" xref="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1b"><lt id="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.cmml" xref="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1"><semantics id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1a"><mo id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1.1" xref="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1b"><gt id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1.1.cmml" xref="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.1.m1.1d">&gt;</annotation></semantics></math></span> mit <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1"><semantics id="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1a"><mo id="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1" xref="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1b"><lt id="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1.cmml" xref="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1"><semantics id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1a"><mo id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1.1" xref="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1b"><gt id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1.1.cmml" xref="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.2.m1.1d">&gt;</annotation></semantics></math></span> Cookies die Session-ID auf dem <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1"><semantics id="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1a"><mo id="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1.1" xref="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1b"><lt id="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1.1.cmml" xref="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m3.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1"><semantics id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1a"><mo id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1.1" xref="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1b"><gt id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1.1.cmml" xref="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.3.m1.1d">&gt;</annotation></semantics></math></span> Client-Betriebssystem speichert <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1"><semantics id="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1a"><mo id="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1.1" xref="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1b"><lt id="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1.1.cmml" xref="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m4.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1"><semantics id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1a"><mo id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1.1" xref="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1b"><gt id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1.1.cmml" xref="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.4.m1.1d">&gt;</annotation></semantics></math></span> .</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.48">German: session.use_only_cookies spezifiziert, ob das Modul nur Cookies verwendet, um die Session-ID clientseitig zu speichern.</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.49">English: Note that SID is only defined if the client didn’t send the right cookie.</span>
<span class="ltx_p" id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24">Hypothesis: <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1"><semantics id="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1a"><mo id="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1" xref="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1b"><lt id="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1.cmml" xref="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1"><semantics id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1a"><mo id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1" xref="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1b"><gt id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1.cmml" xref="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.1.m1.1d">&gt;</annotation></semantics></math></span> Beachtet <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1"><semantics id="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1a"><mo id="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1" xref="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1b"><lt id="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1.cmml" xref="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1"><semantics id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1a"><mo id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1" xref="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1b"><gt id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1.cmml" xref="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.2.m1.1d">&gt;</annotation></semantics></math></span> , dass SID nur definiert <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1"><semantics id="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1a"><mo id="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1.1" xref="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1b"><lt id="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1.1.cmml" xref="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m3.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1"><semantics id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1a"><mo id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1.1" xref="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1b"><gt id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1.1.cmml" xref="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.3.m1.1d">&gt;</annotation></semantics></math></span> ist <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1"><semantics id="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1a"><mo id="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1.1" xref="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1b"><lt id="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1.1.cmml" xref="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m4.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1"><semantics id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1a"><mo id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1.1" xref="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1b"><gt id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1.1.cmml" xref="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.4.m1.1d">&gt;</annotation></semantics></math></span> , wenn der Client nicht den richtigen Cookie gesendet hat .</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.50">German: Beachten Sie, dass SID nur definiert ist, wenn vom Client nicht das richtige Cookie gesendet wurde.</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.51">English: The server does not support the request type of the body.</span>
<span class="ltx_p" id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32">Hypothesis: Der Server unterstützt nicht <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1"><semantics id="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1a"><mo id="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1.1" xref="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1b"><lt id="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1.1.cmml" xref="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1"><semantics id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1a"><mo id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1.1" xref="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1b"><gt id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1.1.cmml" xref="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.1.m1.1d">&gt;</annotation></semantics></math></span> die <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1"><semantics id="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1a"><mo id="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1" xref="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1b"><lt id="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1.cmml" xref="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1"><semantics id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1a"><mo id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1.1" xref="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1b"><gt id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1.1.cmml" xref="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.2.m1.1d">&gt;</annotation></semantics></math></span> Anforderungstyp <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1"><semantics id="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1a"><mo id="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1.1" xref="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1b"><lt id="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1.1.cmml" xref="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m3.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1"><semantics id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1a"><mo id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1.1" xref="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1b"><gt id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1.1.cmml" xref="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.3.m1.1d">&gt;</annotation></semantics></math></span> der <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1"><semantics id="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1a"><mo id="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1.1" xref="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1b"><lt id="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1.1.cmml" xref="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m4.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1"><semantics id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1a"><mo id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1.1" xref="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1b"><gt id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1.1.cmml" xref="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.4.m1.1d">&gt;</annotation></semantics></math></span> Body .</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.52">German: Der Server unterstützt den angeforderten Typ nicht.%1: request type</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.53">English: Must be in &amp; active session on local console</span>
<span class="ltx_p" id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36">Hypothesis: Muss in &amp; aktiver Sitzung auf <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1"><semantics id="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1a"><mo id="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1.1" xref="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1b"><lt id="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1.1.cmml" xref="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1"><semantics id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1a"><mo id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1.1" xref="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1b"><gt id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1.1.cmml" xref="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.1.m1.1d">&gt;</annotation></semantics></math></span> dem <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1"><semantics id="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1a"><mo id="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1.1" xref="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1b"><lt id="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1.1.cmml" xref="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1"><semantics id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1a"><mo id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1.1" xref="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1b"><gt id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1.1.cmml" xref="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.2.m1.1d">&gt;</annotation></semantics></math></span> lokalen Konsole</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.54">German: Nur in &amp; aktiver Sitzung auf lokaler Konsole</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.55">English: Like other headers, cookies must be sent before any output from your script (this is a protocol restriction).</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44">Hypothesis: Wie andere <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1"><semantics id="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1a"><mo id="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1" xref="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1b"><lt id="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1.cmml" xref="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1"><semantics id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1a"><mo id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1.1" xref="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1b"><gt id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1.1.cmml" xref="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.1.m1.1d">&gt;</annotation></semantics></math></span> Headern <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1"><semantics id="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1a"><mo id="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1.1" xref="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1b"><lt id="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1.1.cmml" xref="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m2.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1"><semantics id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1a"><mo id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1.1" xref="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1b"><gt id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1.1.cmml" xref="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.2.m1.1d">&gt;</annotation></semantics></math></span> müssen Cookies vor jedem <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1"><semantics id="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1a"><mo id="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1.1" xref="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1b"><lt id="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1.1.cmml" xref="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m3.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1"><semantics id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1a"><mo id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1.1" xref="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1b"><gt id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1.1.cmml" xref="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.3.m1.1d">&gt;</annotation></semantics></math></span> Ausgabe-Output <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1"><semantics id="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1a"><mo id="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1.1" xref="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1b"><lt id="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1.1.cmml" xref="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m4.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4">/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1"><semantics id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1a"><mo id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1.1" xref="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1b"><gt id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1.1.cmml" xref="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.4.m1.1d">&gt;</annotation></semantics></math></span> ( dies ist eine Protokoll-Einschränkung ) gesendet werden .</span>
<span class="ltx_p" id="A1.F5.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.56">German:</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Example of 5-shot prompt for English-to-German Post-Editing with error markings (<span class="ltx_text ltx_font_italic" id="A1.F5.10.4">MRK</span>). Error markings inside by tags <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.5.m1.1"><semantics id="A1.F5.5.m1.1b"><mo id="A1.F5.5.m1.1.1" xref="A1.F5.5.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.5.m1.1c"><lt id="A1.F5.5.m1.1.1.cmml" xref="A1.F5.5.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.5.m1.1d">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.5.m1.1e">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.F5.8.3">bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.6.1.m1.1"><semantics id="A1.F5.6.1.m1.1b"><mo id="A1.F5.6.1.m1.1.1" xref="A1.F5.6.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.6.1.m1.1c"><gt id="A1.F5.6.1.m1.1.1.cmml" xref="A1.F5.6.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.6.1.m1.1d">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.6.1.m1.1e">&gt;</annotation></semantics></math> <math alttext="&lt;" class="ltx_Math" display="inline" id="A1.F5.7.2.m2.1"><semantics id="A1.F5.7.2.m2.1b"><mo id="A1.F5.7.2.m2.1.1" xref="A1.F5.7.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.7.2.m2.1c"><lt id="A1.F5.7.2.m2.1.1.cmml" xref="A1.F5.7.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.7.2.m2.1d">&lt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.7.2.m2.1e">&lt;</annotation></semantics></math>/bad<math alttext="&gt;" class="ltx_Math" display="inline" id="A1.F5.8.3.m3.1"><semantics id="A1.F5.8.3.m3.1b"><mo id="A1.F5.8.3.m3.1.1" xref="A1.F5.8.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A1.F5.8.3.m3.1c"><gt id="A1.F5.8.3.m3.1.1.cmml" xref="A1.F5.8.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.8.3.m3.1d">&gt;</annotation><annotation encoding="application/x-llamapun" id="A1.F5.8.3.m3.1e">&gt;</annotation></semantics></math></span>. Each demonstration example consists of a source segment in English (in green), a translation hypothesis in German (in blue), and a reference translation (in red).</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jun  4 12:42:55 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
