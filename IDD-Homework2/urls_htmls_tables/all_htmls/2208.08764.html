<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2208.08764] FedComm: Understanding Communication Protocols for Edge-based Federated Learning</title><meta property="og:description" content="Federated learning (FL) trains machine learning (ML) models on devices using locally generated data and exchanges models without transferring raw data to a distant server.
This exchange incurs a communication overhead …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedComm: Understanding Communication Protocols for Edge-based Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedComm: Understanding Communication Protocols for Edge-based Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2208.08764">

<!--Generated on Wed Mar 13 17:39:35 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Distributed Machine Learning,  Federated Learning,  Internet of Things,  Communication Protocols
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
<span id="id1.id1" class="ltx_text ltx_font_typewriter">FedComm</span>: Understanding Communication Protocols for Edge-based Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gary Cleland1, Di Wu2, Rehmat Ullah2, and Blesson Varghese12
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">1<span id="id2.1.id1" class="ltx_text ltx_font_italic">School of Electronics, Electrical Engineering and Computer Science,
Queen’s University Belfast, UK
<br class="ltx_break"></span>
</span>
<span class="ltx_contact ltx_role_affiliation">2<span id="id3.2.id1" class="ltx_text ltx_font_italic">School of Computer Science,
University of St Andrews, UK
<br class="ltx_break"></span>Corresponding author: bv6@st-andrews.ac.uk
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Federated learning (FL) trains machine learning (ML) models on devices using locally generated data and exchanges models without transferring raw data to a distant server.
This exchange incurs a communication overhead and impacts the performance of FL training. There is limited understanding of how communication protocols specifically contribute to the performance of FL. Such an understanding is essential for selecting the right communication protocol when designing an FL system. This paper presents <span id="id4.id1.1" class="ltx_text ltx_font_typewriter">FedComm</span>  a benchmarking methodology to quantify the impact of optimized application layer protocols, namely Message Queue Telemetry Transport (MQTT), Advanced Message Queuing Protocol (AMQP), and ZeroMQ Message Transport Protocol (ZMTP), and non-optimized application layer protocols, namely as TCP and UDP, on the performance of FL. <span id="id4.id1.2" class="ltx_text ltx_font_typewriter">FedComm</span> measures the overall performance of FL in terms of communication time and accuracy under varying computational and network stress and packet loss rates. Experiments on a lab-based testbed demonstrate that TCP outperforms UDP as a non-optimized application layer protocol with higher accuracy and shorter communication times for 4G and Wi-Fi networks. Optimized application layer protocols such as AMQP, MQTT, and ZMTP outperformed non-optimized application layer protocols in most network conditions, resulting in a 2.5x reduction in communication time compared to TCP while maintaining accuracy. The experimental results enable us to highlight a number of open research issues for further investigation. <span id="id4.id1.3" class="ltx_text ltx_font_typewriter">FedComm</span> is available for download from <a target="_blank" href="https://github.com/qub-blesson/FedComm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/qub-blesson/FedComm</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Distributed Machine Learning, Federated Learning, Internet of Things, Communication Protocols

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With billions of devices getting connected to the Internet, it is anticipated that 180 zettabytes of data will be generated by 2025 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The premise of edge computing is to (pre-)process data closer to the source (near to the devices) where it is generated.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Machine learning (ML) techniques, such as federated learning (FL) have emerged to preserve the privacy of data when it is processed. Unlike traditional machine learning techniques, FL does not require raw data generated on the devices to be sent to a server for processing. Instead, FL involves a number of participating devices that train local neural network models that are sent to a server (for example, located on the edge) to aggregate the models and generate a global model.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">FL requires extensive communication between the devices and the server that significantly contributes to the overall time taken to train the model. The cost of communication is usually a bottleneck when the number of devices and the size of the model increases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and when there are network bandwidth constraints and high dimensional model updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Therefore, it is essential to optimise communication in FL.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">There is a significant body of research on strategies for optimising communication between devices and the server in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Many of these strategies are highly intrusive and require substantial reengineering of the application since they are directly implemented at the algorithmic level of FL.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We argue that one key opportunity where there is a limited research focus for optimising communication in FL is the underlying communication protocols (both application and transport layers) that contribute to communication in FL.
There are a variety of communication protocols, such as the Message Queue Telemetry Transport (MQTT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, Advanced Message Queuing Protocol (AMQP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, ZeroMQ Message Transport Protocol (ZMTP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and socket implementations of TCP and UDP that are available for implementing FL.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">However, there is a limited understanding of how these protocols impact communication in FL.
Such an understanding is essential to determine whether the communication protocols need to be carefully or can be arbitrarily chosen. If the protocols impact communication, then end-to-end system designers and developers will need to identify and select performance efficient combinations of application and transport layer protocols when developing novel edge computing systems and applications.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">This paper presents a methodology, namely <span id="S1.p7.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> that benchmarks a variety of lightweight application layer and transport layer protocols within the context of FL. The classic FL implementation suitable for resource constrained devices and can operate in a device-edge environment presented in FedAdapt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> is chosen for <span id="S1.p7.1.2" class="ltx_text ltx_font_typewriter">FedComm</span>. Metrics that capture performance aspects, including the accuracy of the model, and communication time in diverse network conditions, namely 3G, 4G and Wi-Fi based networks are considered.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">We anticipate that <span id="S1.p8.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> will be useful to determine the answers of at least three fundamental questions: (i) How computational and network constraints, including packet loss affect the communication time and model accuracy of FL when using a given application layer protocol? (ii) Which application layer protocols are suitable for executing FL in resource constrained environments without requiring substantial or additional hardware and complex software environments? (iii) Given no constraints on the network and computation, which application layer protocol(s) deliver the best communication performance during FL training?</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">The results from a lab-based experimental testbed for <span id="S1.p9.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> provides early insights into the effect of communication protocols on FL.
The experimental studies highlight that when the network conditions are good (4G and Wi-Fi settings), TCP socket implementation achieves better communication time and accuracy than when using UDP. However, the TCP socket implementation poorly performs under poor network conditions in terms of communication time. In 4G and Wi-Fi networks, however, the effect on UDP accuracy is lower than that of TCP, but the communication time remains large. TCP accuracy is consistent even in poor network conditions, whereas UDP accuracy is significantly affected by poor network conditions such as 3G. TCP socket is considered the best non-optimized application layer protocol if the network conditions are not poor. Optimized application layer protocols, such as AMQP or MQTT, and ZMTP, produce the best results across all experiments, resulting in a communication time reduction of 2.5x compared to TCP socket while maintaining accuracy with a small difference of <math id="S1.p9.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S1.p9.1.m1.1a"><mo id="S1.p9.1.m1.1.1" xref="S1.p9.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S1.p9.1.m1.1b"><lt id="S1.p9.1.m1.1.1.cmml" xref="S1.p9.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S1.p9.1.m1.1c">&lt;</annotation></semantics></math>0.5%. <span id="S1.p9.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> is available for public use<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/qub-blesson/FedComm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/qub-blesson/FedComm</a></span></span></span>.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">The contributions of this paper are:</p>
</div>
<div id="S1.p11" class="ltx_para">
<p id="S1.p11.1" class="ltx_p">(i) The development of an FL benchmarking methodology, <span id="S1.p11.1.1" class="ltx_text ltx_font_typewriter">FedComm</span>  that operates in a device-to-edge environment that quantifies the system performance when using different communication protocols.</p>
</div>
<div id="S1.p12" class="ltx_para">
<p id="S1.p12.1" class="ltx_p">(ii) The evaluation of five application layer protocols that are relevant to FL in edge computing environments.</p>
</div>
<div id="S1.p13" class="ltx_para">
<p id="S1.p13.1" class="ltx_p">(iii) The identification and collection of metrics that capture the performance of FL under varying network conditions using different application layer protocols.</p>
</div>
<div id="S1.p14" class="ltx_para">
<p id="S1.p14.1" class="ltx_p">(iv) An experimental evaluation using <span id="S1.p14.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> on a lab-based testbed.</p>
</div>
<div id="S1.p15" class="ltx_para">
<p id="S1.p15.1" class="ltx_p">The rest of this paper is organised as follows.
Section <a href="#S2" title="II Related Work ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> presents related research.
Section <a href="#S3" title="III FedComm ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> presents the <span id="S1.p15.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> motivation, protocols used and the benchmarking methodology.
Section <a href="#S4" title="IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> presents the experimental studies from a lab-based testbed.
Section <a href="#S5" title="V Discussion &amp; Conclusions ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> concludes this paper by summarising the experimental studies and highlighting future work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section will consider relevant research related to edge-based FL, communication overheads in FL and the communication protocols in FL.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Edge-based FL</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Edge computing is a natural fit for applying FL paradigm as it facilitates collaborative training on end-user devices or edge nodes. There are two significant benefits in bringing together FL and edge computing: (i) user devices and edge nodes generate large volume of data, which need to be analyzed to extract insight from them for automated decision making by machine learning techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>; (ii) FL provides a distributed machine learning solution to extract knowledge from data in a privacy-preserving manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">However, running conventional FL in edge environments is challenging for two reasons: the relatively limited computational resources available on devices and a wide-range of heterogeneous devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. In particular, end-user devices and edge nodes usually have limited computation resources compared to the cloud, resulting in impractical local training time in conventional FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. In addition, end-user devices and edge nodes tend to be highly heterogeneous in terms of computation and communication capacity, which further degrades the performances of a edge-based FL system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">To address the above challenges, recent research has proposed reducing the amount of computational workload on end-user devices using techniques such as model pruning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, computation offloading <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, partial training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and gradient sparsification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
Personalized FL has also been proposed to surmount the challenges arising due to device heterogeneity in a cloud-edge based FL system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. FedAdapt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> adopts the reinforcement learning technique to adjust the amount of computation that is offloaded to the edge server, thereby adapting to varying resource availability and computational capacities of heterogeneous end-user devices. However, above researches rarely consider the effect of different communication protocols for a edge-based FL system since end-user devices and edge nodes always need customized communication protocols to meet their application requirements.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Communication overhead in FL</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The communication overhead incurred in FL is well documented in the existing research literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Multiple communication-efficient approaches have been proposed to alleviate this problem. These approaches can be grouped into three categories - those that: (i) reduce the frequency of device updates, (ii) adopt compression schemes; (iii) optimise the FL architecture.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">There is research on selecting the participating end-user devices to reduce the overall communication costs between end-user devices and the server in each round of FL training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. In addition, reducing the frequency of model updates for each device also reduces the total communication overhead <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. There is a large body of research that focuses on compression schemes. For example, FetchSGD compresses the gradient by employing a sketching technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. An online learning approach based on an adaptive degree of sparsity for gradient sparsification on non-i.i.d. local datasets is developed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. In addition, Fedpaq <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> introduces the quantization technique to compress the size of communicated updates of each end-user device before sending them to the server.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">In contrast to the above approaches, there is research that focuses on optimising the architecture of FL to reduce the overall communication overhead. RingFed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> reduces communication costs by limiting data transfers between the server and devices. This is achieved by only one device receiving model updates from the server and then passing it on to other clients in a ring topology. HierFAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> reduces the overall communication cost, training time and energy consumption of the end-user devices by introducing the intermediate edge servers in traditional cloud-based FL systems.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">Current communication reduction approaches in FL pay less attention to the basic communication protocols adopted between end-user devices and the server. Alternate approaches to the above as mentioned previously is to employ lightweight communication protocols, such as MQTT, AMQP, ZMPT and UDP, or develop new protocols that are suited for FL. However, the current literature has limited research on the impact of these protocols on FL.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Communication Protocols in FL</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In an edge-based FL system, the global model is collaboratively trained across a large number of end-user devices with limited network bandwidth and unstable connections <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. As a result, the communication cost is a key consideration in FL training. Current FL research and frameworks adopt the TCP protocol for the communication between end-user devices and the server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. One major advantage of using TCP protocol is that it guarantees complete transmission of model updates from each end-user devices. However, when the network connections are relatively poor, the use of TCP leads to large re-transmissions, which negatively impacts the training time.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Developing the underlying communication protocols suited for FL will make data transmission more efficient. For instance, recent research explores the use of UDP protocols for communication and shows that UDP-based protocols will require less time than those that are TCP-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. In addition, a soft-DSGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> method is proposed to mitigate the effect of missing model parameters (due to using UDP protocol). This is achieved by adjusting the weights of updated models during aggregation based on communication reliability. However, there is limited research on the underlying protocols and current research has neither systematically explored the TCP and UDP protocols nor have considered the protocols of the application layer. Therefore, the focus of this paper is a preliminary step in this direction to quantify the impact of communication protocols in FL.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">FedComm</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section describes the rationale behind <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> benchmarking and its potential benefits and the communication protocols that are evaluated.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Motivation</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To the best of our knowledge, benchmarking lightweight application layer protocols under FL has not been carried done to this extent before. The main goal of this study is to highlight the outcomes of evaluating lightweight application layer protocols in comparison to standard socket implementations of TCP. The emphasis is on identifying protocols that reduce the communication time and highlighting their pros and cons under different network conditions.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> offers a series of tests that determines which communication protocols are beneficial in real-world FL scenarios. It should be noted that the aim of this paper is not to accelerate FL by implementing new mechanisms or protocols; rather, it considers existing application and transport layer protocols that developers can choose to easily incorporate into their own FL applications.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">We anticipate a better understanding of application layer protocols in the context of FL as a result of this study. <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> also benefits the FL community by utilizing lightweight application layer protocols to improve communication time without the use of additional hardware, specialized equipment, or large software environments.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Protocols</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> coined the term FL in 2016, which is a privacy-preserving ML technique in which an ML model is collaboratively learned across several distributed devices (e.g., mobile phones), while all training data is kept on local devices. An FL system is shown in Figure <a href="#S3.F1" title="Figure 1 ‣ III-B Protocols ‣ III FedComm ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In the first step, the edge server initiates the global model and distributes the model parameters to all connected edge devices. In the second step, each local edge device trains a local version of the ML model on its local data. Instead of sending raw data to the server (edge), only the local model parameter updates are sent up to the server. In the third step, the server computes a weighted average of the parameter updates on the server using the Federated Averaging (FedAvg) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> algorithm to obtain the new set of parameters for the global model. In the fourth step, a new global model is then sent back down to each device for the next round of training by the edge server. The entire process is repeated until the model converges.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2208.08764/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="212" height="274" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Overview of federated learning.</span></figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">FL employs transport layer and application layer protocols to send and receive deep neural network (DNN) model parameters between the devices and the server.
The developer can choose from protocols at two main layers of the OSI model: Layer 4 (transport) and Layer 7 (application). The developer must select a transport layer protocol that will serve as the foundation of communication. The developer then has the option of using a standard socket implementation of TCP/UDP or an alternative application layer protocol, such as MQTT, ZMTP, and AMQP.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">At the application layer, <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> currently evaluates socket TCP/UDP, MQTT, AMQP, and ZMTP. At the transport layer, all of these protocols use either TCP or UDP. The subsequent section discusses the transport layer and application layer protocols for the FL system.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.5.1.1" class="ltx_text">III-B</span>1 </span>Transport Layer Protocols</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">TCP as a transport layer protocol, is widely used in FL. TCP provides reliability through packet re-transmission, ensuring that model parameters are correctly sent and received by the device or server. TCP may be slower than other transport layer protocols, such as UDP, due to packet re-transmission. However, in terms of reliability, TCP remains the best transport layer protocol and is extensively used.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">UDP on the other hand, is used in scenarios where packet loss is not a major concern and the overall performance measured by time is the most important factor. Packet loss can significantly affect model accuracy in the context of FL. Moreover, FL typically employs low-power devices, which are vulnerable to large packet loss rates under poor network conditions, limiting the learning rate of DNN models in comparison to TCP.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">In <span id="S3.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_typewriter">FedComm</span>, we evaluate both the above transport layer protocols using a standard socket implementation.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.5.1.1" class="ltx_text">III-B</span>2 </span>Application Layer Protocols</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Application layer protocols are implemented at the seventh layer of the OSI model and are used for application communication. They provide rules for how data is exchanged. Source and destination applications must use the same protocol for accurate communication and to avoid transferring incompatible or inaccurate data that causes applications to fail. Application layer protocols have their own rules and can be used for purposes other than transferring data, such as transferring data in poor network conditions or providing lightweight communication for low power devices seen at the edge (or extreme edge), such as single board computers.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">FL algorithms with the proliferation of the Internet-of-Things are required to run on low-power devices that have relatively less processing power and will operate in ‘in-the-wild’ scenarios that may have poor network conditions when compared to cloud data centre type environments. Application layer protocols designed for low-power IoT devices in poor network conditions, such as MQTT, AMQP, and ZMTP are useful in such cases for communication in FL.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p"><span id="S3.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_italic">MQTT</span> is a lightweight application layer protocol that implements a publish-subscribe architecture over TCP and is intended for use in low-power devices and microcontrollers in unreliable networks with limited bandwidth. There is no direct connection between a sender (publisher) and receiver (subscriber). An MQTT broker is used as a central system for communication between them and is responsible for filtering all incoming messages from publisher and distributing them to subscribers.
An MQTT client sends a single packet to the MQTT broker, which publishes it to all subscribers on devices and server backend systems. MQTT keeps a persistent connection to the broker.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.1" class="ltx_p"><span id="S3.SS2.SSS2.p4.1.1" class="ltx_text ltx_font_italic">AMQP</span> is an application layer protocol that runs over TCP at the transport layer and is designed for communication with middleware brokers such as RabbitMQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. AMQP is more advanced than MQTT, with built-in security and support for multiple architectures such as client/broker and client/server, and multiple exchange types such as direct, fan-out, topic, and headers. The AMQP fan-out exchange was used in <span id="S3.SS2.SSS2.p4.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> because it routes messages to all queues that are bound to it, which is similar to what MQTT provides. Although AMQP has a larger header file than MQTT, it is faster and cost effective.</p>
</div>
<div id="S3.SS2.SSS2.p5" class="ltx_para">
<p id="S3.SS2.SSS2.p5.1" class="ltx_p"><span id="S3.SS2.SSS2.p5.1.1" class="ltx_text ltx_font_italic">ZMTP</span> uses TCP at the transport layer and implements various architectures such as publish-subscribe, request-reply, and push-pull. ZMTP employs sockets rather than a broker server, potentially eliminating the broker overhead that may be present in other optimised application layer protocols.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Benchmarking Methodology</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p"><span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> aims to automatically benchmark FL using a variety of application layer protocols, with a focus on communication time and accuracy. Figure <a href="#S3.F2" title="Figure 2 ‣ III-C Benchmarking Methodology ‣ III FedComm ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> method, which consists of the following steps:</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 1 - Select application layer protocol</span>:
In the first step, the user manually selects from the list of application<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>TCP socket and UDP socket are non-optimized application layer protocols, and MQTT, AMQP, and ZMTP are optimised application layer protocols.</span></span></span> layer protocols available in <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_typewriter">FedComm</span>. All devices must communicate using the protocol selected at the application layer in order to transfer FL model parameters. This step is optional; if not chosen, then communication will take place via the TCP socket by default.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 2 - Select the FL model type</span>:
In the second step, the user chooses from a list of available FL models<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Support for the VGG-5 and VGG-8 DNN models is currently offered. The implementation can be easily extended to support other models.</span></span></span>. The model will be transferred between devices and server using the application layer protocol chosen from Step 1. This step is optional; if no model is selected, then in <span id="S3.SS3.p3.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> the VGG-8 model is used as the default.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 3 - Set round counter</span>:
In the third step, the user determines how many rounds to run FL on all devices. One round consists of all devices receiving a model with initial or new weights from the server. Devices then train the selected model locally and send new weights to the server, where the aggregation process combines the trained model weights. This is optional; if the counter is not specified, then <span id="S3.SS3.p4.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> runs five FL rounds as default.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2208.08764/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="221" height="374" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedComm<span id="S3.F2.4.2.1" class="ltx_text ltx_font_serif"> benchmaking method.</span></span></figcaption>
</figure>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p"><span id="S3.SS3.p5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 4 - Apply CPU and network stress</span>:
CPU and network stress is applied in this step. CPU stress is applied by performing intensive matrix computations to rapidly increase CPU activity to reduce the amount of computational resources available for running FL to represent the environment of a device with relatively limited computational capabilities. Network stress is applied by sending an influx of TCP packets between the device and the server in order to generate network traffic for representing a networked device operating in an environment with varying network conditions. The user is provided with the option to either select CPU or network stress; this step is optional, and no stressor is selected by default.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.1" class="ltx_p"><span id="S3.SS3.p6.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 5 - Apply network limiter</span>:
Using an internal bandwidth limiter, this step emulates specific network conditions, similar to Step 4. A list of bandwidth limits are provided as options to the user to select from, including a 5Mbps limit for 3G bandwidth, a 20Mbps limit for 4G bandwidth, and a 60Mbps limit for Wi-Fi bandwidth. This step is optional, and by default, the entire available bandwidth is utilised and no network constraints are applied.</p>
</div>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p"><span id="S3.SS3.p7.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 6 - Select target device</span>:
In this step, the IP address of the server and of the participating devices are provided by the user as metadata in a configuration file. The FL process is initiated on the server.</p>
</div>
<div id="S3.SS3.p8" class="ltx_para">
<p id="S3.SS3.p8.1" class="ltx_p"><span id="S3.SS3.p8.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 7 - Run FL process</span>:
After completing all of the preceding steps, a classic FL task will be executed (as shown in Figure <a href="#S3.F1" title="Figure 1 ‣ III-B Protocols ‣ III FedComm ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The server will initiate model parameters and distribute them to each participating device via the application layer protocol. The devices will train the model and send it back to the server for testing, where the server collects the necessary metrics and stores them as a file.</p>
</div>
<div id="S3.SS3.p9" class="ltx_para">
<p id="S3.SS3.p9.1" class="ltx_p"><span id="S3.SS3.p9.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 8 - Monitor network</span>:
In this step, the network is monitored for the re-transmissions of TCP packets.
Once the FL process is completed, the number of packets re-transmitted across all clients is recorded, and output metrics are saved to a pickle file on the edge server.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experimental Studies</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents the evaluation results obtained using <span id="S4.p1.1.1" class="ltx_text ltx_font_typewriter">FedComm</span>Ṫhe experimental setup and protocol setup are presented in Section <a href="#S4.SS1" title="IV-A Setup ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>. Section <a href="#S4.SS2" title="IV-B Benchmark Metrics ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a> discusses performance evaluation metrics, and Section <a href="#S4.SS3" title="IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a> presents the results.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Setup</span>
</h3>

<section id="S4.SS1.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Experimental Setup</h4>

<div id="S4.SS1.SSSx1.p1" class="ltx_para">
<p id="S4.SS1.SSSx1.p1.1" class="ltx_p">All experiments were carried out on a lab-based testbed comprising five virtual machines running Ubuntu 20.04.3 LTS, one of which serves as the server and the other four as devices. The server has 16GB of DIMM DRAM EDO memory, an octa-core Intel Xeon E5 CPU E5-2695 v4 @ 2.10GHz, and 105GB of storage. The devices include 2GB of DRAM memory, a single core of the Intel Xeon E5 CPU E5-2695 v4 @ 2.10GHz, and 30GB of storage.</p>
</div>
<div id="S4.SS1.SSSx1.p2" class="ltx_para">
<p id="S4.SS1.SSSx1.p2.1" class="ltx_p">The DNN models used are VGG-5 and VGG-8, and the dataset is CIFAR-10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. The dataset contains 50K training samples and 10K testing samples. The FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> aggregation method is used on the server.</p>
</div>
</section>
<section id="S4.SS1.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Protocol Setup</h4>

<div id="S4.SS1.SSSx2.p1" class="ltx_para">
<p id="S4.SS1.SSSx2.p1.1" class="ltx_p">The configuration related to enabling the protocols for <span id="S4.SS1.SSSx2.p1.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> are as follows:</p>
</div>
<div id="S4.SS1.SSSx2.p2" class="ltx_para">
<p id="S4.SS1.SSSx2.p2.1" class="ltx_p">(i) TCP, UDP and ZMTP required no additional configuration; the built-in Python module socket was used for communication.</p>
</div>
<div id="S4.SS1.SSSx2.p3" class="ltx_para">
<p id="S4.SS1.SSSx2.p3.1" class="ltx_p">(ii) Experiments using MQTT require the installation of Mosquitto <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, a MQTT broker, on the server machine where all clients and server establish a connection using the <span id="S4.SS1.SSSx2.p3.1.1" class="ltx_text ltx_font_typewriter">paho-mqtt</span> Python module. To enable remote connections from other client machines, a new Mosquitto configuration file must be created with the listener set to port 1883 and anonymous connections enabled. The Mosquitto broker must be started before using MQTT within <span id="S4.SS1.SSSx2.p3.1.2" class="ltx_text ltx_font_typewriter">FedComm</span>.</p>
</div>
<div id="S4.SS1.SSSx2.p4" class="ltx_para">
<p id="S4.SS1.SSSx2.p4.1" class="ltx_p">(iii) Similar to MQTT, AMQP experiments require the installation of the open source messaging broker RabbitMQ, and a connection must be established between all client machines and a single server in order to send and receive messages. The Python <span id="S4.SS1.SSSx2.p4.1.1" class="ltx_text ltx_font_typewriter">pika</span> module is required for the client-server message exchange.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Benchmark Metrics</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The performance metrics for the evaluation of protocols used in <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">FedComm</span> are as follows:</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">1) <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Communication time</span> - This metric calculates the total communication time across all FL rounds. The communication time includes the time spent sending and receiving model parameters between the devices and server during FL training. We aim to understand the impact on communication time when computational stress and network stress are there in the environment and packet losses occur.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">a) <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_italic">Communication time under computational stress:</span>
This metric measures the total communication time under computational stress. The <span id="S4.SS2.p3.1.2" class="ltx_text ltx_font_typewriter">stress-ng</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> module is used to spawn threads to increase the number of computations performed on the compute core of the device in order to simulate a working networked device. Stress-ng computes 830 ops/s using 99% of the CPU power to simulate a low-power device incapable of performing large tasks.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">b) <span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_italic">Communication time under network stress:</span>
This metric measures the total amount of communication time spent under network stress. <span id="S4.SS2.p4.1.2" class="ltx_text ltx_font_typewriter">Netstress</span> emulates an active network, sending messages at around 250 Mbits/s.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">c) <span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_italic">Communication time under packet loss:</span>
This metric measures the total amount of communication time spent when the packet loss rate varies. Packet loss is calculated as the percentage of packets received incorrectly or not at all at a destination. To simulate packet loss, we use the <span id="S4.SS2.p5.1.2" class="ltx_text ltx_font_typewriter">tc</span> tool and simulate 0%, 5%, 10%, and 20% packet loss rates.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p">2) <span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Accuracy</span> - Accuracy is defined as the number of correct predictions divided by the total number of predictions. This metric measures how accurate the new aggregated model is against the test data in each FL round.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Results</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">This section evaluates the non-optimized and optimized application layer protocols under varying network conditions and presents the above performance metrics.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">1) <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">Non-optimized Application Layer Protocols</span></p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Communication time without computational/network stress:</span> Figure <a href="#S4.F3.sf1" title="In Figure 3 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> and Figure <a href="#S4.F3.sf2" title="In Figure 3 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> shows the communication time by comparing TCP socket and UDP socket after 5 rounds of the VGG-5 and VGG-8 models for varying network settings. When the network bandwidth increases from that of 3G to Wi-Fi, there is a consistent decrease in communication time when using TCP for both VGG-5 and VGG-8. Moreover, when the model parameters are smaller, such as for VGG-5, TCP sockets significantly outperform UDP sockets in terms of time spent transferring the model to another device under 4G and Wi-Fi network conditions. However, when network conditions are relatively poorer, such as in 3G, UDP outperforms TCP and is suitable for larger models. TCP performs well when measuring communication time for relatively good network bandwidths and small models. When the network condition is poorer and large models are required, UDP performs better than TCP. This is because there are no re-transmissions due to packet loss in the network when using UDP. However, TCP by design re-transmits packets, increasing communication time if the network condition is poor.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_UDP_Comm_VGG5.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="425" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">VGG-5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_UDP_Comm.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="425" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">VGG-8</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Communication time when using TCP and UDP sockets after 5 training rounds for VGG-5 and VGG-8 models under different network settings when under no stress.</span></figcaption>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">Communication time under computational stress:</span> Figure <a href="#S4.F4.sf1" title="In Figure 4 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> shows that when 99% CPU stress is applied, communication time using the TCP socket is affected more than UDP for the VGG-5 model. In comparison to Figure <a href="#S4.F3.sf1" title="In Figure 3 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>, Figure <a href="#S4.F4.sf1" title="In Figure 4 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> shows that TCP increases by a total of 16.82 seconds across all network conditions, whereas UDP maintains consistency while only adding 2.72 seconds to total communication time. Figure <a href="#S4.F4.sf2" title="In Figure 4 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a> shows that when CPU stress is applied to the larger VGG-8 model, the UDP communication time increases by 49.19 seconds, whereas the TCP socket communication time increases by 22.61 seconds when compared to Figure <a href="#S4.F3.sf2" title="In Figure 3 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>. Overall, CPU stress has a significant impact on UDP for larger models. This is due to the implementation of UDP and the additional processing required to send and receive model parameters in FL. Computationally intensive DNN models will therefore have a substantial impact on UDP performance on low-powered devices with poor CPU performance.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_UDP_CPUSTRESS_VGG5.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="425" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">VGG-5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_UDP_CPUSTRESS.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="425" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">VGG-8</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Communication time when using TCP and UDP sockets after 5 training rounds for VGG-5 and VGG-8 models under different network settings while under CPU stress.</span></figcaption>
</figure>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_bold">Communication time under network stress:</span>
Figure <a href="#S4.F5.sf1" title="In Figure 5 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a> and Figure <a href="#S4.F5.sf2" title="In Figure 5 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a> show the communication time when network stress is applied when using VGG-5 and VGG-8 models.
It is noted that network stress influences UDP less adversely than CPU stress due to the additional computations performed during CPU stress. Moreover, the observed performance of UDP under network stress when using the VGG-5 model may also be since a small number of model parameters that have no effect on the overall communication time are used. As an application layer protocol, the TCP socket is significantly impacted by network stress, which increases communication time when compared to CPU stress. UDP outperforms TCP in all network stress tests conducted with the VGG-8 model. The results shown in Figure <a href="#S4.F5.sf1" title="In Figure 5 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a> and Figure <a href="#S4.F5.sf2" title="In Figure 5 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a> indicate that UDP performs well under 3G network conditions and can therefore be recommended if accuracy is not a concern.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_UDP_NETSTRESS_VGG5.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="429" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F5.sf1.3.2" class="ltx_text" style="font-size:90%;">VGG-5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_UDP_NETSTRESS.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="417" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F5.sf2.3.2" class="ltx_text" style="font-size:90%;">VGG-8</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Communication time when using TCP and UDP sockets after 5 training rounds for VGG-5 and VGG-8 models with different network settings under network stress.</span></figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TvU_5.png" id="S4.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="454" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">VGG-5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TvU_8.png" id="S4.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="454" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">VGG-8</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Communication time when using TCP and UDP sockets after 5 training rounds for VGG-5 and VGG-8 models under different packet loss rates.</span></figcaption>
</figure>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.1" class="ltx_p"><span id="S4.SS3.p6.1.1" class="ltx_text ltx_font_bold">Communication time under packet loss rate:</span>
Figure <a href="#S4.F6.sf1" title="In Figure 6 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> and Figure <a href="#S4.F6.sf2" title="In Figure 6 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> shows the communication time under various packet loss rates of 0%, 5%, 10%, and 20% for both the VGG-5 and VGG-8 models. It is evident that UDP communication time is uniform across varying packet loss rates, whereas TCP communication time increases significantly when the packet loss ranges from 0% to 20%. Variable packet loss rates have a significant impact on TCP socket and the major reason is that TCP re-transmits all packets that were received incorrectly or were not received. A lower communication time is observed for UDP since it is a connectionless protocol that does not re-transmit packets.</p>
</div>
<div id="S4.SS3.p7" class="ltx_para">
<p id="S4.SS3.p7.1" class="ltx_p"><span id="S4.SS3.p7.1.1" class="ltx_text ltx_font_bold">Accuracy:</span>
Figure <a href="#S4.F7" title="Figure 7 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> highlights that TCP maintains accuracy in all network conditions because TCP is a reliable protocol that re-transmits all packets that were incorrectly received or were not successfully transmitted. TCP re-transmits packets until all packets are successfully received, and as a result, accuracy is preserved. On the other hand, the accuracy of UDP is inconsistent, particularly for 3G networks. When the network condition is poor, there is a greater possibility of packet loss, which impacts the overall accuracy. The packet loss rate for 4G and Wi-Fi network conditions is relatively low; there is a negligible decrease in accuracy when switching from 4G to Wi-Fi. It should be noted that there is no direct link between packet loss and the quality of network conditions, as other factors, such as network congestion, transmission power and fading can affect the rate at which packets are lost.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2208.08764/assets/images/TCP_UDP_Acc.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Accuracy when using TCP and UDP sockets after 100 training rounds of the VGG-5 model under different network conditions.</span></figcaption>
</figure>
<div id="S4.SS3.p8" class="ltx_para">
<p id="S4.SS3.p8.1" class="ltx_p">2) <span id="S4.SS3.p8.1.1" class="ltx_text ltx_font_italic">Non-optimized Application Layer Protocols</span>
When comparing the results, TCP socket is the preferred non-optimized application layer protocol in most cases, and all of the optimized application layer protocols tested in <span id="S4.SS3.p8.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> use TCP at the transport layer. Therefore, this section compares the optimized application layer protocols when using the non-optimized socket implementation of TCP.</p>
</div>
<div id="S4.SS3.p9" class="ltx_para">
<p id="S4.SS3.p9.1" class="ltx_p"><span id="S4.SS3.p9.1.1" class="ltx_text ltx_font_bold">Communication time without computational/network stress:</span> Figure <a href="#S4.F8.sf1" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> and Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a> shows the communication time against various network conditions involving TCP and all application layer protocols under the VGG-5 and VGG-8 models. Under most network conditions, TCP’s performance is poor resulting in the largest communication time. AMQP is 1.75x faster than TCP in 3G network conditions, 2.15x faster in 4G network conditions, and 2.5x faster in Wi-Fi. AMQP and MQTT perform almost the same in all network conditions with both models. This is potentially because AMQP and MQTT use brokers to distribute a single message to all devices, whereas TCP requires one message per device. ZMTP, despite being an optimized application layer protocol, performs similarly to TCP in most network conditions, as shown in Figure <a href="#S4.F8.sf1" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> and Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>. MQTT performs better when small amounts of data are transferred (for the VGG-5 model), whereas AMQP performs better overall for the VGG-8 model when more data is transferred per round.</p>
</div>
<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_MQTT_AMQP_Comm_VGG5.png" id="S4.F8.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F8.sf1.3.2" class="ltx_text" style="font-size:90%;">VGG-5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_MQTT_AMQP_Comm.png" id="S4.F8.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F8.sf2.3.2" class="ltx_text" style="font-size:90%;">VGG-8</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.3.2" class="ltx_text" style="font-size:90%;">Communication time when using TCP socket, MQTT, AMQP and ZMTP after 5 training rounds of the VGG-5 and VGG-8 model under different network settings.</span></figcaption>
</figure>
<div id="S4.SS3.p10" class="ltx_para">
<p id="S4.SS3.p10.1" class="ltx_p"><span id="S4.SS3.p10.1.1" class="ltx_text ltx_font_bold">Communication time under computational stress:</span> CPU stress on all devices has different effects on each protocol because they are designed for use in different scenarios. With 99% CPU stress, TCP has a 22.5 second increase in communication time, MQTT has a 40.6 second increase, and AMQP has a 42.3 second increase from Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a> to Figure <a href="#S4.F9.sf2" title="In Figure 9 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a>. The IoT-based protocols gain a larger increase in communication time, but they outperform socket TCP. The AMQP implementation relies on additional threads created by the developer to listen for incoming messages, which can be limiting for devices that can only run a single thread. This has a significant impact on computation, resulting in a large increase in communication time. MQTT is similar to AMQP, but handles the additional thread automatically. TCP does not require threads, which reduces the impact of CPU stress.</p>
</div>
<div id="S4.SS3.p11" class="ltx_para">
<p id="S4.SS3.p11.1" class="ltx_p"><span id="S4.SS3.p11.1.1" class="ltx_text ltx_font_bold">Communication time under network stress:</span> The effects of network stress are almost similar to those shown in Figure <a href="#S4.F8.sf1" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> and Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>. This is because network stress works similarly to the <span id="S4.SS3.p11.1.2" class="ltx_text ltx_font_typewriter">tc</span> command, limiting the network bandwidth. In Figure <a href="#S5.F10.sf2" title="In Figure 10 ‣ V Discussion &amp; Conclusions ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(b)</span></a>, TCP performs the worst with the slowest time and an increase in communication time of 158 seconds (Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>). AMQP performs the best with the fastest time and an increase in communication time of 114 seconds (Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>). MQTT performs moderately with an increase in communication time of 123 seconds (Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-C Results ‣ IV Experimental Studies ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>). MQTT and AMQP are designed to operate in poor network conditions because the server sends only one message to the broker, which is then distributed to all the devices. However, TCP sends the messages directly to the four devices that results in poorer performance by TCP.</p>
</div>
<figure id="S4.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_MQTT_AMQP_CPUSTRESS_vgg5.png" id="S4.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F9.sf1.3.2" class="ltx_text" style="font-size:90%;">VGG-5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_MQTT_AMQP_CPUSTRESS.png" id="S4.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F9.sf2.3.2" class="ltx_text" style="font-size:90%;">VGG-8</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S4.F9.3.2" class="ltx_text" style="font-size:90%;">Communication time when using TCP socket, MQTT, AMQP and ZMTP after 5 training rounds of the VGG-5 and VGG-8 models for different network settings while under CPU stress.</span></figcaption>
</figure>
<div id="S4.SS3.p12" class="ltx_para">
<p id="S4.SS3.p12.1" class="ltx_p"><span id="S4.SS3.p12.1.1" class="ltx_text ltx_font_bold">Accuracy:</span>
The accuracy for socket TCP and all optimized application layer protocols remains largely similar with a few exceptions as in Figure <a href="#S5.F11" title="Figure 11 ‣ V Discussion &amp; Conclusions ‣ FedComm: Understanding Communication Protocols for Edge-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. The exceptions have a less than 0.5% difference which may be due to how the <span id="S4.SS3.p12.1.2" class="ltx_text ltx_font_typewriter">tc</span> command is used with the brokers or how the optimized application layer protocols have been designed. The main reason that accuracy is preserved is because these protocols all use TCP as the transport layer protocol.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Discussion &amp; Conclusions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we proposed <span id="S5.p1.1.1" class="ltx_text ltx_font_typewriter">FedComm</span>,  a benchmarking method for FL application layer protocols. We evaluated the major application layer protocols that could be used in a FL context, such as standard TCP, standard UDP, MQTT, AMQP, and ZMTP. In summary, it is observed that the results of UDP seem inconsistent and not in line with the considerations taken into account when designing UDP. However, there are several factors related to the FL algorithm that may skew the UDP results. First of all, UDP requires additional computation, in sending the weights, requiring the model to be split up into multiple chunks that adhere to the UDP protocol size restriction. Furthermore, the UDP implementation uses TCP to send END messages to indicate the final weight sent per round; however, the implementation requires an additional thread to receive this, resulting in extra waiting periods and affecting communication time. Furthermore, if packets are lost during transmission, UDP requires additional computation to fill in the missing chunks and make sure the model is the correct size. This is common in poor network conditions; therefore, it would be computationally expensive to guarantee the missing chunks.</p>
</div>
<figure id="S5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_MQTT_AMQP_NETSTRESS_vgg5.png" id="S5.F10.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="299" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F10.sf1.3.2" class="ltx_text" style="font-size:90%;">VGG-5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08764/assets/images/TCP_MQTT_AMQP_NETSTRESS.png" id="S5.F10.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="293" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F10.sf2.3.2" class="ltx_text" style="font-size:90%;">VGG-8</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S5.F10.3.2" class="ltx_text" style="font-size:90%;">Communication time when using TCP socket, MQTT, AMQP and ZMTP after 5 training rounds of the VGG-5 and VGG-8 models for different network settings while under network stress.</span></figcaption>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Optimized application layer protocols have outperformed the basic implementation of TCP/UDP in most aspects of the evaluation. According to the results, the two broker-based application layer protocols perform better, with AMQP having the best performance, followed by MQTT. Broker-based applications outperform socket-based implementations due to the messaging architecture and protocol design, despite the fact that broker-based applications may require more work to set up.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">The ZMTP protocol uses the publish/subscribe model that broker-based protocols use, but it uses sockets to create one-way communication. This is less efficient than MQTT and AMQP, which affects the overall performance.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">In the majority of experiments, the two socket-based implementations perform the worst. TCP socket implementation outperforms UDP in all experiments in terms of communication time and accuracy when network conditions are good, but performs the worst in terms of communication time when network conditions are poor. Therefore, when network conditions are not guaranteed, either AMQP or MQTT may be more appropriate for implementing FL as optimized application layer protocols. Moreover, the optimised application layer protocols demonstrated high accuracy with minor differences of less than 0.5% at certain points. Therefore, when compared to non-optimized application layer protocols, optimized application layer protocols are more suitable for FL settings in both poor and good network conditions.</p>
</div>
<figure id="S5.F11" class="ltx_figure"><img src="/html/2208.08764/assets/images/TCP_MQTT_AMQP_Acc.png" id="S5.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="287" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S5.F11.3.2" class="ltx_text" style="font-size:90%;">Accuracy when using TCP socket, MQTT, AMQP and ZMTP after 5 training rounds of the VGG-5 model under Wi-Fi conditions.</span></figcaption>
</figure>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p"><span id="S5.p5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Future Research:</span> Currently, <span id="S5.p5.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> evaluates a limited number of core application layer protocols and highlights the fundamental functionality of each protocol. As a future work, we highlight a number of application layer enhancements within the context of FL that will require further investigation.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p"><span id="S5.p6.1.1" class="ltx_text ltx_font_italic">Reliable implementation of socket UDP for FL:</span> We will improve and thoroughly test UDP socket implementation with additional parameters. <span id="S5.p6.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> will support adjusting the size of UDP chunks, giving users more control over communication time and accuracy.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p"><span id="S5.p7.1.1" class="ltx_text ltx_font_italic">Enhancement of standard MQTT, AMQP and ZMTP for FL:</span> MQTT will be evaluated using various broker configurations, including both local and public brokers, to provide a more in-depth analysis of real-world MQTT usage. Furthermore, MQTT for sensor networks will be added to <span id="S5.p7.1.2" class="ltx_text ltx_font_typewriter">FedComm</span> and compared to standard MQTT in the FL setting.</p>
</div>
<div id="S5.p8" class="ltx_para">
<p id="S5.p8.1" class="ltx_p">Different brokers will be implemented for AMQP to investigate the differences in how AMQP operates; will communication time be reduced? Will the accuracy improve? Will there be a change in packet loss? All of this will be thoroughly investigated. Moreover, we will attempt to change the architecture of AMQP and investigate how this different architecture will affect AMQP in a FL setting.</p>
</div>
<div id="S5.p9" class="ltx_para">
<p id="S5.p9.1" class="ltx_p">ZMTP is highly modifiable; various messaging types will be compared to all application layer protocols, including request/response, pull/push, pipeline, and pairs. To provide a more in-depth evaluation of the application layer protocols in various environments, we will attempt to scale the testbed by adding more devices.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M. Zwolenski and L. Weatherill, “The digital universe: Rich data and the
increasing value of the internet of things,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Journal of
Telecommunications and the Digital Economy</em>, vol. 2, no. 3, pp. 47–1, 2014.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Singh, P. Vepakomma, O. Gupta, and R. Raskar, “Detailed comparison of
communication efficiency of split learning and federated learning,”
<em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.09145</em>, 2019. [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/1909.09145" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1909.09145</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Asad, A. Moustafa, T. Ito, and A. Muhammad, “Evaluating the communication
efficiency in federated learning algorithms,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">2021 IEEE 24th
International Conference on Computer Supported Cooperative Work in Design
(CSCWD)</em>, pp. 552–557, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
P. Zhou, H. Xu, L. H. Lee, P. Fang, and P. Hui, “Are you left out? an
efficient and fair federated learning for personalized profiles on wearable
devices of inferior networking conditions,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on
Interactive, Mobile, Wearable and Ubiquitous Technologies</em>, vol. 6, no. 2,
pp. 1–25, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M. Chen, N. Shlezinger, H. V. Poor, Y. C. Eldar, and S. Cui,
“Communication-efficient federated learning,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
National Academy of Sciences</em>, vol. 118, no. 17, p. e2024789118, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
G. C. Hillar, <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">MQTT Essentials-A lightweight IoT protocol</em>.   Packt Publishing Ltd, 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Kramer, “Advanced message queuing protocol (amqp),” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Linux Journal</em>,
vol. 2009, p. 3, 01 2009.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
“Zeromq message transport protocol.”
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">http://zmtp.org/page:read-the-docs</em>. [Online]. Available:
<a target="_blank" href="https://http://zmtp.org/page:read-the-docs" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://http://zmtp.org/page:read-the-docs</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
D. Wu, R. Ullah, P. Harvey, P. Kilpatrick, I. Spence, and B. Varghese,
“Fedadapt: Adaptive offloading for iot devices in federated learning,”
2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2107.04271" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2107.04271</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, and J. Zhang, “Edge intelligence:
Paving the last mile of artificial intelligence with edge computing,”
<em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, vol. 107, no. 8, pp. 1738–1762, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
H. G. Abreha, M. Hayajneh, and M. A. Serhani, “Federated learning in edge
computing: a systematic survey,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 22, no. 2, p. 450,
2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Q. Xia, W. Ye, Z. Tao, J. Wu, and Q. Li, “A survey of federated learning for
edge computing: Research problems and solutions,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">High-Confidence
Computing</em>, vol. 1, no. 1, p. 100008, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L. U. Khan, W. Saad, Z. Han, E. Hossain, and C. S. Hong, “Federated learning
for internet of things: Recent advances, taxonomy, and open challenges,”
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Gao, M. Kim, S. Abuadbba, Y. Kim, C. Thapa, K. Kim, S. A. Camtepe, H. Kim,
and S. Nepal, “End-to-end evaluation of federated learning and split
learning for internet of things,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">The 39th International Symposium
on Reliable Distributed Systems (SRDS)</em>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
C. Wang, Y. Yang, and P. Zhou, “Towards efficient scheduling of federated
mobile devices under computational and statistical heterogeneity,”
<em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>, vol. 32, no. 2,
pp. 394–410, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Das and T. Brunschwiler, “Privacy is what we care about: Experimental
investigation of federated learning on edge devices,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the First International Workshop on Challenges in Artificial Intelligence
and Machine Learning for Internet of Things</em>, 2019, pp. 39–42.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Imteaj, U. Thakker, S. Wang, J. Li, and M. H. Amini, “Federated learning
for resource-constrained iot devices: Panoramas and state-of-the-art,”
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.10610</em>, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Z. Chai, H. Fayyaz, Z. Fayyaz, A. Anwar, Y. Zhou, N. Baracaldo, H. Ludwig, and
Y. Cheng, “Towards taming the resource and data heterogeneity in federated
learning,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2019 USENIX Conference on Operational Machine Learning
(OpML 19)</em>, 2019, pp. 19–21.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing
Magazine</em>, vol. 37, no. 3, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y. Jiang, S. Wang, V. Valls, B. J. Ko, W.-H. Lee, K. K. Leung, and
L. Tassiulas, “Model pruning enables efficient federated learning on edge
devices,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>,
2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
C. Thapa, P. C. M. Arachchige, S. Camtepe, and L. Sun, “Splitfed: When
federated learning meets split learning,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI
Conference on Artificial Intelligence</em>, vol. 36, no. 8, 2022, pp. 8485–8493.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Z. Xu, F. Yu, J. Xiong, and X. Chen, “Helios: Heterogeneity-aware federated
learning with dynamically balanced collaboration,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2021 58th
ACM/IEEE Design Automation Conference (DAC)</em>.   IEEE, 2021, pp. 997–1002.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
P. Han, S. Wang, and K. K. Leung, “Adaptive gradient sparsification for
efficient federated learning: An online learning approach,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">2020
IEEE 40th International Conference on Distributed Computing Systems
(ICDCS)</em>.   IEEE, 2020, pp. 300–310.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
A. Fallah, A. Mokhtari, and A. Ozdaglar, “Personalized federated learning: A
meta-learning approach,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.07948</em>, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
D. Wu, R. Ullah, P. Harvey, P. Kilpatrick, I. Spence, and B. Varghese,
“Fedadapt: Adaptive offloading for iot devices in federated learning,”
<em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances
and open problems in federated learning,” <em id="bib.bib27.2.2" class="ltx_emph ltx_font_italic">Foundations and
Trends® in Machine Learning</em>, vol. 14, no. 1–2, pp. 1–210,
2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, D. Ramage, and P. Richtárik,
“Federated optimization: Distributed machine learning for on-device
intelligence,” <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.02527</em>, 2016.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client selection for federated learning with
heterogeneous resources in mobile edge,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ICC 2019-2019 IEEE
international conference on communications (ICC)</em>.   IEEE, 2019, pp. 1–7.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan,
“Adaptive federated learning in resource constrained edge computing
systems,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em>, vol. 37,
no. 6, pp. 1205–1221, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
D. Rothchild, A. Panda, E. Ullah, N. Ivkin, I. Stoica, V. Braverman,
J. Gonzalez, and R. Arora, “Fetchsgd: Communication-efficient federated
learning with sketching,” in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>.   PMLR, 2020, pp. 8253–8265.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani,
“Fedpaq: A communication-efficient federated learning method with periodic
averaging and quantization,” in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial
Intelligence and Statistics</em>.   PMLR,
2020, pp. 2021–2031.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
G. Yang, K. Mu, C. Song, Z. Yang, and T. Gong, “Ringfed: Reducing
communication costs in federated learning on non-iid data,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2107.08873</em>, 2021. [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/2107.08873" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2107.08873</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
L. Liu, J. Zhang, S. Song, and K. B. Letaief, “Client-edge-cloud hierarchical
federated learning,” in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International Conference on
Communications (ICC)</em>.   IEEE, 2020, pp.
1–6.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
S. Vineeth, “Federated learning over wifi: Should we use tcp or udp?”

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
H. Ye, L. Liang, and G. Y. Li, “Decentralized federated learning with
unreliable communications,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Selected Topics in Signal
Processing</em>, vol. 16, no. 3, pp. 487–500, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
A. Wood, <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Rabbit MQ: For Starters</em>.   North Charleston, SC, USA: CreateSpace Independent Publishing Platform, 2016.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A. Krizhevsky, G. Hinton <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Learning multiple layers of features
from tiny images,” <em id="bib.bib39.2.2" class="ltx_emph ltx_font_italic">(Technical Report), University of Toronto</em>, 2009.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
R. A. Light, “Mosquitto: server and client implementation of the mqtt
protocol,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Journal of Open Source Software</em>, vol. 2, no. 13, p. 265,
2017. [Online]. Available: <a target="_blank" href="https://doi.org/10.21105/joss.00265" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21105/joss.00265</a>

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
C. King, “stress-ng: a tool to load and stress a computer system.” 2019.
[Online]. Available:
<a target="_blank" href="http://manpages.ubuntu.com/manpages/bionic/man1/stress-ng.1.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://manpages.ubuntu.com/manpages/bionic/man1/stress-ng.1.html</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2208.08763" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2208.08764" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.08764">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2208.08764" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2208.08765" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 17:39:35 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
