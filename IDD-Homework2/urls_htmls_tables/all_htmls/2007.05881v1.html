<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2007.05881] Applying recent advances in Visual Question Answering to Record Linkage</title><meta property="og:description" content="Multi-modal Record Linkage is the process of matching multi-modal records from multiple sources that represent the same entity. This field has not been explored in research and we propose two solutions based on Deep Le…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Applying recent advances in Visual Question Answering to Record Linkage">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Applying recent advances in Visual Question Answering to Record Linkage">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2007.05881">

<!--Generated on Fri Mar  8 15:38:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">{preliminary}</span>
</div>
<h1 class="ltx_title ltx_title_document">Applying recent advances in Visual Question Answering to Record Linkage</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marko Smilevski
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text">Multi-modal Record Linkage is the process of matching multi-modal records from multiple sources that represent the same entity. This field has not been explored in research and we propose two solutions based on Deep Learning architectures that are inspired by recent work in Visual Question Answering. The neural networks we propose use two different fusion modules, the Recurrent Neural Network + Convolutional Neural Network fusion module and the Stacked Attention Network fusion module, that jointly combine the visual and the textual data of the records. The output of these fusion models is the input of a Siamese Neural Network that computes the similarity of the records. Using data from the Avito Duplicate Advertisements Detection dataset, we train these solutions and from the experiments, we concluded that the Recurrent Neural Network + Convolutional Neural Network fusion module outperforms a simple model that uses hand-crafted features. We also find that the Recurrent Neural Network + Convolutional Neural Network fusion module classifies dissimilar advertisements as similar more frequently if their average description is bigger than 40 words. We conclude that the reason for this is that the longer advertisements have a different distribution then the shorter advertisements who are more prevalent in the dataset. In the end, we also conclude that further research needs to be done with the Stacked Attention Network, to further explore the effects of the visual data on the performance of the fusion modules.</span></p>
</div>
<section id="Ch0.Sx1" class="ltx_section">
<h3 class="ltx_title ltx_title_section">Acknowledgements</h3>

<div id="Ch0.Sx1.p1" class="ltx_para">
<p id="Ch0.Sx1.p1.1" class="ltx_p">I would like to thank my supervisors Yoni Lev, Grant Galloway and Iain Murray for their advice, mentorship, patience and thorough feedback for my dissertation. I would also like to thank The University of Edinburgh and Amazon for providing an opportunity for me to work with mentors from the industry.</p>
</div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="#Ch1" title="In Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a href="#Ch2" title="In Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background and related work</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch2.S1" title="In Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Record Linkage</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#Ch2.S2" title="In Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Deep Learning</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#Ch2.S2.SS1" title="In 2.2 Deep Learning ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Short introduction to Deep Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#Ch2.S2.SS2" title="In 2.2 Deep Learning ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>Deep Learning and Record Linkage</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#Ch2.S2.SS3" title="In 2.2 Deep Learning ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.3 </span>Recurrent Neural Networks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#Ch2.S2.SS4" title="In 2.2 Deep Learning ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.4 </span>Convolutional Neural Networks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#Ch2.S3" title="In Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>The link between Visual Question Answering and Record Linkage</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#Ch2.S3.SS1" title="In 2.3 The link between Visual Question Answering and Record Linkage ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Visual Question Answering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#Ch2.S3.SS2" title="In 2.3 The link between Visual Question Answering and Record Linkage ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>The Attention Mechanism</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch2.S4" title="In Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Siamese Neural Networks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a href="#Ch3" title="In Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch3.S1" title="In Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data set and Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch3.S2" title="In Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Baseline Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch3.S3" title="In Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Siamese Neural Network Framework</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch3.S4" title="In Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Recurrent Neural Network + Convolutional Neural Network fusion module</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch3.S5" title="In Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Stacked Attention Network fusion module</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a href="#Ch4" title="In Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results and Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch4.S1" title="In Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Evaluation Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch4.S2" title="In Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Baseline Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch4.S3" title="In Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Training the Neural Network model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch4.S4" title="In Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Recurrent Neural Network + Convolutional Neural Network fusion module</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch4.S5" title="In Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Stacked Attention Network fusion module</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#Ch4.S6" title="In Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>Comparison of the fusion modules</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="#Ch5" title="In Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
</ol></nav>
</section>
<section id="Ch1" class="ltx_chapter">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 1 </span>Introduction</h2>

<div id="Ch1.p1" class="ltx_para">
<p id="Ch1.p1.1" class="ltx_p">Record linkage is the process of joining records from multiple data sources that represents the same entity. Record linkage is used in domains where storing data is essential, therefore government agencies, the health sector, security agencies, online stores and other various organization would benefit immensely by any advances in this field. The task is commonly used for improving data quality, improving the order of items within databases and to reduce costs and give computational efficiency to data acquisition and data re-usage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.</p>
</div>
<div id="Ch1.p2" class="ltx_para">
<p id="Ch1.p2.1" class="ltx_p">All the research in record linkage has been done on textual data. Researchers have used various metrics to compute the similarity between textual fields and have proposed different machine learning methods to classify the output of these metrics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The problem with this approach is that for different domains, researches needed to use different similarity metrics and needed to design a lot of hand-crafted features, so the metric would be able to represent the similarity more accurately. This led to inefficient system development and systems that are not robust. In recent years Deep Learning has emerged as a solution to hand-crafting features, because of the ability of deep neural networks to extract features and knowledge from raw data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. For record linkage, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> proposes three architectures that are based on Recurrent Neural Networks and they outperform the state-of-the-art record linkage system (that uses classical machine learning methods) on raw text.</p>
</div>
<div id="Ch1.p3" class="ltx_para">
<p id="Ch1.p3.1" class="ltx_p">One thing that hasn’t been researched in record linkage is the linkage of multi-modal records. The rise of the Internet has introduced more visual content which provides more information about the entities. Our motivation is to build on top of the success that <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> had with Deep Learning methods and we do this by proposing two Deep Learning architectures that will learn how to model multi-modal records and learn how to compute their similarity successfully. Another field that uses multi-modal data and combines them jointly is Visual Question Answering (VQA)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In VQA they use Deep Learning architectures to combine an image and a question and they use the output of the fusion module to predict the answer to the question. In this way, VQA relates to Record Linkage, because both problems need to jointly encode both the visual and textual data.</p>
</div>
<div id="Ch1.p4" class="ltx_para">
<p id="Ch1.p4.1" class="ltx_p">The solutions that we propose consist of two parts: <span id="Ch1.p4.1.1" class="ltx_text ltx_font_bold">two fusion modules</span> that combine the visual and textual information for each record in the pair separately and a <span id="Ch1.p4.1.2" class="ltx_text ltx_font_bold">Siamese Neural Network</span> that computes the similarity between the outputs of the fusion modules. For the fusion modules we propose, two solutions that were inspired by the fusion modules introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. The first proposed module is the <span id="Ch1.p4.1.3" class="ltx_text ltx_font_bold">Recurrent Neural Network + Convolutional Neural Network fusion module</span> that uses recurrent neural networks to model the textual data and a pre-trained convolutional neural network that extracts features from images. The outputs of the networks are then fused by point-wise multiplication. An extension to this module is the <span id="Ch1.p4.1.4" class="ltx_text ltx_font_bold">Stacked Attention Network fusion module</span>, that uses multiple attention layers to create a more refined encoding of the multi-modal data. To train the whole network we used the Avito Duplicate Ads Detection dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. This dataset hasn’t been used in any previous research, so we also propose a simple baseline model that we will use to compare our two proposed solutions. The baseline model is a logistic regression model and for each pair of records, we compute two features: the Jaccard similarity coefficient between the textual data of each advertisement and the Euclidian distance between the feature vectors of the images associated with each advertisement.</p>
</div>
<div id="Ch1.p5" class="ltx_para">
<p id="Ch1.p5.1" class="ltx_p">We hypothesized that by increasing the complexity of the structure of the fusion module we would get better results. We were also interested in how the models perform when the textual data in the advertisements is long. Finally, we hypothesised that the Stacked Attention Network fusion module would be able to learn how to find similar regions in the images of similar advertisements.</p>
</div>
<div id="Ch1.p6" class="ltx_para">
<p id="Ch1.p6.1" class="ltx_p">For the <span id="Ch1.p6.1.1" class="ltx_text ltx_font_bold">Recurrent Neural Network + Convolutional Neural Network fusion module</span> we did a small hyperparameter search and choose the model that performed best on the validation set. For the <span id="Ch1.p6.1.2" class="ltx_text ltx_font_bold">Stacked Attention Network</span> we trained only one model because of time constraints.</p>
</div>
<div id="Ch1.p7" class="ltx_para">
<p id="Ch1.p7.1" class="ltx_p">From the experiments, we concluded that the <span id="Ch1.p7.1.1" class="ltx_text ltx_font_bold">Recurrent Neural Network + Convolutional Neural Network</span> performs better than the baseline model. We failed to prove our hypothesis that the increase in fusion module complexity (upgrading the RNN + CNN module to the Stacked Attention Network module) would result in better model performance. We also failed to prove that the Stacked Attention Network solution can learn how to attend similar regions in the images of similar advertisements, due to time constraints. We did however found out that the hyperparameter setting used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> didn’t work for the <span id="Ch1.p7.1.2" class="ltx_text ltx_font_bold">Recurrent Neural Network + Convolutional Neural Network</span> solution. Another interesting discovery was that the <span id="Ch1.p7.1.3" class="ltx_text ltx_font_bold">Recurrent Neural Network + Convolutional Neural Network</span> model, both struggle with advertisements that have very different description lengths and advertisements that have long descriptions. This is because the <span id="Ch1.p7.1.4" class="ltx_text ltx_font_bold">Recurrent Neural Network + Convolutional Neural Network</span> model tends to overfit the distribution of pairs of advertisements that have an average description length smaller than 40 words. The distribution of these type of pairs consists of more similar pairs and it is different than the distribution of pairs of advertisements that have an average description length of more then 40 words.</p>
</div>
<div id="Ch1.p8" class="ltx_para">
<p id="Ch1.p8.1" class="ltx_p">The code used for this project is available at <a target="_blank" href="https://github.com/msmilevski/nrl" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/msmilevski/nrl</a>.</p>
</div>
<div id="Ch1.p9" class="ltx_para">
<p id="Ch1.p9.1" class="ltx_p">The following paragraph outlines the structure for the rest of the document. In Chapter 2 we talk about the related work done in Record Linkage and provide the needed background for the proposed models. Section 2.1 explores different similarity metrics and machine learning methods (supervised and unsupervised) that are widely used in record linkage. Section 2.2 introduces the reader to Deep Learning, explains the connection between Deep Learning and Record Linkage and also gives a short introduction to Recurrent and Convolutional Neural Networks. Section 2.3 explores the link between Visual Question Answering and Record Linkage, explains what Visual Question Answering is in more detail and also introduces the concept of the Attention mechanism. Section 2.4 introduces Siamese Neural Networks. Chapter 3 is for the Methodology. In Section 3.1 we describe the dataset that we are using and all the preprocessing that we have done to it. Section 3.2 outlines the baseline model. Section 3.3 describes the Siamese Neural Network architecture in detail and provides an illustration of the architecture of the proposed framework. Section 3.4 describes the Recurrent Neural Network + Convolutional Neural Network fusion module and provides an illustration of its architecture. Section 3.5 explains the concept of the Stacked Attention Network, provides mathematical formulas to better understand the fusion module and a diagram of how the Stacked Attention Network looks when it uses one attention layer. Chapter 4 presents the results from the experiments. In Section 4.1 we introduce the evaluation metric we use to compare our models. Section 4.2 presents the results for the baseline model. Section 4.3 explains the training process for neural networks. Section 4.4 presents the results from the hyperparameter search for the Recurrent Neural Network + Convolutional Neural Network fusion module and we explain the thought process behind our experiments. Section 4.5 presents the results for the Stacked Attention Network fusion module. Section 4.6 compares all three models that we trained. It also looks into how well the models perform for different text lengths. Chapter 5 summarizes our work and introduces some possibilities for future work.</p>
</div>
</section>
<section id="Ch2" class="ltx_chapter">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 2 </span>Background and related work</h2>

<section id="Ch2.S1" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.1 </span>Record Linkage</h3>

<div id="Ch2.S1.p1" class="ltx_para">
<p id="Ch2.S1.p1.1" class="ltx_p">The goal of record linkage is to identify records in the same or different databases that refer to the same real-world entity, even if the records are not identical <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The same task in other domains is referred to as entity matching, entity resolution or database deduplication. It is a crucial task for data integration and data cleaning and it has a massive financial impact on companies that store and work with large databases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. The general process of record linkage consists of four steps: data cleaning and standardisation, indexing, record pair comparison and similarity vector classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The main task of data cleaning and standardisation is the conversion of raw input data into well defined, consistent forms, as well as the resolution of inconsistencies in the way information, is represented and encoded <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. The indexing step aims to reduce the number of comparisons between the records in the databases by dismissing record pairs who are non-matching. This is done by techniques like blocking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, which will not be covered in this thesis.</p>
</div>
<div id="Ch2.S1.p2" class="ltx_para">
<p id="Ch2.S1.p2.1" class="ltx_p">The record pair comparison uses a variety of comparison functions (similarity metrics) appropriate to the content of the record fields. These similarity metrics are divided into four categories: Character-based, Token-based, Phonetic and Numeric similarity metrics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. With character-based similarity metrics we measure the distance between fields on character level, with token-based we compare them on the word level and we use numeric similarity metrics if we compare numbers. Phonetic similarity metrics are used when two words are written in different languages, therefore phonetically they are similar but on character level, they would be very dissimilar. Widely used character-based similarity metrics are Edit-distance, Levenshtein distance and Jaro-Winkler distance, while for token-based similarity researchers have used metrics like TF-IDF cosine similarity, Jaccard coefficient and probabilistic analogues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. The problem with these similarity metrics is that they are good for specific datasets and task, therefore making them not robust enough. For example, Edit-distance is suitable for common typing mistakes but it may be costly operation for large strings and problematic for specific domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Only a few attempts for comparative evaluations of some sub-approaches have been made in terms of evaluation of different string similarity metrics, but most published entity resolution evaluations focus on individual approaches and use diverse methodologies, measures, and test problems making it difficult to assess the quality of each approach, not to mention their comparative effectiveness and efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Furthermore, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> find that matching product entities from online shops is not sufficiently solved with conventional approaches based on the similarity of attribute values because these approaches have poor classification performance. This means that matching records from online shops is a challenging resolution task.</p>
</div>
<div id="Ch2.S1.p3" class="ltx_para">
<p id="Ch2.S1.p3.1" class="ltx_p">The similarity metrics produce a numerical representation of the similarity between the entities. Non-learning systems have a pre-defined threshold <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> which decides whether two records are similar. This can be problematic because the data may be noisy or the similarity metric might output values that are not linearly separable. Therefore the system might achieve better performance if it was able to learn the threshold. To create a system that can learn the threshold parameter the system should include machine learning methods in its structure. The similarity metrics produce a similarity coefficient/vector, that is the input of a classifier which decides whether the pair is matching or not. These classifiers are based on supervised and unsupervised machine learning methods. Supervised approaches aim at automating the process of record linkage. One of the more famous models is the Fellegi-Sunter model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, which approaches record linkage as a Bayesian inference problem. Its goal is to approximate the sets of similar and dissimilar item pairs by minimizing the number of matches that we are uncertain about. Other supervised solutions for record linkage include SVM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and the CART algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> (decision trees) as the similarity vector classifier. However, supervised models require suitable labelled training data and providing such data requires manual effort. The drawback to these classifiers is that they are not robust enough, which means that when the data distribution changes slightly, new methods for feature extraction would be needed. As a solution to this problem, there are unsupervised methods for record linkage that propose different clustering techniques to group similar records together. The result of the clustering is that each cluster corresponds to a single distinct entity. One of the most cited solutions is Canopy clustering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> where the dataset is first divided into smaller subsets (canopies) by computing the similarity between pairs with an extremely inexpensive method. After the canopies are built, a standard clustering algorithm is applied to the canopies and they are clustered by using a more expensive distance (similarity) metric. Significant computation is saved by eliminating all of the distance comparisons among points that do not fall within a common canopy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Other clustering algorithms have been explored, like the Star clustering algorithm, Ricochet family of clustering algorithms, Cut Clustering, Articulation Point Clustering, Markov Clustering and Correlation Clustering and what <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> concluded is that none of these clustering algorithms produces perfect clusters. Therefore <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> propose that the best approach is to retrain your model more frequently and keep the important quantitative information produced by these algorithms. This only reinforces the idea that these solutions are not robust enough and their scalability would be problematic since frequent retraining is computationally expensive for large training sets. A more recent unsupervised method was proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> where they introduced the idea of incremental graph clustering technique for the record linkage task, meaning that the matching rules evolve through iterations.</p>
</div>
<div id="Ch2.S1.p4" class="ltx_para">
<p id="Ch2.S1.p4.1" class="ltx_p">The problem with unsupervised and supervised models is that there is no comparison between their performances and that they are mostly trained and evaluated on different datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. For our research we used the Avito Duplicate Ads Detection dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and it contains labelled data about which pairs of advertisements (records) are similar and which are not. Because of this we decided to explore supervised modelling techniques. The current state-of-the-art solution for record linkage is Magellan which is an end-to-end EM (entity matching) system, that uses either supervised learning methods, rule-based methods or an ensemble of supervised learning and rule-based algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. All of the above-mentioned models work well with structured data, but classical machine learning methods may have difficulties matching textual instances because there are few meaningful features that we can create from raw text <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> found that classical learning methods also perform poorly for the classification of matching product entities from online shops. Another issue is that our dataset contains images and a lot of hand-crafted feature engineering would be needed to capture the relevant visual features of each image.</p>
</div>
</section>
<section id="Ch2.S2" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.2 </span>Deep Learning</h3>

<section id="Ch2.S2.SS1" class="ltx_subsection">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2.1 </span>Short introduction to Deep Learning</h4>

<div id="Ch2.S2.SS1.p1" class="ltx_para">
<p id="Ch2.S2.SS1.p1.1" class="ltx_p">Deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> is an increasingly popular field in Artificial Intelligence. It is based on the idea of using a large number of perceptrons to approximate the distribution of the training data. Each perceptron consists of a weight that transforms the input (usually by multiplication) and an activation function that further transforms the weighted input into an output. By having weights and output, we can approximate the error that the perceptron makes and using backpropagation we can adjust the weights of the perceptron so that the output of the perceptron is a close to the real value.
By using multiple perceptrons inline, we can create a network, commonly referred to as a fully connected neural network. If we stack two fully connected neural network, we create a Multi-Layer Perceptron. Multi-Layer Perceptrons are considered to be universal function approximators, hence the idea of Deep Learning is that by stacking more layers in-depth, the model would be able to approximate very complex functions. The input is usually referred to as the visible layer, and all the other layers in the deep architectures are called hidden layers. There are various types of layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, but the most notable, apart from the fully connected neural networks, are the recurrent neural networks and the convolutional neural networks, which will be discussed in the further sections.</p>
</div>
</section>
<section id="Ch2.S2.SS2" class="ltx_subsection">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2.2 </span>Deep Learning and Record Linkage</h4>

<div id="Ch2.S2.SS2.p1" class="ltx_para">
<p id="Ch2.S2.SS2.p1.1" class="ltx_p">Deep learning models have had success in various Natural Language Processing tasks, like language modelling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and machine translation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> amongst others. In their work, the main building block for modelling language (sentences) were recurrent neural networks. Because of this <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> proposed three different architectures based on recurrent neural networks for record linkage. These architectures outperform the Magellan system for entities that were consisted of raw and unfiltered textual fields, but they underperformed for structured entities. The data that we use to train our models is raw textual data with an additional image component. The results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> encouraged us to use deep learning as the building block of our models. Therefore in the next subsections, we introduce some of the concepts from Deep learning that have been used to model text and images.</p>
</div>
</section>
<section id="Ch2.S2.SS3" class="ltx_subsection">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2.3 </span>Recurrent Neural Networks</h4>

<div id="Ch2.S2.SS3.p1" class="ltx_para">
<p id="Ch2.S2.SS3.p1.13" class="ltx_p">Recurrent Neural Networks (RNNs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> are neural networks designed for processing and learning the patterns in sequential data. This is achieved by including a recurrent connection to the same network layer, which enables the network to keep knowledge of the previous elements in the sequence. With this, the recurrent network can learn the dependencies between the elements of the sequence. One of the problems that RNNs face is that they are susceptible to the vanishing and exploding gradient problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> (gradients become 0 or gradients become very large numbers respectively, which results in the network not learning anything from the input). As a solution for this problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> proposed the Long Short-Term Memory (LSTM) model, which introduced the idea of representing the neural network in the RNN (cell) as a gated unit with multiple neural networks. The unit consists of a cell state (which contains the memory of all the previous inputs in the LSTM), hidden state (the output) and three gates. The forget gate controls how much of the previous cell state will affect the current cell state, the input gate controls how much the new input will affect the current hidden state and the output gate controls how the current cell state effects the output of the LSTM. Because of these gates, the LSTM has a proven ability to learn and exploit long-term dependencies in sequential data, especially in textual data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. The following formulas give a better representation of how the LSTM recurrent neural network cell is constructed:</p>
<table id="Ch2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E1.m1.1" class="ltx_Math" alttext="f_{t}=\sigma(W_{f}*[h_{t-1},x_{t}]+b_{f})" display="block"><semantics id="Ch2.E1.m1.1a"><mrow id="Ch2.E1.m1.1.1" xref="Ch2.E1.m1.1.1.cmml"><msub id="Ch2.E1.m1.1.1.3" xref="Ch2.E1.m1.1.1.3.cmml"><mi id="Ch2.E1.m1.1.1.3.2" xref="Ch2.E1.m1.1.1.3.2.cmml">f</mi><mi id="Ch2.E1.m1.1.1.3.3" xref="Ch2.E1.m1.1.1.3.3.cmml">t</mi></msub><mo id="Ch2.E1.m1.1.1.2" xref="Ch2.E1.m1.1.1.2.cmml">=</mo><mrow id="Ch2.E1.m1.1.1.1" xref="Ch2.E1.m1.1.1.1.cmml"><mi id="Ch2.E1.m1.1.1.1.3" xref="Ch2.E1.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="Ch2.E1.m1.1.1.1.2" xref="Ch2.E1.m1.1.1.1.2.cmml">​</mo><mrow id="Ch2.E1.m1.1.1.1.1.1" xref="Ch2.E1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch2.E1.m1.1.1.1.1.1.2" xref="Ch2.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch2.E1.m1.1.1.1.1.1.1" xref="Ch2.E1.m1.1.1.1.1.1.1.cmml"><mrow id="Ch2.E1.m1.1.1.1.1.1.1.2" xref="Ch2.E1.m1.1.1.1.1.1.1.2.cmml"><msub id="Ch2.E1.m1.1.1.1.1.1.1.2.4" xref="Ch2.E1.m1.1.1.1.1.1.1.2.4.cmml"><mi id="Ch2.E1.m1.1.1.1.1.1.1.2.4.2" xref="Ch2.E1.m1.1.1.1.1.1.1.2.4.2.cmml">W</mi><mi id="Ch2.E1.m1.1.1.1.1.1.1.2.4.3" xref="Ch2.E1.m1.1.1.1.1.1.1.2.4.3.cmml">f</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E1.m1.1.1.1.1.1.1.2.3" xref="Ch2.E1.m1.1.1.1.1.1.1.2.3.cmml">∗</mo><mrow id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.3" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.3.cmml">[</mo><msub id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mrow id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.1" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.4" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.2" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.2.cmml">x</mi><mi id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.3" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.5" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.3.cmml">]</mo></mrow></mrow><mo id="Ch2.E1.m1.1.1.1.1.1.1.3" xref="Ch2.E1.m1.1.1.1.1.1.1.3.cmml">+</mo><msub id="Ch2.E1.m1.1.1.1.1.1.1.4" xref="Ch2.E1.m1.1.1.1.1.1.1.4.cmml"><mi id="Ch2.E1.m1.1.1.1.1.1.1.4.2" xref="Ch2.E1.m1.1.1.1.1.1.1.4.2.cmml">b</mi><mi id="Ch2.E1.m1.1.1.1.1.1.1.4.3" xref="Ch2.E1.m1.1.1.1.1.1.1.4.3.cmml">f</mi></msub></mrow><mo stretchy="false" id="Ch2.E1.m1.1.1.1.1.1.3" xref="Ch2.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E1.m1.1b"><apply id="Ch2.E1.m1.1.1.cmml" xref="Ch2.E1.m1.1.1"><eq id="Ch2.E1.m1.1.1.2.cmml" xref="Ch2.E1.m1.1.1.2"></eq><apply id="Ch2.E1.m1.1.1.3.cmml" xref="Ch2.E1.m1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E1.m1.1.1.3.1.cmml" xref="Ch2.E1.m1.1.1.3">subscript</csymbol><ci id="Ch2.E1.m1.1.1.3.2.cmml" xref="Ch2.E1.m1.1.1.3.2">𝑓</ci><ci id="Ch2.E1.m1.1.1.3.3.cmml" xref="Ch2.E1.m1.1.1.3.3">𝑡</ci></apply><apply id="Ch2.E1.m1.1.1.1.cmml" xref="Ch2.E1.m1.1.1.1"><times id="Ch2.E1.m1.1.1.1.2.cmml" xref="Ch2.E1.m1.1.1.1.2"></times><ci id="Ch2.E1.m1.1.1.1.3.cmml" xref="Ch2.E1.m1.1.1.1.3">𝜎</ci><apply id="Ch2.E1.m1.1.1.1.1.1.1.cmml" xref="Ch2.E1.m1.1.1.1.1.1"><plus id="Ch2.E1.m1.1.1.1.1.1.1.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.3"></plus><apply id="Ch2.E1.m1.1.1.1.1.1.1.2.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2"><times id="Ch2.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.3"></times><apply id="Ch2.E1.m1.1.1.1.1.1.1.2.4.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="Ch2.E1.m1.1.1.1.1.1.1.2.4.1.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="Ch2.E1.m1.1.1.1.1.1.1.2.4.2.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.4.2">𝑊</ci><ci id="Ch2.E1.m1.1.1.1.1.1.1.2.4.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.4.3">𝑓</ci></apply><interval closure="closed" id="Ch2.E1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2"><apply id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.2">ℎ</ci><apply id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3"><minus id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.1"></minus><ci id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.2">𝑥</ci><ci id="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.2.2.2.2.3">𝑡</ci></apply></interval></apply><apply id="Ch2.E1.m1.1.1.1.1.1.1.4.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Ch2.E1.m1.1.1.1.1.1.1.4.1.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Ch2.E1.m1.1.1.1.1.1.1.4.2.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.4.2">𝑏</ci><ci id="Ch2.E1.m1.1.1.1.1.1.1.4.3.cmml" xref="Ch2.E1.m1.1.1.1.1.1.1.4.3">𝑓</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E1.m1.1c">f_{t}=\sigma(W_{f}*[h_{t-1},x_{t}]+b_{f})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.1)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E2.m1.1" class="ltx_Math" alttext="i_{t}=\sigma(W_{i}*[h_{t-1},x_{t}]+b_{i})" display="block"><semantics id="Ch2.E2.m1.1a"><mrow id="Ch2.E2.m1.1.1" xref="Ch2.E2.m1.1.1.cmml"><msub id="Ch2.E2.m1.1.1.3" xref="Ch2.E2.m1.1.1.3.cmml"><mi id="Ch2.E2.m1.1.1.3.2" xref="Ch2.E2.m1.1.1.3.2.cmml">i</mi><mi id="Ch2.E2.m1.1.1.3.3" xref="Ch2.E2.m1.1.1.3.3.cmml">t</mi></msub><mo id="Ch2.E2.m1.1.1.2" xref="Ch2.E2.m1.1.1.2.cmml">=</mo><mrow id="Ch2.E2.m1.1.1.1" xref="Ch2.E2.m1.1.1.1.cmml"><mi id="Ch2.E2.m1.1.1.1.3" xref="Ch2.E2.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="Ch2.E2.m1.1.1.1.2" xref="Ch2.E2.m1.1.1.1.2.cmml">​</mo><mrow id="Ch2.E2.m1.1.1.1.1.1" xref="Ch2.E2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch2.E2.m1.1.1.1.1.1.2" xref="Ch2.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch2.E2.m1.1.1.1.1.1.1" xref="Ch2.E2.m1.1.1.1.1.1.1.cmml"><mrow id="Ch2.E2.m1.1.1.1.1.1.1.2" xref="Ch2.E2.m1.1.1.1.1.1.1.2.cmml"><msub id="Ch2.E2.m1.1.1.1.1.1.1.2.4" xref="Ch2.E2.m1.1.1.1.1.1.1.2.4.cmml"><mi id="Ch2.E2.m1.1.1.1.1.1.1.2.4.2" xref="Ch2.E2.m1.1.1.1.1.1.1.2.4.2.cmml">W</mi><mi id="Ch2.E2.m1.1.1.1.1.1.1.2.4.3" xref="Ch2.E2.m1.1.1.1.1.1.1.2.4.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E2.m1.1.1.1.1.1.1.2.3" xref="Ch2.E2.m1.1.1.1.1.1.1.2.3.cmml">∗</mo><mrow id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.3" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.3.cmml">[</mo><msub id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.2" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mrow id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.4" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.2" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.2.cmml">x</mi><mi id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.3" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.5" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.3.cmml">]</mo></mrow></mrow><mo id="Ch2.E2.m1.1.1.1.1.1.1.3" xref="Ch2.E2.m1.1.1.1.1.1.1.3.cmml">+</mo><msub id="Ch2.E2.m1.1.1.1.1.1.1.4" xref="Ch2.E2.m1.1.1.1.1.1.1.4.cmml"><mi id="Ch2.E2.m1.1.1.1.1.1.1.4.2" xref="Ch2.E2.m1.1.1.1.1.1.1.4.2.cmml">b</mi><mi id="Ch2.E2.m1.1.1.1.1.1.1.4.3" xref="Ch2.E2.m1.1.1.1.1.1.1.4.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="Ch2.E2.m1.1.1.1.1.1.3" xref="Ch2.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E2.m1.1b"><apply id="Ch2.E2.m1.1.1.cmml" xref="Ch2.E2.m1.1.1"><eq id="Ch2.E2.m1.1.1.2.cmml" xref="Ch2.E2.m1.1.1.2"></eq><apply id="Ch2.E2.m1.1.1.3.cmml" xref="Ch2.E2.m1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E2.m1.1.1.3.1.cmml" xref="Ch2.E2.m1.1.1.3">subscript</csymbol><ci id="Ch2.E2.m1.1.1.3.2.cmml" xref="Ch2.E2.m1.1.1.3.2">𝑖</ci><ci id="Ch2.E2.m1.1.1.3.3.cmml" xref="Ch2.E2.m1.1.1.3.3">𝑡</ci></apply><apply id="Ch2.E2.m1.1.1.1.cmml" xref="Ch2.E2.m1.1.1.1"><times id="Ch2.E2.m1.1.1.1.2.cmml" xref="Ch2.E2.m1.1.1.1.2"></times><ci id="Ch2.E2.m1.1.1.1.3.cmml" xref="Ch2.E2.m1.1.1.1.3">𝜎</ci><apply id="Ch2.E2.m1.1.1.1.1.1.1.cmml" xref="Ch2.E2.m1.1.1.1.1.1"><plus id="Ch2.E2.m1.1.1.1.1.1.1.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.3"></plus><apply id="Ch2.E2.m1.1.1.1.1.1.1.2.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2"><times id="Ch2.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.3"></times><apply id="Ch2.E2.m1.1.1.1.1.1.1.2.4.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="Ch2.E2.m1.1.1.1.1.1.1.2.4.1.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="Ch2.E2.m1.1.1.1.1.1.1.2.4.2.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.4.2">𝑊</ci><ci id="Ch2.E2.m1.1.1.1.1.1.1.2.4.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.4.3">𝑖</ci></apply><interval closure="closed" id="Ch2.E2.m1.1.1.1.1.1.1.2.2.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2"><apply id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.2">ℎ</ci><apply id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3"><minus id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1"></minus><ci id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.2">𝑥</ci><ci id="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.2.2.2.2.3">𝑡</ci></apply></interval></apply><apply id="Ch2.E2.m1.1.1.1.1.1.1.4.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Ch2.E2.m1.1.1.1.1.1.1.4.1.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Ch2.E2.m1.1.1.1.1.1.1.4.2.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.4.2">𝑏</ci><ci id="Ch2.E2.m1.1.1.1.1.1.1.4.3.cmml" xref="Ch2.E2.m1.1.1.1.1.1.1.4.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E2.m1.1c">i_{t}=\sigma(W_{i}*[h_{t-1},x_{t}]+b_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.2)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E3.m1.1" class="ltx_Math" alttext="\widetilde{C}_{t}=\sigma(W_{C}*[h_{t-1},x_{t}]+b_{C})" display="block"><semantics id="Ch2.E3.m1.1a"><mrow id="Ch2.E3.m1.1.1" xref="Ch2.E3.m1.1.1.cmml"><msub id="Ch2.E3.m1.1.1.3" xref="Ch2.E3.m1.1.1.3.cmml"><mover accent="true" id="Ch2.E3.m1.1.1.3.2" xref="Ch2.E3.m1.1.1.3.2.cmml"><mi id="Ch2.E3.m1.1.1.3.2.2" xref="Ch2.E3.m1.1.1.3.2.2.cmml">C</mi><mo id="Ch2.E3.m1.1.1.3.2.1" xref="Ch2.E3.m1.1.1.3.2.1.cmml">~</mo></mover><mi id="Ch2.E3.m1.1.1.3.3" xref="Ch2.E3.m1.1.1.3.3.cmml">t</mi></msub><mo id="Ch2.E3.m1.1.1.2" xref="Ch2.E3.m1.1.1.2.cmml">=</mo><mrow id="Ch2.E3.m1.1.1.1" xref="Ch2.E3.m1.1.1.1.cmml"><mi id="Ch2.E3.m1.1.1.1.3" xref="Ch2.E3.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="Ch2.E3.m1.1.1.1.2" xref="Ch2.E3.m1.1.1.1.2.cmml">​</mo><mrow id="Ch2.E3.m1.1.1.1.1.1" xref="Ch2.E3.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch2.E3.m1.1.1.1.1.1.2" xref="Ch2.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch2.E3.m1.1.1.1.1.1.1" xref="Ch2.E3.m1.1.1.1.1.1.1.cmml"><mrow id="Ch2.E3.m1.1.1.1.1.1.1.2" xref="Ch2.E3.m1.1.1.1.1.1.1.2.cmml"><msub id="Ch2.E3.m1.1.1.1.1.1.1.2.4" xref="Ch2.E3.m1.1.1.1.1.1.1.2.4.cmml"><mi id="Ch2.E3.m1.1.1.1.1.1.1.2.4.2" xref="Ch2.E3.m1.1.1.1.1.1.1.2.4.2.cmml">W</mi><mi id="Ch2.E3.m1.1.1.1.1.1.1.2.4.3" xref="Ch2.E3.m1.1.1.1.1.1.1.2.4.3.cmml">C</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E3.m1.1.1.1.1.1.1.2.3" xref="Ch2.E3.m1.1.1.1.1.1.1.2.3.cmml">∗</mo><mrow id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.3" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.3.cmml">[</mo><msub id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mrow id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.1" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.4" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.2" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.2.cmml">x</mi><mi id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.3" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.5" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.3.cmml">]</mo></mrow></mrow><mo id="Ch2.E3.m1.1.1.1.1.1.1.3" xref="Ch2.E3.m1.1.1.1.1.1.1.3.cmml">+</mo><msub id="Ch2.E3.m1.1.1.1.1.1.1.4" xref="Ch2.E3.m1.1.1.1.1.1.1.4.cmml"><mi id="Ch2.E3.m1.1.1.1.1.1.1.4.2" xref="Ch2.E3.m1.1.1.1.1.1.1.4.2.cmml">b</mi><mi id="Ch2.E3.m1.1.1.1.1.1.1.4.3" xref="Ch2.E3.m1.1.1.1.1.1.1.4.3.cmml">C</mi></msub></mrow><mo stretchy="false" id="Ch2.E3.m1.1.1.1.1.1.3" xref="Ch2.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E3.m1.1b"><apply id="Ch2.E3.m1.1.1.cmml" xref="Ch2.E3.m1.1.1"><eq id="Ch2.E3.m1.1.1.2.cmml" xref="Ch2.E3.m1.1.1.2"></eq><apply id="Ch2.E3.m1.1.1.3.cmml" xref="Ch2.E3.m1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E3.m1.1.1.3.1.cmml" xref="Ch2.E3.m1.1.1.3">subscript</csymbol><apply id="Ch2.E3.m1.1.1.3.2.cmml" xref="Ch2.E3.m1.1.1.3.2"><ci id="Ch2.E3.m1.1.1.3.2.1.cmml" xref="Ch2.E3.m1.1.1.3.2.1">~</ci><ci id="Ch2.E3.m1.1.1.3.2.2.cmml" xref="Ch2.E3.m1.1.1.3.2.2">𝐶</ci></apply><ci id="Ch2.E3.m1.1.1.3.3.cmml" xref="Ch2.E3.m1.1.1.3.3">𝑡</ci></apply><apply id="Ch2.E3.m1.1.1.1.cmml" xref="Ch2.E3.m1.1.1.1"><times id="Ch2.E3.m1.1.1.1.2.cmml" xref="Ch2.E3.m1.1.1.1.2"></times><ci id="Ch2.E3.m1.1.1.1.3.cmml" xref="Ch2.E3.m1.1.1.1.3">𝜎</ci><apply id="Ch2.E3.m1.1.1.1.1.1.1.cmml" xref="Ch2.E3.m1.1.1.1.1.1"><plus id="Ch2.E3.m1.1.1.1.1.1.1.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.3"></plus><apply id="Ch2.E3.m1.1.1.1.1.1.1.2.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2"><times id="Ch2.E3.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.3"></times><apply id="Ch2.E3.m1.1.1.1.1.1.1.2.4.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="Ch2.E3.m1.1.1.1.1.1.1.2.4.1.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="Ch2.E3.m1.1.1.1.1.1.1.2.4.2.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.4.2">𝑊</ci><ci id="Ch2.E3.m1.1.1.1.1.1.1.2.4.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.4.3">𝐶</ci></apply><interval closure="closed" id="Ch2.E3.m1.1.1.1.1.1.1.2.2.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2"><apply id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.2">ℎ</ci><apply id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3"><minus id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.1"></minus><ci id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.2">𝑥</ci><ci id="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.2.2.2.2.3">𝑡</ci></apply></interval></apply><apply id="Ch2.E3.m1.1.1.1.1.1.1.4.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Ch2.E3.m1.1.1.1.1.1.1.4.1.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Ch2.E3.m1.1.1.1.1.1.1.4.2.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.4.2">𝑏</ci><ci id="Ch2.E3.m1.1.1.1.1.1.1.4.3.cmml" xref="Ch2.E3.m1.1.1.1.1.1.1.4.3">𝐶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E3.m1.1c">\widetilde{C}_{t}=\sigma(W_{C}*[h_{t-1},x_{t}]+b_{C})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.3)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E4.m1.1" class="ltx_Math" alttext="C_{t}=f_{t}*C_{t-1}+i_{t}*\widetilde{C}_{t}" display="block"><semantics id="Ch2.E4.m1.1a"><mrow id="Ch2.E4.m1.1.1" xref="Ch2.E4.m1.1.1.cmml"><msub id="Ch2.E4.m1.1.1.2" xref="Ch2.E4.m1.1.1.2.cmml"><mi id="Ch2.E4.m1.1.1.2.2" xref="Ch2.E4.m1.1.1.2.2.cmml">C</mi><mi id="Ch2.E4.m1.1.1.2.3" xref="Ch2.E4.m1.1.1.2.3.cmml">t</mi></msub><mo id="Ch2.E4.m1.1.1.1" xref="Ch2.E4.m1.1.1.1.cmml">=</mo><mrow id="Ch2.E4.m1.1.1.3" xref="Ch2.E4.m1.1.1.3.cmml"><mrow id="Ch2.E4.m1.1.1.3.2" xref="Ch2.E4.m1.1.1.3.2.cmml"><msub id="Ch2.E4.m1.1.1.3.2.2" xref="Ch2.E4.m1.1.1.3.2.2.cmml"><mi id="Ch2.E4.m1.1.1.3.2.2.2" xref="Ch2.E4.m1.1.1.3.2.2.2.cmml">f</mi><mi id="Ch2.E4.m1.1.1.3.2.2.3" xref="Ch2.E4.m1.1.1.3.2.2.3.cmml">t</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E4.m1.1.1.3.2.1" xref="Ch2.E4.m1.1.1.3.2.1.cmml">∗</mo><msub id="Ch2.E4.m1.1.1.3.2.3" xref="Ch2.E4.m1.1.1.3.2.3.cmml"><mi id="Ch2.E4.m1.1.1.3.2.3.2" xref="Ch2.E4.m1.1.1.3.2.3.2.cmml">C</mi><mrow id="Ch2.E4.m1.1.1.3.2.3.3" xref="Ch2.E4.m1.1.1.3.2.3.3.cmml"><mi id="Ch2.E4.m1.1.1.3.2.3.3.2" xref="Ch2.E4.m1.1.1.3.2.3.3.2.cmml">t</mi><mo id="Ch2.E4.m1.1.1.3.2.3.3.1" xref="Ch2.E4.m1.1.1.3.2.3.3.1.cmml">−</mo><mn id="Ch2.E4.m1.1.1.3.2.3.3.3" xref="Ch2.E4.m1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="Ch2.E4.m1.1.1.3.1" xref="Ch2.E4.m1.1.1.3.1.cmml">+</mo><mrow id="Ch2.E4.m1.1.1.3.3" xref="Ch2.E4.m1.1.1.3.3.cmml"><msub id="Ch2.E4.m1.1.1.3.3.2" xref="Ch2.E4.m1.1.1.3.3.2.cmml"><mi id="Ch2.E4.m1.1.1.3.3.2.2" xref="Ch2.E4.m1.1.1.3.3.2.2.cmml">i</mi><mi id="Ch2.E4.m1.1.1.3.3.2.3" xref="Ch2.E4.m1.1.1.3.3.2.3.cmml">t</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E4.m1.1.1.3.3.1" xref="Ch2.E4.m1.1.1.3.3.1.cmml">∗</mo><msub id="Ch2.E4.m1.1.1.3.3.3" xref="Ch2.E4.m1.1.1.3.3.3.cmml"><mover accent="true" id="Ch2.E4.m1.1.1.3.3.3.2" xref="Ch2.E4.m1.1.1.3.3.3.2.cmml"><mi id="Ch2.E4.m1.1.1.3.3.3.2.2" xref="Ch2.E4.m1.1.1.3.3.3.2.2.cmml">C</mi><mo id="Ch2.E4.m1.1.1.3.3.3.2.1" xref="Ch2.E4.m1.1.1.3.3.3.2.1.cmml">~</mo></mover><mi id="Ch2.E4.m1.1.1.3.3.3.3" xref="Ch2.E4.m1.1.1.3.3.3.3.cmml">t</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E4.m1.1b"><apply id="Ch2.E4.m1.1.1.cmml" xref="Ch2.E4.m1.1.1"><eq id="Ch2.E4.m1.1.1.1.cmml" xref="Ch2.E4.m1.1.1.1"></eq><apply id="Ch2.E4.m1.1.1.2.cmml" xref="Ch2.E4.m1.1.1.2"><csymbol cd="ambiguous" id="Ch2.E4.m1.1.1.2.1.cmml" xref="Ch2.E4.m1.1.1.2">subscript</csymbol><ci id="Ch2.E4.m1.1.1.2.2.cmml" xref="Ch2.E4.m1.1.1.2.2">𝐶</ci><ci id="Ch2.E4.m1.1.1.2.3.cmml" xref="Ch2.E4.m1.1.1.2.3">𝑡</ci></apply><apply id="Ch2.E4.m1.1.1.3.cmml" xref="Ch2.E4.m1.1.1.3"><plus id="Ch2.E4.m1.1.1.3.1.cmml" xref="Ch2.E4.m1.1.1.3.1"></plus><apply id="Ch2.E4.m1.1.1.3.2.cmml" xref="Ch2.E4.m1.1.1.3.2"><times id="Ch2.E4.m1.1.1.3.2.1.cmml" xref="Ch2.E4.m1.1.1.3.2.1"></times><apply id="Ch2.E4.m1.1.1.3.2.2.cmml" xref="Ch2.E4.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="Ch2.E4.m1.1.1.3.2.2.1.cmml" xref="Ch2.E4.m1.1.1.3.2.2">subscript</csymbol><ci id="Ch2.E4.m1.1.1.3.2.2.2.cmml" xref="Ch2.E4.m1.1.1.3.2.2.2">𝑓</ci><ci id="Ch2.E4.m1.1.1.3.2.2.3.cmml" xref="Ch2.E4.m1.1.1.3.2.2.3">𝑡</ci></apply><apply id="Ch2.E4.m1.1.1.3.2.3.cmml" xref="Ch2.E4.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="Ch2.E4.m1.1.1.3.2.3.1.cmml" xref="Ch2.E4.m1.1.1.3.2.3">subscript</csymbol><ci id="Ch2.E4.m1.1.1.3.2.3.2.cmml" xref="Ch2.E4.m1.1.1.3.2.3.2">𝐶</ci><apply id="Ch2.E4.m1.1.1.3.2.3.3.cmml" xref="Ch2.E4.m1.1.1.3.2.3.3"><minus id="Ch2.E4.m1.1.1.3.2.3.3.1.cmml" xref="Ch2.E4.m1.1.1.3.2.3.3.1"></minus><ci id="Ch2.E4.m1.1.1.3.2.3.3.2.cmml" xref="Ch2.E4.m1.1.1.3.2.3.3.2">𝑡</ci><cn type="integer" id="Ch2.E4.m1.1.1.3.2.3.3.3.cmml" xref="Ch2.E4.m1.1.1.3.2.3.3.3">1</cn></apply></apply></apply><apply id="Ch2.E4.m1.1.1.3.3.cmml" xref="Ch2.E4.m1.1.1.3.3"><times id="Ch2.E4.m1.1.1.3.3.1.cmml" xref="Ch2.E4.m1.1.1.3.3.1"></times><apply id="Ch2.E4.m1.1.1.3.3.2.cmml" xref="Ch2.E4.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="Ch2.E4.m1.1.1.3.3.2.1.cmml" xref="Ch2.E4.m1.1.1.3.3.2">subscript</csymbol><ci id="Ch2.E4.m1.1.1.3.3.2.2.cmml" xref="Ch2.E4.m1.1.1.3.3.2.2">𝑖</ci><ci id="Ch2.E4.m1.1.1.3.3.2.3.cmml" xref="Ch2.E4.m1.1.1.3.3.2.3">𝑡</ci></apply><apply id="Ch2.E4.m1.1.1.3.3.3.cmml" xref="Ch2.E4.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="Ch2.E4.m1.1.1.3.3.3.1.cmml" xref="Ch2.E4.m1.1.1.3.3.3">subscript</csymbol><apply id="Ch2.E4.m1.1.1.3.3.3.2.cmml" xref="Ch2.E4.m1.1.1.3.3.3.2"><ci id="Ch2.E4.m1.1.1.3.3.3.2.1.cmml" xref="Ch2.E4.m1.1.1.3.3.3.2.1">~</ci><ci id="Ch2.E4.m1.1.1.3.3.3.2.2.cmml" xref="Ch2.E4.m1.1.1.3.3.3.2.2">𝐶</ci></apply><ci id="Ch2.E4.m1.1.1.3.3.3.3.cmml" xref="Ch2.E4.m1.1.1.3.3.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E4.m1.1c">C_{t}=f_{t}*C_{t-1}+i_{t}*\widetilde{C}_{t}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.4)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E5.m1.1" class="ltx_Math" alttext="o_{t}=\sigma(W_{o}*[h_{t-1},x_{t}]+b_{o})" display="block"><semantics id="Ch2.E5.m1.1a"><mrow id="Ch2.E5.m1.1.1" xref="Ch2.E5.m1.1.1.cmml"><msub id="Ch2.E5.m1.1.1.3" xref="Ch2.E5.m1.1.1.3.cmml"><mi id="Ch2.E5.m1.1.1.3.2" xref="Ch2.E5.m1.1.1.3.2.cmml">o</mi><mi id="Ch2.E5.m1.1.1.3.3" xref="Ch2.E5.m1.1.1.3.3.cmml">t</mi></msub><mo id="Ch2.E5.m1.1.1.2" xref="Ch2.E5.m1.1.1.2.cmml">=</mo><mrow id="Ch2.E5.m1.1.1.1" xref="Ch2.E5.m1.1.1.1.cmml"><mi id="Ch2.E5.m1.1.1.1.3" xref="Ch2.E5.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="Ch2.E5.m1.1.1.1.2" xref="Ch2.E5.m1.1.1.1.2.cmml">​</mo><mrow id="Ch2.E5.m1.1.1.1.1.1" xref="Ch2.E5.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch2.E5.m1.1.1.1.1.1.2" xref="Ch2.E5.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch2.E5.m1.1.1.1.1.1.1" xref="Ch2.E5.m1.1.1.1.1.1.1.cmml"><mrow id="Ch2.E5.m1.1.1.1.1.1.1.2" xref="Ch2.E5.m1.1.1.1.1.1.1.2.cmml"><msub id="Ch2.E5.m1.1.1.1.1.1.1.2.4" xref="Ch2.E5.m1.1.1.1.1.1.1.2.4.cmml"><mi id="Ch2.E5.m1.1.1.1.1.1.1.2.4.2" xref="Ch2.E5.m1.1.1.1.1.1.1.2.4.2.cmml">W</mi><mi id="Ch2.E5.m1.1.1.1.1.1.1.2.4.3" xref="Ch2.E5.m1.1.1.1.1.1.1.2.4.3.cmml">o</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E5.m1.1.1.1.1.1.1.2.3" xref="Ch2.E5.m1.1.1.1.1.1.1.2.3.cmml">∗</mo><mrow id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.3" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.3.cmml">[</mo><msub id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mrow id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.1" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.4" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.2" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.2.cmml">x</mi><mi id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.3" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.5" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.3.cmml">]</mo></mrow></mrow><mo id="Ch2.E5.m1.1.1.1.1.1.1.3" xref="Ch2.E5.m1.1.1.1.1.1.1.3.cmml">+</mo><msub id="Ch2.E5.m1.1.1.1.1.1.1.4" xref="Ch2.E5.m1.1.1.1.1.1.1.4.cmml"><mi id="Ch2.E5.m1.1.1.1.1.1.1.4.2" xref="Ch2.E5.m1.1.1.1.1.1.1.4.2.cmml">b</mi><mi id="Ch2.E5.m1.1.1.1.1.1.1.4.3" xref="Ch2.E5.m1.1.1.1.1.1.1.4.3.cmml">o</mi></msub></mrow><mo stretchy="false" id="Ch2.E5.m1.1.1.1.1.1.3" xref="Ch2.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E5.m1.1b"><apply id="Ch2.E5.m1.1.1.cmml" xref="Ch2.E5.m1.1.1"><eq id="Ch2.E5.m1.1.1.2.cmml" xref="Ch2.E5.m1.1.1.2"></eq><apply id="Ch2.E5.m1.1.1.3.cmml" xref="Ch2.E5.m1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E5.m1.1.1.3.1.cmml" xref="Ch2.E5.m1.1.1.3">subscript</csymbol><ci id="Ch2.E5.m1.1.1.3.2.cmml" xref="Ch2.E5.m1.1.1.3.2">𝑜</ci><ci id="Ch2.E5.m1.1.1.3.3.cmml" xref="Ch2.E5.m1.1.1.3.3">𝑡</ci></apply><apply id="Ch2.E5.m1.1.1.1.cmml" xref="Ch2.E5.m1.1.1.1"><times id="Ch2.E5.m1.1.1.1.2.cmml" xref="Ch2.E5.m1.1.1.1.2"></times><ci id="Ch2.E5.m1.1.1.1.3.cmml" xref="Ch2.E5.m1.1.1.1.3">𝜎</ci><apply id="Ch2.E5.m1.1.1.1.1.1.1.cmml" xref="Ch2.E5.m1.1.1.1.1.1"><plus id="Ch2.E5.m1.1.1.1.1.1.1.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.3"></plus><apply id="Ch2.E5.m1.1.1.1.1.1.1.2.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2"><times id="Ch2.E5.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.3"></times><apply id="Ch2.E5.m1.1.1.1.1.1.1.2.4.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="Ch2.E5.m1.1.1.1.1.1.1.2.4.1.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="Ch2.E5.m1.1.1.1.1.1.1.2.4.2.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.4.2">𝑊</ci><ci id="Ch2.E5.m1.1.1.1.1.1.1.2.4.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.4.3">𝑜</ci></apply><interval closure="closed" id="Ch2.E5.m1.1.1.1.1.1.1.2.2.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2"><apply id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.2">ℎ</ci><apply id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3"><minus id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.1"></minus><ci id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.2">𝑥</ci><ci id="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.2.2.2.2.3">𝑡</ci></apply></interval></apply><apply id="Ch2.E5.m1.1.1.1.1.1.1.4.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Ch2.E5.m1.1.1.1.1.1.1.4.1.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Ch2.E5.m1.1.1.1.1.1.1.4.2.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.4.2">𝑏</ci><ci id="Ch2.E5.m1.1.1.1.1.1.1.4.3.cmml" xref="Ch2.E5.m1.1.1.1.1.1.1.4.3">𝑜</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E5.m1.1c">o_{t}=\sigma(W_{o}*[h_{t-1},x_{t}]+b_{o})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.5)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E6.m1.2" class="ltx_Math" alttext="h_{t}=o_{t}*\tanh(C_{t})" display="block"><semantics id="Ch2.E6.m1.2a"><mrow id="Ch2.E6.m1.2.2" xref="Ch2.E6.m1.2.2.cmml"><msub id="Ch2.E6.m1.2.2.3" xref="Ch2.E6.m1.2.2.3.cmml"><mi id="Ch2.E6.m1.2.2.3.2" xref="Ch2.E6.m1.2.2.3.2.cmml">h</mi><mi id="Ch2.E6.m1.2.2.3.3" xref="Ch2.E6.m1.2.2.3.3.cmml">t</mi></msub><mo id="Ch2.E6.m1.2.2.2" xref="Ch2.E6.m1.2.2.2.cmml">=</mo><mrow id="Ch2.E6.m1.2.2.1" xref="Ch2.E6.m1.2.2.1.cmml"><msub id="Ch2.E6.m1.2.2.1.3" xref="Ch2.E6.m1.2.2.1.3.cmml"><mi id="Ch2.E6.m1.2.2.1.3.2" xref="Ch2.E6.m1.2.2.1.3.2.cmml">o</mi><mi id="Ch2.E6.m1.2.2.1.3.3" xref="Ch2.E6.m1.2.2.1.3.3.cmml">t</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E6.m1.2.2.1.2" xref="Ch2.E6.m1.2.2.1.2.cmml">∗</mo><mrow id="Ch2.E6.m1.2.2.1.1.1" xref="Ch2.E6.m1.2.2.1.1.2.cmml"><mi id="Ch2.E6.m1.1.1" xref="Ch2.E6.m1.1.1.cmml">tanh</mi><mo id="Ch2.E6.m1.2.2.1.1.1a" xref="Ch2.E6.m1.2.2.1.1.2.cmml">⁡</mo><mrow id="Ch2.E6.m1.2.2.1.1.1.1" xref="Ch2.E6.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="Ch2.E6.m1.2.2.1.1.1.1.2" xref="Ch2.E6.m1.2.2.1.1.2.cmml">(</mo><msub id="Ch2.E6.m1.2.2.1.1.1.1.1" xref="Ch2.E6.m1.2.2.1.1.1.1.1.cmml"><mi id="Ch2.E6.m1.2.2.1.1.1.1.1.2" xref="Ch2.E6.m1.2.2.1.1.1.1.1.2.cmml">C</mi><mi id="Ch2.E6.m1.2.2.1.1.1.1.1.3" xref="Ch2.E6.m1.2.2.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E6.m1.2.2.1.1.1.1.3" xref="Ch2.E6.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E6.m1.2b"><apply id="Ch2.E6.m1.2.2.cmml" xref="Ch2.E6.m1.2.2"><eq id="Ch2.E6.m1.2.2.2.cmml" xref="Ch2.E6.m1.2.2.2"></eq><apply id="Ch2.E6.m1.2.2.3.cmml" xref="Ch2.E6.m1.2.2.3"><csymbol cd="ambiguous" id="Ch2.E6.m1.2.2.3.1.cmml" xref="Ch2.E6.m1.2.2.3">subscript</csymbol><ci id="Ch2.E6.m1.2.2.3.2.cmml" xref="Ch2.E6.m1.2.2.3.2">ℎ</ci><ci id="Ch2.E6.m1.2.2.3.3.cmml" xref="Ch2.E6.m1.2.2.3.3">𝑡</ci></apply><apply id="Ch2.E6.m1.2.2.1.cmml" xref="Ch2.E6.m1.2.2.1"><times id="Ch2.E6.m1.2.2.1.2.cmml" xref="Ch2.E6.m1.2.2.1.2"></times><apply id="Ch2.E6.m1.2.2.1.3.cmml" xref="Ch2.E6.m1.2.2.1.3"><csymbol cd="ambiguous" id="Ch2.E6.m1.2.2.1.3.1.cmml" xref="Ch2.E6.m1.2.2.1.3">subscript</csymbol><ci id="Ch2.E6.m1.2.2.1.3.2.cmml" xref="Ch2.E6.m1.2.2.1.3.2">𝑜</ci><ci id="Ch2.E6.m1.2.2.1.3.3.cmml" xref="Ch2.E6.m1.2.2.1.3.3">𝑡</ci></apply><apply id="Ch2.E6.m1.2.2.1.1.2.cmml" xref="Ch2.E6.m1.2.2.1.1.1"><tanh id="Ch2.E6.m1.1.1.cmml" xref="Ch2.E6.m1.1.1"></tanh><apply id="Ch2.E6.m1.2.2.1.1.1.1.1.cmml" xref="Ch2.E6.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.E6.m1.2.2.1.1.1.1.1.1.cmml" xref="Ch2.E6.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="Ch2.E6.m1.2.2.1.1.1.1.1.2.cmml" xref="Ch2.E6.m1.2.2.1.1.1.1.1.2">𝐶</ci><ci id="Ch2.E6.m1.2.2.1.1.1.1.1.3.cmml" xref="Ch2.E6.m1.2.2.1.1.1.1.1.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E6.m1.2c">h_{t}=o_{t}*\tanh(C_{t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.6)</span></td>
</tr></tbody>
</table>
<p id="Ch2.S2.SS3.p1.12" class="ltx_p">where <math id="Ch2.S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="Ch2.S2.SS3.p1.1.m1.1a"><msub id="Ch2.S2.SS3.p1.1.m1.1.1" xref="Ch2.S2.SS3.p1.1.m1.1.1.cmml"><mi id="Ch2.S2.SS3.p1.1.m1.1.1.2" xref="Ch2.S2.SS3.p1.1.m1.1.1.2.cmml">x</mi><mi id="Ch2.S2.SS3.p1.1.m1.1.1.3" xref="Ch2.S2.SS3.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.1.m1.1b"><apply id="Ch2.S2.SS3.p1.1.m1.1.1.cmml" xref="Ch2.S2.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.1.m1.1.1.1.cmml" xref="Ch2.S2.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.1.m1.1.1.2.cmml" xref="Ch2.S2.SS3.p1.1.m1.1.1.2">𝑥</ci><ci id="Ch2.S2.SS3.p1.1.m1.1.1.3.cmml" xref="Ch2.S2.SS3.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.1.m1.1c">x_{t}</annotation></semantics></math> is the input in the LSTM in current time step <math id="Ch2.S2.SS3.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="Ch2.S2.SS3.p1.2.m2.1a"><mi id="Ch2.S2.SS3.p1.2.m2.1.1" xref="Ch2.S2.SS3.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.2.m2.1b"><ci id="Ch2.S2.SS3.p1.2.m2.1.1.cmml" xref="Ch2.S2.SS3.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.2.m2.1c">t</annotation></semantics></math>, <math id="Ch2.S2.SS3.p1.3.m3.1" class="ltx_Math" alttext="h_{t-1}" display="inline"><semantics id="Ch2.S2.SS3.p1.3.m3.1a"><msub id="Ch2.S2.SS3.p1.3.m3.1.1" xref="Ch2.S2.SS3.p1.3.m3.1.1.cmml"><mi id="Ch2.S2.SS3.p1.3.m3.1.1.2" xref="Ch2.S2.SS3.p1.3.m3.1.1.2.cmml">h</mi><mrow id="Ch2.S2.SS3.p1.3.m3.1.1.3" xref="Ch2.S2.SS3.p1.3.m3.1.1.3.cmml"><mi id="Ch2.S2.SS3.p1.3.m3.1.1.3.2" xref="Ch2.S2.SS3.p1.3.m3.1.1.3.2.cmml">t</mi><mo id="Ch2.S2.SS3.p1.3.m3.1.1.3.1" xref="Ch2.S2.SS3.p1.3.m3.1.1.3.1.cmml">−</mo><mn id="Ch2.S2.SS3.p1.3.m3.1.1.3.3" xref="Ch2.S2.SS3.p1.3.m3.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.3.m3.1b"><apply id="Ch2.S2.SS3.p1.3.m3.1.1.cmml" xref="Ch2.S2.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.3.m3.1.1.1.cmml" xref="Ch2.S2.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.3.m3.1.1.2.cmml" xref="Ch2.S2.SS3.p1.3.m3.1.1.2">ℎ</ci><apply id="Ch2.S2.SS3.p1.3.m3.1.1.3.cmml" xref="Ch2.S2.SS3.p1.3.m3.1.1.3"><minus id="Ch2.S2.SS3.p1.3.m3.1.1.3.1.cmml" xref="Ch2.S2.SS3.p1.3.m3.1.1.3.1"></minus><ci id="Ch2.S2.SS3.p1.3.m3.1.1.3.2.cmml" xref="Ch2.S2.SS3.p1.3.m3.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.S2.SS3.p1.3.m3.1.1.3.3.cmml" xref="Ch2.S2.SS3.p1.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.3.m3.1c">h_{t-1}</annotation></semantics></math> is the hidden state of the LSTM from the previous time step, <math id="Ch2.S2.SS3.p1.4.m4.1" class="ltx_Math" alttext="h_{t}" display="inline"><semantics id="Ch2.S2.SS3.p1.4.m4.1a"><msub id="Ch2.S2.SS3.p1.4.m4.1.1" xref="Ch2.S2.SS3.p1.4.m4.1.1.cmml"><mi id="Ch2.S2.SS3.p1.4.m4.1.1.2" xref="Ch2.S2.SS3.p1.4.m4.1.1.2.cmml">h</mi><mi id="Ch2.S2.SS3.p1.4.m4.1.1.3" xref="Ch2.S2.SS3.p1.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.4.m4.1b"><apply id="Ch2.S2.SS3.p1.4.m4.1.1.cmml" xref="Ch2.S2.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.4.m4.1.1.1.cmml" xref="Ch2.S2.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.4.m4.1.1.2.cmml" xref="Ch2.S2.SS3.p1.4.m4.1.1.2">ℎ</ci><ci id="Ch2.S2.SS3.p1.4.m4.1.1.3.cmml" xref="Ch2.S2.SS3.p1.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.4.m4.1c">h_{t}</annotation></semantics></math> is the hidden state of the LSTM in the current time step, <math id="Ch2.S2.SS3.p1.5.m5.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="Ch2.S2.SS3.p1.5.m5.1a"><msub id="Ch2.S2.SS3.p1.5.m5.1.1" xref="Ch2.S2.SS3.p1.5.m5.1.1.cmml"><mi id="Ch2.S2.SS3.p1.5.m5.1.1.2" xref="Ch2.S2.SS3.p1.5.m5.1.1.2.cmml">f</mi><mi id="Ch2.S2.SS3.p1.5.m5.1.1.3" xref="Ch2.S2.SS3.p1.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.5.m5.1b"><apply id="Ch2.S2.SS3.p1.5.m5.1.1.cmml" xref="Ch2.S2.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.5.m5.1.1.1.cmml" xref="Ch2.S2.SS3.p1.5.m5.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.5.m5.1.1.2.cmml" xref="Ch2.S2.SS3.p1.5.m5.1.1.2">𝑓</ci><ci id="Ch2.S2.SS3.p1.5.m5.1.1.3.cmml" xref="Ch2.S2.SS3.p1.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.5.m5.1c">f_{t}</annotation></semantics></math> is the forget gate, <math id="Ch2.S2.SS3.p1.6.m6.1" class="ltx_Math" alttext="i_{t}" display="inline"><semantics id="Ch2.S2.SS3.p1.6.m6.1a"><msub id="Ch2.S2.SS3.p1.6.m6.1.1" xref="Ch2.S2.SS3.p1.6.m6.1.1.cmml"><mi id="Ch2.S2.SS3.p1.6.m6.1.1.2" xref="Ch2.S2.SS3.p1.6.m6.1.1.2.cmml">i</mi><mi id="Ch2.S2.SS3.p1.6.m6.1.1.3" xref="Ch2.S2.SS3.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.6.m6.1b"><apply id="Ch2.S2.SS3.p1.6.m6.1.1.cmml" xref="Ch2.S2.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.6.m6.1.1.1.cmml" xref="Ch2.S2.SS3.p1.6.m6.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.6.m6.1.1.2.cmml" xref="Ch2.S2.SS3.p1.6.m6.1.1.2">𝑖</ci><ci id="Ch2.S2.SS3.p1.6.m6.1.1.3.cmml" xref="Ch2.S2.SS3.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.6.m6.1c">i_{t}</annotation></semantics></math> is the input gate, <math id="Ch2.S2.SS3.p1.7.m7.1" class="ltx_Math" alttext="o_{t}" display="inline"><semantics id="Ch2.S2.SS3.p1.7.m7.1a"><msub id="Ch2.S2.SS3.p1.7.m7.1.1" xref="Ch2.S2.SS3.p1.7.m7.1.1.cmml"><mi id="Ch2.S2.SS3.p1.7.m7.1.1.2" xref="Ch2.S2.SS3.p1.7.m7.1.1.2.cmml">o</mi><mi id="Ch2.S2.SS3.p1.7.m7.1.1.3" xref="Ch2.S2.SS3.p1.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.7.m7.1b"><apply id="Ch2.S2.SS3.p1.7.m7.1.1.cmml" xref="Ch2.S2.SS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.7.m7.1.1.1.cmml" xref="Ch2.S2.SS3.p1.7.m7.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.7.m7.1.1.2.cmml" xref="Ch2.S2.SS3.p1.7.m7.1.1.2">𝑜</ci><ci id="Ch2.S2.SS3.p1.7.m7.1.1.3.cmml" xref="Ch2.S2.SS3.p1.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.7.m7.1c">o_{t}</annotation></semantics></math> is the output gate, <math id="Ch2.S2.SS3.p1.8.m8.1" class="ltx_Math" alttext="C_{t-1}" display="inline"><semantics id="Ch2.S2.SS3.p1.8.m8.1a"><msub id="Ch2.S2.SS3.p1.8.m8.1.1" xref="Ch2.S2.SS3.p1.8.m8.1.1.cmml"><mi id="Ch2.S2.SS3.p1.8.m8.1.1.2" xref="Ch2.S2.SS3.p1.8.m8.1.1.2.cmml">C</mi><mrow id="Ch2.S2.SS3.p1.8.m8.1.1.3" xref="Ch2.S2.SS3.p1.8.m8.1.1.3.cmml"><mi id="Ch2.S2.SS3.p1.8.m8.1.1.3.2" xref="Ch2.S2.SS3.p1.8.m8.1.1.3.2.cmml">t</mi><mo id="Ch2.S2.SS3.p1.8.m8.1.1.3.1" xref="Ch2.S2.SS3.p1.8.m8.1.1.3.1.cmml">−</mo><mn id="Ch2.S2.SS3.p1.8.m8.1.1.3.3" xref="Ch2.S2.SS3.p1.8.m8.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.8.m8.1b"><apply id="Ch2.S2.SS3.p1.8.m8.1.1.cmml" xref="Ch2.S2.SS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.8.m8.1.1.1.cmml" xref="Ch2.S2.SS3.p1.8.m8.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.8.m8.1.1.2.cmml" xref="Ch2.S2.SS3.p1.8.m8.1.1.2">𝐶</ci><apply id="Ch2.S2.SS3.p1.8.m8.1.1.3.cmml" xref="Ch2.S2.SS3.p1.8.m8.1.1.3"><minus id="Ch2.S2.SS3.p1.8.m8.1.1.3.1.cmml" xref="Ch2.S2.SS3.p1.8.m8.1.1.3.1"></minus><ci id="Ch2.S2.SS3.p1.8.m8.1.1.3.2.cmml" xref="Ch2.S2.SS3.p1.8.m8.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.S2.SS3.p1.8.m8.1.1.3.3.cmml" xref="Ch2.S2.SS3.p1.8.m8.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.8.m8.1c">C_{t-1}</annotation></semantics></math> is the cell state of the LSTM from the previous time step, <math id="Ch2.S2.SS3.p1.9.m9.1" class="ltx_Math" alttext="\widetilde{C}_{t}" display="inline"><semantics id="Ch2.S2.SS3.p1.9.m9.1a"><msub id="Ch2.S2.SS3.p1.9.m9.1.1" xref="Ch2.S2.SS3.p1.9.m9.1.1.cmml"><mover accent="true" id="Ch2.S2.SS3.p1.9.m9.1.1.2" xref="Ch2.S2.SS3.p1.9.m9.1.1.2.cmml"><mi id="Ch2.S2.SS3.p1.9.m9.1.1.2.2" xref="Ch2.S2.SS3.p1.9.m9.1.1.2.2.cmml">C</mi><mo id="Ch2.S2.SS3.p1.9.m9.1.1.2.1" xref="Ch2.S2.SS3.p1.9.m9.1.1.2.1.cmml">~</mo></mover><mi id="Ch2.S2.SS3.p1.9.m9.1.1.3" xref="Ch2.S2.SS3.p1.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.9.m9.1b"><apply id="Ch2.S2.SS3.p1.9.m9.1.1.cmml" xref="Ch2.S2.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.9.m9.1.1.1.cmml" xref="Ch2.S2.SS3.p1.9.m9.1.1">subscript</csymbol><apply id="Ch2.S2.SS3.p1.9.m9.1.1.2.cmml" xref="Ch2.S2.SS3.p1.9.m9.1.1.2"><ci id="Ch2.S2.SS3.p1.9.m9.1.1.2.1.cmml" xref="Ch2.S2.SS3.p1.9.m9.1.1.2.1">~</ci><ci id="Ch2.S2.SS3.p1.9.m9.1.1.2.2.cmml" xref="Ch2.S2.SS3.p1.9.m9.1.1.2.2">𝐶</ci></apply><ci id="Ch2.S2.SS3.p1.9.m9.1.1.3.cmml" xref="Ch2.S2.SS3.p1.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.9.m9.1c">\widetilde{C}_{t}</annotation></semantics></math> is the intermediate cell state of the LSTM in the current time step and <math id="Ch2.S2.SS3.p1.10.m10.1" class="ltx_Math" alttext="C_{t}" display="inline"><semantics id="Ch2.S2.SS3.p1.10.m10.1a"><msub id="Ch2.S2.SS3.p1.10.m10.1.1" xref="Ch2.S2.SS3.p1.10.m10.1.1.cmml"><mi id="Ch2.S2.SS3.p1.10.m10.1.1.2" xref="Ch2.S2.SS3.p1.10.m10.1.1.2.cmml">C</mi><mi id="Ch2.S2.SS3.p1.10.m10.1.1.3" xref="Ch2.S2.SS3.p1.10.m10.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.10.m10.1b"><apply id="Ch2.S2.SS3.p1.10.m10.1.1.cmml" xref="Ch2.S2.SS3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.10.m10.1.1.1.cmml" xref="Ch2.S2.SS3.p1.10.m10.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.10.m10.1.1.2.cmml" xref="Ch2.S2.SS3.p1.10.m10.1.1.2">𝐶</ci><ci id="Ch2.S2.SS3.p1.10.m10.1.1.3.cmml" xref="Ch2.S2.SS3.p1.10.m10.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.10.m10.1c">C_{t}</annotation></semantics></math> is the cell state of the LSTM in the current time step. <math id="Ch2.S2.SS3.p1.11.m11.4" class="ltx_Math" alttext="W_{f},W_{i},W_{C},W_{o}" display="inline"><semantics id="Ch2.S2.SS3.p1.11.m11.4a"><mrow id="Ch2.S2.SS3.p1.11.m11.4.4.4" xref="Ch2.S2.SS3.p1.11.m11.4.4.5.cmml"><msub id="Ch2.S2.SS3.p1.11.m11.1.1.1.1" xref="Ch2.S2.SS3.p1.11.m11.1.1.1.1.cmml"><mi id="Ch2.S2.SS3.p1.11.m11.1.1.1.1.2" xref="Ch2.S2.SS3.p1.11.m11.1.1.1.1.2.cmml">W</mi><mi id="Ch2.S2.SS3.p1.11.m11.1.1.1.1.3" xref="Ch2.S2.SS3.p1.11.m11.1.1.1.1.3.cmml">f</mi></msub><mo id="Ch2.S2.SS3.p1.11.m11.4.4.4.5" xref="Ch2.S2.SS3.p1.11.m11.4.4.5.cmml">,</mo><msub id="Ch2.S2.SS3.p1.11.m11.2.2.2.2" xref="Ch2.S2.SS3.p1.11.m11.2.2.2.2.cmml"><mi id="Ch2.S2.SS3.p1.11.m11.2.2.2.2.2" xref="Ch2.S2.SS3.p1.11.m11.2.2.2.2.2.cmml">W</mi><mi id="Ch2.S2.SS3.p1.11.m11.2.2.2.2.3" xref="Ch2.S2.SS3.p1.11.m11.2.2.2.2.3.cmml">i</mi></msub><mo id="Ch2.S2.SS3.p1.11.m11.4.4.4.6" xref="Ch2.S2.SS3.p1.11.m11.4.4.5.cmml">,</mo><msub id="Ch2.S2.SS3.p1.11.m11.3.3.3.3" xref="Ch2.S2.SS3.p1.11.m11.3.3.3.3.cmml"><mi id="Ch2.S2.SS3.p1.11.m11.3.3.3.3.2" xref="Ch2.S2.SS3.p1.11.m11.3.3.3.3.2.cmml">W</mi><mi id="Ch2.S2.SS3.p1.11.m11.3.3.3.3.3" xref="Ch2.S2.SS3.p1.11.m11.3.3.3.3.3.cmml">C</mi></msub><mo id="Ch2.S2.SS3.p1.11.m11.4.4.4.7" xref="Ch2.S2.SS3.p1.11.m11.4.4.5.cmml">,</mo><msub id="Ch2.S2.SS3.p1.11.m11.4.4.4.4" xref="Ch2.S2.SS3.p1.11.m11.4.4.4.4.cmml"><mi id="Ch2.S2.SS3.p1.11.m11.4.4.4.4.2" xref="Ch2.S2.SS3.p1.11.m11.4.4.4.4.2.cmml">W</mi><mi id="Ch2.S2.SS3.p1.11.m11.4.4.4.4.3" xref="Ch2.S2.SS3.p1.11.m11.4.4.4.4.3.cmml">o</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.11.m11.4b"><list id="Ch2.S2.SS3.p1.11.m11.4.4.5.cmml" xref="Ch2.S2.SS3.p1.11.m11.4.4.4"><apply id="Ch2.S2.SS3.p1.11.m11.1.1.1.1.cmml" xref="Ch2.S2.SS3.p1.11.m11.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.11.m11.1.1.1.1.1.cmml" xref="Ch2.S2.SS3.p1.11.m11.1.1.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.11.m11.1.1.1.1.2.cmml" xref="Ch2.S2.SS3.p1.11.m11.1.1.1.1.2">𝑊</ci><ci id="Ch2.S2.SS3.p1.11.m11.1.1.1.1.3.cmml" xref="Ch2.S2.SS3.p1.11.m11.1.1.1.1.3">𝑓</ci></apply><apply id="Ch2.S2.SS3.p1.11.m11.2.2.2.2.cmml" xref="Ch2.S2.SS3.p1.11.m11.2.2.2.2"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.11.m11.2.2.2.2.1.cmml" xref="Ch2.S2.SS3.p1.11.m11.2.2.2.2">subscript</csymbol><ci id="Ch2.S2.SS3.p1.11.m11.2.2.2.2.2.cmml" xref="Ch2.S2.SS3.p1.11.m11.2.2.2.2.2">𝑊</ci><ci id="Ch2.S2.SS3.p1.11.m11.2.2.2.2.3.cmml" xref="Ch2.S2.SS3.p1.11.m11.2.2.2.2.3">𝑖</ci></apply><apply id="Ch2.S2.SS3.p1.11.m11.3.3.3.3.cmml" xref="Ch2.S2.SS3.p1.11.m11.3.3.3.3"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.11.m11.3.3.3.3.1.cmml" xref="Ch2.S2.SS3.p1.11.m11.3.3.3.3">subscript</csymbol><ci id="Ch2.S2.SS3.p1.11.m11.3.3.3.3.2.cmml" xref="Ch2.S2.SS3.p1.11.m11.3.3.3.3.2">𝑊</ci><ci id="Ch2.S2.SS3.p1.11.m11.3.3.3.3.3.cmml" xref="Ch2.S2.SS3.p1.11.m11.3.3.3.3.3">𝐶</ci></apply><apply id="Ch2.S2.SS3.p1.11.m11.4.4.4.4.cmml" xref="Ch2.S2.SS3.p1.11.m11.4.4.4.4"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.11.m11.4.4.4.4.1.cmml" xref="Ch2.S2.SS3.p1.11.m11.4.4.4.4">subscript</csymbol><ci id="Ch2.S2.SS3.p1.11.m11.4.4.4.4.2.cmml" xref="Ch2.S2.SS3.p1.11.m11.4.4.4.4.2">𝑊</ci><ci id="Ch2.S2.SS3.p1.11.m11.4.4.4.4.3.cmml" xref="Ch2.S2.SS3.p1.11.m11.4.4.4.4.3">𝑜</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.11.m11.4c">W_{f},W_{i},W_{C},W_{o}</annotation></semantics></math> are weight matrices and <math id="Ch2.S2.SS3.p1.12.m12.4" class="ltx_Math" alttext="b_{f},b_{i},b_{C},b_{o}" display="inline"><semantics id="Ch2.S2.SS3.p1.12.m12.4a"><mrow id="Ch2.S2.SS3.p1.12.m12.4.4.4" xref="Ch2.S2.SS3.p1.12.m12.4.4.5.cmml"><msub id="Ch2.S2.SS3.p1.12.m12.1.1.1.1" xref="Ch2.S2.SS3.p1.12.m12.1.1.1.1.cmml"><mi id="Ch2.S2.SS3.p1.12.m12.1.1.1.1.2" xref="Ch2.S2.SS3.p1.12.m12.1.1.1.1.2.cmml">b</mi><mi id="Ch2.S2.SS3.p1.12.m12.1.1.1.1.3" xref="Ch2.S2.SS3.p1.12.m12.1.1.1.1.3.cmml">f</mi></msub><mo id="Ch2.S2.SS3.p1.12.m12.4.4.4.5" xref="Ch2.S2.SS3.p1.12.m12.4.4.5.cmml">,</mo><msub id="Ch2.S2.SS3.p1.12.m12.2.2.2.2" xref="Ch2.S2.SS3.p1.12.m12.2.2.2.2.cmml"><mi id="Ch2.S2.SS3.p1.12.m12.2.2.2.2.2" xref="Ch2.S2.SS3.p1.12.m12.2.2.2.2.2.cmml">b</mi><mi id="Ch2.S2.SS3.p1.12.m12.2.2.2.2.3" xref="Ch2.S2.SS3.p1.12.m12.2.2.2.2.3.cmml">i</mi></msub><mo id="Ch2.S2.SS3.p1.12.m12.4.4.4.6" xref="Ch2.S2.SS3.p1.12.m12.4.4.5.cmml">,</mo><msub id="Ch2.S2.SS3.p1.12.m12.3.3.3.3" xref="Ch2.S2.SS3.p1.12.m12.3.3.3.3.cmml"><mi id="Ch2.S2.SS3.p1.12.m12.3.3.3.3.2" xref="Ch2.S2.SS3.p1.12.m12.3.3.3.3.2.cmml">b</mi><mi id="Ch2.S2.SS3.p1.12.m12.3.3.3.3.3" xref="Ch2.S2.SS3.p1.12.m12.3.3.3.3.3.cmml">C</mi></msub><mo id="Ch2.S2.SS3.p1.12.m12.4.4.4.7" xref="Ch2.S2.SS3.p1.12.m12.4.4.5.cmml">,</mo><msub id="Ch2.S2.SS3.p1.12.m12.4.4.4.4" xref="Ch2.S2.SS3.p1.12.m12.4.4.4.4.cmml"><mi id="Ch2.S2.SS3.p1.12.m12.4.4.4.4.2" xref="Ch2.S2.SS3.p1.12.m12.4.4.4.4.2.cmml">b</mi><mi id="Ch2.S2.SS3.p1.12.m12.4.4.4.4.3" xref="Ch2.S2.SS3.p1.12.m12.4.4.4.4.3.cmml">o</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p1.12.m12.4b"><list id="Ch2.S2.SS3.p1.12.m12.4.4.5.cmml" xref="Ch2.S2.SS3.p1.12.m12.4.4.4"><apply id="Ch2.S2.SS3.p1.12.m12.1.1.1.1.cmml" xref="Ch2.S2.SS3.p1.12.m12.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.12.m12.1.1.1.1.1.cmml" xref="Ch2.S2.SS3.p1.12.m12.1.1.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p1.12.m12.1.1.1.1.2.cmml" xref="Ch2.S2.SS3.p1.12.m12.1.1.1.1.2">𝑏</ci><ci id="Ch2.S2.SS3.p1.12.m12.1.1.1.1.3.cmml" xref="Ch2.S2.SS3.p1.12.m12.1.1.1.1.3">𝑓</ci></apply><apply id="Ch2.S2.SS3.p1.12.m12.2.2.2.2.cmml" xref="Ch2.S2.SS3.p1.12.m12.2.2.2.2"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.12.m12.2.2.2.2.1.cmml" xref="Ch2.S2.SS3.p1.12.m12.2.2.2.2">subscript</csymbol><ci id="Ch2.S2.SS3.p1.12.m12.2.2.2.2.2.cmml" xref="Ch2.S2.SS3.p1.12.m12.2.2.2.2.2">𝑏</ci><ci id="Ch2.S2.SS3.p1.12.m12.2.2.2.2.3.cmml" xref="Ch2.S2.SS3.p1.12.m12.2.2.2.2.3">𝑖</ci></apply><apply id="Ch2.S2.SS3.p1.12.m12.3.3.3.3.cmml" xref="Ch2.S2.SS3.p1.12.m12.3.3.3.3"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.12.m12.3.3.3.3.1.cmml" xref="Ch2.S2.SS3.p1.12.m12.3.3.3.3">subscript</csymbol><ci id="Ch2.S2.SS3.p1.12.m12.3.3.3.3.2.cmml" xref="Ch2.S2.SS3.p1.12.m12.3.3.3.3.2">𝑏</ci><ci id="Ch2.S2.SS3.p1.12.m12.3.3.3.3.3.cmml" xref="Ch2.S2.SS3.p1.12.m12.3.3.3.3.3">𝐶</ci></apply><apply id="Ch2.S2.SS3.p1.12.m12.4.4.4.4.cmml" xref="Ch2.S2.SS3.p1.12.m12.4.4.4.4"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p1.12.m12.4.4.4.4.1.cmml" xref="Ch2.S2.SS3.p1.12.m12.4.4.4.4">subscript</csymbol><ci id="Ch2.S2.SS3.p1.12.m12.4.4.4.4.2.cmml" xref="Ch2.S2.SS3.p1.12.m12.4.4.4.4.2">𝑏</ci><ci id="Ch2.S2.SS3.p1.12.m12.4.4.4.4.3.cmml" xref="Ch2.S2.SS3.p1.12.m12.4.4.4.4.3">𝑜</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p1.12.m12.4c">b_{f},b_{i},b_{C},b_{o}</annotation></semantics></math> are bias vectors and together they represent the learnable parameters of the LSTM. For better visualisation of the gates and their interactions, a LSTM cell is shown in Figure <a href="#Ch2.F1" title="Figure 2.1 ‣ 2.2.3 Recurrent Neural Networks ‣ 2.2 Deep Learning ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.</p>
</div>
<figure id="Ch2.F1" class="ltx_figure"><img src="/html/2007.05881/assets/x1.png" id="Ch2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="218" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2.1: </span>A diagram of the LSTM model and the interactions between the gates, the hidden state and the cell state. The blue squares represent a Fully Connected Neural Network, with the activation assigned in the blue square. The purple circles are point-wise operations and the type of operation is noted inside the circle. The diagram was inspired by the diagrams in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</figcaption>
</figure>
<div id="Ch2.S2.SS3.p2" class="ltx_para">
<p id="Ch2.S2.SS3.p2.9" class="ltx_p">There are many variations of the LSTM network, but one that is worth mentioning is the Gated Recurrent Unit (GRU) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. It differs from the LSTM in that it combines the forget and input gates into an update gate. It also merges the cell state and hidden state, which results in a much simpler network that is easier to implement and is computationally efficient. The following formulas describe the gated unit of the GRU recurrent neural network:</p>
<table id="Ch2.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E7.m1.1" class="ltx_Math" alttext="z_{t}=\sigma(W_{z}*[h_{t-1},x_{t}])" display="block"><semantics id="Ch2.E7.m1.1a"><mrow id="Ch2.E7.m1.1.1" xref="Ch2.E7.m1.1.1.cmml"><msub id="Ch2.E7.m1.1.1.3" xref="Ch2.E7.m1.1.1.3.cmml"><mi id="Ch2.E7.m1.1.1.3.2" xref="Ch2.E7.m1.1.1.3.2.cmml">z</mi><mi id="Ch2.E7.m1.1.1.3.3" xref="Ch2.E7.m1.1.1.3.3.cmml">t</mi></msub><mo id="Ch2.E7.m1.1.1.2" xref="Ch2.E7.m1.1.1.2.cmml">=</mo><mrow id="Ch2.E7.m1.1.1.1" xref="Ch2.E7.m1.1.1.1.cmml"><mi id="Ch2.E7.m1.1.1.1.3" xref="Ch2.E7.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="Ch2.E7.m1.1.1.1.2" xref="Ch2.E7.m1.1.1.1.2.cmml">​</mo><mrow id="Ch2.E7.m1.1.1.1.1.1" xref="Ch2.E7.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch2.E7.m1.1.1.1.1.1.2" xref="Ch2.E7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch2.E7.m1.1.1.1.1.1.1" xref="Ch2.E7.m1.1.1.1.1.1.1.cmml"><msub id="Ch2.E7.m1.1.1.1.1.1.1.4" xref="Ch2.E7.m1.1.1.1.1.1.1.4.cmml"><mi id="Ch2.E7.m1.1.1.1.1.1.1.4.2" xref="Ch2.E7.m1.1.1.1.1.1.1.4.2.cmml">W</mi><mi id="Ch2.E7.m1.1.1.1.1.1.1.4.3" xref="Ch2.E7.m1.1.1.1.1.1.1.4.3.cmml">z</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E7.m1.1.1.1.1.1.1.3" xref="Ch2.E7.m1.1.1.1.1.1.1.3.cmml">∗</mo><mrow id="Ch2.E7.m1.1.1.1.1.1.1.2.2" xref="Ch2.E7.m1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="Ch2.E7.m1.1.1.1.1.1.1.2.2.3" xref="Ch2.E7.m1.1.1.1.1.1.1.2.3.cmml">[</mo><msub id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.2" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mrow id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.2" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.1" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.3" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="Ch2.E7.m1.1.1.1.1.1.1.2.2.4" xref="Ch2.E7.m1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="Ch2.E7.m1.1.1.1.1.1.1.2.2.2" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.cmml"><mi id="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.2" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mi id="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.3" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E7.m1.1.1.1.1.1.1.2.2.5" xref="Ch2.E7.m1.1.1.1.1.1.1.2.3.cmml">]</mo></mrow></mrow><mo stretchy="false" id="Ch2.E7.m1.1.1.1.1.1.3" xref="Ch2.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E7.m1.1b"><apply id="Ch2.E7.m1.1.1.cmml" xref="Ch2.E7.m1.1.1"><eq id="Ch2.E7.m1.1.1.2.cmml" xref="Ch2.E7.m1.1.1.2"></eq><apply id="Ch2.E7.m1.1.1.3.cmml" xref="Ch2.E7.m1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E7.m1.1.1.3.1.cmml" xref="Ch2.E7.m1.1.1.3">subscript</csymbol><ci id="Ch2.E7.m1.1.1.3.2.cmml" xref="Ch2.E7.m1.1.1.3.2">𝑧</ci><ci id="Ch2.E7.m1.1.1.3.3.cmml" xref="Ch2.E7.m1.1.1.3.3">𝑡</ci></apply><apply id="Ch2.E7.m1.1.1.1.cmml" xref="Ch2.E7.m1.1.1.1"><times id="Ch2.E7.m1.1.1.1.2.cmml" xref="Ch2.E7.m1.1.1.1.2"></times><ci id="Ch2.E7.m1.1.1.1.3.cmml" xref="Ch2.E7.m1.1.1.1.3">𝜎</ci><apply id="Ch2.E7.m1.1.1.1.1.1.1.cmml" xref="Ch2.E7.m1.1.1.1.1.1"><times id="Ch2.E7.m1.1.1.1.1.1.1.3.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.3"></times><apply id="Ch2.E7.m1.1.1.1.1.1.1.4.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Ch2.E7.m1.1.1.1.1.1.1.4.1.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Ch2.E7.m1.1.1.1.1.1.1.4.2.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.4.2">𝑊</ci><ci id="Ch2.E7.m1.1.1.1.1.1.1.4.3.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.4.3">𝑧</ci></apply><interval closure="closed" id="Ch2.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2"><apply id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.2">ℎ</ci><apply id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3"><minus id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.1"></minus><ci id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.1.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.2">𝑥</ci><ci id="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.3.cmml" xref="Ch2.E7.m1.1.1.1.1.1.1.2.2.2.3">𝑡</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E7.m1.1c">z_{t}=\sigma(W_{z}*[h_{t-1},x_{t}])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.7)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E8.m1.1" class="ltx_Math" alttext="r_{t}=\sigma(W_{r}*[h_{t-1},x_{t}])" display="block"><semantics id="Ch2.E8.m1.1a"><mrow id="Ch2.E8.m1.1.1" xref="Ch2.E8.m1.1.1.cmml"><msub id="Ch2.E8.m1.1.1.3" xref="Ch2.E8.m1.1.1.3.cmml"><mi id="Ch2.E8.m1.1.1.3.2" xref="Ch2.E8.m1.1.1.3.2.cmml">r</mi><mi id="Ch2.E8.m1.1.1.3.3" xref="Ch2.E8.m1.1.1.3.3.cmml">t</mi></msub><mo id="Ch2.E8.m1.1.1.2" xref="Ch2.E8.m1.1.1.2.cmml">=</mo><mrow id="Ch2.E8.m1.1.1.1" xref="Ch2.E8.m1.1.1.1.cmml"><mi id="Ch2.E8.m1.1.1.1.3" xref="Ch2.E8.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="Ch2.E8.m1.1.1.1.2" xref="Ch2.E8.m1.1.1.1.2.cmml">​</mo><mrow id="Ch2.E8.m1.1.1.1.1.1" xref="Ch2.E8.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch2.E8.m1.1.1.1.1.1.2" xref="Ch2.E8.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch2.E8.m1.1.1.1.1.1.1" xref="Ch2.E8.m1.1.1.1.1.1.1.cmml"><msub id="Ch2.E8.m1.1.1.1.1.1.1.4" xref="Ch2.E8.m1.1.1.1.1.1.1.4.cmml"><mi id="Ch2.E8.m1.1.1.1.1.1.1.4.2" xref="Ch2.E8.m1.1.1.1.1.1.1.4.2.cmml">W</mi><mi id="Ch2.E8.m1.1.1.1.1.1.1.4.3" xref="Ch2.E8.m1.1.1.1.1.1.1.4.3.cmml">r</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E8.m1.1.1.1.1.1.1.3" xref="Ch2.E8.m1.1.1.1.1.1.1.3.cmml">∗</mo><mrow id="Ch2.E8.m1.1.1.1.1.1.1.2.2" xref="Ch2.E8.m1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="Ch2.E8.m1.1.1.1.1.1.1.2.2.3" xref="Ch2.E8.m1.1.1.1.1.1.1.2.3.cmml">[</mo><msub id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.2" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mrow id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.2" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.1" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.3" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="Ch2.E8.m1.1.1.1.1.1.1.2.2.4" xref="Ch2.E8.m1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="Ch2.E8.m1.1.1.1.1.1.1.2.2.2" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.cmml"><mi id="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.2" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mi id="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.3" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E8.m1.1.1.1.1.1.1.2.2.5" xref="Ch2.E8.m1.1.1.1.1.1.1.2.3.cmml">]</mo></mrow></mrow><mo stretchy="false" id="Ch2.E8.m1.1.1.1.1.1.3" xref="Ch2.E8.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E8.m1.1b"><apply id="Ch2.E8.m1.1.1.cmml" xref="Ch2.E8.m1.1.1"><eq id="Ch2.E8.m1.1.1.2.cmml" xref="Ch2.E8.m1.1.1.2"></eq><apply id="Ch2.E8.m1.1.1.3.cmml" xref="Ch2.E8.m1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E8.m1.1.1.3.1.cmml" xref="Ch2.E8.m1.1.1.3">subscript</csymbol><ci id="Ch2.E8.m1.1.1.3.2.cmml" xref="Ch2.E8.m1.1.1.3.2">𝑟</ci><ci id="Ch2.E8.m1.1.1.3.3.cmml" xref="Ch2.E8.m1.1.1.3.3">𝑡</ci></apply><apply id="Ch2.E8.m1.1.1.1.cmml" xref="Ch2.E8.m1.1.1.1"><times id="Ch2.E8.m1.1.1.1.2.cmml" xref="Ch2.E8.m1.1.1.1.2"></times><ci id="Ch2.E8.m1.1.1.1.3.cmml" xref="Ch2.E8.m1.1.1.1.3">𝜎</ci><apply id="Ch2.E8.m1.1.1.1.1.1.1.cmml" xref="Ch2.E8.m1.1.1.1.1.1"><times id="Ch2.E8.m1.1.1.1.1.1.1.3.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.3"></times><apply id="Ch2.E8.m1.1.1.1.1.1.1.4.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Ch2.E8.m1.1.1.1.1.1.1.4.1.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Ch2.E8.m1.1.1.1.1.1.1.4.2.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.4.2">𝑊</ci><ci id="Ch2.E8.m1.1.1.1.1.1.1.4.3.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.4.3">𝑟</ci></apply><interval closure="closed" id="Ch2.E8.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2"><apply id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.2">ℎ</ci><apply id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3"><minus id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.1"></minus><ci id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.1.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.2">𝑥</ci><ci id="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.3.cmml" xref="Ch2.E8.m1.1.1.1.1.1.1.2.2.2.3">𝑡</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E8.m1.1c">r_{t}=\sigma(W_{r}*[h_{t-1},x_{t}])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.8)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E9.m1.2" class="ltx_Math" alttext="\tilde{h}_{t}=\tanh(W*[r_{t}*h_{t-1},x_{t}])" display="block"><semantics id="Ch2.E9.m1.2a"><mrow id="Ch2.E9.m1.2.2" xref="Ch2.E9.m1.2.2.cmml"><msub id="Ch2.E9.m1.2.2.3" xref="Ch2.E9.m1.2.2.3.cmml"><mover accent="true" id="Ch2.E9.m1.2.2.3.2" xref="Ch2.E9.m1.2.2.3.2.cmml"><mi id="Ch2.E9.m1.2.2.3.2.2" xref="Ch2.E9.m1.2.2.3.2.2.cmml">h</mi><mo id="Ch2.E9.m1.2.2.3.2.1" xref="Ch2.E9.m1.2.2.3.2.1.cmml">~</mo></mover><mi id="Ch2.E9.m1.2.2.3.3" xref="Ch2.E9.m1.2.2.3.3.cmml">t</mi></msub><mo id="Ch2.E9.m1.2.2.2" xref="Ch2.E9.m1.2.2.2.cmml">=</mo><mrow id="Ch2.E9.m1.2.2.1.1" xref="Ch2.E9.m1.2.2.1.2.cmml"><mi id="Ch2.E9.m1.1.1" xref="Ch2.E9.m1.1.1.cmml">tanh</mi><mo id="Ch2.E9.m1.2.2.1.1a" xref="Ch2.E9.m1.2.2.1.2.cmml">⁡</mo><mrow id="Ch2.E9.m1.2.2.1.1.1" xref="Ch2.E9.m1.2.2.1.2.cmml"><mo stretchy="false" id="Ch2.E9.m1.2.2.1.1.1.2" xref="Ch2.E9.m1.2.2.1.2.cmml">(</mo><mrow id="Ch2.E9.m1.2.2.1.1.1.1" xref="Ch2.E9.m1.2.2.1.1.1.1.cmml"><mi id="Ch2.E9.m1.2.2.1.1.1.1.4" xref="Ch2.E9.m1.2.2.1.1.1.1.4.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="Ch2.E9.m1.2.2.1.1.1.1.3" xref="Ch2.E9.m1.2.2.1.1.1.1.3.cmml">∗</mo><mrow id="Ch2.E9.m1.2.2.1.1.1.1.2.2" xref="Ch2.E9.m1.2.2.1.1.1.1.2.3.cmml"><mo stretchy="false" id="Ch2.E9.m1.2.2.1.1.1.1.2.2.3" xref="Ch2.E9.m1.2.2.1.1.1.1.2.3.cmml">[</mo><mrow id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.2" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">r</mi><mi id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.3" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.1" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.1.cmml">∗</mo><msub id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.2" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">h</mi><mrow id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.cmml"><mi id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.2" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.1" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.3" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="Ch2.E9.m1.2.2.1.1.1.1.2.2.4" xref="Ch2.E9.m1.2.2.1.1.1.1.2.3.cmml">,</mo><msub id="Ch2.E9.m1.2.2.1.1.1.1.2.2.2" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.cmml"><mi id="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.2" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.2.cmml">x</mi><mi id="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.3" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="Ch2.E9.m1.2.2.1.1.1.1.2.2.5" xref="Ch2.E9.m1.2.2.1.1.1.1.2.3.cmml">]</mo></mrow></mrow><mo stretchy="false" id="Ch2.E9.m1.2.2.1.1.1.3" xref="Ch2.E9.m1.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E9.m1.2b"><apply id="Ch2.E9.m1.2.2.cmml" xref="Ch2.E9.m1.2.2"><eq id="Ch2.E9.m1.2.2.2.cmml" xref="Ch2.E9.m1.2.2.2"></eq><apply id="Ch2.E9.m1.2.2.3.cmml" xref="Ch2.E9.m1.2.2.3"><csymbol cd="ambiguous" id="Ch2.E9.m1.2.2.3.1.cmml" xref="Ch2.E9.m1.2.2.3">subscript</csymbol><apply id="Ch2.E9.m1.2.2.3.2.cmml" xref="Ch2.E9.m1.2.2.3.2"><ci id="Ch2.E9.m1.2.2.3.2.1.cmml" xref="Ch2.E9.m1.2.2.3.2.1">~</ci><ci id="Ch2.E9.m1.2.2.3.2.2.cmml" xref="Ch2.E9.m1.2.2.3.2.2">ℎ</ci></apply><ci id="Ch2.E9.m1.2.2.3.3.cmml" xref="Ch2.E9.m1.2.2.3.3">𝑡</ci></apply><apply id="Ch2.E9.m1.2.2.1.2.cmml" xref="Ch2.E9.m1.2.2.1.1"><tanh id="Ch2.E9.m1.1.1.cmml" xref="Ch2.E9.m1.1.1"></tanh><apply id="Ch2.E9.m1.2.2.1.1.1.1.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1"><times id="Ch2.E9.m1.2.2.1.1.1.1.3.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.3"></times><ci id="Ch2.E9.m1.2.2.1.1.1.1.4.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.4">𝑊</ci><interval closure="closed" id="Ch2.E9.m1.2.2.1.1.1.1.2.3.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2"><apply id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1"><times id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.1"></times><apply id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.2">𝑟</ci><ci id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.2">ℎ</ci><apply id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3"><minus id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.1"></minus><ci id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply><apply id="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.1.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.2.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.2">𝑥</ci><ci id="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.3.cmml" xref="Ch2.E9.m1.2.2.1.1.1.1.2.2.2.3">𝑡</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E9.m1.2c">\tilde{h}_{t}=\tanh(W*[r_{t}*h_{t-1},x_{t}])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.9)</span></td>
</tr></tbody>
</table>
<table id="Ch2.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch2.E10.m1.1" class="ltx_Math" alttext="h_{t}=(1-z_{t})*h_{t-1}+z_{t}*\widetilde{h}_{t}" display="block"><semantics id="Ch2.E10.m1.1a"><mrow id="Ch2.E10.m1.1.1" xref="Ch2.E10.m1.1.1.cmml"><msub id="Ch2.E10.m1.1.1.3" xref="Ch2.E10.m1.1.1.3.cmml"><mi id="Ch2.E10.m1.1.1.3.2" xref="Ch2.E10.m1.1.1.3.2.cmml">h</mi><mi id="Ch2.E10.m1.1.1.3.3" xref="Ch2.E10.m1.1.1.3.3.cmml">t</mi></msub><mo id="Ch2.E10.m1.1.1.2" xref="Ch2.E10.m1.1.1.2.cmml">=</mo><mrow id="Ch2.E10.m1.1.1.1" xref="Ch2.E10.m1.1.1.1.cmml"><mrow id="Ch2.E10.m1.1.1.1.1" xref="Ch2.E10.m1.1.1.1.1.cmml"><mrow id="Ch2.E10.m1.1.1.1.1.1.1" xref="Ch2.E10.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch2.E10.m1.1.1.1.1.1.1.2" xref="Ch2.E10.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch2.E10.m1.1.1.1.1.1.1.1" xref="Ch2.E10.m1.1.1.1.1.1.1.1.cmml"><mn id="Ch2.E10.m1.1.1.1.1.1.1.1.2" xref="Ch2.E10.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="Ch2.E10.m1.1.1.1.1.1.1.1.1" xref="Ch2.E10.m1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="Ch2.E10.m1.1.1.1.1.1.1.1.3" xref="Ch2.E10.m1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch2.E10.m1.1.1.1.1.1.1.1.3.2" xref="Ch2.E10.m1.1.1.1.1.1.1.1.3.2.cmml">z</mi><mi id="Ch2.E10.m1.1.1.1.1.1.1.1.3.3" xref="Ch2.E10.m1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="Ch2.E10.m1.1.1.1.1.1.1.3" xref="Ch2.E10.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="Ch2.E10.m1.1.1.1.1.2" xref="Ch2.E10.m1.1.1.1.1.2.cmml">∗</mo><msub id="Ch2.E10.m1.1.1.1.1.3" xref="Ch2.E10.m1.1.1.1.1.3.cmml"><mi id="Ch2.E10.m1.1.1.1.1.3.2" xref="Ch2.E10.m1.1.1.1.1.3.2.cmml">h</mi><mrow id="Ch2.E10.m1.1.1.1.1.3.3" xref="Ch2.E10.m1.1.1.1.1.3.3.cmml"><mi id="Ch2.E10.m1.1.1.1.1.3.3.2" xref="Ch2.E10.m1.1.1.1.1.3.3.2.cmml">t</mi><mo id="Ch2.E10.m1.1.1.1.1.3.3.1" xref="Ch2.E10.m1.1.1.1.1.3.3.1.cmml">−</mo><mn id="Ch2.E10.m1.1.1.1.1.3.3.3" xref="Ch2.E10.m1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="Ch2.E10.m1.1.1.1.2" xref="Ch2.E10.m1.1.1.1.2.cmml">+</mo><mrow id="Ch2.E10.m1.1.1.1.3" xref="Ch2.E10.m1.1.1.1.3.cmml"><msub id="Ch2.E10.m1.1.1.1.3.2" xref="Ch2.E10.m1.1.1.1.3.2.cmml"><mi id="Ch2.E10.m1.1.1.1.3.2.2" xref="Ch2.E10.m1.1.1.1.3.2.2.cmml">z</mi><mi id="Ch2.E10.m1.1.1.1.3.2.3" xref="Ch2.E10.m1.1.1.1.3.2.3.cmml">t</mi></msub><mo lspace="0.222em" rspace="0.222em" id="Ch2.E10.m1.1.1.1.3.1" xref="Ch2.E10.m1.1.1.1.3.1.cmml">∗</mo><msub id="Ch2.E10.m1.1.1.1.3.3" xref="Ch2.E10.m1.1.1.1.3.3.cmml"><mover accent="true" id="Ch2.E10.m1.1.1.1.3.3.2" xref="Ch2.E10.m1.1.1.1.3.3.2.cmml"><mi id="Ch2.E10.m1.1.1.1.3.3.2.2" xref="Ch2.E10.m1.1.1.1.3.3.2.2.cmml">h</mi><mo id="Ch2.E10.m1.1.1.1.3.3.2.1" xref="Ch2.E10.m1.1.1.1.3.3.2.1.cmml">~</mo></mover><mi id="Ch2.E10.m1.1.1.1.3.3.3" xref="Ch2.E10.m1.1.1.1.3.3.3.cmml">t</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch2.E10.m1.1b"><apply id="Ch2.E10.m1.1.1.cmml" xref="Ch2.E10.m1.1.1"><eq id="Ch2.E10.m1.1.1.2.cmml" xref="Ch2.E10.m1.1.1.2"></eq><apply id="Ch2.E10.m1.1.1.3.cmml" xref="Ch2.E10.m1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E10.m1.1.1.3.1.cmml" xref="Ch2.E10.m1.1.1.3">subscript</csymbol><ci id="Ch2.E10.m1.1.1.3.2.cmml" xref="Ch2.E10.m1.1.1.3.2">ℎ</ci><ci id="Ch2.E10.m1.1.1.3.3.cmml" xref="Ch2.E10.m1.1.1.3.3">𝑡</ci></apply><apply id="Ch2.E10.m1.1.1.1.cmml" xref="Ch2.E10.m1.1.1.1"><plus id="Ch2.E10.m1.1.1.1.2.cmml" xref="Ch2.E10.m1.1.1.1.2"></plus><apply id="Ch2.E10.m1.1.1.1.1.cmml" xref="Ch2.E10.m1.1.1.1.1"><times id="Ch2.E10.m1.1.1.1.1.2.cmml" xref="Ch2.E10.m1.1.1.1.1.2"></times><apply id="Ch2.E10.m1.1.1.1.1.1.1.1.cmml" xref="Ch2.E10.m1.1.1.1.1.1.1"><minus id="Ch2.E10.m1.1.1.1.1.1.1.1.1.cmml" xref="Ch2.E10.m1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="Ch2.E10.m1.1.1.1.1.1.1.1.2.cmml" xref="Ch2.E10.m1.1.1.1.1.1.1.1.2">1</cn><apply id="Ch2.E10.m1.1.1.1.1.1.1.1.3.cmml" xref="Ch2.E10.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E10.m1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch2.E10.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch2.E10.m1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch2.E10.m1.1.1.1.1.1.1.1.3.2">𝑧</ci><ci id="Ch2.E10.m1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch2.E10.m1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply><apply id="Ch2.E10.m1.1.1.1.1.3.cmml" xref="Ch2.E10.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch2.E10.m1.1.1.1.1.3.1.cmml" xref="Ch2.E10.m1.1.1.1.1.3">subscript</csymbol><ci id="Ch2.E10.m1.1.1.1.1.3.2.cmml" xref="Ch2.E10.m1.1.1.1.1.3.2">ℎ</ci><apply id="Ch2.E10.m1.1.1.1.1.3.3.cmml" xref="Ch2.E10.m1.1.1.1.1.3.3"><minus id="Ch2.E10.m1.1.1.1.1.3.3.1.cmml" xref="Ch2.E10.m1.1.1.1.1.3.3.1"></minus><ci id="Ch2.E10.m1.1.1.1.1.3.3.2.cmml" xref="Ch2.E10.m1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="Ch2.E10.m1.1.1.1.1.3.3.3.cmml" xref="Ch2.E10.m1.1.1.1.1.3.3.3">1</cn></apply></apply></apply><apply id="Ch2.E10.m1.1.1.1.3.cmml" xref="Ch2.E10.m1.1.1.1.3"><times id="Ch2.E10.m1.1.1.1.3.1.cmml" xref="Ch2.E10.m1.1.1.1.3.1"></times><apply id="Ch2.E10.m1.1.1.1.3.2.cmml" xref="Ch2.E10.m1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch2.E10.m1.1.1.1.3.2.1.cmml" xref="Ch2.E10.m1.1.1.1.3.2">subscript</csymbol><ci id="Ch2.E10.m1.1.1.1.3.2.2.cmml" xref="Ch2.E10.m1.1.1.1.3.2.2">𝑧</ci><ci id="Ch2.E10.m1.1.1.1.3.2.3.cmml" xref="Ch2.E10.m1.1.1.1.3.2.3">𝑡</ci></apply><apply id="Ch2.E10.m1.1.1.1.3.3.cmml" xref="Ch2.E10.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="Ch2.E10.m1.1.1.1.3.3.1.cmml" xref="Ch2.E10.m1.1.1.1.3.3">subscript</csymbol><apply id="Ch2.E10.m1.1.1.1.3.3.2.cmml" xref="Ch2.E10.m1.1.1.1.3.3.2"><ci id="Ch2.E10.m1.1.1.1.3.3.2.1.cmml" xref="Ch2.E10.m1.1.1.1.3.3.2.1">~</ci><ci id="Ch2.E10.m1.1.1.1.3.3.2.2.cmml" xref="Ch2.E10.m1.1.1.1.3.3.2.2">ℎ</ci></apply><ci id="Ch2.E10.m1.1.1.1.3.3.3.cmml" xref="Ch2.E10.m1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.E10.m1.1c">h_{t}=(1-z_{t})*h_{t-1}+z_{t}*\widetilde{h}_{t}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2.10)</span></td>
</tr></tbody>
</table>
<p id="Ch2.S2.SS3.p2.8" class="ltx_p">where <math id="Ch2.S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="Ch2.S2.SS3.p2.1.m1.1a"><msub id="Ch2.S2.SS3.p2.1.m1.1.1" xref="Ch2.S2.SS3.p2.1.m1.1.1.cmml"><mi id="Ch2.S2.SS3.p2.1.m1.1.1.2" xref="Ch2.S2.SS3.p2.1.m1.1.1.2.cmml">x</mi><mi id="Ch2.S2.SS3.p2.1.m1.1.1.3" xref="Ch2.S2.SS3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.1.m1.1b"><apply id="Ch2.S2.SS3.p2.1.m1.1.1.cmml" xref="Ch2.S2.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.1.m1.1.1.1.cmml" xref="Ch2.S2.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p2.1.m1.1.1.2.cmml" xref="Ch2.S2.SS3.p2.1.m1.1.1.2">𝑥</ci><ci id="Ch2.S2.SS3.p2.1.m1.1.1.3.cmml" xref="Ch2.S2.SS3.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.1.m1.1c">x_{t}</annotation></semantics></math> is the input in the GRU cell in current time step <math id="Ch2.S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="Ch2.S2.SS3.p2.2.m2.1a"><mi id="Ch2.S2.SS3.p2.2.m2.1.1" xref="Ch2.S2.SS3.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.2.m2.1b"><ci id="Ch2.S2.SS3.p2.2.m2.1.1.cmml" xref="Ch2.S2.SS3.p2.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.2.m2.1c">t</annotation></semantics></math>, <math id="Ch2.S2.SS3.p2.3.m3.1" class="ltx_Math" alttext="h_{t-1}" display="inline"><semantics id="Ch2.S2.SS3.p2.3.m3.1a"><msub id="Ch2.S2.SS3.p2.3.m3.1.1" xref="Ch2.S2.SS3.p2.3.m3.1.1.cmml"><mi id="Ch2.S2.SS3.p2.3.m3.1.1.2" xref="Ch2.S2.SS3.p2.3.m3.1.1.2.cmml">h</mi><mrow id="Ch2.S2.SS3.p2.3.m3.1.1.3" xref="Ch2.S2.SS3.p2.3.m3.1.1.3.cmml"><mi id="Ch2.S2.SS3.p2.3.m3.1.1.3.2" xref="Ch2.S2.SS3.p2.3.m3.1.1.3.2.cmml">t</mi><mo id="Ch2.S2.SS3.p2.3.m3.1.1.3.1" xref="Ch2.S2.SS3.p2.3.m3.1.1.3.1.cmml">−</mo><mn id="Ch2.S2.SS3.p2.3.m3.1.1.3.3" xref="Ch2.S2.SS3.p2.3.m3.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.3.m3.1b"><apply id="Ch2.S2.SS3.p2.3.m3.1.1.cmml" xref="Ch2.S2.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.3.m3.1.1.1.cmml" xref="Ch2.S2.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p2.3.m3.1.1.2.cmml" xref="Ch2.S2.SS3.p2.3.m3.1.1.2">ℎ</ci><apply id="Ch2.S2.SS3.p2.3.m3.1.1.3.cmml" xref="Ch2.S2.SS3.p2.3.m3.1.1.3"><minus id="Ch2.S2.SS3.p2.3.m3.1.1.3.1.cmml" xref="Ch2.S2.SS3.p2.3.m3.1.1.3.1"></minus><ci id="Ch2.S2.SS3.p2.3.m3.1.1.3.2.cmml" xref="Ch2.S2.SS3.p2.3.m3.1.1.3.2">𝑡</ci><cn type="integer" id="Ch2.S2.SS3.p2.3.m3.1.1.3.3.cmml" xref="Ch2.S2.SS3.p2.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.3.m3.1c">h_{t-1}</annotation></semantics></math> is the hidden state of the GRU from the previous time step, <math id="Ch2.S2.SS3.p2.4.m4.1" class="ltx_Math" alttext="h_{t}" display="inline"><semantics id="Ch2.S2.SS3.p2.4.m4.1a"><msub id="Ch2.S2.SS3.p2.4.m4.1.1" xref="Ch2.S2.SS3.p2.4.m4.1.1.cmml"><mi id="Ch2.S2.SS3.p2.4.m4.1.1.2" xref="Ch2.S2.SS3.p2.4.m4.1.1.2.cmml">h</mi><mi id="Ch2.S2.SS3.p2.4.m4.1.1.3" xref="Ch2.S2.SS3.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.4.m4.1b"><apply id="Ch2.S2.SS3.p2.4.m4.1.1.cmml" xref="Ch2.S2.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.4.m4.1.1.1.cmml" xref="Ch2.S2.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p2.4.m4.1.1.2.cmml" xref="Ch2.S2.SS3.p2.4.m4.1.1.2">ℎ</ci><ci id="Ch2.S2.SS3.p2.4.m4.1.1.3.cmml" xref="Ch2.S2.SS3.p2.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.4.m4.1c">h_{t}</annotation></semantics></math> is the hidden state of the GRU in the current time step, <math id="Ch2.S2.SS3.p2.5.m5.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="Ch2.S2.SS3.p2.5.m5.1a"><msub id="Ch2.S2.SS3.p2.5.m5.1.1" xref="Ch2.S2.SS3.p2.5.m5.1.1.cmml"><mi id="Ch2.S2.SS3.p2.5.m5.1.1.2" xref="Ch2.S2.SS3.p2.5.m5.1.1.2.cmml">z</mi><mi id="Ch2.S2.SS3.p2.5.m5.1.1.3" xref="Ch2.S2.SS3.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.5.m5.1b"><apply id="Ch2.S2.SS3.p2.5.m5.1.1.cmml" xref="Ch2.S2.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.5.m5.1.1.1.cmml" xref="Ch2.S2.SS3.p2.5.m5.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p2.5.m5.1.1.2.cmml" xref="Ch2.S2.SS3.p2.5.m5.1.1.2">𝑧</ci><ci id="Ch2.S2.SS3.p2.5.m5.1.1.3.cmml" xref="Ch2.S2.SS3.p2.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.5.m5.1c">z_{t}</annotation></semantics></math> and <math id="Ch2.S2.SS3.p2.6.m6.1" class="ltx_Math" alttext="r_{t}" display="inline"><semantics id="Ch2.S2.SS3.p2.6.m6.1a"><msub id="Ch2.S2.SS3.p2.6.m6.1.1" xref="Ch2.S2.SS3.p2.6.m6.1.1.cmml"><mi id="Ch2.S2.SS3.p2.6.m6.1.1.2" xref="Ch2.S2.SS3.p2.6.m6.1.1.2.cmml">r</mi><mi id="Ch2.S2.SS3.p2.6.m6.1.1.3" xref="Ch2.S2.SS3.p2.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.6.m6.1b"><apply id="Ch2.S2.SS3.p2.6.m6.1.1.cmml" xref="Ch2.S2.SS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.6.m6.1.1.1.cmml" xref="Ch2.S2.SS3.p2.6.m6.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p2.6.m6.1.1.2.cmml" xref="Ch2.S2.SS3.p2.6.m6.1.1.2">𝑟</ci><ci id="Ch2.S2.SS3.p2.6.m6.1.1.3.cmml" xref="Ch2.S2.SS3.p2.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.6.m6.1c">r_{t}</annotation></semantics></math> are regulating gates and <math id="Ch2.S2.SS3.p2.7.m7.1" class="ltx_Math" alttext="\tilde{h}_{t}" display="inline"><semantics id="Ch2.S2.SS3.p2.7.m7.1a"><msub id="Ch2.S2.SS3.p2.7.m7.1.1" xref="Ch2.S2.SS3.p2.7.m7.1.1.cmml"><mover accent="true" id="Ch2.S2.SS3.p2.7.m7.1.1.2" xref="Ch2.S2.SS3.p2.7.m7.1.1.2.cmml"><mi id="Ch2.S2.SS3.p2.7.m7.1.1.2.2" xref="Ch2.S2.SS3.p2.7.m7.1.1.2.2.cmml">h</mi><mo id="Ch2.S2.SS3.p2.7.m7.1.1.2.1" xref="Ch2.S2.SS3.p2.7.m7.1.1.2.1.cmml">~</mo></mover><mi id="Ch2.S2.SS3.p2.7.m7.1.1.3" xref="Ch2.S2.SS3.p2.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.7.m7.1b"><apply id="Ch2.S2.SS3.p2.7.m7.1.1.cmml" xref="Ch2.S2.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.7.m7.1.1.1.cmml" xref="Ch2.S2.SS3.p2.7.m7.1.1">subscript</csymbol><apply id="Ch2.S2.SS3.p2.7.m7.1.1.2.cmml" xref="Ch2.S2.SS3.p2.7.m7.1.1.2"><ci id="Ch2.S2.SS3.p2.7.m7.1.1.2.1.cmml" xref="Ch2.S2.SS3.p2.7.m7.1.1.2.1">~</ci><ci id="Ch2.S2.SS3.p2.7.m7.1.1.2.2.cmml" xref="Ch2.S2.SS3.p2.7.m7.1.1.2.2">ℎ</ci></apply><ci id="Ch2.S2.SS3.p2.7.m7.1.1.3.cmml" xref="Ch2.S2.SS3.p2.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.7.m7.1c">\tilde{h}_{t}</annotation></semantics></math> is the intermediate cell state of the GRU in the current time step. <math id="Ch2.S2.SS3.p2.8.m8.3" class="ltx_Math" alttext="W_{z},W_{r},W" display="inline"><semantics id="Ch2.S2.SS3.p2.8.m8.3a"><mrow id="Ch2.S2.SS3.p2.8.m8.3.3.2" xref="Ch2.S2.SS3.p2.8.m8.3.3.3.cmml"><msub id="Ch2.S2.SS3.p2.8.m8.2.2.1.1" xref="Ch2.S2.SS3.p2.8.m8.2.2.1.1.cmml"><mi id="Ch2.S2.SS3.p2.8.m8.2.2.1.1.2" xref="Ch2.S2.SS3.p2.8.m8.2.2.1.1.2.cmml">W</mi><mi id="Ch2.S2.SS3.p2.8.m8.2.2.1.1.3" xref="Ch2.S2.SS3.p2.8.m8.2.2.1.1.3.cmml">z</mi></msub><mo id="Ch2.S2.SS3.p2.8.m8.3.3.2.3" xref="Ch2.S2.SS3.p2.8.m8.3.3.3.cmml">,</mo><msub id="Ch2.S2.SS3.p2.8.m8.3.3.2.2" xref="Ch2.S2.SS3.p2.8.m8.3.3.2.2.cmml"><mi id="Ch2.S2.SS3.p2.8.m8.3.3.2.2.2" xref="Ch2.S2.SS3.p2.8.m8.3.3.2.2.2.cmml">W</mi><mi id="Ch2.S2.SS3.p2.8.m8.3.3.2.2.3" xref="Ch2.S2.SS3.p2.8.m8.3.3.2.2.3.cmml">r</mi></msub><mo id="Ch2.S2.SS3.p2.8.m8.3.3.2.4" xref="Ch2.S2.SS3.p2.8.m8.3.3.3.cmml">,</mo><mi id="Ch2.S2.SS3.p2.8.m8.1.1" xref="Ch2.S2.SS3.p2.8.m8.1.1.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch2.S2.SS3.p2.8.m8.3b"><list id="Ch2.S2.SS3.p2.8.m8.3.3.3.cmml" xref="Ch2.S2.SS3.p2.8.m8.3.3.2"><apply id="Ch2.S2.SS3.p2.8.m8.2.2.1.1.cmml" xref="Ch2.S2.SS3.p2.8.m8.2.2.1.1"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.8.m8.2.2.1.1.1.cmml" xref="Ch2.S2.SS3.p2.8.m8.2.2.1.1">subscript</csymbol><ci id="Ch2.S2.SS3.p2.8.m8.2.2.1.1.2.cmml" xref="Ch2.S2.SS3.p2.8.m8.2.2.1.1.2">𝑊</ci><ci id="Ch2.S2.SS3.p2.8.m8.2.2.1.1.3.cmml" xref="Ch2.S2.SS3.p2.8.m8.2.2.1.1.3">𝑧</ci></apply><apply id="Ch2.S2.SS3.p2.8.m8.3.3.2.2.cmml" xref="Ch2.S2.SS3.p2.8.m8.3.3.2.2"><csymbol cd="ambiguous" id="Ch2.S2.SS3.p2.8.m8.3.3.2.2.1.cmml" xref="Ch2.S2.SS3.p2.8.m8.3.3.2.2">subscript</csymbol><ci id="Ch2.S2.SS3.p2.8.m8.3.3.2.2.2.cmml" xref="Ch2.S2.SS3.p2.8.m8.3.3.2.2.2">𝑊</ci><ci id="Ch2.S2.SS3.p2.8.m8.3.3.2.2.3.cmml" xref="Ch2.S2.SS3.p2.8.m8.3.3.2.2.3">𝑟</ci></apply><ci id="Ch2.S2.SS3.p2.8.m8.1.1.cmml" xref="Ch2.S2.SS3.p2.8.m8.1.1">𝑊</ci></list></annotation-xml><annotation encoding="application/x-tex" id="Ch2.S2.SS3.p2.8.m8.3c">W_{z},W_{r},W</annotation></semantics></math> are weight matrices and they are the learnable parameters of the GRU. For better visualisation of the gates and their interactions, the GRU cell is shown in Figure <a href="#Ch2.F2" title="Figure 2.2 ‣ 2.2.3 Recurrent Neural Networks ‣ 2.2 Deep Learning ‣ Chapter 2 Background and related work ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.</p>
</div>
<figure id="Ch2.F2" class="ltx_figure"><img src="/html/2007.05881/assets/x2.png" id="Ch2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="219" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2.2: </span>A diagram of the GRU model and the interactions between the gates and the hidden state. The blue squares represent a Fully Connected Neural Network, with the activation assigned in the blue square. The purple circles are point-wise operations and the type of operation is noted inside the circle. The diagram was inspired by the diagrams in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</figcaption>
</figure>
</section>
<section id="Ch2.S2.SS4" class="ltx_subsection">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2.4 </span>Convolutional Neural Networks</h4>

<div id="Ch2.S2.SS4.p1" class="ltx_para">
<p id="Ch2.S2.SS4.p1.1" class="ltx_p">Deep learning has also been very successful in various vision task such as image recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and image segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. This success can mostly be attributed to the usage of deep convolutional neural networks. Convolutional neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> are neural networks that use the function convolution instead of general matrix multiplication in at least one of their layers. Convolution is a linear operation that can be explained as a sliding window function applied to parts of a matrix. The reason for their modelling power is the combination of architectural ideas such as local receptive fields, shared weights and spatial (or temporal) subsampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. For multi-modal tasks like Image Captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> and Visual Question Answering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, researchers usually use a pre-trained deep convolutional neural network (like VGG-19 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> or ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>), that has been trained for a task like image recognition, to obtain a vector representation of the features of every image. These vector representations are obtained by taking the output of the layers that are aligned before the 1000 dimensional classification layer. They serve as image embeddings, which means that an image of dogs would be closer to an image of a group of people, then an image of a single cat, because the image embeddings contain information about the visual context of the image which is very useful in multi-modal tasks, such as our record linkage problem. The benefit of this procedure is also computational efficiency because the image embeddings are only pre-computed and stored once, therefore making the training process of the neural network faster.</p>
</div>
</section>
</section>
<section id="Ch2.S3" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.3 </span>The link between Visual Question Answering and Record Linkage</h3>

<div id="Ch2.S3.p1" class="ltx_para">
<p id="Ch2.S3.p1.1" class="ltx_p">All of the previously mentioned research in Record Linkage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> has been done on textual data. The rise of digital media has provided additional information for the description of entities (such as products, advertisements etc.), which means that the above-mentioned methods have to be adjusted to take into consideration the data coming from the corresponding images. Therefore this makes record linkage a multi-modal problem since the system should combine the information that is available from the image and description of the entity and produce a joint embedding for each record. The lack of research in multi-modal record linkage forced us to explore the fields of Image Captioning and Visual Question Answering because their research is focused on modelling both textual and visual data. Our problem relates better to Visual Question Answering, where the joint representation of the question and the image is used to produce an answer, whereas in Image Captioning there is an inline representation of the caption and the image since the produced caption is conditioned on the image representation.</p>
</div>
<section id="Ch2.S3.SS1" class="ltx_subsection">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3.1 </span>Visual Question Answering</h4>

<div id="Ch2.S3.SS1.p1" class="ltx_para">
<p id="Ch2.S3.SS1.p1.1" class="ltx_p">Visual question answering (VQA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> is a task where a model needs to learn how to produce a correct answer from a given image and a question about that image. It is a unique challenge as it requires the ability to encode multi-modal input, while also being able to extract knowledge beyond a single sub-domain. For the VQA task, the algorithm needs to decide what is the relevant information, fetch that information from the image and the question, and use that to answer the questions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.</p>
</div>
<div id="Ch2.S3.SS1.p2" class="ltx_para">
<p id="Ch2.S3.SS1.p2.1" class="ltx_p">The simplest architecture for VQA consists of a pre-trained convolutional neural network for image feature extraction and an LSTM for modelling the question <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The output of the two networks is then concatenated and it is fed to a classifier that outputs the answer. The LSTM, due to its ability to capture dependencies between elements in a sequence has enjoyed a lot of success in the modelling language. Sentences are an ordered sequence of words, hence the LSTM is able to learn something about the underlying structure of the sentence and the dependencies between the words <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. Likewise, convolutional neural networks have proved to be extremely accurate in object detection and pre-trained CNN have been used in multi-modal models to increase the accuracy and decrease training time of the models. Other variations of this model use bidirectional LSTMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, stacked LSTMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and a convolutional neural network to model the question<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.</p>
</div>
</section>
<section id="Ch2.S3.SS2" class="ltx_subsection">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3.2 </span>The Attention Mechanism</h4>

<div id="Ch2.S3.SS2.p1" class="ltx_para">
<p id="Ch2.S3.SS2.p1.1" class="ltx_p">To improve the standard VQA pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> proposed a solution that implements an attention mechanism, whose goal is to find a better correlation between the encoding of question and the visual features. Attention mechanisms were introduced and successfully used in machine translation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> as a solution to the bottleneck that was the fixed-length vector produced by the recurrent neural network that was encoding the source sentence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. The attention mechanism allows the model to automatically (soft-)search for parts in the source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The attention mechanism in machine translation produces a probability distribution over the parts of the source sentence so that the machine translation system can focus on the most probable parts of the source sentence when it is trying to produce a correct translation. Attention has been also used in image captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and there the attention layer provides a probability distribution over all the pixels of the image. The result is a higher probability on the pixels of the image that are relevant to the task. In the case of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> the attention layer creates a query from the question encoding and uses it to obtain a probability distribution over regions of the images. They find that one attention layer is not enough, therefore their proposed solution is to use two stacked attention layers in which the second attention layer uses the output of the first attention layer as the new query which is used to produce the probability distribution over the regions of the image.</p>
</div>
</section>
</section>
<section id="Ch2.S4" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.4 </span>Siamese Neural Networks</h3>

<div id="Ch2.S4.p1" class="ltx_para">
<p id="Ch2.S4.p1.1" class="ltx_p">As mentioned in section 2.1, another problem in record linkage is the choice of metrics that will be used to compute the similarity between the vector representations of the two records. Since the similarity metric is a function with two inputs and one output it is possible to approximate this function using a deep learning architecture known as Siamese neural network. Siamese neural networks were first introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> to solve signature verification as an image matching problem. The Siamese network consists of two branches of networks that share the same architecture and the same set of weights. The output of the two branches is joined by an energy function at the top (which can be a similarity function like cosine distance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> or a neural network<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>). Siamese networks have found usage in signature matching <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and recently have been used in one-shot learning for the task of image classification<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. For the architecture of the two branches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> propose multiple stacked fully connected neural network layers, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> propose two convolutional layers, whereas <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> propose a deep fully convolutional neural network. For the energy function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> propose a fully connected network that will output a single number as the similarity between the two distinct inputs. Using the Siamese neural network as part of our model, allows us to create a large neural network where we can use the ideas from Visual Question Answering to create a vector representation of an image and a description and then use the Siamese neural network to compute the similarity between a pair of multi-modal records.</p>
</div>
</section>
</section>
<section id="Ch3" class="ltx_chapter">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 3 </span>Methodology</h2>

<div id="Ch3.p1" class="ltx_para">
<p id="Ch3.p1.1" class="ltx_p">Based on previous research we propose a framework that is consisted of two separate units that fuse the visual and textual information of each record and a Siamese neural network that uses the output of the two fusing units to compute the similarity between the two items. We also describe two different architectures for multi-modal fusion that are inspired by Visual Question Answering models.</p>
</div>
<section id="Ch3.S1" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.1 </span>Data set and Preprocessing</h3>

<div id="Ch3.S1.p1" class="ltx_para">
<p id="Ch3.S1.p1.1" class="ltx_p">In this section, we describe the dataset we used to train and evaluate the models we propose in this chapter. In the previous chapter, we noted that record linkage is also referred to as database deduplication, therefore for our models, we used the Avito duplicate advertisement detection dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, that is publicly available on Kaggle. The dataset was collected from a Russian online store. The dataset consists of multiple databases that can be linked by the identification number of the advertisement and all the images that are associated with the advertisements. We use two data tables from the whole dataset. One table is a database that consists of pairs of identification numbers and a matching field that tells us whether the two items are similar (1) or dissimilar (0). The second table is a database that contains multiple fields for each advertisement. For our problem, we only used the ”Description” and ”Images” columns. The ”Description” column contained the text that explained the advertisement and the ”Images” column contained a list of image ID numbers that were associated with the particular advertisement.</p>
</div>
<div id="Ch3.S1.p2" class="ltx_para">
<p id="Ch3.S1.p2.1" class="ltx_p">The preprocessing process was done in stages and we followed the techniques described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. First, we preprocessed the database that consists the information about the advertisements, then we calibrated the changes made from that database with the pairs database. The descriptions were in Russian, so the preprocessing of the text consisted of: lowercasing every character, substituting every number with 0 (because we wanted to keep information about numerical occurrences but not the original number), removing all characters that weren’t in the Latin or Cyrillic alphabet, removing all double spaces and new line characters and transliterating every non-Russian word into its Cyrillic counter part <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. Russian is a morphologically rich language, therefore we used lemmatization to get the original form of each word (removing any suffixes or prefixes). We believe that lemmatization is better than stemming because it uses morphology and grammar to find the proper form of the word (for saw it will return see), whereas stemming is using heuristics to find the root of the word. It is not always useful, because for the words ’see’ and ’saw’, stemming will return ’s’. The next step was to tokenizing the descriptions. We sorted the words by their frequency and decided to create a vocabulary of the 30,000 most frequent words as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. We assigned an integer to all the words in the vocabulary and substituted each word in the descriptions with their corresponding vocabulary index. The words that were not in the vocabulary were substituted with an ”Unknown word” token. We also added a ”Start of sentence” and ”End of sentence” tokens to each of the descriptions. One standard practice in deep learning is to make the samples in a batch to have the same dimensions (in this way GPUs can be used more efficiently). By exploring our processed dataset we found that 90 % of the descriptions were shorter than 100 words. Therefore all the sentences longer than 100 words were reduced to their first 100 words, whereas all the sentences that were shorter than 100 words were padded with the ”Zero index” token, which is later handled within our models.</p>
</div>
<div id="Ch3.S1.p3" class="ltx_para">
<p id="Ch3.S1.p3.1" class="ltx_p">To make our model more robust, we decided to randomly choose one image from the sequence of images to represent each advertisement. Based on the practices from Visual Question Answering we wanted to precompute the feature vectors for all the images that we were going to use. To do that we needed to preprocess them. The images were resized with its shorter side randomly sampled in [256, 480] for scale augmentation, a [224, 224] crop is randomly sampled from each image or its horizontal flip, with the per-pixel mean subtracted and we used the standard colour augmentation described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="Ch3.S1.p4" class="ltx_para">
<p id="Ch3.S1.p4.1" class="ltx_p">We also deleted all advertisements that had corrupted images and descriptions of length 0 after the initial preprocessing. After this, we updated the pairs database by deleting all the pairs that had at least one item, not in the item database. In the end, our pairs dataset had 2,594,948 pairs of items with a class distribution: 67% dissimilar pairs (class 0) and 33% similar pairs (class 1). The dataset was split into a training, validation and test set with a split ratio of 80%, 10%, 10%. When doing the split the samples were chosen randomly and the original distribution was maintained across the three subsets.</p>
</div>
</section>
<section id="Ch3.S2" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.2 </span>Baseline Model</h3>

<div id="Ch3.S2.p1" class="ltx_para">
<p id="Ch3.S2.p1.1" class="ltx_p">The Avito duplicate ads detection data set has not been featured in any research and there is no evidence that it has been used for training any neural network-based models. Here we propose a baseline model that is based on the winning solution on the Kaggle competition that has uses this dataset. We compute two hand-crafted features: Jaccard similarity coefficient between the tokenized descriptions and Euclidian distance between the image feature vectors that represent the record pair. The Jaccard similarity coefficient compares tokens from the two descriptions to see which tokens (words) are shared and which are distinct. It’s a measure of similarity for the two descriptions, with a range from 0.0 to 1.0, where 0.0 is 0% similarity and 1.0 is 100% similarity. The Jaccard similarity coefficient formula is given below:</p>
<table id="Ch3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch3.E1.m1.4" class="ltx_Math" alttext="J(description_{1},description_{2})=\frac{|description_{1}\cap description_{2}|}{|description_{1}\cup description_{2}|}" display="block"><semantics id="Ch3.E1.m1.4a"><mrow id="Ch3.E1.m1.4.4" xref="Ch3.E1.m1.4.4.cmml"><mrow id="Ch3.E1.m1.4.4.2" xref="Ch3.E1.m1.4.4.2.cmml"><mi id="Ch3.E1.m1.4.4.2.4" xref="Ch3.E1.m1.4.4.2.4.cmml">J</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.3" xref="Ch3.E1.m1.4.4.2.3.cmml">​</mo><mrow id="Ch3.E1.m1.4.4.2.2.2" xref="Ch3.E1.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="Ch3.E1.m1.4.4.2.2.2.3" xref="Ch3.E1.m1.4.4.2.2.3.cmml">(</mo><mrow id="Ch3.E1.m1.3.3.1.1.1.1" xref="Ch3.E1.m1.3.3.1.1.1.1.cmml"><mi id="Ch3.E1.m1.3.3.1.1.1.1.2" xref="Ch3.E1.m1.3.3.1.1.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.3" xref="Ch3.E1.m1.3.3.1.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1a" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.4" xref="Ch3.E1.m1.3.3.1.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1b" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.5" xref="Ch3.E1.m1.3.3.1.1.1.1.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1c" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.6" xref="Ch3.E1.m1.3.3.1.1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1d" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.7" xref="Ch3.E1.m1.3.3.1.1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1e" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.8" xref="Ch3.E1.m1.3.3.1.1.1.1.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1f" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.9" xref="Ch3.E1.m1.3.3.1.1.1.1.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1g" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.10" xref="Ch3.E1.m1.3.3.1.1.1.1.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1h" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E1.m1.3.3.1.1.1.1.11" xref="Ch3.E1.m1.3.3.1.1.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.3.3.1.1.1.1.1i" xref="Ch3.E1.m1.3.3.1.1.1.1.1.cmml">​</mo><msub id="Ch3.E1.m1.3.3.1.1.1.1.12" xref="Ch3.E1.m1.3.3.1.1.1.1.12.cmml"><mi id="Ch3.E1.m1.3.3.1.1.1.1.12.2" xref="Ch3.E1.m1.3.3.1.1.1.1.12.2.cmml">n</mi><mn id="Ch3.E1.m1.3.3.1.1.1.1.12.3" xref="Ch3.E1.m1.3.3.1.1.1.1.12.3.cmml">1</mn></msub></mrow><mo id="Ch3.E1.m1.4.4.2.2.2.4" xref="Ch3.E1.m1.4.4.2.2.3.cmml">,</mo><mrow id="Ch3.E1.m1.4.4.2.2.2.2" xref="Ch3.E1.m1.4.4.2.2.2.2.cmml"><mi id="Ch3.E1.m1.4.4.2.2.2.2.2" xref="Ch3.E1.m1.4.4.2.2.2.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.3" xref="Ch3.E1.m1.4.4.2.2.2.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1a" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.4" xref="Ch3.E1.m1.4.4.2.2.2.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1b" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.5" xref="Ch3.E1.m1.4.4.2.2.2.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1c" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.6" xref="Ch3.E1.m1.4.4.2.2.2.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1d" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.7" xref="Ch3.E1.m1.4.4.2.2.2.2.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1e" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.8" xref="Ch3.E1.m1.4.4.2.2.2.2.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1f" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.9" xref="Ch3.E1.m1.4.4.2.2.2.2.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1g" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.10" xref="Ch3.E1.m1.4.4.2.2.2.2.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1h" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E1.m1.4.4.2.2.2.2.11" xref="Ch3.E1.m1.4.4.2.2.2.2.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.4.4.2.2.2.2.1i" xref="Ch3.E1.m1.4.4.2.2.2.2.1.cmml">​</mo><msub id="Ch3.E1.m1.4.4.2.2.2.2.12" xref="Ch3.E1.m1.4.4.2.2.2.2.12.cmml"><mi id="Ch3.E1.m1.4.4.2.2.2.2.12.2" xref="Ch3.E1.m1.4.4.2.2.2.2.12.2.cmml">n</mi><mn id="Ch3.E1.m1.4.4.2.2.2.2.12.3" xref="Ch3.E1.m1.4.4.2.2.2.2.12.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="Ch3.E1.m1.4.4.2.2.2.5" xref="Ch3.E1.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow><mo id="Ch3.E1.m1.4.4.3" xref="Ch3.E1.m1.4.4.3.cmml">=</mo><mfrac id="Ch3.E1.m1.2.2" xref="Ch3.E1.m1.2.2.cmml"><mrow id="Ch3.E1.m1.1.1.1.1" xref="Ch3.E1.m1.1.1.1.2.cmml"><mo stretchy="false" id="Ch3.E1.m1.1.1.1.1.2" xref="Ch3.E1.m1.1.1.1.2.1.cmml">|</mo><mrow id="Ch3.E1.m1.1.1.1.1.1" xref="Ch3.E1.m1.1.1.1.1.1.cmml"><mrow id="Ch3.E1.m1.1.1.1.1.1.2" xref="Ch3.E1.m1.1.1.1.1.1.2.cmml"><mi id="Ch3.E1.m1.1.1.1.1.1.2.2" xref="Ch3.E1.m1.1.1.1.1.1.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.3" xref="Ch3.E1.m1.1.1.1.1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1a" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.4" xref="Ch3.E1.m1.1.1.1.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1b" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.5" xref="Ch3.E1.m1.1.1.1.1.1.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1c" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.6" xref="Ch3.E1.m1.1.1.1.1.1.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1d" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.7" xref="Ch3.E1.m1.1.1.1.1.1.2.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1e" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.8" xref="Ch3.E1.m1.1.1.1.1.1.2.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1f" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.9" xref="Ch3.E1.m1.1.1.1.1.1.2.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1g" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.10" xref="Ch3.E1.m1.1.1.1.1.1.2.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1h" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.2.11" xref="Ch3.E1.m1.1.1.1.1.1.2.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.2.1i" xref="Ch3.E1.m1.1.1.1.1.1.2.1.cmml">​</mo><msub id="Ch3.E1.m1.1.1.1.1.1.2.12" xref="Ch3.E1.m1.1.1.1.1.1.2.12.cmml"><mi id="Ch3.E1.m1.1.1.1.1.1.2.12.2" xref="Ch3.E1.m1.1.1.1.1.1.2.12.2.cmml">n</mi><mn id="Ch3.E1.m1.1.1.1.1.1.2.12.3" xref="Ch3.E1.m1.1.1.1.1.1.2.12.3.cmml">1</mn></msub></mrow><mo id="Ch3.E1.m1.1.1.1.1.1.1" xref="Ch3.E1.m1.1.1.1.1.1.1.cmml">∩</mo><mrow id="Ch3.E1.m1.1.1.1.1.1.3" xref="Ch3.E1.m1.1.1.1.1.1.3.cmml"><mi id="Ch3.E1.m1.1.1.1.1.1.3.2" xref="Ch3.E1.m1.1.1.1.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.3" xref="Ch3.E1.m1.1.1.1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1a" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.4" xref="Ch3.E1.m1.1.1.1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1b" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.5" xref="Ch3.E1.m1.1.1.1.1.1.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1c" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.6" xref="Ch3.E1.m1.1.1.1.1.1.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1d" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.7" xref="Ch3.E1.m1.1.1.1.1.1.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1e" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.8" xref="Ch3.E1.m1.1.1.1.1.1.3.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1f" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.9" xref="Ch3.E1.m1.1.1.1.1.1.3.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1g" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.10" xref="Ch3.E1.m1.1.1.1.1.1.3.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1h" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.1.1.1.1.1.3.11" xref="Ch3.E1.m1.1.1.1.1.1.3.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.1.1.1.1.1.3.1i" xref="Ch3.E1.m1.1.1.1.1.1.3.1.cmml">​</mo><msub id="Ch3.E1.m1.1.1.1.1.1.3.12" xref="Ch3.E1.m1.1.1.1.1.1.3.12.cmml"><mi id="Ch3.E1.m1.1.1.1.1.1.3.12.2" xref="Ch3.E1.m1.1.1.1.1.1.3.12.2.cmml">n</mi><mn id="Ch3.E1.m1.1.1.1.1.1.3.12.3" xref="Ch3.E1.m1.1.1.1.1.1.3.12.3.cmml">2</mn></msub></mrow></mrow><mo stretchy="false" id="Ch3.E1.m1.1.1.1.1.3" xref="Ch3.E1.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="Ch3.E1.m1.2.2.2.1" xref="Ch3.E1.m1.2.2.2.2.cmml"><mo stretchy="false" id="Ch3.E1.m1.2.2.2.1.2" xref="Ch3.E1.m1.2.2.2.2.1.cmml">|</mo><mrow id="Ch3.E1.m1.2.2.2.1.1" xref="Ch3.E1.m1.2.2.2.1.1.cmml"><mrow id="Ch3.E1.m1.2.2.2.1.1.2" xref="Ch3.E1.m1.2.2.2.1.1.2.cmml"><mi id="Ch3.E1.m1.2.2.2.1.1.2.2" xref="Ch3.E1.m1.2.2.2.1.1.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.3" xref="Ch3.E1.m1.2.2.2.1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1a" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.4" xref="Ch3.E1.m1.2.2.2.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1b" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.5" xref="Ch3.E1.m1.2.2.2.1.1.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1c" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.6" xref="Ch3.E1.m1.2.2.2.1.1.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1d" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.7" xref="Ch3.E1.m1.2.2.2.1.1.2.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1e" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.8" xref="Ch3.E1.m1.2.2.2.1.1.2.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1f" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.9" xref="Ch3.E1.m1.2.2.2.1.1.2.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1g" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.10" xref="Ch3.E1.m1.2.2.2.1.1.2.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1h" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.2.11" xref="Ch3.E1.m1.2.2.2.1.1.2.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.2.1i" xref="Ch3.E1.m1.2.2.2.1.1.2.1.cmml">​</mo><msub id="Ch3.E1.m1.2.2.2.1.1.2.12" xref="Ch3.E1.m1.2.2.2.1.1.2.12.cmml"><mi id="Ch3.E1.m1.2.2.2.1.1.2.12.2" xref="Ch3.E1.m1.2.2.2.1.1.2.12.2.cmml">n</mi><mn id="Ch3.E1.m1.2.2.2.1.1.2.12.3" xref="Ch3.E1.m1.2.2.2.1.1.2.12.3.cmml">1</mn></msub></mrow><mo id="Ch3.E1.m1.2.2.2.1.1.1" xref="Ch3.E1.m1.2.2.2.1.1.1.cmml">∪</mo><mrow id="Ch3.E1.m1.2.2.2.1.1.3" xref="Ch3.E1.m1.2.2.2.1.1.3.cmml"><mi id="Ch3.E1.m1.2.2.2.1.1.3.2" xref="Ch3.E1.m1.2.2.2.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.3" xref="Ch3.E1.m1.2.2.2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1a" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.4" xref="Ch3.E1.m1.2.2.2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1b" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.5" xref="Ch3.E1.m1.2.2.2.1.1.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1c" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.6" xref="Ch3.E1.m1.2.2.2.1.1.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1d" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.7" xref="Ch3.E1.m1.2.2.2.1.1.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1e" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.8" xref="Ch3.E1.m1.2.2.2.1.1.3.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1f" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.9" xref="Ch3.E1.m1.2.2.2.1.1.3.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1g" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.10" xref="Ch3.E1.m1.2.2.2.1.1.3.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1h" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><mi id="Ch3.E1.m1.2.2.2.1.1.3.11" xref="Ch3.E1.m1.2.2.2.1.1.3.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="Ch3.E1.m1.2.2.2.1.1.3.1i" xref="Ch3.E1.m1.2.2.2.1.1.3.1.cmml">​</mo><msub id="Ch3.E1.m1.2.2.2.1.1.3.12" xref="Ch3.E1.m1.2.2.2.1.1.3.12.cmml"><mi id="Ch3.E1.m1.2.2.2.1.1.3.12.2" xref="Ch3.E1.m1.2.2.2.1.1.3.12.2.cmml">n</mi><mn id="Ch3.E1.m1.2.2.2.1.1.3.12.3" xref="Ch3.E1.m1.2.2.2.1.1.3.12.3.cmml">2</mn></msub></mrow></mrow><mo stretchy="false" id="Ch3.E1.m1.2.2.2.1.3" xref="Ch3.E1.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="Ch3.E1.m1.4b"><apply id="Ch3.E1.m1.4.4.cmml" xref="Ch3.E1.m1.4.4"><eq id="Ch3.E1.m1.4.4.3.cmml" xref="Ch3.E1.m1.4.4.3"></eq><apply id="Ch3.E1.m1.4.4.2.cmml" xref="Ch3.E1.m1.4.4.2"><times id="Ch3.E1.m1.4.4.2.3.cmml" xref="Ch3.E1.m1.4.4.2.3"></times><ci id="Ch3.E1.m1.4.4.2.4.cmml" xref="Ch3.E1.m1.4.4.2.4">𝐽</ci><interval closure="open" id="Ch3.E1.m1.4.4.2.2.3.cmml" xref="Ch3.E1.m1.4.4.2.2.2"><apply id="Ch3.E1.m1.3.3.1.1.1.1.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1"><times id="Ch3.E1.m1.3.3.1.1.1.1.1.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.1"></times><ci id="Ch3.E1.m1.3.3.1.1.1.1.2.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.2">𝑑</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.3.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.3">𝑒</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.4.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.4">𝑠</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.5.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.5">𝑐</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.6.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.6">𝑟</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.7.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.7">𝑖</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.8.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.8">𝑝</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.9.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.9">𝑡</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.10.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.10">𝑖</ci><ci id="Ch3.E1.m1.3.3.1.1.1.1.11.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.11">𝑜</ci><apply id="Ch3.E1.m1.3.3.1.1.1.1.12.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.12"><csymbol cd="ambiguous" id="Ch3.E1.m1.3.3.1.1.1.1.12.1.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.12">subscript</csymbol><ci id="Ch3.E1.m1.3.3.1.1.1.1.12.2.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.12.2">𝑛</ci><cn type="integer" id="Ch3.E1.m1.3.3.1.1.1.1.12.3.cmml" xref="Ch3.E1.m1.3.3.1.1.1.1.12.3">1</cn></apply></apply><apply id="Ch3.E1.m1.4.4.2.2.2.2.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2"><times id="Ch3.E1.m1.4.4.2.2.2.2.1.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.1"></times><ci id="Ch3.E1.m1.4.4.2.2.2.2.2.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.2">𝑑</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.3.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.3">𝑒</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.4.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.4">𝑠</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.5.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.5">𝑐</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.6.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.6">𝑟</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.7.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.7">𝑖</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.8.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.8">𝑝</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.9.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.9">𝑡</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.10.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.10">𝑖</ci><ci id="Ch3.E1.m1.4.4.2.2.2.2.11.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.11">𝑜</ci><apply id="Ch3.E1.m1.4.4.2.2.2.2.12.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.12"><csymbol cd="ambiguous" id="Ch3.E1.m1.4.4.2.2.2.2.12.1.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.12">subscript</csymbol><ci id="Ch3.E1.m1.4.4.2.2.2.2.12.2.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.12.2">𝑛</ci><cn type="integer" id="Ch3.E1.m1.4.4.2.2.2.2.12.3.cmml" xref="Ch3.E1.m1.4.4.2.2.2.2.12.3">2</cn></apply></apply></interval></apply><apply id="Ch3.E1.m1.2.2.cmml" xref="Ch3.E1.m1.2.2"><divide id="Ch3.E1.m1.2.2.3.cmml" xref="Ch3.E1.m1.2.2"></divide><apply id="Ch3.E1.m1.1.1.1.2.cmml" xref="Ch3.E1.m1.1.1.1.1"><abs id="Ch3.E1.m1.1.1.1.2.1.cmml" xref="Ch3.E1.m1.1.1.1.1.2"></abs><apply id="Ch3.E1.m1.1.1.1.1.1.cmml" xref="Ch3.E1.m1.1.1.1.1.1"><intersect id="Ch3.E1.m1.1.1.1.1.1.1.cmml" xref="Ch3.E1.m1.1.1.1.1.1.1"></intersect><apply id="Ch3.E1.m1.1.1.1.1.1.2.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2"><times id="Ch3.E1.m1.1.1.1.1.1.2.1.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.1"></times><ci id="Ch3.E1.m1.1.1.1.1.1.2.2.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.2">𝑑</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.3.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.3">𝑒</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.4.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.4">𝑠</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.5.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.5">𝑐</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.6.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.6">𝑟</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.7.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.7">𝑖</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.8.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.8">𝑝</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.9.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.9">𝑡</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.10.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.10">𝑖</ci><ci id="Ch3.E1.m1.1.1.1.1.1.2.11.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.11">𝑜</ci><apply id="Ch3.E1.m1.1.1.1.1.1.2.12.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.12"><csymbol cd="ambiguous" id="Ch3.E1.m1.1.1.1.1.1.2.12.1.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.12">subscript</csymbol><ci id="Ch3.E1.m1.1.1.1.1.1.2.12.2.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.12.2">𝑛</ci><cn type="integer" id="Ch3.E1.m1.1.1.1.1.1.2.12.3.cmml" xref="Ch3.E1.m1.1.1.1.1.1.2.12.3">1</cn></apply></apply><apply id="Ch3.E1.m1.1.1.1.1.1.3.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3"><times id="Ch3.E1.m1.1.1.1.1.1.3.1.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.1"></times><ci id="Ch3.E1.m1.1.1.1.1.1.3.2.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.2">𝑑</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.3.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.3">𝑒</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.4.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.4">𝑠</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.5.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.5">𝑐</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.6.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.6">𝑟</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.7.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.7">𝑖</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.8.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.8">𝑝</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.9.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.9">𝑡</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.10.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.10">𝑖</ci><ci id="Ch3.E1.m1.1.1.1.1.1.3.11.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.11">𝑜</ci><apply id="Ch3.E1.m1.1.1.1.1.1.3.12.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.12"><csymbol cd="ambiguous" id="Ch3.E1.m1.1.1.1.1.1.3.12.1.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.12">subscript</csymbol><ci id="Ch3.E1.m1.1.1.1.1.1.3.12.2.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.12.2">𝑛</ci><cn type="integer" id="Ch3.E1.m1.1.1.1.1.1.3.12.3.cmml" xref="Ch3.E1.m1.1.1.1.1.1.3.12.3">2</cn></apply></apply></apply></apply><apply id="Ch3.E1.m1.2.2.2.2.cmml" xref="Ch3.E1.m1.2.2.2.1"><abs id="Ch3.E1.m1.2.2.2.2.1.cmml" xref="Ch3.E1.m1.2.2.2.1.2"></abs><apply id="Ch3.E1.m1.2.2.2.1.1.cmml" xref="Ch3.E1.m1.2.2.2.1.1"><union id="Ch3.E1.m1.2.2.2.1.1.1.cmml" xref="Ch3.E1.m1.2.2.2.1.1.1"></union><apply id="Ch3.E1.m1.2.2.2.1.1.2.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2"><times id="Ch3.E1.m1.2.2.2.1.1.2.1.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.1"></times><ci id="Ch3.E1.m1.2.2.2.1.1.2.2.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.2">𝑑</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.3.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.3">𝑒</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.4.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.4">𝑠</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.5.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.5">𝑐</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.6.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.6">𝑟</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.7.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.7">𝑖</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.8.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.8">𝑝</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.9.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.9">𝑡</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.10.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.10">𝑖</ci><ci id="Ch3.E1.m1.2.2.2.1.1.2.11.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.11">𝑜</ci><apply id="Ch3.E1.m1.2.2.2.1.1.2.12.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.12"><csymbol cd="ambiguous" id="Ch3.E1.m1.2.2.2.1.1.2.12.1.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.12">subscript</csymbol><ci id="Ch3.E1.m1.2.2.2.1.1.2.12.2.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.12.2">𝑛</ci><cn type="integer" id="Ch3.E1.m1.2.2.2.1.1.2.12.3.cmml" xref="Ch3.E1.m1.2.2.2.1.1.2.12.3">1</cn></apply></apply><apply id="Ch3.E1.m1.2.2.2.1.1.3.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3"><times id="Ch3.E1.m1.2.2.2.1.1.3.1.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.1"></times><ci id="Ch3.E1.m1.2.2.2.1.1.3.2.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.2">𝑑</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.3.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.3">𝑒</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.4.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.4">𝑠</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.5.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.5">𝑐</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.6.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.6">𝑟</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.7.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.7">𝑖</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.8.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.8">𝑝</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.9.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.9">𝑡</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.10.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.10">𝑖</ci><ci id="Ch3.E1.m1.2.2.2.1.1.3.11.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.11">𝑜</ci><apply id="Ch3.E1.m1.2.2.2.1.1.3.12.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.12"><csymbol cd="ambiguous" id="Ch3.E1.m1.2.2.2.1.1.3.12.1.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.12">subscript</csymbol><ci id="Ch3.E1.m1.2.2.2.1.1.3.12.2.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.12.2">𝑛</ci><cn type="integer" id="Ch3.E1.m1.2.2.2.1.1.3.12.3.cmml" xref="Ch3.E1.m1.2.2.2.1.1.3.12.3">2</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.E1.m1.4c">J(description_{1},description_{2})=\frac{|description_{1}\cap description_{2}|}{|description_{1}\cup description_{2}|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3.1)</span></td>
</tr></tbody>
</table>
<p id="Ch3.S2.p1.2" class="ltx_p">For every image, we will extract features from a pre-trained ResNet convolutional neural network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and then for each pair of records, we will compute the Euclidian distance between the embedded representations of the associated images. Below is the formula for Euclidean distance:</p>
<table id="Ch3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch3.E2.m1.3" class="ltx_Math" alttext="d(img\_embed_{1},img\_embed_{2})=\sqrt{\sum_{i=1}^{n}(img\_embed_{1}^{i}-img\_embed_{2}^{i})^{2}}" display="block"><semantics id="Ch3.E2.m1.3a"><mrow id="Ch3.E2.m1.3.3" xref="Ch3.E2.m1.3.3.cmml"><mrow id="Ch3.E2.m1.3.3.2" xref="Ch3.E2.m1.3.3.2.cmml"><mi id="Ch3.E2.m1.3.3.2.4" xref="Ch3.E2.m1.3.3.2.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.3" xref="Ch3.E2.m1.3.3.2.3.cmml">​</mo><mrow id="Ch3.E2.m1.3.3.2.2.2" xref="Ch3.E2.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="Ch3.E2.m1.3.3.2.2.2.3" xref="Ch3.E2.m1.3.3.2.2.3.cmml">(</mo><mrow id="Ch3.E2.m1.2.2.1.1.1.1" xref="Ch3.E2.m1.2.2.1.1.1.1.cmml"><mi id="Ch3.E2.m1.2.2.1.1.1.1.2" xref="Ch3.E2.m1.2.2.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E2.m1.2.2.1.1.1.1.3" xref="Ch3.E2.m1.2.2.1.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1a" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E2.m1.2.2.1.1.1.1.4" xref="Ch3.E2.m1.2.2.1.1.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1b" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="Ch3.E2.m1.2.2.1.1.1.1.5" xref="Ch3.E2.m1.2.2.1.1.1.1.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1c" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E2.m1.2.2.1.1.1.1.6" xref="Ch3.E2.m1.2.2.1.1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1d" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E2.m1.2.2.1.1.1.1.7" xref="Ch3.E2.m1.2.2.1.1.1.1.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1e" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E2.m1.2.2.1.1.1.1.8" xref="Ch3.E2.m1.2.2.1.1.1.1.8.cmml">b</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1f" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="Ch3.E2.m1.2.2.1.1.1.1.9" xref="Ch3.E2.m1.2.2.1.1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.2.2.1.1.1.1.1g" xref="Ch3.E2.m1.2.2.1.1.1.1.1.cmml">​</mo><msub id="Ch3.E2.m1.2.2.1.1.1.1.10" xref="Ch3.E2.m1.2.2.1.1.1.1.10.cmml"><mi id="Ch3.E2.m1.2.2.1.1.1.1.10.2" xref="Ch3.E2.m1.2.2.1.1.1.1.10.2.cmml">d</mi><mn id="Ch3.E2.m1.2.2.1.1.1.1.10.3" xref="Ch3.E2.m1.2.2.1.1.1.1.10.3.cmml">1</mn></msub></mrow><mo id="Ch3.E2.m1.3.3.2.2.2.4" xref="Ch3.E2.m1.3.3.2.2.3.cmml">,</mo><mrow id="Ch3.E2.m1.3.3.2.2.2.2" xref="Ch3.E2.m1.3.3.2.2.2.2.cmml"><mi id="Ch3.E2.m1.3.3.2.2.2.2.2" xref="Ch3.E2.m1.3.3.2.2.2.2.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E2.m1.3.3.2.2.2.2.3" xref="Ch3.E2.m1.3.3.2.2.2.2.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1a" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E2.m1.3.3.2.2.2.2.4" xref="Ch3.E2.m1.3.3.2.2.2.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1b" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="Ch3.E2.m1.3.3.2.2.2.2.5" xref="Ch3.E2.m1.3.3.2.2.2.2.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1c" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E2.m1.3.3.2.2.2.2.6" xref="Ch3.E2.m1.3.3.2.2.2.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1d" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E2.m1.3.3.2.2.2.2.7" xref="Ch3.E2.m1.3.3.2.2.2.2.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1e" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E2.m1.3.3.2.2.2.2.8" xref="Ch3.E2.m1.3.3.2.2.2.2.8.cmml">b</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1f" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><mi id="Ch3.E2.m1.3.3.2.2.2.2.9" xref="Ch3.E2.m1.3.3.2.2.2.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.3.3.2.2.2.2.1g" xref="Ch3.E2.m1.3.3.2.2.2.2.1.cmml">​</mo><msub id="Ch3.E2.m1.3.3.2.2.2.2.10" xref="Ch3.E2.m1.3.3.2.2.2.2.10.cmml"><mi id="Ch3.E2.m1.3.3.2.2.2.2.10.2" xref="Ch3.E2.m1.3.3.2.2.2.2.10.2.cmml">d</mi><mn id="Ch3.E2.m1.3.3.2.2.2.2.10.3" xref="Ch3.E2.m1.3.3.2.2.2.2.10.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="Ch3.E2.m1.3.3.2.2.2.5" xref="Ch3.E2.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow><mo id="Ch3.E2.m1.3.3.3" xref="Ch3.E2.m1.3.3.3.cmml">=</mo><msqrt id="Ch3.E2.m1.1.1" xref="Ch3.E2.m1.1.1.cmml"><mrow id="Ch3.E2.m1.1.1.1" xref="Ch3.E2.m1.1.1.1.cmml"><munderover id="Ch3.E2.m1.1.1.1.2" xref="Ch3.E2.m1.1.1.1.2.cmml"><mo movablelimits="false" id="Ch3.E2.m1.1.1.1.2.2.2" xref="Ch3.E2.m1.1.1.1.2.2.2.cmml">∑</mo><mrow id="Ch3.E2.m1.1.1.1.2.2.3" xref="Ch3.E2.m1.1.1.1.2.2.3.cmml"><mi id="Ch3.E2.m1.1.1.1.2.2.3.2" xref="Ch3.E2.m1.1.1.1.2.2.3.2.cmml">i</mi><mo id="Ch3.E2.m1.1.1.1.2.2.3.1" xref="Ch3.E2.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="Ch3.E2.m1.1.1.1.2.2.3.3" xref="Ch3.E2.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="Ch3.E2.m1.1.1.1.2.3" xref="Ch3.E2.m1.1.1.1.2.3.cmml">n</mi></munderover><msup id="Ch3.E2.m1.1.1.1.1" xref="Ch3.E2.m1.1.1.1.1.cmml"><mrow id="Ch3.E2.m1.1.1.1.1.1.1" xref="Ch3.E2.m1.1.1.1.1.1.1.1.cmml"><mo lspace="0em" stretchy="false" id="Ch3.E2.m1.1.1.1.1.1.1.2" xref="Ch3.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch3.E2.m1.1.1.1.1.1.1.1" xref="Ch3.E2.m1.1.1.1.1.1.1.1.cmml"><mrow id="Ch3.E2.m1.1.1.1.1.1.1.1.2" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.cmml"><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.2" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1a" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.4" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1b" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.5" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1c" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.6" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1d" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.7" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1e" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.8" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.8.cmml">b</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1f" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.9" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1g" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml">​</mo><msubsup id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.cmml"><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.2" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.2.cmml">d</mi><mn id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.3.cmml">1</mn><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.3.cmml">i</mi></msubsup></mrow><mo id="Ch3.E2.m1.1.1.1.1.1.1.1.1" xref="Ch3.E2.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="Ch3.E2.m1.1.1.1.1.1.1.1.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.2" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1a" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.4" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1b" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.5" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1c" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.6" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1d" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.7" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1e" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.8" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.8.cmml">b</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1f" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.9" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1g" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><msubsup id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.cmml"><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.2" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.2.cmml">d</mi><mn id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.3.cmml">2</mn><mi id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.3.cmml">i</mi></msubsup></mrow></mrow><mo stretchy="false" id="Ch3.E2.m1.1.1.1.1.1.1.3" xref="Ch3.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="Ch3.E2.m1.1.1.1.1.3" xref="Ch3.E2.m1.1.1.1.1.3.cmml">2</mn></msup></mrow></msqrt></mrow><annotation-xml encoding="MathML-Content" id="Ch3.E2.m1.3b"><apply id="Ch3.E2.m1.3.3.cmml" xref="Ch3.E2.m1.3.3"><eq id="Ch3.E2.m1.3.3.3.cmml" xref="Ch3.E2.m1.3.3.3"></eq><apply id="Ch3.E2.m1.3.3.2.cmml" xref="Ch3.E2.m1.3.3.2"><times id="Ch3.E2.m1.3.3.2.3.cmml" xref="Ch3.E2.m1.3.3.2.3"></times><ci id="Ch3.E2.m1.3.3.2.4.cmml" xref="Ch3.E2.m1.3.3.2.4">𝑑</ci><interval closure="open" id="Ch3.E2.m1.3.3.2.2.3.cmml" xref="Ch3.E2.m1.3.3.2.2.2"><apply id="Ch3.E2.m1.2.2.1.1.1.1.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1"><times id="Ch3.E2.m1.2.2.1.1.1.1.1.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.1"></times><ci id="Ch3.E2.m1.2.2.1.1.1.1.2.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.2">𝑖</ci><ci id="Ch3.E2.m1.2.2.1.1.1.1.3.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.3">𝑚</ci><ci id="Ch3.E2.m1.2.2.1.1.1.1.4.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.4">𝑔</ci><ci id="Ch3.E2.m1.2.2.1.1.1.1.5.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.5">_</ci><ci id="Ch3.E2.m1.2.2.1.1.1.1.6.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.6">𝑒</ci><ci id="Ch3.E2.m1.2.2.1.1.1.1.7.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.7">𝑚</ci><ci id="Ch3.E2.m1.2.2.1.1.1.1.8.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.8">𝑏</ci><ci id="Ch3.E2.m1.2.2.1.1.1.1.9.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.9">𝑒</ci><apply id="Ch3.E2.m1.2.2.1.1.1.1.10.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.10"><csymbol cd="ambiguous" id="Ch3.E2.m1.2.2.1.1.1.1.10.1.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.10">subscript</csymbol><ci id="Ch3.E2.m1.2.2.1.1.1.1.10.2.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.10.2">𝑑</ci><cn type="integer" id="Ch3.E2.m1.2.2.1.1.1.1.10.3.cmml" xref="Ch3.E2.m1.2.2.1.1.1.1.10.3">1</cn></apply></apply><apply id="Ch3.E2.m1.3.3.2.2.2.2.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2"><times id="Ch3.E2.m1.3.3.2.2.2.2.1.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.1"></times><ci id="Ch3.E2.m1.3.3.2.2.2.2.2.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.2">𝑖</ci><ci id="Ch3.E2.m1.3.3.2.2.2.2.3.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.3">𝑚</ci><ci id="Ch3.E2.m1.3.3.2.2.2.2.4.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.4">𝑔</ci><ci id="Ch3.E2.m1.3.3.2.2.2.2.5.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.5">_</ci><ci id="Ch3.E2.m1.3.3.2.2.2.2.6.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.6">𝑒</ci><ci id="Ch3.E2.m1.3.3.2.2.2.2.7.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.7">𝑚</ci><ci id="Ch3.E2.m1.3.3.2.2.2.2.8.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.8">𝑏</ci><ci id="Ch3.E2.m1.3.3.2.2.2.2.9.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.9">𝑒</ci><apply id="Ch3.E2.m1.3.3.2.2.2.2.10.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.10"><csymbol cd="ambiguous" id="Ch3.E2.m1.3.3.2.2.2.2.10.1.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.10">subscript</csymbol><ci id="Ch3.E2.m1.3.3.2.2.2.2.10.2.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.10.2">𝑑</ci><cn type="integer" id="Ch3.E2.m1.3.3.2.2.2.2.10.3.cmml" xref="Ch3.E2.m1.3.3.2.2.2.2.10.3">2</cn></apply></apply></interval></apply><apply id="Ch3.E2.m1.1.1.cmml" xref="Ch3.E2.m1.1.1"><root id="Ch3.E2.m1.1.1a.cmml" xref="Ch3.E2.m1.1.1"></root><apply id="Ch3.E2.m1.1.1.1.cmml" xref="Ch3.E2.m1.1.1.1"><apply id="Ch3.E2.m1.1.1.1.2.cmml" xref="Ch3.E2.m1.1.1.1.2"><csymbol cd="ambiguous" id="Ch3.E2.m1.1.1.1.2.1.cmml" xref="Ch3.E2.m1.1.1.1.2">superscript</csymbol><apply id="Ch3.E2.m1.1.1.1.2.2.cmml" xref="Ch3.E2.m1.1.1.1.2"><csymbol cd="ambiguous" id="Ch3.E2.m1.1.1.1.2.2.1.cmml" xref="Ch3.E2.m1.1.1.1.2">subscript</csymbol><sum id="Ch3.E2.m1.1.1.1.2.2.2.cmml" xref="Ch3.E2.m1.1.1.1.2.2.2"></sum><apply id="Ch3.E2.m1.1.1.1.2.2.3.cmml" xref="Ch3.E2.m1.1.1.1.2.2.3"><eq id="Ch3.E2.m1.1.1.1.2.2.3.1.cmml" xref="Ch3.E2.m1.1.1.1.2.2.3.1"></eq><ci id="Ch3.E2.m1.1.1.1.2.2.3.2.cmml" xref="Ch3.E2.m1.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="Ch3.E2.m1.1.1.1.2.2.3.3.cmml" xref="Ch3.E2.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="Ch3.E2.m1.1.1.1.2.3.cmml" xref="Ch3.E2.m1.1.1.1.2.3">𝑛</ci></apply><apply id="Ch3.E2.m1.1.1.1.1.cmml" xref="Ch3.E2.m1.1.1.1.1"><csymbol cd="ambiguous" id="Ch3.E2.m1.1.1.1.1.2.cmml" xref="Ch3.E2.m1.1.1.1.1">superscript</csymbol><apply id="Ch3.E2.m1.1.1.1.1.1.1.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1"><minus id="Ch3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.1"></minus><apply id="Ch3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2"><times id="Ch3.E2.m1.1.1.1.1.1.1.1.2.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.1"></times><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.2.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.2">𝑖</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.3.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.3">𝑚</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.4.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.4">𝑔</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.5.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.5">_</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.6.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.6">𝑒</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.7.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.7">𝑚</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.8.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.8">𝑏</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.9.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.9">𝑒</ci><apply id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10"><csymbol cd="ambiguous" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10">superscript</csymbol><apply id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10"><csymbol cd="ambiguous" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10">subscript</csymbol><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.2.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.2">𝑑</ci><cn type="integer" id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.3.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.2.3">1</cn></apply><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.3.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.2.10.3">𝑖</ci></apply></apply><apply id="Ch3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3"><times id="Ch3.E2.m1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.1"></times><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.2">𝑖</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.3">𝑚</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.4.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.4">𝑔</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.5.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.5">_</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.6.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.6">𝑒</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.7.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.7">𝑚</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.8.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.8">𝑏</ci><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.9.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.9">𝑒</ci><apply id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10"><csymbol cd="ambiguous" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10">superscript</csymbol><apply id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10"><csymbol cd="ambiguous" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.1.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10">subscript</csymbol><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.2.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.2">𝑑</ci><cn type="integer" id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.3.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.2.3">2</cn></apply><ci id="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.3.cmml" xref="Ch3.E2.m1.1.1.1.1.1.1.1.3.10.3">𝑖</ci></apply></apply></apply><cn type="integer" id="Ch3.E2.m1.1.1.1.1.3.cmml" xref="Ch3.E2.m1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.E2.m1.3c">d(img\_embed_{1},img\_embed_{2})=\sqrt{\sum_{i=1}^{n}(img\_embed_{1}^{i}-img\_embed_{2}^{i})^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3.2)</span></td>
</tr></tbody>
</table>
<p id="Ch3.S2.p1.3" class="ltx_p">There are more hand-crafted features that the winners of the competition used, but for a better comparison of the models, we only use the descriptions and images of the advertisements. We normalize both of the features in the training set using z-score normalization and we apply the same z-score normalization on the test set. Z-score normalization is done by subtracting the mean of the feature from each sample and then dividing this with the standard deviation of the feature. With this we are centering the features around their corresponding means and we also ensure that both features will be in the same range, which will help our model to generalize better. These two features are the input to a logistic regression model.</p>
</div>
</section>
<section id="Ch3.S3" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.3 </span>Siamese Neural Network Framework</h3>

<div id="Ch3.S3.p1" class="ltx_para">
<p id="Ch3.S3.p1.1" class="ltx_p">The framework that we propose consists of a fusion unit that needs to learn how to combine the image and the description of each item in the pair. The fusion units output two vector representations each for the corresponding advertisement. These outputs are fed into a Siamese Neural network that produces a binary output. The scope of our research is the fusion models and their architecture will be explained in the sections below. We based our Siamese Neural Network model on the work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. The model consists of two branches and an energy function on the top. The architectures of the branches are identical and share weights. The architecture of one branch consists of two fully connected neural network layers with a ReLU activation function after each layer. The outputs of the two branches are then combined by computing the absolute distance between the two outputs. After we have combined the outputs of the two branches into one vector, we feed this vector into a fully connected layer that is followed by a sigmoid function that finally produces a binary output. Figure <a href="#Ch3.F1" title="Figure 3.1 ‣ 3.3 Siamese Neural Network Framework ‣ Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> illustrates the architecture of the framework.</p>
</div>
<figure id="Ch3.F1" class="ltx_figure"><img src="/html/2007.05881/assets/x3.png" id="Ch3.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="566" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.1: </span>An illustration of our proposed framework. The fusion models are independent of the framework. The dotted lines mean that the neural network layers share the same weights. The function that combines the two output vectors is the absolute difference of the two vectors.</figcaption>
</figure>
</section>
<section id="Ch3.S4" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.4 </span>Recurrent Neural Network + Convolutional Neural Network fusion module</h3>

<div id="Ch3.S4.p1" class="ltx_para">
<p id="Ch3.S4.p1.1" class="ltx_p">The first fusion module that we proposed is inspired by the architecture proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. The model is composed of a pre-trained ResNet152 convolutional neural network that we use to extract features from the image and a GRU recurrent neural network to model the description. We use the second to last layer of the pre-trained ResNet152, which outputs a 2048-dimensional feature vector. We decided to use GRUs instead of LSTMs because they are more computationally efficient and it has been shown that they achieve similar performance when modelling natural language <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. To encode the description, first, we will replace every token (word) with its corresponding 300-dimensional FastText word embedding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. We do this because the pre-trained embeddings give a better semantic vector space representation of the language than one-hot encodings<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. After we have applied this transformation to the description, we will feed the description to a GRU recurrent neural network. The output of the GRU represents an encoded vector representation of the description. Because the size of the description encoding and the image feature vector is different, we use two separate fully connected neural networks to transform the description encoding and the image encoding into similar sized vectors. To combine the textual and visual information, we use point-wise multiplication (as suggested in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>) to fuse the description encoding and the image feature vector, which is the final output of the fusion module. This architecture is illustrated in Figure <a href="#Ch3.F2" title="Figure 3.2 ‣ 3.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<figure id="Ch3.F2" class="ltx_figure"><img src="/html/2007.05881/assets/x4.png" id="Ch3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="306" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.2: </span>An illustration of the simple fusion model. The GRU is used to create a description encoding and a pre-trained ResNet to extract a vector representation of the image features. After we use fully connected layers to transform the visual and textual encoding to the same vector space, we combine the visual and textual information by point-wise multiplication of the two encodings.</figcaption>
</figure>
</section>
<section id="Ch3.S5" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.5 </span>Stacked Attention Network fusion module</h3>

<div id="Ch3.S5.p1" class="ltx_para">
<p id="Ch3.S5.p1.3" class="ltx_p">The second fusion module is inspired by the Stacked Attention Networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> architecture used for Visual Question Answering. We propose that the fusion model should use a pre-trained VGG-19 convolutional neural network to obtain a feature vector representation of the image. For each image, we obtain a [14, 14, 512] vector, where 14 x 14 is the number of regions that we split our image into. Therefore we transform the output of the VGG-19 network into a [196, 512] matrix, where every 512-dimensional column is a feature representation of each region in the image. We choose VGG-19 instead of ResNet, because ResNet doesn’t have an intermediate output that corresponds to a feature representation of each region. We use a GRU recurrent neural network to obtain an encoding for the description in the same way as the previously described model. For modelling convenience, we use a single fully connected neural network to transform each feature vector to a new vector that has the same dimension as the description vector. We want to find a better correlation between the description and the visual features because if two records represent the same item but the description is worded differently, we would want the vector representations of the two records to be closer. A possible solution would be to use an attention layer that will connect the description and the feature vector of the image. The attention mechanism should learn to give a higher probability mass to the feature vector of the region in the image that is relevant to the words in the description. In this module, we experiment with multiple attention layers because <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> concluded that for complicated questions/descriptions, a single attention layer is not sufficient to locate the correct region for answer prediction if in the image there are some subtle relationships among multiple objects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.
Given the image feature matrix <math id="Ch3.S5.p1.1.m1.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="Ch3.S5.p1.1.m1.1a"><msub id="Ch3.S5.p1.1.m1.1.1" xref="Ch3.S5.p1.1.m1.1.1.cmml"><mi id="Ch3.S5.p1.1.m1.1.1.2" xref="Ch3.S5.p1.1.m1.1.1.2.cmml">v</mi><mi id="Ch3.S5.p1.1.m1.1.1.3" xref="Ch3.S5.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.1.m1.1b"><apply id="Ch3.S5.p1.1.m1.1.1.cmml" xref="Ch3.S5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.1.m1.1.1.1.cmml" xref="Ch3.S5.p1.1.m1.1.1">subscript</csymbol><ci id="Ch3.S5.p1.1.m1.1.1.2.cmml" xref="Ch3.S5.p1.1.m1.1.1.2">𝑣</ci><ci id="Ch3.S5.p1.1.m1.1.1.3.cmml" xref="Ch3.S5.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.1.m1.1c">v_{i}</annotation></semantics></math> and the description encoding <math id="Ch3.S5.p1.2.m2.1" class="ltx_Math" alttext="v_{d}" display="inline"><semantics id="Ch3.S5.p1.2.m2.1a"><msub id="Ch3.S5.p1.2.m2.1.1" xref="Ch3.S5.p1.2.m2.1.1.cmml"><mi id="Ch3.S5.p1.2.m2.1.1.2" xref="Ch3.S5.p1.2.m2.1.1.2.cmml">v</mi><mi id="Ch3.S5.p1.2.m2.1.1.3" xref="Ch3.S5.p1.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.2.m2.1b"><apply id="Ch3.S5.p1.2.m2.1.1.cmml" xref="Ch3.S5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.2.m2.1.1.1.cmml" xref="Ch3.S5.p1.2.m2.1.1">subscript</csymbol><ci id="Ch3.S5.p1.2.m2.1.1.2.cmml" xref="Ch3.S5.p1.2.m2.1.1.2">𝑣</ci><ci id="Ch3.S5.p1.2.m2.1.1.3.cmml" xref="Ch3.S5.p1.2.m2.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.2.m2.1c">v_{d}</annotation></semantics></math>, we combine them by using a fully connected neural network and then we use softmax to produce a probability distribution (attention weights) over the regions of the image. We then calculate a weighted sum of the image feature columns using the attention distribution. Lastly, we combine the weighted sum with the description encoding to form a refined query vector. The final vector is refined because it encodes both the description information and the visual information that is relevant to the description. We implement our solution so that we can experiment with multiple numbers of attention layers. The following formula defines the <math id="Ch3.S5.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="Ch3.S5.p1.3.m3.1a"><mi id="Ch3.S5.p1.3.m3.1.1" xref="Ch3.S5.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.3.m3.1b"><ci id="Ch3.S5.p1.3.m3.1.1.cmml" xref="Ch3.S5.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.3.m3.1c">k</annotation></semantics></math>-th attention layer and gives a mathematical representation of the description above:</p>
<table id="Ch3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch3.E3.m1.6" class="ltx_Math" alttext="h^{k}_{A}=\tanh(W^{k}_{I,A}v_{I}\oplus(W^{k}_{Q,A}u^{k-1}+b^{k}_{A}))" display="block"><semantics id="Ch3.E3.m1.6a"><mrow id="Ch3.E3.m1.6.6" xref="Ch3.E3.m1.6.6.cmml"><msubsup id="Ch3.E3.m1.6.6.3" xref="Ch3.E3.m1.6.6.3.cmml"><mi id="Ch3.E3.m1.6.6.3.2.2" xref="Ch3.E3.m1.6.6.3.2.2.cmml">h</mi><mi id="Ch3.E3.m1.6.6.3.3" xref="Ch3.E3.m1.6.6.3.3.cmml">A</mi><mi id="Ch3.E3.m1.6.6.3.2.3" xref="Ch3.E3.m1.6.6.3.2.3.cmml">k</mi></msubsup><mo id="Ch3.E3.m1.6.6.2" xref="Ch3.E3.m1.6.6.2.cmml">=</mo><mrow id="Ch3.E3.m1.6.6.1.1" xref="Ch3.E3.m1.6.6.1.2.cmml"><mi id="Ch3.E3.m1.5.5" xref="Ch3.E3.m1.5.5.cmml">tanh</mi><mo id="Ch3.E3.m1.6.6.1.1a" xref="Ch3.E3.m1.6.6.1.2.cmml">⁡</mo><mrow id="Ch3.E3.m1.6.6.1.1.1" xref="Ch3.E3.m1.6.6.1.2.cmml"><mo stretchy="false" id="Ch3.E3.m1.6.6.1.1.1.2" xref="Ch3.E3.m1.6.6.1.2.cmml">(</mo><mrow id="Ch3.E3.m1.6.6.1.1.1.1" xref="Ch3.E3.m1.6.6.1.1.1.1.cmml"><mrow id="Ch3.E3.m1.6.6.1.1.1.1.3" xref="Ch3.E3.m1.6.6.1.1.1.1.3.cmml"><msubsup id="Ch3.E3.m1.6.6.1.1.1.1.3.2" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2.cmml"><mi id="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.2" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.2.cmml">W</mi><mrow id="Ch3.E3.m1.2.2.2.4" xref="Ch3.E3.m1.2.2.2.3.cmml"><mi id="Ch3.E3.m1.1.1.1.1" xref="Ch3.E3.m1.1.1.1.1.cmml">I</mi><mo id="Ch3.E3.m1.2.2.2.4.1" xref="Ch3.E3.m1.2.2.2.3.cmml">,</mo><mi id="Ch3.E3.m1.2.2.2.2" xref="Ch3.E3.m1.2.2.2.2.cmml">A</mi></mrow><mi id="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.3" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="Ch3.E3.m1.6.6.1.1.1.1.3.1" xref="Ch3.E3.m1.6.6.1.1.1.1.3.1.cmml">​</mo><msub id="Ch3.E3.m1.6.6.1.1.1.1.3.3" xref="Ch3.E3.m1.6.6.1.1.1.1.3.3.cmml"><mi id="Ch3.E3.m1.6.6.1.1.1.1.3.3.2" xref="Ch3.E3.m1.6.6.1.1.1.1.3.3.2.cmml">v</mi><mi id="Ch3.E3.m1.6.6.1.1.1.1.3.3.3" xref="Ch3.E3.m1.6.6.1.1.1.1.3.3.3.cmml">I</mi></msub></mrow><mo id="Ch3.E3.m1.6.6.1.1.1.1.2" xref="Ch3.E3.m1.6.6.1.1.1.1.2.cmml">⊕</mo><mrow id="Ch3.E3.m1.6.6.1.1.1.1.1.1" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.2" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.cmml"><mrow id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.cmml"><msubsup id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.cmml"><mi id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.2" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml">W</mi><mrow id="Ch3.E3.m1.4.4.2.4" xref="Ch3.E3.m1.4.4.2.3.cmml"><mi id="Ch3.E3.m1.3.3.1.1" xref="Ch3.E3.m1.3.3.1.1.cmml">Q</mi><mo id="Ch3.E3.m1.4.4.2.4.1" xref="Ch3.E3.m1.4.4.2.3.cmml">,</mo><mi id="Ch3.E3.m1.4.4.2.2" xref="Ch3.E3.m1.4.4.2.2.cmml">A</mi></mrow><mi id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.1" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">​</mo><msup id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.cmml"><mi id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.2" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml">u</mi><mrow id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml"><mi id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.2" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.2.cmml">k</mi><mo id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.1" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></msup></mrow><mo id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.1" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.1.cmml">+</mo><msubsup id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.cmml"><mi id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.2" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.2.cmml">b</mi><mi id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.3.cmml">A</mi><mi id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.3.cmml">k</mi></msubsup></mrow><mo stretchy="false" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.3" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="Ch3.E3.m1.6.6.1.1.1.3" xref="Ch3.E3.m1.6.6.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch3.E3.m1.6b"><apply id="Ch3.E3.m1.6.6.cmml" xref="Ch3.E3.m1.6.6"><eq id="Ch3.E3.m1.6.6.2.cmml" xref="Ch3.E3.m1.6.6.2"></eq><apply id="Ch3.E3.m1.6.6.3.cmml" xref="Ch3.E3.m1.6.6.3"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.3.1.cmml" xref="Ch3.E3.m1.6.6.3">subscript</csymbol><apply id="Ch3.E3.m1.6.6.3.2.cmml" xref="Ch3.E3.m1.6.6.3"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.3.2.1.cmml" xref="Ch3.E3.m1.6.6.3">superscript</csymbol><ci id="Ch3.E3.m1.6.6.3.2.2.cmml" xref="Ch3.E3.m1.6.6.3.2.2">ℎ</ci><ci id="Ch3.E3.m1.6.6.3.2.3.cmml" xref="Ch3.E3.m1.6.6.3.2.3">𝑘</ci></apply><ci id="Ch3.E3.m1.6.6.3.3.cmml" xref="Ch3.E3.m1.6.6.3.3">𝐴</ci></apply><apply id="Ch3.E3.m1.6.6.1.2.cmml" xref="Ch3.E3.m1.6.6.1.1"><tanh id="Ch3.E3.m1.5.5.cmml" xref="Ch3.E3.m1.5.5"></tanh><apply id="Ch3.E3.m1.6.6.1.1.1.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1"><csymbol cd="latexml" id="Ch3.E3.m1.6.6.1.1.1.1.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.2">direct-sum</csymbol><apply id="Ch3.E3.m1.6.6.1.1.1.1.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3"><times id="Ch3.E3.m1.6.6.1.1.1.1.3.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.1"></times><apply id="Ch3.E3.m1.6.6.1.1.1.1.3.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.3.2.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2">subscript</csymbol><apply id="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2">superscript</csymbol><ci id="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.2">𝑊</ci><ci id="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.2.2.3">𝑘</ci></apply><list id="Ch3.E3.m1.2.2.2.3.cmml" xref="Ch3.E3.m1.2.2.2.4"><ci id="Ch3.E3.m1.1.1.1.1.cmml" xref="Ch3.E3.m1.1.1.1.1">𝐼</ci><ci id="Ch3.E3.m1.2.2.2.2.cmml" xref="Ch3.E3.m1.2.2.2.2">𝐴</ci></list></apply><apply id="Ch3.E3.m1.6.6.1.1.1.1.3.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.3"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.3.3.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.3">subscript</csymbol><ci id="Ch3.E3.m1.6.6.1.1.1.1.3.3.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.3.2">𝑣</ci><ci id="Ch3.E3.m1.6.6.1.1.1.1.3.3.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.3.3.3">𝐼</ci></apply></apply><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1"><plus id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.1"></plus><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2"><times id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.1"></times><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.2">𝑊</ci><ci id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.2.2.3">𝑘</ci></apply><list id="Ch3.E3.m1.4.4.2.3.cmml" xref="Ch3.E3.m1.4.4.2.4"><ci id="Ch3.E3.m1.3.3.1.1.cmml" xref="Ch3.E3.m1.3.3.1.1">𝑄</ci><ci id="Ch3.E3.m1.4.4.2.2.cmml" xref="Ch3.E3.m1.4.4.2.2">𝐴</ci></list></apply><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3">superscript</csymbol><ci id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.2">𝑢</ci><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3"><minus id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.1"></minus><ci id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.2">𝑘</ci><cn type="integer" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.2.3.3.3">1</cn></apply></apply></apply><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.1.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.2.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.2">𝑏</ci><ci id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.2.3">𝑘</ci></apply><ci id="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.3.cmml" xref="Ch3.E3.m1.6.6.1.1.1.1.1.1.1.3.3">𝐴</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.E3.m1.6c">h^{k}_{A}=\tanh(W^{k}_{I,A}v_{I}\oplus(W^{k}_{Q,A}u^{k-1}+b^{k}_{A}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3.3)</span></td>
</tr></tbody>
</table>
<table id="Ch3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch3.E4.m1.1" class="ltx_Math" alttext="p^{k}_{I}=\textbf{softmax}(W^{k}_{P}h^{k}_{A}+b^{k}_{P})" display="block"><semantics id="Ch3.E4.m1.1a"><mrow id="Ch3.E4.m1.1.1" xref="Ch3.E4.m1.1.1.cmml"><msubsup id="Ch3.E4.m1.1.1.3" xref="Ch3.E4.m1.1.1.3.cmml"><mi id="Ch3.E4.m1.1.1.3.2.2" xref="Ch3.E4.m1.1.1.3.2.2.cmml">p</mi><mi id="Ch3.E4.m1.1.1.3.3" xref="Ch3.E4.m1.1.1.3.3.cmml">I</mi><mi id="Ch3.E4.m1.1.1.3.2.3" xref="Ch3.E4.m1.1.1.3.2.3.cmml">k</mi></msubsup><mo id="Ch3.E4.m1.1.1.2" xref="Ch3.E4.m1.1.1.2.cmml">=</mo><mrow id="Ch3.E4.m1.1.1.1" xref="Ch3.E4.m1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="Ch3.E4.m1.1.1.1.3" xref="Ch3.E4.m1.1.1.1.3a.cmml">softmax</mtext><mo lspace="0em" rspace="0em" id="Ch3.E4.m1.1.1.1.2" xref="Ch3.E4.m1.1.1.1.2.cmml">​</mo><mrow id="Ch3.E4.m1.1.1.1.1.1" xref="Ch3.E4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch3.E4.m1.1.1.1.1.1.2" xref="Ch3.E4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch3.E4.m1.1.1.1.1.1.1" xref="Ch3.E4.m1.1.1.1.1.1.1.cmml"><mrow id="Ch3.E4.m1.1.1.1.1.1.1.2" xref="Ch3.E4.m1.1.1.1.1.1.1.2.cmml"><msubsup id="Ch3.E4.m1.1.1.1.1.1.1.2.2" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2.cmml"><mi id="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.2" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.2.cmml">W</mi><mi id="Ch3.E4.m1.1.1.1.1.1.1.2.2.3" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2.3.cmml">P</mi><mi id="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.3" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="Ch3.E4.m1.1.1.1.1.1.1.2.1" xref="Ch3.E4.m1.1.1.1.1.1.1.2.1.cmml">​</mo><msubsup id="Ch3.E4.m1.1.1.1.1.1.1.2.3" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3.cmml"><mi id="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.2" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.2.cmml">h</mi><mi id="Ch3.E4.m1.1.1.1.1.1.1.2.3.3" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3.3.cmml">A</mi><mi id="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.3" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.3.cmml">k</mi></msubsup></mrow><mo id="Ch3.E4.m1.1.1.1.1.1.1.1" xref="Ch3.E4.m1.1.1.1.1.1.1.1.cmml">+</mo><msubsup id="Ch3.E4.m1.1.1.1.1.1.1.3" xref="Ch3.E4.m1.1.1.1.1.1.1.3.cmml"><mi id="Ch3.E4.m1.1.1.1.1.1.1.3.2.2" xref="Ch3.E4.m1.1.1.1.1.1.1.3.2.2.cmml">b</mi><mi id="Ch3.E4.m1.1.1.1.1.1.1.3.3" xref="Ch3.E4.m1.1.1.1.1.1.1.3.3.cmml">P</mi><mi id="Ch3.E4.m1.1.1.1.1.1.1.3.2.3" xref="Ch3.E4.m1.1.1.1.1.1.1.3.2.3.cmml">k</mi></msubsup></mrow><mo stretchy="false" id="Ch3.E4.m1.1.1.1.1.1.3" xref="Ch3.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch3.E4.m1.1b"><apply id="Ch3.E4.m1.1.1.cmml" xref="Ch3.E4.m1.1.1"><eq id="Ch3.E4.m1.1.1.2.cmml" xref="Ch3.E4.m1.1.1.2"></eq><apply id="Ch3.E4.m1.1.1.3.cmml" xref="Ch3.E4.m1.1.1.3"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.3.1.cmml" xref="Ch3.E4.m1.1.1.3">subscript</csymbol><apply id="Ch3.E4.m1.1.1.3.2.cmml" xref="Ch3.E4.m1.1.1.3"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.3.2.1.cmml" xref="Ch3.E4.m1.1.1.3">superscript</csymbol><ci id="Ch3.E4.m1.1.1.3.2.2.cmml" xref="Ch3.E4.m1.1.1.3.2.2">𝑝</ci><ci id="Ch3.E4.m1.1.1.3.2.3.cmml" xref="Ch3.E4.m1.1.1.3.2.3">𝑘</ci></apply><ci id="Ch3.E4.m1.1.1.3.3.cmml" xref="Ch3.E4.m1.1.1.3.3">𝐼</ci></apply><apply id="Ch3.E4.m1.1.1.1.cmml" xref="Ch3.E4.m1.1.1.1"><times id="Ch3.E4.m1.1.1.1.2.cmml" xref="Ch3.E4.m1.1.1.1.2"></times><ci id="Ch3.E4.m1.1.1.1.3a.cmml" xref="Ch3.E4.m1.1.1.1.3"><mtext class="ltx_mathvariant_bold" id="Ch3.E4.m1.1.1.1.3.cmml" xref="Ch3.E4.m1.1.1.1.3">softmax</mtext></ci><apply id="Ch3.E4.m1.1.1.1.1.1.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1"><plus id="Ch3.E4.m1.1.1.1.1.1.1.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.1"></plus><apply id="Ch3.E4.m1.1.1.1.1.1.1.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2"><times id="Ch3.E4.m1.1.1.1.1.1.1.2.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.1"></times><apply id="Ch3.E4.m1.1.1.1.1.1.1.2.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.1.1.1.1.2.2.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.2">𝑊</ci><ci id="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2.2.3">𝑘</ci></apply><ci id="Ch3.E4.m1.1.1.1.1.1.1.2.2.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.2.3">𝑃</ci></apply><apply id="Ch3.E4.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.1.1.1.1.2.3.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3">subscript</csymbol><apply id="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3">superscript</csymbol><ci id="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.2">ℎ</ci><ci id="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3.2.3">𝑘</ci></apply><ci id="Ch3.E4.m1.1.1.1.1.1.1.2.3.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.2.3.3">𝐴</ci></apply></apply><apply id="Ch3.E4.m1.1.1.1.1.1.1.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.1.1.1.1.3.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="Ch3.E4.m1.1.1.1.1.1.1.3.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch3.E4.m1.1.1.1.1.1.1.3.2.1.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="Ch3.E4.m1.1.1.1.1.1.1.3.2.2.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.3.2.2">𝑏</ci><ci id="Ch3.E4.m1.1.1.1.1.1.1.3.2.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.3.2.3">𝑘</ci></apply><ci id="Ch3.E4.m1.1.1.1.1.1.1.3.3.cmml" xref="Ch3.E4.m1.1.1.1.1.1.1.3.3">𝑃</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.E4.m1.1c">p^{k}_{I}=\textbf{softmax}(W^{k}_{P}h^{k}_{A}+b^{k}_{P})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3.4)</span></td>
</tr></tbody>
</table>
<table id="Ch3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch3.E5.m1.1" class="ltx_Math" alttext="\tilde{v}^{k}_{I}=\sum_{i}p^{k}_{i}v_{i}" display="block"><semantics id="Ch3.E5.m1.1a"><mrow id="Ch3.E5.m1.1.1" xref="Ch3.E5.m1.1.1.cmml"><msubsup id="Ch3.E5.m1.1.1.2" xref="Ch3.E5.m1.1.1.2.cmml"><mover accent="true" id="Ch3.E5.m1.1.1.2.2.2" xref="Ch3.E5.m1.1.1.2.2.2.cmml"><mi id="Ch3.E5.m1.1.1.2.2.2.2" xref="Ch3.E5.m1.1.1.2.2.2.2.cmml">v</mi><mo id="Ch3.E5.m1.1.1.2.2.2.1" xref="Ch3.E5.m1.1.1.2.2.2.1.cmml">~</mo></mover><mi id="Ch3.E5.m1.1.1.2.3" xref="Ch3.E5.m1.1.1.2.3.cmml">I</mi><mi id="Ch3.E5.m1.1.1.2.2.3" xref="Ch3.E5.m1.1.1.2.2.3.cmml">k</mi></msubsup><mo rspace="0.111em" id="Ch3.E5.m1.1.1.1" xref="Ch3.E5.m1.1.1.1.cmml">=</mo><mrow id="Ch3.E5.m1.1.1.3" xref="Ch3.E5.m1.1.1.3.cmml"><munder id="Ch3.E5.m1.1.1.3.1" xref="Ch3.E5.m1.1.1.3.1.cmml"><mo movablelimits="false" id="Ch3.E5.m1.1.1.3.1.2" xref="Ch3.E5.m1.1.1.3.1.2.cmml">∑</mo><mi id="Ch3.E5.m1.1.1.3.1.3" xref="Ch3.E5.m1.1.1.3.1.3.cmml">i</mi></munder><mrow id="Ch3.E5.m1.1.1.3.2" xref="Ch3.E5.m1.1.1.3.2.cmml"><msubsup id="Ch3.E5.m1.1.1.3.2.2" xref="Ch3.E5.m1.1.1.3.2.2.cmml"><mi id="Ch3.E5.m1.1.1.3.2.2.2.2" xref="Ch3.E5.m1.1.1.3.2.2.2.2.cmml">p</mi><mi id="Ch3.E5.m1.1.1.3.2.2.3" xref="Ch3.E5.m1.1.1.3.2.2.3.cmml">i</mi><mi id="Ch3.E5.m1.1.1.3.2.2.2.3" xref="Ch3.E5.m1.1.1.3.2.2.2.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="Ch3.E5.m1.1.1.3.2.1" xref="Ch3.E5.m1.1.1.3.2.1.cmml">​</mo><msub id="Ch3.E5.m1.1.1.3.2.3" xref="Ch3.E5.m1.1.1.3.2.3.cmml"><mi id="Ch3.E5.m1.1.1.3.2.3.2" xref="Ch3.E5.m1.1.1.3.2.3.2.cmml">v</mi><mi id="Ch3.E5.m1.1.1.3.2.3.3" xref="Ch3.E5.m1.1.1.3.2.3.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch3.E5.m1.1b"><apply id="Ch3.E5.m1.1.1.cmml" xref="Ch3.E5.m1.1.1"><eq id="Ch3.E5.m1.1.1.1.cmml" xref="Ch3.E5.m1.1.1.1"></eq><apply id="Ch3.E5.m1.1.1.2.cmml" xref="Ch3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="Ch3.E5.m1.1.1.2.1.cmml" xref="Ch3.E5.m1.1.1.2">subscript</csymbol><apply id="Ch3.E5.m1.1.1.2.2.cmml" xref="Ch3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="Ch3.E5.m1.1.1.2.2.1.cmml" xref="Ch3.E5.m1.1.1.2">superscript</csymbol><apply id="Ch3.E5.m1.1.1.2.2.2.cmml" xref="Ch3.E5.m1.1.1.2.2.2"><ci id="Ch3.E5.m1.1.1.2.2.2.1.cmml" xref="Ch3.E5.m1.1.1.2.2.2.1">~</ci><ci id="Ch3.E5.m1.1.1.2.2.2.2.cmml" xref="Ch3.E5.m1.1.1.2.2.2.2">𝑣</ci></apply><ci id="Ch3.E5.m1.1.1.2.2.3.cmml" xref="Ch3.E5.m1.1.1.2.2.3">𝑘</ci></apply><ci id="Ch3.E5.m1.1.1.2.3.cmml" xref="Ch3.E5.m1.1.1.2.3">𝐼</ci></apply><apply id="Ch3.E5.m1.1.1.3.cmml" xref="Ch3.E5.m1.1.1.3"><apply id="Ch3.E5.m1.1.1.3.1.cmml" xref="Ch3.E5.m1.1.1.3.1"><csymbol cd="ambiguous" id="Ch3.E5.m1.1.1.3.1.1.cmml" xref="Ch3.E5.m1.1.1.3.1">subscript</csymbol><sum id="Ch3.E5.m1.1.1.3.1.2.cmml" xref="Ch3.E5.m1.1.1.3.1.2"></sum><ci id="Ch3.E5.m1.1.1.3.1.3.cmml" xref="Ch3.E5.m1.1.1.3.1.3">𝑖</ci></apply><apply id="Ch3.E5.m1.1.1.3.2.cmml" xref="Ch3.E5.m1.1.1.3.2"><times id="Ch3.E5.m1.1.1.3.2.1.cmml" xref="Ch3.E5.m1.1.1.3.2.1"></times><apply id="Ch3.E5.m1.1.1.3.2.2.cmml" xref="Ch3.E5.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="Ch3.E5.m1.1.1.3.2.2.1.cmml" xref="Ch3.E5.m1.1.1.3.2.2">subscript</csymbol><apply id="Ch3.E5.m1.1.1.3.2.2.2.cmml" xref="Ch3.E5.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="Ch3.E5.m1.1.1.3.2.2.2.1.cmml" xref="Ch3.E5.m1.1.1.3.2.2">superscript</csymbol><ci id="Ch3.E5.m1.1.1.3.2.2.2.2.cmml" xref="Ch3.E5.m1.1.1.3.2.2.2.2">𝑝</ci><ci id="Ch3.E5.m1.1.1.3.2.2.2.3.cmml" xref="Ch3.E5.m1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="Ch3.E5.m1.1.1.3.2.2.3.cmml" xref="Ch3.E5.m1.1.1.3.2.2.3">𝑖</ci></apply><apply id="Ch3.E5.m1.1.1.3.2.3.cmml" xref="Ch3.E5.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="Ch3.E5.m1.1.1.3.2.3.1.cmml" xref="Ch3.E5.m1.1.1.3.2.3">subscript</csymbol><ci id="Ch3.E5.m1.1.1.3.2.3.2.cmml" xref="Ch3.E5.m1.1.1.3.2.3.2">𝑣</ci><ci id="Ch3.E5.m1.1.1.3.2.3.3.cmml" xref="Ch3.E5.m1.1.1.3.2.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.E5.m1.1c">\tilde{v}^{k}_{I}=\sum_{i}p^{k}_{i}v_{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3.5)</span></td>
</tr></tbody>
</table>
<table id="Ch3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch3.E6.m1.1" class="ltx_Math" alttext="u^{k}=\tilde{v}^{k}_{I}+u^{k-1}" display="block"><semantics id="Ch3.E6.m1.1a"><mrow id="Ch3.E6.m1.1.1" xref="Ch3.E6.m1.1.1.cmml"><msup id="Ch3.E6.m1.1.1.2" xref="Ch3.E6.m1.1.1.2.cmml"><mi id="Ch3.E6.m1.1.1.2.2" xref="Ch3.E6.m1.1.1.2.2.cmml">u</mi><mi id="Ch3.E6.m1.1.1.2.3" xref="Ch3.E6.m1.1.1.2.3.cmml">k</mi></msup><mo id="Ch3.E6.m1.1.1.1" xref="Ch3.E6.m1.1.1.1.cmml">=</mo><mrow id="Ch3.E6.m1.1.1.3" xref="Ch3.E6.m1.1.1.3.cmml"><msubsup id="Ch3.E6.m1.1.1.3.2" xref="Ch3.E6.m1.1.1.3.2.cmml"><mover accent="true" id="Ch3.E6.m1.1.1.3.2.2.2" xref="Ch3.E6.m1.1.1.3.2.2.2.cmml"><mi id="Ch3.E6.m1.1.1.3.2.2.2.2" xref="Ch3.E6.m1.1.1.3.2.2.2.2.cmml">v</mi><mo id="Ch3.E6.m1.1.1.3.2.2.2.1" xref="Ch3.E6.m1.1.1.3.2.2.2.1.cmml">~</mo></mover><mi id="Ch3.E6.m1.1.1.3.2.3" xref="Ch3.E6.m1.1.1.3.2.3.cmml">I</mi><mi id="Ch3.E6.m1.1.1.3.2.2.3" xref="Ch3.E6.m1.1.1.3.2.2.3.cmml">k</mi></msubsup><mo id="Ch3.E6.m1.1.1.3.1" xref="Ch3.E6.m1.1.1.3.1.cmml">+</mo><msup id="Ch3.E6.m1.1.1.3.3" xref="Ch3.E6.m1.1.1.3.3.cmml"><mi id="Ch3.E6.m1.1.1.3.3.2" xref="Ch3.E6.m1.1.1.3.3.2.cmml">u</mi><mrow id="Ch3.E6.m1.1.1.3.3.3" xref="Ch3.E6.m1.1.1.3.3.3.cmml"><mi id="Ch3.E6.m1.1.1.3.3.3.2" xref="Ch3.E6.m1.1.1.3.3.3.2.cmml">k</mi><mo id="Ch3.E6.m1.1.1.3.3.3.1" xref="Ch3.E6.m1.1.1.3.3.3.1.cmml">−</mo><mn id="Ch3.E6.m1.1.1.3.3.3.3" xref="Ch3.E6.m1.1.1.3.3.3.3.cmml">1</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch3.E6.m1.1b"><apply id="Ch3.E6.m1.1.1.cmml" xref="Ch3.E6.m1.1.1"><eq id="Ch3.E6.m1.1.1.1.cmml" xref="Ch3.E6.m1.1.1.1"></eq><apply id="Ch3.E6.m1.1.1.2.cmml" xref="Ch3.E6.m1.1.1.2"><csymbol cd="ambiguous" id="Ch3.E6.m1.1.1.2.1.cmml" xref="Ch3.E6.m1.1.1.2">superscript</csymbol><ci id="Ch3.E6.m1.1.1.2.2.cmml" xref="Ch3.E6.m1.1.1.2.2">𝑢</ci><ci id="Ch3.E6.m1.1.1.2.3.cmml" xref="Ch3.E6.m1.1.1.2.3">𝑘</ci></apply><apply id="Ch3.E6.m1.1.1.3.cmml" xref="Ch3.E6.m1.1.1.3"><plus id="Ch3.E6.m1.1.1.3.1.cmml" xref="Ch3.E6.m1.1.1.3.1"></plus><apply id="Ch3.E6.m1.1.1.3.2.cmml" xref="Ch3.E6.m1.1.1.3.2"><csymbol cd="ambiguous" id="Ch3.E6.m1.1.1.3.2.1.cmml" xref="Ch3.E6.m1.1.1.3.2">subscript</csymbol><apply id="Ch3.E6.m1.1.1.3.2.2.cmml" xref="Ch3.E6.m1.1.1.3.2"><csymbol cd="ambiguous" id="Ch3.E6.m1.1.1.3.2.2.1.cmml" xref="Ch3.E6.m1.1.1.3.2">superscript</csymbol><apply id="Ch3.E6.m1.1.1.3.2.2.2.cmml" xref="Ch3.E6.m1.1.1.3.2.2.2"><ci id="Ch3.E6.m1.1.1.3.2.2.2.1.cmml" xref="Ch3.E6.m1.1.1.3.2.2.2.1">~</ci><ci id="Ch3.E6.m1.1.1.3.2.2.2.2.cmml" xref="Ch3.E6.m1.1.1.3.2.2.2.2">𝑣</ci></apply><ci id="Ch3.E6.m1.1.1.3.2.2.3.cmml" xref="Ch3.E6.m1.1.1.3.2.2.3">𝑘</ci></apply><ci id="Ch3.E6.m1.1.1.3.2.3.cmml" xref="Ch3.E6.m1.1.1.3.2.3">𝐼</ci></apply><apply id="Ch3.E6.m1.1.1.3.3.cmml" xref="Ch3.E6.m1.1.1.3.3"><csymbol cd="ambiguous" id="Ch3.E6.m1.1.1.3.3.1.cmml" xref="Ch3.E6.m1.1.1.3.3">superscript</csymbol><ci id="Ch3.E6.m1.1.1.3.3.2.cmml" xref="Ch3.E6.m1.1.1.3.3.2">𝑢</ci><apply id="Ch3.E6.m1.1.1.3.3.3.cmml" xref="Ch3.E6.m1.1.1.3.3.3"><minus id="Ch3.E6.m1.1.1.3.3.3.1.cmml" xref="Ch3.E6.m1.1.1.3.3.3.1"></minus><ci id="Ch3.E6.m1.1.1.3.3.3.2.cmml" xref="Ch3.E6.m1.1.1.3.3.3.2">𝑘</ci><cn type="integer" id="Ch3.E6.m1.1.1.3.3.3.3.cmml" xref="Ch3.E6.m1.1.1.3.3.3.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.E6.m1.1c">u^{k}=\tilde{v}^{k}_{I}+u^{k-1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3.6)</span></td>
</tr></tbody>
</table>
<p id="Ch3.S5.p1.15" class="ltx_p">where <math id="Ch3.S5.p1.4.m1.1" class="ltx_Math" alttext="u^{0}" display="inline"><semantics id="Ch3.S5.p1.4.m1.1a"><msup id="Ch3.S5.p1.4.m1.1.1" xref="Ch3.S5.p1.4.m1.1.1.cmml"><mi id="Ch3.S5.p1.4.m1.1.1.2" xref="Ch3.S5.p1.4.m1.1.1.2.cmml">u</mi><mn id="Ch3.S5.p1.4.m1.1.1.3" xref="Ch3.S5.p1.4.m1.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.4.m1.1b"><apply id="Ch3.S5.p1.4.m1.1.1.cmml" xref="Ch3.S5.p1.4.m1.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.4.m1.1.1.1.cmml" xref="Ch3.S5.p1.4.m1.1.1">superscript</csymbol><ci id="Ch3.S5.p1.4.m1.1.1.2.cmml" xref="Ch3.S5.p1.4.m1.1.1.2">𝑢</ci><cn type="integer" id="Ch3.S5.p1.4.m1.1.1.3.cmml" xref="Ch3.S5.p1.4.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.4.m1.1c">u^{0}</annotation></semantics></math> is initialized to be the initial description embedding <math id="Ch3.S5.p1.5.m2.1" class="ltx_Math" alttext="v_{d}" display="inline"><semantics id="Ch3.S5.p1.5.m2.1a"><msub id="Ch3.S5.p1.5.m2.1.1" xref="Ch3.S5.p1.5.m2.1.1.cmml"><mi id="Ch3.S5.p1.5.m2.1.1.2" xref="Ch3.S5.p1.5.m2.1.1.2.cmml">v</mi><mi id="Ch3.S5.p1.5.m2.1.1.3" xref="Ch3.S5.p1.5.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.5.m2.1b"><apply id="Ch3.S5.p1.5.m2.1.1.cmml" xref="Ch3.S5.p1.5.m2.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.5.m2.1.1.1.cmml" xref="Ch3.S5.p1.5.m2.1.1">subscript</csymbol><ci id="Ch3.S5.p1.5.m2.1.1.2.cmml" xref="Ch3.S5.p1.5.m2.1.1.2">𝑣</ci><ci id="Ch3.S5.p1.5.m2.1.1.3.cmml" xref="Ch3.S5.p1.5.m2.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.5.m2.1c">v_{d}</annotation></semantics></math>, <math id="Ch3.S5.p1.6.m3.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="Ch3.S5.p1.6.m3.1a"><msub id="Ch3.S5.p1.6.m3.1.1" xref="Ch3.S5.p1.6.m3.1.1.cmml"><mi id="Ch3.S5.p1.6.m3.1.1.2" xref="Ch3.S5.p1.6.m3.1.1.2.cmml">v</mi><mi id="Ch3.S5.p1.6.m3.1.1.3" xref="Ch3.S5.p1.6.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.6.m3.1b"><apply id="Ch3.S5.p1.6.m3.1.1.cmml" xref="Ch3.S5.p1.6.m3.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.6.m3.1.1.1.cmml" xref="Ch3.S5.p1.6.m3.1.1">subscript</csymbol><ci id="Ch3.S5.p1.6.m3.1.1.2.cmml" xref="Ch3.S5.p1.6.m3.1.1.2">𝑣</ci><ci id="Ch3.S5.p1.6.m3.1.1.3.cmml" xref="Ch3.S5.p1.6.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.6.m3.1c">v_{i}</annotation></semantics></math> are the image features, <math id="Ch3.S5.p1.7.m4.1" class="ltx_Math" alttext="h^{k}_{A}" display="inline"><semantics id="Ch3.S5.p1.7.m4.1a"><msubsup id="Ch3.S5.p1.7.m4.1.1" xref="Ch3.S5.p1.7.m4.1.1.cmml"><mi id="Ch3.S5.p1.7.m4.1.1.2.2" xref="Ch3.S5.p1.7.m4.1.1.2.2.cmml">h</mi><mi id="Ch3.S5.p1.7.m4.1.1.3" xref="Ch3.S5.p1.7.m4.1.1.3.cmml">A</mi><mi id="Ch3.S5.p1.7.m4.1.1.2.3" xref="Ch3.S5.p1.7.m4.1.1.2.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.7.m4.1b"><apply id="Ch3.S5.p1.7.m4.1.1.cmml" xref="Ch3.S5.p1.7.m4.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.7.m4.1.1.1.cmml" xref="Ch3.S5.p1.7.m4.1.1">subscript</csymbol><apply id="Ch3.S5.p1.7.m4.1.1.2.cmml" xref="Ch3.S5.p1.7.m4.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.7.m4.1.1.2.1.cmml" xref="Ch3.S5.p1.7.m4.1.1">superscript</csymbol><ci id="Ch3.S5.p1.7.m4.1.1.2.2.cmml" xref="Ch3.S5.p1.7.m4.1.1.2.2">ℎ</ci><ci id="Ch3.S5.p1.7.m4.1.1.2.3.cmml" xref="Ch3.S5.p1.7.m4.1.1.2.3">𝑘</ci></apply><ci id="Ch3.S5.p1.7.m4.1.1.3.cmml" xref="Ch3.S5.p1.7.m4.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.7.m4.1c">h^{k}_{A}</annotation></semantics></math> is the intermediate attention layer, <math id="Ch3.S5.p1.8.m5.1" class="ltx_Math" alttext="p^{k}_{I}" display="inline"><semantics id="Ch3.S5.p1.8.m5.1a"><msubsup id="Ch3.S5.p1.8.m5.1.1" xref="Ch3.S5.p1.8.m5.1.1.cmml"><mi id="Ch3.S5.p1.8.m5.1.1.2.2" xref="Ch3.S5.p1.8.m5.1.1.2.2.cmml">p</mi><mi id="Ch3.S5.p1.8.m5.1.1.3" xref="Ch3.S5.p1.8.m5.1.1.3.cmml">I</mi><mi id="Ch3.S5.p1.8.m5.1.1.2.3" xref="Ch3.S5.p1.8.m5.1.1.2.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.8.m5.1b"><apply id="Ch3.S5.p1.8.m5.1.1.cmml" xref="Ch3.S5.p1.8.m5.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.8.m5.1.1.1.cmml" xref="Ch3.S5.p1.8.m5.1.1">subscript</csymbol><apply id="Ch3.S5.p1.8.m5.1.1.2.cmml" xref="Ch3.S5.p1.8.m5.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.8.m5.1.1.2.1.cmml" xref="Ch3.S5.p1.8.m5.1.1">superscript</csymbol><ci id="Ch3.S5.p1.8.m5.1.1.2.2.cmml" xref="Ch3.S5.p1.8.m5.1.1.2.2">𝑝</ci><ci id="Ch3.S5.p1.8.m5.1.1.2.3.cmml" xref="Ch3.S5.p1.8.m5.1.1.2.3">𝑘</ci></apply><ci id="Ch3.S5.p1.8.m5.1.1.3.cmml" xref="Ch3.S5.p1.8.m5.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.8.m5.1c">p^{k}_{I}</annotation></semantics></math> is the probability distribution over each region, <math id="Ch3.S5.p1.9.m6.1" class="ltx_Math" alttext="\tilde{v}^{k}_{I}" display="inline"><semantics id="Ch3.S5.p1.9.m6.1a"><msubsup id="Ch3.S5.p1.9.m6.1.1" xref="Ch3.S5.p1.9.m6.1.1.cmml"><mover accent="true" id="Ch3.S5.p1.9.m6.1.1.2.2" xref="Ch3.S5.p1.9.m6.1.1.2.2.cmml"><mi id="Ch3.S5.p1.9.m6.1.1.2.2.2" xref="Ch3.S5.p1.9.m6.1.1.2.2.2.cmml">v</mi><mo id="Ch3.S5.p1.9.m6.1.1.2.2.1" xref="Ch3.S5.p1.9.m6.1.1.2.2.1.cmml">~</mo></mover><mi id="Ch3.S5.p1.9.m6.1.1.3" xref="Ch3.S5.p1.9.m6.1.1.3.cmml">I</mi><mi id="Ch3.S5.p1.9.m6.1.1.2.3" xref="Ch3.S5.p1.9.m6.1.1.2.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.9.m6.1b"><apply id="Ch3.S5.p1.9.m6.1.1.cmml" xref="Ch3.S5.p1.9.m6.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.9.m6.1.1.1.cmml" xref="Ch3.S5.p1.9.m6.1.1">subscript</csymbol><apply id="Ch3.S5.p1.9.m6.1.1.2.cmml" xref="Ch3.S5.p1.9.m6.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.9.m6.1.1.2.1.cmml" xref="Ch3.S5.p1.9.m6.1.1">superscript</csymbol><apply id="Ch3.S5.p1.9.m6.1.1.2.2.cmml" xref="Ch3.S5.p1.9.m6.1.1.2.2"><ci id="Ch3.S5.p1.9.m6.1.1.2.2.1.cmml" xref="Ch3.S5.p1.9.m6.1.1.2.2.1">~</ci><ci id="Ch3.S5.p1.9.m6.1.1.2.2.2.cmml" xref="Ch3.S5.p1.9.m6.1.1.2.2.2">𝑣</ci></apply><ci id="Ch3.S5.p1.9.m6.1.1.2.3.cmml" xref="Ch3.S5.p1.9.m6.1.1.2.3">𝑘</ci></apply><ci id="Ch3.S5.p1.9.m6.1.1.3.cmml" xref="Ch3.S5.p1.9.m6.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.9.m6.1c">\tilde{v}^{k}_{I}</annotation></semantics></math> is the weighted sum of the attention distribution and the image features and <math id="Ch3.S5.p1.10.m7.1" class="ltx_Math" alttext="u^{k}" display="inline"><semantics id="Ch3.S5.p1.10.m7.1a"><msup id="Ch3.S5.p1.10.m7.1.1" xref="Ch3.S5.p1.10.m7.1.1.cmml"><mi id="Ch3.S5.p1.10.m7.1.1.2" xref="Ch3.S5.p1.10.m7.1.1.2.cmml">u</mi><mi id="Ch3.S5.p1.10.m7.1.1.3" xref="Ch3.S5.p1.10.m7.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.10.m7.1b"><apply id="Ch3.S5.p1.10.m7.1.1.cmml" xref="Ch3.S5.p1.10.m7.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.10.m7.1.1.1.cmml" xref="Ch3.S5.p1.10.m7.1.1">superscript</csymbol><ci id="Ch3.S5.p1.10.m7.1.1.2.cmml" xref="Ch3.S5.p1.10.m7.1.1.2">𝑢</ci><ci id="Ch3.S5.p1.10.m7.1.1.3.cmml" xref="Ch3.S5.p1.10.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.10.m7.1c">u^{k}</annotation></semantics></math> is the new query. <math id="Ch3.S5.p1.11.m8.7" class="ltx_Math" alttext="W^{k}_{I,A},W^{k}_{Q,A},W^{k}" display="inline"><semantics id="Ch3.S5.p1.11.m8.7a"><mrow id="Ch3.S5.p1.11.m8.7.7.3" xref="Ch3.S5.p1.11.m8.7.7.4.cmml"><msubsup id="Ch3.S5.p1.11.m8.5.5.1.1" xref="Ch3.S5.p1.11.m8.5.5.1.1.cmml"><mi id="Ch3.S5.p1.11.m8.5.5.1.1.2.2" xref="Ch3.S5.p1.11.m8.5.5.1.1.2.2.cmml">W</mi><mrow id="Ch3.S5.p1.11.m8.2.2.2.4" xref="Ch3.S5.p1.11.m8.2.2.2.3.cmml"><mi id="Ch3.S5.p1.11.m8.1.1.1.1" xref="Ch3.S5.p1.11.m8.1.1.1.1.cmml">I</mi><mo id="Ch3.S5.p1.11.m8.2.2.2.4.1" xref="Ch3.S5.p1.11.m8.2.2.2.3.cmml">,</mo><mi id="Ch3.S5.p1.11.m8.2.2.2.2" xref="Ch3.S5.p1.11.m8.2.2.2.2.cmml">A</mi></mrow><mi id="Ch3.S5.p1.11.m8.5.5.1.1.2.3" xref="Ch3.S5.p1.11.m8.5.5.1.1.2.3.cmml">k</mi></msubsup><mo id="Ch3.S5.p1.11.m8.7.7.3.4" xref="Ch3.S5.p1.11.m8.7.7.4.cmml">,</mo><msubsup id="Ch3.S5.p1.11.m8.6.6.2.2" xref="Ch3.S5.p1.11.m8.6.6.2.2.cmml"><mi id="Ch3.S5.p1.11.m8.6.6.2.2.2.2" xref="Ch3.S5.p1.11.m8.6.6.2.2.2.2.cmml">W</mi><mrow id="Ch3.S5.p1.11.m8.4.4.2.4" xref="Ch3.S5.p1.11.m8.4.4.2.3.cmml"><mi id="Ch3.S5.p1.11.m8.3.3.1.1" xref="Ch3.S5.p1.11.m8.3.3.1.1.cmml">Q</mi><mo id="Ch3.S5.p1.11.m8.4.4.2.4.1" xref="Ch3.S5.p1.11.m8.4.4.2.3.cmml">,</mo><mi id="Ch3.S5.p1.11.m8.4.4.2.2" xref="Ch3.S5.p1.11.m8.4.4.2.2.cmml">A</mi></mrow><mi id="Ch3.S5.p1.11.m8.6.6.2.2.2.3" xref="Ch3.S5.p1.11.m8.6.6.2.2.2.3.cmml">k</mi></msubsup><mo id="Ch3.S5.p1.11.m8.7.7.3.5" xref="Ch3.S5.p1.11.m8.7.7.4.cmml">,</mo><msup id="Ch3.S5.p1.11.m8.7.7.3.3" xref="Ch3.S5.p1.11.m8.7.7.3.3.cmml"><mi id="Ch3.S5.p1.11.m8.7.7.3.3.2" xref="Ch3.S5.p1.11.m8.7.7.3.3.2.cmml">W</mi><mi id="Ch3.S5.p1.11.m8.7.7.3.3.3" xref="Ch3.S5.p1.11.m8.7.7.3.3.3.cmml">k</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.11.m8.7b"><list id="Ch3.S5.p1.11.m8.7.7.4.cmml" xref="Ch3.S5.p1.11.m8.7.7.3"><apply id="Ch3.S5.p1.11.m8.5.5.1.1.cmml" xref="Ch3.S5.p1.11.m8.5.5.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.11.m8.5.5.1.1.1.cmml" xref="Ch3.S5.p1.11.m8.5.5.1.1">subscript</csymbol><apply id="Ch3.S5.p1.11.m8.5.5.1.1.2.cmml" xref="Ch3.S5.p1.11.m8.5.5.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.11.m8.5.5.1.1.2.1.cmml" xref="Ch3.S5.p1.11.m8.5.5.1.1">superscript</csymbol><ci id="Ch3.S5.p1.11.m8.5.5.1.1.2.2.cmml" xref="Ch3.S5.p1.11.m8.5.5.1.1.2.2">𝑊</ci><ci id="Ch3.S5.p1.11.m8.5.5.1.1.2.3.cmml" xref="Ch3.S5.p1.11.m8.5.5.1.1.2.3">𝑘</ci></apply><list id="Ch3.S5.p1.11.m8.2.2.2.3.cmml" xref="Ch3.S5.p1.11.m8.2.2.2.4"><ci id="Ch3.S5.p1.11.m8.1.1.1.1.cmml" xref="Ch3.S5.p1.11.m8.1.1.1.1">𝐼</ci><ci id="Ch3.S5.p1.11.m8.2.2.2.2.cmml" xref="Ch3.S5.p1.11.m8.2.2.2.2">𝐴</ci></list></apply><apply id="Ch3.S5.p1.11.m8.6.6.2.2.cmml" xref="Ch3.S5.p1.11.m8.6.6.2.2"><csymbol cd="ambiguous" id="Ch3.S5.p1.11.m8.6.6.2.2.1.cmml" xref="Ch3.S5.p1.11.m8.6.6.2.2">subscript</csymbol><apply id="Ch3.S5.p1.11.m8.6.6.2.2.2.cmml" xref="Ch3.S5.p1.11.m8.6.6.2.2"><csymbol cd="ambiguous" id="Ch3.S5.p1.11.m8.6.6.2.2.2.1.cmml" xref="Ch3.S5.p1.11.m8.6.6.2.2">superscript</csymbol><ci id="Ch3.S5.p1.11.m8.6.6.2.2.2.2.cmml" xref="Ch3.S5.p1.11.m8.6.6.2.2.2.2">𝑊</ci><ci id="Ch3.S5.p1.11.m8.6.6.2.2.2.3.cmml" xref="Ch3.S5.p1.11.m8.6.6.2.2.2.3">𝑘</ci></apply><list id="Ch3.S5.p1.11.m8.4.4.2.3.cmml" xref="Ch3.S5.p1.11.m8.4.4.2.4"><ci id="Ch3.S5.p1.11.m8.3.3.1.1.cmml" xref="Ch3.S5.p1.11.m8.3.3.1.1">𝑄</ci><ci id="Ch3.S5.p1.11.m8.4.4.2.2.cmml" xref="Ch3.S5.p1.11.m8.4.4.2.2">𝐴</ci></list></apply><apply id="Ch3.S5.p1.11.m8.7.7.3.3.cmml" xref="Ch3.S5.p1.11.m8.7.7.3.3"><csymbol cd="ambiguous" id="Ch3.S5.p1.11.m8.7.7.3.3.1.cmml" xref="Ch3.S5.p1.11.m8.7.7.3.3">superscript</csymbol><ci id="Ch3.S5.p1.11.m8.7.7.3.3.2.cmml" xref="Ch3.S5.p1.11.m8.7.7.3.3.2">𝑊</ci><ci id="Ch3.S5.p1.11.m8.7.7.3.3.3.cmml" xref="Ch3.S5.p1.11.m8.7.7.3.3.3">𝑘</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.11.m8.7c">W^{k}_{I,A},W^{k}_{Q,A},W^{k}</annotation></semantics></math> are weight matrices and <math id="Ch3.S5.p1.12.m9.2" class="ltx_Math" alttext="b^{k}_{A},b^{k}_{P}" display="inline"><semantics id="Ch3.S5.p1.12.m9.2a"><mrow id="Ch3.S5.p1.12.m9.2.2.2" xref="Ch3.S5.p1.12.m9.2.2.3.cmml"><msubsup id="Ch3.S5.p1.12.m9.1.1.1.1" xref="Ch3.S5.p1.12.m9.1.1.1.1.cmml"><mi id="Ch3.S5.p1.12.m9.1.1.1.1.2.2" xref="Ch3.S5.p1.12.m9.1.1.1.1.2.2.cmml">b</mi><mi id="Ch3.S5.p1.12.m9.1.1.1.1.3" xref="Ch3.S5.p1.12.m9.1.1.1.1.3.cmml">A</mi><mi id="Ch3.S5.p1.12.m9.1.1.1.1.2.3" xref="Ch3.S5.p1.12.m9.1.1.1.1.2.3.cmml">k</mi></msubsup><mo id="Ch3.S5.p1.12.m9.2.2.2.3" xref="Ch3.S5.p1.12.m9.2.2.3.cmml">,</mo><msubsup id="Ch3.S5.p1.12.m9.2.2.2.2" xref="Ch3.S5.p1.12.m9.2.2.2.2.cmml"><mi id="Ch3.S5.p1.12.m9.2.2.2.2.2.2" xref="Ch3.S5.p1.12.m9.2.2.2.2.2.2.cmml">b</mi><mi id="Ch3.S5.p1.12.m9.2.2.2.2.3" xref="Ch3.S5.p1.12.m9.2.2.2.2.3.cmml">P</mi><mi id="Ch3.S5.p1.12.m9.2.2.2.2.2.3" xref="Ch3.S5.p1.12.m9.2.2.2.2.2.3.cmml">k</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.12.m9.2b"><list id="Ch3.S5.p1.12.m9.2.2.3.cmml" xref="Ch3.S5.p1.12.m9.2.2.2"><apply id="Ch3.S5.p1.12.m9.1.1.1.1.cmml" xref="Ch3.S5.p1.12.m9.1.1.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.12.m9.1.1.1.1.1.cmml" xref="Ch3.S5.p1.12.m9.1.1.1.1">subscript</csymbol><apply id="Ch3.S5.p1.12.m9.1.1.1.1.2.cmml" xref="Ch3.S5.p1.12.m9.1.1.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.12.m9.1.1.1.1.2.1.cmml" xref="Ch3.S5.p1.12.m9.1.1.1.1">superscript</csymbol><ci id="Ch3.S5.p1.12.m9.1.1.1.1.2.2.cmml" xref="Ch3.S5.p1.12.m9.1.1.1.1.2.2">𝑏</ci><ci id="Ch3.S5.p1.12.m9.1.1.1.1.2.3.cmml" xref="Ch3.S5.p1.12.m9.1.1.1.1.2.3">𝑘</ci></apply><ci id="Ch3.S5.p1.12.m9.1.1.1.1.3.cmml" xref="Ch3.S5.p1.12.m9.1.1.1.1.3">𝐴</ci></apply><apply id="Ch3.S5.p1.12.m9.2.2.2.2.cmml" xref="Ch3.S5.p1.12.m9.2.2.2.2"><csymbol cd="ambiguous" id="Ch3.S5.p1.12.m9.2.2.2.2.1.cmml" xref="Ch3.S5.p1.12.m9.2.2.2.2">subscript</csymbol><apply id="Ch3.S5.p1.12.m9.2.2.2.2.2.cmml" xref="Ch3.S5.p1.12.m9.2.2.2.2"><csymbol cd="ambiguous" id="Ch3.S5.p1.12.m9.2.2.2.2.2.1.cmml" xref="Ch3.S5.p1.12.m9.2.2.2.2">superscript</csymbol><ci id="Ch3.S5.p1.12.m9.2.2.2.2.2.2.cmml" xref="Ch3.S5.p1.12.m9.2.2.2.2.2.2">𝑏</ci><ci id="Ch3.S5.p1.12.m9.2.2.2.2.2.3.cmml" xref="Ch3.S5.p1.12.m9.2.2.2.2.2.3">𝑘</ci></apply><ci id="Ch3.S5.p1.12.m9.2.2.2.2.3.cmml" xref="Ch3.S5.p1.12.m9.2.2.2.2.3">𝑃</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.12.m9.2c">b^{k}_{A},b^{k}_{P}</annotation></semantics></math> are biases and together they are the learnable parameteres of the attention mechanism.
This is repeated for <math id="Ch3.S5.p1.13.m10.1" class="ltx_Math" alttext="K" display="inline"><semantics id="Ch3.S5.p1.13.m10.1a"><mi id="Ch3.S5.p1.13.m10.1.1" xref="Ch3.S5.p1.13.m10.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.13.m10.1b"><ci id="Ch3.S5.p1.13.m10.1.1.cmml" xref="Ch3.S5.p1.13.m10.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.13.m10.1c">K</annotation></semantics></math> times and then the final <math id="Ch3.S5.p1.14.m11.1" class="ltx_Math" alttext="u^{K}" display="inline"><semantics id="Ch3.S5.p1.14.m11.1a"><msup id="Ch3.S5.p1.14.m11.1.1" xref="Ch3.S5.p1.14.m11.1.1.cmml"><mi id="Ch3.S5.p1.14.m11.1.1.2" xref="Ch3.S5.p1.14.m11.1.1.2.cmml">u</mi><mi id="Ch3.S5.p1.14.m11.1.1.3" xref="Ch3.S5.p1.14.m11.1.1.3.cmml">K</mi></msup><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.14.m11.1b"><apply id="Ch3.S5.p1.14.m11.1.1.cmml" xref="Ch3.S5.p1.14.m11.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.14.m11.1.1.1.cmml" xref="Ch3.S5.p1.14.m11.1.1">superscript</csymbol><ci id="Ch3.S5.p1.14.m11.1.1.2.cmml" xref="Ch3.S5.p1.14.m11.1.1.2">𝑢</ci><ci id="Ch3.S5.p1.14.m11.1.1.3.cmml" xref="Ch3.S5.p1.14.m11.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.14.m11.1c">u^{K}</annotation></semantics></math> will be used as one of the inputs to a Siamese neural network. Same as the second model, to train the Siamese neural network, for each item in the pair of similar or dissimilar records, we will need to obtain <math id="Ch3.S5.p1.15.m12.1" class="ltx_Math" alttext="u^{K}" display="inline"><semantics id="Ch3.S5.p1.15.m12.1a"><msup id="Ch3.S5.p1.15.m12.1.1" xref="Ch3.S5.p1.15.m12.1.1.cmml"><mi id="Ch3.S5.p1.15.m12.1.1.2" xref="Ch3.S5.p1.15.m12.1.1.2.cmml">u</mi><mi id="Ch3.S5.p1.15.m12.1.1.3" xref="Ch3.S5.p1.15.m12.1.1.3.cmml">K</mi></msup><annotation-xml encoding="MathML-Content" id="Ch3.S5.p1.15.m12.1b"><apply id="Ch3.S5.p1.15.m12.1.1.cmml" xref="Ch3.S5.p1.15.m12.1.1"><csymbol cd="ambiguous" id="Ch3.S5.p1.15.m12.1.1.1.cmml" xref="Ch3.S5.p1.15.m12.1.1">superscript</csymbol><ci id="Ch3.S5.p1.15.m12.1.1.2.cmml" xref="Ch3.S5.p1.15.m12.1.1.2">𝑢</ci><ci id="Ch3.S5.p1.15.m12.1.1.3.cmml" xref="Ch3.S5.p1.15.m12.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.S5.p1.15.m12.1c">u^{K}</annotation></semantics></math> for both entities. In Figure <a href="#Ch3.F3" title="Figure 3.3 ‣ 3.5 Stacked Attention Network fusion module ‣ Chapter 3 Methodology ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> we illustrate a single attention layer SAN network module.</p>
</div>
<figure id="Ch3.F3" class="ltx_figure"><img src="/html/2007.05881/assets/x5.png" id="Ch3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.3: </span>An illustration of the Stacked Neural Network fusion module. The GRU is used to create a description encoding and a pre-trained VGG-19 to extract a vector representation of the image features.</figcaption>
</figure>
</section>
</section>
<section id="Ch4" class="ltx_chapter">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 4 </span>Results and Evaluation</h2>

<section id="Ch4.S1" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.1 </span>Evaluation Metric</h3>

<div id="Ch4.S1.p1" class="ltx_para">
<p id="Ch4.S1.p1.4" class="ltx_p">Before we present all the results that we gathered from our experiments we will explain our evaluation metric. Record linkage is a binary classification problem and we decided to use Average Precision Score to evaluate our models. In the following section, we will refer to class 1 as the positive class (the pair of items is similar) and class 0 as the negative class (the pair of items is not similar). Average Precision Score summarizes the area under the Precision-Recall curve as the weighted mean of precisions achieved at different thresholds, with the increase in recall from the previous threshold used as the weight <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>:</p>
<table id="Ch4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch4.E1.m1.1" class="ltx_Math" alttext="\text{AP}=\sum_{n}(R_{n}-R_{n-1})P_{n}" display="block"><semantics id="Ch4.E1.m1.1a"><mrow id="Ch4.E1.m1.1.1" xref="Ch4.E1.m1.1.1.cmml"><mtext id="Ch4.E1.m1.1.1.3" xref="Ch4.E1.m1.1.1.3a.cmml">AP</mtext><mo rspace="0.111em" id="Ch4.E1.m1.1.1.2" xref="Ch4.E1.m1.1.1.2.cmml">=</mo><mrow id="Ch4.E1.m1.1.1.1" xref="Ch4.E1.m1.1.1.1.cmml"><munder id="Ch4.E1.m1.1.1.1.2" xref="Ch4.E1.m1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="Ch4.E1.m1.1.1.1.2.2" xref="Ch4.E1.m1.1.1.1.2.2.cmml">∑</mo><mi id="Ch4.E1.m1.1.1.1.2.3" xref="Ch4.E1.m1.1.1.1.2.3.cmml">n</mi></munder><mrow id="Ch4.E1.m1.1.1.1.1" xref="Ch4.E1.m1.1.1.1.1.cmml"><mrow id="Ch4.E1.m1.1.1.1.1.1.1" xref="Ch4.E1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch4.E1.m1.1.1.1.1.1.1.2" xref="Ch4.E1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch4.E1.m1.1.1.1.1.1.1.1" xref="Ch4.E1.m1.1.1.1.1.1.1.1.cmml"><msub id="Ch4.E1.m1.1.1.1.1.1.1.1.2" xref="Ch4.E1.m1.1.1.1.1.1.1.1.2.cmml"><mi id="Ch4.E1.m1.1.1.1.1.1.1.1.2.2" xref="Ch4.E1.m1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mi id="Ch4.E1.m1.1.1.1.1.1.1.1.2.3" xref="Ch4.E1.m1.1.1.1.1.1.1.1.2.3.cmml">n</mi></msub><mo id="Ch4.E1.m1.1.1.1.1.1.1.1.1" xref="Ch4.E1.m1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="Ch4.E1.m1.1.1.1.1.1.1.1.3" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch4.E1.m1.1.1.1.1.1.1.1.3.2" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.2.cmml">R</mi><mrow id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.cmml"><mi id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.2" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.2.cmml">n</mi><mo id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.1" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.3" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo stretchy="false" id="Ch4.E1.m1.1.1.1.1.1.1.3" xref="Ch4.E1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="Ch4.E1.m1.1.1.1.1.2" xref="Ch4.E1.m1.1.1.1.1.2.cmml">​</mo><msub id="Ch4.E1.m1.1.1.1.1.3" xref="Ch4.E1.m1.1.1.1.1.3.cmml"><mi id="Ch4.E1.m1.1.1.1.1.3.2" xref="Ch4.E1.m1.1.1.1.1.3.2.cmml">P</mi><mi id="Ch4.E1.m1.1.1.1.1.3.3" xref="Ch4.E1.m1.1.1.1.1.3.3.cmml">n</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E1.m1.1b"><apply id="Ch4.E1.m1.1.1.cmml" xref="Ch4.E1.m1.1.1"><eq id="Ch4.E1.m1.1.1.2.cmml" xref="Ch4.E1.m1.1.1.2"></eq><ci id="Ch4.E1.m1.1.1.3a.cmml" xref="Ch4.E1.m1.1.1.3"><mtext id="Ch4.E1.m1.1.1.3.cmml" xref="Ch4.E1.m1.1.1.3">AP</mtext></ci><apply id="Ch4.E1.m1.1.1.1.cmml" xref="Ch4.E1.m1.1.1.1"><apply id="Ch4.E1.m1.1.1.1.2.cmml" xref="Ch4.E1.m1.1.1.1.2"><csymbol cd="ambiguous" id="Ch4.E1.m1.1.1.1.2.1.cmml" xref="Ch4.E1.m1.1.1.1.2">subscript</csymbol><sum id="Ch4.E1.m1.1.1.1.2.2.cmml" xref="Ch4.E1.m1.1.1.1.2.2"></sum><ci id="Ch4.E1.m1.1.1.1.2.3.cmml" xref="Ch4.E1.m1.1.1.1.2.3">𝑛</ci></apply><apply id="Ch4.E1.m1.1.1.1.1.cmml" xref="Ch4.E1.m1.1.1.1.1"><times id="Ch4.E1.m1.1.1.1.1.2.cmml" xref="Ch4.E1.m1.1.1.1.1.2"></times><apply id="Ch4.E1.m1.1.1.1.1.1.1.1.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1"><minus id="Ch4.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.1"></minus><apply id="Ch4.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch4.E1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="Ch4.E1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.2.2">𝑅</ci><ci id="Ch4.E1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.2.3">𝑛</ci></apply><apply id="Ch4.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch4.E1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch4.E1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.2">𝑅</ci><apply id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3"><minus id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.1"></minus><ci id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.2">𝑛</ci><cn type="integer" id="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="Ch4.E1.m1.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply><apply id="Ch4.E1.m1.1.1.1.1.3.cmml" xref="Ch4.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch4.E1.m1.1.1.1.1.3.1.cmml" xref="Ch4.E1.m1.1.1.1.1.3">subscript</csymbol><ci id="Ch4.E1.m1.1.1.1.1.3.2.cmml" xref="Ch4.E1.m1.1.1.1.1.3.2">𝑃</ci><ci id="Ch4.E1.m1.1.1.1.1.3.3.cmml" xref="Ch4.E1.m1.1.1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E1.m1.1c">\text{AP}=\sum_{n}(R_{n}-R_{n-1})P_{n}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.1)</span></td>
</tr></tbody>
</table>
<p id="Ch4.S1.p1.3" class="ltx_p">where <math id="Ch4.S1.p1.1.m1.1" class="ltx_Math" alttext="P_{n}" display="inline"><semantics id="Ch4.S1.p1.1.m1.1a"><msub id="Ch4.S1.p1.1.m1.1.1" xref="Ch4.S1.p1.1.m1.1.1.cmml"><mi id="Ch4.S1.p1.1.m1.1.1.2" xref="Ch4.S1.p1.1.m1.1.1.2.cmml">P</mi><mi id="Ch4.S1.p1.1.m1.1.1.3" xref="Ch4.S1.p1.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.p1.1.m1.1b"><apply id="Ch4.S1.p1.1.m1.1.1.cmml" xref="Ch4.S1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Ch4.S1.p1.1.m1.1.1.1.cmml" xref="Ch4.S1.p1.1.m1.1.1">subscript</csymbol><ci id="Ch4.S1.p1.1.m1.1.1.2.cmml" xref="Ch4.S1.p1.1.m1.1.1.2">𝑃</ci><ci id="Ch4.S1.p1.1.m1.1.1.3.cmml" xref="Ch4.S1.p1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.p1.1.m1.1c">P_{n}</annotation></semantics></math> and <math id="Ch4.S1.p1.2.m2.1" class="ltx_Math" alttext="R_{n}" display="inline"><semantics id="Ch4.S1.p1.2.m2.1a"><msub id="Ch4.S1.p1.2.m2.1.1" xref="Ch4.S1.p1.2.m2.1.1.cmml"><mi id="Ch4.S1.p1.2.m2.1.1.2" xref="Ch4.S1.p1.2.m2.1.1.2.cmml">R</mi><mi id="Ch4.S1.p1.2.m2.1.1.3" xref="Ch4.S1.p1.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.p1.2.m2.1b"><apply id="Ch4.S1.p1.2.m2.1.1.cmml" xref="Ch4.S1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Ch4.S1.p1.2.m2.1.1.1.cmml" xref="Ch4.S1.p1.2.m2.1.1">subscript</csymbol><ci id="Ch4.S1.p1.2.m2.1.1.2.cmml" xref="Ch4.S1.p1.2.m2.1.1.2">𝑅</ci><ci id="Ch4.S1.p1.2.m2.1.1.3.cmml" xref="Ch4.S1.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.p1.2.m2.1c">R_{n}</annotation></semantics></math> are the precision and recall at the <math id="Ch4.S1.p1.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="Ch4.S1.p1.3.m3.1a"><mi id="Ch4.S1.p1.3.m3.1.1" xref="Ch4.S1.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.p1.3.m3.1b"><ci id="Ch4.S1.p1.3.m3.1.1.cmml" xref="Ch4.S1.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.p1.3.m3.1c">n</annotation></semantics></math>-th threshold. Precision and Recall gives us information about the ratios of true positives <span id="Ch4.S1.p1.3.1" class="ltx_text ltx_font_italic">TP</span>, false positives <span id="Ch4.S1.p1.3.2" class="ltx_text ltx_font_italic">FP</span> and false negatives <span id="Ch4.S1.p1.3.3" class="ltx_text ltx_font_italic">FN</span>. <span id="Ch4.S1.p1.3.4" class="ltx_text ltx_font_italic">TP</span> is the number of examples that were positive and that the model classified as positive, <span id="Ch4.S1.p1.3.5" class="ltx_text ltx_font_bold">FP</span> is the number of examples that were negative but the model predicted that they were positive and <span id="Ch4.S1.p1.3.6" class="ltx_text ltx_font_italic">FN</span> is the number of examples that were positive but the model predicted that they were negative. Precision is calculated as:</p>
<table id="Ch4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch4.E2.m1.1" class="ltx_Math" alttext="\text{P}=\frac{\textit{TP}}{(\textit{TP}+\textit{FP})}" display="block"><semantics id="Ch4.E2.m1.1a"><mrow id="Ch4.E2.m1.1.2" xref="Ch4.E2.m1.1.2.cmml"><mtext id="Ch4.E2.m1.1.2.2" xref="Ch4.E2.m1.1.2.2a.cmml">P</mtext><mo id="Ch4.E2.m1.1.2.1" xref="Ch4.E2.m1.1.2.1.cmml">=</mo><mfrac id="Ch4.E2.m1.1.1" xref="Ch4.E2.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="Ch4.E2.m1.1.1.3" xref="Ch4.E2.m1.1.1.3a.cmml">TP</mtext><mrow id="Ch4.E2.m1.1.1.1.1" xref="Ch4.E2.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch4.E2.m1.1.1.1.1.2" xref="Ch4.E2.m1.1.1.1.1.1.cmml">(</mo><mrow id="Ch4.E2.m1.1.1.1.1.1" xref="Ch4.E2.m1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="Ch4.E2.m1.1.1.1.1.1.2" xref="Ch4.E2.m1.1.1.1.1.1.2a.cmml">TP</mtext><mo id="Ch4.E2.m1.1.1.1.1.1.1" xref="Ch4.E2.m1.1.1.1.1.1.1.cmml">+</mo><mtext class="ltx_mathvariant_italic" id="Ch4.E2.m1.1.1.1.1.1.3" xref="Ch4.E2.m1.1.1.1.1.1.3a.cmml">FP</mtext></mrow><mo stretchy="false" id="Ch4.E2.m1.1.1.1.1.3" xref="Ch4.E2.m1.1.1.1.1.1.cmml">)</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E2.m1.1b"><apply id="Ch4.E2.m1.1.2.cmml" xref="Ch4.E2.m1.1.2"><eq id="Ch4.E2.m1.1.2.1.cmml" xref="Ch4.E2.m1.1.2.1"></eq><ci id="Ch4.E2.m1.1.2.2a.cmml" xref="Ch4.E2.m1.1.2.2"><mtext id="Ch4.E2.m1.1.2.2.cmml" xref="Ch4.E2.m1.1.2.2">P</mtext></ci><apply id="Ch4.E2.m1.1.1.cmml" xref="Ch4.E2.m1.1.1"><divide id="Ch4.E2.m1.1.1.2.cmml" xref="Ch4.E2.m1.1.1"></divide><ci id="Ch4.E2.m1.1.1.3a.cmml" xref="Ch4.E2.m1.1.1.3"><mtext class="ltx_mathvariant_italic" id="Ch4.E2.m1.1.1.3.cmml" xref="Ch4.E2.m1.1.1.3">TP</mtext></ci><apply id="Ch4.E2.m1.1.1.1.1.1.cmml" xref="Ch4.E2.m1.1.1.1.1"><plus id="Ch4.E2.m1.1.1.1.1.1.1.cmml" xref="Ch4.E2.m1.1.1.1.1.1.1"></plus><ci id="Ch4.E2.m1.1.1.1.1.1.2a.cmml" xref="Ch4.E2.m1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_italic" id="Ch4.E2.m1.1.1.1.1.1.2.cmml" xref="Ch4.E2.m1.1.1.1.1.1.2">TP</mtext></ci><ci id="Ch4.E2.m1.1.1.1.1.1.3a.cmml" xref="Ch4.E2.m1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="Ch4.E2.m1.1.1.1.1.1.3.cmml" xref="Ch4.E2.m1.1.1.1.1.1.3">FP</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E2.m1.1c">\text{P}=\frac{\textit{TP}}{(\textit{TP}+\textit{FP})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.2)</span></td>
</tr></tbody>
</table>
<p id="Ch4.S1.p1.5" class="ltx_p">It describes how good the model is at predicting the positive class, which in our case is class 1, the less represented class. Recall is calculated as:</p>
<table id="Ch4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch4.E3.m1.1" class="ltx_Math" alttext="\text{R}=\frac{\textit{TP}}{(\textit{TP}+\textit{FN})}" display="block"><semantics id="Ch4.E3.m1.1a"><mrow id="Ch4.E3.m1.1.2" xref="Ch4.E3.m1.1.2.cmml"><mtext id="Ch4.E3.m1.1.2.2" xref="Ch4.E3.m1.1.2.2a.cmml">R</mtext><mo id="Ch4.E3.m1.1.2.1" xref="Ch4.E3.m1.1.2.1.cmml">=</mo><mfrac id="Ch4.E3.m1.1.1" xref="Ch4.E3.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="Ch4.E3.m1.1.1.3" xref="Ch4.E3.m1.1.1.3a.cmml">TP</mtext><mrow id="Ch4.E3.m1.1.1.1.1" xref="Ch4.E3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch4.E3.m1.1.1.1.1.2" xref="Ch4.E3.m1.1.1.1.1.1.cmml">(</mo><mrow id="Ch4.E3.m1.1.1.1.1.1" xref="Ch4.E3.m1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="Ch4.E3.m1.1.1.1.1.1.2" xref="Ch4.E3.m1.1.1.1.1.1.2a.cmml">TP</mtext><mo id="Ch4.E3.m1.1.1.1.1.1.1" xref="Ch4.E3.m1.1.1.1.1.1.1.cmml">+</mo><mtext class="ltx_mathvariant_italic" id="Ch4.E3.m1.1.1.1.1.1.3" xref="Ch4.E3.m1.1.1.1.1.1.3a.cmml">FN</mtext></mrow><mo stretchy="false" id="Ch4.E3.m1.1.1.1.1.3" xref="Ch4.E3.m1.1.1.1.1.1.cmml">)</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E3.m1.1b"><apply id="Ch4.E3.m1.1.2.cmml" xref="Ch4.E3.m1.1.2"><eq id="Ch4.E3.m1.1.2.1.cmml" xref="Ch4.E3.m1.1.2.1"></eq><ci id="Ch4.E3.m1.1.2.2a.cmml" xref="Ch4.E3.m1.1.2.2"><mtext id="Ch4.E3.m1.1.2.2.cmml" xref="Ch4.E3.m1.1.2.2">R</mtext></ci><apply id="Ch4.E3.m1.1.1.cmml" xref="Ch4.E3.m1.1.1"><divide id="Ch4.E3.m1.1.1.2.cmml" xref="Ch4.E3.m1.1.1"></divide><ci id="Ch4.E3.m1.1.1.3a.cmml" xref="Ch4.E3.m1.1.1.3"><mtext class="ltx_mathvariant_italic" id="Ch4.E3.m1.1.1.3.cmml" xref="Ch4.E3.m1.1.1.3">TP</mtext></ci><apply id="Ch4.E3.m1.1.1.1.1.1.cmml" xref="Ch4.E3.m1.1.1.1.1"><plus id="Ch4.E3.m1.1.1.1.1.1.1.cmml" xref="Ch4.E3.m1.1.1.1.1.1.1"></plus><ci id="Ch4.E3.m1.1.1.1.1.1.2a.cmml" xref="Ch4.E3.m1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_italic" id="Ch4.E3.m1.1.1.1.1.1.2.cmml" xref="Ch4.E3.m1.1.1.1.1.1.2">TP</mtext></ci><ci id="Ch4.E3.m1.1.1.1.1.1.3a.cmml" xref="Ch4.E3.m1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="Ch4.E3.m1.1.1.1.1.1.3.cmml" xref="Ch4.E3.m1.1.1.1.1.1.3">FN</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E3.m1.1c">\text{R}=\frac{\textit{TP}}{(\textit{TP}+\textit{FN})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.3)</span></td>
</tr></tbody>
</table>
<p id="Ch4.S1.p1.6" class="ltx_p">Recall measures the proportion of true positives that are correctly identified and it is also referred to as sensitivity. Precision usually refers to precision at a certain threshold. For example, if we classify any output of the model that is less then 0.5 as negative and positive if the output is greater then 0.5, then the precision score is accurate only for threshold = 0.5. If we were to change the threshold, the precision score would change. When the class distribution is unbalanced (as in our case) we would like to vary this threshold, to get a better understanding of how the model is performing. Average Precision Score gives us the average precision at all such possible thresholds, without having to specify the decision thresholds. This implementation <a href="#Ch4.E1" title="In 4.1 Evaluation Metric ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> is not interpolated and is different from computing the area under the precision-recall curve with the trapezoidal rule, which uses linear interpolation and can be too optimistic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Even though we choose the models based on the Average Precision Score, we compare the Precision-Recall curves for each of the models we propose, to get a better visualization of the performance of our model. The Precision-Recall curve shows the tradeoff between precision and recall at different thresholds. A large area under the curve means that both recall and precision are high, where high precision relates to a low <span id="Ch4.S1.p1.6.1" class="ltx_text ltx_font_bold">FP</span> rate, and high recall relates to low <span id="Ch4.S1.p1.6.2" class="ltx_text ltx_font_bold">FN</span> rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
</section>
<section id="Ch4.S2" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.2 </span>Baseline Model</h3>

<div id="Ch4.S2.p1" class="ltx_para">
<p id="Ch4.S2.p1.1" class="ltx_p">The baseline model is a logistic regression model trained on a training data set with two hand-crafted features (Euclidian distance between the image feature vectors of advertisements and Jaccard similarity coefficient between the descriptions of the advertisements in the pair). The baseline model achieved an average precision score of <span id="Ch4.S2.p1.1.1" class="ltx_text ltx_font_bold">0.4776</span> on the <span id="Ch4.S2.p1.1.2" class="ltx_text ltx_font_bold">training set</span> and an average precision score of <span id="Ch4.S2.p1.1.3" class="ltx_text ltx_font_bold">0.4808</span> on the <span id="Ch4.S2.p1.1.4" class="ltx_text ltx_font_bold">test set</span>. Figures <a href="#Ch4.F1" title="Figure 4.1 ‣ Figure 4.5 ‣ 4.2 Baseline Model ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> and <a href="#Ch4.F3" title="Figure 4.3 ‣ Figure 4.5 ‣ 4.2 Baseline Model ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> illustrates the actual distribution of the training set and test set respectively, while in Figures <a href="#Ch4.F2" title="Figure 4.2 ‣ Figure 4.5 ‣ 4.2 Baseline Model ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> and <a href="#Ch4.F4" title="Figure 4.4 ‣ Figure 4.5 ‣ 4.2 Baseline Model ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> we can see how the model predicts the distributions of the training and test set. From the figures it is obvious that the logistic regression model has learned the coefficients of a linear function that minimizes the negative-log-likelihood loss. Figures <a href="#Ch4.F6" title="Figure 4.6 ‣ 4.2 Baseline Model ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.6</span></a> and <a href="#Ch4.F7" title="Figure 4.7 ‣ 4.2 Baseline Model ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.7</span></a> are almost identical and they illustrate the Precision - Recall curve for the baseline model on the training and test set. The figures show that the baseline model has a precision above 0.6 when the recall is in the range of 0.0 and 0.4. For bigger recall the precision drops to 0.4. This means that when the baseline model produces more positive outcomes, it predicts the positive examples more accurately but it also predicts a large number of negative examples as positive.</p>
</div>
<figure id="Ch4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="Ch4.F5.5" class="ltx_block ltx_figure_panel">
<figure id="Ch4.F1" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:216.8pt;"><img src="/html/2007.05881/assets/images/baseline_data.png" id="Ch4.F5.1.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="598" height="598" alt="Refer to caption">
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4.1: </span>Actual dist. of training set.</figcaption>
</figure>
<figure id="Ch4.F2" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:216.8pt;"><img src="/html/2007.05881/assets/images/baseline_predictions.png" id="Ch4.F5.2.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="598" height="598" alt="Refer to caption">
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4.2: </span>Predicted dist. of training set.</figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="Ch4.F5.6" class="ltx_block ltx_figure_panel">
<figure id="Ch4.F3" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:216.8pt;"><img src="/html/2007.05881/assets/images/baseline_test_data.png" id="Ch4.F5.3.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="598" height="598" alt="Refer to caption">
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4.3: </span>Actual dist. of test set.</figcaption>
</figure>
<figure id="Ch4.F4" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:216.8pt;"><img src="/html/2007.05881/assets/images/baseline_test_predictions.png" id="Ch4.F5.4.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="598" height="598" alt="Refer to caption">
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4.4: </span>Predicted dist. of test set.</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.5: </span>In the plots, the red dots represent samples from the negative class and the blue dots are samples from the positive class.</figcaption>
</figure>
<figure id="Ch4.F6" class="ltx_figure"><img src="/html/2007.05881/assets/x6.png" id="Ch4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="288" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.6: </span>Precision - Recall curve produced by the baseline model on the training set.</figcaption>
</figure>
<figure id="Ch4.F7" class="ltx_figure"><img src="/html/2007.05881/assets/x7.png" id="Ch4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="288" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.7: </span>Precision - Recall curve produced by the baseline model on the test set.</figcaption>
</figure>
</section>
<section id="Ch4.S3" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.3 </span>Training the Neural Network model</h3>

<div id="Ch4.S3.p1" class="ltx_para">
<p id="Ch4.S3.p1.4" class="ltx_p">The neural network based solutions that we propose are based on two fusion modules that combine the textual and visual information of each advertisement and a Siamese Neural Network that takes the output of the fusion modules as its input and produces an output that is a number between 0 and 1. The output of this model is the probability that the two advertisements are similar, therefore if the output is closer to 1 it means that the model predicts with high certainty that the advertisements are similar. Neural networks are trained by updating their weights using Backpropagation (as explained in Section 2.2.1) and for that we need to compute the difference between the output of the model and the actual value. This is done by using a differentiable loss function. The labels in our dataset are either 0’s or 1’s and our model outputs probabilities that are in the range of 0 to 1. This means that we need to penalize the model when it outputs a high probability but the true label is 0 or it outputs a low probability but the actual label is 1. This can be done with the Binary Cross Entropy loss function, that is defined as:</p>
<table id="Ch4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Ch4.E4.m1.6" class="ltx_Math" alttext="BCE(x,y)=-(y*\log{p(x)}+(1-y)*\log{(1-p(x))})" display="block"><semantics id="Ch4.E4.m1.6a"><mrow id="Ch4.E4.m1.6.6" xref="Ch4.E4.m1.6.6.cmml"><mrow id="Ch4.E4.m1.6.6.3" xref="Ch4.E4.m1.6.6.3.cmml"><mi id="Ch4.E4.m1.6.6.3.2" xref="Ch4.E4.m1.6.6.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="Ch4.E4.m1.6.6.3.1" xref="Ch4.E4.m1.6.6.3.1.cmml">​</mo><mi id="Ch4.E4.m1.6.6.3.3" xref="Ch4.E4.m1.6.6.3.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="Ch4.E4.m1.6.6.3.1a" xref="Ch4.E4.m1.6.6.3.1.cmml">​</mo><mi id="Ch4.E4.m1.6.6.3.4" xref="Ch4.E4.m1.6.6.3.4.cmml">E</mi><mo lspace="0em" rspace="0em" id="Ch4.E4.m1.6.6.3.1b" xref="Ch4.E4.m1.6.6.3.1.cmml">​</mo><mrow id="Ch4.E4.m1.6.6.3.5.2" xref="Ch4.E4.m1.6.6.3.5.1.cmml"><mo stretchy="false" id="Ch4.E4.m1.6.6.3.5.2.1" xref="Ch4.E4.m1.6.6.3.5.1.cmml">(</mo><mi id="Ch4.E4.m1.1.1" xref="Ch4.E4.m1.1.1.cmml">x</mi><mo id="Ch4.E4.m1.6.6.3.5.2.2" xref="Ch4.E4.m1.6.6.3.5.1.cmml">,</mo><mi id="Ch4.E4.m1.2.2" xref="Ch4.E4.m1.2.2.cmml">y</mi><mo stretchy="false" id="Ch4.E4.m1.6.6.3.5.2.3" xref="Ch4.E4.m1.6.6.3.5.1.cmml">)</mo></mrow></mrow><mo id="Ch4.E4.m1.6.6.2" xref="Ch4.E4.m1.6.6.2.cmml">=</mo><mrow id="Ch4.E4.m1.6.6.1" xref="Ch4.E4.m1.6.6.1.cmml"><mo id="Ch4.E4.m1.6.6.1a" xref="Ch4.E4.m1.6.6.1.cmml">−</mo><mrow id="Ch4.E4.m1.6.6.1.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.cmml"><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.2" xref="Ch4.E4.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.cmml"><mrow id="Ch4.E4.m1.6.6.1.1.1.1.4" xref="Ch4.E4.m1.6.6.1.1.1.1.4.cmml"><mrow id="Ch4.E4.m1.6.6.1.1.1.1.4.2" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.cmml"><mi id="Ch4.E4.m1.6.6.1.1.1.1.4.2.2" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.2.cmml">y</mi><mo lspace="0.222em" rspace="0.222em" id="Ch4.E4.m1.6.6.1.1.1.1.4.2.1" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.1.cmml">∗</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.4.2.3" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.cmml"><mi id="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.1" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.1.cmml">log</mi><mo lspace="0.167em" id="Ch4.E4.m1.6.6.1.1.1.1.4.2.3a" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.cmml">⁡</mo><mi id="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.2" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.2.cmml">p</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="Ch4.E4.m1.6.6.1.1.1.1.4.1" xref="Ch4.E4.m1.6.6.1.1.1.1.4.1.cmml">​</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.4.3.2" xref="Ch4.E4.m1.6.6.1.1.1.1.4.cmml"><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.4.3.2.1" xref="Ch4.E4.m1.6.6.1.1.1.1.4.cmml">(</mo><mi id="Ch4.E4.m1.3.3" xref="Ch4.E4.m1.3.3.cmml">x</mi><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.4.3.2.2" xref="Ch4.E4.m1.6.6.1.1.1.1.4.cmml">)</mo></mrow></mrow><mo id="Ch4.E4.m1.6.6.1.1.1.1.3" xref="Ch4.E4.m1.6.6.1.1.1.1.3.cmml">+</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.2" xref="Ch4.E4.m1.6.6.1.1.1.1.2.cmml"><mrow id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.2" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mn id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.2" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.3" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo rspace="0.055em" stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.3" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="Ch4.E4.m1.6.6.1.1.1.1.2.3" xref="Ch4.E4.m1.6.6.1.1.1.1.2.3.cmml">∗</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.2.cmml"><mi id="Ch4.E4.m1.5.5" xref="Ch4.E4.m1.5.5.cmml">log</mi><mo id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1a" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.2.cmml">⁡</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.2.cmml"><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.2" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.2.cmml">(</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.cmml"><mn id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.2" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.2.cmml">1</mn><mo id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.1" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.1.cmml">−</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.cmml"><mi id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.2" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.1" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.1.cmml">​</mo><mrow id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.3.2" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.cmml"><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.3.2.1" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.cmml">(</mo><mi id="Ch4.E4.m1.4.4" xref="Ch4.E4.m1.4.4.cmml">x</mi><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.3.2.2" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.3" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="Ch4.E4.m1.6.6.1.1.1.3" xref="Ch4.E4.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E4.m1.6b"><apply id="Ch4.E4.m1.6.6.cmml" xref="Ch4.E4.m1.6.6"><eq id="Ch4.E4.m1.6.6.2.cmml" xref="Ch4.E4.m1.6.6.2"></eq><apply id="Ch4.E4.m1.6.6.3.cmml" xref="Ch4.E4.m1.6.6.3"><times id="Ch4.E4.m1.6.6.3.1.cmml" xref="Ch4.E4.m1.6.6.3.1"></times><ci id="Ch4.E4.m1.6.6.3.2.cmml" xref="Ch4.E4.m1.6.6.3.2">𝐵</ci><ci id="Ch4.E4.m1.6.6.3.3.cmml" xref="Ch4.E4.m1.6.6.3.3">𝐶</ci><ci id="Ch4.E4.m1.6.6.3.4.cmml" xref="Ch4.E4.m1.6.6.3.4">𝐸</ci><interval closure="open" id="Ch4.E4.m1.6.6.3.5.1.cmml" xref="Ch4.E4.m1.6.6.3.5.2"><ci id="Ch4.E4.m1.1.1.cmml" xref="Ch4.E4.m1.1.1">𝑥</ci><ci id="Ch4.E4.m1.2.2.cmml" xref="Ch4.E4.m1.2.2">𝑦</ci></interval></apply><apply id="Ch4.E4.m1.6.6.1.cmml" xref="Ch4.E4.m1.6.6.1"><minus id="Ch4.E4.m1.6.6.1.2.cmml" xref="Ch4.E4.m1.6.6.1"></minus><apply id="Ch4.E4.m1.6.6.1.1.1.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1"><plus id="Ch4.E4.m1.6.6.1.1.1.1.3.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.3"></plus><apply id="Ch4.E4.m1.6.6.1.1.1.1.4.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4"><times id="Ch4.E4.m1.6.6.1.1.1.1.4.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4.1"></times><apply id="Ch4.E4.m1.6.6.1.1.1.1.4.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2"><times id="Ch4.E4.m1.6.6.1.1.1.1.4.2.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.1"></times><ci id="Ch4.E4.m1.6.6.1.1.1.1.4.2.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.2">𝑦</ci><apply id="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.3"><log id="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.1"></log><ci id="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.4.2.3.2">𝑝</ci></apply></apply><ci id="Ch4.E4.m1.3.3.cmml" xref="Ch4.E4.m1.3.3">𝑥</ci></apply><apply id="Ch4.E4.m1.6.6.1.1.1.1.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2"><times id="Ch4.E4.m1.6.6.1.1.1.1.2.3.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.3"></times><apply id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1"><minus id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.2">1</cn><ci id="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.3.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.1.1.1.1.3">𝑦</ci></apply><apply id="Ch4.E4.m1.6.6.1.1.1.1.2.2.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1"><log id="Ch4.E4.m1.5.5.cmml" xref="Ch4.E4.m1.5.5"></log><apply id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1"><minus id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.1"></minus><cn type="integer" id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.2">1</cn><apply id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3"><times id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.1.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.1"></times><ci id="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.2.cmml" xref="Ch4.E4.m1.6.6.1.1.1.1.2.2.1.1.1.3.2">𝑝</ci><ci id="Ch4.E4.m1.4.4.cmml" xref="Ch4.E4.m1.4.4">𝑥</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E4.m1.6c">BCE(x,y)=-(y*\log{p(x)}+(1-y)*\log{(1-p(x))})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.4)</span></td>
</tr></tbody>
</table>
<p id="Ch4.S3.p1.3" class="ltx_p">where <math id="Ch4.S3.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="Ch4.S3.p1.1.m1.1a"><mi id="Ch4.S3.p1.1.m1.1.1" xref="Ch4.S3.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Ch4.S3.p1.1.m1.1b"><ci id="Ch4.S3.p1.1.m1.1.1.cmml" xref="Ch4.S3.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S3.p1.1.m1.1c">x</annotation></semantics></math> is the pair of advertisements and the input to the model, <math id="Ch4.S3.p1.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Ch4.S3.p1.2.m2.1a"><mi id="Ch4.S3.p1.2.m2.1.1" xref="Ch4.S3.p1.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Ch4.S3.p1.2.m2.1b"><ci id="Ch4.S3.p1.2.m2.1.1.cmml" xref="Ch4.S3.p1.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S3.p1.2.m2.1c">y</annotation></semantics></math> is the label and <math id="Ch4.S3.p1.3.m3.1" class="ltx_Math" alttext="p(x)" display="inline"><semantics id="Ch4.S3.p1.3.m3.1a"><mrow id="Ch4.S3.p1.3.m3.1.2" xref="Ch4.S3.p1.3.m3.1.2.cmml"><mi id="Ch4.S3.p1.3.m3.1.2.2" xref="Ch4.S3.p1.3.m3.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="Ch4.S3.p1.3.m3.1.2.1" xref="Ch4.S3.p1.3.m3.1.2.1.cmml">​</mo><mrow id="Ch4.S3.p1.3.m3.1.2.3.2" xref="Ch4.S3.p1.3.m3.1.2.cmml"><mo stretchy="false" id="Ch4.S3.p1.3.m3.1.2.3.2.1" xref="Ch4.S3.p1.3.m3.1.2.cmml">(</mo><mi id="Ch4.S3.p1.3.m3.1.1" xref="Ch4.S3.p1.3.m3.1.1.cmml">x</mi><mo stretchy="false" id="Ch4.S3.p1.3.m3.1.2.3.2.2" xref="Ch4.S3.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S3.p1.3.m3.1b"><apply id="Ch4.S3.p1.3.m3.1.2.cmml" xref="Ch4.S3.p1.3.m3.1.2"><times id="Ch4.S3.p1.3.m3.1.2.1.cmml" xref="Ch4.S3.p1.3.m3.1.2.1"></times><ci id="Ch4.S3.p1.3.m3.1.2.2.cmml" xref="Ch4.S3.p1.3.m3.1.2.2">𝑝</ci><ci id="Ch4.S3.p1.3.m3.1.1.cmml" xref="Ch4.S3.p1.3.m3.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S3.p1.3.m3.1c">p(x)</annotation></semantics></math> is the output of our model. By minimizing the Binary Cross-Entropy loss function we will force the model to learn how to adjust its weights, so when it produces a probability about the similarity of the pair of advertisements, it is as close as possible to the true label. Our choice of the loss function is also supported by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, who also use Binary Cross Entropy to compute the loss between the true label and the output of their Siamese neural networks. It is also worth noting that Binary Cross Entropy is just an approximation of the Average Precision Score metric. Decreasing the BCE loss doesn’t have to correlate to an increase in the Average Precision Score, but we assume that is the case. We have to use Binary Cross Entropy instead of Average Precision Score because APS is not a differentiable function. We will use BCE to train the model, but we also compute the Average Precision Score after every epoch in the Stochastic Gradient Process, because that is the metric that we use to compare models.</p>
</div>
</section>
<section id="Ch4.S4" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.4 </span>Recurrent Neural Network + Convolutional Neural Network fusion module</h3>

<div id="Ch4.S4.p1" class="ltx_para">
<p id="Ch4.S4.p1.1" class="ltx_p">The first proposed fusion module consists of a GRU that encodes the description, a pre-trained ResNet that outputs a vector representation of the image and two fully connected layers that transform the image feature representation and description encoding to the same vector space. The outputs of the two fully connected layers are combined by point-wise multiplication. To find the best hyperparameter configuration for the fusion module and Siamese neural network we did a small hyperparameter search by training 10 different models. We explored the number of stacked GRU layers (layers), the size of the GRU cell (hid_size), the size of the two fully connected layers (fs_out_size), the size of the first fully connected layer in the Siamese neural network (fc1_hid_size), the size of the second fully connected layer in the Siamese neural network (fc2_hid_size) and the learning rate (lr.). All models were trained for 30 epochs and as an optimization technique, we used early stopping (we stopped the training loop if after 5 epochs the validation loss didn’t improve). Due to the exponential complexity of doing a more in-depth hyperparameter search, we decided that we are going to train our models with mini-batches of 64 samples and use a fixed random seed so that the weights in the neural networks in our models would always have the same random initialization. By doing this we would be able to compare the results of the models more accurately. The results of the hyperparameter search are shown in Table <a href="#Ch4.T1" title="Table 4.1 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> and Table <a href="#Ch4.T2" title="Table 4.2 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>. Table <a href="#Ch4.T1" title="Table 4.1 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> shows the Binary Cross Entropy loss and the Average Precision Score. the model achieved on the training set, while Table <a href="#Ch4.T2" title="Table 4.2 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> show the same metrics the model achieved on the validation set. We are more interested in the scores the model achieves on the validation set, because the model hasn’t seen the validation data (hasn’t been trained on it), therefore the scores achieved on the validation set give us a more honest outlook on how the model generalizes and how it will perform in the future on unseen data from the real world.</p>
</div>
<figure id="Ch4.T1" class="ltx_table">
<table id="Ch4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ch4.T1.1.1.1" class="ltx_tr">
<th id="Ch4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">layers</th>
<th id="Ch4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">hid_size</th>
<th id="Ch4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fs_out_size</th>
<th id="Ch4.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc1_hid_size</th>
<th id="Ch4.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc2_hid_size</th>
<th id="Ch4.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">lr.</th>
<th id="Ch4.T1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">train_loss</th>
<th id="Ch4.T1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">train_aps</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ch4.T1.1.2.1" class="ltx_tr">
<td id="Ch4.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.1</td>
<td id="Ch4.T1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">15.23</td>
<td id="Ch4.T1.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.391</td>
</tr>
<tr id="Ch4.T1.1.3.2" class="ltx_tr">
<td id="Ch4.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.01</td>
<td id="Ch4.T1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">13.45</td>
<td id="Ch4.T1.1.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.392</td>
</tr>
<tr id="Ch4.T1.1.4.3" class="ltx_tr">
<td id="Ch4.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.001</td>
<td id="Ch4.T1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">10.20</td>
<td id="Ch4.T1.1.4.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.387</td>
</tr>
<tr id="Ch4.T1.1.5.4" class="ltx_tr">
<td id="Ch4.T1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T1.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.0001</td>
<td id="Ch4.T1.1.5.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.5241</td>
<td id="Ch4.T1.1.5.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.741</td>
</tr>
<tr id="Ch4.T1.1.6.5" class="ltx_tr">
<td id="Ch4.T1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.6.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.1</td>
<td id="Ch4.T1.1.6.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">14.05</td>
<td id="Ch4.T1.1.6.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.393</td>
</tr>
<tr id="Ch4.T1.1.7.6" class="ltx_tr">
<td id="Ch4.T1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T1.1.7.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.7.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.01</td>
<td id="Ch4.T1.1.7.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">11.43</td>
<td id="Ch4.T1.1.7.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.398</td>
</tr>
<tr id="Ch4.T1.1.8.7" class="ltx_tr">
<td id="Ch4.T1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T1.1.8.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.8.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.001</td>
<td id="Ch4.T1.1.8.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">10.15</td>
<td id="Ch4.T1.1.8.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.413</td>
</tr>
<tr id="Ch4.T1.1.9.8" class="ltx_tr">
<td id="Ch4.T1.1.9.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T1.1.9.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T1.1.9.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.0001</td>
<td id="Ch4.T1.1.9.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFBFBF;padding-bottom:2.15277pt;"><span id="Ch4.T1.1.9.8.7.1" class="ltx_text" style="background-color:#FFBFBF;">0.463</span></td>
<td id="Ch4.T1.1.9.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFBFBF;padding-bottom:2.15277pt;"><span id="Ch4.T1.1.9.8.8.1" class="ltx_text" style="background-color:#FFBFBF;">0.802</span></td>
</tr>
<tr id="Ch4.T1.1.10.9" class="ltx_tr">
<td id="Ch4.T1.1.10.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">2</td>
<td id="Ch4.T1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T1.1.10.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T1.1.10.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.01</td>
<td id="Ch4.T1.1.10.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">14.94</td>
<td id="Ch4.T1.1.10.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.3912</td>
</tr>
<tr id="Ch4.T1.1.11.10" class="ltx_tr">
<td id="Ch4.T1.1.11.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">2</td>
<td id="Ch4.T1.1.11.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T1.1.11.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T1.1.11.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T1.1.11.10.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T1.1.11.10.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.0001</td>
<td id="Ch4.T1.1.11.10.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">6.67</td>
<td id="Ch4.T1.1.11.10.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.454</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4.1: </span>Results the models achieved on the training set. The highlighted cells are the lowest training loss and highest training average precision score that were achieved by the models that we trained.</figcaption>
</figure>
<figure id="Ch4.T2" class="ltx_table">
<table id="Ch4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ch4.T2.1.1.1" class="ltx_tr">
<th id="Ch4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">layers</th>
<th id="Ch4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">hid_size</th>
<th id="Ch4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fs_out_size</th>
<th id="Ch4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc1_hid_size</th>
<th id="Ch4.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc2_hid_size</th>
<th id="Ch4.T2.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">lr.</th>
<th id="Ch4.T2.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">val_loss</th>
<th id="Ch4.T2.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">val_aps</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ch4.T2.1.2.1" class="ltx_tr">
<td id="Ch4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T2.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.1</td>
<td id="Ch4.T2.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">10.83</td>
<td id="Ch4.T2.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.392</td>
</tr>
<tr id="Ch4.T2.1.3.2" class="ltx_tr">
<td id="Ch4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T2.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.01</td>
<td id="Ch4.T2.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">16.79</td>
<td id="Ch4.T2.1.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.392</td>
</tr>
<tr id="Ch4.T2.1.4.3" class="ltx_tr">
<td id="Ch4.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T2.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.001</td>
<td id="Ch4.T2.1.4.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">7.56</td>
<td id="Ch4.T2.1.4.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.375</td>
</tr>
<tr id="Ch4.T2.1.5.4" class="ltx_tr">
<td id="Ch4.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">100</td>
<td id="Ch4.T2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">32</td>
<td id="Ch4.T2.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.0001</td>
<td id="Ch4.T2.1.5.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.581</td>
<td id="Ch4.T2.1.5.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.668</td>
</tr>
<tr id="Ch4.T2.1.6.5" class="ltx_tr">
<td id="Ch4.T2.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T2.1.6.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.6.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.1</td>
<td id="Ch4.T2.1.6.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">7.74</td>
<td id="Ch4.T2.1.6.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.388</td>
</tr>
<tr id="Ch4.T2.1.7.6" class="ltx_tr">
<td id="Ch4.T2.1.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T2.1.7.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.7.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.01</td>
<td id="Ch4.T2.1.7.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">11.12</td>
<td id="Ch4.T2.1.7.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.401</td>
</tr>
<tr id="Ch4.T2.1.8.7" class="ltx_tr">
<td id="Ch4.T2.1.8.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T2.1.8.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.8.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.001</td>
<td id="Ch4.T2.1.8.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">8.76</td>
<td id="Ch4.T2.1.8.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.44</td>
</tr>
<tr id="Ch4.T2.1.9.8" class="ltx_tr">
<td id="Ch4.T2.1.9.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T2.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T2.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T2.1.9.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T2.1.9.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.0001</td>
<td id="Ch4.T2.1.9.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFBFBF;padding-bottom:2.15277pt;"><span id="Ch4.T2.1.9.8.7.1" class="ltx_text" style="background-color:#FFBFBF;">0.587</span></td>
<td id="Ch4.T2.1.9.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFBFBF;padding-bottom:2.15277pt;"><span id="Ch4.T2.1.9.8.8.1" class="ltx_text" style="background-color:#FFBFBF;">0.684</span></td>
</tr>
<tr id="Ch4.T2.1.10.9" class="ltx_tr">
<td id="Ch4.T2.1.10.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">2</td>
<td id="Ch4.T2.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T2.1.10.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T2.1.10.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T2.1.10.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T2.1.10.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.01</td>
<td id="Ch4.T2.1.10.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">10.83</td>
<td id="Ch4.T2.1.10.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.392</td>
</tr>
<tr id="Ch4.T2.1.11.10" class="ltx_tr">
<td id="Ch4.T2.1.11.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">2</td>
<td id="Ch4.T2.1.11.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T2.1.11.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T2.1.11.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">512</td>
<td id="Ch4.T2.1.11.10.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1024</td>
<td id="Ch4.T2.1.11.10.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.0001</td>
<td id="Ch4.T2.1.11.10.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.653</td>
<td id="Ch4.T2.1.11.10.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.516</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4.2: </span>Results the models achieved on the validation set. The highlighted cells are the lowest validation loss and highest validation average precision score that were achieved by the models that we trained.</figcaption>
</figure>
<div id="Ch4.S4.p2" class="ltx_para">
<p id="Ch4.S4.p2.1" class="ltx_p">From the tables we can see that the model with the 8th configuration has achieved the best training and validation average precision score of <span id="Ch4.S4.p2.1.1" class="ltx_text ltx_font_bold">0.802</span> and <span id="Ch4.S4.p2.1.2" class="ltx_text ltx_font_bold">0.684</span>. The second best model is the 4th model and it is twice as smaller in size then the 8th model, but it achieved a validation average precision score of <span id="Ch4.S4.p2.1.3" class="ltx_text ltx_font_bold">0.668</span> which isn’t so far from the best score. Given the results, we can conclude that the models are performing better with a small learning rate, which in our case is 0.0001. The last two models in the tables have the same setting as the best model in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> (for the fusion module) and for the Siamese Neural Network we used the settings from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. An interesting observation from this is that the hyperparameters that were the best setting for the networks in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, didn’t achieve good results for our task, which means that hyperparameters settings from papers don’t always transfer well from one task to another.</p>
</div>
<figure id="Ch4.F8" class="ltx_figure"><img src="/html/2007.05881/assets/x8.png" id="Ch4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.8: </span>The change of Binary Cross Entropy loss during training. The blue line is the training loss and the orange line is the validation loss.</figcaption>
</figure>
<figure id="Ch4.F9" class="ltx_figure"><img src="/html/2007.05881/assets/x9.png" id="Ch4.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.9: </span>The change of Average Precision Score during training. The blue line is the training score and the orange line is the validation score.</figcaption>
</figure>
<div id="Ch4.S4.p3" class="ltx_para">
<p id="Ch4.S4.p3.1" class="ltx_p">In Figure <a href="#Ch4.F8" title="Figure 4.8 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.8</span></a> we can see how the Binary Cross Entropy loss changes during training time and in Figure <a href="#Ch4.F9" title="Figure 4.9 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.9</span></a> illustrates the same thing about the Average Precision Score. From the figures, we can see that after the 12th epoch the model decreases the training loss, but the validation loss seems to get bigger. This is a sign of overfitting, which means that while the model is improving his performance on the training data, it starts to lose its generalization power and performs worse on the validation set. As a solution to this, we proposed to train our model using the Dropout regularization technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Dropout is a simple process that randomly sets units to be zero (this results in dropping their connections) from the neural network during training and this prevents the units from co-adapting so much. Dropout has one parameter which is the dropout rate or in other words the proportion of connection we going to forget from the input. In our model, we use Dropout right after the point-wise multiplication. By doing this we are regularizing the way the fusion module works and don’t interfere with how the Siamese Neural Network learns because our main focus is to explore which fusion module works best.</p>
</div>
<div id="Ch4.S4.p4" class="ltx_para">
<p id="Ch4.S4.p4.1" class="ltx_p">For the following experiments, we explored three different dropout rates (0.2, 0.3 and 0.5) and fixed the learning rate to 0.0001. The results of the experiments can be seen in Tables <a href="#Ch4.T3" title="Table 4.3 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> and <a href="#Ch4.T4" title="Table 4.4 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
<figure id="Ch4.T3" class="ltx_table">
<table id="Ch4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ch4.T3.1.1.1" class="ltx_tr">
<th id="Ch4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">layers</th>
<th id="Ch4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">hid_size</th>
<th id="Ch4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fs_out_size</th>
<th id="Ch4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc1_hid_size</th>
<th id="Ch4.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc2_hid_size</th>
<th id="Ch4.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">dr</th>
<th id="Ch4.T3.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">train_loss</th>
<th id="Ch4.T3.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">train_aps</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ch4.T3.1.2.1" class="ltx_tr">
<td id="Ch4.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T3.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T3.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.2</td>
<td id="Ch4.T3.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.591</td>
<td id="Ch4.T3.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.647</td>
</tr>
<tr id="Ch4.T3.1.3.2" class="ltx_tr">
<td id="Ch4.T3.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T3.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T3.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T3.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T3.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.3</td>
<td id="Ch4.T3.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.6</td>
<td id="Ch4.T3.1.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.63</td>
</tr>
<tr id="Ch4.T3.1.4.3" class="ltx_tr">
<td id="Ch4.T3.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T3.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T3.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T3.1.4.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T3.1.4.3.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.5</td>
<td id="Ch4.T3.1.4.3.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.624</td>
<td id="Ch4.T3.1.4.3.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.587</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4.3: </span>Results the models achieved on the training set.</figcaption>
</figure>
<figure id="Ch4.T4" class="ltx_table">
<table id="Ch4.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ch4.T4.1.1.1" class="ltx_tr">
<th id="Ch4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">layers</th>
<th id="Ch4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">hid_size</th>
<th id="Ch4.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fs_out_size</th>
<th id="Ch4.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc1_hid_size</th>
<th id="Ch4.T4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">fc2_hid_size</th>
<th id="Ch4.T4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">dr</th>
<th id="Ch4.T4.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">val_loss</th>
<th id="Ch4.T4.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">val_aps</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ch4.T4.1.2.1" class="ltx_tr">
<td id="Ch4.T4.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T4.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T4.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.2</td>
<td id="Ch4.T4.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.586</td>
<td id="Ch4.T4.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.654</td>
</tr>
<tr id="Ch4.T4.1.3.2" class="ltx_tr">
<td id="Ch4.T4.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T4.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T4.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T4.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T4.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T4.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.3</td>
<td id="Ch4.T4.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.593</td>
<td id="Ch4.T4.1.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.643</td>
</tr>
<tr id="Ch4.T4.1.4.3" class="ltx_tr">
<td id="Ch4.T4.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">1</td>
<td id="Ch4.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T4.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">256</td>
<td id="Ch4.T4.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">128</td>
<td id="Ch4.T4.1.4.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">64</td>
<td id="Ch4.T4.1.4.3.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.5</td>
<td id="Ch4.T4.1.4.3.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.617</td>
<td id="Ch4.T4.1.4.3.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.605</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4.4: </span>Results the models achieved on the validation set.</figcaption>
</figure>
<div id="Ch4.S4.p5" class="ltx_para">
<p id="Ch4.S4.p5.1" class="ltx_p">From the tables, we can see that applying dropout right after the point-wise multiplication didn’t improve the model’s performance. Therefore in this section, we conclude that the best model from these experiments is the model with the 8th configuration from Table <a href="#Ch4.T1" title="Table 4.1 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. To get a better estimation of the average precision score on the validation set, we trained two models that had the 8th configuration but we used a different random initialization of the weights of the model. After we trained the models we averaged their validation scores, therefore the final average precision score on the validation set is <math id="Ch4.S4.p5.1.m1.1" class="ltx_Math" alttext="\textbf{0.682}\pm 0.003" display="inline"><semantics id="Ch4.S4.p5.1.m1.1a"><mrow id="Ch4.S4.p5.1.m1.1.1" xref="Ch4.S4.p5.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="Ch4.S4.p5.1.m1.1.1.2" xref="Ch4.S4.p5.1.m1.1.1.2a.cmml">0.682</mtext><mo id="Ch4.S4.p5.1.m1.1.1.1" xref="Ch4.S4.p5.1.m1.1.1.1.cmml">±</mo><mn id="Ch4.S4.p5.1.m1.1.1.3" xref="Ch4.S4.p5.1.m1.1.1.3.cmml">0.003</mn></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S4.p5.1.m1.1b"><apply id="Ch4.S4.p5.1.m1.1.1.cmml" xref="Ch4.S4.p5.1.m1.1.1"><csymbol cd="latexml" id="Ch4.S4.p5.1.m1.1.1.1.cmml" xref="Ch4.S4.p5.1.m1.1.1.1">plus-or-minus</csymbol><ci id="Ch4.S4.p5.1.m1.1.1.2a.cmml" xref="Ch4.S4.p5.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="Ch4.S4.p5.1.m1.1.1.2.cmml" xref="Ch4.S4.p5.1.m1.1.1.2">0.682</mtext></ci><cn type="float" id="Ch4.S4.p5.1.m1.1.1.3.cmml" xref="Ch4.S4.p5.1.m1.1.1.3">0.003</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S4.p5.1.m1.1c">\textbf{0.682}\pm 0.003</annotation></semantics></math>.</p>
</div>
</section>
<section id="Ch4.S5" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.5 </span>Stacked Attention Network fusion module</h3>

<div id="Ch4.S5.p1" class="ltx_para">
<p id="Ch4.S5.p1.1" class="ltx_p">The Stacked Attention Network fusion module is an extension to the previously proposed fusion module. Instead of combining the outputs of the GRU and the pre-trained convolutional network by point-wise multiplication, SAN uses the attention mechanism to create a more refined joint representation of the description and the image features. Because of time constraints (one epoch lasted 48 hours) we were able to train only one model with this fusion module. Since the 8th configuration from Table <a href="#Ch4.T2" title="Table 4.2 ‣ 4.4 Recurrent Neural Network + Convolutional Neural Network fusion module ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> performed the best in previous experiments, we decided that our model is going to have the same configuration. The only difference is that the attention layers had the same size as the output of the first fusion module.</p>
</div>
<div id="Ch4.S5.p2" class="ltx_para">
<p id="Ch4.S5.p2.1" class="ltx_p">The average precision score that this model achieves on the validation set is <span id="Ch4.S5.p2.1.1" class="ltx_text ltx_font_bold">0.534</span> and a Binary Cross-Entropy loss of <span id="Ch4.S5.p2.1.2" class="ltx_text ltx_font_bold">0.7938</span>. We looked into a large number of attention maps over the images but we couldn’t find any evidence that the model finds correlation between the similar regions of the images in the advertisements. We believe that this is due to the small number of epochs we used to train our model.</p>
</div>
</section>
<section id="Ch4.S6" class="ltx_section">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.6 </span>Comparison of the fusion modules</h3>

<div id="Ch4.S6.p1" class="ltx_para">
<p id="Ch4.S6.p1.1" class="ltx_p">In this section, we compare the three models we have experimented with so far. We analyze them based on the average precision scores that they achieve on the test set, the set that we didn’t use to choose the hyperparameter setting for the models that needed hyperparameter tuning. In Table <a href="#Ch4.T5" title="Table 4.5 ‣ 4.6 Comparison of the fusion modules ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a> we can see the average precision scores for each proposed solution. The RNN + CNN fusion module along with the Siamese Neural Network significantly outperform the baseline model. The Stacked Attention Network performs worse than the RNN + CNN module and we believe that this is because the model wasn’t trained long enough. Therefore in the further discussion, we will omit the Stacked Attention Network module since it doesn’t provide additional information to what we already have with the RNN + CNN model. As a way to illustrate the difference in performance between the baseline and the RNN + CNN model, we have plotted the Precision-Recall curve for both models in Figure <a href="#Ch4.F10" title="Figure 4.10 ‣ 4.6 Comparison of the fusion modules ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.10</span></a> and as expected the PR curve of the RNN + CNN model has a much larger area under the curve then the PR curve of the baseline model.</p>
</div>
<figure id="Ch4.T5" class="ltx_table">
<table id="Ch4.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ch4.T5.1.2.1" class="ltx_tr">
<th id="Ch4.T5.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Model name</th>
<th id="Ch4.T5.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Average Precision Score on Test set</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ch4.T5.1.3.1" class="ltx_tr">
<th id="Ch4.T5.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Baseline model</th>
<td id="Ch4.T5.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.48</td>
</tr>
<tr id="Ch4.T5.1.1" class="ltx_tr">
<th id="Ch4.T5.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">RNN + CNN model</th>
<td id="Ch4.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;"><math id="Ch4.T5.1.1.1.m1.1" class="ltx_Math" alttext="0.683\pm 0.004" display="inline"><semantics id="Ch4.T5.1.1.1.m1.1a"><mrow id="Ch4.T5.1.1.1.m1.1.1" xref="Ch4.T5.1.1.1.m1.1.1.cmml"><mn id="Ch4.T5.1.1.1.m1.1.1.2" xref="Ch4.T5.1.1.1.m1.1.1.2.cmml">0.683</mn><mo id="Ch4.T5.1.1.1.m1.1.1.1" xref="Ch4.T5.1.1.1.m1.1.1.1.cmml">±</mo><mn id="Ch4.T5.1.1.1.m1.1.1.3" xref="Ch4.T5.1.1.1.m1.1.1.3.cmml">0.004</mn></mrow><annotation-xml encoding="MathML-Content" id="Ch4.T5.1.1.1.m1.1b"><apply id="Ch4.T5.1.1.1.m1.1.1.cmml" xref="Ch4.T5.1.1.1.m1.1.1"><csymbol cd="latexml" id="Ch4.T5.1.1.1.m1.1.1.1.cmml" xref="Ch4.T5.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="Ch4.T5.1.1.1.m1.1.1.2.cmml" xref="Ch4.T5.1.1.1.m1.1.1.2">0.683</cn><cn type="float" id="Ch4.T5.1.1.1.m1.1.1.3.cmml" xref="Ch4.T5.1.1.1.m1.1.1.3">0.004</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T5.1.1.1.m1.1c">0.683\pm 0.004</annotation></semantics></math></td>
</tr>
<tr id="Ch4.T5.1.4.2" class="ltx_tr">
<th id="Ch4.T5.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">SAN model</th>
<td id="Ch4.T5.1.4.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">0.574</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4.5: </span>In this table we have presented the Average Precision Score that each model has achieved on the test set.</figcaption>
</figure>
<figure id="Ch4.F10" class="ltx_figure"><img src="/html/2007.05881/assets/x10.png" id="Ch4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="288" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.10: </span>Comparison between the Precision - Recall curves of the Baseline model and the RNN + CNN model.</figcaption>
</figure>
<div id="Ch4.S6.p2" class="ltx_para">
<p id="Ch4.S6.p2.1" class="ltx_p">Advertisements tend to have different description lengths, so we wanted to investigate how does the model perform when both descriptions in the pair are short, when the descriptions are both very long and when the descriptions are different lengths. We want to see if the models can predict equally well when the advertisements have different lengths because that would mean that the fusion module can capture crucial similarities between the descriptions even though, one description might contain more information then the other. To do that we computed the average length of each pair of descriptions. The maximum average could be 100 (because we limited our descriptions to 100 words) and the minimum could be 1, so we decided to divide the test set into 11 groups. The first group would be pairs that have an average description length of 1 to 9 words, the second group would have a length of 10 to 19 words, and so on until the last group, which is consisted of pairs that have an average length of 100 words. This is because we cut many descriptions in our preprocessing so, this group represents all the long advertisements. Table <a href="#Ch4.T6" title="Table 4.6 ‣ 4.6 Comparison of the fusion modules ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.6</span></a> shows the number of pairs that each group contains and Figure <a href="#Ch4.F11" title="Figure 4.11 ‣ 4.6 Comparison of the fusion modules ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.11</span></a> shows the class distribution within each bucket.</p>
</div>
<figure id="Ch4.T6" class="ltx_table">
<table id="Ch4.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Ch4.T6.1.1.1" class="ltx_tr">
<td id="Ch4.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">0</td>
<td id="Ch4.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="Ch4.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="Ch4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3</td>
<td id="Ch4.T6.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4</td>
<td id="Ch4.T6.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5</td>
<td id="Ch4.T6.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6</td>
<td id="Ch4.T6.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7</td>
<td id="Ch4.T6.1.1.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8</td>
<td id="Ch4.T6.1.1.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9</td>
<td id="Ch4.T6.1.1.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</td>
</tr>
<tr id="Ch4.T6.1.2.2" class="ltx_tr">
<td id="Ch4.T6.1.2.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">36531</td>
<td id="Ch4.T6.1.2.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">63573</td>
<td id="Ch4.T6.1.2.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">41254</td>
<td id="Ch4.T6.1.2.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">27039</td>
<td id="Ch4.T6.1.2.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">18984</td>
<td id="Ch4.T6.1.2.2.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">14836</td>
<td id="Ch4.T6.1.2.2.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">11684</td>
<td id="Ch4.T6.1.2.2.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">8925</td>
<td id="Ch4.T6.1.2.2.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">6910</td>
<td id="Ch4.T6.1.2.2.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">6144</td>
<td id="Ch4.T6.1.2.2.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">23809</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4.6: </span>Distribution of the test set pairs in the buckets of average description length. In the first row show the number of the bucket and in the second row we show how many pairs does the bucket contain.</figcaption>
</figure>
<figure id="Ch4.F11" class="ltx_figure"><img src="/html/2007.05881/assets/x11.png" id="Ch4.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.11: </span>This bar chart shows the class distribution of each bucket.</figcaption>
</figure>
<figure id="Ch4.F12" class="ltx_figure"><img src="/html/2007.05881/assets/x12.png" id="Ch4.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.12: </span>The bar chart show how do the models perform when they are predicting examples from the given buckets.</figcaption>
</figure>
<div id="Ch4.S6.p3" class="ltx_para">
<p id="Ch4.S6.p3.1" class="ltx_p">From Figure <a href="#Ch4.F12" title="Figure 4.12 ‣ 4.6 Comparison of the fusion modules ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.12</span></a> we can see that both models perform better on pairs whose average description length is shorter than 40 words. The decline in the average precision score for pairs who have a bigger average description length maybe because there are pairs where the descriptions vary a lot in terms of word count. This means that both models predict poorly (worse than the models overall average) when, for example, one advertisement has a description of length 20 and the other advertisement has a description of length 100. There also seems to be a correlation between the distribution ratio and the average precision score. When the ration is closer to 1:3 instead of 1:2 in favour of the negative class, the model seems to have a lower average precision score. From Figure <a href="#Ch4.F12" title="Figure 4.12 ‣ 4.6 Comparison of the fusion modules ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.12</span></a> we can see that most of the examples in the test set have an average length between 1 and 40, and the ratio of that joint bucket is much closer to 1:2 than it is to 1:3. This means that the model has learned to maximise the distribution of pairs with an average description length that is between 1 and 40. This results in a model that is too optimistic when it comes to advertisements that have very different or very big description lengths, therefore the model is more prone to classify a pair of dissimilar advertisements as similar. With this the number of <span id="Ch4.S6.p3.1.1" class="ltx_text ltx_font_italic">FN</span> (false negatives) would increase, resulting in a smaller average precision score across the pairs that have a average description length bigger than 40 words. From Figure <a href="#Ch4.F12" title="Figure 4.12 ‣ 4.6 Comparison of the fusion modules ‣ Chapter 4 Results and Evaluation ‣ Applying recent advances in Visual Question Answering to Record Linkage" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.12</span></a> we can see that the RNN + CNN fusion module outperforms the baseline model for every average description length, but it doesn’t appear that it solves the problem of variable description lengths in the pair of advertisements.</p>
</div>
<div id="Ch4.S6.p4" class="ltx_para">
<p id="Ch4.S6.p4.1" class="ltx_p">It is hard for us to evaluate what kind of role does the image have in the improvement of the results. If we trained a separate model that only used the descriptions to match the advertisements we would have a clearer view of how does the inclusion of images in the fusion model affect the overall performance of the RNN + CNN solution.</p>
</div>
<div id="Ch4.S6.p5" class="ltx_para">
<p id="Ch4.S6.p5.1" class="ltx_p">Overall, we proved that the neural network model performs better than the baseline model, but we couldn’t distinguish which part of the fusion module contributes more to the improvement. We failed to prove that by increasing the complexity of the fusion module (upgrading from the RNN + CNN module to the Stacke Attention Network module) we would achieve better results and we also failed to train the Stacked Attention Network solution to find similar regions in the images of similar advertisements. We believe that with further training of the Stacked Attention Network solution, we might get better results and that by using the attention maps of the images, we would be able to have a better representation of the effect of the visual information.</p>
</div>
</section>
</section>
<section id="Ch5" class="ltx_chapter">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 5 </span>Conclusions</h2>

<div id="Ch5.p1" class="ltx_para">
<p id="Ch5.p1.1" class="ltx_p">In this dissertation, we proposed two novel neural network-based solutions for the problem of multi-modal Record Linkage. When doing experiments with the RNN + CNN solution we found that the hyperparameters that were the best setting for the fusion module in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and the Siamese Neural Network in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, didn’t achieve good results, therefore we concluded that the hyperparameter settings from these papers didn’t transfer well from their tasks to ours. We were not able to achieve the objective set regarding the Stacked Attention Network solution, because of time constraints with our training process. We weren’t able to find any evidence in the attention maps produced by the SAN solution that the model learned how to attend similar regions in the images of similar advertisements. By comparing the models we proved that the RNN + CNN solution achieves better Average Precision Score than the baseline. We also found that there is a correlation between how well the model performs depending on the average length of the descriptions of the advertisements. If the average length is over 40 words, then the model performs worse than the overall average precision score. The RNN + CNN is too optimistic with pairs of advertisements whose average description length is over 40 words, meaning that it usually classifies dissimilar pairs as similar. Therefore we believe that the RNN + CNN model struggles when the advertisements have very different description lengths or very long description lengths.</p>
</div>
<div id="Ch5.p2" class="ltx_para">
<p id="Ch5.p2.1" class="ltx_p">For future work, we propose training the Stacked Attention Network for longer and training just an RNN module that will work only with the descriptions of the advertisements. We believe that by doing this, we could further investigate the overall effect of the images in our multi-modal fusion solutions. Another possibility would be to explore bilinear fusion as an alternative to the Stacked Neural Network fusion module <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick,
and D. Parikh.

</span>
<span class="ltx_bibblock">Vqa: Visual question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">2015 IEEE International Conference on Computer Vision
(ICCV)</span>, pages 2425–2433, Dec 2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
C Lawrence Zitnick, and Devi Parikh.

</span>
<span class="ltx_bibblock">Vqa: Visual question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</span>, pages 2425–2433, 2015.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla.

</span>
<span class="ltx_bibblock">Segnet: A deep convolutional encoder-decoder architecture for image
segmentation.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</span>,
39(12):2481–2495, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Neural machine translation by jointly learning to align and
translate.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1409.0473</span>, 2014.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Mikhail Bilenko, Raymond Mooney, William Cohen, Pradeep Ravikumar, and Stephen
Fienberg.

</span>
<span class="ltx_bibblock">Adaptive name matching in information integration.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">IEEE Intelligent Systems</span>, 18(5):16–23, September 2003.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov.

</span>
<span class="ltx_bibblock">Enriching word vectors with subword information.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1607.04606</span>, 2016.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Säckinger, and Roopak
Shah.

</span>
<span class="ltx_bibblock">Signature verification using a” siamese” time delay neural network.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, pages
737–744, 1994.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Remi Cadene, Hedi Ben-Younes, Matthieu Cord, and Nicolas Thome.

</span>
<span class="ltx_bibblock">Murel: Multimodal relational reasoning for visual question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 1989–1998, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart Van Merriënboer, Dzmitry Bahdanau, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">On the properties of neural machine translation: Encoder-decoder
approaches.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1409.1259</span>, 2014.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart van Merrienboer, Çaglar Gülçehre, Fethi
Bougares, Holger Schwenk, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Learning phrase representations using RNN encoder-decoder for
statistical machine translation.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1406.1078, 2014.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
P. Christen.

</span>
<span class="ltx_bibblock">A survey of indexing techniques for scalable record linkage and
deduplication.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</span>,
24(9):1537–1555, Sep. 2012.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Munir Cochinwala, Verghese Kurien, Gail Lalk, and Dennis Shasha.

</span>
<span class="ltx_bibblock">Efficient data reconciliation.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Inf. Sci.</span>, 137(1-4):1–15, September 2001.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Ahmed K. Elmagarmid, Panagiotis G. Ipeirotis, and Vassilios S. Verykios.

</span>
<span class="ltx_bibblock">Duplicate record detection: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">IEEE Trans. on Knowl. and Data Eng.</span>, 19(1):1–16, January 2007.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Ivan P. Fellegi and Alan B. Sunter.

</span>
<span class="ltx_bibblock">A theory for record linkage.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Journal of the American Statistical Association</span>,
64(328):1183–1210, 1969.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Deep Learning</span>.

</span>
<span class="ltx_bibblock">MIT Press, 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.deeplearningbook.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.deeplearningbook.org</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Anja Gruenheid, Xin Luna Dong, and Divesh Srivastava.

</span>
<span class="ltx_bibblock">Incremental record linkage.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Proc. VLDB Endow.</span>, 7(9):697–708, May 2014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Oktie Hassanzadeh, Fei Chiang, Hyun Chul Lee, and Renée J Miller.

</span>
<span class="ltx_bibblock">Framework for evaluating clustering algorithms in duplicate
detection.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the VLDB Endowment</span>, 2(1):1282–1293, 2009.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1512.03385, 2015.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 770–778, 2016.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Sepp Hochreiter and Jürgen Schmidhuber.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Neural computation</span>, 9(8):1735–1780, 1997.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov.

</span>
<span class="ltx_bibblock">Siamese neural networks for one-shot image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">ICML deep learning workshop</span>, volume 2, 2015.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Pradap Konda, Sanjib Das, Paul Suganthan G. C., AnHai Doan, Adel Ardalan,
Jeffrey R. Ballard, Han Li, Fatemah Panahi, Haojun Zhang, Jeffrey F.
Naughton, Shishir Prasad, Ganesh Krishnan, Rohit Deep, and Vijay Raghavendra.

</span>
<span class="ltx_bibblock">Magellan: Toward building entity matching management systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">PVLDB</span>, 9(12):1197–1208, 2016.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Hanna Köpcke, Andreas Thor, and Erhard Rahm.

</span>
<span class="ltx_bibblock">Evaluation of entity resolution approaches on real-world match
problems.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proc. VLDB Endow.</span>, 3(1-2):484–493, September 2010.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Nick Koudas, Sunita Sarawagi, and Divesh Srivastava.

</span>
<span class="ltx_bibblock">Record linkage: similarity measures and algorithms.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2006 ACM SIGMOD international conference
on Management of data</span>, pages 802–803. ACM, 2006.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, pages
1097–1105, 2012.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Scikit learn staff.

</span>
<span class="ltx_bibblock">Average precision score.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html</a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Yann LeCun, Bernhard E. Boser, John S. Denker, Donnie Henderson, Richard E.
Howard, Wayne E. Hubbard, and Lawrence D. Jackel.

</span>
<span class="ltx_bibblock">Backpropagation applied to handwritten zip code recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Neural Computation</span>, 1(4):541–551, 1989.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner, et al.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, 86(11):2278–2324, 1998.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Andrew McCallum, Kamal Nigam, and Lyle H Ungar.

</span>
<span class="ltx_bibblock">Efficient clustering of high-dimensional data sets with application
to reference matching.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Proceedings of the sixth ACM SIGKDD international conference
on Knowledge discovery and data mining</span>, pages 169–178. Citeseer, 2000.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
T. Mikolov and G. Zweig.

</span>
<span class="ltx_bibblock">Context dependent recurrent neural network language model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">2012 IEEE Spoken Language Technology Workshop (SLT)</span>, pages
234–239, Dec 2012.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Sidharth Mudgal, Han Li, Theodoros Rekatsinas, AnHai Doan, Youngchoon Park,
Ganesh Krishnan, Rohit Deep, Esteban Arcaute, and Vijay Raghavendra.

</span>
<span class="ltx_bibblock">Deep learning for entity matching: A design space exploration.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2018 International Conference on
Management of Data</span>, SIGMOD ’18, pages 19–34, New York, NY, USA, 2018. ACM.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Hyeonseob Nam, Jung-Woo Ha, and Jeonghee Kim.

</span>
<span class="ltx_bibblock">Dual attention networks for multimodal reasoning and matching.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1611.00471, 2016.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Christopher Olah.

</span>
<span class="ltx_bibblock">Understanding lstms, August 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Supriya Pandhre and Shagun Sodhani.

</span>
<span class="ltx_bibblock">Survey of recent advances in visual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1709.08203, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Jeffrey Pennington, Richard Socher, and Christopher D. Manning.

</span>
<span class="ltx_bibblock">Glove: Global vectors for word representation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">In EMNLP</span>, 2014.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
David E Rumelhart, Geoffrey E Hinton, Ronald J Williams, et al.

</span>
<span class="ltx_bibblock">Learning representations by back-propagating errors.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Cognitive modeling</span>, 5(3):1, 1988.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Avito Russia.

</span>
<span class="ltx_bibblock">Avito duplicate ads detection dataset, February 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.kaggle.com/c/avito-duplicate-ads-detection/data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/c/avito-duplicate-ads-detection/data</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch.

</span>
<span class="ltx_bibblock">Edinburgh neural machine translation systems for wmt 16.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1606.02891</span>, 2016.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Karen Simonyan and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Very deep convolutional networks for large-scale image recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1409.1556</span>, 2014.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov.

</span>
<span class="ltx_bibblock">Dropout: a simple way to prevent neural networks from overfitting.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">The journal of machine learning research</span>, 15(1):1929–1958,
2014.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Martin Sundermeyer, Ralf Schlüter, and Hermann Ney.

</span>
<span class="ltx_bibblock">Lstm neural networks for language modeling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Thirteenth annual conference of the international speech
communication association</span>, 2012.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Rinalds Vīksna and Gints Jēkabsons.

</span>
<span class="ltx_bibblock">Sentiment analysis in latvian and russian: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Applied Computer Systems</span>, 23(1):45–51, 2018.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al.

</span>
<span class="ltx_bibblock">Matching networks for one shot learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, pages
3630–3638, 2016.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
William E Winkler.

</span>
<span class="ltx_bibblock">Methods for evaluating and creating data quality.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Information Systems</span>, 29(7):531–550, 2004.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan
Salakhutdinov, Richard S. Zemel, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Show, attend and tell: Neural image caption generation with visual
attention.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1502.03044, 2015.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alexander J. Smola.

</span>
<span class="ltx_bibblock">Stacked attention networks for image question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1511.02274, 2015.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Quanzeng You, Hailin Jin, Zhaowen Wang, Chen Fang, and Jiebo Luo.

</span>
<span class="ltx_bibblock">Image captioning with semantic attention.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 4651–4659, 2016.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Sergey Zagoruyko and Nikos Komodakis.

</span>
<span class="ltx_bibblock">Learning to compare image patches via convolutional neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 4353–4361, 2015.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2007.05880" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2007.05881" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2007.05881">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2007.05881" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2007.05882" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  8 15:38:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
