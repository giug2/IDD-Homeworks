<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2209.11843] Privacy–Preserving Online Content Moderation: A Federated Learning Use Case</title><meta property="og:description" content="Users are exposed to a large volume of harmful content that appears daily on various social network platforms. One solution to users’ protection is developing online moderation tools using Machine Learning (ML) techniq…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Privacy–Preserving Online Content Moderation: A Federated Learning Use Case">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Privacy–Preserving Online Content Moderation: A Federated Learning Use Case">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2209.11843">

<!--Generated on Wed Mar 13 20:56:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Privacy–Preserving Online Content Moderation: A Federated Learning Use Case</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Pantelitsa Leonidou<sup id="id2.1.id1" class="ltx_sup">1</sup>
Nicolas Kourtellis <sup id="id3.2.id2" class="ltx_sup">2</sup>
Nikos Salamanos <sup id="id4.3.id3" class="ltx_sup">1</sup>
Michael Sirivianos <sup id="id5.4.id4" class="ltx_sup">1</sup>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.1" class="ltx_p">Users are exposed to a large volume of harmful content that appears daily on various social network platforms. One solution to users’ protection is developing online moderation tools using Machine Learning (ML) techniques for automatic detection or content filtering. On the other hand, the processing of user data by social network platforms requires compliance with privacy policies. Federated Learning (FL) is one of the proposed solutions, where the training of ML models is performed locally on the users’ devices (the FL “clients”), and only the model updates are shared with the central server (the FL central aggregator). Although the raw data never leave the users’ devices, privacy leaks can still occur. One threat is data (or membership) inference attacks, where an attacker accessing the final trained model (the FL output) can successfully perform unwanted inference of the data belonging to the users who participated in the training process. In this paper, we propose a privacy–preserving FL framework for online content moderation that incorporates Differential Privacy (DP). To demonstrate the feasibility of our approach, we focus on detecting harmful content on Twitter – but the overall concept can be generalized to other types of misbehavior. We simulate a text classifier –- in a distributed FL fashion –- which can detect tweets with harmful content. We show that the performance of the proposed FL framework can be close to the centralized approach – for both the DP and non–DP FL versions. Moreover, it has a high performance even if a small number of clients (each with a small number of data points) are available for the FL training. When reducing the number of clients (from fifty to ten) or the data points per client (from 1K to 0.1K), the classifier can still achieve <math id="id1.1.m1.1" class="ltx_Math" alttext="{\sim}{81}\%" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml"></mi><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">∼</mo><mrow id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml"><mn id="id1.1.m1.1.1.3.2" xref="id1.1.m1.1.1.3.2.cmml">81</mn><mo id="id1.1.m1.1.1.3.1" xref="id1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">absent</csymbol><apply id="id1.1.m1.1.1.3.cmml" xref="id1.1.m1.1.1.3"><csymbol cd="latexml" id="id1.1.m1.1.1.3.1.cmml" xref="id1.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="id1.1.m1.1.1.3.2.cmml" xref="id1.1.m1.1.1.3.2">81</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">{\sim}{81}\%</annotation></semantics></math> AUC. Furthermore, we extend the evaluation to four other Twitter datasets that capture different types of user misbehavior and still obtain a promising performance (61% – 80% AUC). Finally, we explore the overhead on the users’ devices during the FL training phase and show that the local training does not introduce excessive CPU utilization and memory consumption overhead.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Users of all ages are exposed to a large volume of information from various Online Social Networks (OSNs). The content is often questionable or even harmful regardless of age, expressing abusive behavior, extreme sarcasm, cyberbullying, racism, and offensive or hate speech. OSN platforms try to protect users by setting special terms and conditions, blocking malicious accounts, and flagging or even taking down harmful content. Despite these efforts, harmful content is still present. Researchers and developers have made a great effort to develop automated detection tools mainly based on Machine Learning (ML) algorithms  <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib10" title="" class="ltx_ref">2018</a>; Rajadesingan, Zafarani, and Liu <a href="#bib.bib20" title="" class="ltx_ref">2015</a>; Waseem and Hovy <a href="#bib.bib24" title="" class="ltx_ref">2016</a>; Davidson et al. <a href="#bib.bib7" title="" class="ltx_ref">2017</a>; Chatzakou et al. <a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite>.
These ML models are first trained on large annotated datasets and then deployed online. One challenge is creating large labeled datasets suitable for deep learning training. The data are large (from millions of users), multi-modal (text, video, and images or a combination of those), and they change dynamically. Additionally, it is challenging for the platforms and researchers to collect and process these data in the first place. The users’ online data are private and sensitive, which is why the EU has imposed strict policies to protect users’ privacy (GDPR and accompanying national legislation).</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper, we investigate whether privacy–preserving ML methods can effectively detect harmful online content while complying with privacy policies. For this purpose, we propose and evaluate a privacy–preserving Federated Learning (FL) framework for training text classifiers able to detect harmful content. FL is a collaborative ML training process where in each round, the training phase is performed locally at users’ devices (the FL “clients”), and only the model parameters are sent to the central server (the FL “aggregator”). The central server aggregates the received information and updates the global model <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al. <a href="#bib.bib14" title="" class="ltx_ref">2017</a>)</cite>. Therefore, FL has access to local, up-to-date user data and does not require such data to be globally collected by a central unit for storage and ML training; data that are usually massive in volume and a potential target for cyber-attacks, theft, and prying on.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Although the FL paradigm complies, in theory, with the GDPR policies (since the raw data never leave the users’ devices), privacy leakages can still occur. Prior studies have shown that the FL framework is vulnerable to membership inference and backdoor attacks <cite class="ltx_cite ltx_citemacro_citep">(Andrew et al. <a href="#bib.bib3" title="" class="ltx_ref">2021</a>; Naseri, Hayes, and De Cristofaro <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>. In this paper, we consider Differential Privacy (DP) as a defense mechanism against membership and attribute inference attacks <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al. <a href="#bib.bib8" title="" class="ltx_ref">2006</a>; Dwork and Roth <a href="#bib.bib9" title="" class="ltx_ref">2014</a>)</cite>. DP provides privacy guarantees (at the user level) against data (or membership) inference attacks by an external attacker who has access to the trained model. We incorporate the DP model proposed in <cite class="ltx_cite ltx_citemacro_citep">(Andrew et al. <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> which is a generalization of DP for the FL framework.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our central research question is whether harmful online content can be detected efficiently and effectively by a privacy–preserving FL framework. To answer this, we bootstrap our ML text model from a modified version of the classifier presented in <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>. We evaluate it when trained in an FL fashion (with and without DP) on different Twitter datasets from five studies of Twitter user misbehavior by generalizing the classification problem as detecting harmful or normal behavior.
We compare the classifier’s FL performance with the centralized version that has access to all data.
Finally, we assess a typical user device’s overhead while training the classifier locally to examine whether the FL approach slows down the device.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">This work makes the following contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We are the first to propose a methodology for applying privacy–preserving FL in the context of harmful content detection. Moreover, we provide a simulation methodology for using centralized datasets to test the performance of an FL framework.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.2" class="ltx_p">We show that the performance of the proposed FL framework can be close to the centralized approach – for both the DP and non–DP FL versions. The FL classification performance on a total of 100K tweets has only a 10% difference in AUC compared to the centralized approach. For instance, by training the classifier (without DP) for only twenty FL rounds on fifty clients, we achieve <math id="S1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="{\sim}{83}\%" display="inline"><semantics id="S1.I1.i2.p1.1.m1.1a"><mrow id="S1.I1.i2.p1.1.m1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.cmml"><mi id="S1.I1.i2.p1.1.m1.1.1.2" xref="S1.I1.i2.p1.1.m1.1.1.2.cmml"></mi><mo id="S1.I1.i2.p1.1.m1.1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.1.cmml">∼</mo><mrow id="S1.I1.i2.p1.1.m1.1.1.3" xref="S1.I1.i2.p1.1.m1.1.1.3.cmml"><mn id="S1.I1.i2.p1.1.m1.1.1.3.2" xref="S1.I1.i2.p1.1.m1.1.1.3.2.cmml">83</mn><mo id="S1.I1.i2.p1.1.m1.1.1.3.1" xref="S1.I1.i2.p1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.1.m1.1b"><apply id="S1.I1.i2.p1.1.m1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i2.p1.1.m1.1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S1.I1.i2.p1.1.m1.1.1.2.cmml" xref="S1.I1.i2.p1.1.m1.1.1.2">absent</csymbol><apply id="S1.I1.i2.p1.1.m1.1.1.3.cmml" xref="S1.I1.i2.p1.1.m1.1.1.3"><csymbol cd="latexml" id="S1.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S1.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S1.I1.i2.p1.1.m1.1.1.3.2">83</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.1.m1.1c">{\sim}{83}\%</annotation></semantics></math> AUC. Moreover, when reducing the number of clients (from fifty to ten) or the data points per client (from 1K to 0.1K), the classifier can still achieve <math id="S1.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="{\sim}{81}\%" display="inline"><semantics id="S1.I1.i2.p1.2.m2.1a"><mrow id="S1.I1.i2.p1.2.m2.1.1" xref="S1.I1.i2.p1.2.m2.1.1.cmml"><mi id="S1.I1.i2.p1.2.m2.1.1.2" xref="S1.I1.i2.p1.2.m2.1.1.2.cmml"></mi><mo id="S1.I1.i2.p1.2.m2.1.1.1" xref="S1.I1.i2.p1.2.m2.1.1.1.cmml">∼</mo><mrow id="S1.I1.i2.p1.2.m2.1.1.3" xref="S1.I1.i2.p1.2.m2.1.1.3.cmml"><mn id="S1.I1.i2.p1.2.m2.1.1.3.2" xref="S1.I1.i2.p1.2.m2.1.1.3.2.cmml">81</mn><mo id="S1.I1.i2.p1.2.m2.1.1.3.1" xref="S1.I1.i2.p1.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.2.m2.1b"><apply id="S1.I1.i2.p1.2.m2.1.1.cmml" xref="S1.I1.i2.p1.2.m2.1.1"><csymbol cd="latexml" id="S1.I1.i2.p1.2.m2.1.1.1.cmml" xref="S1.I1.i2.p1.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S1.I1.i2.p1.2.m2.1.1.2.cmml" xref="S1.I1.i2.p1.2.m2.1.1.2">absent</csymbol><apply id="S1.I1.i2.p1.2.m2.1.1.3.cmml" xref="S1.I1.i2.p1.2.m2.1.1.3"><csymbol cd="latexml" id="S1.I1.i2.p1.2.m2.1.1.3.1.cmml" xref="S1.I1.i2.p1.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S1.I1.i2.p1.2.m2.1.1.3.2.cmml" xref="S1.I1.i2.p1.2.m2.1.1.3.2">81</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.2.m2.1c">{\sim}{81}\%</annotation></semantics></math> AUC. In other words, we can achieve high performance even if few clients (with few data locally) are available.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Our further evaluation of the classifier on four smaller Twitter datasets of other types of misbehavior shows promising performance, ranging from 61% to 80% AUC. This means that the classifier can generalize and detect different types of misbehavior.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Finally, we show that the FL training process does not introduce excessive system overhead – in terms of CPU utilization and memory consumption –- on the users’ devices.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">The simulation and the classifier code are made available to the research community.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2209.11843/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="484" height="237" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>FL Differential Private Framework and Dataflow</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Machine Learning for Automatic Detection and Filtering of Harmful Content</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Harmful content can be found in a text, visual (image, video), audio (songs, recordings) format, or a combination of those. We define any violent, abusive, sexual, disrespectful, hateful, illegal content, or any content that may harm the user as <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">“harmful”</span>. One solution to protect users from such content is adopting automatic detection or filtering using Machine Learning techniques in online moderation tools.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Several studies have investigated misbehavior on Twitter. <cite class="ltx_cite ltx_citemacro_citep">(Chatzakou et al. <a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite> proposes a deep-learning architecture to classify various types of abusive behavior (bullying and aggression) on Twitter. They proposed a methodology of extracting textual, user, and network-based features for Twitter accounts to identify patterns of abusive behavior. Then, they applied the methodology in a large dataset of 1.6M tweets collected during a period of three months. <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite> presents a unified deep learning classifier to detect abusive texts on Twitter. The authors tested the unified classifier with several abusive Twitter datasets and achieved high performance. One of the evaluation datasets was the one presented in  <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite> with 100K tweets labeled as “Abusive”, “Hate”, “Normal”, and “Spam” using crowdsourcing annotation techniques. The unified classifier consists of two different classifiers whose results are combined to give the final result. One classifier is a text classification model, and the other treats domain-specific metadata (i.e., user’s friend network, number of retweets, etc.). They tested the unified classifier with several abusive Twitter datasets and achieved high performance. In this work, we adopt a simplified version of the proposed classifier by replicating the model for the text classification task – since we use no meta-data as training input but only text stored on a user’s device.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Yenala et al. proposed a deep learning architecture for detecting inappropriate language in query completion suggestions in search engines and users’ conversations in messengers <cite class="ltx_cite ltx_citemacro_citep">(Yenala et al. <a href="#bib.bib27" title="" class="ltx_ref">2018</a>)</cite>. They used Convolution Neural Networks and Bi-directional LSTMs sequential model for the use case of the search engine suggestions and LSTM and Bidirectional LSTM sequential model for the users’ conversations messengers. They prove that the suggested architecture outperforms pattern-based and hand-crafted feature-based architectures. The authors in <cite class="ltx_cite ltx_citemacro_citep">(Alshamrani et al. <a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> collected a dataset of <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="{\sim}{4}M" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mrow id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.1.1.2" xref="S2.SS1.p3.1.m1.1.1.2.cmml"></mi><mo id="S2.SS1.p3.1.m1.1.1.1" xref="S2.SS1.p3.1.m1.1.1.1.cmml">∼</mo><mrow id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3.cmml"><mn id="S2.SS1.p3.1.m1.1.1.3.2" xref="S2.SS1.p3.1.m1.1.1.3.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.1.1.3.1" xref="S2.SS1.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.1.1.3.3" xref="S2.SS1.p3.1.m1.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><csymbol cd="latexml" id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2">absent</csymbol><apply id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3"><times id="S2.SS1.p3.1.m1.1.1.3.1.cmml" xref="S2.SS1.p3.1.m1.1.1.3.1"></times><cn type="integer" id="S2.SS1.p3.1.m1.1.1.3.2.cmml" xref="S2.SS1.p3.1.m1.1.1.3.2">4</cn><ci id="S2.SS1.p3.1.m1.1.1.3.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">{\sim}{4}M</annotation></semantics></math> records to assess the exposure of kids and adolescents to inappropriate comments on YouTube. They built a model consisting of five high-accuracy classifiers using Natural Language Processing and ML to classify the comments obtained in five age-inappropriate classes (Toxic, Obscene, Insult, Threat, Identity hate). The model acts as a binary classifier that classifies input as inappropriate if it falls into at least one of the five classes.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Papadamou et al. built a deep learning classifier to detect videos with inappropriate content that targets toddlers on YouTube with high accuracy (84.3%) <cite class="ltx_cite ltx_citemacro_citep">(Papadamou et al. <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>. The authors in <cite class="ltx_cite ltx_citemacro_citep">(Tahir et al. <a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite> created a dataset with three different categories of videos: “Original Videos”, “Explicit Fake Videos”, and “Violent Fake Videos”. They trained a deep learning classifier to detect videos with content inappropriate for kids. with an accuracy of more than 90%. Additionally, Papadamou et al. collected <math id="S2.SS1.p4.1.m1.1" class="ltx_Math" alttext="{\sim}{7}K" display="inline"><semantics id="S2.SS1.p4.1.m1.1a"><mrow id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml"><mi id="S2.SS1.p4.1.m1.1.1.2" xref="S2.SS1.p4.1.m1.1.1.2.cmml"></mi><mo id="S2.SS1.p4.1.m1.1.1.1" xref="S2.SS1.p4.1.m1.1.1.1.cmml">∼</mo><mrow id="S2.SS1.p4.1.m1.1.1.3" xref="S2.SS1.p4.1.m1.1.1.3.cmml"><mn id="S2.SS1.p4.1.m1.1.1.3.2" xref="S2.SS1.p4.1.m1.1.1.3.2.cmml">7</mn><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.1.1.3.1" xref="S2.SS1.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p4.1.m1.1.1.3.3" xref="S2.SS1.p4.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><apply id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1"><csymbol cd="latexml" id="S2.SS1.p4.1.m1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S2.SS1.p4.1.m1.1.1.2.cmml" xref="S2.SS1.p4.1.m1.1.1.2">absent</csymbol><apply id="S2.SS1.p4.1.m1.1.1.3.cmml" xref="S2.SS1.p4.1.m1.1.1.3"><times id="S2.SS1.p4.1.m1.1.1.3.1.cmml" xref="S2.SS1.p4.1.m1.1.1.3.1"></times><cn type="integer" id="S2.SS1.p4.1.m1.1.1.3.2.cmml" xref="S2.SS1.p4.1.m1.1.1.3.2">7</cn><ci id="S2.SS1.p4.1.m1.1.1.3.3.cmml" xref="S2.SS1.p4.1.m1.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">{\sim}{7}K</annotation></semantics></math> YouTube videos related to pseudoscientific content and used the resulting dataset to train a deep learning classifier to detect misinformation videos on YouTube and achieved an accuracy of 79% <cite class="ltx_cite ltx_citemacro_citep">(Papadamou et al. <a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite>. These studies used video processing techniques to extract information from the videos but also collected other related information (i.e., the video’s title, comments, caption, etc.). Moreover, this work focuses on detecting inappropriate text content.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Federated Learning and Differential Privacy</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">McMahan et al. introduced Federated Learning(FL) as a distributed approach for training machine learning models without sharing an individual’s data with a central unit <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al. <a href="#bib.bib14" title="" class="ltx_ref">2017</a>)</cite>. The idea is to train local models on clients’ devices with their on-device available data and only share locally-computed updates with the central server. The server will collect the locally computed updates from the clients and aggregate them to update the global model. A client device in an FL setting can scale from a mobile device, a laptop, a desktop, or an IoT device to a company’s data server.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Since the FL appearance, many studies have described FL applications in real settings. Gboard <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite> uses FL for training, evaluating, and deploying a model for giving optimized web, GIFs, and Stickers query suggestions. Gboard also used FL to train a model for next-word prediction<cite class="ltx_cite ltx_citemacro_citep">(Hard et al. <a href="#bib.bib12" title="" class="ltx_ref">2018</a>)</cite>. Next word prediction is used on the keyboard to suggest words for the user to type next based on the text already typed. In <cite class="ltx_cite ltx_citemacro_citep">(Chen et al. <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>, the authors applied FL to train a neural network to learn out-of-vocabulary (OOV) words to minimize annoying users by auto-correcting the OOV words considering them as misspellings. FL is also used to train an image-classification model to decide whether a patient has the COVID-19 virus or not using x-ray images from several hospitals to preserve the patients’ privacy in <cite class="ltx_cite ltx_citemacro_citep">(Yan et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>. The performance obtained when training the models using FL was slightly worse than training using a centralized approach.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Several studies have shown that maintaining the raw data locally does not sufficiently protect the users’ privacy so data leakages can occur in the FL framework. There are two main potential threats to data privacy; data inference attacks performed (i) by the other clients – or even the central aggregator – during the training phase and (ii) by an external attacker who has access to the final trained model. One of the proposed ways to provide privacy-preserving guarantees to FL is Differential Privacy (DP). The DP was first introduced by <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al. <a href="#bib.bib8" title="" class="ltx_ref">2006</a>; Dwork and Roth <a href="#bib.bib9" title="" class="ltx_ref">2014</a>)</cite> as a privacy–preserving technique for learning tasks on statistical databases. It can limit the information leakages regarding the data records used for the learning phase. DP provides statistical guarantees against data inference attacks performed by an adversary who has access to the output of the learning algorithm. These privacy guarantees are achieved by adding noise to the learning process to limit the data records’ influence on the algorithm’s final output. Two main variations of DP methodology have been incorporated into the FL framework toward privacy–preserving FL: the Central Differential Privacy (CDP) and the Local Differential Privacy (LDP) <cite class="ltx_cite ltx_citemacro_citep">(Naseri, Hayes, and De Cristofaro <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>; other hybrid approaches have also lately proposed <cite class="ltx_cite ltx_citemacro_citep">(Chandrasekaran et al. <a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>. In CDP, the agents send the model updates to the central server, which will perform the DP noise addition <cite class="ltx_cite ltx_citemacro_citep">(Andrew et al. <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>. This implies that the central server is a trusted system entity, namely, it will not perform malicious inferences on the clients’ data. In LDP, the DP noise addition is performed locally by the clients – before sending the updates to the central server <cite class="ltx_cite ltx_citemacro_citep">(Truex et al. <a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>. In this context, no trusted entity is required.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Conceptual Framework</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To further explain the idea of applying the FL paradigm to the online moderation tools, we present our conceptual framework in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Regarding the <span id="S3.p1.1.1" class="ltx_text ltx_font_bold">threat model</span> we assume that the only trusted entity is the central aggregator. Under the Central Differential Private protocol <cite class="ltx_cite ltx_citemacro_citep">(Andrew et al. <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> – that we use in this study – the central aggregator is responsible for adding the DP–noise on the model updates that receives from the clients in an FL round. This implies that the aggregator is a trusted entity, but the other participants may not. Hence, possible adversaries are either some clients or an external entity that may perform data inference attacks either during the training phase or through the final model.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>System Components</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold">Client Device:</span> The user’s device that accesses the Online Social Network application (i.e, Twitter).</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Browser Add-On:</span> filters the users’ online activity, conducts DOM tree analysis, and sends the selected data (i.e., tweets) to the Labeling Module.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Labeling Module:</span> aggregates the labels obtained from the Auto-Labeling and User Feedback modules. <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_italic">Auto-Labeling module</span> can use semi-supervised learning techniques to label the data automatically. The <span id="S3.SS1.p3.1.3" class="ltx_text ltx_font_italic">User Feedback module</span> asks the user to label the data.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Local Database:</span> stores the labeled data.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">FL Module:</span> schedules and executes FL tasks on the user device. <span id="S3.SS1.p5.1.2" class="ltx_text ltx_font_bold">FL task</span> defines and executes the <span id="S3.SS1.p5.1.3" class="ltx_text ltx_font_bold">Local training</span>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para ltx_noindent">
<p id="S3.SS1.p6.1" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">Data properties computing:</span> the module that computes the metadata of the user’s dataset (i.e., size of data, etc.), accompanied by other device information (e.g., battery, internet connection type, device capabilities, etc.).</p>
</div>
<div id="S3.SS1.p7" class="ltx_para ltx_noindent">
<p id="S3.SS1.p7.1" class="ltx_p"><span id="S3.SS1.p7.1.1" class="ltx_text ltx_font_bold">Cloud Server:</span> a unit owned by a trusted party that coordinates the FL training.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para ltx_noindent">
<p id="S3.SS1.p8.1" class="ltx_p"><span id="S3.SS1.p8.1.1" class="ltx_text ltx_font_bold">FL Task Configuration:</span> generates the FL Task description, which contains the baseline model for training, the criteria for the clients to participate in this task, and the FL parameters (e.g., number of FL rounds, the number of clients to participate, etc.).</p>
</div>
<div id="S3.SS1.p9" class="ltx_para ltx_noindent">
<p id="S3.SS1.p9.1" class="ltx_p"><span id="S3.SS1.p9.1.1" class="ltx_text ltx_font_bold">Scheduler:</span> advertise the FL task to the available clients and manage the communication with the clients.</p>
</div>
<div id="S3.SS1.p10" class="ltx_para ltx_noindent">
<p id="S3.SS1.p10.1" class="ltx_p"><span id="S3.SS1.p10.1.1" class="ltx_text ltx_font_bold">Client Selection Mechanism:</span> checks if the client’s device complies with the criteria set by the FL Task Config module.</p>
</div>
<div id="S3.SS1.p11" class="ltx_para ltx_noindent">
<p id="S3.SS1.p11.1" class="ltx_p"><span id="S3.SS1.p11.1.1" class="ltx_text ltx_font_bold">Model Aggregator:</span> aggregates the clients’ model updates and applies the aggregated update to the global model.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data-Flow</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the data flow of the proposed framework. Specifically:</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">(A1)</span> The user accesses Twitter through the device’s browser, <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_bold">(A2)</span> and sends an HTTP request to Twitter. <span id="S3.SS2.p2.1.3" class="ltx_text ltx_font_bold">(A3)</span> The <span id="S3.SS2.p2.1.4" class="ltx_text ltx_font_italic">Browser Add–On</span>’s <span id="S3.SS2.p2.1.5" class="ltx_text ltx_font_italic">DOM Tree Analysis module</span> receives the Twitter newsfeed page DOM tree, filters the user activity, and selects data for labeling. <span id="S3.SS2.p2.1.6" class="ltx_text ltx_font_bold">(A4)</span> The <span id="S3.SS2.p2.1.7" class="ltx_text ltx_font_italic">Labeling module</span> receives the data (e.g. a tweet text). The <span id="S3.SS2.p2.1.8" class="ltx_text ltx_font_italic">Auto Labeling module</span> automatically labels the data. The <span id="S3.SS2.p2.1.9" class="ltx_text ltx_font_italic">User Feedback module</span> asks the user to label it. <span id="S3.SS2.p2.1.10" class="ltx_text ltx_font_bold">(A5)</span> Then, the two labeling modules send the {tweet, label} pairs to the <span id="S3.SS2.p2.1.11" class="ltx_text ltx_font_italic">Labeling Aggregator</span>, which defines a final label for the tweet using an aggregation method, and <span id="S3.SS2.p2.1.12" class="ltx_text ltx_font_bold">(A6)</span> stores the labeled data at the <span id="S3.SS2.p2.1.13" class="ltx_text ltx_font_italic">Local Database</span>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">When there is a pending FL task at the server, <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">(B1)</span> the <span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_italic">FL Task Config module</span> sends the task description to the <span id="S3.SS2.p3.1.3" class="ltx_text ltx_font_italic">Scheduler</span>. <span id="S3.SS2.p3.1.4" class="ltx_text ltx_font_bold">(B2)</span> The <span id="S3.SS2.p3.1.5" class="ltx_text ltx_font_italic">Scheduler</span> sends the task descriptions to the available clients. <span id="S3.SS2.p3.1.6" class="ltx_text ltx_font_bold">(B3)</span> The <span id="S3.SS2.p3.1.7" class="ltx_text ltx_font_italic">client’s FL Scheduler</span> receives it, and forwards it to the <span id="S3.SS2.p3.1.8" class="ltx_text ltx_font_italic">Data properties Computing module</span>, <span id="S3.SS2.p3.1.9" class="ltx_text ltx_font_bold">(B4)</span> which sends the device properties back to it. <span id="S3.SS2.p3.1.10" class="ltx_text ltx_font_bold">(B5)</span> The <span id="S3.SS2.p3.1.11" class="ltx_text ltx_font_italic">FL scheduler</span> sends the properties to the <span id="S3.SS2.p3.1.12" class="ltx_text ltx_font_italic">Scheduler</span>, <span id="S3.SS2.p3.1.13" class="ltx_text ltx_font_bold">(B6)</span> which forwards them to the <span id="S3.SS2.p3.1.14" class="ltx_text ltx_font_italic">Client Selection Mechanism</span> to tell if the client will participate in the training or not. <span id="S3.SS2.p3.1.15" class="ltx_text ltx_font_bold">(B7)</span> The mechanism module sends its positive or negative decision to the <span id="S3.SS2.p3.1.16" class="ltx_text ltx_font_italic">Scheduler</span>, <span id="S3.SS2.p3.1.17" class="ltx_text ltx_font_bold">(B8)</span> which announces to the <span id="S3.SS2.p3.1.18" class="ltx_text ltx_font_italic">client’s FL scheduler</span> its participation in training with the global model to train or closes the connection with it.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">For participating clients, <span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">(B9)</span> the <span id="S3.SS2.p4.1.2" class="ltx_text ltx_font_italic">FL Scheduler</span> sends the global model, and the task description to the <span id="S3.SS2.p4.1.3" class="ltx_text ltx_font_italic">FL Task module</span>, and <span id="S3.SS2.p4.1.4" class="ltx_text ltx_font_bold">(B10)</span> requests the local dataset. <span id="S3.SS2.p4.1.5" class="ltx_text ltx_font_bold">(B11)</span> The <span id="S3.SS2.p4.1.6" class="ltx_text ltx_font_italic">Local Database</span> sends the dataset, and starts the local ML training with Differential Privacy (DP) Adaptive Clipping. The <span id="S3.SS2.p4.1.7" class="ltx_text ltx_font_italic">Adaptive Clipping</span> receives the local model’s updates, clip them, and <span id="S3.SS2.p4.1.8" class="ltx_text ltx_font_bold">(B12)</span> sends them to the <span id="S3.SS2.p4.1.9" class="ltx_text ltx_font_italic">Model Aggregator</span>. The <span id="S3.SS2.p4.1.10" class="ltx_text ltx_font_italic">Model Aggregator</span> aggregates the updates, adds <span id="S3.SS2.p4.1.11" class="ltx_text ltx_font_italic">DP–noise</span> (i.e., it adds noise to the updates’ sum), and applies the updates to the global model. Finally, <span id="S3.SS2.p4.1.12" class="ltx_text ltx_font_bold">(B13)</span> it sends the model to the <span id="S3.SS2.p4.1.13" class="ltx_text ltx_font_italic">FL Task Config module</span> for its use in the next round of the FL training.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2209.11843/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Federated Learning Setup Pipeline</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Federated Learning Setup</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>General Assumptions</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Since we do not have access to the raw Twitter data from millions of users, the true distribution of harmful tweets to users is unknown.
Thus, we have to somehow simulate the users’ browsing history. For this purpose, we construct artificial clients by splitting a centralized Twitter dataset – which contains harmful tweets – into a number of disjoint sets. Moreover, we assume a homogeneous population of clients, namely, all clients have the same number of total tweets with the same ratio harmful to normal (i.e., that same class ratio). Additionally, we assume that the clients selected for the FL training remain available during the whole FL phase.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Federated Learning Training</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We used TensorFlow Federated (TFF), an open–source framework for computations on decentralized data<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.tensorflow.org/federated</span></span></span></span>, to simulate the FL training process for our experiments. The FL algorithm we used for aggregating the client’s model updates is the Federated Averaging <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al. <a href="#bib.bib14" title="" class="ltx_ref">2017</a>)</cite>. TFF provides the implementation<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/tensorflow/privacy</span></span></span></span> of Differential Privacy for FL training which we use to add CDP in our FL training simulation. Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2 Data-Flow ‣ 3 Conceptual Framework ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents our pipeline to simulate the FL training. We describe next the FL pipeline’s steps and main components.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Text classifier</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.2" class="ltx_p">We use a simplified version of the unified classification model described in <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>, where only the text-classification path is enabled. We used this classifier since it showed a high performance (<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mo id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\sim</annotation></semantics></math>80% to <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mo id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><csymbol cd="latexml" id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\sim</annotation></semantics></math>93% AUC) across many harmful tweet datasets. We used this simplified version to give a lighter computational task to the user’s device. The input of the classifier is the text of the tweets. We used TensorFlow Keras for the implementation of the classifier. The sequential ML pipeline starts with an Embedding layer, we use the GloVe embedding <cite class="ltx_cite ltx_citemacro_citep">(Pennington, Socher, and Manning <a href="#bib.bib19" title="" class="ltx_ref">2014</a>)</cite> with the highest dimension (200). A Recurrent Neural Network Layer follows with gated recurrent unit (GRU), 128 units, and a dropout of p=0.5. The output layer is a classification dense layer, with one neuron with the sigmoid activation function. We set the parameters as proposed in <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>. TFF framework offers a function that wraps a Keras model<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.tensorflow.org/federated/api˙docs/python/tff/learning/from˙keras˙model</span></span></span></span> for its use in the federated training simulation.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Creating artificial clients for FL</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We needed a decentralized dataset with a sufficient number of harmful and normal texts to simulate the FL training of the text classifier. Since we could not find a dataset fulfilling our criteria, we converted existing centralized datasets from past studies into artificial federated datasets. For this purpose, given a dataset with two classes of tweets (harmful and normal) and a sufficient number of harmful tweets, we do the following:</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">First, we create a test set with a size the 10% of the dataset, with the condition that 8% of the tweets in the test set are harmful. In other words, the class ratio harmful:normal in the test set is 8:92. We apply this percentage (8%) based on the results of previous studies <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib10" title="" class="ltx_ref">2018</a>; Chatzakou et al. <a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite> that showed that the percentage of harmful content on Twitter is around <math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="{\sim}{8}\%" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mrow id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mi id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2.cmml"></mi><mo id="S4.SS4.p2.1.m1.1.1.1" xref="S4.SS4.p2.1.m1.1.1.1.cmml">∼</mo><mrow id="S4.SS4.p2.1.m1.1.1.3" xref="S4.SS4.p2.1.m1.1.1.3.cmml"><mn id="S4.SS4.p2.1.m1.1.1.3.2" xref="S4.SS4.p2.1.m1.1.1.3.2.cmml">8</mn><mo id="S4.SS4.p2.1.m1.1.1.3.1" xref="S4.SS4.p2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S4.SS4.p2.1.m1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.1.1.2">absent</csymbol><apply id="S4.SS4.p2.1.m1.1.1.3.cmml" xref="S4.SS4.p2.1.m1.1.1.3"><csymbol cd="latexml" id="S4.SS4.p2.1.m1.1.1.3.1.cmml" xref="S4.SS4.p2.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS4.p2.1.m1.1.1.3.2.cmml" xref="S4.SS4.p2.1.m1.1.1.3.2">8</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">{\sim}{8}\%</annotation></semantics></math>.
Then, we create the clients using the remaining 90% of the dataset. In our simulation, the clients are represented by sets of tweets (the clients’ local data). To evaluate the FL on different populations of clients, we control the class ratio in clients’ data, i.e harmful:normal. We also set the total number of tweets per client. Finally, given the clients’ class ratio and clients’ data size, we compute the maximum number of clients we can construct.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Evaluation</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Training Setup</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To address the research questions of this work, we conducted experiments having the following training setups:
<br class="ltx_break"><span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold">FL training:</span> For the FL training setup, we are following the method described in Section <a href="#S4.SS4" title="4.4 Creating artificial clients for FL ‣ 4 Federated Learning Setup ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> – given the parameters (clients’ data size, percentage of harmful tweets) – to construct the federated dataset.
Then, we set the FL rounds and the number of participating clients in each round. Finally, we use the TFF framework to simulate the FL training. We refer to <span id="S5.SS1.p1.1.2" class="ltx_text ltx_font_italic">Local training</span> as the training of the model on the client’s device, using the whole client’s dataset as the local training set.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Centralized training:</span> This is the traditional ML training setup where the text classifier is trained with a single train set. Regarding the train–test split, we construct the test set following the same procedure described in Section <a href="#S4.SS4" title="4.4 Creating artificial clients for FL ‣ 4 Federated Learning Setup ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>. That is, we initially split the dataset into a test set of 10% size with class ratio 8:92 (i.e. 8% harmful tweets). Then, from the remaining 90% of the dataset, we construct the train set. We set a class ratio and a training–set size and then we randomly select a subset of tweets that satisfies these properties.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.2" class="ltx_p">In both setups, we train the text classifier described in Section <a href="#S4.SS3" title="4.3 Text classifier ‣ 4 Federated Learning Setup ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>, and we compute the weighted classification metrics<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://scikit-learn.org/</span></span></span></span>. We set the parameters (epochs=7, batch size=10, Adams optimizer, learning rate=0.001) after experimenting with different values for tuning and applying early stopping.
We run all the experiments on a server with Intel(R) Core(TM) i7-7700K CPU <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="@" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mi mathvariant="normal" id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml">@</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><ci id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">@</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">@</annotation></semantics></math> 4.20GHz, and a 62GiB RAM except for the “overhead on client’s device” (Section <a href="#S5.SS7" title="5.7 Overhead on Client’s Device ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.7</span></a>) which we run on a Dell laptop device with Intel(R) Core(TM) i7-6500U CPU <math id="S5.SS1.p3.2.m2.1" class="ltx_Math" alttext="@" display="inline"><semantics id="S5.SS1.p3.2.m2.1a"><mi mathvariant="normal" id="S5.SS1.p3.2.m2.1.1" xref="S5.SS1.p3.2.m2.1.1.cmml">@</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.2.m2.1b"><ci id="S5.SS1.p3.2.m2.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1">@</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.2.m2.1c">@</annotation></semantics></math> 2.50 GHz and 8GB RAM.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>FL simulation parameters</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The FL evaluation is based on the following three simulation parameters:</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Size of harmful class in each client:</span> With this parameter, we control the size of the harmful class on each client’s dataset. We consider a homogeneous population with the same class ratio (harmful:normal). Generally, as studies showed, <math id="S5.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="{\sim}{8}\%" display="inline"><semantics id="S5.I1.i1.p1.1.m1.1a"><mrow id="S5.I1.i1.p1.1.m1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.cmml"><mi id="S5.I1.i1.p1.1.m1.1.1.2" xref="S5.I1.i1.p1.1.m1.1.1.2.cmml"></mi><mo id="S5.I1.i1.p1.1.m1.1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.I1.i1.p1.1.m1.1.1.3" xref="S5.I1.i1.p1.1.m1.1.1.3.cmml"><mn id="S5.I1.i1.p1.1.m1.1.1.3.2" xref="S5.I1.i1.p1.1.m1.1.1.3.2.cmml">8</mn><mo id="S5.I1.i1.p1.1.m1.1.1.3.1" xref="S5.I1.i1.p1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.m1.1b"><apply id="S5.I1.i1.p1.1.m1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.I1.i1.p1.1.m1.1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.I1.i1.p1.1.m1.1.1.2.cmml" xref="S5.I1.i1.p1.1.m1.1.1.2">absent</csymbol><apply id="S5.I1.i1.p1.1.m1.1.1.3.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3"><csymbol cd="latexml" id="S5.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S5.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3.2">8</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.m1.1c">{\sim}{8}\%</annotation></semantics></math> of Twitter’s online content is harmful <cite class="ltx_cite ltx_citemacro_citep">(Chatzakou et al. <a href="#bib.bib5" title="" class="ltx_ref">2017</a>; Founta et al. <a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite>. That said, there are often controversial topics where the users’ behavior is highly polarized. For instance, COVID-19 vaccination, the Russian invasion of Ukraine, and several conspiracy theories. We expect that the browsing history of users interested in these topics will contain a higher number of harmful content.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p"><span id="S5.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Client dataset size:</span> the number of tweets at a client device. These tweets can represent either the user’s browsing history or tweets posted, retweeted, etc., by the user.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p"><span id="S5.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Number of FL clients:</span> the number of clients available for the FL training.</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">We experiment with different values of the simulation parameters to explore how they affect the FL classification performance.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Datasets</h3>

<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2209.11843/assets/x3.png" id="S5.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Harmful Class Ratio</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2209.11843/assets/x4.png" id="S5.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Client Dataset Size</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2209.11843/assets/x5.png" id="S5.F3.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Number of Clients</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Evaluation of non-DP FL. (a) 50 clients, 1K data points per client; (b) 50 clients, balanced data per client (i.e. 50% harmful data); (c) 1K data points and balanced data per client</figcaption>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We select the following datasets for the experimental evaluation based on past studies of misbehavior on Twitter. For all datasets, in order to keep the FL task lighter for the user device, we binarize the classification problem by merging the several harmful classes into a single “harmful” class. We report below the original classes together with the final binary ones.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS3.p2.2" class="ltx_p"><span id="S5.SS3.p2.2.1" class="ltx_text ltx_font_bold">Abusive Dataset</span> <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite> initially contains <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="{\sim}{100}K" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mi id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml"></mi><mo id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml"><mn id="S5.SS3.p2.1.m1.1.1.3.2" xref="S5.SS3.p2.1.m1.1.1.3.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S5.SS3.p2.1.m1.1.1.3.1" xref="S5.SS3.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS3.p2.1.m1.1.1.3.3" xref="S5.SS3.p2.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">absent</csymbol><apply id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3"><times id="S5.SS3.p2.1.m1.1.1.3.1.cmml" xref="S5.SS3.p2.1.m1.1.1.3.1"></times><cn type="integer" id="S5.SS3.p2.1.m1.1.1.3.2.cmml" xref="S5.SS3.p2.1.m1.1.1.3.2">100</cn><ci id="S5.SS3.p2.1.m1.1.1.3.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">{\sim}{100}K</annotation></semantics></math> tweets, labeled as “Abusive”, “Hate”, “Normal”, and “Spam”. We remove 14,030 tweets labeled as “Spam” – following the same methodology of <cite class="ltx_cite ltx_citemacro_citep">(Founta et al. <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite> because there are more sophisticated techniques to handle spam profiles.
The resulting dataset consists of <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="{\sim}{86}K" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mi id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml"></mi><mo id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">∼</mo><mrow id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml"><mn id="S5.SS3.p2.2.m2.1.1.3.2" xref="S5.SS3.p2.2.m2.1.1.3.2.cmml">86</mn><mo lspace="0em" rspace="0em" id="S5.SS3.p2.2.m2.1.1.3.1" xref="S5.SS3.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS3.p2.2.m2.1.1.3.3" xref="S5.SS3.p2.2.m2.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">absent</csymbol><apply id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3"><times id="S5.SS3.p2.2.m2.1.1.3.1.cmml" xref="S5.SS3.p2.2.m2.1.1.3.1"></times><cn type="integer" id="S5.SS3.p2.2.m2.1.1.3.2.cmml" xref="S5.SS3.p2.2.m2.1.1.3.2">86</cn><ci id="S5.SS3.p2.2.m2.1.1.3.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">{\sim}{86}K</annotation></semantics></math> tweets with 31.6% “Abusive”, 5.8% “Hate”, and 62.6% “Normal” classes. Final binary classes: 37.4% “Harmful” and 62.6% “Normal”.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para ltx_noindent">
<p id="S5.SS3.p3.1" class="ltx_p"><span id="S5.SS3.p3.1.1" class="ltx_text ltx_font_bold">Sarcastic Dataset</span> <cite class="ltx_cite ltx_citemacro_citep">(Rajadesingan, Zafarani, and Liu <a href="#bib.bib20" title="" class="ltx_ref">2015</a>)</cite> contains <math id="S5.SS3.p3.1.m1.1" class="ltx_Math" alttext="{\sim}{61}K" display="inline"><semantics id="S5.SS3.p3.1.m1.1a"><mrow id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml"><mi id="S5.SS3.p3.1.m1.1.1.2" xref="S5.SS3.p3.1.m1.1.1.2.cmml"></mi><mo id="S5.SS3.p3.1.m1.1.1.1" xref="S5.SS3.p3.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.SS3.p3.1.m1.1.1.3" xref="S5.SS3.p3.1.m1.1.1.3.cmml"><mn id="S5.SS3.p3.1.m1.1.1.3.2" xref="S5.SS3.p3.1.m1.1.1.3.2.cmml">61</mn><mo lspace="0em" rspace="0em" id="S5.SS3.p3.1.m1.1.1.3.1" xref="S5.SS3.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS3.p3.1.m1.1.1.3.3" xref="S5.SS3.p3.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><apply id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p3.1.m1.1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p3.1.m1.1.1.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2">absent</csymbol><apply id="S5.SS3.p3.1.m1.1.1.3.cmml" xref="S5.SS3.p3.1.m1.1.1.3"><times id="S5.SS3.p3.1.m1.1.1.3.1.cmml" xref="S5.SS3.p3.1.m1.1.1.3.1"></times><cn type="integer" id="S5.SS3.p3.1.m1.1.1.3.2.cmml" xref="S5.SS3.p3.1.m1.1.1.3.2">61</cn><ci id="S5.SS3.p3.1.m1.1.1.3.3.cmml" xref="S5.SS3.p3.1.m1.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">{\sim}{61}K</annotation></semantics></math> tweets text classified in two classes labeled as “Sarcastic”(10.5%), and “None”(89.5%). Final binary classes: 10.5% “Harmful” and 89.5% “Normal”</p>
</div>
<div id="S5.SS3.p4" class="ltx_para ltx_noindent">
<p id="S5.SS3.p4.1" class="ltx_p"><span id="S5.SS3.p4.1.1" class="ltx_text ltx_font_bold">Hateful Dataset</span> <cite class="ltx_cite ltx_citemacro_citep">(Waseem and Hovy <a href="#bib.bib24" title="" class="ltx_ref">2016</a>)</cite> is a <math id="S5.SS3.p4.1.m1.1" class="ltx_Math" alttext="{\sim}{16}K" display="inline"><semantics id="S5.SS3.p4.1.m1.1a"><mrow id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml"><mi id="S5.SS3.p4.1.m1.1.1.2" xref="S5.SS3.p4.1.m1.1.1.2.cmml"></mi><mo id="S5.SS3.p4.1.m1.1.1.1" xref="S5.SS3.p4.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.SS3.p4.1.m1.1.1.3" xref="S5.SS3.p4.1.m1.1.1.3.cmml"><mn id="S5.SS3.p4.1.m1.1.1.3.2" xref="S5.SS3.p4.1.m1.1.1.3.2.cmml">16</mn><mo lspace="0em" rspace="0em" id="S5.SS3.p4.1.m1.1.1.3.1" xref="S5.SS3.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS3.p4.1.m1.1.1.3.3" xref="S5.SS3.p4.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><apply id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p4.1.m1.1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p4.1.m1.1.1.2.cmml" xref="S5.SS3.p4.1.m1.1.1.2">absent</csymbol><apply id="S5.SS3.p4.1.m1.1.1.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3"><times id="S5.SS3.p4.1.m1.1.1.3.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3.1"></times><cn type="integer" id="S5.SS3.p4.1.m1.1.1.3.2.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2">16</cn><ci id="S5.SS3.p4.1.m1.1.1.3.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">{\sim}{16}K</annotation></semantics></math> tweets dataset. The tweets are categorized in “Racism”(12%), “Sexism”(20%), and “Normal”(68%) classes. Final binary classes: 32% “Harmful” and 68% “Normal”.</p>
</div>
<div id="S5.SS3.p5" class="ltx_para ltx_noindent">
<p id="S5.SS3.p5.1" class="ltx_p"><span id="S5.SS3.p5.1.1" class="ltx_text ltx_font_bold">Offensive Dataset</span> <cite class="ltx_cite ltx_citemacro_citep">(Davidson et al. <a href="#bib.bib7" title="" class="ltx_ref">2017</a>)</cite> consists of <math id="S5.SS3.p5.1.m1.1" class="ltx_Math" alttext="{\sim}{25}K" display="inline"><semantics id="S5.SS3.p5.1.m1.1a"><mrow id="S5.SS3.p5.1.m1.1.1" xref="S5.SS3.p5.1.m1.1.1.cmml"><mi id="S5.SS3.p5.1.m1.1.1.2" xref="S5.SS3.p5.1.m1.1.1.2.cmml"></mi><mo id="S5.SS3.p5.1.m1.1.1.1" xref="S5.SS3.p5.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.SS3.p5.1.m1.1.1.3" xref="S5.SS3.p5.1.m1.1.1.3.cmml"><mn id="S5.SS3.p5.1.m1.1.1.3.2" xref="S5.SS3.p5.1.m1.1.1.3.2.cmml">25</mn><mo lspace="0em" rspace="0em" id="S5.SS3.p5.1.m1.1.1.3.1" xref="S5.SS3.p5.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS3.p5.1.m1.1.1.3.3" xref="S5.SS3.p5.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p5.1.m1.1b"><apply id="S5.SS3.p5.1.m1.1.1.cmml" xref="S5.SS3.p5.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p5.1.m1.1.1.1.cmml" xref="S5.SS3.p5.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p5.1.m1.1.1.2.cmml" xref="S5.SS3.p5.1.m1.1.1.2">absent</csymbol><apply id="S5.SS3.p5.1.m1.1.1.3.cmml" xref="S5.SS3.p5.1.m1.1.1.3"><times id="S5.SS3.p5.1.m1.1.1.3.1.cmml" xref="S5.SS3.p5.1.m1.1.1.3.1"></times><cn type="integer" id="S5.SS3.p5.1.m1.1.1.3.2.cmml" xref="S5.SS3.p5.1.m1.1.1.3.2">25</cn><ci id="S5.SS3.p5.1.m1.1.1.3.3.cmml" xref="S5.SS3.p5.1.m1.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p5.1.m1.1c">{\sim}{25}K</annotation></semantics></math> tweets categorized in three classes: “Hate”(6%), “Offensive”(77%), and “Normal”(17%).
Final binary classes: 83% “Harmful” and 17% “Normal”.</p>
</div>
<div id="S5.SS3.p6" class="ltx_para ltx_noindent">
<p id="S5.SS3.p6.1" class="ltx_p"><span id="S5.SS3.p6.1.1" class="ltx_text ltx_font_bold">Cyberbully Dataset</span> <cite class="ltx_cite ltx_citemacro_citep">(Chatzakou et al. <a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite> is a smaller dataset, with <math id="S5.SS3.p6.1.m1.1" class="ltx_Math" alttext="{\sim}{6}K" display="inline"><semantics id="S5.SS3.p6.1.m1.1a"><mrow id="S5.SS3.p6.1.m1.1.1" xref="S5.SS3.p6.1.m1.1.1.cmml"><mi id="S5.SS3.p6.1.m1.1.1.2" xref="S5.SS3.p6.1.m1.1.1.2.cmml"></mi><mo id="S5.SS3.p6.1.m1.1.1.1" xref="S5.SS3.p6.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.SS3.p6.1.m1.1.1.3" xref="S5.SS3.p6.1.m1.1.1.3.cmml"><mn id="S5.SS3.p6.1.m1.1.1.3.2" xref="S5.SS3.p6.1.m1.1.1.3.2.cmml">6</mn><mo lspace="0em" rspace="0em" id="S5.SS3.p6.1.m1.1.1.3.1" xref="S5.SS3.p6.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS3.p6.1.m1.1.1.3.3" xref="S5.SS3.p6.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.1.m1.1b"><apply id="S5.SS3.p6.1.m1.1.1.cmml" xref="S5.SS3.p6.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p6.1.m1.1.1.1.cmml" xref="S5.SS3.p6.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p6.1.m1.1.1.2.cmml" xref="S5.SS3.p6.1.m1.1.1.2">absent</csymbol><apply id="S5.SS3.p6.1.m1.1.1.3.cmml" xref="S5.SS3.p6.1.m1.1.1.3"><times id="S5.SS3.p6.1.m1.1.1.3.1.cmml" xref="S5.SS3.p6.1.m1.1.1.3.1"></times><cn type="integer" id="S5.SS3.p6.1.m1.1.1.3.2.cmml" xref="S5.SS3.p6.1.m1.1.1.3.2">6</cn><ci id="S5.SS3.p6.1.m1.1.1.3.3.cmml" xref="S5.SS3.p6.1.m1.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.1.m1.1c">{\sim}{6}K</annotation></semantics></math> tweets distinguished the “Bully”(8.5%), “Aggressive”(5.5%), and “Normal”(86%) classes. Final binary classes: 14% “Harmful” and 86% “Normal”.</p>
</div>
<div id="S5.SS3.p7" class="ltx_para">
<p id="S5.SS3.p7.1" class="ltx_p">We also <span id="S5.SS3.p7.1.1" class="ltx_text ltx_font_bold">preprocess the tweet texts</span> by removing tags, URLs, numbers, punctuation characters, non-ASCII characters, etc.
Moreover, we convert the text to lowercase, all the white spaces into a single one. We also remove English stop words and words that appear only once in the dataset (in case of misspelled words).</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Evaluation of non–DP FL models</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">In the following experiments, we evaluate the non–DP FL framework on the “Abusive” dataset only. We chose this dataset because its size allowed experimentation with various FL simulation parameters.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para ltx_noindent">
<p id="S5.SS4.p2.1" class="ltx_p"><span id="S5.SS4.p2.1.1" class="ltx_text ltx_font_bold">5.4.1 Percent of “harmful” data in the clients.</span>
Here, we evaluate the FL classification when we vary the percent of “harmful” data in the clients’ datasets using the values <math id="S5.SS4.p2.1.m1.4" class="ltx_Math" alttext="(10\%,20\%,30\%,50\%)" display="inline"><semantics id="S5.SS4.p2.1.m1.4a"><mrow id="S5.SS4.p2.1.m1.4.4.4" xref="S5.SS4.p2.1.m1.4.4.5.cmml"><mo stretchy="false" id="S5.SS4.p2.1.m1.4.4.4.5" xref="S5.SS4.p2.1.m1.4.4.5.cmml">(</mo><mrow id="S5.SS4.p2.1.m1.1.1.1.1" xref="S5.SS4.p2.1.m1.1.1.1.1.cmml"><mn id="S5.SS4.p2.1.m1.1.1.1.1.2" xref="S5.SS4.p2.1.m1.1.1.1.1.2.cmml">10</mn><mo id="S5.SS4.p2.1.m1.1.1.1.1.1" xref="S5.SS4.p2.1.m1.1.1.1.1.1.cmml">%</mo></mrow><mo id="S5.SS4.p2.1.m1.4.4.4.6" xref="S5.SS4.p2.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS4.p2.1.m1.2.2.2.2" xref="S5.SS4.p2.1.m1.2.2.2.2.cmml"><mn id="S5.SS4.p2.1.m1.2.2.2.2.2" xref="S5.SS4.p2.1.m1.2.2.2.2.2.cmml">20</mn><mo id="S5.SS4.p2.1.m1.2.2.2.2.1" xref="S5.SS4.p2.1.m1.2.2.2.2.1.cmml">%</mo></mrow><mo id="S5.SS4.p2.1.m1.4.4.4.7" xref="S5.SS4.p2.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS4.p2.1.m1.3.3.3.3" xref="S5.SS4.p2.1.m1.3.3.3.3.cmml"><mn id="S5.SS4.p2.1.m1.3.3.3.3.2" xref="S5.SS4.p2.1.m1.3.3.3.3.2.cmml">30</mn><mo id="S5.SS4.p2.1.m1.3.3.3.3.1" xref="S5.SS4.p2.1.m1.3.3.3.3.1.cmml">%</mo></mrow><mo id="S5.SS4.p2.1.m1.4.4.4.8" xref="S5.SS4.p2.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS4.p2.1.m1.4.4.4.4" xref="S5.SS4.p2.1.m1.4.4.4.4.cmml"><mn id="S5.SS4.p2.1.m1.4.4.4.4.2" xref="S5.SS4.p2.1.m1.4.4.4.4.2.cmml">50</mn><mo id="S5.SS4.p2.1.m1.4.4.4.4.1" xref="S5.SS4.p2.1.m1.4.4.4.4.1.cmml">%</mo></mrow><mo stretchy="false" id="S5.SS4.p2.1.m1.4.4.4.9" xref="S5.SS4.p2.1.m1.4.4.5.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.4b"><vector id="S5.SS4.p2.1.m1.4.4.5.cmml" xref="S5.SS4.p2.1.m1.4.4.4"><apply id="S5.SS4.p2.1.m1.1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.SS4.p2.1.m1.1.1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS4.p2.1.m1.1.1.1.1.2.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1.2">10</cn></apply><apply id="S5.SS4.p2.1.m1.2.2.2.2.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2"><csymbol cd="latexml" id="S5.SS4.p2.1.m1.2.2.2.2.1.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.1">percent</csymbol><cn type="integer" id="S5.SS4.p2.1.m1.2.2.2.2.2.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.2">20</cn></apply><apply id="S5.SS4.p2.1.m1.3.3.3.3.cmml" xref="S5.SS4.p2.1.m1.3.3.3.3"><csymbol cd="latexml" id="S5.SS4.p2.1.m1.3.3.3.3.1.cmml" xref="S5.SS4.p2.1.m1.3.3.3.3.1">percent</csymbol><cn type="integer" id="S5.SS4.p2.1.m1.3.3.3.3.2.cmml" xref="S5.SS4.p2.1.m1.3.3.3.3.2">30</cn></apply><apply id="S5.SS4.p2.1.m1.4.4.4.4.cmml" xref="S5.SS4.p2.1.m1.4.4.4.4"><csymbol cd="latexml" id="S5.SS4.p2.1.m1.4.4.4.4.1.cmml" xref="S5.SS4.p2.1.m1.4.4.4.4.1">percent</csymbol><cn type="integer" id="S5.SS4.p2.1.m1.4.4.4.4.2.cmml" xref="S5.SS4.p2.1.m1.4.4.4.4.2">50</cn></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.4c">(10\%,20\%,30\%,50\%)</annotation></semantics></math>. For a given “%harmful” value, first, we randomly select fifty clients and then we train the classifier in these clients for twenty FL rounds. Each client dataset consists of 1K data. Finally, we repeat the experiment five times to acquire average scores.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">We also ran experiments with the <span id="S5.SS4.p3.1.1" class="ltx_text ltx_font_italic">Centralized training setup</span> by varying the percent of “harmful” text in the training set. Then, we randomly select 50K tweets as the training set.
We chose the 50K samples to compare the centralized classification performance with the previously mentioned FL training. We repeated the training three times for each %harmful value.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.3" class="ltx_p"><span id="S5.SS4.p4.3.1" class="ltx_text ltx_font_bold ltx_font_italic">Results Discussion:</span>
In Figure <a href="#S5.F3.sf1" title="In Figure 3 ‣ 5.3 Datasets ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>, we present the average AUC values (test evaluation).
We note that by increasing the examples of the “harmful” class by 5 times (i.e., from 10% to 50%), we have a <math id="S5.SS4.p4.1.m1.1" class="ltx_Math" alttext="{\sim}" display="inline"><semantics id="S5.SS4.p4.1.m1.1a"><mo id="S5.SS4.p4.1.m1.1.1" xref="S5.SS4.p4.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p4.1.m1.1b"><csymbol cd="latexml" id="S5.SS4.p4.1.m1.1.1.cmml" xref="S5.SS4.p4.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p4.1.m1.1c">{\sim}</annotation></semantics></math>9% increase in AUC (from 74% to 83%). In the case with a 10% harmful class size, we got a 95% score in precision, recall, and F1-score. Interestingly, in the case of 50% of harmful class size, we obtained precision (93%), recall (89%), F1–score (90%), which shows a decrease by <math id="S5.SS4.p4.2.m2.1" class="ltx_Math" alttext="{\sim}" display="inline"><semantics id="S5.SS4.p4.2.m2.1a"><mo id="S5.SS4.p4.2.m2.1.1" xref="S5.SS4.p4.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p4.2.m2.1b"><csymbol cd="latexml" id="S5.SS4.p4.2.m2.1.1.cmml" xref="S5.SS4.p4.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p4.2.m2.1c">{\sim}</annotation></semantics></math>1%, 6%, and 4% respectively. The training dataset is imbalanced when only 10% of clients’ data is harmful.
To understand this reduction in the model’s performance, we also calculated the metrics only on the harmful class (which is the minority class), where we observed a <math id="S5.SS4.p4.3.m3.1" class="ltx_Math" alttext="{\sim}" display="inline"><semantics id="S5.SS4.p4.3.m3.1a"><mo id="S5.SS4.p4.3.m3.1.1" xref="S5.SS4.p4.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p4.3.m3.1b"><csymbol cd="latexml" id="S5.SS4.p4.3.m3.1.1.cmml" xref="S5.SS4.p4.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p4.3.m3.1c">{\sim}</annotation></semantics></math>30% increase in recall but also a 40% negative impact on precision (with 10% of harmful class size we got a recall of 50%, and precision of 82%, with 50% we got a 77%, and a 40% respectively).
This means having a balanced dataset (with 50% of harmful class size) impacts the recall of the harmful class: i.e., it helps the model to learn better the harmful class. This is what drives AUC up as well (in the weighted metrics as well as in the harmful–only case).</p>
</div>
<div id="S5.SS4.p5" class="ltx_para">
<p id="S5.SS4.p5.1" class="ltx_p">In the centralized approach, the classifier shows high performance, with only a 3% AUC difference between the 10% and 50% of harmful class size (90%, and 93% AUC, respectively).
Finally, we get the best FL classification performance for balanced clients datasets (only <math id="S5.SS4.p5.1.m1.1" class="ltx_Math" alttext="{\sim}" display="inline"><semantics id="S5.SS4.p5.1.m1.1a"><mo id="S5.SS4.p5.1.m1.1.1" xref="S5.SS4.p5.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p5.1.m1.1b"><csymbol cd="latexml" id="S5.SS4.p5.1.m1.1.1.cmml" xref="S5.SS4.p5.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p5.1.m1.1c">{\sim}</annotation></semantics></math>10% AUC difference with the centralized training).</p>
</div>
<div id="S5.SS4.p6" class="ltx_para ltx_noindent">
<p id="S5.SS4.p6.1" class="ltx_p"><span id="S5.SS4.p6.1.1" class="ltx_text ltx_font_bold">5.4.2 Client’s dataset size.</span> 
We assumed a homogeneous setting where all clients have the same dataset size. We evaluate the classifier performance for the client’s dataset size in [0.1K, 0.5K, 1K]. We run the <span id="S5.SS4.p6.1.2" class="ltx_text ltx_font_italic">FL training setup</span> for twenty FL rounds by using the same randomly selected fifty clients. Each client has a balanced dataset. We repeat the FL training twenty times for the training with 0.1K and 0.5K data, and five times for the 1K data. We present the average AUC metric in Figure <a href="#S5.F3.sf2" title="In Figure 3 ‣ 5.3 Datasets ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>.</p>
</div>
<div id="S5.SS4.p7" class="ltx_para">
<p id="S5.SS4.p7.6" class="ltx_p"><span id="S5.SS4.p7.6.1" class="ltx_text ltx_font_bold ltx_font_italic">Results discussion:</span>
Increasing client dataset size by ten times (from 0.1K to 1K data points) can lead to the overall improvement of performance metrics by <math id="S5.SS4.p7.1.m1.1" class="ltx_Math" alttext="{\sim}{3}" display="inline"><semantics id="S5.SS4.p7.1.m1.1a"><mrow id="S5.SS4.p7.1.m1.1.1" xref="S5.SS4.p7.1.m1.1.1.cmml"><mi id="S5.SS4.p7.1.m1.1.1.2" xref="S5.SS4.p7.1.m1.1.1.2.cmml"></mi><mo id="S5.SS4.p7.1.m1.1.1.1" xref="S5.SS4.p7.1.m1.1.1.1.cmml">∼</mo><mn id="S5.SS4.p7.1.m1.1.1.3" xref="S5.SS4.p7.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p7.1.m1.1b"><apply id="S5.SS4.p7.1.m1.1.1.cmml" xref="S5.SS4.p7.1.m1.1.1"><csymbol cd="latexml" id="S5.SS4.p7.1.m1.1.1.1.cmml" xref="S5.SS4.p7.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS4.p7.1.m1.1.1.2.cmml" xref="S5.SS4.p7.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.SS4.p7.1.m1.1.1.3.cmml" xref="S5.SS4.p7.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p7.1.m1.1c">{\sim}{3}</annotation></semantics></math>% in the AUC (from <math id="S5.SS4.p7.2.m2.1" class="ltx_Math" alttext="{\sim}81" display="inline"><semantics id="S5.SS4.p7.2.m2.1a"><mrow id="S5.SS4.p7.2.m2.1.1" xref="S5.SS4.p7.2.m2.1.1.cmml"><mi id="S5.SS4.p7.2.m2.1.1.2" xref="S5.SS4.p7.2.m2.1.1.2.cmml"></mi><mo id="S5.SS4.p7.2.m2.1.1.1" xref="S5.SS4.p7.2.m2.1.1.1.cmml">∼</mo><mn id="S5.SS4.p7.2.m2.1.1.3" xref="S5.SS4.p7.2.m2.1.1.3.cmml">81</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p7.2.m2.1b"><apply id="S5.SS4.p7.2.m2.1.1.cmml" xref="S5.SS4.p7.2.m2.1.1"><csymbol cd="latexml" id="S5.SS4.p7.2.m2.1.1.1.cmml" xref="S5.SS4.p7.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS4.p7.2.m2.1.1.2.cmml" xref="S5.SS4.p7.2.m2.1.1.2">absent</csymbol><cn type="integer" id="S5.SS4.p7.2.m2.1.1.3.cmml" xref="S5.SS4.p7.2.m2.1.1.3">81</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p7.2.m2.1c">{\sim}81</annotation></semantics></math>% to 83%). We observed also a <math id="S5.SS4.p7.3.m3.1" class="ltx_Math" alttext="{\sim}{2}" display="inline"><semantics id="S5.SS4.p7.3.m3.1a"><mrow id="S5.SS4.p7.3.m3.1.1" xref="S5.SS4.p7.3.m3.1.1.cmml"><mi id="S5.SS4.p7.3.m3.1.1.2" xref="S5.SS4.p7.3.m3.1.1.2.cmml"></mi><mo id="S5.SS4.p7.3.m3.1.1.1" xref="S5.SS4.p7.3.m3.1.1.1.cmml">∼</mo><mn id="S5.SS4.p7.3.m3.1.1.3" xref="S5.SS4.p7.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p7.3.m3.1b"><apply id="S5.SS4.p7.3.m3.1.1.cmml" xref="S5.SS4.p7.3.m3.1.1"><csymbol cd="latexml" id="S5.SS4.p7.3.m3.1.1.1.cmml" xref="S5.SS4.p7.3.m3.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS4.p7.3.m3.1.1.2.cmml" xref="S5.SS4.p7.3.m3.1.1.2">absent</csymbol><cn type="integer" id="S5.SS4.p7.3.m3.1.1.3.cmml" xref="S5.SS4.p7.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p7.3.m3.1c">{\sim}{2}</annotation></semantics></math>% improvement in F1 score (from 88% to 90%), <math id="S5.SS4.p7.4.m4.1" class="ltx_Math" alttext="{\sim}{4}\%" display="inline"><semantics id="S5.SS4.p7.4.m4.1a"><mrow id="S5.SS4.p7.4.m4.1.1" xref="S5.SS4.p7.4.m4.1.1.cmml"><mi id="S5.SS4.p7.4.m4.1.1.2" xref="S5.SS4.p7.4.m4.1.1.2.cmml"></mi><mo id="S5.SS4.p7.4.m4.1.1.1" xref="S5.SS4.p7.4.m4.1.1.1.cmml">∼</mo><mrow id="S5.SS4.p7.4.m4.1.1.3" xref="S5.SS4.p7.4.m4.1.1.3.cmml"><mn id="S5.SS4.p7.4.m4.1.1.3.2" xref="S5.SS4.p7.4.m4.1.1.3.2.cmml">4</mn><mo id="S5.SS4.p7.4.m4.1.1.3.1" xref="S5.SS4.p7.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p7.4.m4.1b"><apply id="S5.SS4.p7.4.m4.1.1.cmml" xref="S5.SS4.p7.4.m4.1.1"><csymbol cd="latexml" id="S5.SS4.p7.4.m4.1.1.1.cmml" xref="S5.SS4.p7.4.m4.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS4.p7.4.m4.1.1.2.cmml" xref="S5.SS4.p7.4.m4.1.1.2">absent</csymbol><apply id="S5.SS4.p7.4.m4.1.1.3.cmml" xref="S5.SS4.p7.4.m4.1.1.3"><csymbol cd="latexml" id="S5.SS4.p7.4.m4.1.1.3.1.cmml" xref="S5.SS4.p7.4.m4.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS4.p7.4.m4.1.1.3.2.cmml" xref="S5.SS4.p7.4.m4.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p7.4.m4.1c">{\sim}{4}\%</annotation></semantics></math> in accuracy (from 85% to 89%), recall (from 85% to 89%), and <math id="S5.SS4.p7.5.m5.1" class="ltx_Math" alttext="{\sim}{1}\%" display="inline"><semantics id="S5.SS4.p7.5.m5.1a"><mrow id="S5.SS4.p7.5.m5.1.1" xref="S5.SS4.p7.5.m5.1.1.cmml"><mi id="S5.SS4.p7.5.m5.1.1.2" xref="S5.SS4.p7.5.m5.1.1.2.cmml"></mi><mo id="S5.SS4.p7.5.m5.1.1.1" xref="S5.SS4.p7.5.m5.1.1.1.cmml">∼</mo><mrow id="S5.SS4.p7.5.m5.1.1.3" xref="S5.SS4.p7.5.m5.1.1.3.cmml"><mn id="S5.SS4.p7.5.m5.1.1.3.2" xref="S5.SS4.p7.5.m5.1.1.3.2.cmml">1</mn><mo id="S5.SS4.p7.5.m5.1.1.3.1" xref="S5.SS4.p7.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p7.5.m5.1b"><apply id="S5.SS4.p7.5.m5.1.1.cmml" xref="S5.SS4.p7.5.m5.1.1"><csymbol cd="latexml" id="S5.SS4.p7.5.m5.1.1.1.cmml" xref="S5.SS4.p7.5.m5.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS4.p7.5.m5.1.1.2.cmml" xref="S5.SS4.p7.5.m5.1.1.2">absent</csymbol><apply id="S5.SS4.p7.5.m5.1.1.3.cmml" xref="S5.SS4.p7.5.m5.1.1.3"><csymbol cd="latexml" id="S5.SS4.p7.5.m5.1.1.3.1.cmml" xref="S5.SS4.p7.5.m5.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS4.p7.5.m5.1.1.3.2.cmml" xref="S5.SS4.p7.5.m5.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p7.5.m5.1c">{\sim}{1}\%</annotation></semantics></math> in precision (from 92% to 93%).
The results show that increasing the data by five times did not significantly improve the performance, but the model performs similarly with the 0.1K data points per client.
Therefore, the experiment shows that the FL training can build an effective model (<math id="S5.SS4.p7.6.m6.1" class="ltx_Math" alttext="{\sim}{81}\%" display="inline"><semantics id="S5.SS4.p7.6.m6.1a"><mrow id="S5.SS4.p7.6.m6.1.1" xref="S5.SS4.p7.6.m6.1.1.cmml"><mi id="S5.SS4.p7.6.m6.1.1.2" xref="S5.SS4.p7.6.m6.1.1.2.cmml"></mi><mo id="S5.SS4.p7.6.m6.1.1.1" xref="S5.SS4.p7.6.m6.1.1.1.cmml">∼</mo><mrow id="S5.SS4.p7.6.m6.1.1.3" xref="S5.SS4.p7.6.m6.1.1.3.cmml"><mn id="S5.SS4.p7.6.m6.1.1.3.2" xref="S5.SS4.p7.6.m6.1.1.3.2.cmml">81</mn><mo id="S5.SS4.p7.6.m6.1.1.3.1" xref="S5.SS4.p7.6.m6.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p7.6.m6.1b"><apply id="S5.SS4.p7.6.m6.1.1.cmml" xref="S5.SS4.p7.6.m6.1.1"><csymbol cd="latexml" id="S5.SS4.p7.6.m6.1.1.1.cmml" xref="S5.SS4.p7.6.m6.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS4.p7.6.m6.1.1.2.cmml" xref="S5.SS4.p7.6.m6.1.1.2">absent</csymbol><apply id="S5.SS4.p7.6.m6.1.1.3.cmml" xref="S5.SS4.p7.6.m6.1.1.3"><csymbol cd="latexml" id="S5.SS4.p7.6.m6.1.1.3.1.cmml" xref="S5.SS4.p7.6.m6.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS4.p7.6.m6.1.1.3.2.cmml" xref="S5.SS4.p7.6.m6.1.1.3.2">81</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p7.6.m6.1c">{\sim}{81}\%</annotation></semantics></math> AUC) even with 100 data points per client.</p>
</div>
<div id="S5.SS4.p8" class="ltx_para ltx_noindent">
<p id="S5.SS4.p8.1" class="ltx_p"><span id="S5.SS4.p8.1.1" class="ltx_text ltx_font_bold">5.4.3 Number of FL Clients.</span> 
In this experiment, we run the <span id="S5.SS4.p8.1.2" class="ltx_text ltx_font_italic">FL training setup</span> by varying the number of available clients, i.e., 10, 20, 30, 40, 50.
Each client has a 1K balanced dataset, and the FL training runs for twenty rounds with the same randomly selected clients. We run the FL training five times for each value of the number of clients property, and we present the average test AUC in Figure <a href="#S5.F3.sf3" title="In Figure 3 ‣ 5.3 Datasets ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a>.</p>
</div>
<div id="S5.SS4.p9" class="ltx_para">
<p id="S5.SS4.p9.2" class="ltx_p"><span id="S5.SS4.p9.2.1" class="ltx_text ltx_font_bold ltx_font_italic">Results Discussion:</span> Increasing the number of clients participating in FL training by five times (i.e., from 10 to 50) results in increasing the AUC by <math id="S5.SS4.p9.1.m1.1" class="ltx_Math" alttext="{\sim}2\%" display="inline"><semantics id="S5.SS4.p9.1.m1.1a"><mrow id="S5.SS4.p9.1.m1.1.1" xref="S5.SS4.p9.1.m1.1.1.cmml"><mi id="S5.SS4.p9.1.m1.1.1.2" xref="S5.SS4.p9.1.m1.1.1.2.cmml"></mi><mo id="S5.SS4.p9.1.m1.1.1.1" xref="S5.SS4.p9.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.SS4.p9.1.m1.1.1.3" xref="S5.SS4.p9.1.m1.1.1.3.cmml"><mn id="S5.SS4.p9.1.m1.1.1.3.2" xref="S5.SS4.p9.1.m1.1.1.3.2.cmml">2</mn><mo id="S5.SS4.p9.1.m1.1.1.3.1" xref="S5.SS4.p9.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p9.1.m1.1b"><apply id="S5.SS4.p9.1.m1.1.1.cmml" xref="S5.SS4.p9.1.m1.1.1"><csymbol cd="latexml" id="S5.SS4.p9.1.m1.1.1.1.cmml" xref="S5.SS4.p9.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS4.p9.1.m1.1.1.2.cmml" xref="S5.SS4.p9.1.m1.1.1.2">absent</csymbol><apply id="S5.SS4.p9.1.m1.1.1.3.cmml" xref="S5.SS4.p9.1.m1.1.1.3"><csymbol cd="latexml" id="S5.SS4.p9.1.m1.1.1.3.1.cmml" xref="S5.SS4.p9.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS4.p9.1.m1.1.1.3.2.cmml" xref="S5.SS4.p9.1.m1.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p9.1.m1.1c">{\sim}2\%</annotation></semantics></math> (from 81% to 83%). Additionally, the accuracy, precision, recall, and f1-score, increase by <math id="S5.SS4.p9.2.m2.1" class="ltx_Math" alttext="{\sim}" display="inline"><semantics id="S5.SS4.p9.2.m2.1a"><mo id="S5.SS4.p9.2.m2.1.1" xref="S5.SS4.p9.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p9.2.m2.1b"><csymbol cd="latexml" id="S5.SS4.p9.2.m2.1.1.cmml" xref="S5.SS4.p9.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p9.2.m2.1c">{\sim}</annotation></semantics></math>3%, 1%, 3%, and 2% respectively (from 86%, 92%,86%, 88% to 89%, 93%, 89%, 90%).
However, the interesting point is that even with ten users/clients, the system can build an efficient model.
The model performs similarly well when varying the number of clients participating in the FL training.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.4.5.1" class="ltx_tr">
<th id="S5.T1.4.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T1.4.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.5.1.1.1.1" class="ltx_p" style="width:39.8pt;">Dataset</span>
</span>
</th>
<th id="S5.T1.4.5.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_t">
<span id="S5.T1.4.5.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.5.1.2.1.1" class="ltx_p" style="width:31.3pt;">#Clients</span>
</span>
</th>
<th id="S5.T1.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Accuracy</th>
<th id="S5.T1.4.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">AUC</th>
<th id="S5.T1.4.5.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1 Score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.4.6.1" class="ltx_tr">
<th id="S5.T1.4.6.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4">
<span id="S5.T1.4.6.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.6.1.1.1.1" class="ltx_p" style="width:39.8pt;"><span id="S5.T1.4.6.1.1.1.1.1" class="ltx_text">Abusive</span></span>
</span>
</th>
<th id="S5.T1.4.6.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.6.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.6.1.2.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.6.1.2.1.1.1" class="ltx_text">50</span></span>
</span>
</th>
<td id="S5.T1.4.6.1.3" class="ltx_td ltx_align_center ltx_border_t">0.85</td>
<td id="S5.T1.4.6.1.4" class="ltx_td ltx_align_center ltx_border_t">0.81</td>
<td id="S5.T1.4.6.1.5" class="ltx_td ltx_align_center ltx_border_t">0.88</td>
</tr>
<tr id="S5.T1.4.7.2" class="ltx_tr">
<td id="S5.T1.4.7.2.1" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.7.2.2" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.7.2.3" class="ltx_td ltx_align_center">(0.01)</td>
</tr>
<tr id="S5.T1.4.8.3" class="ltx_tr">
<th id="S5.T1.4.8.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.8.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.8.3.1.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.8.3.1.1.1.1" class="ltx_text">Centr.</span></span>
</span>
</th>
<td id="S5.T1.4.8.3.2" class="ltx_td ltx_align_center ltx_border_t">0.92</td>
<td id="S5.T1.4.8.3.3" class="ltx_td ltx_align_center ltx_border_t">0.92</td>
<td id="S5.T1.4.8.3.4" class="ltx_td ltx_align_center ltx_border_t">0.94</td>
</tr>
<tr id="S5.T1.1.1" class="ltx_tr">
<td id="S5.T1.1.1.2" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_center">(<math id="S5.T1.1.1.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S5.T1.1.1.1.m1.1a"><mo id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><lt id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">&lt;</annotation></semantics></math>1e-3)</td>
<td id="S5.T1.1.1.3" class="ltx_td ltx_align_center">(0.01)</td>
</tr>
<tr id="S5.T1.4.9.4" class="ltx_tr">
<th id="S5.T1.4.9.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4">
<span id="S5.T1.4.9.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.9.4.1.1.1" class="ltx_p" style="width:39.8pt;"><span id="S5.T1.4.9.4.1.1.1.1" class="ltx_text">Sarcastic</span></span>
</span>
</th>
<th id="S5.T1.4.9.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.9.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.9.4.2.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.9.4.2.1.1.1" class="ltx_text">50</span></span>
</span>
</th>
<td id="S5.T1.4.9.4.3" class="ltx_td ltx_align_center ltx_border_t">0.73</td>
<td id="S5.T1.4.9.4.4" class="ltx_td ltx_align_center ltx_border_t">0.66</td>
<td id="S5.T1.4.9.4.5" class="ltx_td ltx_align_center ltx_border_t">0.79</td>
</tr>
<tr id="S5.T1.4.10.5" class="ltx_tr">
<td id="S5.T1.4.10.5.1" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.10.5.2" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.10.5.3" class="ltx_td ltx_align_center">(0.01)</td>
</tr>
<tr id="S5.T1.4.11.6" class="ltx_tr">
<th id="S5.T1.4.11.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.11.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.11.6.1.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.11.6.1.1.1.1" class="ltx_text">Centr.</span></span>
</span>
</th>
<td id="S5.T1.4.11.6.2" class="ltx_td ltx_align_center ltx_border_t">0.76</td>
<td id="S5.T1.4.11.6.3" class="ltx_td ltx_align_center ltx_border_t">0.75</td>
<td id="S5.T1.4.11.6.4" class="ltx_td ltx_align_center ltx_border_t">.0.83</td>
</tr>
<tr id="S5.T1.4.12.7" class="ltx_tr">
<td id="S5.T1.4.12.7.1" class="ltx_td ltx_align_center">(0.05)</td>
<td id="S5.T1.4.12.7.2" class="ltx_td ltx_align_center">(0.03)</td>
<td id="S5.T1.4.12.7.3" class="ltx_td ltx_align_center">(0.03)</td>
</tr>
<tr id="S5.T1.4.13.8" class="ltx_tr">
<th id="S5.T1.4.13.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4">
<span id="S5.T1.4.13.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.13.8.1.1.1" class="ltx_p" style="width:39.8pt;"><span id="S5.T1.4.13.8.1.1.1.1" class="ltx_text">Hateful</span></span>
</span>
</th>
<th id="S5.T1.4.13.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.13.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.13.8.2.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.13.8.2.1.1.1" class="ltx_text">50</span></span>
</span>
</th>
<td id="S5.T1.4.13.8.3" class="ltx_td ltx_align_center ltx_border_t">0.85</td>
<td id="S5.T1.4.13.8.4" class="ltx_td ltx_align_center ltx_border_t">0.61</td>
<td id="S5.T1.4.13.8.5" class="ltx_td ltx_align_center ltx_border_t">0.87</td>
</tr>
<tr id="S5.T1.4.14.9" class="ltx_tr">
<td id="S5.T1.4.14.9.1" class="ltx_td ltx_align_center">(0.02)</td>
<td id="S5.T1.4.14.9.2" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.14.9.3" class="ltx_td ltx_align_center">(0.01)</td>
</tr>
<tr id="S5.T1.4.15.10" class="ltx_tr">
<th id="S5.T1.4.15.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.15.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.15.10.1.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.15.10.1.1.1.1" class="ltx_text">Centr.</span></span>
</span>
</th>
<td id="S5.T1.4.15.10.2" class="ltx_td ltx_align_center ltx_border_t">0.79</td>
<td id="S5.T1.4.15.10.3" class="ltx_td ltx_align_center ltx_border_t">0.79</td>
<td id="S5.T1.4.15.10.4" class="ltx_td ltx_align_center ltx_border_t">0.85</td>
</tr>
<tr id="S5.T1.4.16.11" class="ltx_tr">
<td id="S5.T1.4.16.11.1" class="ltx_td ltx_align_center">(0.02)</td>
<td id="S5.T1.4.16.11.2" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.16.11.3" class="ltx_td ltx_align_center">(0.01)</td>
</tr>
<tr id="S5.T1.4.17.12" class="ltx_tr">
<th id="S5.T1.4.17.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4">
<span id="S5.T1.4.17.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.17.12.1.1.1" class="ltx_p" style="width:39.8pt;"><span id="S5.T1.4.17.12.1.1.1.1" class="ltx_text">Offensive</span></span>
</span>
</th>
<th id="S5.T1.4.17.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.17.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.17.12.2.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.17.12.2.1.1.1" class="ltx_text">37</span></span>
</span>
</th>
<td id="S5.T1.4.17.12.3" class="ltx_td ltx_align_center ltx_border_t">0.78</td>
<td id="S5.T1.4.17.12.4" class="ltx_td ltx_align_center ltx_border_t">0.78</td>
<td id="S5.T1.4.17.12.5" class="ltx_td ltx_align_center ltx_border_t">0.83</td>
</tr>
<tr id="S5.T1.4.18.13" class="ltx_tr">
<td id="S5.T1.4.18.13.1" class="ltx_td ltx_align_center">(0.02)</td>
<td id="S5.T1.4.18.13.2" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.18.13.3" class="ltx_td ltx_align_center">(0.02)</td>
</tr>
<tr id="S5.T1.4.19.14" class="ltx_tr">
<th id="S5.T1.4.19.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.19.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.19.14.1.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.19.14.1.1.1.1" class="ltx_text">Centr.</span></span>
</span>
</th>
<td id="S5.T1.4.19.14.2" class="ltx_td ltx_align_center ltx_border_t">0.92</td>
<td id="S5.T1.4.19.14.3" class="ltx_td ltx_align_center ltx_border_t">0.92</td>
<td id="S5.T1.4.19.14.4" class="ltx_td ltx_align_center ltx_border_t">0.94</td>
</tr>
<tr id="S5.T1.2.2" class="ltx_tr">
<td id="S5.T1.2.2.2" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.2.2.1" class="ltx_td ltx_align_center">(<math id="S5.T1.2.2.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S5.T1.2.2.1.m1.1a"><mo id="S5.T1.2.2.1.m1.1.1" xref="S5.T1.2.2.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.1.m1.1b"><lt id="S5.T1.2.2.1.m1.1.1.cmml" xref="S5.T1.2.2.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.1.m1.1c">&lt;</annotation></semantics></math>1e-3)</td>
<td id="S5.T1.2.2.3" class="ltx_td ltx_align_center">(0.01)</td>
</tr>
<tr id="S5.T1.4.20.15" class="ltx_tr">
<th id="S5.T1.4.20.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" rowspan="4">
<span id="S5.T1.4.20.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.20.15.1.1.1" class="ltx_p" style="width:39.8pt;"><span id="S5.T1.4.20.15.1.1.1.1" class="ltx_text">Cyberbully</span></span>
</span>
</th>
<th id="S5.T1.4.20.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" rowspan="2">
<span id="S5.T1.4.20.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.20.15.2.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.20.15.2.1.1.1" class="ltx_text">16</span></span>
</span>
</th>
<td id="S5.T1.4.20.15.3" class="ltx_td ltx_align_center ltx_border_t">0.94</td>
<td id="S5.T1.4.20.15.4" class="ltx_td ltx_align_center ltx_border_t">0.80</td>
<td id="S5.T1.4.20.15.5" class="ltx_td ltx_align_center ltx_border_t">0.94</td>
</tr>
<tr id="S5.T1.4.4" class="ltx_tr">
<td id="S5.T1.3.3.1" class="ltx_td ltx_align_center">(<math id="S5.T1.3.3.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S5.T1.3.3.1.m1.1a"><mo id="S5.T1.3.3.1.m1.1.1" xref="S5.T1.3.3.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.1.m1.1b"><lt id="S5.T1.3.3.1.m1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.1.m1.1c">&lt;</annotation></semantics></math>1e-3)</td>
<td id="S5.T1.4.4.3" class="ltx_td ltx_align_center">(0.01)</td>
<td id="S5.T1.4.4.2" class="ltx_td ltx_align_center">(<math id="S5.T1.4.4.2.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S5.T1.4.4.2.m1.1a"><mo id="S5.T1.4.4.2.m1.1.1" xref="S5.T1.4.4.2.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.2.m1.1b"><lt id="S5.T1.4.4.2.m1.1.1.cmml" xref="S5.T1.4.4.2.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.2.m1.1c">&lt;</annotation></semantics></math>1e-3)</td>
</tr>
<tr id="S5.T1.4.21.16" class="ltx_tr">
<th id="S5.T1.4.21.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_t" rowspan="2">
<span id="S5.T1.4.21.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.21.16.1.1.1" class="ltx_p" style="width:31.3pt;"><span id="S5.T1.4.21.16.1.1.1.1" class="ltx_text">Centr.</span></span>
</span>
</th>
<td id="S5.T1.4.21.16.2" class="ltx_td ltx_align_center ltx_border_t">0.91</td>
<td id="S5.T1.4.21.16.3" class="ltx_td ltx_align_center ltx_border_t">0.91</td>
<td id="S5.T1.4.21.16.4" class="ltx_td ltx_align_center ltx_border_t">0.93</td>
</tr>
<tr id="S5.T1.4.22.17" class="ltx_tr">
<td id="S5.T1.4.22.17.1" class="ltx_td ltx_align_center ltx_border_b">(0.03)</td>
<td id="S5.T1.4.22.17.2" class="ltx_td ltx_align_center ltx_border_b">(0.02)</td>
<td id="S5.T1.4.22.17.3" class="ltx_td ltx_align_center ltx_border_b">(0.02)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparing FL and centralized approach. Average values over five repetitions (std in parenthesis) for five different datasets. Each client has 0.1K data points and balanced data (50% harmful class).</figcaption>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Generalization on other Twitter datasets</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">Bootstrapping from the first round of experiments, we test the <span id="S5.SS5.p1.1.1" class="ltx_text ltx_font_italic">FL training setup</span> with four other datasets (see datasets details in Section <a href="#S5.SS3" title="5.3 Datasets ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>) to explore the generalization of the classifier’s utility. For each dataset, we run both the FL, and centralized training for five repetitions each, and then compare the average performances.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">We run the FL training for twenty rounds, with the same clients participating in each round. Each client had a 100 tweets balanced dataset. We set the data size to 100 due to the datasets’ size limitations, and based on the previous experiments that 100 data points per client are sufficient for effective FL training.
We randomly select fifty clients when the dataset size allowed us to do so. For small datasets we build the maximum number of clients i.e., 37 and 16 clients for Offensive and Cyberbully datasets, respectively. For the Centralized training, we used a training set size<math id="S5.SS5.p2.1.m1.1" class="ltx_Math" alttext="=\#clients\times 100" display="inline"><semantics id="S5.SS5.p2.1.m1.1a"><mrow id="S5.SS5.p2.1.m1.1.1" xref="S5.SS5.p2.1.m1.1.1.cmml"><mi id="S5.SS5.p2.1.m1.1.1.2" xref="S5.SS5.p2.1.m1.1.1.2.cmml"></mi><mo id="S5.SS5.p2.1.m1.1.1.1" xref="S5.SS5.p2.1.m1.1.1.1.cmml">=</mo><mrow id="S5.SS5.p2.1.m1.1.1.3" xref="S5.SS5.p2.1.m1.1.1.3.cmml"><mrow id="S5.SS5.p2.1.m1.1.1.3.2" xref="S5.SS5.p2.1.m1.1.1.3.2.cmml"><mi mathvariant="normal" id="S5.SS5.p2.1.m1.1.1.3.2.2" xref="S5.SS5.p2.1.m1.1.1.3.2.2.cmml">#</mi><mo lspace="0em" rspace="0em" id="S5.SS5.p2.1.m1.1.1.3.2.1" xref="S5.SS5.p2.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S5.SS5.p2.1.m1.1.1.3.2.3" xref="S5.SS5.p2.1.m1.1.1.3.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS5.p2.1.m1.1.1.3.2.1a" xref="S5.SS5.p2.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S5.SS5.p2.1.m1.1.1.3.2.4" xref="S5.SS5.p2.1.m1.1.1.3.2.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS5.p2.1.m1.1.1.3.2.1b" xref="S5.SS5.p2.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S5.SS5.p2.1.m1.1.1.3.2.5" xref="S5.SS5.p2.1.m1.1.1.3.2.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS5.p2.1.m1.1.1.3.2.1c" xref="S5.SS5.p2.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S5.SS5.p2.1.m1.1.1.3.2.6" xref="S5.SS5.p2.1.m1.1.1.3.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS5.p2.1.m1.1.1.3.2.1d" xref="S5.SS5.p2.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S5.SS5.p2.1.m1.1.1.3.2.7" xref="S5.SS5.p2.1.m1.1.1.3.2.7.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS5.p2.1.m1.1.1.3.2.1e" xref="S5.SS5.p2.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S5.SS5.p2.1.m1.1.1.3.2.8" xref="S5.SS5.p2.1.m1.1.1.3.2.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS5.p2.1.m1.1.1.3.2.1f" xref="S5.SS5.p2.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S5.SS5.p2.1.m1.1.1.3.2.9" xref="S5.SS5.p2.1.m1.1.1.3.2.9.cmml">s</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S5.SS5.p2.1.m1.1.1.3.1" xref="S5.SS5.p2.1.m1.1.1.3.1.cmml">×</mo><mn id="S5.SS5.p2.1.m1.1.1.3.3" xref="S5.SS5.p2.1.m1.1.1.3.3.cmml">100</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.1.m1.1b"><apply id="S5.SS5.p2.1.m1.1.1.cmml" xref="S5.SS5.p2.1.m1.1.1"><eq id="S5.SS5.p2.1.m1.1.1.1.cmml" xref="S5.SS5.p2.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S5.SS5.p2.1.m1.1.1.2.cmml" xref="S5.SS5.p2.1.m1.1.1.2">absent</csymbol><apply id="S5.SS5.p2.1.m1.1.1.3.cmml" xref="S5.SS5.p2.1.m1.1.1.3"><times id="S5.SS5.p2.1.m1.1.1.3.1.cmml" xref="S5.SS5.p2.1.m1.1.1.3.1"></times><apply id="S5.SS5.p2.1.m1.1.1.3.2.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2"><times id="S5.SS5.p2.1.m1.1.1.3.2.1.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.1"></times><ci id="S5.SS5.p2.1.m1.1.1.3.2.2.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.2">#</ci><ci id="S5.SS5.p2.1.m1.1.1.3.2.3.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.3">𝑐</ci><ci id="S5.SS5.p2.1.m1.1.1.3.2.4.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.4">𝑙</ci><ci id="S5.SS5.p2.1.m1.1.1.3.2.5.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.5">𝑖</ci><ci id="S5.SS5.p2.1.m1.1.1.3.2.6.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.6">𝑒</ci><ci id="S5.SS5.p2.1.m1.1.1.3.2.7.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.7">𝑛</ci><ci id="S5.SS5.p2.1.m1.1.1.3.2.8.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.8">𝑡</ci><ci id="S5.SS5.p2.1.m1.1.1.3.2.9.cmml" xref="S5.SS5.p2.1.m1.1.1.3.2.9">𝑠</ci></apply><cn type="integer" id="S5.SS5.p2.1.m1.1.1.3.3.cmml" xref="S5.SS5.p2.1.m1.1.1.3.3">100</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.1.m1.1c">=\#clients\times 100</annotation></semantics></math> to fit the total data used in the FL training for the corresponding dataset. We did not perform hyperparameter tuning to train the model with the different datasets. We present the average evaluation metrics (test phase) for both setups in Table <a href="#S5.T1" title="Table 1 ‣ 5.4 Evaluation of non–DP FL models ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para">
<p id="S5.SS5.p3.3" class="ltx_p"><span id="S5.SS5.p3.3.1" class="ltx_text ltx_font_bold ltx_font_italic">Results Discussion:</span>
Across all five datasets, we observe an AUC performance <math id="S5.SS5.p3.1.m1.1" class="ltx_Math" alttext="{&gt;}{61}\%" display="inline"><semantics id="S5.SS5.p3.1.m1.1a"><mrow id="S5.SS5.p3.1.m1.1.1" xref="S5.SS5.p3.1.m1.1.1.cmml"><mi id="S5.SS5.p3.1.m1.1.1.2" xref="S5.SS5.p3.1.m1.1.1.2.cmml"></mi><mo id="S5.SS5.p3.1.m1.1.1.1" xref="S5.SS5.p3.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S5.SS5.p3.1.m1.1.1.3" xref="S5.SS5.p3.1.m1.1.1.3.cmml"><mn id="S5.SS5.p3.1.m1.1.1.3.2" xref="S5.SS5.p3.1.m1.1.1.3.2.cmml">61</mn><mo id="S5.SS5.p3.1.m1.1.1.3.1" xref="S5.SS5.p3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.1.m1.1b"><apply id="S5.SS5.p3.1.m1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1"><gt id="S5.SS5.p3.1.m1.1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S5.SS5.p3.1.m1.1.1.2.cmml" xref="S5.SS5.p3.1.m1.1.1.2">absent</csymbol><apply id="S5.SS5.p3.1.m1.1.1.3.cmml" xref="S5.SS5.p3.1.m1.1.1.3"><csymbol cd="latexml" id="S5.SS5.p3.1.m1.1.1.3.1.cmml" xref="S5.SS5.p3.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS5.p3.1.m1.1.1.3.2.cmml" xref="S5.SS5.p3.1.m1.1.1.3.2">61</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.1.m1.1c">{&gt;}{61}\%</annotation></semantics></math>. We get the best AUC while training with the Abusive dataset (81%), and with the smallest dataset, the Cyberbully, we achieved an AUC of 80%. Training with the Offensive, Sarcastic, and Hateful, we got an AUC performance of 78%, 66%, and 61%, respectively.
Additionally, we can observe that the model’s performance decreases by <math id="S5.SS5.p3.2.m2.1" class="ltx_Math" alttext="{\sim}{9}\%" display="inline"><semantics id="S5.SS5.p3.2.m2.1a"><mrow id="S5.SS5.p3.2.m2.1.1" xref="S5.SS5.p3.2.m2.1.1.cmml"><mi id="S5.SS5.p3.2.m2.1.1.2" xref="S5.SS5.p3.2.m2.1.1.2.cmml"></mi><mo id="S5.SS5.p3.2.m2.1.1.1" xref="S5.SS5.p3.2.m2.1.1.1.cmml">∼</mo><mrow id="S5.SS5.p3.2.m2.1.1.3" xref="S5.SS5.p3.2.m2.1.1.3.cmml"><mn id="S5.SS5.p3.2.m2.1.1.3.2" xref="S5.SS5.p3.2.m2.1.1.3.2.cmml">9</mn><mo id="S5.SS5.p3.2.m2.1.1.3.1" xref="S5.SS5.p3.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.2.m2.1b"><apply id="S5.SS5.p3.2.m2.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p3.2.m2.1.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS5.p3.2.m2.1.1.2.cmml" xref="S5.SS5.p3.2.m2.1.1.2">absent</csymbol><apply id="S5.SS5.p3.2.m2.1.1.3.cmml" xref="S5.SS5.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S5.SS5.p3.2.m2.1.1.3.1.cmml" xref="S5.SS5.p3.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS5.p3.2.m2.1.1.3.2.cmml" xref="S5.SS5.p3.2.m2.1.1.3.2">9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.2.m2.1c">{\sim}{9}\%</annotation></semantics></math> (the minimum) to <math id="S5.SS5.p3.3.m3.1" class="ltx_Math" alttext="{\sim}{18}\%" display="inline"><semantics id="S5.SS5.p3.3.m3.1a"><mrow id="S5.SS5.p3.3.m3.1.1" xref="S5.SS5.p3.3.m3.1.1.cmml"><mi id="S5.SS5.p3.3.m3.1.1.2" xref="S5.SS5.p3.3.m3.1.1.2.cmml"></mi><mo id="S5.SS5.p3.3.m3.1.1.1" xref="S5.SS5.p3.3.m3.1.1.1.cmml">∼</mo><mrow id="S5.SS5.p3.3.m3.1.1.3" xref="S5.SS5.p3.3.m3.1.1.3.cmml"><mn id="S5.SS5.p3.3.m3.1.1.3.2" xref="S5.SS5.p3.3.m3.1.1.3.2.cmml">18</mn><mo id="S5.SS5.p3.3.m3.1.1.3.1" xref="S5.SS5.p3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.3.m3.1b"><apply id="S5.SS5.p3.3.m3.1.1.cmml" xref="S5.SS5.p3.3.m3.1.1"><csymbol cd="latexml" id="S5.SS5.p3.3.m3.1.1.1.cmml" xref="S5.SS5.p3.3.m3.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS5.p3.3.m3.1.1.2.cmml" xref="S5.SS5.p3.3.m3.1.1.2">absent</csymbol><apply id="S5.SS5.p3.3.m3.1.1.3.cmml" xref="S5.SS5.p3.3.m3.1.1.3"><csymbol cd="latexml" id="S5.SS5.p3.3.m3.1.1.3.1.cmml" xref="S5.SS5.p3.3.m3.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS5.p3.3.m3.1.1.3.2.cmml" xref="S5.SS5.p3.3.m3.1.1.3.2">18</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.3.m3.1c">{\sim}{18}\%</annotation></semantics></math> (the maximum) when trained with the FL approach compared to the centralized one. However, the results show that the classifier can be generalized and achieve acceptable performance on different types of misbehavior, even without hyperparameter tuning.</p>
</div>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>FL with Central Differential Privacy</h3>

<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2209.11843/assets/x6.png" id="S5.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="415" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>
</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2209.11843/assets/x7.png" id="S5.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="403" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2209.11843/assets/x8.png" id="S5.F4.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="403" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Comparing DP and non-DP FL. Evaluation of <math id="S5.F4.4.m1.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="S5.F4.4.m1.2b"><mrow id="S5.F4.4.m1.2.3.2" xref="S5.F4.4.m1.2.3.1.cmml"><mo stretchy="false" id="S5.F4.4.m1.2.3.2.1" xref="S5.F4.4.m1.2.3.1.cmml">(</mo><mi id="S5.F4.4.m1.1.1" xref="S5.F4.4.m1.1.1.cmml">ε</mi><mo id="S5.F4.4.m1.2.3.2.2" xref="S5.F4.4.m1.2.3.1.cmml">,</mo><mi id="S5.F4.4.m1.2.2" xref="S5.F4.4.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S5.F4.4.m1.2.3.2.3" xref="S5.F4.4.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.4.m1.2c"><interval closure="open" id="S5.F4.4.m1.2.3.1.cmml" xref="S5.F4.4.m1.2.3.2"><ci id="S5.F4.4.m1.1.1.cmml" xref="S5.F4.4.m1.1.1">𝜀</ci><ci id="S5.F4.4.m1.2.2.cmml" xref="S5.F4.4.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.4.m1.2d">(\varepsilon,\delta)</annotation></semantics></math>-DP FL for different <math id="S5.F4.5.m2.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.F4.5.m2.1b"><mi id="S5.F4.5.m2.1.1" xref="S5.F4.5.m2.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.F4.5.m2.1c"><ci id="S5.F4.5.m2.1.1.cmml" xref="S5.F4.5.m2.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.5.m2.1d">\varepsilon</annotation></semantics></math> values and <math id="S5.F4.6.m3.1" class="ltx_Math" alttext="\delta=10^{-3}" display="inline"><semantics id="S5.F4.6.m3.1b"><mrow id="S5.F4.6.m3.1.1" xref="S5.F4.6.m3.1.1.cmml"><mi id="S5.F4.6.m3.1.1.2" xref="S5.F4.6.m3.1.1.2.cmml">δ</mi><mo id="S5.F4.6.m3.1.1.1" xref="S5.F4.6.m3.1.1.1.cmml">=</mo><msup id="S5.F4.6.m3.1.1.3" xref="S5.F4.6.m3.1.1.3.cmml"><mn id="S5.F4.6.m3.1.1.3.2" xref="S5.F4.6.m3.1.1.3.2.cmml">10</mn><mrow id="S5.F4.6.m3.1.1.3.3" xref="S5.F4.6.m3.1.1.3.3.cmml"><mo id="S5.F4.6.m3.1.1.3.3b" xref="S5.F4.6.m3.1.1.3.3.cmml">−</mo><mn id="S5.F4.6.m3.1.1.3.3.2" xref="S5.F4.6.m3.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.6.m3.1c"><apply id="S5.F4.6.m3.1.1.cmml" xref="S5.F4.6.m3.1.1"><eq id="S5.F4.6.m3.1.1.1.cmml" xref="S5.F4.6.m3.1.1.1"></eq><ci id="S5.F4.6.m3.1.1.2.cmml" xref="S5.F4.6.m3.1.1.2">𝛿</ci><apply id="S5.F4.6.m3.1.1.3.cmml" xref="S5.F4.6.m3.1.1.3"><csymbol cd="ambiguous" id="S5.F4.6.m3.1.1.3.1.cmml" xref="S5.F4.6.m3.1.1.3">superscript</csymbol><cn type="integer" id="S5.F4.6.m3.1.1.3.2.cmml" xref="S5.F4.6.m3.1.1.3.2">10</cn><apply id="S5.F4.6.m3.1.1.3.3.cmml" xref="S5.F4.6.m3.1.1.3.3"><minus id="S5.F4.6.m3.1.1.3.3.1.cmml" xref="S5.F4.6.m3.1.1.3.3"></minus><cn type="integer" id="S5.F4.6.m3.1.1.3.3.2.cmml" xref="S5.F4.6.m3.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.6.m3.1d">\delta=10^{-3}</annotation></semantics></math>. Experiments with 628 total clients; 100 data points per client; 50% harmful-class (balanced data). For the non-DP FL, we perform client selection (per FL round) with the same sampling values used for the DP FL.</figcaption>
</figure>
<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">Central Differential Privacy provides privacy guarantees (at the user level) against data (or membership) inference attacks by an external attacker who has access to the trained model. We apply the CDP to our FL training setup (our implementation is based on the TensorFlow privacy library<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/tensorflow/privacy</span></span></span></span>. TensorFlow modifies the Federated Averaging algorithm to add CDP based on the study of <cite class="ltx_cite ltx_citemacro_citep">(Andrew et al. <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>. The modifications are the following:
(i) each client clips the model’s updates before transmitting them to the server.
(ii) the server, during the aggregation of the client’s updates, adds noise to the sum of the updates before averaging.</p>
</div>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.3" class="ltx_p">TensorFlow privacy library provides an implementation that returns the necessary DP parameters (i.e., noise multiplier, sampling size) to achieve a specific <math id="S5.SS6.p2.1.m1.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="S5.SS6.p2.1.m1.2a"><mrow id="S5.SS6.p2.1.m1.2.3.2" xref="S5.SS6.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.SS6.p2.1.m1.2.3.2.1" xref="S5.SS6.p2.1.m1.2.3.1.cmml">(</mo><mi id="S5.SS6.p2.1.m1.1.1" xref="S5.SS6.p2.1.m1.1.1.cmml">ε</mi><mo id="S5.SS6.p2.1.m1.2.3.2.2" xref="S5.SS6.p2.1.m1.2.3.1.cmml">,</mo><mi id="S5.SS6.p2.1.m1.2.2" xref="S5.SS6.p2.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S5.SS6.p2.1.m1.2.3.2.3" xref="S5.SS6.p2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p2.1.m1.2b"><interval closure="open" id="S5.SS6.p2.1.m1.2.3.1.cmml" xref="S5.SS6.p2.1.m1.2.3.2"><ci id="S5.SS6.p2.1.m1.1.1.cmml" xref="S5.SS6.p2.1.m1.1.1">𝜀</ci><ci id="S5.SS6.p2.1.m1.2.2.cmml" xref="S5.SS6.p2.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p2.1.m1.2c">(\varepsilon,\delta)</annotation></semantics></math>-DP for the FL training setup. This implementation is based on the Moment Accountant method <cite class="ltx_cite ltx_citemacro_citep">(Wang, Balle, and Kasiviswanathan <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> which assesses the <math id="S5.SS6.p2.2.m2.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="S5.SS6.p2.2.m2.2a"><mrow id="S5.SS6.p2.2.m2.2.3.2" xref="S5.SS6.p2.2.m2.2.3.1.cmml"><mo stretchy="false" id="S5.SS6.p2.2.m2.2.3.2.1" xref="S5.SS6.p2.2.m2.2.3.1.cmml">(</mo><mi id="S5.SS6.p2.2.m2.1.1" xref="S5.SS6.p2.2.m2.1.1.cmml">ε</mi><mo id="S5.SS6.p2.2.m2.2.3.2.2" xref="S5.SS6.p2.2.m2.2.3.1.cmml">,</mo><mi id="S5.SS6.p2.2.m2.2.2" xref="S5.SS6.p2.2.m2.2.2.cmml">δ</mi><mo stretchy="false" id="S5.SS6.p2.2.m2.2.3.2.3" xref="S5.SS6.p2.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p2.2.m2.2b"><interval closure="open" id="S5.SS6.p2.2.m2.2.3.1.cmml" xref="S5.SS6.p2.2.m2.2.3.2"><ci id="S5.SS6.p2.2.m2.1.1.cmml" xref="S5.SS6.p2.2.m2.1.1">𝜀</ci><ci id="S5.SS6.p2.2.m2.2.2.cmml" xref="S5.SS6.p2.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p2.2.m2.2c">(\varepsilon,\delta)</annotation></semantics></math>-DP of the model.
Lower <math id="S5.SS6.p2.3.m3.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p2.3.m3.1a"><mi id="S5.SS6.p2.3.m3.1.1" xref="S5.SS6.p2.3.m3.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p2.3.m3.1b"><ci id="S5.SS6.p2.3.m3.1.1.cmml" xref="S5.SS6.p2.3.m3.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p2.3.m3.1c">\varepsilon</annotation></semantics></math> values mean that we offer higher privacy to the clients participating in the FL training. The noise multiplier property defines the addition of noise to the sum of the model’s updates, and the sampling size refers to randomly selecting a subset of the available clients to participate in each round. The client sampling adds to the privacy guarantee of the training since we do not set a fixed number of clients participating in every round.</p>
</div>
<div id="S5.SS6.p3" class="ltx_para">
<p id="S5.SS6.p3.1" class="ltx_p">We run an experiment to assess the privacy guarantee and utility trade-off. For this experiment, we use the Abusive dataset, split and distribute the data to clients as described in Section <a href="#S4.SS4" title="4.4 Creating artificial clients for FL ‣ 4 Federated Learning Setup ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>. We run the <span id="S5.SS6.p3.1.1" class="ltx_text ltx_font_italic">FL training setup</span> for 100 rounds, and each client has a 0.1K balanced dataset. These FL parameters give the maximum available number of clients, i.e, 628 clients. We use Poisson sampling, which gives a different number of clients to participate in each round, with a mean set to <span id="S5.SS6.p3.1.2" class="ltx_text ltx_font_italic">sampling size</span> value.</p>
</div>
<div id="S5.SS6.p4" class="ltx_para">
<p id="S5.SS6.p4.9" class="ltx_p">We evaluate the DP-classifier with different <math id="S5.SS6.p4.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p4.1.m1.1a"><mi id="S5.SS6.p4.1.m1.1.1" xref="S5.SS6.p4.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.1.m1.1b"><ci id="S5.SS6.p4.1.m1.1.1.cmml" xref="S5.SS6.p4.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.1.m1.1c">\varepsilon</annotation></semantics></math> values, while setting <math id="S5.SS6.p4.2.m2.1" class="ltx_Math" alttext="{\delta={1e-3}}" display="inline"><semantics id="S5.SS6.p4.2.m2.1a"><mrow id="S5.SS6.p4.2.m2.1.1" xref="S5.SS6.p4.2.m2.1.1.cmml"><mi id="S5.SS6.p4.2.m2.1.1.2" xref="S5.SS6.p4.2.m2.1.1.2.cmml">δ</mi><mo id="S5.SS6.p4.2.m2.1.1.1" xref="S5.SS6.p4.2.m2.1.1.1.cmml">=</mo><mrow id="S5.SS6.p4.2.m2.1.1.3" xref="S5.SS6.p4.2.m2.1.1.3.cmml"><mrow id="S5.SS6.p4.2.m2.1.1.3.2" xref="S5.SS6.p4.2.m2.1.1.3.2.cmml"><mn id="S5.SS6.p4.2.m2.1.1.3.2.2" xref="S5.SS6.p4.2.m2.1.1.3.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S5.SS6.p4.2.m2.1.1.3.2.1" xref="S5.SS6.p4.2.m2.1.1.3.2.1.cmml">​</mo><mi id="S5.SS6.p4.2.m2.1.1.3.2.3" xref="S5.SS6.p4.2.m2.1.1.3.2.3.cmml">e</mi></mrow><mo id="S5.SS6.p4.2.m2.1.1.3.1" xref="S5.SS6.p4.2.m2.1.1.3.1.cmml">−</mo><mn id="S5.SS6.p4.2.m2.1.1.3.3" xref="S5.SS6.p4.2.m2.1.1.3.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.2.m2.1b"><apply id="S5.SS6.p4.2.m2.1.1.cmml" xref="S5.SS6.p4.2.m2.1.1"><eq id="S5.SS6.p4.2.m2.1.1.1.cmml" xref="S5.SS6.p4.2.m2.1.1.1"></eq><ci id="S5.SS6.p4.2.m2.1.1.2.cmml" xref="S5.SS6.p4.2.m2.1.1.2">𝛿</ci><apply id="S5.SS6.p4.2.m2.1.1.3.cmml" xref="S5.SS6.p4.2.m2.1.1.3"><minus id="S5.SS6.p4.2.m2.1.1.3.1.cmml" xref="S5.SS6.p4.2.m2.1.1.3.1"></minus><apply id="S5.SS6.p4.2.m2.1.1.3.2.cmml" xref="S5.SS6.p4.2.m2.1.1.3.2"><times id="S5.SS6.p4.2.m2.1.1.3.2.1.cmml" xref="S5.SS6.p4.2.m2.1.1.3.2.1"></times><cn type="integer" id="S5.SS6.p4.2.m2.1.1.3.2.2.cmml" xref="S5.SS6.p4.2.m2.1.1.3.2.2">1</cn><ci id="S5.SS6.p4.2.m2.1.1.3.2.3.cmml" xref="S5.SS6.p4.2.m2.1.1.3.2.3">𝑒</ci></apply><cn type="integer" id="S5.SS6.p4.2.m2.1.1.3.3.cmml" xref="S5.SS6.p4.2.m2.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.2.m2.1c">{\delta={1e-3}}</annotation></semantics></math>. We define <math id="S5.SS6.p4.3.m3.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S5.SS6.p4.3.m3.1a"><mi id="S5.SS6.p4.3.m3.1.1" xref="S5.SS6.p4.3.m3.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.3.m3.1b"><ci id="S5.SS6.p4.3.m3.1.1.cmml" xref="S5.SS6.p4.3.m3.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.3.m3.1c">\delta</annotation></semantics></math> using the suggested formula <math id="S5.SS6.p4.4.m4.1" class="ltx_Math" alttext="{\delta=1/|totalsamples|}" display="inline"><semantics id="S5.SS6.p4.4.m4.1a"><mrow id="S5.SS6.p4.4.m4.1.1" xref="S5.SS6.p4.4.m4.1.1.cmml"><mi id="S5.SS6.p4.4.m4.1.1.3" xref="S5.SS6.p4.4.m4.1.1.3.cmml">δ</mi><mo id="S5.SS6.p4.4.m4.1.1.2" xref="S5.SS6.p4.4.m4.1.1.2.cmml">=</mo><mrow id="S5.SS6.p4.4.m4.1.1.1" xref="S5.SS6.p4.4.m4.1.1.1.cmml"><mn id="S5.SS6.p4.4.m4.1.1.1.3" xref="S5.SS6.p4.4.m4.1.1.1.3.cmml">1</mn><mo id="S5.SS6.p4.4.m4.1.1.1.2" xref="S5.SS6.p4.4.m4.1.1.1.2.cmml">/</mo><mrow id="S5.SS6.p4.4.m4.1.1.1.1.1" xref="S5.SS6.p4.4.m4.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.SS6.p4.4.m4.1.1.1.1.1.2" xref="S5.SS6.p4.4.m4.1.1.1.1.2.1.cmml">|</mo><mrow id="S5.SS6.p4.4.m4.1.1.1.1.1.1" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.cmml"><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.2" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.3" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1a" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.4" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1b" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.5" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1c" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.6" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1d" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.7" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1e" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.8" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1f" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.9" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.9.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1g" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.10" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.10.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1h" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.11" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.11.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1i" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.12" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.12.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1j" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml">​</mo><mi id="S5.SS6.p4.4.m4.1.1.1.1.1.1.13" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.13.cmml">s</mi></mrow><mo stretchy="false" id="S5.SS6.p4.4.m4.1.1.1.1.1.3" xref="S5.SS6.p4.4.m4.1.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.4.m4.1b"><apply id="S5.SS6.p4.4.m4.1.1.cmml" xref="S5.SS6.p4.4.m4.1.1"><eq id="S5.SS6.p4.4.m4.1.1.2.cmml" xref="S5.SS6.p4.4.m4.1.1.2"></eq><ci id="S5.SS6.p4.4.m4.1.1.3.cmml" xref="S5.SS6.p4.4.m4.1.1.3">𝛿</ci><apply id="S5.SS6.p4.4.m4.1.1.1.cmml" xref="S5.SS6.p4.4.m4.1.1.1"><divide id="S5.SS6.p4.4.m4.1.1.1.2.cmml" xref="S5.SS6.p4.4.m4.1.1.1.2"></divide><cn type="integer" id="S5.SS6.p4.4.m4.1.1.1.3.cmml" xref="S5.SS6.p4.4.m4.1.1.1.3">1</cn><apply id="S5.SS6.p4.4.m4.1.1.1.1.2.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1"><abs id="S5.SS6.p4.4.m4.1.1.1.1.2.1.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.2"></abs><apply id="S5.SS6.p4.4.m4.1.1.1.1.1.1.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1"><times id="S5.SS6.p4.4.m4.1.1.1.1.1.1.1.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.1"></times><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.2.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.2">𝑡</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.3.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.3">𝑜</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.4.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.4">𝑡</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.5.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.5">𝑎</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.6.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.6">𝑙</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.7.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.7">𝑠</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.8.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.8">𝑎</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.9.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.9">𝑚</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.10.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.10">𝑝</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.11.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.11">𝑙</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.12.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.12">𝑒</ci><ci id="S5.SS6.p4.4.m4.1.1.1.1.1.1.13.cmml" xref="S5.SS6.p4.4.m4.1.1.1.1.1.1.13">𝑠</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.4.m4.1c">{\delta=1/|totalsamples|}</annotation></semantics></math> in <cite class="ltx_cite ltx_citemacro_citep">(Abadi et al. <a href="#bib.bib1" title="" class="ltx_ref">2016</a>; McMahan et al. <a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite>. For each <math id="S5.SS6.p4.5.m5.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p4.5.m5.1a"><mi id="S5.SS6.p4.5.m5.1.1" xref="S5.SS6.p4.5.m5.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.5.m5.1b"><ci id="S5.SS6.p4.5.m5.1.1.cmml" xref="S5.SS6.p4.5.m5.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.5.m5.1c">\varepsilon</annotation></semantics></math> value, we get the DP-parameters – necessary for achieving the given <math id="S5.SS6.p4.6.m6.2" class="ltx_Math" alttext="(\varepsilon,\delta)" display="inline"><semantics id="S5.SS6.p4.6.m6.2a"><mrow id="S5.SS6.p4.6.m6.2.3.2" xref="S5.SS6.p4.6.m6.2.3.1.cmml"><mo stretchy="false" id="S5.SS6.p4.6.m6.2.3.2.1" xref="S5.SS6.p4.6.m6.2.3.1.cmml">(</mo><mi id="S5.SS6.p4.6.m6.1.1" xref="S5.SS6.p4.6.m6.1.1.cmml">ε</mi><mo id="S5.SS6.p4.6.m6.2.3.2.2" xref="S5.SS6.p4.6.m6.2.3.1.cmml">,</mo><mi id="S5.SS6.p4.6.m6.2.2" xref="S5.SS6.p4.6.m6.2.2.cmml">δ</mi><mo stretchy="false" id="S5.SS6.p4.6.m6.2.3.2.3" xref="S5.SS6.p4.6.m6.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.6.m6.2b"><interval closure="open" id="S5.SS6.p4.6.m6.2.3.1.cmml" xref="S5.SS6.p4.6.m6.2.3.2"><ci id="S5.SS6.p4.6.m6.1.1.cmml" xref="S5.SS6.p4.6.m6.1.1">𝜀</ci><ci id="S5.SS6.p4.6.m6.2.2.cmml" xref="S5.SS6.p4.6.m6.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.6.m6.2c">(\varepsilon,\delta)</annotation></semantics></math>-DP – using the TensorFlow privacy library. So for <math id="S5.SS6.p4.7.m7.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p4.7.m7.1a"><mi id="S5.SS6.p4.7.m7.1.1" xref="S5.SS6.p4.7.m7.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.7.m7.1b"><ci id="S5.SS6.p4.7.m7.1.1.cmml" xref="S5.SS6.p4.7.m7.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.7.m7.1c">\varepsilon</annotation></semantics></math> value of [1.5, 3, 5, 10], we get the following DP-parameters {sampling size, noise multiplier}: 1.5={23, 1.15}, 3={25, 0.875}, 5={66, 1.1}, 10={37, 0.612} respectively. We repeated the simulations ten times for <math id="S5.SS6.p4.8.m8.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p4.8.m8.1a"><mi id="S5.SS6.p4.8.m8.1.1" xref="S5.SS6.p4.8.m8.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.8.m8.1b"><ci id="S5.SS6.p4.8.m8.1.1.cmml" xref="S5.SS6.p4.8.m8.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.8.m8.1c">\varepsilon</annotation></semantics></math> set to [1.5, 3], and five times for <math id="S5.SS6.p4.9.m9.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p4.9.m9.1a"><mi id="S5.SS6.p4.9.m9.1.1" xref="S5.SS6.p4.9.m9.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p4.9.m9.1b"><ci id="S5.SS6.p4.9.m9.1.1.cmml" xref="S5.SS6.p4.9.m9.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p4.9.m9.1c">\varepsilon</annotation></semantics></math> set to [5, 10]. We present the average AUC achieved in Figure <a href="#S5.F4.sf1" title="In Figure 4 ‣ 5.6 FL with Central Differential Privacy ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> (the green line shows the mean, and the red the median).</p>
</div>
<div id="S5.SS6.p5" class="ltx_para">
<p id="S5.SS6.p5.1" class="ltx_p">To investigate the trade-off between utility and privacy, we run a set of experiments with the <span id="S5.SS6.p5.1.1" class="ltx_text ltx_font_italic">FL training setup</span> using the same parameters mentioned before (i.e., clients dataset, sampling size, number of FL rounds) but without adding DP. In Figure <a href="#S5.F4.sf1" title="In Figure 4 ‣ 5.6 FL with Central Differential Privacy ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a>, we present the average AUC values (over five repetitions) for the non-DP model.
We evaluated the model’s performance every ten rounds of the FL training for both the non-DP model and DP model for the <math id="S5.SS6.p5.1.m1.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p5.1.m1.1a"><mi id="S5.SS6.p5.1.m1.1.1" xref="S5.SS6.p5.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p5.1.m1.1b"><ci id="S5.SS6.p5.1.m1.1.1.cmml" xref="S5.SS6.p5.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p5.1.m1.1c">\varepsilon</annotation></semantics></math> values 3 (medium) and 5 (medium-high). We present the average AUC values in Figure <a href="#S5.F4.sf2" title="In Figure 4 ‣ 5.6 FL with Central Differential Privacy ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a>, and <a href="#S5.F4.sf3" title="In Figure 4 ‣ 5.6 FL with Central Differential Privacy ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a> respectively.</p>
</div>
<div id="S5.SS6.p6" class="ltx_para">
<p id="S5.SS6.p6.3" class="ltx_p"><span id="S5.SS6.p6.3.1" class="ltx_text ltx_font_bold ltx_font_italic">Results Discussion:</span>
Figure <a href="#S5.F4.sf1" title="In Figure 4 ‣ 5.6 FL with Central Differential Privacy ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> shows that adding DP with a strict privacy guarantee (i.e., <math id="S5.SS6.p6.1.m1.1" class="ltx_Math" alttext="\varepsilon=1.5" display="inline"><semantics id="S5.SS6.p6.1.m1.1a"><mrow id="S5.SS6.p6.1.m1.1.1" xref="S5.SS6.p6.1.m1.1.1.cmml"><mi id="S5.SS6.p6.1.m1.1.1.2" xref="S5.SS6.p6.1.m1.1.1.2.cmml">ε</mi><mo id="S5.SS6.p6.1.m1.1.1.1" xref="S5.SS6.p6.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS6.p6.1.m1.1.1.3" xref="S5.SS6.p6.1.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p6.1.m1.1b"><apply id="S5.SS6.p6.1.m1.1.1.cmml" xref="S5.SS6.p6.1.m1.1.1"><eq id="S5.SS6.p6.1.m1.1.1.1.cmml" xref="S5.SS6.p6.1.m1.1.1.1"></eq><ci id="S5.SS6.p6.1.m1.1.1.2.cmml" xref="S5.SS6.p6.1.m1.1.1.2">𝜀</ci><cn type="float" id="S5.SS6.p6.1.m1.1.1.3.cmml" xref="S5.SS6.p6.1.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p6.1.m1.1c">\varepsilon=1.5</annotation></semantics></math>) causes a 20% decrease in AUC when compared to the non-DP model performance. Experimenting with lower <math id="S5.SS6.p6.2.m2.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S5.SS6.p6.2.m2.1a"><mi id="S5.SS6.p6.2.m2.1.1" xref="S5.SS6.p6.2.m2.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS6.p6.2.m2.1b"><ci id="S5.SS6.p6.2.m2.1.1.cmml" xref="S5.SS6.p6.2.m2.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p6.2.m2.1c">\varepsilon</annotation></semantics></math> values, we observed that we do not get a robust model with stable behavior (i.e., four out of ten repetitions gave a 10% to 30% AUC). Additionally, we observed that the classifier could tolerate a noise multiplier near the value 1; adding more noise does not allow the classifier to learn during the training. With a medium DP level, <math id="S5.SS6.p6.3.m3.3" class="ltx_Math" alttext="(\varepsilon=3,5)" display="inline"><semantics id="S5.SS6.p6.3.m3.3a"><mrow id="S5.SS6.p6.3.m3.3.3.1" xref="S5.SS6.p6.3.m3.3.3.1.1.cmml"><mo stretchy="false" id="S5.SS6.p6.3.m3.3.3.1.2" xref="S5.SS6.p6.3.m3.3.3.1.1.cmml">(</mo><mrow id="S5.SS6.p6.3.m3.3.3.1.1" xref="S5.SS6.p6.3.m3.3.3.1.1.cmml"><mi id="S5.SS6.p6.3.m3.3.3.1.1.2" xref="S5.SS6.p6.3.m3.3.3.1.1.2.cmml">ε</mi><mo id="S5.SS6.p6.3.m3.3.3.1.1.1" xref="S5.SS6.p6.3.m3.3.3.1.1.1.cmml">=</mo><mrow id="S5.SS6.p6.3.m3.3.3.1.1.3.2" xref="S5.SS6.p6.3.m3.3.3.1.1.3.1.cmml"><mn id="S5.SS6.p6.3.m3.1.1" xref="S5.SS6.p6.3.m3.1.1.cmml">3</mn><mo id="S5.SS6.p6.3.m3.3.3.1.1.3.2.1" xref="S5.SS6.p6.3.m3.3.3.1.1.3.1.cmml">,</mo><mn id="S5.SS6.p6.3.m3.2.2" xref="S5.SS6.p6.3.m3.2.2.cmml">5</mn></mrow></mrow><mo stretchy="false" id="S5.SS6.p6.3.m3.3.3.1.3" xref="S5.SS6.p6.3.m3.3.3.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS6.p6.3.m3.3b"><apply id="S5.SS6.p6.3.m3.3.3.1.1.cmml" xref="S5.SS6.p6.3.m3.3.3.1"><eq id="S5.SS6.p6.3.m3.3.3.1.1.1.cmml" xref="S5.SS6.p6.3.m3.3.3.1.1.1"></eq><ci id="S5.SS6.p6.3.m3.3.3.1.1.2.cmml" xref="S5.SS6.p6.3.m3.3.3.1.1.2">𝜀</ci><list id="S5.SS6.p6.3.m3.3.3.1.1.3.1.cmml" xref="S5.SS6.p6.3.m3.3.3.1.1.3.2"><cn type="integer" id="S5.SS6.p6.3.m3.1.1.cmml" xref="S5.SS6.p6.3.m3.1.1">3</cn><cn type="integer" id="S5.SS6.p6.3.m3.2.2.cmml" xref="S5.SS6.p6.3.m3.2.2">5</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS6.p6.3.m3.3c">(\varepsilon=3,5)</annotation></semantics></math>, we get an average AUC of 75%, and 80%, approaching the non-DP model’s performance. Figures <a href="#S5.F4.sf2" title="In Figure 4 ‣ 5.6 FL with Central Differential Privacy ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a>, <a href="#S5.F4.sf3" title="In Figure 4 ‣ 5.6 FL with Central Differential Privacy ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a> show that a DP-model training requires more FL rounds to converge (i.e., 100 rounds) while the non-DP model’s performance shows a rapid increase, and reaches an acceptable AUC (i.e., 20-30 rounds). The performance of the non-private model additionally confirms our previous observations that altering the number of FL participants (i.e., sampling size) does not affect the model’s performance. Finally, we observe that by training the model for 100 FL rounds, we get 85% AUC. In other words, the performance is improved by 4% from the case we present in Figure <a href="#S5.F3.sf2" title="In Figure 3 ‣ 5.3 Datasets ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> — i.e. fifty clients with 0.1K balanced dataset each.</p>
</div>
</section>
<section id="S5.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.7 </span>Overhead on Client’s Device</h3>

<div id="S5.SS7.p1" class="ltx_para">
<p id="S5.SS7.p1.1" class="ltx_p">We experiment to measure the extra overhead caused to the client’s device when participating in the FL training. Specifically, we assess the overhead during the local training, which happens in one FL round on the client’s device.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2209.11843/assets/x9.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>CPU and memory consumption (every 2 seconds) on client’s device due to the FL training. The client’s training set consists of 0.1K data.</figcaption>
</figure>
<div id="S5.SS7.p2" class="ltx_para">
<p id="S5.SS7.p2.1" class="ltx_p">We run the <span id="S5.SS7.p2.1.1" class="ltx_text ltx_font_italic">Local training</span> on a laptop (see laptop properties in Section <a href="#S5.SS1" title="5.1 Training Setup ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>), using the whole client’s dataset as the training set. Since the results of the experiments with 0.1K data per client showed that we can have a well-performing classifier, we set the client’s dataset size to 0.1K.
While training the model locally, we monitor the machine resource utilization (memory consumption and CPU utilization) and collect the logs after every two seconds. We repeated the training ten times. We kept the CPU ‘idle’ during the training by not running other applications. Figure <a href="#S5.F5" title="Figure 5 ‣ 5.7 Overhead on Client’s Device ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the device’s CPU utilization percentage and the memory consumption (in MB) during the local training after averaging the results of the experiment.</p>
</div>
<div id="S5.SS7.p3" class="ltx_para">
<p id="S5.SS7.p3.6" class="ltx_p"><span id="S5.SS7.p3.6.1" class="ltx_text ltx_font_bold ltx_font_italic">Results discussion:</span>
In Figure <a href="#S5.F5" title="Figure 5 ‣ 5.7 Overhead on Client’s Device ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we see that the total duration of the training phase is <math id="S5.SS7.p3.1.m1.1" class="ltx_Math" alttext="{\sim}{14}" display="inline"><semantics id="S5.SS7.p3.1.m1.1a"><mrow id="S5.SS7.p3.1.m1.1.1" xref="S5.SS7.p3.1.m1.1.1.cmml"><mi id="S5.SS7.p3.1.m1.1.1.2" xref="S5.SS7.p3.1.m1.1.1.2.cmml"></mi><mo id="S5.SS7.p3.1.m1.1.1.1" xref="S5.SS7.p3.1.m1.1.1.1.cmml">∼</mo><mn id="S5.SS7.p3.1.m1.1.1.3" xref="S5.SS7.p3.1.m1.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p3.1.m1.1b"><apply id="S5.SS7.p3.1.m1.1.1.cmml" xref="S5.SS7.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.SS7.p3.1.m1.1.1.1.cmml" xref="S5.SS7.p3.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p3.1.m1.1.1.2.cmml" xref="S5.SS7.p3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.SS7.p3.1.m1.1.1.3.cmml" xref="S5.SS7.p3.1.m1.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p3.1.m1.1c">{\sim}{14}</annotation></semantics></math> seconds. From seconds 0 to 8, the CPU utilization increases linearly from <math id="S5.SS7.p3.2.m2.1" class="ltx_Math" alttext="{\sim}{10}\%" display="inline"><semantics id="S5.SS7.p3.2.m2.1a"><mrow id="S5.SS7.p3.2.m2.1.1" xref="S5.SS7.p3.2.m2.1.1.cmml"><mi id="S5.SS7.p3.2.m2.1.1.2" xref="S5.SS7.p3.2.m2.1.1.2.cmml"></mi><mo id="S5.SS7.p3.2.m2.1.1.1" xref="S5.SS7.p3.2.m2.1.1.1.cmml">∼</mo><mrow id="S5.SS7.p3.2.m2.1.1.3" xref="S5.SS7.p3.2.m2.1.1.3.cmml"><mn id="S5.SS7.p3.2.m2.1.1.3.2" xref="S5.SS7.p3.2.m2.1.1.3.2.cmml">10</mn><mo id="S5.SS7.p3.2.m2.1.1.3.1" xref="S5.SS7.p3.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p3.2.m2.1b"><apply id="S5.SS7.p3.2.m2.1.1.cmml" xref="S5.SS7.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS7.p3.2.m2.1.1.1.cmml" xref="S5.SS7.p3.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p3.2.m2.1.1.2.cmml" xref="S5.SS7.p3.2.m2.1.1.2">absent</csymbol><apply id="S5.SS7.p3.2.m2.1.1.3.cmml" xref="S5.SS7.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S5.SS7.p3.2.m2.1.1.3.1.cmml" xref="S5.SS7.p3.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS7.p3.2.m2.1.1.3.2.cmml" xref="S5.SS7.p3.2.m2.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p3.2.m2.1c">{\sim}{10}\%</annotation></semantics></math> to 20%. Then, there is a rapid increase (from seconds 8 to 10) in which the CPU reaches <math id="S5.SS7.p3.3.m3.1" class="ltx_Math" alttext="{\sim}{70}\%" display="inline"><semantics id="S5.SS7.p3.3.m3.1a"><mrow id="S5.SS7.p3.3.m3.1.1" xref="S5.SS7.p3.3.m3.1.1.cmml"><mi id="S5.SS7.p3.3.m3.1.1.2" xref="S5.SS7.p3.3.m3.1.1.2.cmml"></mi><mo id="S5.SS7.p3.3.m3.1.1.1" xref="S5.SS7.p3.3.m3.1.1.1.cmml">∼</mo><mrow id="S5.SS7.p3.3.m3.1.1.3" xref="S5.SS7.p3.3.m3.1.1.3.cmml"><mn id="S5.SS7.p3.3.m3.1.1.3.2" xref="S5.SS7.p3.3.m3.1.1.3.2.cmml">70</mn><mo id="S5.SS7.p3.3.m3.1.1.3.1" xref="S5.SS7.p3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p3.3.m3.1b"><apply id="S5.SS7.p3.3.m3.1.1.cmml" xref="S5.SS7.p3.3.m3.1.1"><csymbol cd="latexml" id="S5.SS7.p3.3.m3.1.1.1.cmml" xref="S5.SS7.p3.3.m3.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p3.3.m3.1.1.2.cmml" xref="S5.SS7.p3.3.m3.1.1.2">absent</csymbol><apply id="S5.SS7.p3.3.m3.1.1.3.cmml" xref="S5.SS7.p3.3.m3.1.1.3"><csymbol cd="latexml" id="S5.SS7.p3.3.m3.1.1.3.1.cmml" xref="S5.SS7.p3.3.m3.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS7.p3.3.m3.1.1.3.2.cmml" xref="S5.SS7.p3.3.m3.1.1.3.2">70</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p3.3.m3.1c">{\sim}{70}\%</annotation></semantics></math>. At the end of the training phase, there is a decrease to <math id="S5.SS7.p3.4.m4.1" class="ltx_Math" alttext="{\sim}{60}\%" display="inline"><semantics id="S5.SS7.p3.4.m4.1a"><mrow id="S5.SS7.p3.4.m4.1.1" xref="S5.SS7.p3.4.m4.1.1.cmml"><mi id="S5.SS7.p3.4.m4.1.1.2" xref="S5.SS7.p3.4.m4.1.1.2.cmml"></mi><mo id="S5.SS7.p3.4.m4.1.1.1" xref="S5.SS7.p3.4.m4.1.1.1.cmml">∼</mo><mrow id="S5.SS7.p3.4.m4.1.1.3" xref="S5.SS7.p3.4.m4.1.1.3.cmml"><mn id="S5.SS7.p3.4.m4.1.1.3.2" xref="S5.SS7.p3.4.m4.1.1.3.2.cmml">60</mn><mo id="S5.SS7.p3.4.m4.1.1.3.1" xref="S5.SS7.p3.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p3.4.m4.1b"><apply id="S5.SS7.p3.4.m4.1.1.cmml" xref="S5.SS7.p3.4.m4.1.1"><csymbol cd="latexml" id="S5.SS7.p3.4.m4.1.1.1.cmml" xref="S5.SS7.p3.4.m4.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p3.4.m4.1.1.2.cmml" xref="S5.SS7.p3.4.m4.1.1.2">absent</csymbol><apply id="S5.SS7.p3.4.m4.1.1.3.cmml" xref="S5.SS7.p3.4.m4.1.1.3"><csymbol cd="latexml" id="S5.SS7.p3.4.m4.1.1.3.1.cmml" xref="S5.SS7.p3.4.m4.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS7.p3.4.m4.1.1.3.2.cmml" xref="S5.SS7.p3.4.m4.1.1.3.2">60</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p3.4.m4.1c">{\sim}{60}\%</annotation></semantics></math>, and CPU utilization reaches a maximum of <math id="S5.SS7.p3.5.m5.1" class="ltx_Math" alttext="{\sim}{80}\%" display="inline"><semantics id="S5.SS7.p3.5.m5.1a"><mrow id="S5.SS7.p3.5.m5.1.1" xref="S5.SS7.p3.5.m5.1.1.cmml"><mi id="S5.SS7.p3.5.m5.1.1.2" xref="S5.SS7.p3.5.m5.1.1.2.cmml"></mi><mo id="S5.SS7.p3.5.m5.1.1.1" xref="S5.SS7.p3.5.m5.1.1.1.cmml">∼</mo><mrow id="S5.SS7.p3.5.m5.1.1.3" xref="S5.SS7.p3.5.m5.1.1.3.cmml"><mn id="S5.SS7.p3.5.m5.1.1.3.2" xref="S5.SS7.p3.5.m5.1.1.3.2.cmml">80</mn><mo id="S5.SS7.p3.5.m5.1.1.3.1" xref="S5.SS7.p3.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p3.5.m5.1b"><apply id="S5.SS7.p3.5.m5.1.1.cmml" xref="S5.SS7.p3.5.m5.1.1"><csymbol cd="latexml" id="S5.SS7.p3.5.m5.1.1.1.cmml" xref="S5.SS7.p3.5.m5.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p3.5.m5.1.1.2.cmml" xref="S5.SS7.p3.5.m5.1.1.2">absent</csymbol><apply id="S5.SS7.p3.5.m5.1.1.3.cmml" xref="S5.SS7.p3.5.m5.1.1.3"><csymbol cd="latexml" id="S5.SS7.p3.5.m5.1.1.3.1.cmml" xref="S5.SS7.p3.5.m5.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS7.p3.5.m5.1.1.3.2.cmml" xref="S5.SS7.p3.5.m5.1.1.3.2">80</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p3.5.m5.1c">{\sim}{80}\%</annotation></semantics></math>. The average CPU utilization during the training across all repetitions is <math id="S5.SS7.p3.6.m6.1" class="ltx_Math" alttext="{\sim}{25.5}\%" display="inline"><semantics id="S5.SS7.p3.6.m6.1a"><mrow id="S5.SS7.p3.6.m6.1.1" xref="S5.SS7.p3.6.m6.1.1.cmml"><mi id="S5.SS7.p3.6.m6.1.1.2" xref="S5.SS7.p3.6.m6.1.1.2.cmml"></mi><mo id="S5.SS7.p3.6.m6.1.1.1" xref="S5.SS7.p3.6.m6.1.1.1.cmml">∼</mo><mrow id="S5.SS7.p3.6.m6.1.1.3" xref="S5.SS7.p3.6.m6.1.1.3.cmml"><mn id="S5.SS7.p3.6.m6.1.1.3.2" xref="S5.SS7.p3.6.m6.1.1.3.2.cmml">25.5</mn><mo id="S5.SS7.p3.6.m6.1.1.3.1" xref="S5.SS7.p3.6.m6.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p3.6.m6.1b"><apply id="S5.SS7.p3.6.m6.1.1.cmml" xref="S5.SS7.p3.6.m6.1.1"><csymbol cd="latexml" id="S5.SS7.p3.6.m6.1.1.1.cmml" xref="S5.SS7.p3.6.m6.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p3.6.m6.1.1.2.cmml" xref="S5.SS7.p3.6.m6.1.1.2">absent</csymbol><apply id="S5.SS7.p3.6.m6.1.1.3.cmml" xref="S5.SS7.p3.6.m6.1.1.3"><csymbol cd="latexml" id="S5.SS7.p3.6.m6.1.1.3.1.cmml" xref="S5.SS7.p3.6.m6.1.1.3.1">percent</csymbol><cn type="float" id="S5.SS7.p3.6.m6.1.1.3.2.cmml" xref="S5.SS7.p3.6.m6.1.1.3.2">25.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p3.6.m6.1c">{\sim}{25.5}\%</annotation></semantics></math>.</p>
</div>
<div id="S5.SS7.p4" class="ltx_para">
<p id="S5.SS7.p4.7" class="ltx_p">The memory consumption varies between <math id="S5.SS7.p4.1.m1.1" class="ltx_Math" alttext="{\sim}{2300}" display="inline"><semantics id="S5.SS7.p4.1.m1.1a"><mrow id="S5.SS7.p4.1.m1.1.1" xref="S5.SS7.p4.1.m1.1.1.cmml"><mi id="S5.SS7.p4.1.m1.1.1.2" xref="S5.SS7.p4.1.m1.1.1.2.cmml"></mi><mo id="S5.SS7.p4.1.m1.1.1.1" xref="S5.SS7.p4.1.m1.1.1.1.cmml">∼</mo><mn id="S5.SS7.p4.1.m1.1.1.3" xref="S5.SS7.p4.1.m1.1.1.3.cmml">2300</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p4.1.m1.1b"><apply id="S5.SS7.p4.1.m1.1.1.cmml" xref="S5.SS7.p4.1.m1.1.1"><csymbol cd="latexml" id="S5.SS7.p4.1.m1.1.1.1.cmml" xref="S5.SS7.p4.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p4.1.m1.1.1.2.cmml" xref="S5.SS7.p4.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.SS7.p4.1.m1.1.1.3.cmml" xref="S5.SS7.p4.1.m1.1.1.3">2300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p4.1.m1.1c">{\sim}{2300}</annotation></semantics></math> to <math id="S5.SS7.p4.2.m2.1" class="ltx_Math" alttext="{\sim}{2600}" display="inline"><semantics id="S5.SS7.p4.2.m2.1a"><mrow id="S5.SS7.p4.2.m2.1.1" xref="S5.SS7.p4.2.m2.1.1.cmml"><mi id="S5.SS7.p4.2.m2.1.1.2" xref="S5.SS7.p4.2.m2.1.1.2.cmml"></mi><mo id="S5.SS7.p4.2.m2.1.1.1" xref="S5.SS7.p4.2.m2.1.1.1.cmml">∼</mo><mn id="S5.SS7.p4.2.m2.1.1.3" xref="S5.SS7.p4.2.m2.1.1.3.cmml">2600</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p4.2.m2.1b"><apply id="S5.SS7.p4.2.m2.1.1.cmml" xref="S5.SS7.p4.2.m2.1.1"><csymbol cd="latexml" id="S5.SS7.p4.2.m2.1.1.1.cmml" xref="S5.SS7.p4.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p4.2.m2.1.1.2.cmml" xref="S5.SS7.p4.2.m2.1.1.2">absent</csymbol><cn type="integer" id="S5.SS7.p4.2.m2.1.1.3.cmml" xref="S5.SS7.p4.2.m2.1.1.3">2600</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p4.2.m2.1c">{\sim}{2600}</annotation></semantics></math>MB during the training, with an average of <math id="S5.SS7.p4.3.m3.1" class="ltx_Math" alttext="{\sim}{2560}" display="inline"><semantics id="S5.SS7.p4.3.m3.1a"><mrow id="S5.SS7.p4.3.m3.1.1" xref="S5.SS7.p4.3.m3.1.1.cmml"><mi id="S5.SS7.p4.3.m3.1.1.2" xref="S5.SS7.p4.3.m3.1.1.2.cmml"></mi><mo id="S5.SS7.p4.3.m3.1.1.1" xref="S5.SS7.p4.3.m3.1.1.1.cmml">∼</mo><mn id="S5.SS7.p4.3.m3.1.1.3" xref="S5.SS7.p4.3.m3.1.1.3.cmml">2560</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p4.3.m3.1b"><apply id="S5.SS7.p4.3.m3.1.1.cmml" xref="S5.SS7.p4.3.m3.1.1"><csymbol cd="latexml" id="S5.SS7.p4.3.m3.1.1.1.cmml" xref="S5.SS7.p4.3.m3.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p4.3.m3.1.1.2.cmml" xref="S5.SS7.p4.3.m3.1.1.2">absent</csymbol><cn type="integer" id="S5.SS7.p4.3.m3.1.1.3.cmml" xref="S5.SS7.p4.3.m3.1.1.3">2560</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p4.3.m3.1c">{\sim}{2560}</annotation></semantics></math>MB. There is a warm-up phase (from 0 to 10) (when the training phase begins) where the memory consumption increases by <math id="S5.SS7.p4.4.m4.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS7.p4.4.m4.1a"><mo id="S5.SS7.p4.4.m4.1.1" xref="S5.SS7.p4.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS7.p4.4.m4.1b"><csymbol cd="latexml" id="S5.SS7.p4.4.m4.1.1.cmml" xref="S5.SS7.p4.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p4.4.m4.1c">\sim</annotation></semantics></math>100MB. There is a decrease in memory consumption at 12 seconds (as it also happens with CPU utilization), resulting from one of the repetitions completing the training faster than the rest. Overall, the results show that the local training, with a mean of the CPU utilization around <math id="S5.SS7.p4.5.m5.1" class="ltx_Math" alttext="{\sim}{64}\%" display="inline"><semantics id="S5.SS7.p4.5.m5.1a"><mrow id="S5.SS7.p4.5.m5.1.1" xref="S5.SS7.p4.5.m5.1.1.cmml"><mi id="S5.SS7.p4.5.m5.1.1.2" xref="S5.SS7.p4.5.m5.1.1.2.cmml"></mi><mo id="S5.SS7.p4.5.m5.1.1.1" xref="S5.SS7.p4.5.m5.1.1.1.cmml">∼</mo><mrow id="S5.SS7.p4.5.m5.1.1.3" xref="S5.SS7.p4.5.m5.1.1.3.cmml"><mn id="S5.SS7.p4.5.m5.1.1.3.2" xref="S5.SS7.p4.5.m5.1.1.3.2.cmml">64</mn><mo id="S5.SS7.p4.5.m5.1.1.3.1" xref="S5.SS7.p4.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p4.5.m5.1b"><apply id="S5.SS7.p4.5.m5.1.1.cmml" xref="S5.SS7.p4.5.m5.1.1"><csymbol cd="latexml" id="S5.SS7.p4.5.m5.1.1.1.cmml" xref="S5.SS7.p4.5.m5.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p4.5.m5.1.1.2.cmml" xref="S5.SS7.p4.5.m5.1.1.2">absent</csymbol><apply id="S5.SS7.p4.5.m5.1.1.3.cmml" xref="S5.SS7.p4.5.m5.1.1.3"><csymbol cd="latexml" id="S5.SS7.p4.5.m5.1.1.3.1.cmml" xref="S5.SS7.p4.5.m5.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS7.p4.5.m5.1.1.3.2.cmml" xref="S5.SS7.p4.5.m5.1.1.3.2">64</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p4.5.m5.1c">{\sim}{64}\%</annotation></semantics></math> and at a maximum of <math id="S5.SS7.p4.6.m6.1" class="ltx_Math" alttext="{\sim}{85}\%" display="inline"><semantics id="S5.SS7.p4.6.m6.1a"><mrow id="S5.SS7.p4.6.m6.1.1" xref="S5.SS7.p4.6.m6.1.1.cmml"><mi id="S5.SS7.p4.6.m6.1.1.2" xref="S5.SS7.p4.6.m6.1.1.2.cmml"></mi><mo id="S5.SS7.p4.6.m6.1.1.1" xref="S5.SS7.p4.6.m6.1.1.1.cmml">∼</mo><mrow id="S5.SS7.p4.6.m6.1.1.3" xref="S5.SS7.p4.6.m6.1.1.3.cmml"><mn id="S5.SS7.p4.6.m6.1.1.3.2" xref="S5.SS7.p4.6.m6.1.1.3.2.cmml">85</mn><mo id="S5.SS7.p4.6.m6.1.1.3.1" xref="S5.SS7.p4.6.m6.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p4.6.m6.1b"><apply id="S5.SS7.p4.6.m6.1.1.cmml" xref="S5.SS7.p4.6.m6.1.1"><csymbol cd="latexml" id="S5.SS7.p4.6.m6.1.1.1.cmml" xref="S5.SS7.p4.6.m6.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p4.6.m6.1.1.2.cmml" xref="S5.SS7.p4.6.m6.1.1.2">absent</csymbol><apply id="S5.SS7.p4.6.m6.1.1.3.cmml" xref="S5.SS7.p4.6.m6.1.1.3"><csymbol cd="latexml" id="S5.SS7.p4.6.m6.1.1.3.1.cmml" xref="S5.SS7.p4.6.m6.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS7.p4.6.m6.1.1.3.2.cmml" xref="S5.SS7.p4.6.m6.1.1.3.2">85</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p4.6.m6.1c">{\sim}{85}\%</annotation></semantics></math>, occupies the device for a short time of <math id="S5.SS7.p4.7.m7.1" class="ltx_Math" alttext="{\sim}{14}" display="inline"><semantics id="S5.SS7.p4.7.m7.1a"><mrow id="S5.SS7.p4.7.m7.1.1" xref="S5.SS7.p4.7.m7.1.1.cmml"><mi id="S5.SS7.p4.7.m7.1.1.2" xref="S5.SS7.p4.7.m7.1.1.2.cmml"></mi><mo id="S5.SS7.p4.7.m7.1.1.1" xref="S5.SS7.p4.7.m7.1.1.1.cmml">∼</mo><mn id="S5.SS7.p4.7.m7.1.1.3" xref="S5.SS7.p4.7.m7.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p4.7.m7.1b"><apply id="S5.SS7.p4.7.m7.1.1.cmml" xref="S5.SS7.p4.7.m7.1.1"><csymbol cd="latexml" id="S5.SS7.p4.7.m7.1.1.1.cmml" xref="S5.SS7.p4.7.m7.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS7.p4.7.m7.1.1.2.cmml" xref="S5.SS7.p4.7.m7.1.1.2">absent</csymbol><cn type="integer" id="S5.SS7.p4.7.m7.1.1.3.cmml" xref="S5.SS7.p4.7.m7.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p4.7.m7.1c">{\sim}{14}</annotation></semantics></math> seconds thus, it does not introduce a severe overhead for the client device.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">People of all ages excessively use Online Social Networks and often are exposed to harmful content and various types of misbehavior (i.e., hate speech, cyberbullying, sarcasm, offense, etc.). Online content moderation tools provide countermeasures against such distorted content but at the same time require processing sensitive users’ data. The FL paradigm, together with Differential privacy techniques, provides a distributed and private-preserving ML training framework that complies with privacy policies (i.e., GDPR).</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">In this work, we proposed a privacy-preserving (DP) FL framework for content moderation on Twitter. This DP FL paradigm protects the users’ privacy and can be easily adapted to other social media platforms and other types of misbehavior. The experimental results – over five Twitter datasets – show that (i) for both the DP and non-DP FL variations, the text classification performance is close to the centralized approach; (ii) it has a high performance even if only a small number of clients (with small local datasets) are available for the FL training; (iii) it does not affect the performance of user’s device – in terms of CPU and memory consumption – during the FL training.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgments</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This project has been funded by the European Union’s Horizon 2020 Research and Innovation program under the Cybersecurity CONCORDIA project (Grant Agreement No. 830927) and the Marie Skłodowska–Curie AERAS project (Grant Agreement No. 872735).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. (2016)</span>
<span class="ltx_bibblock">
Abadi, M.; Chu, A.; Goodfellow, I.; McMahan, H. B.; Mironov, I.; Talwar, K.;
and Zhang, L. 2016.

</span>
<span class="ltx_bibblock">Deep Learning with Differential Privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 ACM SIGSAC Conference on Computer
and Communications Security</em>, CCS ’16, 308–318. New York, NY, USA.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alshamrani et al. (2021)</span>
<span class="ltx_bibblock">
Alshamrani, S.; Abusnaina, A.; Abuhamad, M.; Nyang, D.; and Mohaisen, D. 2021.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Hate, Obscenity, and Insults: Measuring the Exposure of
Children to Inappropriate Comments in YouTube</em>, 508–515.

</span>
<span class="ltx_bibblock">New York, NY, USA.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andrew et al. (2021)</span>
<span class="ltx_bibblock">
Andrew, G.; Thakkar, O.; McMahan, B.; and Ramaswamy, S. 2021.

</span>
<span class="ltx_bibblock">Differentially Private Learning with Adaptive Clipping.

</span>
<span class="ltx_bibblock">In Ranzato, M.; Beygelzimer, A.; Dauphin, Y.; Liang, P.; and Vaughan,
J. W., eds., <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
volume 34, 17455–17466. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chandrasekaran et al. (2022)</span>
<span class="ltx_bibblock">
Chandrasekaran, V.; Banerjee, S.; Perino, D.; and Kourtellis, N. 2022.

</span>
<span class="ltx_bibblock">Hierarchical Federated Learning with Privacy.

</span>
<span class="ltx_bibblock">Available at <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://arxiv.org/abs/2206.05209</span>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chatzakou et al. (2017)</span>
<span class="ltx_bibblock">
Chatzakou, D.; Kourtellis, N.; Blackburn, J.; De Cristofaro, E.; Stringhini,
G.; and Vakali, A. 2017.

</span>
<span class="ltx_bibblock">Mean Birds: Detecting Aggression and Bullying on Twitter.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM on Web Science Conference</em>,
WebSci ’17, 13–22. New York, NY, USA.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2019)</span>
<span class="ltx_bibblock">
Chen, M.; Mathews, R.; Ouyang, T.; and Beaufays, F. 2019.

</span>
<span class="ltx_bibblock">Federated Learning Of Out-Of-Vocabulary Words.

</span>
<span class="ltx_bibblock">Published by Google Research.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Davidson et al. (2017)</span>
<span class="ltx_bibblock">
Davidson, T.; Warmsley, D.; Macy, M. W.; and Weber, I. 2017.

</span>
<span class="ltx_bibblock">Automated Hate Speech Detection and the Problem of Offensive
Language.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on Web
and Social Media, ICWSM 2017, Montréal, Québec, Canada, May
15-18, 2017</em>, 512–515. AAAI Press.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al. (2006)</span>
<span class="ltx_bibblock">
Dwork, C.; Kenthapadi, K.; McSherry, F.; Mironov, I.; and Naor, M. 2006.

</span>
<span class="ltx_bibblock">Our Data, Ourselves: Privacy Via Distributed Noise Generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in Cryptology (EUROCRYPT 2006)</em>, volume 4004 of
<em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, 486–503.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork and Roth (2014)</span>
<span class="ltx_bibblock">
Dwork, C.; and Roth, A. 2014.

</span>
<span class="ltx_bibblock">The Algorithmic Foundations of Differential Privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Found. Trends Theor. Comput. Sci.</em>, 9(3–4): 211–407.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Founta et al. (2018)</span>
<span class="ltx_bibblock">
Founta, A.; Djouvas, C.; Chatzakou, D.; Leontiadis, I.; Blackburn, J.;
Stringhini, G.; Vakali, A.; Sirivianos, M.; and Kourtellis, N. 2018.

</span>
<span class="ltx_bibblock">Large Scale Crowdsourcing and Characterization of Twitter Abusive
Behavior.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International AAAI Conference on Web and
Social Media</em>, 12(1).

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Founta et al. (2019)</span>
<span class="ltx_bibblock">
Founta, A. M.; Chatzakou, D.; Kourtellis, N.; Blackburn, J.; Vakali, A.; and
Leontiadis, I. 2019.

</span>
<span class="ltx_bibblock">A Unified Deep Learning Architecture for Abuse Detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th ACM Conference on Web Science</em>,
WebSci ’19, 105–114. New York, NY, USA.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. (2018)</span>
<span class="ltx_bibblock">
Hard, A.; Rao, K.; Mathews, R.; Ramaswamy, S.; Beaufays, F.; Augenstein, S.;
Eichner, H.; Kiddon, C.; and Ramage, D. 2018.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kenneally and Dittrich (2012)</span>
<span class="ltx_bibblock">
Kenneally, E.; and Dittrich, D. 2012.

</span>
<span class="ltx_bibblock">The menlo report: Ethical principles guiding information and
communication technology research.

</span>
<span class="ltx_bibblock">Available at SSRN 2445102.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
McMahan, B.; Moore, E.; Ramage, D.; Hampson, S.; and y Arcas, B. A. 2017.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from Decentralized
Data.

</span>
<span class="ltx_bibblock">In Singh, A.; and Zhu, X. J., eds., <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th
International Conference on Artificial Intelligence and Statistics, AISTATS
2017, 20-22 April 2017, Fort Lauderdale, FL, USA</em>, volume 54 of
<em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, 1273–1282. PMLR.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2018)</span>
<span class="ltx_bibblock">
McMahan, H. B.; Ramage, D.; Talwar, K.; and Zhang, L. 2018.

</span>
<span class="ltx_bibblock">Learning Differentially Private Recurrent Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">6th International Conference on Learning Representations,
ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
Proceedings</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naseri, Hayes, and De Cristofaro (2022)</span>
<span class="ltx_bibblock">
Naseri, M.; Hayes, J.; and De Cristofaro, E. 2022.

</span>
<span class="ltx_bibblock">Local and Central Differential Privacy for Robustness and Privacy in
Federated Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th Network and Distributed System
Security Symposium (NDSS 2022)</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papadamou et al. (2020)</span>
<span class="ltx_bibblock">
Papadamou, K.; Papasavva, A.; Zannettou, S.; Blackburn, J.; Kourtellis, N.;
Leontiadis, I.; Stringhini, G.; and Sirivianos, M. 2020.

</span>
<span class="ltx_bibblock">Disturbed YouTube for Kids: Characterizing and Detecting
Inappropriate Videos Targeting Young Children.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International AAAI Conference on Web and
Social Media</em>, 14(1): 522–533.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papadamou et al. (2022)</span>
<span class="ltx_bibblock">
Papadamou, K.; Zannettou, S.; Blackburn, J.; Cristofaro, E. D.; Stringhini, G.;
and Sirivianos, M. 2022.

</span>
<span class="ltx_bibblock">“It Is Just a Flu”: Assessing the Effect of Watch History on
YouTube’s Pseudoscientific Video Recommendations.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International AAAI Conference on Web and
Social Media</em>, 16(1): 723–734.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pennington, Socher, and Manning (2014)</span>
<span class="ltx_bibblock">
Pennington, J.; Socher, R.; and Manning, C. D. 2014.

</span>
<span class="ltx_bibblock">GloVe: Global Vectors for Word Representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Empirical Methods in Natural Language Processing (EMNLP)</em>,
1532–1543.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajadesingan, Zafarani, and Liu (2015)</span>
<span class="ltx_bibblock">
Rajadesingan, A.; Zafarani, R.; and Liu, H. 2015.

</span>
<span class="ltx_bibblock">Sarcasm Detection on Twitter: A Behavioral Modeling Approach.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth ACM International Conference on
Web Search and Data Mining</em>, WSDM ’15, 97–106. New York, NY, USA.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tahir et al. (2019)</span>
<span class="ltx_bibblock">
Tahir, R.; Ahmed, F.; Saeed, H.; Ali, S.; Zaffar, F.; and Wilson, C. 2019.

</span>
<span class="ltx_bibblock">Bringing the Kid Back into YouTube Kids: Detecting Inappropriate
Content on Video Streaming Platforms.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 IEEE/ACM International Conference on
Advances in Social Networks Analysis and Mining</em>, ASONAM ’19, 464–469. New
York, NY, USA.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truex et al. (2020)</span>
<span class="ltx_bibblock">
Truex, S.; Liu, L.; Chow, K.-H.; Gursoy, M. E.; and Wei, W. 2020.

</span>
<span class="ltx_bibblock">LDP-Fed: Federated Learning with Local Differential Privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third ACM International Workshop on Edge
Systems, Analytics and Networking</em>, EdgeSys ’20, 61–66. New York, NY, USA.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang, Balle, and Kasiviswanathan (2019)</span>
<span class="ltx_bibblock">
Wang, Y.-X.; Balle, B.; and Kasiviswanathan, S. P. 2019.

</span>
<span class="ltx_bibblock">Subsampled Renyi Differential Privacy and Analytical Moments
Accountant.

</span>
<span class="ltx_bibblock">In Chaudhuri, K.; and Sugiyama, M., eds., <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Twenty-Second International Conference on Artificial Intelligence and
Statistics</em>, volume 89 of <em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>,
1226–1235.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waseem and Hovy (2016)</span>
<span class="ltx_bibblock">
Waseem, Z.; and Hovy, D. 2016.

</span>
<span class="ltx_bibblock">Hateful Symbols or Hateful People? Predictive Features for Hate
Speech Detection on Twitter.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the NAACL Student Research Workshop</em>,
88–93. San Diego, California: Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. (2021)</span>
<span class="ltx_bibblock">
Yan, B.; Wang, J.; Cheng, J.; Zhou, Y.; Zhang, Y.; Yang, Y.; Liu, L.; Zhao, H.;
Wang, C.; and Liu, B. 2021.

</span>
<span class="ltx_bibblock">Experiments of Federated Learning for COVID-19 Chest X-ray Images.

</span>
<span class="ltx_bibblock">In Sun, X.; Zhang, X.; Xia, Z.; and Bertino, E., eds., <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Advances
in Artificial Intelligence and Security</em>, 41–53. Cham: Springer
International Publishing.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2018)</span>
<span class="ltx_bibblock">
Yang, T.; Andrew, G.; Eichner, H.; Sun, H.; Li, W.; Kong, N.; Ramage, D.; and
Beaufays, F. 2018.

</span>
<span class="ltx_bibblock">Applied Federated Learning: Improving Google Keyboard Query
Suggestions.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yenala et al. (2018)</span>
<span class="ltx_bibblock">
Yenala, H.; Jhanwar, A.; Chinnakotla, M. K.; and Goyal, J. 2018.

</span>
<span class="ltx_bibblock">Deep learning for detecting inappropriate content in text.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Journal of Data Science and Analytics</em>, 6(4):
273–286.

</span>
</li>
</ul>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work followed the principles and guidelines on executing ethical information research and using shared data <cite class="ltx_cite ltx_citemacro_citep">(Kenneally and Dittrich <a href="#bib.bib13" title="" class="ltx_ref">2012</a>)</cite>. The suggested methodology complies with the GDPR and ePrivacy regulations. We have not collected data from Twitter. We use existing Twitter datasets – that have already been published by other academic studies by requesting access from their publishers. For this reason, we will not publicly release any dataset used in this study. We did not use or present any identifiable user information from the datasets (e.g., Twitter user IDs). We applied text preprocessing in order to clean the tweets from any information that could identify specific Twitter accounts (see Section <a href="#S5.SS3" title="5.3 Datasets ‣ 5 Experimental Evaluation ‣ Privacy–Preserving Online Content Moderation: A Federated Learning Use Case" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>). Hence, the train data of the text classifier did not contain Twitter usernames. Finally, we implemented and executed the experiments locally – on our devices – without using any cloud computation services, so we did not upload any of the datasets to the cloud.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2209.11842" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2209.11843" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2209.11843">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2209.11843" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2209.11845" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 20:56:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
