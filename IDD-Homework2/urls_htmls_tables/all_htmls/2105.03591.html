<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2105.03591] Loss Tolerant Federated Learning</title><meta property="og:description" content="Federated learning has attracted attention in recent years for collaboratively training data on distributed devices with privacy-preservation. The limited network capacity of mobile and IoT devices has been seen as one…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Loss Tolerant Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Loss Tolerant Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2105.03591">

<!--Generated on Thu Mar  7 00:49:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Loss Tolerant Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Pengyuan Zhou<sup id="id7.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pei Fang<sup id="id8.6.id1" class="ltx_sup">2</sup>&amp;Pan Hui<sup id="id9.7.id2" class="ltx_sup"><span id="id9.7.id2.1" class="ltx_text ltx_font_italic">1,3</span></sup>
<br class="ltx_break"><sup id="id10.8.id3" class="ltx_sup">1</sup>University of Helsinki
<br class="ltx_break"><sup id="id11.9.id4" class="ltx_sup">2</sup>Tongji University
<br class="ltx_break"><sup id="id12.10.id5" class="ltx_sup">3</sup>Hong Kong University of Science and Technology
<br class="ltx_break">pengyuan.zhou@helsinki.fi,
greilfang@gmail.com,
pan.hui@helsinki.fi
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">Federated learning has attracted attention in recent years for collaboratively training data on distributed devices with privacy-preservation. The limited network capacity of mobile and IoT devices has been seen as one of the major challenges for cross-device federated learning. Recent solutions have been focusing on threshold-based client selection schemes to guarantee the communication efficiency. However, we find this approach can cause biased client selection and results in deteriorated performance. Moreover, we find that the challenge of network limit may be overstated in some cases and the packet loss is not always harmful.</p>
<p id="id14.id2" class="ltx_p">In this paper, we explore the loss tolerant federated learning (LT-FL) in terms of aggregation, fairness, and personalization. We use ThrowRightAway (TRA) to accelerate the data uploading for low-bandwidth-devices by intentionally ignoring some packet losses. The results suggest that, with proper integration, TRA and other algorithms can together guarantee the personalization and fairness performance in the face of packet loss below a certain fraction (10%–30%).</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the popularization of the mobile and wearable devices, smart activity learning applications have been prominently used by consumers and in turn generate more user data.
Despite the potential to act as effective data sources for machine learning tasks, the training of machine learning models for mobile and wearable applications usually demands data far more than each individual device collects. Currently, aggregating user data in the cloud for big data analysis is the de facto solution. However, privacy concerns have spawned a series of policies that limit data collection and storage only to consumer-consented and absolutely necessary usage <cite class="ltx_cite ltx_citemacro_cite">Lim <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>. For example, most data collected from mobiles and wearables are subject to data protection regulations such as European Commission’s General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">Custers <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> and Consumer Privacy Act (CCPA) in USA <cite class="ltx_cite ltx_citemacro_cite">CCPA (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>. Such regulations make it harder to aggregate user data for large scale data analysis.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In face of the above challenge, federated learning rises as a new distributed paradigm where multiple clients collaboratively train a model without revealing private data. Based on whether the clients are different organization or a large number of mobile IoT devices, federated learning is divided into cross-silo and cross-device, Mobile and wearable devices as the major participants, cross-device federated learning faces challenges from stateless and unreliable clients. Moreover, communication seems to be another bottleneck as the operations of cross-device federated learning systems largely rely on Wi-fi <cite class="ltx_cite ltx_citemacro_cite">Bonawitz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite> or slower communication networks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">With the concern on improving the communication efficiency, most of the recent works propose or assume a threshold to select clients with sufficient network capacities. However, such proposals inevitably cause data shifts during client selection. Although very recently researchers have proposed fairness schemes specifically for federated learning aggregation, data shift occurring at the beginning of client selection has been overlooked.
Consequently, the performance of federated learning is impacted.
</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we reexamine the network limit challenge and the threshold-based approach to answer the following questions:

<span id="S1.I1" class="ltx_inline-enumerate">
<span id="S1.I1.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">1.</span> <span id="S1.I1.i1.1" class="ltx_text">Is the challenge overstated?
</span></span>
<span id="S1.I1.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">2.</span> <span id="S1.I1.i2.1" class="ltx_text">What is the drawback of threshold-based client selection approach?
</span></span>
<span id="S1.I1.i3" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">3.</span> <span id="S1.I1.i3.1" class="ltx_text">Are there better alternative solutions?
</span></span>
</span>
Concretely, we make the following contributions in this work:</p>
<ol id="S1.I2" class="ltx_enumerate">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p"><span id="S1.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">Bottlenecks.</span> We conduct a trace-driven analysis and learn that the network limit challenge may be overstated in some aspects. Meanwhile, we identify an overlooked bias potentially caused by threshold-based client selection. We further analyze its impact on the performances of the state-of-the-art algorithms in the fields of aggregation, fairness and personalization (<a href="#S3" title="3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p"><span id="S1.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">Loss tolerance.</span> We explore the loss tolerant federated learning (LT-FL) by using ThrowRightAway (TRA) to ignore some of the lost packets on purpose. As its name indicates, TRA “throws” away lost packets to accelerate the uploading of low-bandwidth-devices thus enable fully fair selection to all the clients, while avoiding straggling impact caused by retransmissions. For specific algorithms, TRA tweaks the aggregation algorithm to compensate for the lost information (<a href="#S4" title="4 ThrowRightAway ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p"><span id="S1.I2.i3.p1.1.1" class="ltx_text ltx_font_italic">Applicability.</span> We apply TRA to aggregation, personalization, and fairness, by respectively integrating it with the state-of-the-art algorithms in each subfield. The empirical evaluation results show that TRA improves the performance of the paired algorithms in threshold-based client selection settings. We implement the combinatorial algorithms based on the state-of-the-art codebases and open source here <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/Greilfang/Loss-Tolerant-Federated-Learning" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Greilfang/Loss-Tolerant-Federated-Learning</a></span></span></span>.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Motivation</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we describe the background and drawback of threshold-based client selection scheme and state the motivations of this work.
</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Fair Client Selection</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">As noted by Bonawitz et al. <cite class="ltx_cite ltx_citemacro_cite">Bonawitz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>, the FedAvg <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite> model aggregation protocol’s assumption about equitable participation of all devices is not the case in practice. Consequently, fairness <cite class="ltx_cite ltx_citemacro_cite">Barocas <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib1" title="" class="ltx_ref">2017</a>); <a href="#bib.bib11" title="" class="ltx_ref">Fang <span class="ltx_text ltx_font_italic">et al.</span> </a>; Lyu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite> is impacted and results in bias. For instance, to avoid packet error and client drop (<a href="#S2.F1" title="In 2.1 Fair Client Selection ‣ 2 Background and Motivation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>), cross-device federated learning systems commonly use transmission speed and battery status as criteria for mobile client selection.
In such cases, the clients with more packet errors and drops are unlikely be taken into model aggregation. Even worse, <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">users consistently having worse networking conditions may never be represented in training which leads to a biased model.</span> The aggregation approaches with only model weights taken into account have been proved unable to tackle such challenges <cite class="ltx_cite ltx_citemacro_cite">Karimireddy <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>); Lin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Here we summarize common factors for bias in federated learning as: (1) <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">over-represented</span>, (2) <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">under-represented</span>, (3) <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_bold ltx_font_italic">never-represented</span>.
(1) and (2) have been partly solved with approaches targeting training procedure bias such as AFL <cite class="ltx_cite ltx_citemacro_cite">Mohri <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite> and q-FedAvg <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>. AFL minimizes the maximum loss incurred on the worst-performing devices as a classical minimax problem. q-FedAvg generalizes AFL by allowing for a flexible trade-off between fairness and accuracy. Although these approaches promote accuracy equity among participaed devices through the mitigation of training procedure bias, still they can not solve bias caused by unfair client selection in (3), as also noted by the authors of AFL.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2105.03591/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="165" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Threshold-based schemes select clients with better network conditions, e.g., higher speed/bandwidth, to avoid packet loss and stragglers during aggregation.</span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Inspirations</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">There have been recent works focusing on different techniques suggesting intentionally “losing” some information to avoid latency for better communication efficiency, and ease the gap between demanded and actual network capacities. For instance, some related works have proposed to use lossy compression to reduce the transferred data volume. The authors in <cite class="ltx_cite ltx_citemacro_cite">Konečnỳ <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2016</a>); Dong <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite> perform lossy compression on the model updates using both structured and sketched updates. The main idea is to learn from a restricted space or upload a compressed model. Authors in <cite class="ltx_cite ltx_citemacro_cite">Caldas <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite> focus on the server-to-client communication and similarly applies a lossy compression scheme with less frequent updates. The authors in <cite class="ltx_cite ltx_citemacro_cite">Xia <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> tapped into the loss tolerance potential in distributed machine learning, which show its bounded loss tolerance of via evaluations. These works inspire us to explore the network data loss tolerance of cross-device federated learning. The differences between our work and aforementioned works are twofold: 
<span id="S2.I1" class="ltx_inline-enumerate">
<span id="S2.I1.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">1.</span> <span id="S2.I1.i1.1" class="ltx_text">We propose a loss-tolerant scheme not only to address communication efficiency, but also to guarantee fairness during client selection.
</span></span>
<span id="S2.I1.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">2.</span> <span id="S2.I1.i2.1" class="ltx_text">We look deeper into the potential of a loss-tolerant scheme by integrating it into two state-of-the-art fairness algorithms regarding fairness and personalization respectively and show performance improvements in different aspects.
</span></span>
</span></p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<svg id="S2.SS2.p2.pic1" class="ltx_picture" height="84.34" overflow="visible" version="1.1" width="600"><g transform="translate(0,84.34) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.94 L 0 82.4 C 0 83.47 0.87 84.34 1.94 84.34 L 598.06 84.34 C 599.13 84.34 600 83.47 600 82.4 L 600 1.94 C 600 0.87 599.13 0 598.06 0 L 1.94 0 C 0.87 0 0 0.87 0 1.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.55 1.94 L 0.55 82.4 C 0.55 83.16 1.17 83.78 1.94 83.78 L 598.06 83.78 C 598.83 83.78 599.45 83.16 599.45 82.4 L 599.45 1.94 C 599.45 1.17 598.83 0.55 598.06 0.55 L 1.94 0.55 C 1.17 0.55 0.55 1.17 0.55 1.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 4.7 4.7)"><foreignObject width="590.59" height="74.93" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S2.SS2.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:426.8pt;">
<span id="S2.SS2.p2.pic1.1.1.1.1.1.1" class="ltx_p"><span id="S2.SS2.p2.pic1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">Note:</span> The network threshold for selection can be bandwidth, transmission speed, or packet loss, or their hybrids. In this work we use TRA to convey different network constraints to general packet loss. Specifically, TRA intentionally drops lost packets in avoidance of re-transmission to allow a client with slower network to upload local models within a jointly-decided period with other clients.</span>
</span></foreignObject></g></g></svg>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem Study</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we analyze the problems mentioned in <a href="#S2" title="2 Background and Motivation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2</span></a> in detail. First we learn the disparate networking conditions by analyzing a real-world dataset and discover its biased impact on client selection. Then we show how the state-of-the-art approaches regarding fairness and personalization for federated learning suffer from the data shift due to the biased selection.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Mobile Network Conditions</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.4" class="ltx_p">We use a mobile broadband dataset provide by FCC <cite class="ltx_cite ltx_citemacro_cite">Commission (<a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> to study the mobile network conditions of users. We select data from the “Download speed and upload speed” category in 2019 Q1 &amp; Q2 collection. The data is measured via Android and iOS applications installed in the user phones. It contains uploading traces from thousands of volunteered participants, recording the average received packets, lost packets and throughput. Note that the throughput was collected as the sum of speeds during saturated streams, hence it can represent the max speed. We calculate the packet loss by dividing the lost packets by the sum of received and lost packets. After processing the trace according to unique identifiers, the cumulative distributions of the average packet loss ratio and upload speed are shown in <a href="#S3.F2" title="In 3.1 Mobile Network Conditions ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>. It shows that 90% of the users have packet loss ratio <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="&lt;0.1" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml"></mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><lt id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">absent</csymbol><cn type="float" id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">&lt;0.1</annotation></semantics></math> and 76% of the users have upload speed <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="&gt;2" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml"></mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">&gt;</mo><mn id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><gt id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">absent</csymbol><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">&gt;2</annotation></semantics></math> Mbps. Therefore the majority of the users have sufficient network capacities required by common federated learning systems. However, the upload speeds vary tremendously across users. For instance, 24% of the users have upload speed <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="&lt;2" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml"></mi><mo id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">&lt;</mo><mn id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><lt id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></lt><csymbol cd="latexml" id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">absent</csymbol><cn type="integer" id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">&lt;2</annotation></semantics></math> Mbps while 51% of the users have upload speed <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="&gt;8" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml"></mi><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">&gt;</mo><mn id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><gt id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></gt><csymbol cd="latexml" id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">absent</csymbol><cn type="integer" id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">&gt;8</annotation></semantics></math> Mbps.
Transmission speed is an important metric during client selection and has been adopted by both industrial and academic works <cite class="ltx_cite ltx_citemacro_cite">Nishio and Yonetani (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>); Openmined (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>. For instance, Openmined sets 2 Mbps as the default upload speed threshold for client selection. As we found out from the data analysis, a considerable part of users may fail to meet the network threshold thus would be <span id="S3.SS1.p1.4.1" class="ltx_text ltx_font_italic">never-represented</span> in the model aggregation and thus being excluded by the system.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<svg id="S3.SS1.p2.pic1" class="ltx_picture" height="54.92" overflow="visible" version="1.1" width="600"><g transform="translate(0,54.92) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.94 L 0 52.98 C 0 54.05 0.87 54.92 1.94 54.92 L 598.06 54.92 C 599.13 54.92 600 54.05 600 52.98 L 600 1.94 C 600 0.87 599.13 0 598.06 0 L 1.94 0 C 0.87 0 0 0.87 0 1.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.55 1.94 L 0.55 52.98 C 0.55 53.74 1.17 54.36 1.94 54.36 L 598.06 54.36 C 598.83 54.36 599.45 53.74 599.45 52.98 L 599.45 1.94 C 599.45 1.17 598.83 0.55 598.06 0.55 L 1.94 0.55 C 1.17 0.55 0.55 1.17 0.55 1.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 4.7 4.7)"><foreignObject width="590.59" height="45.51" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.SS1.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:426.8pt;">
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1" class="ltx_p"><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">Takeaway</span>: The trace-driven analysis shows that the network conditions of most mobile clients are not so “limited” and “challenging” as most related works assumed. However, the tremendously varied upload speeds may indeed cause biased client selection in threshold-based settings.</span>
</span></foreignObject></g></g></svg>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2105.03591/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="184" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Network conditions analysis.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Impacts</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Following the takeaway in <a href="#S3.SS1" title="3.1 Mobile Network Conditions ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>, we investigate the impact of biased selection led by threshold-based settings. We define the essential terms in our investigated problem as follows.</p>
</div>
<div id="Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition 1</span></span><span id="Thmdefinition1.2.2" class="ltx_text ltx_font_bold"> </span>(<span id="Thmdefinition1.3.3" class="ltx_text ltx_font_bold ltx_font_italic">Eligible client</span>)<span id="Thmdefinition1.4.4" class="ltx_text ltx_font_bold">.</span>
</h6>
<div id="Thmdefinition1.p1" class="ltx_para">
<p id="Thmdefinition1.p1.1" class="ltx_p">An eligible client is one that meets the required network threshold to participate in federated learning aggregation.</p>
</div>
</div>
<div id="Thmdefinition2" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition2.1.1.1" class="ltx_text ltx_font_bold">Definition 2</span></span><span id="Thmdefinition2.2.2" class="ltx_text ltx_font_bold"> </span>(<span id="Thmdefinition2.3.3" class="ltx_text ltx_font_bold ltx_font_italic">Eligible ratio</span>)<span id="Thmdefinition2.4.4" class="ltx_text ltx_font_bold">.</span>
</h6>
<div id="Thmdefinition2.p1" class="ltx_para">
<p id="Thmdefinition2.p1.1" class="ltx_p">Eligible ratio is the proportion of the eligible clients out of all the clients.</p>
</div>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.4" class="ltx_p">In threshold-based settings, only the eligible clients within the eligible ratio may be selected for aggregation. As some users have lower network capacities than the threshold (<a href="#S3.F2" title="In 3.1 Mobile Network Conditions ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>), the system only can choose eligible clients for aggregation and generate bias and result in models with discrimination.
For the completeness of the work, we adjust the eligible ratios between 100%, 90%, 80%, and 70% in the evaluation of the paper. More specifically, we investigate the impacts on aggregation, fairness, and personalization, respectively. In the rest of the evaluation, we use the synthetic datasets generated following the process described in the experiment detail of q-FedAvg, where <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\alpha</annotation></semantics></math> and <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\beta</annotation></semantics></math> allow the precise manipulation of the degree of heterogeneity. Increasing the values of <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\alpha</annotation></semantics></math> and <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\beta</annotation></semantics></math> result in higher statistical heterogeneity. We use the same datasets for both bottleneck analysis and evaluation for consistency.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Aggregation</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">First we examine the impact of biased selection on aggregation. We target at the prevailing and common FedAvg, which evenly averages the selected clients’ models. As <a href="#S3.F3" title="In Aggregation ‣ 3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a> shows, smaller eligible ratios have higher impacts on the model performance. The final model accuracy of FedAvg with eligible ratios of 100%, 90%, 80%, and 70%, are 83.52%, 75.60%, 64.10%, and 62.60%. For the users in <a href="#S3.F2" title="In 3.1 Mobile Network Conditions ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, the model accuracy would decrease around 10% if using 2 Mbps as the selection threshold.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2105.03591/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="230" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Impact of biased selection on aggregation (FedAvg). The dataset is Synthetic(0.5,0.5).</span></figcaption>
</figure>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Impact of biased client selection on fairness (q-FedAvg). Threshold (TH) indicates whether considering the 70% eligible ratio. Best/Worst 10% indicate the top 10% best/worst accuracies. </span></figcaption>
<div id="S3.T1.4" class="ltx_inline-block ltx_transformed_outer" style="width:251.0pt;height:113.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-13.9pt,6.3pt) scale(0.9,0.9) ;">
<table id="S3.T1.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.4.1.1.1" class="ltx_tr">
<th id="S3.T1.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S3.T1.4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.4.1.1.1.2.1" class="ltx_text ltx_font_bold">TH</span></th>
<th id="S3.T1.4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.4.1.1.1.3.1" class="ltx_text ltx_font_bold">Average</span></th>
<th id="S3.T1.4.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.4.1.1.1.4.1" class="ltx_text ltx_font_bold">Best/Worst 10%</span></th>
<th id="S3.T1.4.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.4.1.1.1.5.1" class="ltx_text ltx_font_bold">Variance</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.4.1.2.1" class="ltx_tr">
<td id="S3.T1.4.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.4.1.2.1.1.1" class="ltx_text">
<span id="S3.T1.4.1.2.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.4.1.2.1.1.1.1.1" class="ltx_tr">
<span id="S3.T1.4.1.2.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.4.1.2.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Synthetic</span></span></span>
<span id="S3.T1.4.1.2.1.1.1.1.2" class="ltx_tr">
<span id="S3.T1.4.1.2.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.4.1.2.1.1.1.1.2.1.1" class="ltx_text ltx_font_bold">(i.i.d)</span></span></span>
</span></span></td>
<td id="S3.T1.4.1.2.1.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T1.4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">72.47%</td>
<td id="S3.T1.4.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">91.85% / 43.19%</td>
<td id="S3.T1.4.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">179</td>
</tr>
<tr id="S3.T1.4.1.3.2" class="ltx_tr">
<td id="S3.T1.4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T1.4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t">68.67%</td>
<td id="S3.T1.4.1.3.2.3" class="ltx_td ltx_align_left ltx_border_t">94.25% / 36.30%</td>
<td id="S3.T1.4.1.3.2.4" class="ltx_td ltx_align_left ltx_border_t">245</td>
</tr>
<tr id="S3.T1.4.1.4.3" class="ltx_tr">
<td id="S3.T1.4.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.4.1.4.3.1.1" class="ltx_text">
<span id="S3.T1.4.1.4.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.4.1.4.3.1.1.1.1" class="ltx_tr">
<span id="S3.T1.4.1.4.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.4.1.4.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Synthetic</span></span></span>
<span id="S3.T1.4.1.4.3.1.1.1.2" class="ltx_tr">
<span id="S3.T1.4.1.4.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(<span id="S3.T1.4.1.4.3.1.1.1.2.1.1" class="ltx_text ltx_font_bold">0.5,0.5</span>)</span></span>
</span></span></td>
<td id="S3.T1.4.1.4.3.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T1.4.1.4.3.3" class="ltx_td ltx_align_left ltx_border_t">66.21%</td>
<td id="S3.T1.4.1.4.3.4" class="ltx_td ltx_align_left ltx_border_t">98.30% / 22.51%</td>
<td id="S3.T1.4.1.4.3.5" class="ltx_td ltx_align_left ltx_border_t">536</td>
</tr>
<tr id="S3.T1.4.1.5.4" class="ltx_tr">
<td id="S3.T1.4.1.5.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T1.4.1.5.4.2" class="ltx_td ltx_align_left ltx_border_t">52.81%</td>
<td id="S3.T1.4.1.5.4.3" class="ltx_td ltx_align_left ltx_border_t">99.79% / 0</td>
<td id="S3.T1.4.1.5.4.4" class="ltx_td ltx_align_left ltx_border_t">1350</td>
</tr>
<tr id="S3.T1.4.1.6.5" class="ltx_tr">
<td id="S3.T1.4.1.6.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.4.1.6.5.1.1" class="ltx_text">
<span id="S3.T1.4.1.6.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.4.1.6.5.1.1.1.1" class="ltx_tr">
<span id="S3.T1.4.1.6.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.4.1.6.5.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Synthetic</span></span></span>
<span id="S3.T1.4.1.6.5.1.1.1.2" class="ltx_tr">
<span id="S3.T1.4.1.6.5.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(<span id="S3.T1.4.1.6.5.1.1.1.2.1.1" class="ltx_text ltx_font_bold">1,1)</span></span></span>
</span></span></td>
<td id="S3.T1.4.1.6.5.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T1.4.1.6.5.3" class="ltx_td ltx_align_left ltx_border_t">64.17%</td>
<td id="S3.T1.4.1.6.5.4" class="ltx_td ltx_align_left ltx_border_t">100% / 7.67%</td>
<td id="S3.T1.4.1.6.5.5" class="ltx_td ltx_align_left ltx_border_t">937</td>
</tr>
<tr id="S3.T1.4.1.7.6" class="ltx_tr">
<td id="S3.T1.4.1.7.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✓</td>
<td id="S3.T1.4.1.7.6.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">55.24%</td>
<td id="S3.T1.4.1.7.6.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">100% / 0</td>
<td id="S3.T1.4.1.7.6.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">1439</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Fairness</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">As noted in <a href="#S2.SS1" title="2.1 Fair Client Selection ‣ 2 Background and Motivation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2.1</span></a>, existing schemes improve fairness for <span id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">over-represented</span> and <span id="S3.SS2.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">under-represented</span> clients, but fail to serve the <span id="S3.SS2.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_italic">never-represented</span> clients. To validate this argument, we reproduce the evaluations of q-FedAvg using the code and default hyperparameters provided by the authors of q-FedAvg.
We use a 70% eligible ratio to get the bottleneck performance.
We adjust the distribution of training sample data on each device (from i.i.d data to non-i.i.d data) to comprehensively test the degradation of both accuracy and fairness performance caused by biased client selection.
<a href="#S3.T1" title="In Aggregation ‣ 3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> shows that the performances of q-FedAvg are impacted due to biased selection with both i.i.d and non-i.i.d data distributions. Non.i.i.d data presents larger performance degradation than i.i.d data in terms of both accuracy and fairness.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Personalization</h4>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">Existing approaches either trai n a new deep neural network (transfer learning) <cite class="ltx_cite ltx_citemacro_cite">Chen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>, with loss function measuring the heterogeneity for local and global models, other than the one for the task. In resource-intensive cases, transfer learning reduces the model size so that a device can simultaneously hold two transferable models, but its advantage over a single larger model requires further explorations.
Per-FedAvg <cite class="ltx_cite ltx_citemacro_cite">Fallah <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> looks for an initial shared model that clients can easily adapt via a few gradient descents with respect to their own data.
pFedMe <cite class="ltx_cite ltx_citemacro_cite">Dinh <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> adds constraints into the loss function of global training and shows outperformance of Per-FedAvg.
Therefore, we use pFedMe as the target to examine the impact of biased selection on personalization performance.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2105.03591/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="230" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.4.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.5.2" class="ltx_text" style="font-size:90%;">The impact of biased client selection on personalized and global performance of pFedMe. Label <span id="S3.F4.5.2.1" class="ltx_text ltx_font_bold">p</span> refers to the average local accuracy after personalization while <span id="S3.F4.5.2.2" class="ltx_text ltx_font_bold">G</span> refers to the global accuracy. The dataset is Synthetic(0.5,0.5). We use the fine-tuned hyperparameters of Table. 1 in the paper of pFedMe.</span></figcaption>
</figure>
<div id="S3.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p2.1" class="ltx_p">As shown in <a href="#S3.F4" title="In Personalization ‣ 3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, pFedMe shows resilient performance in its personalized model. However, the performance of the global model presents considerable degradation in lower eligible ratios.
We note that pFedMe achieves robustness on personalized model performance via more computation and power cost. Unlike most approaches selecting clients before local training, pFedMe let all clients do local training and then select some to upload. As such, its performance of personalized model is less depending on the convergence of the global model, while costing more computation and power of the client devices as a trade-off. For example, applying an eligible ratio to Per-FedAvg gets degraded performance as shown in <a href="#S3.F5" title="In Personalization ‣ 3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p3" class="ltx_para ltx_noindent">
<svg id="S3.SS2.SSS0.Px3.p3.pic1" class="ltx_picture" height="54.92" overflow="visible" version="1.1" width="600"><g transform="translate(0,54.92) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.94 L 0 52.98 C 0 54.05 0.87 54.92 1.94 54.92 L 598.06 54.92 C 599.13 54.92 600 54.05 600 52.98 L 600 1.94 C 600 0.87 599.13 0 598.06 0 L 1.94 0 C 0.87 0 0 0.87 0 1.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.55 1.94 L 0.55 52.98 C 0.55 53.74 1.17 54.36 1.94 54.36 L 598.06 54.36 C 598.83 54.36 599.45 53.74 599.45 52.98 L 599.45 1.94 C 599.45 1.17 598.83 0.55 598.06 0.55 L 1.94 0.55 C 1.17 0.55 0.55 1.17 0.55 1.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 4.7 4.7)"><foreignObject width="590.59" height="45.51" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.SS2.SSS0.Px3.p3.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:426.8pt;">
<span id="S3.SS2.SSS0.Px3.p3.pic1.1.1.1.1.1.1" class="ltx_p"><span id="S3.SS2.SSS0.Px3.p3.pic1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">Takeaway</span>: The biased client selection caused by threshold-based selection can severely deteriorate the performance of aggregation, personalization, and fairness in the context of federated learning. Therefore, an alternative loss-tolerant selection scheme allowing fair participation is demanded.</span>
</span></foreignObject></g></g></svg>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2105.03591/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="230" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.3.2" class="ltx_text" style="font-size:90%;">The impact of biased client selection on Per-Fedavg. The dataset is Synthetic(0.5,0.5). We use the hyperparameters of Table. 1 in the paper of pFedMe.</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>ThrowRightAway</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we propose an alternative scheme to threshold-based schemes, to tackle the performance degradation caused by biased selection.
</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2105.03591/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="153" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">TRA allows clients participate in the aggregation regardless of network conditions..</span></figcaption>
</figure>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">Xia <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> have recently demonstrated that in contrary to common sense, data loss to an extent is not necessarily harmful in distributed learning systems. Through empirical evaluations, they discover that machine learning algorithms tolerate bounded data loss (10%–35% in their tests).
Inspired by the work, we propose to explore the loss tolerance in cross-device federated learning systems. We propose ThrowRightAway (TRA) scheme, i.e., the server accepts all clients as eligible participants even if some selected clients may have worse network capacities than requirement and undesired packet loss ratio during updates uploading (<a href="#S4.F6" title="In 4 ThrowRightAway ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">6</span></a>). TRA is super lightweight and easy to implement. It can be integrated into different kinds of federated learning algorithms to augment their performances. <a href="#alg1" title="In 4 ThrowRightAway ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span> <span class="ltx_text ltx_ref_tag">1</span></a> shows the skeleton of the integration of TRA and general federated learning algorithms.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2105.03591/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="80" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Sample based aggregations performance of biased FedAvg, q-FedAvg, and TRA-q-FedAvg on Synthetic(1,1) and Synthetic(2,2) datasets with 70%, 80%, and 90% eligible ratios. TRA-a-FedAvg-X% indicates the packet loss ratios (10%, 30%, 50%).</span></figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">At the beginning of selection, each client compares its network condition with preset standards and sends a sufficiency investigation report to the server. The report contains only critical information, e.g., 0 or 1 to indicate insufficient or sufficient, thus adds negligible network load. After collecting the sufficiency reports of all willing-to-participate clients, the server classified the candidate clients into <span id="S4.p3.1.1" class="ltx_text ltx_font_italic">sufficient</span> and <span id="S4.p3.1.2" class="ltx_text ltx_font_italic">insufficient</span> based on the reports. Then the server randomly selects a number of clients regardless of the belonging groups and sends the global model. The clients send back updates after local training. Upon detecting loss, the server sends retransmission notification if the client belongs to the <span id="S4.p3.1.3" class="ltx_text ltx_font_italic">sufficient</span> group, or sets the lost data to zero directly otherwise. The rest of the processes follow the common federated learning flow.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.14" class="ltx_p">We base the logic behind different loss operations on estimating whether retransmission would take long. For clients with sufficient network capacities, most likely the retransmission would only take very few times without affecting the aggregation pace. However for the “insufficient” clients, the retransmission is more likely to straggle and impact the system flow. Therefore instead of retransferring the lost packets to guarantee data integrity, TRA discards such delayed/lost packets, resets the lost data as 0, and records the data loss. After uploading finished, TRA uses the loss record to recalculate the sample space to achieve an adaptive aggregation. As such, TRA prevents the biased selection in threshold-based settings by safely ignoring some packet losses. The recalculation can be summarized as follows:</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="W_{agg}=\frac{1}{n}\sum_{i=1}^{n}W_{i}+\frac{1}{m(1-r)}\sum_{i=1}^{m}\hat{W}_{j}" display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.2" xref="S4.E1.m1.1.2.cmml"><msub id="S4.E1.m1.1.2.2" xref="S4.E1.m1.1.2.2.cmml"><mi id="S4.E1.m1.1.2.2.2" xref="S4.E1.m1.1.2.2.2.cmml">W</mi><mrow id="S4.E1.m1.1.2.2.3" xref="S4.E1.m1.1.2.2.3.cmml"><mi id="S4.E1.m1.1.2.2.3.2" xref="S4.E1.m1.1.2.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.2.2.3.1" xref="S4.E1.m1.1.2.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.2.2.3.3" xref="S4.E1.m1.1.2.2.3.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.2.2.3.1a" xref="S4.E1.m1.1.2.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.2.2.3.4" xref="S4.E1.m1.1.2.2.3.4.cmml">g</mi></mrow></msub><mo id="S4.E1.m1.1.2.1" xref="S4.E1.m1.1.2.1.cmml">=</mo><mrow id="S4.E1.m1.1.2.3" xref="S4.E1.m1.1.2.3.cmml"><mrow id="S4.E1.m1.1.2.3.2" xref="S4.E1.m1.1.2.3.2.cmml"><mfrac id="S4.E1.m1.1.2.3.2.2" xref="S4.E1.m1.1.2.3.2.2.cmml"><mn id="S4.E1.m1.1.2.3.2.2.2" xref="S4.E1.m1.1.2.3.2.2.2.cmml">1</mn><mi id="S4.E1.m1.1.2.3.2.2.3" xref="S4.E1.m1.1.2.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.2.3.2.1" xref="S4.E1.m1.1.2.3.2.1.cmml">​</mo><mrow id="S4.E1.m1.1.2.3.2.3" xref="S4.E1.m1.1.2.3.2.3.cmml"><munderover id="S4.E1.m1.1.2.3.2.3.1" xref="S4.E1.m1.1.2.3.2.3.1.cmml"><mo movablelimits="false" id="S4.E1.m1.1.2.3.2.3.1.2.2" xref="S4.E1.m1.1.2.3.2.3.1.2.2.cmml">∑</mo><mrow id="S4.E1.m1.1.2.3.2.3.1.2.3" xref="S4.E1.m1.1.2.3.2.3.1.2.3.cmml"><mi id="S4.E1.m1.1.2.3.2.3.1.2.3.2" xref="S4.E1.m1.1.2.3.2.3.1.2.3.2.cmml">i</mi><mo id="S4.E1.m1.1.2.3.2.3.1.2.3.1" xref="S4.E1.m1.1.2.3.2.3.1.2.3.1.cmml">=</mo><mn id="S4.E1.m1.1.2.3.2.3.1.2.3.3" xref="S4.E1.m1.1.2.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E1.m1.1.2.3.2.3.1.3" xref="S4.E1.m1.1.2.3.2.3.1.3.cmml">n</mi></munderover><msub id="S4.E1.m1.1.2.3.2.3.2" xref="S4.E1.m1.1.2.3.2.3.2.cmml"><mi id="S4.E1.m1.1.2.3.2.3.2.2" xref="S4.E1.m1.1.2.3.2.3.2.2.cmml">W</mi><mi id="S4.E1.m1.1.2.3.2.3.2.3" xref="S4.E1.m1.1.2.3.2.3.2.3.cmml">i</mi></msub></mrow></mrow><mo id="S4.E1.m1.1.2.3.1" xref="S4.E1.m1.1.2.3.1.cmml">+</mo><mrow id="S4.E1.m1.1.2.3.3" xref="S4.E1.m1.1.2.3.3.cmml"><mfrac id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><mn id="S4.E1.m1.1.1.3" xref="S4.E1.m1.1.1.3.cmml">1</mn><mrow id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.cmml"><mi id="S4.E1.m1.1.1.1.3" xref="S4.E1.m1.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.2" xref="S4.E1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml"><mn id="S4.E1.m1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.E1.m1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S4.E1.m1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.3.cmml">r</mi></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.2.3.3.1" xref="S4.E1.m1.1.2.3.3.1.cmml">​</mo><mrow id="S4.E1.m1.1.2.3.3.2" xref="S4.E1.m1.1.2.3.3.2.cmml"><munderover id="S4.E1.m1.1.2.3.3.2.1" xref="S4.E1.m1.1.2.3.3.2.1.cmml"><mo movablelimits="false" id="S4.E1.m1.1.2.3.3.2.1.2.2" xref="S4.E1.m1.1.2.3.3.2.1.2.2.cmml">∑</mo><mrow id="S4.E1.m1.1.2.3.3.2.1.2.3" xref="S4.E1.m1.1.2.3.3.2.1.2.3.cmml"><mi id="S4.E1.m1.1.2.3.3.2.1.2.3.2" xref="S4.E1.m1.1.2.3.3.2.1.2.3.2.cmml">i</mi><mo id="S4.E1.m1.1.2.3.3.2.1.2.3.1" xref="S4.E1.m1.1.2.3.3.2.1.2.3.1.cmml">=</mo><mn id="S4.E1.m1.1.2.3.3.2.1.2.3.3" xref="S4.E1.m1.1.2.3.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E1.m1.1.2.3.3.2.1.3" xref="S4.E1.m1.1.2.3.3.2.1.3.cmml">m</mi></munderover><msub id="S4.E1.m1.1.2.3.3.2.2" xref="S4.E1.m1.1.2.3.3.2.2.cmml"><mover accent="true" id="S4.E1.m1.1.2.3.3.2.2.2" xref="S4.E1.m1.1.2.3.3.2.2.2.cmml"><mi id="S4.E1.m1.1.2.3.3.2.2.2.2" xref="S4.E1.m1.1.2.3.3.2.2.2.2.cmml">W</mi><mo id="S4.E1.m1.1.2.3.3.2.2.2.1" xref="S4.E1.m1.1.2.3.3.2.2.2.1.cmml">^</mo></mover><mi id="S4.E1.m1.1.2.3.3.2.2.3" xref="S4.E1.m1.1.2.3.3.2.2.3.cmml">j</mi></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.2.cmml" xref="S4.E1.m1.1.2"><eq id="S4.E1.m1.1.2.1.cmml" xref="S4.E1.m1.1.2.1"></eq><apply id="S4.E1.m1.1.2.2.cmml" xref="S4.E1.m1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.2.2.1.cmml" xref="S4.E1.m1.1.2.2">subscript</csymbol><ci id="S4.E1.m1.1.2.2.2.cmml" xref="S4.E1.m1.1.2.2.2">𝑊</ci><apply id="S4.E1.m1.1.2.2.3.cmml" xref="S4.E1.m1.1.2.2.3"><times id="S4.E1.m1.1.2.2.3.1.cmml" xref="S4.E1.m1.1.2.2.3.1"></times><ci id="S4.E1.m1.1.2.2.3.2.cmml" xref="S4.E1.m1.1.2.2.3.2">𝑎</ci><ci id="S4.E1.m1.1.2.2.3.3.cmml" xref="S4.E1.m1.1.2.2.3.3">𝑔</ci><ci id="S4.E1.m1.1.2.2.3.4.cmml" xref="S4.E1.m1.1.2.2.3.4">𝑔</ci></apply></apply><apply id="S4.E1.m1.1.2.3.cmml" xref="S4.E1.m1.1.2.3"><plus id="S4.E1.m1.1.2.3.1.cmml" xref="S4.E1.m1.1.2.3.1"></plus><apply id="S4.E1.m1.1.2.3.2.cmml" xref="S4.E1.m1.1.2.3.2"><times id="S4.E1.m1.1.2.3.2.1.cmml" xref="S4.E1.m1.1.2.3.2.1"></times><apply id="S4.E1.m1.1.2.3.2.2.cmml" xref="S4.E1.m1.1.2.3.2.2"><divide id="S4.E1.m1.1.2.3.2.2.1.cmml" xref="S4.E1.m1.1.2.3.2.2"></divide><cn type="integer" id="S4.E1.m1.1.2.3.2.2.2.cmml" xref="S4.E1.m1.1.2.3.2.2.2">1</cn><ci id="S4.E1.m1.1.2.3.2.2.3.cmml" xref="S4.E1.m1.1.2.3.2.2.3">𝑛</ci></apply><apply id="S4.E1.m1.1.2.3.2.3.cmml" xref="S4.E1.m1.1.2.3.2.3"><apply id="S4.E1.m1.1.2.3.2.3.1.cmml" xref="S4.E1.m1.1.2.3.2.3.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.2.3.2.3.1.1.cmml" xref="S4.E1.m1.1.2.3.2.3.1">superscript</csymbol><apply id="S4.E1.m1.1.2.3.2.3.1.2.cmml" xref="S4.E1.m1.1.2.3.2.3.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.2.3.2.3.1.2.1.cmml" xref="S4.E1.m1.1.2.3.2.3.1">subscript</csymbol><sum id="S4.E1.m1.1.2.3.2.3.1.2.2.cmml" xref="S4.E1.m1.1.2.3.2.3.1.2.2"></sum><apply id="S4.E1.m1.1.2.3.2.3.1.2.3.cmml" xref="S4.E1.m1.1.2.3.2.3.1.2.3"><eq id="S4.E1.m1.1.2.3.2.3.1.2.3.1.cmml" xref="S4.E1.m1.1.2.3.2.3.1.2.3.1"></eq><ci id="S4.E1.m1.1.2.3.2.3.1.2.3.2.cmml" xref="S4.E1.m1.1.2.3.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S4.E1.m1.1.2.3.2.3.1.2.3.3.cmml" xref="S4.E1.m1.1.2.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S4.E1.m1.1.2.3.2.3.1.3.cmml" xref="S4.E1.m1.1.2.3.2.3.1.3">𝑛</ci></apply><apply id="S4.E1.m1.1.2.3.2.3.2.cmml" xref="S4.E1.m1.1.2.3.2.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.2.3.2.3.2.1.cmml" xref="S4.E1.m1.1.2.3.2.3.2">subscript</csymbol><ci id="S4.E1.m1.1.2.3.2.3.2.2.cmml" xref="S4.E1.m1.1.2.3.2.3.2.2">𝑊</ci><ci id="S4.E1.m1.1.2.3.2.3.2.3.cmml" xref="S4.E1.m1.1.2.3.2.3.2.3">𝑖</ci></apply></apply></apply><apply id="S4.E1.m1.1.2.3.3.cmml" xref="S4.E1.m1.1.2.3.3"><times id="S4.E1.m1.1.2.3.3.1.cmml" xref="S4.E1.m1.1.2.3.3.1"></times><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"><divide id="S4.E1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1"></divide><cn type="integer" id="S4.E1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.3">1</cn><apply id="S4.E1.m1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"><times id="S4.E1.m1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.2"></times><ci id="S4.E1.m1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.3">𝑚</ci><apply id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1"><minus id="S4.E1.m1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E1.m1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2">1</cn><ci id="S4.E1.m1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.3">𝑟</ci></apply></apply></apply><apply id="S4.E1.m1.1.2.3.3.2.cmml" xref="S4.E1.m1.1.2.3.3.2"><apply id="S4.E1.m1.1.2.3.3.2.1.cmml" xref="S4.E1.m1.1.2.3.3.2.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.2.3.3.2.1.1.cmml" xref="S4.E1.m1.1.2.3.3.2.1">superscript</csymbol><apply id="S4.E1.m1.1.2.3.3.2.1.2.cmml" xref="S4.E1.m1.1.2.3.3.2.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.2.3.3.2.1.2.1.cmml" xref="S4.E1.m1.1.2.3.3.2.1">subscript</csymbol><sum id="S4.E1.m1.1.2.3.3.2.1.2.2.cmml" xref="S4.E1.m1.1.2.3.3.2.1.2.2"></sum><apply id="S4.E1.m1.1.2.3.3.2.1.2.3.cmml" xref="S4.E1.m1.1.2.3.3.2.1.2.3"><eq id="S4.E1.m1.1.2.3.3.2.1.2.3.1.cmml" xref="S4.E1.m1.1.2.3.3.2.1.2.3.1"></eq><ci id="S4.E1.m1.1.2.3.3.2.1.2.3.2.cmml" xref="S4.E1.m1.1.2.3.3.2.1.2.3.2">𝑖</ci><cn type="integer" id="S4.E1.m1.1.2.3.3.2.1.2.3.3.cmml" xref="S4.E1.m1.1.2.3.3.2.1.2.3.3">1</cn></apply></apply><ci id="S4.E1.m1.1.2.3.3.2.1.3.cmml" xref="S4.E1.m1.1.2.3.3.2.1.3">𝑚</ci></apply><apply id="S4.E1.m1.1.2.3.3.2.2.cmml" xref="S4.E1.m1.1.2.3.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.2.3.3.2.2.1.cmml" xref="S4.E1.m1.1.2.3.3.2.2">subscript</csymbol><apply id="S4.E1.m1.1.2.3.3.2.2.2.cmml" xref="S4.E1.m1.1.2.3.3.2.2.2"><ci id="S4.E1.m1.1.2.3.3.2.2.2.1.cmml" xref="S4.E1.m1.1.2.3.3.2.2.2.1">^</ci><ci id="S4.E1.m1.1.2.3.3.2.2.2.2.cmml" xref="S4.E1.m1.1.2.3.3.2.2.2.2">𝑊</ci></apply><ci id="S4.E1.m1.1.2.3.3.2.2.3.cmml" xref="S4.E1.m1.1.2.3.3.2.2.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">W_{agg}=\frac{1}{n}\sum_{i=1}^{n}W_{i}+\frac{1}{m(1-r)}\sum_{i=1}^{m}\hat{W}_{j}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.p4.13" class="ltx_p"><math id="S4.p4.1.m1.1" class="ltx_Math" alttext="W_{i}" display="inline"><semantics id="S4.p4.1.m1.1a"><msub id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mi id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">W</mi><mi id="S4.p4.1.m1.1.1.3" xref="S4.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1">subscript</csymbol><ci id="S4.p4.1.m1.1.1.2.cmml" xref="S4.p4.1.m1.1.1.2">𝑊</ci><ci id="S4.p4.1.m1.1.1.3.cmml" xref="S4.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">W_{i}</annotation></semantics></math> and <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="\hat{W}_{j}" display="inline"><semantics id="S4.p4.2.m2.1a"><msub id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml"><mover accent="true" id="S4.p4.2.m2.1.1.2" xref="S4.p4.2.m2.1.1.2.cmml"><mi id="S4.p4.2.m2.1.1.2.2" xref="S4.p4.2.m2.1.1.2.2.cmml">W</mi><mo id="S4.p4.2.m2.1.1.2.1" xref="S4.p4.2.m2.1.1.2.1.cmml">^</mo></mover><mi id="S4.p4.2.m2.1.1.3" xref="S4.p4.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><apply id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p4.2.m2.1.1.1.cmml" xref="S4.p4.2.m2.1.1">subscript</csymbol><apply id="S4.p4.2.m2.1.1.2.cmml" xref="S4.p4.2.m2.1.1.2"><ci id="S4.p4.2.m2.1.1.2.1.cmml" xref="S4.p4.2.m2.1.1.2.1">^</ci><ci id="S4.p4.2.m2.1.1.2.2.cmml" xref="S4.p4.2.m2.1.1.2.2">𝑊</ci></apply><ci id="S4.p4.2.m2.1.1.3.cmml" xref="S4.p4.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">\hat{W}_{j}</annotation></semantics></math> are respectively model weights in <math id="S4.p4.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.p4.3.m3.1a"><mi id="S4.p4.3.m3.1.1" xref="S4.p4.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.1b"><ci id="S4.p4.3.m3.1.1.cmml" xref="S4.p4.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.1c">n</annotation></semantics></math> users with sufficient and <math id="S4.p4.4.m4.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.p4.4.m4.1a"><mi id="S4.p4.4.m4.1.1" xref="S4.p4.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.p4.4.m4.1b"><ci id="S4.p4.4.m4.1.1.cmml" xref="S4.p4.4.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.4.m4.1c">m</annotation></semantics></math> users with insufficient network capacities. <math id="S4.p4.5.m5.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.p4.5.m5.1a"><mi id="S4.p4.5.m5.1.1" xref="S4.p4.5.m5.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.p4.5.m5.1b"><ci id="S4.p4.5.m5.1.1.cmml" xref="S4.p4.5.m5.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.5.m5.1c">r</annotation></semantics></math> indicates the package drop rate. Hence each weight <math id="S4.p4.6.m6.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.p4.6.m6.1a"><mi id="S4.p4.6.m6.1.1" xref="S4.p4.6.m6.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.p4.6.m6.1b"><ci id="S4.p4.6.m6.1.1.cmml" xref="S4.p4.6.m6.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.6.m6.1c">w</annotation></semantics></math> in <math id="S4.p4.7.m7.1" class="ltx_Math" alttext="\hat{W}" display="inline"><semantics id="S4.p4.7.m7.1a"><mover accent="true" id="S4.p4.7.m7.1.1" xref="S4.p4.7.m7.1.1.cmml"><mi id="S4.p4.7.m7.1.1.2" xref="S4.p4.7.m7.1.1.2.cmml">W</mi><mo id="S4.p4.7.m7.1.1.1" xref="S4.p4.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.p4.7.m7.1b"><apply id="S4.p4.7.m7.1.1.cmml" xref="S4.p4.7.m7.1.1"><ci id="S4.p4.7.m7.1.1.1.cmml" xref="S4.p4.7.m7.1.1.1">^</ci><ci id="S4.p4.7.m7.1.1.2.cmml" xref="S4.p4.7.m7.1.1.2">𝑊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.7.m7.1c">\hat{W}</annotation></semantics></math> has probability <math id="S4.p4.8.m8.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.p4.8.m8.1a"><mi id="S4.p4.8.m8.1.1" xref="S4.p4.8.m8.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.p4.8.m8.1b"><ci id="S4.p4.8.m8.1.1.cmml" xref="S4.p4.8.m8.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.8.m8.1c">r</annotation></semantics></math> to be dropped and set zero. We denote <math id="S4.p4.9.m9.1" class="ltx_Math" alttext="\mathbb{E}(W)=\mu" display="inline"><semantics id="S4.p4.9.m9.1a"><mrow id="S4.p4.9.m9.1.2" xref="S4.p4.9.m9.1.2.cmml"><mrow id="S4.p4.9.m9.1.2.2" xref="S4.p4.9.m9.1.2.2.cmml"><mi id="S4.p4.9.m9.1.2.2.2" xref="S4.p4.9.m9.1.2.2.2.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S4.p4.9.m9.1.2.2.1" xref="S4.p4.9.m9.1.2.2.1.cmml">​</mo><mrow id="S4.p4.9.m9.1.2.2.3.2" xref="S4.p4.9.m9.1.2.2.cmml"><mo stretchy="false" id="S4.p4.9.m9.1.2.2.3.2.1" xref="S4.p4.9.m9.1.2.2.cmml">(</mo><mi id="S4.p4.9.m9.1.1" xref="S4.p4.9.m9.1.1.cmml">W</mi><mo stretchy="false" id="S4.p4.9.m9.1.2.2.3.2.2" xref="S4.p4.9.m9.1.2.2.cmml">)</mo></mrow></mrow><mo id="S4.p4.9.m9.1.2.1" xref="S4.p4.9.m9.1.2.1.cmml">=</mo><mi id="S4.p4.9.m9.1.2.3" xref="S4.p4.9.m9.1.2.3.cmml">μ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.9.m9.1b"><apply id="S4.p4.9.m9.1.2.cmml" xref="S4.p4.9.m9.1.2"><eq id="S4.p4.9.m9.1.2.1.cmml" xref="S4.p4.9.m9.1.2.1"></eq><apply id="S4.p4.9.m9.1.2.2.cmml" xref="S4.p4.9.m9.1.2.2"><times id="S4.p4.9.m9.1.2.2.1.cmml" xref="S4.p4.9.m9.1.2.2.1"></times><ci id="S4.p4.9.m9.1.2.2.2.cmml" xref="S4.p4.9.m9.1.2.2.2">𝔼</ci><ci id="S4.p4.9.m9.1.1.cmml" xref="S4.p4.9.m9.1.1">𝑊</ci></apply><ci id="S4.p4.9.m9.1.2.3.cmml" xref="S4.p4.9.m9.1.2.3">𝜇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.9.m9.1c">\mathbb{E}(W)=\mu</annotation></semantics></math>, then <math id="S4.p4.10.m10.4" class="ltx_Math" alttext="\mathbb{E}(\hat{W})=(1-r)\mathbb{E}(W)=(1-r)\mu" display="inline"><semantics id="S4.p4.10.m10.4a"><mrow id="S4.p4.10.m10.4.4" xref="S4.p4.10.m10.4.4.cmml"><mrow id="S4.p4.10.m10.4.4.4" xref="S4.p4.10.m10.4.4.4.cmml"><mi id="S4.p4.10.m10.4.4.4.2" xref="S4.p4.10.m10.4.4.4.2.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S4.p4.10.m10.4.4.4.1" xref="S4.p4.10.m10.4.4.4.1.cmml">​</mo><mrow id="S4.p4.10.m10.4.4.4.3.2" xref="S4.p4.10.m10.1.1.cmml"><mo stretchy="false" id="S4.p4.10.m10.4.4.4.3.2.1" xref="S4.p4.10.m10.1.1.cmml">(</mo><mover accent="true" id="S4.p4.10.m10.1.1" xref="S4.p4.10.m10.1.1.cmml"><mi id="S4.p4.10.m10.1.1.2" xref="S4.p4.10.m10.1.1.2.cmml">W</mi><mo id="S4.p4.10.m10.1.1.1" xref="S4.p4.10.m10.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S4.p4.10.m10.4.4.4.3.2.2" xref="S4.p4.10.m10.1.1.cmml">)</mo></mrow></mrow><mo id="S4.p4.10.m10.4.4.5" xref="S4.p4.10.m10.4.4.5.cmml">=</mo><mrow id="S4.p4.10.m10.3.3.1" xref="S4.p4.10.m10.3.3.1.cmml"><mrow id="S4.p4.10.m10.3.3.1.1.1" xref="S4.p4.10.m10.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.p4.10.m10.3.3.1.1.1.2" xref="S4.p4.10.m10.3.3.1.1.1.1.cmml">(</mo><mrow id="S4.p4.10.m10.3.3.1.1.1.1" xref="S4.p4.10.m10.3.3.1.1.1.1.cmml"><mn id="S4.p4.10.m10.3.3.1.1.1.1.2" xref="S4.p4.10.m10.3.3.1.1.1.1.2.cmml">1</mn><mo id="S4.p4.10.m10.3.3.1.1.1.1.1" xref="S4.p4.10.m10.3.3.1.1.1.1.1.cmml">−</mo><mi id="S4.p4.10.m10.3.3.1.1.1.1.3" xref="S4.p4.10.m10.3.3.1.1.1.1.3.cmml">r</mi></mrow><mo stretchy="false" id="S4.p4.10.m10.3.3.1.1.1.3" xref="S4.p4.10.m10.3.3.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.p4.10.m10.3.3.1.2" xref="S4.p4.10.m10.3.3.1.2.cmml">​</mo><mi id="S4.p4.10.m10.3.3.1.3" xref="S4.p4.10.m10.3.3.1.3.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S4.p4.10.m10.3.3.1.2a" xref="S4.p4.10.m10.3.3.1.2.cmml">​</mo><mrow id="S4.p4.10.m10.3.3.1.4.2" xref="S4.p4.10.m10.3.3.1.cmml"><mo stretchy="false" id="S4.p4.10.m10.3.3.1.4.2.1" xref="S4.p4.10.m10.3.3.1.cmml">(</mo><mi id="S4.p4.10.m10.2.2" xref="S4.p4.10.m10.2.2.cmml">W</mi><mo stretchy="false" id="S4.p4.10.m10.3.3.1.4.2.2" xref="S4.p4.10.m10.3.3.1.cmml">)</mo></mrow></mrow><mo id="S4.p4.10.m10.4.4.6" xref="S4.p4.10.m10.4.4.6.cmml">=</mo><mrow id="S4.p4.10.m10.4.4.2" xref="S4.p4.10.m10.4.4.2.cmml"><mrow id="S4.p4.10.m10.4.4.2.1.1" xref="S4.p4.10.m10.4.4.2.1.1.1.cmml"><mo stretchy="false" id="S4.p4.10.m10.4.4.2.1.1.2" xref="S4.p4.10.m10.4.4.2.1.1.1.cmml">(</mo><mrow id="S4.p4.10.m10.4.4.2.1.1.1" xref="S4.p4.10.m10.4.4.2.1.1.1.cmml"><mn id="S4.p4.10.m10.4.4.2.1.1.1.2" xref="S4.p4.10.m10.4.4.2.1.1.1.2.cmml">1</mn><mo id="S4.p4.10.m10.4.4.2.1.1.1.1" xref="S4.p4.10.m10.4.4.2.1.1.1.1.cmml">−</mo><mi id="S4.p4.10.m10.4.4.2.1.1.1.3" xref="S4.p4.10.m10.4.4.2.1.1.1.3.cmml">r</mi></mrow><mo stretchy="false" id="S4.p4.10.m10.4.4.2.1.1.3" xref="S4.p4.10.m10.4.4.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.p4.10.m10.4.4.2.2" xref="S4.p4.10.m10.4.4.2.2.cmml">​</mo><mi id="S4.p4.10.m10.4.4.2.3" xref="S4.p4.10.m10.4.4.2.3.cmml">μ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.10.m10.4b"><apply id="S4.p4.10.m10.4.4.cmml" xref="S4.p4.10.m10.4.4"><and id="S4.p4.10.m10.4.4a.cmml" xref="S4.p4.10.m10.4.4"></and><apply id="S4.p4.10.m10.4.4b.cmml" xref="S4.p4.10.m10.4.4"><eq id="S4.p4.10.m10.4.4.5.cmml" xref="S4.p4.10.m10.4.4.5"></eq><apply id="S4.p4.10.m10.4.4.4.cmml" xref="S4.p4.10.m10.4.4.4"><times id="S4.p4.10.m10.4.4.4.1.cmml" xref="S4.p4.10.m10.4.4.4.1"></times><ci id="S4.p4.10.m10.4.4.4.2.cmml" xref="S4.p4.10.m10.4.4.4.2">𝔼</ci><apply id="S4.p4.10.m10.1.1.cmml" xref="S4.p4.10.m10.4.4.4.3.2"><ci id="S4.p4.10.m10.1.1.1.cmml" xref="S4.p4.10.m10.1.1.1">^</ci><ci id="S4.p4.10.m10.1.1.2.cmml" xref="S4.p4.10.m10.1.1.2">𝑊</ci></apply></apply><apply id="S4.p4.10.m10.3.3.1.cmml" xref="S4.p4.10.m10.3.3.1"><times id="S4.p4.10.m10.3.3.1.2.cmml" xref="S4.p4.10.m10.3.3.1.2"></times><apply id="S4.p4.10.m10.3.3.1.1.1.1.cmml" xref="S4.p4.10.m10.3.3.1.1.1"><minus id="S4.p4.10.m10.3.3.1.1.1.1.1.cmml" xref="S4.p4.10.m10.3.3.1.1.1.1.1"></minus><cn type="integer" id="S4.p4.10.m10.3.3.1.1.1.1.2.cmml" xref="S4.p4.10.m10.3.3.1.1.1.1.2">1</cn><ci id="S4.p4.10.m10.3.3.1.1.1.1.3.cmml" xref="S4.p4.10.m10.3.3.1.1.1.1.3">𝑟</ci></apply><ci id="S4.p4.10.m10.3.3.1.3.cmml" xref="S4.p4.10.m10.3.3.1.3">𝔼</ci><ci id="S4.p4.10.m10.2.2.cmml" xref="S4.p4.10.m10.2.2">𝑊</ci></apply></apply><apply id="S4.p4.10.m10.4.4c.cmml" xref="S4.p4.10.m10.4.4"><eq id="S4.p4.10.m10.4.4.6.cmml" xref="S4.p4.10.m10.4.4.6"></eq><share href="#S4.p4.10.m10.3.3.1.cmml" id="S4.p4.10.m10.4.4d.cmml" xref="S4.p4.10.m10.4.4"></share><apply id="S4.p4.10.m10.4.4.2.cmml" xref="S4.p4.10.m10.4.4.2"><times id="S4.p4.10.m10.4.4.2.2.cmml" xref="S4.p4.10.m10.4.4.2.2"></times><apply id="S4.p4.10.m10.4.4.2.1.1.1.cmml" xref="S4.p4.10.m10.4.4.2.1.1"><minus id="S4.p4.10.m10.4.4.2.1.1.1.1.cmml" xref="S4.p4.10.m10.4.4.2.1.1.1.1"></minus><cn type="integer" id="S4.p4.10.m10.4.4.2.1.1.1.2.cmml" xref="S4.p4.10.m10.4.4.2.1.1.1.2">1</cn><ci id="S4.p4.10.m10.4.4.2.1.1.1.3.cmml" xref="S4.p4.10.m10.4.4.2.1.1.1.3">𝑟</ci></apply><ci id="S4.p4.10.m10.4.4.2.3.cmml" xref="S4.p4.10.m10.4.4.2.3">𝜇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.10.m10.4c">\mathbb{E}(\hat{W})=(1-r)\mathbb{E}(W)=(1-r)\mu</annotation></semantics></math>. When the clients’ model have the same distributions, it is clear that <math id="S4.p4.11.m11.1" class="ltx_Math" alttext="\mathbb{E}(W_{agg})=\mu" display="inline"><semantics id="S4.p4.11.m11.1a"><mrow id="S4.p4.11.m11.1.1" xref="S4.p4.11.m11.1.1.cmml"><mrow id="S4.p4.11.m11.1.1.1" xref="S4.p4.11.m11.1.1.1.cmml"><mi id="S4.p4.11.m11.1.1.1.3" xref="S4.p4.11.m11.1.1.1.3.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S4.p4.11.m11.1.1.1.2" xref="S4.p4.11.m11.1.1.1.2.cmml">​</mo><mrow id="S4.p4.11.m11.1.1.1.1.1" xref="S4.p4.11.m11.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.p4.11.m11.1.1.1.1.1.2" xref="S4.p4.11.m11.1.1.1.1.1.1.cmml">(</mo><msub id="S4.p4.11.m11.1.1.1.1.1.1" xref="S4.p4.11.m11.1.1.1.1.1.1.cmml"><mi id="S4.p4.11.m11.1.1.1.1.1.1.2" xref="S4.p4.11.m11.1.1.1.1.1.1.2.cmml">W</mi><mrow id="S4.p4.11.m11.1.1.1.1.1.1.3" xref="S4.p4.11.m11.1.1.1.1.1.1.3.cmml"><mi id="S4.p4.11.m11.1.1.1.1.1.1.3.2" xref="S4.p4.11.m11.1.1.1.1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p4.11.m11.1.1.1.1.1.1.3.1" xref="S4.p4.11.m11.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S4.p4.11.m11.1.1.1.1.1.1.3.3" xref="S4.p4.11.m11.1.1.1.1.1.1.3.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.p4.11.m11.1.1.1.1.1.1.3.1a" xref="S4.p4.11.m11.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S4.p4.11.m11.1.1.1.1.1.1.3.4" xref="S4.p4.11.m11.1.1.1.1.1.1.3.4.cmml">g</mi></mrow></msub><mo stretchy="false" id="S4.p4.11.m11.1.1.1.1.1.3" xref="S4.p4.11.m11.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.p4.11.m11.1.1.2" xref="S4.p4.11.m11.1.1.2.cmml">=</mo><mi id="S4.p4.11.m11.1.1.3" xref="S4.p4.11.m11.1.1.3.cmml">μ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.11.m11.1b"><apply id="S4.p4.11.m11.1.1.cmml" xref="S4.p4.11.m11.1.1"><eq id="S4.p4.11.m11.1.1.2.cmml" xref="S4.p4.11.m11.1.1.2"></eq><apply id="S4.p4.11.m11.1.1.1.cmml" xref="S4.p4.11.m11.1.1.1"><times id="S4.p4.11.m11.1.1.1.2.cmml" xref="S4.p4.11.m11.1.1.1.2"></times><ci id="S4.p4.11.m11.1.1.1.3.cmml" xref="S4.p4.11.m11.1.1.1.3">𝔼</ci><apply id="S4.p4.11.m11.1.1.1.1.1.1.cmml" xref="S4.p4.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p4.11.m11.1.1.1.1.1.1.1.cmml" xref="S4.p4.11.m11.1.1.1.1.1">subscript</csymbol><ci id="S4.p4.11.m11.1.1.1.1.1.1.2.cmml" xref="S4.p4.11.m11.1.1.1.1.1.1.2">𝑊</ci><apply id="S4.p4.11.m11.1.1.1.1.1.1.3.cmml" xref="S4.p4.11.m11.1.1.1.1.1.1.3"><times id="S4.p4.11.m11.1.1.1.1.1.1.3.1.cmml" xref="S4.p4.11.m11.1.1.1.1.1.1.3.1"></times><ci id="S4.p4.11.m11.1.1.1.1.1.1.3.2.cmml" xref="S4.p4.11.m11.1.1.1.1.1.1.3.2">𝑎</ci><ci id="S4.p4.11.m11.1.1.1.1.1.1.3.3.cmml" xref="S4.p4.11.m11.1.1.1.1.1.1.3.3">𝑔</ci><ci id="S4.p4.11.m11.1.1.1.1.1.1.3.4.cmml" xref="S4.p4.11.m11.1.1.1.1.1.1.3.4">𝑔</ci></apply></apply></apply><ci id="S4.p4.11.m11.1.1.3.cmml" xref="S4.p4.11.m11.1.1.3">𝜇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.11.m11.1c">\mathbb{E}(W_{agg})=\mu</annotation></semantics></math> and is equal to <math id="S4.p4.12.m12.1" class="ltx_Math" alttext="\mathbb{E}(\frac{1}{n+m}\sum_{i=1}^{n+m}W_{i})" display="inline"><semantics id="S4.p4.12.m12.1a"><mrow id="S4.p4.12.m12.1.1" xref="S4.p4.12.m12.1.1.cmml"><mi id="S4.p4.12.m12.1.1.3" xref="S4.p4.12.m12.1.1.3.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S4.p4.12.m12.1.1.2" xref="S4.p4.12.m12.1.1.2.cmml">​</mo><mrow id="S4.p4.12.m12.1.1.1.1" xref="S4.p4.12.m12.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.p4.12.m12.1.1.1.1.2" xref="S4.p4.12.m12.1.1.1.1.1.cmml">(</mo><mrow id="S4.p4.12.m12.1.1.1.1.1" xref="S4.p4.12.m12.1.1.1.1.1.cmml"><mfrac id="S4.p4.12.m12.1.1.1.1.1.2" xref="S4.p4.12.m12.1.1.1.1.1.2.cmml"><mn id="S4.p4.12.m12.1.1.1.1.1.2.2" xref="S4.p4.12.m12.1.1.1.1.1.2.2.cmml">1</mn><mrow id="S4.p4.12.m12.1.1.1.1.1.2.3" xref="S4.p4.12.m12.1.1.1.1.1.2.3.cmml"><mi id="S4.p4.12.m12.1.1.1.1.1.2.3.2" xref="S4.p4.12.m12.1.1.1.1.1.2.3.2.cmml">n</mi><mo id="S4.p4.12.m12.1.1.1.1.1.2.3.1" xref="S4.p4.12.m12.1.1.1.1.1.2.3.1.cmml">+</mo><mi id="S4.p4.12.m12.1.1.1.1.1.2.3.3" xref="S4.p4.12.m12.1.1.1.1.1.2.3.3.cmml">m</mi></mrow></mfrac><mo lspace="0em" rspace="0em" id="S4.p4.12.m12.1.1.1.1.1.1" xref="S4.p4.12.m12.1.1.1.1.1.1.cmml">​</mo><mrow id="S4.p4.12.m12.1.1.1.1.1.3" xref="S4.p4.12.m12.1.1.1.1.1.3.cmml"><msubsup id="S4.p4.12.m12.1.1.1.1.1.3.1" xref="S4.p4.12.m12.1.1.1.1.1.3.1.cmml"><mo id="S4.p4.12.m12.1.1.1.1.1.3.1.2.2" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.cmml"><mi id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.2" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.2.cmml">i</mi><mo id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.1" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.3" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S4.p4.12.m12.1.1.1.1.1.3.1.3" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3.cmml"><mi id="S4.p4.12.m12.1.1.1.1.1.3.1.3.2" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3.2.cmml">n</mi><mo id="S4.p4.12.m12.1.1.1.1.1.3.1.3.1" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3.1.cmml">+</mo><mi id="S4.p4.12.m12.1.1.1.1.1.3.1.3.3" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3.3.cmml">m</mi></mrow></msubsup><msub id="S4.p4.12.m12.1.1.1.1.1.3.2" xref="S4.p4.12.m12.1.1.1.1.1.3.2.cmml"><mi id="S4.p4.12.m12.1.1.1.1.1.3.2.2" xref="S4.p4.12.m12.1.1.1.1.1.3.2.2.cmml">W</mi><mi id="S4.p4.12.m12.1.1.1.1.1.3.2.3" xref="S4.p4.12.m12.1.1.1.1.1.3.2.3.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S4.p4.12.m12.1.1.1.1.3" xref="S4.p4.12.m12.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.12.m12.1b"><apply id="S4.p4.12.m12.1.1.cmml" xref="S4.p4.12.m12.1.1"><times id="S4.p4.12.m12.1.1.2.cmml" xref="S4.p4.12.m12.1.1.2"></times><ci id="S4.p4.12.m12.1.1.3.cmml" xref="S4.p4.12.m12.1.1.3">𝔼</ci><apply id="S4.p4.12.m12.1.1.1.1.1.cmml" xref="S4.p4.12.m12.1.1.1.1"><times id="S4.p4.12.m12.1.1.1.1.1.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.1"></times><apply id="S4.p4.12.m12.1.1.1.1.1.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.2"><divide id="S4.p4.12.m12.1.1.1.1.1.2.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.2"></divide><cn type="integer" id="S4.p4.12.m12.1.1.1.1.1.2.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.2.2">1</cn><apply id="S4.p4.12.m12.1.1.1.1.1.2.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.2.3"><plus id="S4.p4.12.m12.1.1.1.1.1.2.3.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.2.3.1"></plus><ci id="S4.p4.12.m12.1.1.1.1.1.2.3.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.2.3.2">𝑛</ci><ci id="S4.p4.12.m12.1.1.1.1.1.2.3.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.2.3.3">𝑚</ci></apply></apply><apply id="S4.p4.12.m12.1.1.1.1.1.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3"><apply id="S4.p4.12.m12.1.1.1.1.1.3.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.p4.12.m12.1.1.1.1.1.3.1.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1">superscript</csymbol><apply id="S4.p4.12.m12.1.1.1.1.1.3.1.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.p4.12.m12.1.1.1.1.1.3.1.2.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1">subscript</csymbol><sum id="S4.p4.12.m12.1.1.1.1.1.3.1.2.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.2"></sum><apply id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3"><eq id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.1"></eq><ci id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.2">𝑖</ci><cn type="integer" id="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><apply id="S4.p4.12.m12.1.1.1.1.1.3.1.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3"><plus id="S4.p4.12.m12.1.1.1.1.1.3.1.3.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3.1"></plus><ci id="S4.p4.12.m12.1.1.1.1.1.3.1.3.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3.2">𝑛</ci><ci id="S4.p4.12.m12.1.1.1.1.1.3.1.3.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.1.3.3">𝑚</ci></apply></apply><apply id="S4.p4.12.m12.1.1.1.1.1.3.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.p4.12.m12.1.1.1.1.1.3.2.1.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.p4.12.m12.1.1.1.1.1.3.2.2.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.2.2">𝑊</ci><ci id="S4.p4.12.m12.1.1.1.1.1.3.2.3.cmml" xref="S4.p4.12.m12.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.12.m12.1c">\mathbb{E}(\frac{1}{n+m}\sum_{i=1}^{n+m}W_{i})</annotation></semantics></math>, which is the expectation of the aggregated model without packet loss. Generally, <math id="S4.p4.13.m13.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.p4.13.m13.1a"><mi id="S4.p4.13.m13.1.1" xref="S4.p4.13.m13.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.p4.13.m13.1b"><ci id="S4.p4.13.m13.1.1.cmml" xref="S4.p4.13.m13.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.13.m13.1c">r</annotation></semantics></math> ensures that, after the clients’ model with packet loss being taken in, the aggregated model’s weights would not be smaller than those without packet loss.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">To validate the easy-to-integrate feature and performance of TRA, we integrate TRA with several state-of-the-art algorithms in different aspects of federated learning. <a href="#S5" title="5 Evaluation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a> shows the performance of the integrated algorithms.</p>
</div>
<figure id="alg1" class="ltx_float ltx_algorithm">
<div id="alg1.11" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="alg1.11.12" class="ltx_listingline">

<span id="alg1.11.12.1" class="ltx_text ltx_font_bold">thread</span> <em id="alg1.11.12.2" class="ltx_emph ltx_font_italic">Server</em><span id="alg1.11.12.3" class="ltx_text ltx_font_bold">:</span>
</div>
<div id="alg1.11.13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
collect(sufficiencyReport) 
</div>
<div id="alg1.11.14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
categorize(sufficiencyGroup)
</div>
<div id="alg1.1.1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Randomly selects a subset <math id="alg1.1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="alg1.1.1.m1.1a"><mi id="alg1.1.1.m1.1.1" xref="alg1.1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg1.1.1.m1.1b"><ci id="alg1.1.1.m1.1.1.cmml" xref="alg1.1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.1.m1.1c">S</annotation></semantics></math> of the clients
</div>
<div id="alg1.11.15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.11.15.1" class="ltx_text ltx_font_bold">for</span> <em id="alg1.11.15.2" class="ltx_emph ltx_font_italic">t=1 to T-1</em> <span id="alg1.11.15.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="alg1.2.2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.2.2.2" class="ltx_text ltx_font_bold">for</span> <em id="alg1.2.2.1" class="ltx_emph ltx_font_italic">each client <math id="alg1.2.2.1.m1.1" class="ltx_Math" alttext="k\in S" display="inline"><semantics id="alg1.2.2.1.m1.1a"><mrow id="alg1.2.2.1.m1.1.1" xref="alg1.2.2.1.m1.1.1.cmml"><mi id="alg1.2.2.1.m1.1.1.2" xref="alg1.2.2.1.m1.1.1.2.cmml">k</mi><mo id="alg1.2.2.1.m1.1.1.1" xref="alg1.2.2.1.m1.1.1.1.cmml">∈</mo><mi id="alg1.2.2.1.m1.1.1.3" xref="alg1.2.2.1.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.2.2.1.m1.1b"><apply id="alg1.2.2.1.m1.1.1.cmml" xref="alg1.2.2.1.m1.1.1"><in id="alg1.2.2.1.m1.1.1.1.cmml" xref="alg1.2.2.1.m1.1.1.1"></in><ci id="alg1.2.2.1.m1.1.1.2.cmml" xref="alg1.2.2.1.m1.1.1.2">𝑘</ci><ci id="alg1.2.2.1.m1.1.1.3.cmml" xref="alg1.2.2.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.2.1.m1.1c">k\in S</annotation></semantics></math></em> <span id="alg1.2.2.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="alg1.4.4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.3.3.m1.1" class="ltx_Math" alttext="\mathbf{x}_{k}^{t+1}\leftarrow" display="inline"><semantics id="alg1.3.3.m1.1a"><mrow id="alg1.3.3.m1.1.1" xref="alg1.3.3.m1.1.1.cmml"><msubsup id="alg1.3.3.m1.1.1.2" xref="alg1.3.3.m1.1.1.2.cmml"><mi id="alg1.3.3.m1.1.1.2.2.2" xref="alg1.3.3.m1.1.1.2.2.2.cmml">𝐱</mi><mi id="alg1.3.3.m1.1.1.2.2.3" xref="alg1.3.3.m1.1.1.2.2.3.cmml">k</mi><mrow id="alg1.3.3.m1.1.1.2.3" xref="alg1.3.3.m1.1.1.2.3.cmml"><mi id="alg1.3.3.m1.1.1.2.3.2" xref="alg1.3.3.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.3.3.m1.1.1.2.3.1" xref="alg1.3.3.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.3.3.m1.1.1.2.3.3" xref="alg1.3.3.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="alg1.3.3.m1.1.1.1" xref="alg1.3.3.m1.1.1.1.cmml">←</mo><mi id="alg1.3.3.m1.1.1.3" xref="alg1.3.3.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.3.3.m1.1b"><apply id="alg1.3.3.m1.1.1.cmml" xref="alg1.3.3.m1.1.1"><ci id="alg1.3.3.m1.1.1.1.cmml" xref="alg1.3.3.m1.1.1.1">←</ci><apply id="alg1.3.3.m1.1.1.2.cmml" xref="alg1.3.3.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.3.3.m1.1.1.2.1.cmml" xref="alg1.3.3.m1.1.1.2">superscript</csymbol><apply id="alg1.3.3.m1.1.1.2.2.cmml" xref="alg1.3.3.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.3.3.m1.1.1.2.2.1.cmml" xref="alg1.3.3.m1.1.1.2">subscript</csymbol><ci id="alg1.3.3.m1.1.1.2.2.2.cmml" xref="alg1.3.3.m1.1.1.2.2.2">𝐱</ci><ci id="alg1.3.3.m1.1.1.2.2.3.cmml" xref="alg1.3.3.m1.1.1.2.2.3">𝑘</ci></apply><apply id="alg1.3.3.m1.1.1.2.3.cmml" xref="alg1.3.3.m1.1.1.2.3"><plus id="alg1.3.3.m1.1.1.2.3.1.cmml" xref="alg1.3.3.m1.1.1.2.3.1"></plus><ci id="alg1.3.3.m1.1.1.2.3.2.cmml" xref="alg1.3.3.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.3.3.m1.1.1.2.3.3.cmml" xref="alg1.3.3.m1.1.1.2.3.3">1</cn></apply></apply><csymbol cd="latexml" id="alg1.3.3.m1.1.1.3.cmml" xref="alg1.3.3.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.3.m1.1c">\mathbf{x}_{k}^{t+1}\leftarrow</annotation></semantics></math> <span id="alg1.4.4.1" class="ltx_text ltx_font_italic">Client<math id="alg1.4.4.1.m1.2" class="ltx_Math" alttext="(k,w^{t})" display="inline"><semantics id="alg1.4.4.1.m1.2a"><mrow id="alg1.4.4.1.m1.2.2.1" xref="alg1.4.4.1.m1.2.2.2.cmml"><mo stretchy="false" id="alg1.4.4.1.m1.2.2.1.2" xref="alg1.4.4.1.m1.2.2.2.cmml">(</mo><mi id="alg1.4.4.1.m1.1.1" xref="alg1.4.4.1.m1.1.1.cmml">k</mi><mo id="alg1.4.4.1.m1.2.2.1.3" xref="alg1.4.4.1.m1.2.2.2.cmml">,</mo><msup id="alg1.4.4.1.m1.2.2.1.1" xref="alg1.4.4.1.m1.2.2.1.1.cmml"><mi id="alg1.4.4.1.m1.2.2.1.1.2" xref="alg1.4.4.1.m1.2.2.1.1.2.cmml">w</mi><mi id="alg1.4.4.1.m1.2.2.1.1.3" xref="alg1.4.4.1.m1.2.2.1.1.3.cmml">t</mi></msup><mo stretchy="false" id="alg1.4.4.1.m1.2.2.1.4" xref="alg1.4.4.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.4.4.1.m1.2b"><interval closure="open" id="alg1.4.4.1.m1.2.2.2.cmml" xref="alg1.4.4.1.m1.2.2.1"><ci id="alg1.4.4.1.m1.1.1.cmml" xref="alg1.4.4.1.m1.1.1">𝑘</ci><apply id="alg1.4.4.1.m1.2.2.1.1.cmml" xref="alg1.4.4.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="alg1.4.4.1.m1.2.2.1.1.1.cmml" xref="alg1.4.4.1.m1.2.2.1.1">superscript</csymbol><ci id="alg1.4.4.1.m1.2.2.1.1.2.cmml" xref="alg1.4.4.1.m1.2.2.1.1.2">𝑤</ci><ci id="alg1.4.4.1.m1.2.2.1.1.3.cmml" xref="alg1.4.4.1.m1.2.2.1.1.3">𝑡</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.4.1.m1.2c">(k,w^{t})</annotation></semantics></math></span>
</div>
<div id="alg1.11.16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.11.16.1" class="ltx_text ltx_font_bold">if</span> <em id="alg1.11.16.2" class="ltx_emph ltx_font_italic">loss</em> <span id="alg1.11.16.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="alg1.11.17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.11.17.1" class="ltx_text ltx_font_bold">if</span> <em id="alg1.11.17.2" class="ltx_emph ltx_font_italic">sufficient</em> <span id="alg1.11.17.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="alg1.11.18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   retransfer(loss)
</div>
<div id="alg1.11.19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.11.19.1" class="ltx_text ltx_font_bold">else</span>
</div>
<div id="alg1.11.20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   setzero(loss)
</div>
<div id="alg1.11.21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="alg1.5.5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   Update model <math id="alg1.5.5.m1.1" class="ltx_Math" alttext="w^{t+1}" display="inline"><semantics id="alg1.5.5.m1.1a"><msup id="alg1.5.5.m1.1.1" xref="alg1.5.5.m1.1.1.cmml"><mi id="alg1.5.5.m1.1.1.2" xref="alg1.5.5.m1.1.1.2.cmml">w</mi><mrow id="alg1.5.5.m1.1.1.3" xref="alg1.5.5.m1.1.1.3.cmml"><mi id="alg1.5.5.m1.1.1.3.2" xref="alg1.5.5.m1.1.1.3.2.cmml">t</mi><mo id="alg1.5.5.m1.1.1.3.1" xref="alg1.5.5.m1.1.1.3.1.cmml">+</mo><mn id="alg1.5.5.m1.1.1.3.3" xref="alg1.5.5.m1.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="alg1.5.5.m1.1b"><apply id="alg1.5.5.m1.1.1.cmml" xref="alg1.5.5.m1.1.1"><csymbol cd="ambiguous" id="alg1.5.5.m1.1.1.1.cmml" xref="alg1.5.5.m1.1.1">superscript</csymbol><ci id="alg1.5.5.m1.1.1.2.cmml" xref="alg1.5.5.m1.1.1.2">𝑤</ci><apply id="alg1.5.5.m1.1.1.3.cmml" xref="alg1.5.5.m1.1.1.3"><plus id="alg1.5.5.m1.1.1.3.1.cmml" xref="alg1.5.5.m1.1.1.3.1"></plus><ci id="alg1.5.5.m1.1.1.3.2.cmml" xref="alg1.5.5.m1.1.1.3.2">𝑡</ci><cn type="integer" id="alg1.5.5.m1.1.1.3.3.cmml" xref="alg1.5.5.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.5.m1.1c">w^{t+1}</annotation></semantics></math> via aggregation algorithm 
</div>
<div id="alg1.6.6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   Return(<math id="alg1.6.6.m1.1" class="ltx_Math" alttext="w^{T}" display="inline"><semantics id="alg1.6.6.m1.1a"><msup id="alg1.6.6.m1.1.1" xref="alg1.6.6.m1.1.1.cmml"><mi id="alg1.6.6.m1.1.1.2" xref="alg1.6.6.m1.1.1.2.cmml">w</mi><mi id="alg1.6.6.m1.1.1.3" xref="alg1.6.6.m1.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.6.6.m1.1b"><apply id="alg1.6.6.m1.1.1.cmml" xref="alg1.6.6.m1.1.1"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.cmml" xref="alg1.6.6.m1.1.1">superscript</csymbol><ci id="alg1.6.6.m1.1.1.2.cmml" xref="alg1.6.6.m1.1.1.2">𝑤</ci><ci id="alg1.6.6.m1.1.1.3.cmml" xref="alg1.6.6.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.6.m1.1c">w^{T}</annotation></semantics></math>)

</div>
<div id="alg1.11.22" class="ltx_listingline">
<span id="alg1.11.22.1" class="ltx_text ltx_font_bold">thread</span> <em id="alg1.11.22.2" class="ltx_emph ltx_font_italic">Client</em><span id="alg1.11.22.3" class="ltx_text ltx_font_bold">:</span>
</div>
<div id="alg1.11.23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
send(sufficiencyReport)
</div>
<div id="alg1.8.8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.7.7.m1.1" class="ltx_Math" alttext="w_{k}^{t+1}\leftarrow E" display="inline"><semantics id="alg1.7.7.m1.1a"><mrow id="alg1.7.7.m1.1.1" xref="alg1.7.7.m1.1.1.cmml"><msubsup id="alg1.7.7.m1.1.1.2" xref="alg1.7.7.m1.1.1.2.cmml"><mi id="alg1.7.7.m1.1.1.2.2.2" xref="alg1.7.7.m1.1.1.2.2.2.cmml">w</mi><mi id="alg1.7.7.m1.1.1.2.2.3" xref="alg1.7.7.m1.1.1.2.2.3.cmml">k</mi><mrow id="alg1.7.7.m1.1.1.2.3" xref="alg1.7.7.m1.1.1.2.3.cmml"><mi id="alg1.7.7.m1.1.1.2.3.2" xref="alg1.7.7.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.7.7.m1.1.1.2.3.1" xref="alg1.7.7.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.7.7.m1.1.1.2.3.3" xref="alg1.7.7.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="alg1.7.7.m1.1.1.1" xref="alg1.7.7.m1.1.1.1.cmml">←</mo><mi id="alg1.7.7.m1.1.1.3" xref="alg1.7.7.m1.1.1.3.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.7.7.m1.1b"><apply id="alg1.7.7.m1.1.1.cmml" xref="alg1.7.7.m1.1.1"><ci id="alg1.7.7.m1.1.1.1.cmml" xref="alg1.7.7.m1.1.1.1">←</ci><apply id="alg1.7.7.m1.1.1.2.cmml" xref="alg1.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.7.7.m1.1.1.2.1.cmml" xref="alg1.7.7.m1.1.1.2">superscript</csymbol><apply id="alg1.7.7.m1.1.1.2.2.cmml" xref="alg1.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.7.7.m1.1.1.2.2.1.cmml" xref="alg1.7.7.m1.1.1.2">subscript</csymbol><ci id="alg1.7.7.m1.1.1.2.2.2.cmml" xref="alg1.7.7.m1.1.1.2.2.2">𝑤</ci><ci id="alg1.7.7.m1.1.1.2.2.3.cmml" xref="alg1.7.7.m1.1.1.2.2.3">𝑘</ci></apply><apply id="alg1.7.7.m1.1.1.2.3.cmml" xref="alg1.7.7.m1.1.1.2.3"><plus id="alg1.7.7.m1.1.1.2.3.1.cmml" xref="alg1.7.7.m1.1.1.2.3.1"></plus><ci id="alg1.7.7.m1.1.1.2.3.2.cmml" xref="alg1.7.7.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.7.7.m1.1.1.2.3.3.cmml" xref="alg1.7.7.m1.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.7.7.m1.1.1.3.cmml" xref="alg1.7.7.m1.1.1.3">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.7.m1.1c">w_{k}^{t+1}\leftarrow E</annotation></semantics></math> epochs of gradients <math id="alg1.8.8.m2.1" class="ltx_Math" alttext="\leftarrow w^{t}" display="inline"><semantics id="alg1.8.8.m2.1a"><mrow id="alg1.8.8.m2.1.1" xref="alg1.8.8.m2.1.1.cmml"><mi id="alg1.8.8.m2.1.1.2" xref="alg1.8.8.m2.1.1.2.cmml"></mi><mo stretchy="false" id="alg1.8.8.m2.1.1.1" xref="alg1.8.8.m2.1.1.1.cmml">←</mo><msup id="alg1.8.8.m2.1.1.3" xref="alg1.8.8.m2.1.1.3.cmml"><mi id="alg1.8.8.m2.1.1.3.2" xref="alg1.8.8.m2.1.1.3.2.cmml">w</mi><mi id="alg1.8.8.m2.1.1.3.3" xref="alg1.8.8.m2.1.1.3.3.cmml">t</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.8.8.m2.1b"><apply id="alg1.8.8.m2.1.1.cmml" xref="alg1.8.8.m2.1.1"><ci id="alg1.8.8.m2.1.1.1.cmml" xref="alg1.8.8.m2.1.1.1">←</ci><csymbol cd="latexml" id="alg1.8.8.m2.1.1.2.cmml" xref="alg1.8.8.m2.1.1.2">absent</csymbol><apply id="alg1.8.8.m2.1.1.3.cmml" xref="alg1.8.8.m2.1.1.3"><csymbol cd="ambiguous" id="alg1.8.8.m2.1.1.3.1.cmml" xref="alg1.8.8.m2.1.1.3">superscript</csymbol><ci id="alg1.8.8.m2.1.1.3.2.cmml" xref="alg1.8.8.m2.1.1.3.2">𝑤</ci><ci id="alg1.8.8.m2.1.1.3.3.cmml" xref="alg1.8.8.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.8.m2.1c">\leftarrow w^{t}</annotation></semantics></math> 
</div>
<div id="alg1.11.11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Return(<math id="alg1.9.9.m1.1" class="ltx_Math" alttext="\mathbf{x}_{k}^{t+1}" display="inline"><semantics id="alg1.9.9.m1.1a"><msubsup id="alg1.9.9.m1.1.1" xref="alg1.9.9.m1.1.1.cmml"><mi id="alg1.9.9.m1.1.1.2.2" xref="alg1.9.9.m1.1.1.2.2.cmml">𝐱</mi><mi id="alg1.9.9.m1.1.1.2.3" xref="alg1.9.9.m1.1.1.2.3.cmml">k</mi><mrow id="alg1.9.9.m1.1.1.3" xref="alg1.9.9.m1.1.1.3.cmml"><mi id="alg1.9.9.m1.1.1.3.2" xref="alg1.9.9.m1.1.1.3.2.cmml">t</mi><mo id="alg1.9.9.m1.1.1.3.1" xref="alg1.9.9.m1.1.1.3.1.cmml">+</mo><mn id="alg1.9.9.m1.1.1.3.3" xref="alg1.9.9.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.9.9.m1.1b"><apply id="alg1.9.9.m1.1.1.cmml" xref="alg1.9.9.m1.1.1"><csymbol cd="ambiguous" id="alg1.9.9.m1.1.1.1.cmml" xref="alg1.9.9.m1.1.1">superscript</csymbol><apply id="alg1.9.9.m1.1.1.2.cmml" xref="alg1.9.9.m1.1.1"><csymbol cd="ambiguous" id="alg1.9.9.m1.1.1.2.1.cmml" xref="alg1.9.9.m1.1.1">subscript</csymbol><ci id="alg1.9.9.m1.1.1.2.2.cmml" xref="alg1.9.9.m1.1.1.2.2">𝐱</ci><ci id="alg1.9.9.m1.1.1.2.3.cmml" xref="alg1.9.9.m1.1.1.2.3">𝑘</ci></apply><apply id="alg1.9.9.m1.1.1.3.cmml" xref="alg1.9.9.m1.1.1.3"><plus id="alg1.9.9.m1.1.1.3.1.cmml" xref="alg1.9.9.m1.1.1.3.1"></plus><ci id="alg1.9.9.m1.1.1.3.2.cmml" xref="alg1.9.9.m1.1.1.3.2">𝑡</ci><cn type="integer" id="alg1.9.9.m1.1.1.3.3.cmml" xref="alg1.9.9.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.9.m1.1c">\mathbf{x}_{k}^{t+1}</annotation></semantics></math>)  <math id="alg1.10.10.m2.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.10.10.m2.1a"><mo id="alg1.10.10.m2.1.1" xref="alg1.10.10.m2.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.10.10.m2.1b"><ci id="alg1.10.10.m2.1.1.cmml" xref="alg1.10.10.m2.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.10.m2.1c">\triangleright</annotation></semantics></math> <math id="alg1.11.11.m3.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="alg1.11.11.m3.1a"><mi id="alg1.11.11.m3.1.1" xref="alg1.11.11.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="alg1.11.11.m3.1b"><ci id="alg1.11.11.m3.1.1.cmml" xref="alg1.11.11.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.11.11.m3.1c">\mathbf{x}</annotation></semantics></math> <span id="alg1.11.11.1" class="ltx_text ltx_font_italic"> is algorithm specific value</span>

</div>
<div id="alg1.11.24" class="ltx_listingline">

</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.13.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>The skeleton of integrating TRA into general federated learning algorithms.</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To verify the performance of TRA, we redo the evaluations conducted in <a href="#S3.SS2" title="3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>.
We compare the performance of the algorithms limited by the threshold-based selection with the integrated algorithms. For realistic concern, we only consider nonconvex settings. Similarly with <a href="#S3.SS2" title="3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>, we consider three eligible ratios, i.e., 70%, 80%, and 90% which cause different degrees of biased client selection in threshold-based settings. For each eligible ratio, we consider a variety of packet loss ratios, i.e, 10%, 30%, and 50%, for the <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">insufficient</span> clients.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2105.03591/assets/x8.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="83" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S5.F8.3.2" class="ltx_text" style="font-size:90%;">Fairness performance of biased q-FedAvg and TRA-q-FedAvg on Synthetic(1,1) and Synthetic(2,2) datasets with 70%, 80%, and 90% eligible ratios. TRA-a-FedAvg-X% indicates the packet loss ratios (10%, 30%, 50%).</span></figcaption>
</figure>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2105.03591/assets/x9.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="93" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S5.F9.3.2" class="ltx_text" style="font-size:90%;">Personalization performance of biased pFedMe and TRA-pFedMe with 70%, 80%, and 90% eligible ratios. TRA-pFedMe-X% indicates the packet loss ratios (10%, 20%, 30%). We adapted the tested loss ratios according to the observed performance boundary.</span></figcaption>
</figure>
<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Aggregation</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">Via numerous tests, we find that the combination of TRA and q-FedAvg presents the best aggregation performance in the face of packet loss. As shown in <a href="#S4.F7" title="In 4 ThrowRightAway ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>, TRA-q-FedAvg outperforms biased-FedAvg and biased-q-FedAvg in all scenarios. With slightly longer convergence periods, TRA-q-FedAvg (10% loss ratio) improves the model accuracy on Synthetic(1,1) by 10.35%/6.69%, 8.44%/3.48%, and 9.31%/-0.79%, compared to biased-FedAvg and biased-q-FedAvg in 70%, 80%, and 90% eligible ratio scenarios, respectively. On Synthetic(2,2), the corresponding improvements are 9.88%/7.39%, 3.62%/1.62%, and 2.75%/-1.4%. In a word, when more than 10% clients have worse network than standard, TRA-q-FedAvg would considerably improve aggregated model accuracy over FedAvg and q-FedAvg using threshold-based selection. We reason that TRA-q-FedAvg presents such improvements thanks to both the features of TRA and q-FedAvg. TRA allows a wider selection of participants thus increasing the learning space with the cost of some data integrity. Meanwhile, q-FedAvg employs the idea of <math id="S5.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S5.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.1.m1.1c">\alpha</annotation></semantics></math>-fairness <cite class="ltx_cite ltx_citemacro_cite">Mo and Walrand (<a href="#bib.bib19" title="" class="ltx_ref">2000</a>)</cite> to give higher relative weights to the clients with higher losses. As such, q-FedAvg compensates for the effect of the packet loss due to TRA.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Fairness</h4>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">We utilize TRA-q-FedAvg to tackle the fairness degradation caused by biased client selection in <a href="#S3.T1" title="In Aggregation ‣ 3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>.
As shown in <a href="#S5.F8" title="In 5 Evaluation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">8</span></a>, TRA-q-FedAvg outperforms biased-q-FedAvg in most scenarios, and the superiority increases as the data heterogeneity increases and the eligible ratio decreases. <a href="#S5.T2" title="In Personalization ‣ 5 Evaluation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a> summarizes some numerical results and highlights the best performed algorithms in different scenarios. The results in other scenarios present similar pattern and thus are excluded due to space limit. Note that we use sample based results in <a href="#S4.F7" title="In 4 ThrowRightAway ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a> to
measure the accuracy with a higher granularity, while client based results in <a href="#S5.T2" title="In Personalization ‣ 5 Evaluation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a> focus on inter-client fairness. Thus two presented accuracies are different.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Personalization</h4>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p1.1" class="ltx_p">We integrate TRA with pFedMe to tackle the personalization performance degradation caused by biased client selection as shown in <a href="#S3.F4" title="In Personalization ‣ 3.2 Impacts ‣ 3 Problem Study ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>. As <a href="#S5.F9" title="In 5 Evaluation ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">9</span></a> depicts, TRA-pFedMe has accuracy of the personal model 1% lower than pFedMe on average, however outperforms pFedMe in global model accuracy by 20% at the most.</p>
</div>
<div id="S5.SS0.SSS0.Px3.p2" class="ltx_para ltx_noindent">
<svg id="S5.SS0.SSS0.Px3.p2.pic1" class="ltx_picture" height="71.52" overflow="visible" version="1.1" width="600"><g transform="translate(0,71.52) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.94 L 0 69.58 C 0 70.65 0.87 71.52 1.94 71.52 L 598.06 71.52 C 599.13 71.52 600 70.65 600 69.58 L 600 1.94 C 600 0.87 599.13 0 598.06 0 L 1.94 0 C 0.87 0 0 0.87 0 1.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.55 1.94 L 0.55 69.58 C 0.55 70.35 1.17 70.97 1.94 70.97 L 598.06 70.97 C 598.83 70.97 599.45 70.35 599.45 69.58 L 599.45 1.94 C 599.45 1.17 598.83 0.55 598.06 0.55 L 1.94 0.55 C 1.17 0.55 0.55 1.17 0.55 1.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 4.7 4.7)"><foreignObject width="590.59" height="62.11" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S5.SS0.SSS0.Px3.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:426.8pt;">
<span id="S5.SS0.SSS0.Px3.p2.pic1.1.1.1.1.1.1" class="ltx_p"><span id="S5.SS0.SSS0.Px3.p2.pic1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">Takeaway:</span> Integrating TRA with q-FedAvg enables learning from the entire sample space while mitigating the effect of packet loss by adaptively reweighting. As a result, it improves both convergence and fairness performances. TRA considerable improves the global performance of pFedMe compared to in threshold-based settings with a small cost of personalized model accuracy.</span>
</span></foreignObject></g></g></svg>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.3.2" class="ltx_text" style="font-size:90%;">Client based fairness performance of q-FedAvg with biased selection VS TRA-q-FedAvg with different packet loss ratios. The gray color highlights the best performance algorithms.</span></figcaption>
<div id="S5.T2.4" class="ltx_inline-block ltx_transformed_outer" style="width:263.3pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.6pt,9.0pt) scale(0.9,0.9) ;">
<table id="S5.T2.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.4.1.1.1" class="ltx_tr">
<th id="S5.T2.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Synthetic(1,1)/70%</span></th>
<th id="S5.T2.4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Average</span></th>
<th id="S5.T2.4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.4.1.1.1.3.1" class="ltx_text ltx_font_bold">Best/Worst 10%</span></th>
<th id="S5.T2.4.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.4.1.1.1.4.1" class="ltx_text ltx_font_bold">Variance</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.4.1.2.1" class="ltx_tr">
<td id="S5.T2.4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.2.1.1.1" class="ltx_text ltx_font_italic">q-FedAvg-biased</span></td>
<td id="S5.T2.4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">55.00%</td>
<td id="S5.T2.4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">100% / 0</td>
<td id="S5.T2.4.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">1439</td>
</tr>
<tr id="S5.T2.4.1.3.2" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S5.T2.4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.3.2.1.1" class="ltx_text ltx_font_italic" style="background-color:#E6E6E6;">TRA-q-FedAvg-10%</span></td>
<td id="S5.T2.4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.3.2.2.1" class="ltx_text" style="background-color:#E6E6E6;">61.63%</span></td>
<td id="S5.T2.4.1.3.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.3.2.3.1" class="ltx_text" style="background-color:#E6E6E6;">100% / 6.01%</span></td>
<td id="S5.T2.4.1.3.2.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.3.2.4.1" class="ltx_text" style="background-color:#E6E6E6;">1031</span></td>
</tr>
<tr id="S5.T2.4.1.4.3" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S5.T2.4.1.4.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.4.3.1.1" class="ltx_text ltx_font_italic" style="background-color:#E6E6E6;">TRA-q-FedAvg-30%</span></td>
<td id="S5.T2.4.1.4.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.4.3.2.1" class="ltx_text" style="background-color:#E6E6E6;">59.44%</span></td>
<td id="S5.T2.4.1.4.3.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.4.3.3.1" class="ltx_text" style="background-color:#E6E6E6;">100% / 4.11%</span></td>
<td id="S5.T2.4.1.4.3.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.4.3.4.1" class="ltx_text" style="background-color:#E6E6E6;">1021</span></td>
</tr>
<tr id="S5.T2.4.1.5.4" class="ltx_tr">
<td id="S5.T2.4.1.5.4.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.5.4.1.1" class="ltx_text ltx_font_italic">TRA-q-FedAvg-50%</span></td>
<td id="S5.T2.4.1.5.4.2" class="ltx_td ltx_align_left ltx_border_t">50.99%</td>
<td id="S5.T2.4.1.5.4.3" class="ltx_td ltx_align_left ltx_border_t">99.97% / 0</td>
<td id="S5.T2.4.1.5.4.4" class="ltx_td ltx_align_left ltx_border_t">1220</td>
</tr>
<tr id="S5.T2.4.1.6.5" class="ltx_tr">
<td id="S5.T2.4.1.6.5.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.6.5.1.1" class="ltx_text ltx_font_bold">Synthetic(2,2)/70%</span></td>
<td id="S5.T2.4.1.6.5.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.6.5.2.1" class="ltx_text ltx_font_bold">Average</span></td>
<td id="S5.T2.4.1.6.5.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.6.5.3.1" class="ltx_text ltx_font_bold">Best/Worst 10%</span></td>
<td id="S5.T2.4.1.6.5.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.6.5.4.1" class="ltx_text ltx_font_bold">Variance</span></td>
</tr>
<tr id="S5.T2.4.1.7.6" class="ltx_tr">
<td id="S5.T2.4.1.7.6.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.7.6.1.1" class="ltx_text ltx_font_italic">q-FedAvg-biased</span></td>
<td id="S5.T2.4.1.7.6.2" class="ltx_td ltx_align_left ltx_border_t">62.34%</td>
<td id="S5.T2.4.1.7.6.3" class="ltx_td ltx_align_left ltx_border_t">100% / 0</td>
<td id="S5.T2.4.1.7.6.4" class="ltx_td ltx_align_left ltx_border_t">1584</td>
</tr>
<tr id="S5.T2.4.1.8.7" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S5.T2.4.1.8.7.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.8.7.1.1" class="ltx_text ltx_font_italic" style="background-color:#E6E6E6;">TRA-q-FedAvg-10%</span></td>
<td id="S5.T2.4.1.8.7.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.8.7.2.1" class="ltx_text" style="background-color:#E6E6E6;">69.72%</span></td>
<td id="S5.T2.4.1.8.7.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.8.7.3.1" class="ltx_text" style="background-color:#E6E6E6;">100% / 9.81%</span></td>
<td id="S5.T2.4.1.8.7.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.8.7.4.1" class="ltx_text" style="background-color:#E6E6E6;">870</span></td>
</tr>
<tr id="S5.T2.4.1.9.8" class="ltx_tr">
<td id="S5.T2.4.1.9.8.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.4.1.9.8.1.1" class="ltx_text ltx_font_italic">TRA-q-FedAvg-30%</span></td>
<td id="S5.T2.4.1.9.8.2" class="ltx_td ltx_align_left ltx_border_t">55.38%</td>
<td id="S5.T2.4.1.9.8.3" class="ltx_td ltx_align_left ltx_border_t">99.69% / 0</td>
<td id="S5.T2.4.1.9.8.4" class="ltx_td ltx_align_left ltx_border_t">1109</td>
</tr>
<tr id="S5.T2.4.1.10.9" class="ltx_tr">
<td id="S5.T2.4.1.10.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t"><span id="S5.T2.4.1.10.9.1.1" class="ltx_text ltx_font_italic">TRA-q-FedAvg-50%</span></td>
<td id="S5.T2.4.1.10.9.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">55.00%</td>
<td id="S5.T2.4.1.10.9.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">99.98% / 2.81%</td>
<td id="S5.T2.4.1.10.9.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">1125</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>

<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Limitation.</h4>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">While TRA-q-FedAvg performs fairly well, we do notice via empirical evaluations that TRA itself does not improve the performance of FedAvg in the face of packet loss. We reason this is because the lightweight recalculation (Eq. (<a href="#S4.E1" title="Equation 1 ‣ 4 ThrowRightAway ‣ Loss Tolerant Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>)) is not as efficient as q-FedAvg in terms of reweighting. We also note that the performance of TRA can be sensitive to the hyperparameters when combining with some algorithms, e.g., pFedMe. Although we have not uncovered the detailed reasons, we infer it is also due to the limited efficiency of the recalculation.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Future directions.</h4>

<div id="S6.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p1.1" class="ltx_p">Through empirical evaluations, we find that the lightweight TRA works well in lots of scenarios. However we also note that its performance is sensitive to the hyperparameters some times. Besides TRA needs further improvement to guarantee personalized model accuracy while keeping the advantage of global model performance when integrating with personalization algorithms. Therefore next we plan to conduct theoretical analysis of the algorithm and explore its potential with comprehensive optimization problem formulation and solution for bad network tolerance.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this work, we investigate loss-tolerant federated learning (LT-FL). Through trace-driven analysis, we find that the commonly assumed limit network challenge is overstated but indeed can cause biased client selection in threshold-based selection settings. We show the bias has severe impacts on different aspects of federated learning. We propose TRA as an complementary solution which allows all clients to participate while toleraing the potential losses of the bad-network clients, who would be filtered out in threshold-based settings. As such TRA balances the model performance and fairness. Integrating TRA with state-of-the-art algorithms shows outperforming performances on aggregation, fairness, and personalization in most scenarios.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barocas <span id="bib.bib1.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Solon Barocas, Moritz Hardt, and Arvind Narayanan.

</span>
<span class="ltx_bibblock">Fairness in machine learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic">NIPS Tutorial</span>, 1, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz <span id="bib.bib2.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečnỳ, Stefano
Mazzocchi, H Brendan McMahan, et al.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1902.01046</span>, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas <span id="bib.bib3.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Jakub Konečny, H Brendan McMahan, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Expanding the reach of federated learning by reducing client resource
requirements.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.07210</span>, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">CCPA [2021]</span>
<span class="ltx_bibblock">
CCPA.

</span>
<span class="ltx_bibblock">California consumer privacy act.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.caprivacy.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.caprivacy.org/</a>, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen <span id="bib.bib5.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao.

</span>
<span class="ltx_bibblock">Fedhealth: A federated transfer learning framework for wearable
healthcare.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic">IEEE Intelligent Systems</span>, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Commission [2020]</span>
<span class="ltx_bibblock">
Federal Communications Commission.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Measuring Broadband America Mobile Data</span>, 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.fcc.gov/reports-research/reports/measuring-broadband-america/measuring-broadband-america-mobile-data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.fcc.gov/reports-research/reports/measuring-broadband-america/measuring-broadband-america-mobile-data</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Custers <span id="bib.bib7.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Bart Custers, Alan M Sears, Francien Dechesne, Ilina Georgieva, Tommaso Tani,
and Simone Van der Hof.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic">EU Personal Data Protection in Policy and Practice</span>.

</span>
<span class="ltx_bibblock">Springer, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinh <span id="bib.bib8.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Canh T Dinh, Nguyen H Tran, and Tuan Dung Nguyen.

</span>
<span class="ltx_bibblock">Personalized federated learning with moreau envelopes.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual
Conference on Neural Information Processing Systems 2020, NeurIPS 2020</span>,
2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong <span id="bib.bib9.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Yuanrui Dong, Peng Zhao, Hanqiao Yu, Cong Zhao, and Shusen Yang.

</span>
<span class="ltx_bibblock">Cdc: Classification driven compression for bandwidth efficient
edge-cloud collaborative deep learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic">Proceedings of the Twenty-Ninth International Joint Conference
on Artificial Intelligence, IJCAI 20</span>, pages 3378–3384, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fallah <span id="bib.bib10.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.

</span>
<span class="ltx_bibblock">Personalized federated learning: A meta-learning approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.07948</span>, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Boli Fang, Miao Jiang, Pei-yi Cheng, Jerry Shen, and Yi Fang.

</span>
<span class="ltx_bibblock">Achieving outcome fairness in machine learning models for social
decision problems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.2.1" class="ltx_text ltx_font_italic">Proceedings of the Twenty-Ninth International Joint
Conference on Artificial Intelligence, IJCAI-20</span>, pages 444–450.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy <span id="bib.bib12.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
Stich, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.3.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ <span id="bib.bib13.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2016]</span>
<span class="ltx_bibblock">
Jakub Konečnỳ, H Brendan McMahan, Felix X Yu, Peter Richtárik,
Ananda Theertha Suresh, and Dave Bacon.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1610.05492</span>, 2016.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib14.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith.

</span>
<span class="ltx_bibblock">Fair resource allocation in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.3.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations, ICLR
2019</span>, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim <span id="bib.bib15.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Wei Yang Bryan Lim, Nguyen Cong Luong, Dinh Thai Hoang, Yutao Jiao, Ying-Chang
Liang, Qiang Yang, Dusit Niyato, and Chunyan Miao.

</span>
<span class="ltx_bibblock">Federated learning in mobile edge networks: A comprehensive survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</span>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin <span id="bib.bib16.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Frank Po-Chen Lin, Christopher G Brinton, and Nicolo Michelusi.

</span>
<span class="ltx_bibblock">Federated learning with communication delay in edge networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2008.09323</span>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu <span id="bib.bib17.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Xinyi Xu, Qian Wang, and Han Yu.

</span>
<span class="ltx_bibblock">Collaborative fairness in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.3.1" class="ltx_text ltx_font_italic">Federated Learning</span>, pages 189–204. Springer, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan <span id="bib.bib18.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.3.1" class="ltx_text ltx_font_italic">Artificial Intelligence and Statistics</span>. PMLR, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo and Walrand [2000]</span>
<span class="ltx_bibblock">
Jeonghoon Mo and Jean Walrand.

</span>
<span class="ltx_bibblock">Fair end-to-end window-based congestion control.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on networking</span>, 2000.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohri <span id="bib.bib20.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">Agnostic federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.3.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning, ICML 2019</span>,
pages 4615–4625, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishio and Yonetani [2019]</span>
<span class="ltx_bibblock">
Takayuki Nishio and Ryo Yonetani.

</span>
<span class="ltx_bibblock">Client selection for federated learning with heterogeneous resources
in mobile edge.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">ICC</span>. IEEE, 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Openmined [2021]</span>
<span class="ltx_bibblock">
Openmined.

</span>
<span class="ltx_bibblock">Openmined.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.openmined.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.openmined.org/</a>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia <span id="bib.bib23.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Jiacheng Xia, Gaoxiong Zeng, Junxue Zhang, Weiyan Wang, Wei Bai, Junchen Jiang,
and Kai Chen.

</span>
<span class="ltx_bibblock">Rethinking transport layer design for distributed machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.3.1" class="ltx_text ltx_font_italic">APNet</span>, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2105.03590" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2105.03591" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2105.03591">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2105.03591" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2105.03592" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 00:49:18 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
