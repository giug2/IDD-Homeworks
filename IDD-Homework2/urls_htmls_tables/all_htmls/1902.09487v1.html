<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1902.09487] MUREL: Multimodal Relational Reasoning for Visual Question Answering</title><meta property="og:description" content="Multimodal attentional networks are currently state-of-the-art models for Visual Question Answering (VQA) tasks involving real images. Although attention allows to focus on the visual content relevant to the question, â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MUREL: Multimodal Relational Reasoning for Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MUREL: Multimodal Relational Reasoning for Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1902.09487">

<!--Generated on Thu Mar  7 13:58:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MUREL: Multimodal Relational Reasoning for Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Remi Cadene <sup id="id8.8.id1" class="ltx_sup"><span id="id8.8.id1.1" class="ltx_text ltx_font_italic">1</span></sup>
â€ƒâ€ƒHedi Ben-younes <sup id="id9.9.id2" class="ltx_sup"><span id="id9.9.id2.1" class="ltx_text ltx_font_italic">1,2</span></sup><span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
â€ƒâ€ƒMatthieu Cord <sup id="id10.10.id3" class="ltx_sup">1</sup>
â€ƒâ€ƒNicolas Thome <sup id="id11.11.id4" class="ltx_sup">3</sup>

<br class="ltx_break"><sup id="id12.12.id5" class="ltx_sup">1</sup> Sorbonne UniversitÃ©, CNRS, LIP6, 4 place Jussieu, 75005 Paris

<br class="ltx_break"><sup id="id13.13.id6" class="ltx_sup">2</sup> Heuritech, 248 rue du Faubourg Saint-Antoine, 75012 Paris

<br class="ltx_break"><sup id="id14.14.id7" class="ltx_sup">3</sup> Conservatoire National des Arts et MÃ©tiers, 75003 Paris

<br class="ltx_break"><span id="id15.15.id8" class="ltx_text ltx_font_typewriter" style="font-size:90%;">remi.cadene@lip6.fr,
hedi.ben-younes@lip6.fr,
matthieu.cord@lip6.fr, nicolas.thome@cnam.fr</span>
</span><span class="ltx_author_notes">Equal contribution</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id16.id1" class="ltx_p">Multimodal attentional networks are currently state-of-the-art models for Visual Question Answering (VQA) tasks involving real images. Although attention allows to focus on the visual content relevant to the question, this simple mechanism is arguably insufficient to model complex reasoning features required for VQA or other high-level tasks.</p>
<p id="id17.id2" class="ltx_p">In this paper, we propose MuRel, a multimodal relational network which is learned end-to-end to reason over real images. Our first contribution is the introduction of the MuRel cell, an atomic reasoning primitive representing interactions between question and image regions by a rich vectorial representation, and modeling region relations with pairwise combinations.
Secondly, we incorporate the cell into a full MuRel network, which progressively refines visual and question interactions, and can be leveraged to define visualization schemes finer than mere attention maps.</p>
<p id="id18.id3" class="ltx_p">We validate the relevance of our approach with various ablation studies, and show its superiority to attention-based methods on three datasets: VQA 2.0, VQA-CP v2 and TDIUC. Our final MuRel network is competitive to or outperforms state-of-the-art results in this challenging context.</p>
<p id="id19.id4" class="ltx_p">Our code is available: <a target="_blank" href="https://github.com/Cadene/murel.bootstrap.pytorch" title="" class="ltx_ref ltx_href ltx_font_typewriter">github.com/Cadene/murel.bootstrap.pytorch</a></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Since the success of Convolutional Neural Networks (ConvNets) at the ILSVRC 2012 challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, Deep Learning has become the baseline approach for any computer vision problem.
Beyond their outstanding performances for perception tasks, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span> classification or detection, deep ConvNets have also been successfully used for new artificial intelligence tasks like Visual Question Answering (VQA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. VQA requires a high level understanding of images and questions, and is often considered to be a good proxy for visual reasoning.
However, it is not straightforward to use ConvNets in a context where a high level of reasoning is required. The question of leveraging the perception power of deep CNNs for reasoning tasks is crucial if we want to go further in visual scene understanding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/1902.09487/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="174" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span> <span id="S1.F1.2.1" class="ltx_text ltx_font_bold">Visualization of the MuRel approach.</span>
Our MuRel network for VQA is an iterative process based on a rich vectorial representation between the question and visual information explicitly modeling pairwise region relations. MuRel is thus able to express complex analysis primitives beyond attention maps: here the two regions corresponding to the head and the donuts are selected based on their visual cues and semantic relations to properly answer the question â€what is she eating?â€ </figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">It is also not trivial to define nor evaluate a modelâ€™s capacity to reason about the visual modality in VQA. To fill this need, synthetic datasets have been released, <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">e.g.</span> CLEVRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, which specific structure controls the exact reasoning primitives required to give the answer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
However, methods that tackle the VQA problem on real data struggle to integrate this explicit reasoning procedure. Instead, state-of-the-art methods often rely on the much simpler attentional framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Despite its effectiveness, this mechanism restricts visual reasoning to a soft selection of regions that are relevant to answer the question.
This arguably limits the modeling power of such models to bridge the gap between the perceptual strengths of ConvNets and the high-level reasoning demand for VQA.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we propose MuRel, a multimodal relational network that goes one step further towards reasoning about questions and images.
Â Our first contribution is to introduce the MuRel cell, an atomic reasoning primitive enabling to represent rich interactions between question and image regions. It is based on a vectorial representation that explicitly models relations between regions.
Our second contribution is to embed this MuRel cell into an iterative reasoning process, which progressively refines the internal network representation to answer the question.
The rationale of MuRel is illustrated in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>: for the question â€what is she eatingâ€, our model focuses on two main regions (the head and the donut) with important visual cues and semantic relations between them to provide the correct answer (â€donutâ€).
The visual reasoning of our MuRel system is formed by this multi-step relational module that discards useless information to focus on the relevant regions.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In the experiments, we show additional results for explaining the behaviour of MuRel. We also provide various ablative studies to validate the relevance of the MuRel cell and the iterative reasoning process, and show that MuRel is highly competitive or even outperforms state-of-the-art results on three of the most common VQA datasets: the VQA 2.0 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, VQA-CP v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and TDIUC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work and contributions</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Recently, the deep learning community started to tackle complex visual reasoning problems such as relationship detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, object recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, abstract reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> or visual causality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, while more theoretical work attempt to formalize relational reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">But the most popular image reasoning task is certainly Visual Question Answering (VQA), which has been a hot research topic for the last five years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.
Since the seminal work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, different sub-problems have been identified for the resolution of VQA. In particular, explicit reasoning techniques have been developed relying on the synthetic CLEVR dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Meanwhile, real-data VQA systems are the test bed for more practical approaches based on high quality visual representations or multimodal fusion schemes.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Visual reasoning</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">The research efforts towards VQA models that are able to reason about a visual scene is mainly conducted using the CLEVR dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
This artificial dataset provides questions that require spatial and relational reasoning on simple images coming from a visual world with low variability.
An important line of work attempts to solve this task through explicit reasoning. In such methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, a neural network reads the question and generates a program, corresponding to a graph of elementary neural operations that process the image.
However, there are two major downsides to these techniques. First, their performance strongly depends on whether or not program annotations are used to learn the program generator;
and second, they can be matched or surpassed by simpler models that implicitly learn to reason without requiring program annotation.
In particular, FiLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> modulates the visual feature map with an affine transformation whose parameters depend on the question.
In more recent work, the MAC network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> draws inspiration from the Model-View-Controller paradigm to design the trainable MAC cell on which the network iterates.
Finally, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, they reason over all the possible pairs of objects in the picture, thus introducing relationship modeling in visual question answering.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">VQA on real data</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">An important part of the research in VQA is focused on designing functions that can represent high-level correlations between two vector spaces.
Among these multimodal fusion algorithms, the most effective ones use second order (or higher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>) interactions, made tractable through sketching methods
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, or with more success using the tensor decomposition framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
<div id="S2.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p2.1" class="ltx_p">This line of work is often considered orthogonal to visual reasoning contributions.
In a setup involving real data, complex methods such as explicit or relational reasoning are much more challenging to implement than with artificial images and questions.
This is certainly why the most widely used reasoning framework involves soft attention mechanisms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Given a question, these models assign an importance score to each region, and use them to weight-sum pool the visual representations. Multiple attention maps (also called <span id="S2.SS0.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_italic">glimpses</span>) can even be computed in parallel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> or sequentially <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. More complex attention strategies have been explored, such as the Structured Attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, where a locally-connected graphical structure is considered to infer the region saliency scores.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> also leverages a graphical structure between regions to address weaknesses of the soft-attention mechanism, improving the VQA modelâ€™s ability to count.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, the image representation is computed using pairwise semantic attention and spatial graph convolutions.
The soft attention framework is questioned in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, where regions are hardly selected based on the norm of their feature. Finally, recent work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> simultaneously attends over regions and word tokens through a bilinear attention network.</p>
</div>
<div id="S2.SS0.SSS0.Px2.p3" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p3.1" class="ltx_p">Importantly, the type of visual features used to feed the VQA system has an large impact on performance.
While early work have been using fixed-grid representation given by a fully-convolutional network (such as ResNet-152 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>), performance can be improved using predictions from an object detector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Recently, a crucial component in the VQA Challenge 2018 winning entry was the mix of multiple types of visual features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">MuRel contributions</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">In this work, we move away from the classical attention framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> widely used in real-data VQA systems.
Instead, we use a vectorial representation, more expressive than scalar attention maps, to model the semantic interaction between each regionâ€™s visual content and the question.
In addition, we include a notion of spatial and semantic context in the representations by representing pairs of image regions through interactions between their visual embeddings and spatial coordinates.
Differently than the approach followed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> where a locally connected graph structure is built, we use the relations between all possible pairs of regions.</p>
</div>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p2.1" class="ltx_p">Our MuRel network embodies an iterative process with inspiration from works driven by the synthetic reasoning CLEVR dataset, <span id="S2.SS0.SSS0.Px3.p2.1.1" class="ltx_text ltx_font_italic">e.g.</span>, MAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> or FiLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, which we adapt to the real data VQA purpose. In particular, we improve the interactions between image regions and questions by using richer bilinear fusion models and by explicitly incorporating relations between regions.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>MuRel approach</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.5" class="ltx_p">Our VQA approach is depicted in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Given an image <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="v\in\mathcal{I}" display="inline"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">v</mi><mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">â„</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><in id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"></in><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">ğ‘£</ci><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">v\in\mathcal{I}</annotation></semantics></math> and a question <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="q\in\mathcal{Q}" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">q</mi><mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">ğ’¬</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><in id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></in><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">ğ‘</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">ğ’¬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">q\in\mathcal{Q}</annotation></semantics></math> about this image, we want to predict an answer <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="\hat{a}\in\mathcal{A}" display="inline"><semantics id="S3.p1.3.m3.1a"><mrow id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml"><mi id="S3.p1.3.m3.1.1.2.2" xref="S3.p1.3.m3.1.1.2.2.cmml">a</mi><mo id="S3.p1.3.m3.1.1.2.1" xref="S3.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mo id="S3.p1.3.m3.1.1.1" xref="S3.p1.3.m3.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">ğ’œ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><in id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1"></in><apply id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2"><ci id="S3.p1.3.m3.1.1.2.1.cmml" xref="S3.p1.3.m3.1.1.2.1">^</ci><ci id="S3.p1.3.m3.1.1.2.2.cmml" xref="S3.p1.3.m3.1.1.2.2">ğ‘</ci></apply><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">ğ’œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">\hat{a}\in\mathcal{A}</annotation></semantics></math> that matches the ground truth answer <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="a^{\star}" display="inline"><semantics id="S3.p1.4.m4.1a"><msup id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml"><mi id="S3.p1.4.m4.1.1.2" xref="S3.p1.4.m4.1.1.2.cmml">a</mi><mo id="S3.p1.4.m4.1.1.3" xref="S3.p1.4.m4.1.1.3.cmml">â‹†</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><apply id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p1.4.m4.1.1.1.cmml" xref="S3.p1.4.m4.1.1">superscript</csymbol><ci id="S3.p1.4.m4.1.1.2.cmml" xref="S3.p1.4.m4.1.1.2">ğ‘</ci><ci id="S3.p1.4.m4.1.1.3.cmml" xref="S3.p1.4.m4.1.1.3">â‹†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">a^{\star}</annotation></semantics></math>. As very common in VQA, the prediction <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S3.p1.5.m5.1a"><mover accent="true" id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml"><mi id="S3.p1.5.m5.1.1.2" xref="S3.p1.5.m5.1.1.2.cmml">a</mi><mo id="S3.p1.5.m5.1.1.1" xref="S3.p1.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><apply id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1"><ci id="S3.p1.5.m5.1.1.1.cmml" xref="S3.p1.5.m5.1.1.1">^</ci><ci id="S3.p1.5.m5.1.1.2.cmml" xref="S3.p1.5.m5.1.1.2">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">\hat{a}</annotation></semantics></math> is given by classification scores:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\hat{a}=\arg\!\max_{a\in\mathcal{A}}p_{\theta}(a|v,q)" display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mover accent="true" id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><mi id="S3.E1.m1.3.3.3.2" xref="S3.E1.m1.3.3.3.2.cmml">a</mi><mo id="S3.E1.m1.3.3.3.1" xref="S3.E1.m1.3.3.3.1.cmml">^</mo></mover><mo id="S3.E1.m1.3.3.2" xref="S3.E1.m1.3.3.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.cmml"><mrow id="S3.E1.m1.3.3.1.3" xref="S3.E1.m1.3.3.1.3.cmml"><mi id="S3.E1.m1.3.3.1.3.1" xref="S3.E1.m1.3.3.1.3.1.cmml">arg</mi><mo id="S3.E1.m1.3.3.1.3a" xref="S3.E1.m1.3.3.1.3.cmml">â¡</mo><mrow id="S3.E1.m1.3.3.1.3.2" xref="S3.E1.m1.3.3.1.3.2.cmml"><munder id="S3.E1.m1.3.3.1.3.2.1" xref="S3.E1.m1.3.3.1.3.2.1.cmml"><mi id="S3.E1.m1.3.3.1.3.2.1.2" xref="S3.E1.m1.3.3.1.3.2.1.2.cmml">max</mi><mrow id="S3.E1.m1.3.3.1.3.2.1.3" xref="S3.E1.m1.3.3.1.3.2.1.3.cmml"><mi id="S3.E1.m1.3.3.1.3.2.1.3.2" xref="S3.E1.m1.3.3.1.3.2.1.3.2.cmml">a</mi><mo id="S3.E1.m1.3.3.1.3.2.1.3.1" xref="S3.E1.m1.3.3.1.3.2.1.3.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.3.3.1.3.2.1.3.3" xref="S3.E1.m1.3.3.1.3.2.1.3.3.cmml">ğ’œ</mi></mrow></munder><mo lspace="0.167em" id="S3.E1.m1.3.3.1.3.2a" xref="S3.E1.m1.3.3.1.3.2.cmml">â¡</mo><msub id="S3.E1.m1.3.3.1.3.2.2" xref="S3.E1.m1.3.3.1.3.2.2.cmml"><mi id="S3.E1.m1.3.3.1.3.2.2.2" xref="S3.E1.m1.3.3.1.3.2.2.2.cmml">p</mi><mi id="S3.E1.m1.3.3.1.3.2.2.3" xref="S3.E1.m1.3.3.1.3.2.2.3.cmml">Î¸</mi></msub></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml">a</mi><mo fence="false" id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml">|</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.3.1.cmml"><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">v</mi><mo id="S3.E1.m1.3.3.1.1.1.1.3.2.1" xref="S3.E1.m1.3.3.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">q</mi></mrow></mrow><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><eq id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.2"></eq><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><ci id="S3.E1.m1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.3.1">^</ci><ci id="S3.E1.m1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.3.2">ğ‘</ci></apply><apply id="S3.E1.m1.3.3.1.cmml" xref="S3.E1.m1.3.3.1"><times id="S3.E1.m1.3.3.1.2.cmml" xref="S3.E1.m1.3.3.1.2"></times><apply id="S3.E1.m1.3.3.1.3.cmml" xref="S3.E1.m1.3.3.1.3"><arg id="S3.E1.m1.3.3.1.3.1.cmml" xref="S3.E1.m1.3.3.1.3.1"></arg><apply id="S3.E1.m1.3.3.1.3.2.cmml" xref="S3.E1.m1.3.3.1.3.2"><apply id="S3.E1.m1.3.3.1.3.2.1.cmml" xref="S3.E1.m1.3.3.1.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.3.2.1.1.cmml" xref="S3.E1.m1.3.3.1.3.2.1">subscript</csymbol><max id="S3.E1.m1.3.3.1.3.2.1.2.cmml" xref="S3.E1.m1.3.3.1.3.2.1.2"></max><apply id="S3.E1.m1.3.3.1.3.2.1.3.cmml" xref="S3.E1.m1.3.3.1.3.2.1.3"><in id="S3.E1.m1.3.3.1.3.2.1.3.1.cmml" xref="S3.E1.m1.3.3.1.3.2.1.3.1"></in><ci id="S3.E1.m1.3.3.1.3.2.1.3.2.cmml" xref="S3.E1.m1.3.3.1.3.2.1.3.2">ğ‘</ci><ci id="S3.E1.m1.3.3.1.3.2.1.3.3.cmml" xref="S3.E1.m1.3.3.1.3.2.1.3.3">ğ’œ</ci></apply></apply><apply id="S3.E1.m1.3.3.1.3.2.2.cmml" xref="S3.E1.m1.3.3.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.3.2.2.1.cmml" xref="S3.E1.m1.3.3.1.3.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.3.2.2.2.cmml" xref="S3.E1.m1.3.3.1.3.2.2.2">ğ‘</ci><ci id="S3.E1.m1.3.3.1.3.2.2.3.cmml" xref="S3.E1.m1.3.3.1.3.2.2.3">ğœƒ</ci></apply></apply></apply><apply id="S3.E1.m1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1">conditional</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2">ğ‘</ci><list id="S3.E1.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ‘£</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğ‘</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\hat{a}=\arg\!\max_{a\in\mathcal{A}}p_{\theta}(a|v,q)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.12" class="ltx_p">where <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="p_{\theta}" display="inline"><semantics id="S3.p2.1.m1.1a"><msub id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">p</mi><mi id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">ğ‘</ci><ci id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">p_{\theta}</annotation></semantics></math> is our trainable model. In our system, the image is represented by a set of vectors <math id="S3.p2.2.m2.3" class="ltx_Math" alttext="\{\bm{v}_{i}\}_{i\in[1,N]}" display="inline"><semantics id="S3.p2.2.m2.3a"><msub id="S3.p2.2.m2.3.3" xref="S3.p2.2.m2.3.3.cmml"><mrow id="S3.p2.2.m2.3.3.1.1" xref="S3.p2.2.m2.3.3.1.2.cmml"><mo stretchy="false" id="S3.p2.2.m2.3.3.1.1.2" xref="S3.p2.2.m2.3.3.1.2.cmml">{</mo><msub id="S3.p2.2.m2.3.3.1.1.1" xref="S3.p2.2.m2.3.3.1.1.1.cmml"><mi id="S3.p2.2.m2.3.3.1.1.1.2" xref="S3.p2.2.m2.3.3.1.1.1.2.cmml">ğ’—</mi><mi id="S3.p2.2.m2.3.3.1.1.1.3" xref="S3.p2.2.m2.3.3.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.p2.2.m2.3.3.1.1.3" xref="S3.p2.2.m2.3.3.1.2.cmml">}</mo></mrow><mrow id="S3.p2.2.m2.2.2.2" xref="S3.p2.2.m2.2.2.2.cmml"><mi id="S3.p2.2.m2.2.2.2.4" xref="S3.p2.2.m2.2.2.2.4.cmml">i</mi><mo id="S3.p2.2.m2.2.2.2.3" xref="S3.p2.2.m2.2.2.2.3.cmml">âˆˆ</mo><mrow id="S3.p2.2.m2.2.2.2.5.2" xref="S3.p2.2.m2.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.p2.2.m2.2.2.2.5.2.1" xref="S3.p2.2.m2.2.2.2.5.1.cmml">[</mo><mn id="S3.p2.2.m2.1.1.1.1" xref="S3.p2.2.m2.1.1.1.1.cmml">1</mn><mo id="S3.p2.2.m2.2.2.2.5.2.2" xref="S3.p2.2.m2.2.2.2.5.1.cmml">,</mo><mi id="S3.p2.2.m2.2.2.2.2" xref="S3.p2.2.m2.2.2.2.2.cmml">N</mi><mo stretchy="false" id="S3.p2.2.m2.2.2.2.5.2.3" xref="S3.p2.2.m2.2.2.2.5.1.cmml">]</mo></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.3b"><apply id="S3.p2.2.m2.3.3.cmml" xref="S3.p2.2.m2.3.3"><csymbol cd="ambiguous" id="S3.p2.2.m2.3.3.2.cmml" xref="S3.p2.2.m2.3.3">subscript</csymbol><set id="S3.p2.2.m2.3.3.1.2.cmml" xref="S3.p2.2.m2.3.3.1.1"><apply id="S3.p2.2.m2.3.3.1.1.1.cmml" xref="S3.p2.2.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.3.3.1.1.1.1.cmml" xref="S3.p2.2.m2.3.3.1.1.1">subscript</csymbol><ci id="S3.p2.2.m2.3.3.1.1.1.2.cmml" xref="S3.p2.2.m2.3.3.1.1.1.2">ğ’—</ci><ci id="S3.p2.2.m2.3.3.1.1.1.3.cmml" xref="S3.p2.2.m2.3.3.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.p2.2.m2.2.2.2.cmml" xref="S3.p2.2.m2.2.2.2"><in id="S3.p2.2.m2.2.2.2.3.cmml" xref="S3.p2.2.m2.2.2.2.3"></in><ci id="S3.p2.2.m2.2.2.2.4.cmml" xref="S3.p2.2.m2.2.2.2.4">ğ‘–</ci><interval closure="closed" id="S3.p2.2.m2.2.2.2.5.1.cmml" xref="S3.p2.2.m2.2.2.2.5.2"><cn type="integer" id="S3.p2.2.m2.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1.1">1</cn><ci id="S3.p2.2.m2.2.2.2.2.cmml" xref="S3.p2.2.m2.2.2.2.2">ğ‘</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.3c">\{\bm{v}_{i}\}_{i\in[1,N]}</annotation></semantics></math>, where each <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="\bm{v}_{i}\in\mathbb{R}^{d_{v}}" display="inline"><semantics id="S3.p2.3.m3.1a"><mrow id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml"><msub id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml"><mi id="S3.p2.3.m3.1.1.2.2" xref="S3.p2.3.m3.1.1.2.2.cmml">ğ’—</mi><mi id="S3.p2.3.m3.1.1.2.3" xref="S3.p2.3.m3.1.1.2.3.cmml">i</mi></msub><mo id="S3.p2.3.m3.1.1.1" xref="S3.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml"><mi id="S3.p2.3.m3.1.1.3.2" xref="S3.p2.3.m3.1.1.3.2.cmml">â„</mi><msub id="S3.p2.3.m3.1.1.3.3" xref="S3.p2.3.m3.1.1.3.3.cmml"><mi id="S3.p2.3.m3.1.1.3.3.2" xref="S3.p2.3.m3.1.1.3.3.2.cmml">d</mi><mi id="S3.p2.3.m3.1.1.3.3.3" xref="S3.p2.3.m3.1.1.3.3.3.cmml">v</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1"><in id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1.1"></in><apply id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.p2.3.m3.1.1.2.1.cmml" xref="S3.p2.3.m3.1.1.2">subscript</csymbol><ci id="S3.p2.3.m3.1.1.2.2.cmml" xref="S3.p2.3.m3.1.1.2.2">ğ’—</ci><ci id="S3.p2.3.m3.1.1.2.3.cmml" xref="S3.p2.3.m3.1.1.2.3">ğ‘–</ci></apply><apply id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.p2.3.m3.1.1.3.1.cmml" xref="S3.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.p2.3.m3.1.1.3.2.cmml" xref="S3.p2.3.m3.1.1.3.2">â„</ci><apply id="S3.p2.3.m3.1.1.3.3.cmml" xref="S3.p2.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.p2.3.m3.1.1.3.3.1.cmml" xref="S3.p2.3.m3.1.1.3.3">subscript</csymbol><ci id="S3.p2.3.m3.1.1.3.3.2.cmml" xref="S3.p2.3.m3.1.1.3.3.2">ğ‘‘</ci><ci id="S3.p2.3.m3.1.1.3.3.3.cmml" xref="S3.p2.3.m3.1.1.3.3.3">ğ‘£</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">\bm{v}_{i}\in\mathbb{R}^{d_{v}}</annotation></semantics></math> corresponds to an object detected in the picture. We also use the spatial coordinates of each region <math id="S3.p2.4.m4.4" class="ltx_Math" alttext="\bm{b}_{i}~{}=~{}[x,y,w,h]" display="inline"><semantics id="S3.p2.4.m4.4a"><mrow id="S3.p2.4.m4.4.5" xref="S3.p2.4.m4.4.5.cmml"><msub id="S3.p2.4.m4.4.5.2" xref="S3.p2.4.m4.4.5.2.cmml"><mi id="S3.p2.4.m4.4.5.2.2" xref="S3.p2.4.m4.4.5.2.2.cmml">ğ’ƒ</mi><mi id="S3.p2.4.m4.4.5.2.3" xref="S3.p2.4.m4.4.5.2.3.cmml">i</mi></msub><mo lspace="0.608em" rspace="0.608em" id="S3.p2.4.m4.4.5.1" xref="S3.p2.4.m4.4.5.1.cmml">=</mo><mrow id="S3.p2.4.m4.4.5.3.2" xref="S3.p2.4.m4.4.5.3.1.cmml"><mo stretchy="false" id="S3.p2.4.m4.4.5.3.2.1" xref="S3.p2.4.m4.4.5.3.1.cmml">[</mo><mi id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml">x</mi><mo id="S3.p2.4.m4.4.5.3.2.2" xref="S3.p2.4.m4.4.5.3.1.cmml">,</mo><mi id="S3.p2.4.m4.2.2" xref="S3.p2.4.m4.2.2.cmml">y</mi><mo id="S3.p2.4.m4.4.5.3.2.3" xref="S3.p2.4.m4.4.5.3.1.cmml">,</mo><mi id="S3.p2.4.m4.3.3" xref="S3.p2.4.m4.3.3.cmml">w</mi><mo id="S3.p2.4.m4.4.5.3.2.4" xref="S3.p2.4.m4.4.5.3.1.cmml">,</mo><mi id="S3.p2.4.m4.4.4" xref="S3.p2.4.m4.4.4.cmml">h</mi><mo stretchy="false" id="S3.p2.4.m4.4.5.3.2.5" xref="S3.p2.4.m4.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.4b"><apply id="S3.p2.4.m4.4.5.cmml" xref="S3.p2.4.m4.4.5"><eq id="S3.p2.4.m4.4.5.1.cmml" xref="S3.p2.4.m4.4.5.1"></eq><apply id="S3.p2.4.m4.4.5.2.cmml" xref="S3.p2.4.m4.4.5.2"><csymbol cd="ambiguous" id="S3.p2.4.m4.4.5.2.1.cmml" xref="S3.p2.4.m4.4.5.2">subscript</csymbol><ci id="S3.p2.4.m4.4.5.2.2.cmml" xref="S3.p2.4.m4.4.5.2.2">ğ’ƒ</ci><ci id="S3.p2.4.m4.4.5.2.3.cmml" xref="S3.p2.4.m4.4.5.2.3">ğ‘–</ci></apply><list id="S3.p2.4.m4.4.5.3.1.cmml" xref="S3.p2.4.m4.4.5.3.2"><ci id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1">ğ‘¥</ci><ci id="S3.p2.4.m4.2.2.cmml" xref="S3.p2.4.m4.2.2">ğ‘¦</ci><ci id="S3.p2.4.m4.3.3.cmml" xref="S3.p2.4.m4.3.3">ğ‘¤</ci><ci id="S3.p2.4.m4.4.4.cmml" xref="S3.p2.4.m4.4.4">â„</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.4c">\bm{b}_{i}~{}=~{}[x,y,w,h]</annotation></semantics></math>, where <math id="S3.p2.5.m5.2" class="ltx_Math" alttext="(x,y)" display="inline"><semantics id="S3.p2.5.m5.2a"><mrow id="S3.p2.5.m5.2.3.2" xref="S3.p2.5.m5.2.3.1.cmml"><mo stretchy="false" id="S3.p2.5.m5.2.3.2.1" xref="S3.p2.5.m5.2.3.1.cmml">(</mo><mi id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml">x</mi><mo id="S3.p2.5.m5.2.3.2.2" xref="S3.p2.5.m5.2.3.1.cmml">,</mo><mi id="S3.p2.5.m5.2.2" xref="S3.p2.5.m5.2.2.cmml">y</mi><mo stretchy="false" id="S3.p2.5.m5.2.3.2.3" xref="S3.p2.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.2b"><interval closure="open" id="S3.p2.5.m5.2.3.1.cmml" xref="S3.p2.5.m5.2.3.2"><ci id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1">ğ‘¥</ci><ci id="S3.p2.5.m5.2.2.cmml" xref="S3.p2.5.m5.2.2">ğ‘¦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.2c">(x,y)</annotation></semantics></math> are the coordinates of the top-left point of the box, and <math id="S3.p2.6.m6.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.p2.6.m6.1a"><mi id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><ci id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">h</annotation></semantics></math> and <math id="S3.p2.7.m7.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p2.7.m7.1a"><mi id="S3.p2.7.m7.1.1" xref="S3.p2.7.m7.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p2.7.m7.1b"><ci id="S3.p2.7.m7.1.1.cmml" xref="S3.p2.7.m7.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.7.m7.1c">w</annotation></semantics></math> correspond to the height and the width of the box. Note that <math id="S3.p2.8.m8.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.p2.8.m8.1a"><mi id="S3.p2.8.m8.1.1" xref="S3.p2.8.m8.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.p2.8.m8.1b"><ci id="S3.p2.8.m8.1.1.cmml" xref="S3.p2.8.m8.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.8.m8.1c">x</annotation></semantics></math> and <math id="S3.p2.9.m9.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p2.9.m9.1a"><mi id="S3.p2.9.m9.1.1" xref="S3.p2.9.m9.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p2.9.m9.1b"><ci id="S3.p2.9.m9.1.1.cmml" xref="S3.p2.9.m9.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.9.m9.1c">w</annotation></semantics></math> (respectively <math id="S3.p2.10.m10.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.p2.10.m10.1a"><mi id="S3.p2.10.m10.1.1" xref="S3.p2.10.m10.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.p2.10.m10.1b"><ci id="S3.p2.10.m10.1.1.cmml" xref="S3.p2.10.m10.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.10.m10.1c">y</annotation></semantics></math> and <math id="S3.p2.11.m11.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.p2.11.m11.1a"><mi id="S3.p2.11.m11.1.1" xref="S3.p2.11.m11.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.p2.11.m11.1b"><ci id="S3.p2.11.m11.1.1.cmml" xref="S3.p2.11.m11.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.11.m11.1c">h</annotation></semantics></math>) are normalized by the width (resp. height) of the image.
For the question, we use a gated recurrent unit network to provide a sentence embedding <math id="S3.p2.12.m12.1" class="ltx_Math" alttext="\bm{q}\in\mathbb{R}^{d_{q}}" display="inline"><semantics id="S3.p2.12.m12.1a"><mrow id="S3.p2.12.m12.1.1" xref="S3.p2.12.m12.1.1.cmml"><mi id="S3.p2.12.m12.1.1.2" xref="S3.p2.12.m12.1.1.2.cmml">ğ’’</mi><mo id="S3.p2.12.m12.1.1.1" xref="S3.p2.12.m12.1.1.1.cmml">âˆˆ</mo><msup id="S3.p2.12.m12.1.1.3" xref="S3.p2.12.m12.1.1.3.cmml"><mi id="S3.p2.12.m12.1.1.3.2" xref="S3.p2.12.m12.1.1.3.2.cmml">â„</mi><msub id="S3.p2.12.m12.1.1.3.3" xref="S3.p2.12.m12.1.1.3.3.cmml"><mi id="S3.p2.12.m12.1.1.3.3.2" xref="S3.p2.12.m12.1.1.3.3.2.cmml">d</mi><mi id="S3.p2.12.m12.1.1.3.3.3" xref="S3.p2.12.m12.1.1.3.3.3.cmml">q</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.12.m12.1b"><apply id="S3.p2.12.m12.1.1.cmml" xref="S3.p2.12.m12.1.1"><in id="S3.p2.12.m12.1.1.1.cmml" xref="S3.p2.12.m12.1.1.1"></in><ci id="S3.p2.12.m12.1.1.2.cmml" xref="S3.p2.12.m12.1.1.2">ğ’’</ci><apply id="S3.p2.12.m12.1.1.3.cmml" xref="S3.p2.12.m12.1.1.3"><csymbol cd="ambiguous" id="S3.p2.12.m12.1.1.3.1.cmml" xref="S3.p2.12.m12.1.1.3">superscript</csymbol><ci id="S3.p2.12.m12.1.1.3.2.cmml" xref="S3.p2.12.m12.1.1.3.2">â„</ci><apply id="S3.p2.12.m12.1.1.3.3.cmml" xref="S3.p2.12.m12.1.1.3.3"><csymbol cd="ambiguous" id="S3.p2.12.m12.1.1.3.3.1.cmml" xref="S3.p2.12.m12.1.1.3.3">subscript</csymbol><ci id="S3.p2.12.m12.1.1.3.3.2.cmml" xref="S3.p2.12.m12.1.1.3.3.2">ğ‘‘</ci><ci id="S3.p2.12.m12.1.1.3.3.3.cmml" xref="S3.p2.12.m12.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.12.m12.1c">\bm{q}\in\mathbb{R}^{d_{q}}</annotation></semantics></math>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In SectionÂ <a href="#S3.SS1" title="3.1 MuRel cell â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, we present the MuRel cell, a neural module that learns to perform elementary reasoning operations by blending question information into the set of spatially-grounded visual representations. Next, in SectionÂ <a href="#S3.SS2" title="3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we leverage the power of this cell using the MuRel network, a VQA architecture that iterates through a MuRel cell to reason about the scene with respect to a question.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>MuRel cell</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.3" class="ltx_p">The MuRel cell takes as input a bag of <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">N</annotation></semantics></math> visual features <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\bm{s}_{i}\in\mathbb{R}^{d_{v}}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><msub id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2.2" xref="S3.SS1.p1.2.m2.1.1.2.2.cmml">ğ’”</mi><mi id="S3.SS1.p1.2.m2.1.1.2.3" xref="S3.SS1.p1.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">â„</mi><msub id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.3.2" xref="S3.SS1.p1.2.m2.1.1.3.3.2.cmml">d</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.3.cmml">v</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><apply id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2.2">ğ’”</ci><ci id="S3.SS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.p1.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3">ğ‘£</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\bm{s}_{i}\in\mathbb{R}^{d_{v}}</annotation></semantics></math>, along with their bounding box coordinates <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\bm{b}_{i}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">ğ’ƒ</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ’ƒ</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\bm{b}_{i}</annotation></semantics></math>.
As shown in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.1 MuRel cell â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, it is a residual function consisting of two modules. First, an efficient bilinear fusion module merges question and region feature vectors to provide a local multimodal embedding. This fusion is directly followed by a pairwise modeling component, designed to update each multimodal representation with respect to its own spatial and visual context.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/1902.09487/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> <span id="S3.F2.18.1" class="ltx_text ltx_font_bold">MuRel cell.</span>
In the MuRel cell, the bilinear fusion represents rich and fine-grained interactions between question and region vectors <math id="S3.F2.9.m1.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.F2.9.m1.1b"><mi id="S3.F2.9.m1.1.1" xref="S3.F2.9.m1.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.F2.9.m1.1c"><ci id="S3.F2.9.m1.1.1.cmml" xref="S3.F2.9.m1.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.9.m1.1d">\bm{q}</annotation></semantics></math> and <math id="S3.F2.10.m2.1" class="ltx_Math" alttext="\bm{s}_{i}" display="inline"><semantics id="S3.F2.10.m2.1b"><msub id="S3.F2.10.m2.1.1" xref="S3.F2.10.m2.1.1.cmml"><mi id="S3.F2.10.m2.1.1.2" xref="S3.F2.10.m2.1.1.2.cmml">ğ’”</mi><mi id="S3.F2.10.m2.1.1.3" xref="S3.F2.10.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.10.m2.1c"><apply id="S3.F2.10.m2.1.1.cmml" xref="S3.F2.10.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.10.m2.1.1.1.cmml" xref="S3.F2.10.m2.1.1">subscript</csymbol><ci id="S3.F2.10.m2.1.1.2.cmml" xref="S3.F2.10.m2.1.1.2">ğ’”</ci><ci id="S3.F2.10.m2.1.1.3.cmml" xref="S3.F2.10.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.10.m2.1d">\bm{s}_{i}</annotation></semantics></math>. All the resulting multimodal vectors <math id="S3.F2.11.m3.1" class="ltx_Math" alttext="\bm{m}_{i}" display="inline"><semantics id="S3.F2.11.m3.1b"><msub id="S3.F2.11.m3.1.1" xref="S3.F2.11.m3.1.1.cmml"><mi id="S3.F2.11.m3.1.1.2" xref="S3.F2.11.m3.1.1.2.cmml">ğ’</mi><mi id="S3.F2.11.m3.1.1.3" xref="S3.F2.11.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.11.m3.1c"><apply id="S3.F2.11.m3.1.1.cmml" xref="S3.F2.11.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.11.m3.1.1.1.cmml" xref="S3.F2.11.m3.1.1">subscript</csymbol><ci id="S3.F2.11.m3.1.1.2.cmml" xref="S3.F2.11.m3.1.1.2">ğ’</ci><ci id="S3.F2.11.m3.1.1.3.cmml" xref="S3.F2.11.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.11.m3.1d">\bm{m}_{i}</annotation></semantics></math> pass through a pairwise modeling block to provide a context-aware embedding <math id="S3.F2.12.m4.1" class="ltx_Math" alttext="\bm{x}_{i}" display="inline"><semantics id="S3.F2.12.m4.1b"><msub id="S3.F2.12.m4.1.1" xref="S3.F2.12.m4.1.1.cmml"><mi id="S3.F2.12.m4.1.1.2" xref="S3.F2.12.m4.1.1.2.cmml">ğ’™</mi><mi id="S3.F2.12.m4.1.1.3" xref="S3.F2.12.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.12.m4.1c"><apply id="S3.F2.12.m4.1.1.cmml" xref="S3.F2.12.m4.1.1"><csymbol cd="ambiguous" id="S3.F2.12.m4.1.1.1.cmml" xref="S3.F2.12.m4.1.1">subscript</csymbol><ci id="S3.F2.12.m4.1.1.2.cmml" xref="S3.F2.12.m4.1.1.2">ğ’™</ci><ci id="S3.F2.12.m4.1.1.3.cmml" xref="S3.F2.12.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.12.m4.1d">\bm{x}_{i}</annotation></semantics></math> per region.
The cellâ€™s output <math id="S3.F2.13.m5.1" class="ltx_Math" alttext="\hat{\bm{s}}_{i}" display="inline"><semantics id="S3.F2.13.m5.1b"><msub id="S3.F2.13.m5.1.1" xref="S3.F2.13.m5.1.1.cmml"><mover accent="true" id="S3.F2.13.m5.1.1.2" xref="S3.F2.13.m5.1.1.2.cmml"><mi id="S3.F2.13.m5.1.1.2.2" xref="S3.F2.13.m5.1.1.2.2.cmml">ğ’”</mi><mo id="S3.F2.13.m5.1.1.2.1" xref="S3.F2.13.m5.1.1.2.1.cmml">^</mo></mover><mi id="S3.F2.13.m5.1.1.3" xref="S3.F2.13.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.13.m5.1c"><apply id="S3.F2.13.m5.1.1.cmml" xref="S3.F2.13.m5.1.1"><csymbol cd="ambiguous" id="S3.F2.13.m5.1.1.1.cmml" xref="S3.F2.13.m5.1.1">subscript</csymbol><apply id="S3.F2.13.m5.1.1.2.cmml" xref="S3.F2.13.m5.1.1.2"><ci id="S3.F2.13.m5.1.1.2.1.cmml" xref="S3.F2.13.m5.1.1.2.1">^</ci><ci id="S3.F2.13.m5.1.1.2.2.cmml" xref="S3.F2.13.m5.1.1.2.2">ğ’”</ci></apply><ci id="S3.F2.13.m5.1.1.3.cmml" xref="S3.F2.13.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.13.m5.1d">\hat{\bm{s}}_{i}</annotation></semantics></math> is finally computed as a sum between <math id="S3.F2.14.m6.1" class="ltx_Math" alttext="{\bm{s}_{i}}" display="inline"><semantics id="S3.F2.14.m6.1b"><msub id="S3.F2.14.m6.1.1" xref="S3.F2.14.m6.1.1.cmml"><mi id="S3.F2.14.m6.1.1.2" xref="S3.F2.14.m6.1.1.2.cmml">ğ’”</mi><mi id="S3.F2.14.m6.1.1.3" xref="S3.F2.14.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.14.m6.1c"><apply id="S3.F2.14.m6.1.1.cmml" xref="S3.F2.14.m6.1.1"><csymbol cd="ambiguous" id="S3.F2.14.m6.1.1.1.cmml" xref="S3.F2.14.m6.1.1">subscript</csymbol><ci id="S3.F2.14.m6.1.1.2.cmml" xref="S3.F2.14.m6.1.1.2">ğ’”</ci><ci id="S3.F2.14.m6.1.1.3.cmml" xref="S3.F2.14.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.14.m6.1d">{\bm{s}_{i}}</annotation></semantics></math> and <math id="S3.F2.15.m7.1" class="ltx_Math" alttext="\bm{x}_{i}" display="inline"><semantics id="S3.F2.15.m7.1b"><msub id="S3.F2.15.m7.1.1" xref="S3.F2.15.m7.1.1.cmml"><mi id="S3.F2.15.m7.1.1.2" xref="S3.F2.15.m7.1.1.2.cmml">ğ’™</mi><mi id="S3.F2.15.m7.1.1.3" xref="S3.F2.15.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.15.m7.1c"><apply id="S3.F2.15.m7.1.1.cmml" xref="S3.F2.15.m7.1.1"><csymbol cd="ambiguous" id="S3.F2.15.m7.1.1.1.cmml" xref="S3.F2.15.m7.1.1">subscript</csymbol><ci id="S3.F2.15.m7.1.1.2.cmml" xref="S3.F2.15.m7.1.1.2">ğ’™</ci><ci id="S3.F2.15.m7.1.1.3.cmml" xref="S3.F2.15.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.15.m7.1d">\bm{x}_{i}</annotation></semantics></math>, acting as residual function of <math id="S3.F2.16.m8.1" class="ltx_Math" alttext="{\bm{s}_{i}}" display="inline"><semantics id="S3.F2.16.m8.1b"><msub id="S3.F2.16.m8.1.1" xref="S3.F2.16.m8.1.1.cmml"><mi id="S3.F2.16.m8.1.1.2" xref="S3.F2.16.m8.1.1.2.cmml">ğ’”</mi><mi id="S3.F2.16.m8.1.1.3" xref="S3.F2.16.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.16.m8.1c"><apply id="S3.F2.16.m8.1.1.cmml" xref="S3.F2.16.m8.1.1"><csymbol cd="ambiguous" id="S3.F2.16.m8.1.1.1.cmml" xref="S3.F2.16.m8.1.1">subscript</csymbol><ci id="S3.F2.16.m8.1.1.2.cmml" xref="S3.F2.16.m8.1.1.2">ğ’”</ci><ci id="S3.F2.16.m8.1.1.3.cmml" xref="S3.F2.16.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.16.m8.1d">{\bm{s}_{i}}</annotation></semantics></math>.</figcaption>
</figure>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Multimodal fusion</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.3" class="ltx_p">We want to include question information within each visual representation <math id="S3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\bm{s}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">\bm{s}_{i}</annotation></semantics></math>.
Multiple multimodal fusion strategies have been recently proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> to model the relevant interactions between two modalities. One of the most efficient technique is the one proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, based on the Tucker decomposition of third-order tensors.
This bilinear fusion model learns to focus on the relevant correlations between input dimensions. It models rich and fine-grained multimodal interactions, while keeping a relatively low number of parameters.
Each input vector <math id="S3.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\bm{s}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">\bm{s}_{i}</annotation></semantics></math> is fused with the question embedding <math id="S3.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b"><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">\bm{q}</annotation></semantics></math> using the same bilinear fusion:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.4" class="ltx_Math" alttext="\bm{m}_{i}=\operatorname*{B}\left(\bm{s}_{i},\bm{q};\Theta\right)" display="block"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><msub id="S3.E2.m1.4.4.3" xref="S3.E2.m1.4.4.3.cmml"><mi id="S3.E2.m1.4.4.3.2" xref="S3.E2.m1.4.4.3.2.cmml">ğ’</mi><mi id="S3.E2.m1.4.4.3.3" xref="S3.E2.m1.4.4.3.3.cmml">i</mi></msub><mo rspace="0.1389em" id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1" xref="S3.E2.m1.4.4.1.2.cmml"><mo lspace="0.1389em" rspace="0em" id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">B</mo><mrow id="S3.E2.m1.4.4.1.1.1" xref="S3.E2.m1.4.4.1.2.cmml"><mo id="S3.E2.m1.4.4.1.1.1.2" xref="S3.E2.m1.4.4.1.2.cmml">(</mo><msub id="S3.E2.m1.4.4.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.2.cmml">ğ’”</mi><mi id="S3.E2.m1.4.4.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.4.4.1.1.1.3" xref="S3.E2.m1.4.4.1.2.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">ğ’’</mi><mo id="S3.E2.m1.4.4.1.1.1.4" xref="S3.E2.m1.4.4.1.2.cmml">;</mo><mi mathvariant="normal" id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">Î˜</mi><mo id="S3.E2.m1.4.4.1.1.1.5" xref="S3.E2.m1.4.4.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><eq id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"></eq><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.1.cmml" xref="S3.E2.m1.4.4.3">subscript</csymbol><ci id="S3.E2.m1.4.4.3.2.cmml" xref="S3.E2.m1.4.4.3.2">ğ’</ci><ci id="S3.E2.m1.4.4.3.3.cmml" xref="S3.E2.m1.4.4.3.3">ğ‘–</ci></apply><apply id="S3.E2.m1.4.4.1.2.cmml" xref="S3.E2.m1.4.4.1.1"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">B</ci><apply id="S3.E2.m1.4.4.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2">ğ’”</ci><ci id="S3.E2.m1.4.4.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3">ğ‘–</ci></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ğ’’</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">Î˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\bm{m}_{i}=\operatorname*{B}\left(\bm{s}_{i},\bm{q};\Theta\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS0.Px1.p1.11" class="ltx_p">where <math id="S3.SS1.SSS0.Px1.p1.4.m1.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.4.m1.1a"><mi mathvariant="normal" id="S3.SS1.SSS0.Px1.p1.4.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m1.1.1.cmml">Î˜</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.4.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m1.1.1">Î˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m1.1c">\Theta</annotation></semantics></math> are the trainable parameters of the fusion module. Each dimension <math id="S3.SS1.SSS0.Px1.p1.5.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.5.m2.1a"><mi id="S3.SS1.SSS0.Px1.p1.5.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m2.1b"><ci id="S3.SS1.SSS0.Px1.p1.5.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m2.1c">m</annotation></semantics></math> of <math id="S3.SS1.SSS0.Px1.p1.6.m3.1" class="ltx_Math" alttext="\bm{m}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.6.m3.1a"><msub id="S3.SS1.SSS0.Px1.p1.6.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.6.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p1.6.m3.1.1.2.cmml">ğ’</mi><mi id="S3.SS1.SSS0.Px1.p1.6.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p1.6.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.6.m3.1b"><apply id="S3.SS1.SSS0.Px1.p1.6.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.6.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.6.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m3.1.1.2">ğ’</ci><ci id="S3.SS1.SSS0.Px1.p1.6.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.6.m3.1c">\bm{m}_{i}</annotation></semantics></math> can be written as a bilinear function in the form <math id="S3.SS1.SSS0.Px1.p1.7.m4.5" class="ltx_Math" alttext="\sum_{s,q}w^{s,q,m}\bm{s}_{i}^{s}\bm{q}^{q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.7.m4.5a"><mrow id="S3.SS1.SSS0.Px1.p1.7.m4.5.6" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.cmml"><msub id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1.cmml"><mo id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1.2.cmml">âˆ‘</mo><mrow id="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.4" xref="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m4.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m4.1.1.1.1.cmml">s</mi><mo id="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.4.1" xref="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.2.cmml">q</mi></mrow></msub><mrow id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.cmml"><msup id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2.2.cmml">w</mi><mrow id="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.5" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.4.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m4.3.3.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m4.3.3.1.1.cmml">s</mi><mo id="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.5.1" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.4.cmml">,</mo><mi id="S3.SS1.SSS0.Px1.p1.7.m4.4.4.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.4.4.2.2.cmml">q</mi><mo id="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.5.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.4.cmml">,</mo><mi id="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.3" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.3.cmml">m</mi></mrow></msup><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.1" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.1.cmml">â€‹</mo><msubsup id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.3.cmml">i</mi><mi id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.3" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.3.cmml">s</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.1a" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.1.cmml">â€‹</mo><msup id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.2" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.2.cmml">ğ’’</mi><mi id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.3" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.3.cmml">q</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.7.m4.5b"><apply id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6"><apply id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1">subscript</csymbol><sum id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.1.2"></sum><list id="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.4"><ci id="S3.SS1.SSS0.Px1.p1.7.m4.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.1.1.1.1">ğ‘ </ci><ci id="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.2.2.2.2">ğ‘</ci></list></apply><apply id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2"><times id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.1"></times><apply id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.2.2">ğ‘¤</ci><list id="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.4.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.5"><ci id="S3.SS1.SSS0.Px1.p1.7.m4.3.3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.3.3.1.1">ğ‘ </ci><ci id="S3.SS1.SSS0.Px1.p1.7.m4.4.4.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.4.4.2.2">ğ‘</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.5.3.3">ğ‘š</ci></list></apply><apply id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3">superscript</csymbol><apply id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.2.3">ğ‘–</ci></apply><ci id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.3.3">ğ‘ </ci></apply><apply id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.2">ğ’’</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m4.5.6.2.4.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.7.m4.5c">\sum_{s,q}w^{s,q,m}\bm{s}_{i}^{s}\bm{q}^{q}</annotation></semantics></math>. Thanks to the Tucker decomposition, the tensor <math id="S3.SS1.SSS0.Px1.p1.8.m5.4" class="ltx_Math" alttext="\{w_{s,q,m}\}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.8.m5.4a"><mrow id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.2.cmml">{</mo><msub id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1.2.cmml">w</mi><mrow id="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.5" xref="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.4.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m5.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m5.1.1.1.1.cmml">s</mi><mo id="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.5.1" xref="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.4.cmml">,</mo><mi id="S3.SS1.SSS0.Px1.p1.8.m5.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.8.m5.2.2.2.2.cmml">q</mi><mo id="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.5.2" xref="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.4.cmml">,</mo><mi id="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.3" xref="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.3.cmml">m</mi></mrow></msub><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.8.m5.4b"><set id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1"><apply id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.4.4.1.1.2">ğ‘¤</ci><list id="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.4.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.5"><ci id="S3.SS1.SSS0.Px1.p1.8.m5.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.1.1.1.1">ğ‘ </ci><ci id="S3.SS1.SSS0.Px1.p1.8.m5.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.2.2.2.2">ğ‘</ci><ci id="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m5.3.3.3.3">ğ‘š</ci></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.8.m5.4c">\{w_{s,q,m}\}</annotation></semantics></math> is factorized into the list of parameters <math id="S3.SS1.SSS0.Px1.p1.9.m6.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.9.m6.1a"><mi mathvariant="normal" id="S3.SS1.SSS0.Px1.p1.9.m6.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m6.1.1.cmml">Î˜</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.9.m6.1b"><ci id="S3.SS1.SSS0.Px1.p1.9.m6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m6.1.1">Î˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.9.m6.1c">\Theta</annotation></semantics></math>. We set the number of dimensions in <math id="S3.SS1.SSS0.Px1.p1.10.m7.1" class="ltx_Math" alttext="\bm{m}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.10.m7.1a"><msub id="S3.SS1.SSS0.Px1.p1.10.m7.1.1" xref="S3.SS1.SSS0.Px1.p1.10.m7.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.10.m7.1.1.2" xref="S3.SS1.SSS0.Px1.p1.10.m7.1.1.2.cmml">ğ’</mi><mi id="S3.SS1.SSS0.Px1.p1.10.m7.1.1.3" xref="S3.SS1.SSS0.Px1.p1.10.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.10.m7.1b"><apply id="S3.SS1.SSS0.Px1.p1.10.m7.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.10.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.10.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m7.1.1.2">ğ’</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m7.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.10.m7.1c">\bm{m}_{i}</annotation></semantics></math> to <math id="S3.SS1.SSS0.Px1.p1.11.m8.1" class="ltx_Math" alttext="d_{v}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.11.m8.1a"><msub id="S3.SS1.SSS0.Px1.p1.11.m8.1.1" xref="S3.SS1.SSS0.Px1.p1.11.m8.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.11.m8.1.1.2" xref="S3.SS1.SSS0.Px1.p1.11.m8.1.1.2.cmml">d</mi><mi id="S3.SS1.SSS0.Px1.p1.11.m8.1.1.3" xref="S3.SS1.SSS0.Px1.p1.11.m8.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.11.m8.1b"><apply id="S3.SS1.SSS0.Px1.p1.11.m8.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.11.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m8.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.11.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m8.1.1.2">ğ‘‘</ci><ci id="S3.SS1.SSS0.Px1.p1.11.m8.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m8.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.11.m8.1c">d_{v}</annotation></semantics></math> to facilitate the use of residual connections throughout our architecture.</p>
</div>
<div id="S3.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p2.3" class="ltx_p">In classical attention models, the fusion between image region and question features <math id="S3.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\bm{s}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p2.1.m1.1a"><mi id="S3.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p2.1.m1.1.1.cmml">ğ’”</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p2.1.m1.1b"><ci id="S3.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p2.1.m1.1.1">ğ’”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p2.1.m1.1c">\bm{s}</annotation></semantics></math> and <math id="S3.SS1.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p2.2.m2.1a"><mi id="S3.SS1.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p2.2.m2.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p2.2.m2.1b"><ci id="S3.SS1.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p2.2.m2.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p2.2.m2.1c">\bm{q}</annotation></semantics></math> only learns to encode whether a region is relevant.
In the MuRel cell, the local multimodal information is represented within a richer vectorial form <math id="S3.SS1.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\bm{m}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p2.3.m3.1a"><msub id="S3.SS1.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p2.3.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p2.3.m3.1.1.2.cmml">ğ’</mi><mi id="S3.SS1.SSS0.Px1.p2.3.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p2.3.m3.1b"><apply id="S3.SS1.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p2.3.m3.1.1.2">ğ’</ci><ci id="S3.SS1.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p2.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p2.3.m3.1c">\bm{m}_{i}</annotation></semantics></math> which can encode more complex correlations between both modalities. This allows to store more specific information about what precise characteristic of a particular region is important in a given textual context.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pairwise interactions</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.7" class="ltx_p">To answer certain types of question, it can be necessary to reason over multiple object that interact together. More generally, we want each representation to be aware of the spatial and semantic context around it.
Given that our features are structured as a bag of localized vectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, modeling the visual context of each region is not straightforward. Similarly to the recent work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, we opt for a pairwise relationship modeling where each region receives a message based on its relations to its neighbours.
In their work, a regionâ€™s neighbours correspond to the <math id="S3.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">K</annotation></semantics></math> most similar regions, whereas in the MuRel cell the neighbourhood is composed of every region in the image.
Besides, instead of using scalar pairwise attention and graph convolutions with Gaussian kernels as they do, we merge spatial and semantic representations to build relationship vectors.
In particular, we compute a context vector <math id="S3.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\check{\bm{e}}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mover accent="true" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2.cmml">ğ’†</mi><mo id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.1.cmml">Ë‡</mo></mover><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><apply id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2"><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.1">Ë‡</ci><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2">ğ’†</ci></apply><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.2.m2.1c">\check{\bm{e}}_{i}</annotation></semantics></math> for every region. It consists in an aggregation of all the pairwise links <math id="S3.SS1.SSS0.Px2.p1.3.m3.2" class="ltx_Math" alttext="\bm{r}_{i,j}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.3.m3.2a"><msub id="S3.SS1.SSS0.Px2.p1.3.m3.2.3" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.3.m3.2.3.2" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.3.2.cmml">ğ’“</mi><mrow id="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.4" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.1.cmml">i</mi><mo id="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.4.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.2" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.3.m3.2b"><apply id="S3.SS1.SSS0.Px2.p1.3.m3.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.3.m3.2.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.3.m3.2.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.3.2">ğ’“</ci><list id="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.4"><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.3.m3.2c">\bm{r}_{i,j}</annotation></semantics></math> coming into <math id="S3.SS1.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.4.m4.1a"><mi id="S3.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.4.m4.1b"><ci id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.4.m4.1c">i</annotation></semantics></math>.
We define it as <math id="S3.SS1.SSS0.Px2.p1.5.m5.2" class="ltx_Math" alttext="\check{\bm{e}}_{i}=\max_{j}\bm{r}_{i,j}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.5.m5.2a"><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.2.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.cmml"><msub id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.cmml"><mover accent="true" id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.2.cmml">ğ’†</mi><mo id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.1.cmml">Ë‡</mo></mover><mi id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.1.cmml">=</mo><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.cmml"><msub id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.2.cmml">max</mi><mi id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.3.cmml">j</mi></msub><mo lspace="0.167em" id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3a" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.cmml">â¡</mo><msub id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2.2.cmml">ğ’“</mi><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.4" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.cmml">i</mi><mo id="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.4.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.cmml">j</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.5.m5.2b"><apply id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3"><eq id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.1"></eq><apply id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2">subscript</csymbol><apply id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2"><ci id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.1">Ë‡</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.2.2">ğ’†</ci></apply><ci id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.2.3">ğ‘–</ci></apply><apply id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3"><apply id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1">subscript</csymbol><max id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.2"></max><ci id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.1.3">ğ‘—</ci></apply><apply id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.3.3.2.2">ğ’“</ci><list id="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.4"><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2">ğ‘—</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.5.m5.2c">\check{\bm{e}}_{i}=\max_{j}\bm{r}_{i,j}</annotation></semantics></math>, where <math id="S3.SS1.SSS0.Px2.p1.6.m6.2" class="ltx_Math" alttext="\bm{r}_{i,j}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.6.m6.2a"><msub id="S3.SS1.SSS0.Px2.p1.6.m6.2.3" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.6.m6.2.3.2" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.3.2.cmml">ğ’“</mi><mrow id="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.4" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.1" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.1.cmml">i</mi><mo id="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.4.1" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.2" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.6.m6.2b"><apply id="S3.SS1.SSS0.Px2.p1.6.m6.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.6.m6.2.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.6.m6.2.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.3.2">ğ’“</ci><list id="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.4"><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.6.m6.2c">\bm{r}_{i,j}</annotation></semantics></math> is a vector containing information about the content of both regions, but also about their relative spatial positioning.
We use the <math id="S3.SS1.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="\max" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.7.m7.1a"><mi id="S3.SS1.SSS0.Px2.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.cmml">max</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.7.m7.1b"><max id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1"></max></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.7.m7.1c">\max</annotation></semantics></math> operator in the aggregation function to reduce the noise that can be induced by average or sum poolings, which oblige all the regions to interact with each other.
To encode the relationship vector, we use the following formulation:</p>
</div>
<div id="S3.SS1.SSS0.Px2.p2" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.10" class="ltx_Math" alttext="\bm{r}_{i,j}=\operatorname*{B}\left(\bm{b}_{i},\bm{b}_{j};\Theta_{b}\right)+\operatorname*{B}\left(\bm{m}_{i},\bm{m}_{j};\Theta_{m}\right)" display="block"><semantics id="S3.E3.m1.10a"><mrow id="S3.E3.m1.10.10" xref="S3.E3.m1.10.10.cmml"><msub id="S3.E3.m1.10.10.8" xref="S3.E3.m1.10.10.8.cmml"><mi id="S3.E3.m1.10.10.8.2" xref="S3.E3.m1.10.10.8.2.cmml">ğ’“</mi><mrow id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">i</mi><mo id="S3.E3.m1.2.2.2.4.1" xref="S3.E3.m1.2.2.2.3.cmml">,</mo><mi id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo rspace="0.1389em" id="S3.E3.m1.10.10.7" xref="S3.E3.m1.10.10.7.cmml">=</mo><mrow id="S3.E3.m1.10.10.6" xref="S3.E3.m1.10.10.6.cmml"><mrow id="S3.E3.m1.7.7.3.3.3" xref="S3.E3.m1.7.7.3.3.4.cmml"><mo lspace="0.1389em" rspace="0em" id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">B</mo><mrow id="S3.E3.m1.7.7.3.3.3.3" xref="S3.E3.m1.7.7.3.3.4.cmml"><mo id="S3.E3.m1.7.7.3.3.3.3.4" xref="S3.E3.m1.7.7.3.3.4.cmml">(</mo><msub id="S3.E3.m1.5.5.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.2.cmml">ğ’ƒ</mi><mi id="S3.E3.m1.5.5.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.7.7.3.3.3.3.5" xref="S3.E3.m1.7.7.3.3.4.cmml">,</mo><msub id="S3.E3.m1.6.6.2.2.2.2.2" xref="S3.E3.m1.6.6.2.2.2.2.2.cmml"><mi id="S3.E3.m1.6.6.2.2.2.2.2.2" xref="S3.E3.m1.6.6.2.2.2.2.2.2.cmml">ğ’ƒ</mi><mi id="S3.E3.m1.6.6.2.2.2.2.2.3" xref="S3.E3.m1.6.6.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.E3.m1.7.7.3.3.3.3.6" xref="S3.E3.m1.7.7.3.3.4.cmml">;</mo><msub id="S3.E3.m1.7.7.3.3.3.3.3" xref="S3.E3.m1.7.7.3.3.3.3.3.cmml"><mi mathvariant="normal" id="S3.E3.m1.7.7.3.3.3.3.3.2" xref="S3.E3.m1.7.7.3.3.3.3.3.2.cmml">Î˜</mi><mi id="S3.E3.m1.7.7.3.3.3.3.3.3" xref="S3.E3.m1.7.7.3.3.3.3.3.3.cmml">b</mi></msub><mo id="S3.E3.m1.7.7.3.3.3.3.7" xref="S3.E3.m1.7.7.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.10.10.6.7" xref="S3.E3.m1.10.10.6.7.cmml">+</mo><mrow id="S3.E3.m1.10.10.6.6.3" xref="S3.E3.m1.10.10.6.6.4.cmml"><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml">B</mo><mrow id="S3.E3.m1.10.10.6.6.3.3" xref="S3.E3.m1.10.10.6.6.4.cmml"><mo id="S3.E3.m1.10.10.6.6.3.3.4" xref="S3.E3.m1.10.10.6.6.4.cmml">(</mo><msub id="S3.E3.m1.8.8.4.4.1.1.1" xref="S3.E3.m1.8.8.4.4.1.1.1.cmml"><mi id="S3.E3.m1.8.8.4.4.1.1.1.2" xref="S3.E3.m1.8.8.4.4.1.1.1.2.cmml">ğ’</mi><mi id="S3.E3.m1.8.8.4.4.1.1.1.3" xref="S3.E3.m1.8.8.4.4.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.10.10.6.6.3.3.5" xref="S3.E3.m1.10.10.6.6.4.cmml">,</mo><msub id="S3.E3.m1.9.9.5.5.2.2.2" xref="S3.E3.m1.9.9.5.5.2.2.2.cmml"><mi id="S3.E3.m1.9.9.5.5.2.2.2.2" xref="S3.E3.m1.9.9.5.5.2.2.2.2.cmml">ğ’</mi><mi id="S3.E3.m1.9.9.5.5.2.2.2.3" xref="S3.E3.m1.9.9.5.5.2.2.2.3.cmml">j</mi></msub><mo id="S3.E3.m1.10.10.6.6.3.3.6" xref="S3.E3.m1.10.10.6.6.4.cmml">;</mo><msub id="S3.E3.m1.10.10.6.6.3.3.3" xref="S3.E3.m1.10.10.6.6.3.3.3.cmml"><mi mathvariant="normal" id="S3.E3.m1.10.10.6.6.3.3.3.2" xref="S3.E3.m1.10.10.6.6.3.3.3.2.cmml">Î˜</mi><mi id="S3.E3.m1.10.10.6.6.3.3.3.3" xref="S3.E3.m1.10.10.6.6.3.3.3.3.cmml">m</mi></msub><mo id="S3.E3.m1.10.10.6.6.3.3.7" xref="S3.E3.m1.10.10.6.6.4.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.10b"><apply id="S3.E3.m1.10.10.cmml" xref="S3.E3.m1.10.10"><eq id="S3.E3.m1.10.10.7.cmml" xref="S3.E3.m1.10.10.7"></eq><apply id="S3.E3.m1.10.10.8.cmml" xref="S3.E3.m1.10.10.8"><csymbol cd="ambiguous" id="S3.E3.m1.10.10.8.1.cmml" xref="S3.E3.m1.10.10.8">subscript</csymbol><ci id="S3.E3.m1.10.10.8.2.cmml" xref="S3.E3.m1.10.10.8.2">ğ’“</ci><list id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.4"><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">ğ‘–</ci><ci id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2">ğ‘—</ci></list></apply><apply id="S3.E3.m1.10.10.6.cmml" xref="S3.E3.m1.10.10.6"><plus id="S3.E3.m1.10.10.6.7.cmml" xref="S3.E3.m1.10.10.6.7"></plus><apply id="S3.E3.m1.7.7.3.3.4.cmml" xref="S3.E3.m1.7.7.3.3.3"><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">B</ci><apply id="S3.E3.m1.5.5.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.2">ğ’ƒ</ci><ci id="S3.E3.m1.5.5.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E3.m1.6.6.2.2.2.2.2.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.2.2.2.2.2.1.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.6.6.2.2.2.2.2.2.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2">ğ’ƒ</ci><ci id="S3.E3.m1.6.6.2.2.2.2.2.3.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.3">ğ‘—</ci></apply><apply id="S3.E3.m1.7.7.3.3.3.3.3.cmml" xref="S3.E3.m1.7.7.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.7.7.3.3.3.3.3.1.cmml" xref="S3.E3.m1.7.7.3.3.3.3.3">subscript</csymbol><ci id="S3.E3.m1.7.7.3.3.3.3.3.2.cmml" xref="S3.E3.m1.7.7.3.3.3.3.3.2">Î˜</ci><ci id="S3.E3.m1.7.7.3.3.3.3.3.3.cmml" xref="S3.E3.m1.7.7.3.3.3.3.3.3">ğ‘</ci></apply></apply><apply id="S3.E3.m1.10.10.6.6.4.cmml" xref="S3.E3.m1.10.10.6.6.3"><ci id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4">B</ci><apply id="S3.E3.m1.8.8.4.4.1.1.1.cmml" xref="S3.E3.m1.8.8.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.4.4.1.1.1.1.cmml" xref="S3.E3.m1.8.8.4.4.1.1.1">subscript</csymbol><ci id="S3.E3.m1.8.8.4.4.1.1.1.2.cmml" xref="S3.E3.m1.8.8.4.4.1.1.1.2">ğ’</ci><ci id="S3.E3.m1.8.8.4.4.1.1.1.3.cmml" xref="S3.E3.m1.8.8.4.4.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E3.m1.9.9.5.5.2.2.2.cmml" xref="S3.E3.m1.9.9.5.5.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.5.5.2.2.2.1.cmml" xref="S3.E3.m1.9.9.5.5.2.2.2">subscript</csymbol><ci id="S3.E3.m1.9.9.5.5.2.2.2.2.cmml" xref="S3.E3.m1.9.9.5.5.2.2.2.2">ğ’</ci><ci id="S3.E3.m1.9.9.5.5.2.2.2.3.cmml" xref="S3.E3.m1.9.9.5.5.2.2.2.3">ğ‘—</ci></apply><apply id="S3.E3.m1.10.10.6.6.3.3.3.cmml" xref="S3.E3.m1.10.10.6.6.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.10.10.6.6.3.3.3.1.cmml" xref="S3.E3.m1.10.10.6.6.3.3.3">subscript</csymbol><ci id="S3.E3.m1.10.10.6.6.3.3.3.2.cmml" xref="S3.E3.m1.10.10.6.6.3.3.3.2">Î˜</ci><ci id="S3.E3.m1.10.10.6.6.3.3.3.3.cmml" xref="S3.E3.m1.10.10.6.6.3.3.3.3">ğ‘š</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.10c">\bm{r}_{i,j}=\operatorname*{B}\left(\bm{b}_{i},\bm{b}_{j};\Theta_{b}\right)+\operatorname*{B}\left(\bm{m}_{i},\bm{m}_{j};\Theta_{m}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p3.3" class="ltx_p">Through the <math id="S3.SS1.SSS0.Px2.p3.1.m1.1" class="ltx_math_unparsed" alttext="\operatorname*{B}(.,.;\Theta_{b})" display="inline"><semantics id="S3.SS1.SSS0.Px2.p3.1.m1.1a"><mrow id="S3.SS1.SSS0.Px2.p3.1.m1.1b"><mo rspace="0em" id="S3.SS1.SSS0.Px2.p3.1.m1.1.1">B</mo><mrow id="S3.SS1.SSS0.Px2.p3.1.m1.1.2"><mo stretchy="false" id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.2">.</mo><mo id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.3">,</mo><mo lspace="0em" rspace="0.167em" id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.4">.</mo><mo id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.5">;</mo><msub id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.6"><mi mathvariant="normal" id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.6.2">Î˜</mi><mi id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.6.3">b</mi></msub><mo stretchy="false" id="S3.SS1.SSS0.Px2.p3.1.m1.1.2.7">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p3.1.m1.1c">\operatorname*{B}(.,.;\Theta_{b})</annotation></semantics></math> operator, the cell is free to learn spatial concepts such as <span id="S3.SS1.SSS0.Px2.p3.3.1" class="ltx_text ltx_font_italic">on top of, left, right, etc.</span> In parallel, <math id="S3.SS1.SSS0.Px2.p3.2.m2.1" class="ltx_math_unparsed" alttext="\operatorname*{B}(.,.;\Theta_{s})" display="inline"><semantics id="S3.SS1.SSS0.Px2.p3.2.m2.1a"><mrow id="S3.SS1.SSS0.Px2.p3.2.m2.1b"><mo rspace="0em" id="S3.SS1.SSS0.Px2.p3.2.m2.1.1">B</mo><mrow id="S3.SS1.SSS0.Px2.p3.2.m2.1.2"><mo stretchy="false" id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.2">.</mo><mo id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.3">,</mo><mo lspace="0em" rspace="0.167em" id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.4">.</mo><mo id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.5">;</mo><msub id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.6"><mi mathvariant="normal" id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.6.2">Î˜</mi><mi id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.6.3">s</mi></msub><mo stretchy="false" id="S3.SS1.SSS0.Px2.p3.2.m2.1.2.7">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p3.2.m2.1c">\operatorname*{B}(.,.;\Theta_{s})</annotation></semantics></math> encodes correlations between multimodal vectors <math id="S3.SS1.SSS0.Px2.p3.3.m3.2" class="ltx_Math" alttext="(\bm{s}_{i},\bm{s}_{j})" display="inline"><semantics id="S3.SS1.SSS0.Px2.p3.3.m3.2a"><mrow id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.3" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1" xref="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.2" xref="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.3" xref="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.4" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.cmml"><mi id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.2" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.3" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.5" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p3.3.m3.2b"><interval closure="open" id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2"><apply id="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p3.3.m3.2.2.2.2.3">ğ‘—</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p3.3.m3.2c">(\bm{s}_{i},\bm{s}_{j})</annotation></semantics></math>, corresponding to semantic visual concepts conditionned on the question representation. By summing up both spatial and semantic fusions, the network can learn high-level relational concepts such as <span id="S3.SS1.SSS0.Px2.p3.3.2" class="ltx_text ltx_font_italic">wear, hold, etc.</span></p>
</div>
<div id="S3.SS1.SSS0.Px2.p4" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p4.3" class="ltx_p">The context representation <math id="S3.SS1.SSS0.Px2.p4.1.m1.1" class="ltx_Math" alttext="\check{\bm{e}}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p4.1.m1.1a"><msub id="S3.SS1.SSS0.Px2.p4.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.cmml"><mover accent="true" id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.2" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.2.cmml">ğ’†</mi><mo id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.1" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.1.cmml">Ë‡</mo></mover><mi id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p4.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1">subscript</csymbol><apply id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2"><ci id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.1">Ë‡</ci><ci id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.2.2">ğ’†</ci></apply><ci id="S3.SS1.SSS0.Px2.p4.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p4.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p4.1.m1.1c">\check{\bm{e}}_{i}</annotation></semantics></math> that contains an aggregation of the messages <math id="S3.SS1.SSS0.Px2.p4.2.m2.2" class="ltx_Math" alttext="\bm{r}_{i,j}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p4.2.m2.2a"><msub id="S3.SS1.SSS0.Px2.p4.2.m2.2.3" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p4.2.m2.2.3.2" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.3.2.cmml">ğ’“</mi><mrow id="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.4" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p4.2.m2.1.1.1.1" xref="S3.SS1.SSS0.Px2.p4.2.m2.1.1.1.1.cmml">i</mi><mo id="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.4.1" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.2" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p4.2.m2.2b"><apply id="S3.SS1.SSS0.Px2.p4.2.m2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p4.2.m2.2.3.1.cmml" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p4.2.m2.2.3.2.cmml" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.3.2">ğ’“</ci><list id="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.4"><ci id="S3.SS1.SSS0.Px2.p4.2.m2.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p4.2.m2.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p4.2.m2.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p4.2.m2.2c">\bm{r}_{i,j}</annotation></semantics></math> provided by its neighbours updates the multimodal vector <math id="S3.SS1.SSS0.Px2.p4.3.m3.1" class="ltx_Math" alttext="\bm{m}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p4.3.m3.1a"><msub id="S3.SS1.SSS0.Px2.p4.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p4.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p4.3.m3.1.1.2" xref="S3.SS1.SSS0.Px2.p4.3.m3.1.1.2.cmml">ğ’</mi><mi id="S3.SS1.SSS0.Px2.p4.3.m3.1.1.3" xref="S3.SS1.SSS0.Px2.p4.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p4.3.m3.1b"><apply id="S3.SS1.SSS0.Px2.p4.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p4.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p4.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p4.3.m3.1.1.2">ğ’</ci><ci id="S3.SS1.SSS0.Px2.p4.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p4.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p4.3.m3.1c">\bm{m}_{i}</annotation></semantics></math> in an additive manner:</p>
</div>
<div id="S3.SS1.SSS0.Px2.p5" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\bm{x}_{i}=\bm{m}_{i}+\check{\bm{e}}_{i}" display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.2.2" xref="S3.E4.m1.1.1.2.2.cmml">ğ’™</mi><mi id="S3.E4.m1.1.1.2.3" xref="S3.E4.m1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><msub id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml"><mi id="S3.E4.m1.1.1.3.2.2" xref="S3.E4.m1.1.1.3.2.2.cmml">ğ’</mi><mi id="S3.E4.m1.1.1.3.2.3" xref="S3.E4.m1.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.3.1.cmml">+</mo><msub id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml"><mover accent="true" id="S3.E4.m1.1.1.3.3.2" xref="S3.E4.m1.1.1.3.3.2.cmml"><mi id="S3.E4.m1.1.1.3.3.2.2" xref="S3.E4.m1.1.1.3.3.2.2.cmml">ğ’†</mi><mo id="S3.E4.m1.1.1.3.3.2.1" xref="S3.E4.m1.1.1.3.3.2.1.cmml">Ë‡</mo></mover><mi id="S3.E4.m1.1.1.3.3.3" xref="S3.E4.m1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"></eq><apply id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.2.2">ğ’™</ci><ci id="S3.E4.m1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><plus id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1"></plus><apply id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2">ğ’</ci><ci id="S3.E4.m1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.3.2.3">ğ‘–</ci></apply><apply id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3">subscript</csymbol><apply id="S3.E4.m1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.2"><ci id="S3.E4.m1.1.1.3.3.2.1.cmml" xref="S3.E4.m1.1.1.3.3.2.1">Ë‡</ci><ci id="S3.E4.m1.1.1.3.3.2.2.cmml" xref="S3.E4.m1.1.1.3.3.2.2">ğ’†</ci></apply><ci id="S3.E4.m1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\bm{x}_{i}=\bm{m}_{i}+\check{\bm{e}}_{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS0.Px2.p5.1" class="ltx_p">This formulation of the pairwise modelling is actually closer to the Graph Networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, where the notion of relational inductive biases is formalized.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p6" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p6.2" class="ltx_p">Finally, the MuREL cellâ€™s output is computed as a residual function of its input, to avoid the vanishing gradient problem. Each visual feature <math id="S3.SS1.SSS0.Px2.p6.1.m1.1" class="ltx_Math" alttext="\bm{s}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p6.1.m1.1a"><msub id="S3.SS1.SSS0.Px2.p6.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p6.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p6.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p6.1.m1.1.1.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px2.p6.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p6.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p6.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p6.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p6.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p6.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p6.1.m1.1.1.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px2.p6.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p6.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p6.1.m1.1c">\bm{s}_{i}</annotation></semantics></math> is updated as: <math id="S3.SS1.SSS0.Px2.p6.2.m2.1" class="ltx_Math" alttext="\hat{\bm{s}}_{i}=\bm{s}_{i}+\bm{x}_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p6.2.m2.1a"><mrow id="S3.SS1.SSS0.Px2.p6.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.cmml"><msub id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.cmml"><mover accent="true" id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.cmml"><mi id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.2" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.2.cmml">ğ’”</mi><mo id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.1" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.3" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.1" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.1.cmml">=</mo><mrow id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.cmml"><msub id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.cmml"><mi id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.2" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.3" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.1" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.1.cmml">+</mo><msub id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.2" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.2.cmml">ğ’™</mi><mi id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.3" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p6.2.m2.1b"><apply id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1"><eq id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.1"></eq><apply id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2">subscript</csymbol><apply id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2"><ci id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.1.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.1">^</ci><ci id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.2.2">ğ’”</ci></apply><ci id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3"><plus id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.1"></plus><apply id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.1.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.2.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.3.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.2.3">ğ‘–</ci></apply><apply id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.2">ğ’™</ci><ci id="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.SSS0.Px2.p6.2.m2.1.1.3.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p6.2.m2.1c">\hat{\bm{s}}_{i}=\bm{s}_{i}+\bm{x}_{i}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p7" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p7.2" class="ltx_p">The chain of operations that updates the set of localized region embeddings <math id="S3.SS1.SSS0.Px2.p7.1.m1.3" class="ltx_Math" alttext="\{\bm{s}_{i}\}_{i\in[1,N]}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p7.1.m1.3a"><msub id="S3.SS1.SSS0.Px2.p7.1.m1.3.3" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.cmml"><mrow id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.2" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.2.cmml">{</mo><msub id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.2" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.2.cmml">ğ’”</mi><mi id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.3" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.3" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.cmml"><mi id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.4" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.4.cmml">i</mi><mo id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.3" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.3.cmml">âˆˆ</mo><mrow id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.2" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.2.1" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.1.cmml">[</mo><mn id="S3.SS1.SSS0.Px2.p7.1.m1.1.1.1.1" xref="S3.SS1.SSS0.Px2.p7.1.m1.1.1.1.1.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.2.2" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.1.cmml">,</mo><mi id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.2" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.2.cmml">N</mi><mo stretchy="false" id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.2.3" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.1.cmml">]</mo></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p7.1.m1.3b"><apply id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.2.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3">subscript</csymbol><set id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.2.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1"><apply id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.2">ğ’”</ci><ci id="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.3.3.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2"><in id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.3"></in><ci id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.4.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.4">ğ‘–</ci><interval closure="closed" id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.1.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.5.2"><cn type="integer" id="S3.SS1.SSS0.Px2.p7.1.m1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.1.1.1.1">1</cn><ci id="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px2.p7.1.m1.2.2.2.2">ğ‘</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p7.1.m1.3c">\{\bm{s}_{i}\}_{i\in[1,N]}</annotation></semantics></math> using the multimodal fusion with <math id="S3.SS1.SSS0.Px2.p7.2.m2.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p7.2.m2.1a"><mi id="S3.SS1.SSS0.Px2.p7.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p7.2.m2.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p7.2.m2.1b"><ci id="S3.SS1.SSS0.Px2.p7.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p7.2.m2.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p7.2.m2.1c">\bm{q}</annotation></semantics></math> and the pairwise modeling operator is noted:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.5" class="ltx_Math" alttext="\{\hat{\bm{s}}_{i}\}=\operatorname*{MurelCell}\left(\{\bm{s}_{i}\};\{\bm{b}_{i}\},\bm{q}\right)" display="block"><semantics id="S3.E5.m1.5a"><mrow id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml"><mrow id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.1.1.2" xref="S3.E5.m1.3.3.1.2.cmml">{</mo><msub id="S3.E5.m1.3.3.1.1.1" xref="S3.E5.m1.3.3.1.1.1.cmml"><mover accent="true" id="S3.E5.m1.3.3.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.2.cmml"><mi id="S3.E5.m1.3.3.1.1.1.2.2" xref="S3.E5.m1.3.3.1.1.1.2.2.cmml">ğ’”</mi><mo id="S3.E5.m1.3.3.1.1.1.2.1" xref="S3.E5.m1.3.3.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.3.3.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E5.m1.3.3.1.1.3" xref="S3.E5.m1.3.3.1.2.cmml">}</mo></mrow><mo rspace="0.1389em" id="S3.E5.m1.5.5.4" xref="S3.E5.m1.5.5.4.cmml">=</mo><mrow id="S3.E5.m1.5.5.3.2" xref="S3.E5.m1.5.5.3.3.cmml"><mo lspace="0.1389em" rspace="0em" id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">MurelCell</mo><mrow id="S3.E5.m1.5.5.3.2.2" xref="S3.E5.m1.5.5.3.3.cmml"><mo id="S3.E5.m1.5.5.3.2.2.3" xref="S3.E5.m1.5.5.3.3.cmml">(</mo><mrow id="S3.E5.m1.4.4.2.1.1.1.1" xref="S3.E5.m1.4.4.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.4.4.2.1.1.1.1.2" xref="S3.E5.m1.4.4.2.1.1.1.2.cmml">{</mo><msub id="S3.E5.m1.4.4.2.1.1.1.1.1" xref="S3.E5.m1.4.4.2.1.1.1.1.1.cmml"><mi id="S3.E5.m1.4.4.2.1.1.1.1.1.2" xref="S3.E5.m1.4.4.2.1.1.1.1.1.2.cmml">ğ’”</mi><mi id="S3.E5.m1.4.4.2.1.1.1.1.1.3" xref="S3.E5.m1.4.4.2.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E5.m1.4.4.2.1.1.1.1.3" xref="S3.E5.m1.4.4.2.1.1.1.2.cmml">}</mo></mrow><mo id="S3.E5.m1.5.5.3.2.2.4" xref="S3.E5.m1.5.5.3.3.cmml">;</mo><mrow id="S3.E5.m1.5.5.3.2.2.2.1" xref="S3.E5.m1.5.5.3.2.2.2.2.cmml"><mo stretchy="false" id="S3.E5.m1.5.5.3.2.2.2.1.2" xref="S3.E5.m1.5.5.3.2.2.2.2.cmml">{</mo><msub id="S3.E5.m1.5.5.3.2.2.2.1.1" xref="S3.E5.m1.5.5.3.2.2.2.1.1.cmml"><mi id="S3.E5.m1.5.5.3.2.2.2.1.1.2" xref="S3.E5.m1.5.5.3.2.2.2.1.1.2.cmml">ğ’ƒ</mi><mi id="S3.E5.m1.5.5.3.2.2.2.1.1.3" xref="S3.E5.m1.5.5.3.2.2.2.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E5.m1.5.5.3.2.2.2.1.3" xref="S3.E5.m1.5.5.3.2.2.2.2.cmml">}</mo></mrow><mo id="S3.E5.m1.5.5.3.2.2.5" xref="S3.E5.m1.5.5.3.3.cmml">,</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">ğ’’</mi><mo id="S3.E5.m1.5.5.3.2.2.6" xref="S3.E5.m1.5.5.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.5b"><apply id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5"><eq id="S3.E5.m1.5.5.4.cmml" xref="S3.E5.m1.5.5.4"></eq><set id="S3.E5.m1.3.3.1.2.cmml" xref="S3.E5.m1.3.3.1.1"><apply id="S3.E5.m1.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1">subscript</csymbol><apply id="S3.E5.m1.3.3.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.2"><ci id="S3.E5.m1.3.3.1.1.1.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.2.1">^</ci><ci id="S3.E5.m1.3.3.1.1.1.2.2.cmml" xref="S3.E5.m1.3.3.1.1.1.2.2">ğ’”</ci></apply><ci id="S3.E5.m1.3.3.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.E5.m1.5.5.3.3.cmml" xref="S3.E5.m1.5.5.3.2"><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">MurelCell</ci><set id="S3.E5.m1.4.4.2.1.1.1.2.cmml" xref="S3.E5.m1.4.4.2.1.1.1.1"><apply id="S3.E5.m1.4.4.2.1.1.1.1.1.cmml" xref="S3.E5.m1.4.4.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.2.1.1.1.1.1.1.cmml" xref="S3.E5.m1.4.4.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.4.4.2.1.1.1.1.1.2.cmml" xref="S3.E5.m1.4.4.2.1.1.1.1.1.2">ğ’”</ci><ci id="S3.E5.m1.4.4.2.1.1.1.1.1.3.cmml" xref="S3.E5.m1.4.4.2.1.1.1.1.1.3">ğ‘–</ci></apply></set><set id="S3.E5.m1.5.5.3.2.2.2.2.cmml" xref="S3.E5.m1.5.5.3.2.2.2.1"><apply id="S3.E5.m1.5.5.3.2.2.2.1.1.cmml" xref="S3.E5.m1.5.5.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.3.2.2.2.1.1.1.cmml" xref="S3.E5.m1.5.5.3.2.2.2.1.1">subscript</csymbol><ci id="S3.E5.m1.5.5.3.2.2.2.1.1.2.cmml" xref="S3.E5.m1.5.5.3.2.2.2.1.1.2">ğ’ƒ</ci><ci id="S3.E5.m1.5.5.3.2.2.2.1.1.3.cmml" xref="S3.E5.m1.5.5.3.2.2.2.1.1.3">ğ‘–</ci></apply></set><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">ğ’’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.5c">\{\hat{\bm{s}}_{i}\}=\operatorname*{MurelCell}\left(\{\bm{s}_{i}\};\{\bm{b}_{i}\},\bm{q}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>MuRel network</h3>

<figure id="S3.F3" class="ltx_figure"><img src="/html/1902.09487/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="137" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span> <span id="S3.F3.12.1" class="ltx_text ltx_font_bold">MuRel network.</span> The MuRel network merges the question embedding <math id="S3.F3.6.m1.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.F3.6.m1.1b"><mi id="S3.F3.6.m1.1.1" xref="S3.F3.6.m1.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.F3.6.m1.1c"><ci id="S3.F3.6.m1.1.1.cmml" xref="S3.F3.6.m1.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m1.1d">\bm{q}</annotation></semantics></math> into spatially-grounded visual representations <math id="S3.F3.7.m2.1" class="ltx_Math" alttext="\{\bm{v}_{i}\}" display="inline"><semantics id="S3.F3.7.m2.1b"><mrow id="S3.F3.7.m2.1.1.1" xref="S3.F3.7.m2.1.1.2.cmml"><mo stretchy="false" id="S3.F3.7.m2.1.1.1.2" xref="S3.F3.7.m2.1.1.2.cmml">{</mo><msub id="S3.F3.7.m2.1.1.1.1" xref="S3.F3.7.m2.1.1.1.1.cmml"><mi id="S3.F3.7.m2.1.1.1.1.2" xref="S3.F3.7.m2.1.1.1.1.2.cmml">ğ’—</mi><mi id="S3.F3.7.m2.1.1.1.1.3" xref="S3.F3.7.m2.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.F3.7.m2.1.1.1.3" xref="S3.F3.7.m2.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.7.m2.1c"><set id="S3.F3.7.m2.1.1.2.cmml" xref="S3.F3.7.m2.1.1.1"><apply id="S3.F3.7.m2.1.1.1.1.cmml" xref="S3.F3.7.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.7.m2.1.1.1.1.1.cmml" xref="S3.F3.7.m2.1.1.1.1">subscript</csymbol><ci id="S3.F3.7.m2.1.1.1.1.2.cmml" xref="S3.F3.7.m2.1.1.1.1.2">ğ’—</ci><ci id="S3.F3.7.m2.1.1.1.1.3.cmml" xref="S3.F3.7.m2.1.1.1.1.3">ğ‘–</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.7.m2.1d">\{\bm{v}_{i}\}</annotation></semantics></math> by iterating through a single MuRel cell. This module takes as input a set of localized vectors <math id="S3.F3.8.m3.1" class="ltx_Math" alttext="\{\bm{s}_{i}\}" display="inline"><semantics id="S3.F3.8.m3.1b"><mrow id="S3.F3.8.m3.1.1.1" xref="S3.F3.8.m3.1.1.2.cmml"><mo stretchy="false" id="S3.F3.8.m3.1.1.1.2" xref="S3.F3.8.m3.1.1.2.cmml">{</mo><msub id="S3.F3.8.m3.1.1.1.1" xref="S3.F3.8.m3.1.1.1.1.cmml"><mi id="S3.F3.8.m3.1.1.1.1.2" xref="S3.F3.8.m3.1.1.1.1.2.cmml">ğ’”</mi><mi id="S3.F3.8.m3.1.1.1.1.3" xref="S3.F3.8.m3.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.F3.8.m3.1.1.1.3" xref="S3.F3.8.m3.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.8.m3.1c"><set id="S3.F3.8.m3.1.1.2.cmml" xref="S3.F3.8.m3.1.1.1"><apply id="S3.F3.8.m3.1.1.1.1.cmml" xref="S3.F3.8.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.8.m3.1.1.1.1.1.cmml" xref="S3.F3.8.m3.1.1.1.1">subscript</csymbol><ci id="S3.F3.8.m3.1.1.1.1.2.cmml" xref="S3.F3.8.m3.1.1.1.1.2">ğ’”</ci><ci id="S3.F3.8.m3.1.1.1.1.3.cmml" xref="S3.F3.8.m3.1.1.1.1.3">ğ‘–</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.8.m3.1d">\{\bm{s}_{i}\}</annotation></semantics></math> and updates their representation using a multimodal fusion component. Moreover, it models all the possible pairwise relations between regions by combining spatial and semantic information. To construct the importance map at step <math id="S3.F3.9.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.F3.9.m4.1b"><mi id="S3.F3.9.m4.1.1" xref="S3.F3.9.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.F3.9.m4.1c"><ci id="S3.F3.9.m4.1.1.cmml" xref="S3.F3.9.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.9.m4.1d">t</annotation></semantics></math>, we count the number of time each region provides the maximal value of <math id="S3.F3.10.m5.2" class="ltx_Math" alttext="\max_{i}\{\bm{s}_{i}^{t}\}" display="inline"><semantics id="S3.F3.10.m5.2b"><mrow id="S3.F3.10.m5.2.2.2" xref="S3.F3.10.m5.2.2.3.cmml"><msub id="S3.F3.10.m5.1.1.1.1" xref="S3.F3.10.m5.1.1.1.1.cmml"><mi id="S3.F3.10.m5.1.1.1.1.2" xref="S3.F3.10.m5.1.1.1.1.2.cmml">max</mi><mi id="S3.F3.10.m5.1.1.1.1.3" xref="S3.F3.10.m5.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.F3.10.m5.2.2.2b" xref="S3.F3.10.m5.2.2.3.cmml">â¡</mo><mrow id="S3.F3.10.m5.2.2.2.2" xref="S3.F3.10.m5.2.2.3.cmml"><mo stretchy="false" id="S3.F3.10.m5.2.2.2.2.2" xref="S3.F3.10.m5.2.2.3.cmml">{</mo><msubsup id="S3.F3.10.m5.2.2.2.2.1" xref="S3.F3.10.m5.2.2.2.2.1.cmml"><mi id="S3.F3.10.m5.2.2.2.2.1.2.2" xref="S3.F3.10.m5.2.2.2.2.1.2.2.cmml">ğ’”</mi><mi id="S3.F3.10.m5.2.2.2.2.1.2.3" xref="S3.F3.10.m5.2.2.2.2.1.2.3.cmml">i</mi><mi id="S3.F3.10.m5.2.2.2.2.1.3" xref="S3.F3.10.m5.2.2.2.2.1.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.F3.10.m5.2.2.2.2.3" xref="S3.F3.10.m5.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.10.m5.2c"><apply id="S3.F3.10.m5.2.2.3.cmml" xref="S3.F3.10.m5.2.2.2"><apply id="S3.F3.10.m5.1.1.1.1.cmml" xref="S3.F3.10.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.10.m5.1.1.1.1.1.cmml" xref="S3.F3.10.m5.1.1.1.1">subscript</csymbol><max id="S3.F3.10.m5.1.1.1.1.2.cmml" xref="S3.F3.10.m5.1.1.1.1.2"></max><ci id="S3.F3.10.m5.1.1.1.1.3.cmml" xref="S3.F3.10.m5.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.F3.10.m5.2.2.2.2.1.cmml" xref="S3.F3.10.m5.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.F3.10.m5.2.2.2.2.1.1.cmml" xref="S3.F3.10.m5.2.2.2.2.1">superscript</csymbol><apply id="S3.F3.10.m5.2.2.2.2.1.2.cmml" xref="S3.F3.10.m5.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.F3.10.m5.2.2.2.2.1.2.1.cmml" xref="S3.F3.10.m5.2.2.2.2.1">subscript</csymbol><ci id="S3.F3.10.m5.2.2.2.2.1.2.2.cmml" xref="S3.F3.10.m5.2.2.2.2.1.2.2">ğ’”</ci><ci id="S3.F3.10.m5.2.2.2.2.1.2.3.cmml" xref="S3.F3.10.m5.2.2.2.2.1.2.3">ğ‘–</ci></apply><ci id="S3.F3.10.m5.2.2.2.2.1.3.cmml" xref="S3.F3.10.m5.2.2.2.2.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.10.m5.2d">\max_{i}\{\bm{s}_{i}^{t}\}</annotation></semantics></math> (over the 2048 dimensions).</figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.3" class="ltx_p">Mimicking a simple form of progressive reasoning, our model leverages the power of bilinear fusions to iteratively merge visual information into context-aware visual embeddings.
As we can see in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, a MuRel cell iteratively updates the region state vectors <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\{\bm{s}_{i}\}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.1.m1.1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">{</mo><msub id="S3.SS2.p1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.1.1.2.cmml">ğ’”</mi><mi id="S3.SS2.p1.1.m1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p1.1.m1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><set id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1"><apply id="S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2">ğ’”</ci><ci id="S3.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3">ğ‘–</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\{\bm{s}_{i}\}</annotation></semantics></math>, each time refining the representations with contextual and question information. More specifically, for each step <math id="S3.SS2.p1.2.m2.1" class="ltx_math_unparsed" alttext="t=1..T" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1b"><mi id="S3.SS2.p1.2.m2.1.1">t</mi><mo id="S3.SS2.p1.2.m2.1.2">=</mo><mn id="S3.SS2.p1.2.m2.1.3">1</mn><mo lspace="0em" rspace="0.0835em" id="S3.SS2.p1.2.m2.1.4">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S3.SS2.p1.2.m2.1.5">.</mo><mi id="S3.SS2.p1.2.m2.1.6">T</mi></mrow><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">t=1..T</annotation></semantics></math> where <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">T</annotation></semantics></math> is the total number of steps, a MuRel cell processes and updates the state vectors following EquationÂ (<a href="#S3.E6" title="In 3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>):</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.5" class="ltx_Math" alttext="\{\bm{s}_{i}^{t}\}=\operatorname*{MurelCell}\left(\{\bm{s}_{i}^{t-1}\};\{\bm{b}_{i}\},\bm{q}\right)" display="block"><semantics id="S3.E6.m1.5a"><mrow id="S3.E6.m1.5.5" xref="S3.E6.m1.5.5.cmml"><mrow id="S3.E6.m1.3.3.1.1" xref="S3.E6.m1.3.3.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.2" xref="S3.E6.m1.3.3.1.2.cmml">{</mo><msubsup id="S3.E6.m1.3.3.1.1.1" xref="S3.E6.m1.3.3.1.1.1.cmml"><mi id="S3.E6.m1.3.3.1.1.1.2.2" xref="S3.E6.m1.3.3.1.1.1.2.2.cmml">ğ’”</mi><mi id="S3.E6.m1.3.3.1.1.1.2.3" xref="S3.E6.m1.3.3.1.1.1.2.3.cmml">i</mi><mi id="S3.E6.m1.3.3.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.E6.m1.3.3.1.1.3" xref="S3.E6.m1.3.3.1.2.cmml">}</mo></mrow><mo rspace="0.1389em" id="S3.E6.m1.5.5.4" xref="S3.E6.m1.5.5.4.cmml">=</mo><mrow id="S3.E6.m1.5.5.3.2" xref="S3.E6.m1.5.5.3.3.cmml"><mo lspace="0.1389em" rspace="0em" id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">MurelCell</mo><mrow id="S3.E6.m1.5.5.3.2.2" xref="S3.E6.m1.5.5.3.3.cmml"><mo id="S3.E6.m1.5.5.3.2.2.3" xref="S3.E6.m1.5.5.3.3.cmml">(</mo><mrow id="S3.E6.m1.4.4.2.1.1.1.1" xref="S3.E6.m1.4.4.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.4.4.2.1.1.1.1.2" xref="S3.E6.m1.4.4.2.1.1.1.2.cmml">{</mo><msubsup id="S3.E6.m1.4.4.2.1.1.1.1.1" xref="S3.E6.m1.4.4.2.1.1.1.1.1.cmml"><mi id="S3.E6.m1.4.4.2.1.1.1.1.1.2.2" xref="S3.E6.m1.4.4.2.1.1.1.1.1.2.2.cmml">ğ’”</mi><mi id="S3.E6.m1.4.4.2.1.1.1.1.1.2.3" xref="S3.E6.m1.4.4.2.1.1.1.1.1.2.3.cmml">i</mi><mrow id="S3.E6.m1.4.4.2.1.1.1.1.1.3" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.4.4.2.1.1.1.1.1.3.2" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E6.m1.4.4.2.1.1.1.1.1.3.1" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3.1.cmml">âˆ’</mo><mn id="S3.E6.m1.4.4.2.1.1.1.1.1.3.3" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="S3.E6.m1.4.4.2.1.1.1.1.3" xref="S3.E6.m1.4.4.2.1.1.1.2.cmml">}</mo></mrow><mo id="S3.E6.m1.5.5.3.2.2.4" xref="S3.E6.m1.5.5.3.3.cmml">;</mo><mrow id="S3.E6.m1.5.5.3.2.2.2.1" xref="S3.E6.m1.5.5.3.2.2.2.2.cmml"><mo stretchy="false" id="S3.E6.m1.5.5.3.2.2.2.1.2" xref="S3.E6.m1.5.5.3.2.2.2.2.cmml">{</mo><msub id="S3.E6.m1.5.5.3.2.2.2.1.1" xref="S3.E6.m1.5.5.3.2.2.2.1.1.cmml"><mi id="S3.E6.m1.5.5.3.2.2.2.1.1.2" xref="S3.E6.m1.5.5.3.2.2.2.1.1.2.cmml">ğ’ƒ</mi><mi id="S3.E6.m1.5.5.3.2.2.2.1.1.3" xref="S3.E6.m1.5.5.3.2.2.2.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E6.m1.5.5.3.2.2.2.1.3" xref="S3.E6.m1.5.5.3.2.2.2.2.cmml">}</mo></mrow><mo id="S3.E6.m1.5.5.3.2.2.5" xref="S3.E6.m1.5.5.3.3.cmml">,</mo><mi id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml">ğ’’</mi><mo id="S3.E6.m1.5.5.3.2.2.6" xref="S3.E6.m1.5.5.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.5b"><apply id="S3.E6.m1.5.5.cmml" xref="S3.E6.m1.5.5"><eq id="S3.E6.m1.5.5.4.cmml" xref="S3.E6.m1.5.5.4"></eq><set id="S3.E6.m1.3.3.1.2.cmml" xref="S3.E6.m1.3.3.1.1"><apply id="S3.E6.m1.3.3.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1">superscript</csymbol><apply id="S3.E6.m1.3.3.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.2.2.cmml" xref="S3.E6.m1.3.3.1.1.1.2.2">ğ’”</ci><ci id="S3.E6.m1.3.3.1.1.1.2.3.cmml" xref="S3.E6.m1.3.3.1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.E6.m1.3.3.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.3">ğ‘¡</ci></apply></set><apply id="S3.E6.m1.5.5.3.3.cmml" xref="S3.E6.m1.5.5.3.2"><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">MurelCell</ci><set id="S3.E6.m1.4.4.2.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1"><apply id="S3.E6.m1.4.4.2.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1">superscript</csymbol><apply id="S3.E6.m1.4.4.2.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.4.4.2.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1.2.2">ğ’”</ci><ci id="S3.E6.m1.4.4.2.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.4.4.2.1.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3"><minus id="S3.E6.m1.4.4.2.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3.1"></minus><ci id="S3.E6.m1.4.4.2.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3.2">ğ‘¡</ci><cn type="integer" id="S3.E6.m1.4.4.2.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.4.4.2.1.1.1.1.1.3.3">1</cn></apply></apply></set><set id="S3.E6.m1.5.5.3.2.2.2.2.cmml" xref="S3.E6.m1.5.5.3.2.2.2.1"><apply id="S3.E6.m1.5.5.3.2.2.2.1.1.cmml" xref="S3.E6.m1.5.5.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.5.5.3.2.2.2.1.1.1.cmml" xref="S3.E6.m1.5.5.3.2.2.2.1.1">subscript</csymbol><ci id="S3.E6.m1.5.5.3.2.2.2.1.1.2.cmml" xref="S3.E6.m1.5.5.3.2.2.2.1.1.2">ğ’ƒ</ci><ci id="S3.E6.m1.5.5.3.2.2.2.1.1.3.cmml" xref="S3.E6.m1.5.5.3.2.2.2.1.1.3">ğ‘–</ci></apply></set><ci id="S3.E6.m1.2.2.cmml" xref="S3.E6.m1.2.2">ğ’’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.5c">\{\bm{s}_{i}^{t}\}=\operatorname*{MurelCell}\left(\{\bm{s}_{i}^{t-1}\};\{\bm{b}_{i}\},\bm{q}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.2" class="ltx_p">The state vectors are initialized with the features outputted by the object detector; for each region <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">i</annotation></semantics></math>, <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\bm{s}_{i}^{0}=\bm{v}_{i}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><msubsup id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2.2.2" xref="S3.SS2.p3.2.m2.1.1.2.2.2.cmml">ğ’”</mi><mi id="S3.SS2.p3.2.m2.1.1.2.2.3" xref="S3.SS2.p3.2.m2.1.1.2.2.3.cmml">i</mi><mn id="S3.SS2.p3.2.m2.1.1.2.3" xref="S3.SS2.p3.2.m2.1.1.2.3.cmml">0</mn></msubsup><mo id="S3.SS2.p3.2.m2.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.cmml">=</mo><msub id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml"><mi id="S3.SS2.p3.2.m2.1.1.3.2" xref="S3.SS2.p3.2.m2.1.1.3.2.cmml">ğ’—</mi><mi id="S3.SS2.p3.2.m2.1.1.3.3" xref="S3.SS2.p3.2.m2.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><eq id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1"></eq><apply id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1.2">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2.2">ğ’”</ci><ci id="S3.SS2.p3.2.m2.1.1.2.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S3.SS2.p3.2.m2.1.1.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.2.3">0</cn></apply><apply id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.3.2">ğ’—</ci><ci id="S3.SS2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\bm{s}_{i}^{0}=\bm{v}_{i}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">The MuRel network represents each region regarding the question, but also using its own visual context. This representation is done iteratively, through multiple steps of a MuRel cell.
The residual nature of this module makes it possible to align multiple cells without being subject to gradient vanishing.
Moreover, the weights of our model are shared across the cells, which enables compact parametrization and good generalization.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.3" class="ltx_p">At step <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="t=T" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mrow id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml"><mi id="S3.SS2.p5.1.m1.1.1.2" xref="S3.SS2.p5.1.m1.1.1.2.cmml">t</mi><mo id="S3.SS2.p5.1.m1.1.1.1" xref="S3.SS2.p5.1.m1.1.1.1.cmml">=</mo><mi id="S3.SS2.p5.1.m1.1.1.3" xref="S3.SS2.p5.1.m1.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1"><eq id="S3.SS2.p5.1.m1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1"></eq><ci id="S3.SS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.2">ğ‘¡</ci><ci id="S3.SS2.p5.1.m1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">t=T</annotation></semantics></math>, the representations <math id="S3.SS2.p5.2.m2.1" class="ltx_Math" alttext="\{\bm{s}_{i}^{T}\}" display="inline"><semantics id="S3.SS2.p5.2.m2.1a"><mrow id="S3.SS2.p5.2.m2.1.1.1" xref="S3.SS2.p5.2.m2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p5.2.m2.1.1.1.2" xref="S3.SS2.p5.2.m2.1.1.2.cmml">{</mo><msubsup id="S3.SS2.p5.2.m2.1.1.1.1" xref="S3.SS2.p5.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.1.1.2.2" xref="S3.SS2.p5.2.m2.1.1.1.1.2.2.cmml">ğ’”</mi><mi id="S3.SS2.p5.2.m2.1.1.1.1.2.3" xref="S3.SS2.p5.2.m2.1.1.1.1.2.3.cmml">i</mi><mi id="S3.SS2.p5.2.m2.1.1.1.1.3" xref="S3.SS2.p5.2.m2.1.1.1.1.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.SS2.p5.2.m2.1.1.1.3" xref="S3.SS2.p5.2.m2.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><set id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.1"><apply id="S3.SS2.p5.2.m2.1.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p5.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.1.1.1.1.2.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p5.2.m2.1.1.1.1.2.2.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.2.2">ğ’”</ci><ci id="S3.SS2.p5.2.m2.1.1.1.1.2.3.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS2.p5.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.p5.2.m2.1.1.1.1.3">ğ‘‡</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">\{\bm{s}_{i}^{T}\}</annotation></semantics></math> are aggregated with a global max pooling operation to provide a single vector <math id="S3.SS2.p5.3.m3.1" class="ltx_Math" alttext="\bm{s}\in\mathbb{R}^{d_{v}}" display="inline"><semantics id="S3.SS2.p5.3.m3.1a"><mrow id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.p5.3.m3.1.1.2" xref="S3.SS2.p5.3.m3.1.1.2.cmml">ğ’”</mi><mo id="S3.SS2.p5.3.m3.1.1.1" xref="S3.SS2.p5.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p5.3.m3.1.1.3" xref="S3.SS2.p5.3.m3.1.1.3.cmml"><mi id="S3.SS2.p5.3.m3.1.1.3.2" xref="S3.SS2.p5.3.m3.1.1.3.2.cmml">â„</mi><msub id="S3.SS2.p5.3.m3.1.1.3.3" xref="S3.SS2.p5.3.m3.1.1.3.3.cmml"><mi id="S3.SS2.p5.3.m3.1.1.3.3.2" xref="S3.SS2.p5.3.m3.1.1.3.3.2.cmml">d</mi><mi id="S3.SS2.p5.3.m3.1.1.3.3.3" xref="S3.SS2.p5.3.m3.1.1.3.3.3.cmml">v</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><apply id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1"><in id="S3.SS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1.1"></in><ci id="S3.SS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.p5.3.m3.1.1.2">ğ’”</ci><apply id="S3.SS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.1.1.3.1.cmml" xref="S3.SS2.p5.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p5.3.m3.1.1.3.2.cmml" xref="S3.SS2.p5.3.m3.1.1.3.2">â„</ci><apply id="S3.SS2.p5.3.m3.1.1.3.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.p5.3.m3.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p5.3.m3.1.1.3.3.2.cmml" xref="S3.SS2.p5.3.m3.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.p5.3.m3.1.1.3.3.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3.3.3">ğ‘£</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">\bm{s}\in\mathbb{R}^{d_{v}}</annotation></semantics></math>. This scene representation contains information about the objects, the spatial and semantic relations between them, with respect to a particular question.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.5" class="ltx_p">The scene representation <math id="S3.SS2.p6.1.m1.1" class="ltx_Math" alttext="\bm{s}" display="inline"><semantics id="S3.SS2.p6.1.m1.1a"><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">ğ’”</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">ğ’”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">\bm{s}</annotation></semantics></math> is merged with the question embedding <math id="S3.SS2.p6.2.m2.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">\bm{q}</annotation></semantics></math> to compute a score for every possible answer <math id="S3.SS2.p6.3.m3.4" class="ltx_Math" alttext="\hat{\bm{y}}=\operatorname*{B}\left(\bm{s},\bm{q};\Theta_{y}\right)" display="inline"><semantics id="S3.SS2.p6.3.m3.4a"><mrow id="S3.SS2.p6.3.m3.4.4" xref="S3.SS2.p6.3.m3.4.4.cmml"><mover accent="true" id="S3.SS2.p6.3.m3.4.4.3" xref="S3.SS2.p6.3.m3.4.4.3.cmml"><mi id="S3.SS2.p6.3.m3.4.4.3.2" xref="S3.SS2.p6.3.m3.4.4.3.2.cmml">ğ’š</mi><mo id="S3.SS2.p6.3.m3.4.4.3.1" xref="S3.SS2.p6.3.m3.4.4.3.1.cmml">^</mo></mover><mo rspace="0.1389em" id="S3.SS2.p6.3.m3.4.4.2" xref="S3.SS2.p6.3.m3.4.4.2.cmml">=</mo><mrow id="S3.SS2.p6.3.m3.4.4.1.1" xref="S3.SS2.p6.3.m3.4.4.1.2.cmml"><mo lspace="0.1389em" rspace="0em" id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml">B</mo><mrow id="S3.SS2.p6.3.m3.4.4.1.1.1" xref="S3.SS2.p6.3.m3.4.4.1.2.cmml"><mo id="S3.SS2.p6.3.m3.4.4.1.1.1.2" xref="S3.SS2.p6.3.m3.4.4.1.2.cmml">(</mo><mi id="S3.SS2.p6.3.m3.2.2" xref="S3.SS2.p6.3.m3.2.2.cmml">ğ’”</mi><mo id="S3.SS2.p6.3.m3.4.4.1.1.1.3" xref="S3.SS2.p6.3.m3.4.4.1.2.cmml">,</mo><mi id="S3.SS2.p6.3.m3.3.3" xref="S3.SS2.p6.3.m3.3.3.cmml">ğ’’</mi><mo id="S3.SS2.p6.3.m3.4.4.1.1.1.4" xref="S3.SS2.p6.3.m3.4.4.1.2.cmml">;</mo><msub id="S3.SS2.p6.3.m3.4.4.1.1.1.1" xref="S3.SS2.p6.3.m3.4.4.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p6.3.m3.4.4.1.1.1.1.2" xref="S3.SS2.p6.3.m3.4.4.1.1.1.1.2.cmml">Î˜</mi><mi id="S3.SS2.p6.3.m3.4.4.1.1.1.1.3" xref="S3.SS2.p6.3.m3.4.4.1.1.1.1.3.cmml">y</mi></msub><mo id="S3.SS2.p6.3.m3.4.4.1.1.1.5" xref="S3.SS2.p6.3.m3.4.4.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.4b"><apply id="S3.SS2.p6.3.m3.4.4.cmml" xref="S3.SS2.p6.3.m3.4.4"><eq id="S3.SS2.p6.3.m3.4.4.2.cmml" xref="S3.SS2.p6.3.m3.4.4.2"></eq><apply id="S3.SS2.p6.3.m3.4.4.3.cmml" xref="S3.SS2.p6.3.m3.4.4.3"><ci id="S3.SS2.p6.3.m3.4.4.3.1.cmml" xref="S3.SS2.p6.3.m3.4.4.3.1">^</ci><ci id="S3.SS2.p6.3.m3.4.4.3.2.cmml" xref="S3.SS2.p6.3.m3.4.4.3.2">ğ’š</ci></apply><apply id="S3.SS2.p6.3.m3.4.4.1.2.cmml" xref="S3.SS2.p6.3.m3.4.4.1.1"><ci id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1">B</ci><ci id="S3.SS2.p6.3.m3.2.2.cmml" xref="S3.SS2.p6.3.m3.2.2">ğ’”</ci><ci id="S3.SS2.p6.3.m3.3.3.cmml" xref="S3.SS2.p6.3.m3.3.3">ğ’’</ci><apply id="S3.SS2.p6.3.m3.4.4.1.1.1.1.cmml" xref="S3.SS2.p6.3.m3.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m3.4.4.1.1.1.1.1.cmml" xref="S3.SS2.p6.3.m3.4.4.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p6.3.m3.4.4.1.1.1.1.2.cmml" xref="S3.SS2.p6.3.m3.4.4.1.1.1.1.2">Î˜</ci><ci id="S3.SS2.p6.3.m3.4.4.1.1.1.1.3.cmml" xref="S3.SS2.p6.3.m3.4.4.1.1.1.1.3">ğ‘¦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.4c">\hat{\bm{y}}=\operatorname*{B}\left(\bm{s},\bm{q};\Theta_{y}\right)</annotation></semantics></math>. Finally, <math id="S3.SS2.p6.4.m4.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S3.SS2.p6.4.m4.1a"><mover accent="true" id="S3.SS2.p6.4.m4.1.1" xref="S3.SS2.p6.4.m4.1.1.cmml"><mi id="S3.SS2.p6.4.m4.1.1.2" xref="S3.SS2.p6.4.m4.1.1.2.cmml">a</mi><mo id="S3.SS2.p6.4.m4.1.1.1" xref="S3.SS2.p6.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.1b"><apply id="S3.SS2.p6.4.m4.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1"><ci id="S3.SS2.p6.4.m4.1.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1.1">^</ci><ci id="S3.SS2.p6.4.m4.1.1.2.cmml" xref="S3.SS2.p6.4.m4.1.1.2">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.1c">\hat{a}</annotation></semantics></math> is the answer with maximum score in <math id="S3.SS2.p6.5.m5.1" class="ltx_Math" alttext="\hat{\bm{y}}" display="inline"><semantics id="S3.SS2.p6.5.m5.1a"><mover accent="true" id="S3.SS2.p6.5.m5.1.1" xref="S3.SS2.p6.5.m5.1.1.cmml"><mi id="S3.SS2.p6.5.m5.1.1.2" xref="S3.SS2.p6.5.m5.1.1.2.cmml">ğ’š</mi><mo id="S3.SS2.p6.5.m5.1.1.1" xref="S3.SS2.p6.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m5.1b"><apply id="S3.SS2.p6.5.m5.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1"><ci id="S3.SS2.p6.5.m5.1.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1.1">^</ci><ci id="S3.SS2.p6.5.m5.1.1.2.cmml" xref="S3.SS2.p6.5.m5.1.1.2">ğ’š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m5.1c">\hat{\bm{y}}</annotation></semantics></math>.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Visualizing MuRel network</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.6" class="ltx_p">Our model can also be leveraged to define visualization schemes finer than mere attention maps.
Especially, we can highlight important relations between image regions for answering a specific question.
At the end of the MuRel network, the visual features <math id="S3.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\{\bm{s}_{i}^{T}\}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">{</mo><msubsup id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.2.cmml">ğ’”</mi><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.3.cmml">i</mi><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><set id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.2">ğ’”</ci><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.1.3">ğ‘‡</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">\{\bm{s}_{i}^{T}\}</annotation></semantics></math> are aggregated using a <math id="S3.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\max" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">max</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><max id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"></max></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">\max</annotation></semantics></math> operation, yielding a <math id="S3.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="d_{v}-" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><mrow id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><msub id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2.cmml">d</mi><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.3" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.3.cmml">v</mi></msub><mo id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml">âˆ’</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">limit-from</csymbol><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.2">ğ‘‘</ci><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.3">ğ‘£</ci></apply><minus id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">d_{v}-</annotation></semantics></math>dimensional vector <math id="S3.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="\bm{s}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.4.m4.1a"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">ğ’”</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.4.m4.1b"><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1">ğ’”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.4.m4.1c">\bm{s}</annotation></semantics></math>.
Thus, we can compute a <span id="S3.SS2.SSS0.Px1.p1.6.1" class="ltx_text ltx_font_italic">contribution map</span> by measuring to what extent each region contributes to the final vector.
To do so, we compute the point-wise <math id="S3.SS2.SSS0.Px1.p1.5.m5.4" class="ltx_Math" alttext="\bm{c}=\arg\!\max_{i}\{\bm{s}_{i}^{T}\}\in[1,N]^{d_{v}}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.5.m5.4a"><mrow id="S3.SS2.SSS0.Px1.p1.5.m5.4.4" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.4" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.4.cmml">ğ’„</mi><mo id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.5" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.5.cmml">=</mo><mrow id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.3.cmml">arg</mi><mo id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2a" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.cmml">â¡</mo><mrow id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.3.cmml"><msub id="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.2.cmml">max</mi><mi id="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2a" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.3.cmml">â¡</mo><mrow id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.3.cmml">{</mo><msubsup id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.2.cmml">ğ’”</mi><mi id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.3.cmml">i</mi><mi id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.3.cmml">}</mo></mrow></mrow></mrow><mo id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.6" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.6.cmml">âˆˆ</mo><msup id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.cmml"><mrow id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.2.1" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.1.cmml">[</mo><mn id="S3.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.cmml">1</mn><mo id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.1.cmml">,</mo><mi id="S3.SS2.SSS0.Px1.p1.5.m5.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.cmml">N</mi><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.2.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.1.cmml">]</mo></mrow><msub id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.2.cmml">d</mi><mi id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.3.cmml">v</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.5.m5.4b"><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4"><and id="S3.SS2.SSS0.Px1.p1.5.m5.4.4a.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4"></and><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4b.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4"><eq id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.5.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.5"></eq><ci id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.4">ğ’„</ci><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2"><arg id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.3"></arg><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2"><apply id="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1">subscript</csymbol><max id="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.2"></max><ci id="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.3.3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1">superscript</csymbol><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.2">ğ’”</ci><ci id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.2.3">ğ‘–</ci></apply><ci id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.2.2.2.1.3">ğ‘‡</ci></apply></apply></apply></apply><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4c.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4"><in id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.6.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.6"></in><share href="#S3.SS2.SSS0.Px1.p1.5.m5.4.4.2.cmml" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4d.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4"></share><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7">superscript</csymbol><interval closure="closed" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.2.2"><cn type="integer" id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1">1</cn><ci id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2">ğ‘</ci></interval><apply id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.2">ğ‘‘</ci><ci id="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.4.4.7.3.3">ğ‘£</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.5.m5.4c">\bm{c}=\arg\!\max_{i}\{\bm{s}_{i}^{T}\}\in[1,N]^{d_{v}}</annotation></semantics></math>, and measure the occurrence frequency of each region in this vector <math id="S3.SS2.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\bm{c}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.6.m6.1a"><mi id="S3.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS2.SSS0.Px1.p1.6.m6.1.1.cmml">ğ’„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.6.m6.1b"><ci id="S3.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.6.m6.1.1">ğ’„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.6.m6.1c">\bm{c}</annotation></semantics></math>. This provides a value for each region that estimates its contribution to the final vector.
Interestingly, this process can be done after each cell, and not exclusively at the last one. Intuitively, it measures what the contribution map would have been if the iterative process had stopped at this point.
As we can see in FiguresÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,<a href="#S3.F3" title="Figure 3 â€£ 3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>,<a href="#S4.F5" title="Figure 5 â€£ TDIUC â€£ 4.3 State of the art comparison â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, these relevance scores match human intuition and can be used to explain the modelâ€™s decision, even if the network has not been trained with any selection mechanism.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.5" class="ltx_p">Similarly, we are able to visualize the pairwise relationships involved in the prediction of the MuRel cell. The first step is to find <math id="S3.SS2.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="i^{\star}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.1.m1.1a"><msup id="S3.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml">i</mi><mo id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml">â‹†</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.1.m1.1b"><apply id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2">ğ‘–</ci><ci id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3">â‹†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.1.m1.1c">i^{\star}</annotation></semantics></math>, which is the region that is the most impacted by the pairwise modeling. It is the region such that <math id="S3.SS2.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\|\frac{\check{\bm{e}}_{i}}{\bm{x}_{i}}\|_{2}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.2.m2.1a"><msub id="S3.SS2.SSS0.Px1.p2.2.m2.1.2" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.cmml"><mrow id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.2" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.2.1" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.1.1.cmml">â€–</mo><mfrac id="S3.SS2.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.cmml"><msub id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.cmml"><mover accent="true" id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.cmml"><mi id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.2" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.2.cmml">ğ’†</mi><mo id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.1" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.1.cmml">Ë‡</mo></mover><mi id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.3" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.3.cmml">i</mi></msub><msub id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.2.cmml">ğ’™</mi><mi id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.3" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.3.cmml">i</mi></msub></mfrac><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.2.2" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.1.1.cmml">â€–</mo></mrow><mn id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.3" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2">subscript</csymbol><apply id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.2.2.1">norm</csymbol><apply id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1"><divide id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1"></divide><apply id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2">subscript</csymbol><apply id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2"><ci id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.1">Ë‡</ci><ci id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.2.2">ğ’†</ci></apply><ci id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.2">ğ’™</ci><ci id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn type="integer" id="S3.SS2.SSS0.Px1.p2.2.m2.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.2.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.2.m2.1c">\|\frac{\check{\bm{e}}_{i}}{\bm{x}_{i}}\|_{2}</annotation></semantics></math> is maximal (cf. EquationÂ (<a href="#S3.E4" title="In Pairwise interactions â€£ 3.1 MuRel cell â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>)). This bounding box is shown in green in all our visualizations. We then measure the contribution of every other region to <math id="S3.SS2.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="i^{\star}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.3.m3.1a"><msup id="S3.SS2.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml">i</mi><mo id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml">â‹†</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2">ğ‘–</ci><ci id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3">â‹†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.3.m3.1c">i^{\star}</annotation></semantics></math> using the occurrence frequencies in <math id="S3.SS2.SSS0.Px1.p2.4.m4.2" class="ltx_Math" alttext="\arg\!\max_{j}\bm{r}_{i,j}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.4.m4.2a"><mrow id="S3.SS2.SSS0.Px1.p2.4.m4.2.3" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.cmml"><mi id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.1.cmml">arg</mi><mo id="S3.SS2.SSS0.Px1.p2.4.m4.2.3a" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.cmml">â¡</mo><mrow id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.cmml"><msub id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.2.cmml">max</mi><mi id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.3" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.3.cmml">j</mi></msub><mo lspace="0.167em" id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2a" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.cmml">â¡</mo><msub id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2.cmml"><mi id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2.2.cmml">ğ’“</mi><mrow id="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.4" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.3.cmml"><mi id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.4.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.2.cmml">j</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.4.m4.2b"><apply id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3"><arg id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.1"></arg><apply id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2"><apply id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1">subscript</csymbol><max id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.2"></max><ci id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.1.3">ğ‘—</ci></apply><apply id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.3.2.2.2">ğ’“</ci><list id="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.4"><ci id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1">ğ‘–</ci><ci id="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.2.2.2.2">ğ‘—</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.4.m4.2c">\arg\!\max_{j}\bm{r}_{i,j}</annotation></semantics></math>. We show in red the regions whose contribution to <math id="S3.SS2.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="i^{\star}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.5.m5.1a"><msup id="S3.SS2.SSS0.Px1.p2.5.m5.1.1" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml">i</mi><mo id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml">â‹†</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.5.m5.1b"><apply id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2">ğ‘–</ci><ci id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3">â‹†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.5.m5.1c">i^{\star}</annotation></semantics></math> is above a certain threshold (0.2 in our visualizations). If there is no such region, the green box is not shown.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Connection to previous work</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">We can draw a comparison between our MuRel network and the FiLM network proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.
Beyond the fact that their model is built for the synthetic CLEVR dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and ours processes real data, some connections can be found between both models.
In their work, the image passes through multiple residual cells, whereas we only have one cell through which we iterate. In FiLM, the multimodal interaction is modeled with a feature-wise affine modulation, while we use a bilinear fusion strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> which seems better suited to real world data.
Finally, both MuRel and FiLM leverage the spatial structure of the image representation to model the relations between regions.
In FiLM, the image is represented with a fully-convolutional network which outputs a feature map disposed in a fixed spatial grid. With this structure on image features, the relations between regions are modeled with a <math id="S3.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1"><times id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2">3</cn><cn type="integer" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">3\times 3</annotation></semantics></math> convolution inside each residual block. Thus, the representation of each region depends on its neighbours in the locally-connected graph induced by the fixed grid structure.
In our MuRel network, the image is represented as a set of localized features. This makes the relational modeling non trivial. As we want to model relations between regions that are potentially far apart, we consider that the set of regions forms a complete graph, where each region is connected to all the others.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Datasets</span>: We validate the benefits of the MuRel cell and the MuRel network on three recent datasets.
VQA 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> is the most used dataset. It comes with a training set, a validation set and an online testing set. We provide a fine grained analysis on the validation set, while we compare MuRel to the state-of-the-art models on the testing set.
Then, we use VQA Changing Priors v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> to demonstrate the generalization capacity of MuRel. VQA-CP v2 uses the same data as in VQA 2.0, but proposes different distribution of answers per question between training and validation splits.
Finally, we use the TDIUC dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to construct a more detailed analysis of our modelâ€™s performance on 12 well-defined types of question. TDIUC is currently the biggest dataset for visual question answering.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Hyper-parameters</span>: We use standard features extraction, preprocessings and loss function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
We use the recent Bottom-up features provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> to represent our image as a set of 36 localized regions.
For the question embedding, we use the pretrained Skip-thought encoder from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
Inspired by recent works, we use Adam as optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> with a learning scheduler <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.
More details about the experimental setup are given in appendix.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model validation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We compare MuRel against models trained on the same Bottom-up features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> which are required to reach the best performances.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.1.1" class="ltx_tr">
<th id="S4.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Model</th>
<th id="S4.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">VQA 2.0</th>
<th id="S4.T1.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">VQA CP v2</th>
<th id="S4.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">TDIUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.2.1" class="ltx_tr">
<td id="S4.T1.3.2.1.1" class="ltx_td ltx_align_center ltx_border_t">Attention baseline</td>
<td id="S4.T1.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t">63.44</td>
<td id="S4.T1.3.2.1.3" class="ltx_td ltx_align_center ltx_border_t">38.04</td>
<td id="S4.T1.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t">86.96</td>
</tr>
<tr id="S4.T1.3.3.2" class="ltx_tr">
<td id="S4.T1.3.3.2.1" class="ltx_td ltx_align_center ltx_border_bb">MuRel</td>
<td id="S4.T1.3.3.2.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.3.3.2.2.1" class="ltx_text ltx_font_bold">65.14</span></td>
<td id="S4.T1.3.3.2.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.3.3.2.3.1" class="ltx_text ltx_font_bold">39.54</span></td>
<td id="S4.T1.3.3.2.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.3.3.2.4.1" class="ltx_text ltx_font_bold">88.20</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S4.T1.6.1" class="ltx_text ltx_font_bold">Comparing MuRel to Attention.</span> Comparison of the MuRel strategy against a strong Attention-based model on the VQA 2.0 <span id="S4.T1.7.2" class="ltx_text ltx_font_italic">val</span>, VQA-CP v2 and TDIUC datasets. Both models have an equivalent number of parameters (<math id="S4.T1.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.2.m1.1b"><mo id="S4.T1.2.m1.1.1" xref="S4.T1.2.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.m1.1c"><csymbol cd="latexml" id="S4.T1.2.m1.1.1.cmml" xref="S4.T1.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.m1.1d">\sim</annotation></semantics></math>60 million) and are trained on the same features following the same experimental setup.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Pairwise</th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Iter.</th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">VQA 2.0</th>
<th id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">VQA CP v2</th>
<th id="S4.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">TDIUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">âœ—</th>
<th id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">âœ—</th>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">64.13</td>
<td id="S4.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">38.88</td>
<td id="S4.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">87.50</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">âœ“</th>
<th id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">âœ—</th>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_center">64.57</td>
<td id="S4.T2.1.3.2.4" class="ltx_td ltx_align_center">39.12</td>
<td id="S4.T2.1.3.2.5" class="ltx_td ltx_align_center">87.86</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">âœ—</th>
<th id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">âœ“</th>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_nopad_l ltx_align_center">64.72</td>
<td id="S4.T2.1.4.3.4" class="ltx_td ltx_align_center">39.37</td>
<td id="S4.T2.1.4.3.5" class="ltx_td ltx_align_center">87.92</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<th id="S4.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">âœ“</th>
<th id="S4.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">âœ“</th>
<td id="S4.T2.1.5.4.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S4.T2.1.5.4.3.1" class="ltx_text ltx_font_bold">65.14</span></td>
<td id="S4.T2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.1.5.4.4.1" class="ltx_text ltx_font_bold">39.54</span></td>
<td id="S4.T2.1.5.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.1.5.4.5.1" class="ltx_text ltx_font_bold">88.20</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S4.T2.4.1" class="ltx_text ltx_font_bold">Ablation study of MuRel</span>. Experimental validation of the pairwise module and the iterative processing on the VQA 2.0 <span id="S4.T2.5.2" class="ltx_text ltx_font_italic">val</span>, VQA-CP v2 and TDIUC datasets.</figcaption>
</figure>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Comparison to Attention-based model</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">In TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.2 Model validation â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we compare MuRel against a strong attentional model based on bilinear fusions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, which encompasses a multi-glimpses attentional process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. The goal of this experiments is to compare our approach with strong baselines for real VQA in controlled conditions. In addition to using the same bottom-up features, which are crucial for fair comparisons, we also dimension the attention-based baseline to have an equivalent amount of learned parameters than MuRel (<math id="S4.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">\sim</annotation></semantics></math>60 millions including those from the GRU encoder). Also, we train it following the same experimental setup to insure competitiveness.
MuRel reaches a higher accuracy on the three datasets. We report a significant gain of +1.70 on VQA 2.0 and +1.50 on VQA CP v2.
Not only these results validate the ability of MuRel to better model interactions between the question and the image, but also to generalize when the distribution of the answers per question are completely different between the training and validation set as in VQA CP v2.
A gain of +1.24 on TDIUC demonstrates the richer modeling capacity of MuRel in a fine-grained context of 12 well delimited question types.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Ablation study</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">In TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Model validation â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we compare three ablated instances of MuRel to its complete form.
First, we validate the benefits of the pairwise module. Adding it to a vanilla MuRel without iterative process leads to higher accuracy on every datasets. In fact, between line 1 and 2, we report a gain of +0.44 on VQA 2.0, +0.24 on VQA CP v2 and +0.36 on TDIUC.
Secondly, we validate the interest of the iterative process. Between line 1 et 3, we report a gain of +0.59 on VQA 2.0, +0.49 on VQA CP v2 and +0.42 on TDIUC.
Notably, this modification does not add any parameters, because we iterate over a single MuRel cell.
Unsharing the weights by using a different MuRel cell for each step gives similar results.
Finally, the pairwise module and the iterative process are added to create the complete MuRel network. This instance (in line 4) reaches the highest accuracy on the three datasets. Interestingly, the gains provided by the combination of the two methods are sometimes larger than those of each one separately. For instance, we report a gain of +1.01 on VQA 2.0 between line 1 and 4. This attests to the complementary of the two modules.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Number of reasoning steps</h4>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.1" class="ltx_p">In FigureÂ <a href="#S4.F4" title="Figure 4 â€£ Number of reasoning steps â€£ 4.2 Model validation â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>,
we perform an analysis of the iterative process.
We train four different MuRel networks on the VQA 2.0 <span id="S4.SS2.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">train</span> split, each with a different number of iterations over the MuRel cell. Performance is reported on <span id="S4.SS2.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">val</span> split.
Networks with two and three steps respectively provides a gain of +0.30 and +0.57 in overall accuracy on VQA 2.0 over the network with a single step.
An interesting aspect of the iterative process of MuRel is that the four networks have exactly the same amount of parameters, but the accuracy significantly varies with respect to the number of steps.
While the accuracy for the answer type involving numbers keeps increasing, we report a decrease in overall accuracy at four reasoning steps.
Counting is a challenging task: not only does the model need to detect every occurrence of the desired object, but also the representation computed after the final aggregation must keep the information of the number of detected instances. The complexity of this question may require deeper relational modeling, and thus benefit from a higher number of iterations over the MuRel cell.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/1902.09487/assets/images/visu_cell.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="342" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span> <span id="S4.F4.3.1" class="ltx_text ltx_font_bold">Number of iterations</span>. Impact of the number of steps in the iterative process on the different question types of VQA 2.0 <span id="S4.F4.4.2" class="ltx_text ltx_font_italic">val</span>.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>State of the art comparison</h3>

<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">VQA 2.0</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">In TableÂ <a href="#S4.T3" title="Table 3 â€£ VQA 2.0 â€£ 4.3 State of the art comparison â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we compare MuRel to the most recent contributions on the VQA 2.0 dataset. For fairness considerations, all the scores correspond to models trained on the VQA 2.0 <span id="S4.SS3.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">train+val</span> split, using the Bottom-up visual features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Interestingly, our model surpasses both MUTAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and MLB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, which correspond to some of the latest development in visual attention and bilinear models. This tends to indicate that VQA models can benefit from retaining local information in mulitmodal vectors instead of scalar coefficients.
Moreover, our model greatly improves over the recent method proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> where the regions are structured using pairwise attention scores, which are leveraged through spatial graph convolutions. This shows the interest of our spatial-semantic pairwise modeling between all possible pairs of regions.
Finally, even though we did not extensively tune the hyperparameters of our model, our overall score on the <span id="S4.SS3.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">test-dev</span> split is highly competitive with state-of-the-art methods. In particular, we are comparable to Pythia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> who won the VQA Challenge 2018. Please note that they improve their overall scores up to 70.01% when they include multiple types of visual features and more training data. Also, we did not report the score of 69.52% obtained by BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> as they train their model on extra data from the Visual Genome dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.2.3.1" class="ltx_tr">
<th id="S4.T3.2.3.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T3.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S4.T3.2.3.1.2.1" class="ltx_text ltx_font_italic">test-dev</span></th>
<th id="S4.T3.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.2.3.1.3.1" class="ltx_text ltx_font_italic">test-std</span></th>
</tr>
<tr id="S4.T3.2.4.2" class="ltx_tr">
<th id="S4.T3.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="S4.T3.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Yes/No</th>
<th id="S4.T3.2.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Num.</th>
<th id="S4.T3.2.4.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Other</th>
<th id="S4.T3.2.4.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">All</th>
<th id="S4.T3.2.4.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">All</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.2.5.1" class="ltx_tr">
<th id="S4.T3.2.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Bottom-up</th>
<td id="S4.T3.2.5.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.2.5.1.2.1" class="ltx_text">81.82</span></td>
<td id="S4.T3.2.5.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.2.5.1.3.1" class="ltx_text">44.21</span></td>
<td id="S4.T3.2.5.1.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.2.5.1.4.1" class="ltx_text">56.05</span></td>
<td id="S4.T3.2.5.1.5" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.2.5.1.5.1" class="ltx_text">65.32</span></td>
<td id="S4.T3.2.5.1.6" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.2.5.1.6.1" class="ltx_text">65.67</span></td>
</tr>
<tr id="S4.T3.2.6.2" class="ltx_tr">
<th id="S4.T3.2.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite></th>
</tr>
<tr id="S4.T3.2.7.3" class="ltx_tr">
<th id="S4.T3.2.7.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Graph Att.</th>
<td id="S4.T3.2.7.3.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.7.3.2.1" class="ltx_text">-</span></td>
<td id="S4.T3.2.7.3.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.7.3.3.1" class="ltx_text">-</span></td>
<td id="S4.T3.2.7.3.4" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.7.3.4.1" class="ltx_text">-</span></td>
<td id="S4.T3.2.7.3.5" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.7.3.5.1" class="ltx_text">-</span></td>
<td id="S4.T3.2.7.3.6" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.7.3.6.1" class="ltx_text">66.18</span></td>
</tr>
<tr id="S4.T3.2.8.4" class="ltx_tr">
<th id="S4.T3.2.8.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite></th>
</tr>
<tr id="S4.T3.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">MUTAN<math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S4.T3.1.1.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.1.1.2.1" class="ltx_text">82.88</span></td>
<td id="S4.T3.1.1.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.1.1.3.1" class="ltx_text">44.54</span></td>
<td id="S4.T3.1.1.4" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.1.1.4.1" class="ltx_text">56.50</span></td>
<td id="S4.T3.1.1.5" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.1.1.5.1" class="ltx_text">66.01</span></td>
<td id="S4.T3.1.1.6" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.1.1.6.1" class="ltx_text">66.38</span></td>
</tr>
<tr id="S4.T3.2.9.5" class="ltx_tr">
<th id="S4.T3.2.9.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite></th>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<th id="S4.T3.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">MLB<math id="S4.T3.2.2.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T3.2.2.1.m1.1a"><mo id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><ci id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S4.T3.2.2.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.2.2.1" class="ltx_text">83.58</span></td>
<td id="S4.T3.2.2.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.2.3.1" class="ltx_text">44.92</span></td>
<td id="S4.T3.2.2.4" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.2.4.1" class="ltx_text">56.34</span></td>
<td id="S4.T3.2.2.5" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.2.5.1" class="ltx_text">66.27</span></td>
<td id="S4.T3.2.2.6" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.2.6.1" class="ltx_text">66.62</span></td>
</tr>
<tr id="S4.T3.2.10.6" class="ltx_tr">
<th id="S4.T3.2.10.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></th>
</tr>
<tr id="S4.T3.2.11.7" class="ltx_tr">
<th id="S4.T3.2.11.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">DA-NTN</th>
<td id="S4.T3.2.11.7.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.11.7.2.1" class="ltx_text">84.29</span></td>
<td id="S4.T3.2.11.7.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.11.7.3.1" class="ltx_text">47.14</span></td>
<td id="S4.T3.2.11.7.4" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.11.7.4.1" class="ltx_text">57.92</span></td>
<td id="S4.T3.2.11.7.5" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.11.7.5.1" class="ltx_text">67.56</span></td>
<td id="S4.T3.2.11.7.6" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.11.7.6.1" class="ltx_text">67.94</span></td>
</tr>
<tr id="S4.T3.2.12.8" class="ltx_tr">
<th id="S4.T3.2.12.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite></th>
</tr>
<tr id="S4.T3.2.13.9" class="ltx_tr">
<th id="S4.T3.2.13.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Pythia</th>
<td id="S4.T3.2.13.9.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.13.9.2.1" class="ltx_text">-</span></td>
<td id="S4.T3.2.13.9.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.13.9.3.1" class="ltx_text">-</span></td>
<td id="S4.T3.2.13.9.4" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.13.9.4.1" class="ltx_text">-</span></td>
<td id="S4.T3.2.13.9.5" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.13.9.5.1" class="ltx_text">68.05</span></td>
<td id="S4.T3.2.13.9.6" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.13.9.6.1" class="ltx_text">-</span></td>
</tr>
<tr id="S4.T3.2.14.10" class="ltx_tr">
<th id="S4.T3.2.14.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite></th>
</tr>
<tr id="S4.T3.2.15.11" class="ltx_tr">
<th id="S4.T3.2.15.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Counter</th>
<td id="S4.T3.2.15.11.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.15.11.2.1" class="ltx_text">83.14</span></td>
<td id="S4.T3.2.15.11.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.15.11.3.1" class="ltx_text ltx_font_bold">51.62</span></td>
<td id="S4.T3.2.15.11.4" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.15.11.4.1" class="ltx_text ltx_font_bold">58.97</span></td>
<td id="S4.T3.2.15.11.5" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.15.11.5.1" class="ltx_text ltx_font_bold">68.09</span></td>
<td id="S4.T3.2.15.11.6" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T3.2.15.11.6.1" class="ltx_text ltx_font_bold">68.41</span></td>
</tr>
<tr id="S4.T3.2.16.12" class="ltx_tr">
<th id="S4.T3.2.16.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite></th>
</tr>
<tr id="S4.T3.2.17.13" class="ltx_tr">
<th id="S4.T3.2.17.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t">MuRel</th>
<td id="S4.T3.2.17.13.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.2.17.13.2.1" class="ltx_text ltx_font_bold">84.77</span></td>
<td id="S4.T3.2.17.13.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">49.84</td>
<td id="S4.T3.2.17.13.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">57.85</td>
<td id="S4.T3.2.17.13.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">68.03</td>
<td id="S4.T3.2.17.13.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.2.17.13.6.1" class="ltx_text ltx_font_bold">68.41</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span> <span id="S4.T3.9.1" class="ltx_text ltx_font_bold">State-of-the-art comparison on the VQA 2.0 dataset.</span> Results on <span id="S4.T3.10.2" class="ltx_text ltx_font_italic">test-dev</span> and <span id="S4.T3.11.3" class="ltx_text ltx_font_italic">test-std</span> splits. All these models were trained on the same training set (VQA 2.0 <span id="S4.T3.12.4" class="ltx_text ltx_font_italic">train+val</span>), using the Bottom-up features provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. No ensembling methods have been used. <math id="S4.T3.4.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T3.4.m1.1b"><mo id="S4.T3.4.m1.1.1" xref="S4.T3.4.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.m1.1c"><ci id="S4.T3.4.m1.1.1.cmml" xref="S4.T3.4.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.m1.1d">\dagger</annotation></semantics></math> have been trained by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">TDIUC</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">One of the core aspect of VQA models lies in their ability to address different tasks. The TDIUC dataset enables a detailed analysis of the strengths and limitations of a model by evaluating its performance on different types of question. We show in TableÂ <a href="#S4.T4" title="Table 4 â€£ TDIUC â€£ 4.3 State of the art comparison â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> a detailed comparison of recent models to our MuRel. We obtain state-of-the-art results on the Overall Accuracy and the arithmetic mean of per-type accuracies (A-MPT), and surpass by a significant margin the second best model proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Interestingly, we improve over this model even though it uses a combination of Bottom-up and fixed-grid features, as well as a supervision on the question types (hence its 100% result on the <span id="S4.SS3.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Absurd</span> task).
MuRel notably surpasses all previous methods on the Positional reasoning (+5.9 over MCB), Counting (+8.53 over QTA) questions. These improvements are likely due to the pairwise structure induced within the MuRel cell, which makes the answer prediction depend on the spatial and semantic relations between regions. The effectiveness of our per-region context modelling is also demonstrated by our the improvement on Scene recognition questions. For these questions, representing the image as a collection of independent objects shows lower performance than replacing each of them in its spatial and semantic context.
Interestingly, our results on the harmonic mean of per-type accuracies (H-MPT) are lower than state-of-the-art. For MuRel, this harmonic metric is significantly harmed by our low score of 21.43% on the <span id="S4.SS3.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">Utility and Affordances</span> task. As these questions concern the possible usages of objects present in the scene (such as <span id="S4.SS3.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_italic">Can you eat the yellow object?</span>), and are not directly related to the visual understanding of the scene.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">RAU*</td>
<td id="S4.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">MCB*</td>
<td id="S4.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">QTA</td>
<td id="S4.T4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.1.1.1.5.1" class="ltx_text">MuRel</span></td>
</tr>
<tr id="S4.T4.1.2.2" class="ltx_tr">
<td id="S4.T4.1.2.2.1" class="ltx_td"></td>
<td id="S4.T4.1.2.2.2" class="ltx_td ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite></td>
<td id="S4.T4.1.2.2.3" class="ltx_td ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite></td>
<td id="S4.T4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite></td>
</tr>
<tr id="S4.T4.1.3.3" class="ltx_tr">
<td id="S4.T4.1.3.3.1" class="ltx_td ltx_align_center ltx_border_t">Bottom-up</td>
<td id="S4.T4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S4.T4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S4.T4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">âœ“</td>
<td id="S4.T4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">âœ“</td>
</tr>
<tr id="S4.T4.1.4.4" class="ltx_tr">
<td id="S4.T4.1.4.4.1" class="ltx_td ltx_align_center ltx_border_t">Scene Reco.</td>
<td id="S4.T4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_t">93.96</td>
<td id="S4.T4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_t">93.06</td>
<td id="S4.T4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.80</td>
<td id="S4.T4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.4.4.5.1" class="ltx_text ltx_font_bold">96.11</span></td>
</tr>
<tr id="S4.T4.1.5.5" class="ltx_tr">
<td id="S4.T4.1.5.5.1" class="ltx_td ltx_align_center">Sport Reco.</td>
<td id="S4.T4.1.5.5.2" class="ltx_td ltx_align_center">93.47</td>
<td id="S4.T4.1.5.5.3" class="ltx_td ltx_align_center">92.77</td>
<td id="S4.T4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">95.55</td>
<td id="S4.T4.1.5.5.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.5.5.5.1" class="ltx_text ltx_font_bold">96.20</span></td>
</tr>
<tr id="S4.T4.1.6.6" class="ltx_tr">
<td id="S4.T4.1.6.6.1" class="ltx_td ltx_align_center">Color Attr.</td>
<td id="S4.T4.1.6.6.2" class="ltx_td ltx_align_center">66.86</td>
<td id="S4.T4.1.6.6.3" class="ltx_td ltx_align_center">68.54</td>
<td id="S4.T4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">60.16</td>
<td id="S4.T4.1.6.6.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.6.6.5.1" class="ltx_text ltx_font_bold">74.43</span></td>
</tr>
<tr id="S4.T4.1.7.7" class="ltx_tr">
<td id="S4.T4.1.7.7.1" class="ltx_td ltx_align_center">Other Attr.</td>
<td id="S4.T4.1.7.7.2" class="ltx_td ltx_align_center">56.49</td>
<td id="S4.T4.1.7.7.3" class="ltx_td ltx_align_center">56.72</td>
<td id="S4.T4.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">54.36</td>
<td id="S4.T4.1.7.7.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.7.7.5.1" class="ltx_text ltx_font_bold">58.19</span></td>
</tr>
<tr id="S4.T4.1.8.8" class="ltx_tr">
<td id="S4.T4.1.8.8.1" class="ltx_td ltx_align_center">Activity Reco.</td>
<td id="S4.T4.1.8.8.2" class="ltx_td ltx_align_center">51.60</td>
<td id="S4.T4.1.8.8.3" class="ltx_td ltx_align_center">52.35</td>
<td id="S4.T4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">60.10</td>
<td id="S4.T4.1.8.8.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.8.8.5.1" class="ltx_text ltx_font_bold">63.83</span></td>
</tr>
<tr id="S4.T4.1.9.9" class="ltx_tr">
<td id="S4.T4.1.9.9.1" class="ltx_td ltx_align_center">Pos. Reasoning</td>
<td id="S4.T4.1.9.9.2" class="ltx_td ltx_align_center">35.26</td>
<td id="S4.T4.1.9.9.3" class="ltx_td ltx_align_center">35.40</td>
<td id="S4.T4.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">34.71</td>
<td id="S4.T4.1.9.9.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.9.9.5.1" class="ltx_text ltx_font_bold">41.19</span></td>
</tr>
<tr id="S4.T4.1.10.10" class="ltx_tr">
<td id="S4.T4.1.10.10.1" class="ltx_td ltx_align_center">Object Reco.</td>
<td id="S4.T4.1.10.10.2" class="ltx_td ltx_align_center">86.11</td>
<td id="S4.T4.1.10.10.3" class="ltx_td ltx_align_center">85.54</td>
<td id="S4.T4.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">86.98</td>
<td id="S4.T4.1.10.10.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.10.10.5.1" class="ltx_text ltx_font_bold">89.41</span></td>
</tr>
<tr id="S4.T4.1.11.11" class="ltx_tr">
<td id="S4.T4.1.11.11.1" class="ltx_td ltx_align_center">Absurd</td>
<td id="S4.T4.1.11.11.2" class="ltx_td ltx_align_center">96.08</td>
<td id="S4.T4.1.11.11.3" class="ltx_td ltx_align_center">84.82</td>
<td id="S4.T4.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.1.11.11.4.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S4.T4.1.11.11.5" class="ltx_td ltx_align_center">99.8</td>
</tr>
<tr id="S4.T4.1.12.12" class="ltx_tr">
<td id="S4.T4.1.12.12.1" class="ltx_td ltx_align_center">Util. and Afford.</td>
<td id="S4.T4.1.12.12.2" class="ltx_td ltx_align_center">31.58</td>
<td id="S4.T4.1.12.12.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.12.12.3.1" class="ltx_text ltx_font_bold">35.09</span></td>
<td id="S4.T4.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r">31.48</td>
<td id="S4.T4.1.12.12.5" class="ltx_td ltx_align_center">21.43</td>
</tr>
<tr id="S4.T4.1.13.13" class="ltx_tr">
<td id="S4.T4.1.13.13.1" class="ltx_td ltx_align_center">Object Presence</td>
<td id="S4.T4.1.13.13.2" class="ltx_td ltx_align_center">94.38</td>
<td id="S4.T4.1.13.13.3" class="ltx_td ltx_align_center">93.64</td>
<td id="S4.T4.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r">94.55</td>
<td id="S4.T4.1.13.13.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.13.13.5.1" class="ltx_text ltx_font_bold">95.75</span></td>
</tr>
<tr id="S4.T4.1.14.14" class="ltx_tr">
<td id="S4.T4.1.14.14.1" class="ltx_td ltx_align_center">Counting</td>
<td id="S4.T4.1.14.14.2" class="ltx_td ltx_align_center">48.43</td>
<td id="S4.T4.1.14.14.3" class="ltx_td ltx_align_center">51.01</td>
<td id="S4.T4.1.14.14.4" class="ltx_td ltx_align_center ltx_border_r">53.25</td>
<td id="S4.T4.1.14.14.5" class="ltx_td ltx_align_center"><span id="S4.T4.1.14.14.5.1" class="ltx_text ltx_font_bold">61.78</span></td>
</tr>
<tr id="S4.T4.1.15.15" class="ltx_tr">
<td id="S4.T4.1.15.15.1" class="ltx_td ltx_align_center">Sentiment</td>
<td id="S4.T4.1.15.15.2" class="ltx_td ltx_align_center">60.09</td>
<td id="S4.T4.1.15.15.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.15.15.3.1" class="ltx_text ltx_font_bold">66.25</span></td>
<td id="S4.T4.1.15.15.4" class="ltx_td ltx_align_center ltx_border_r">64.38</td>
<td id="S4.T4.1.15.15.5" class="ltx_td ltx_align_center">60.65</td>
</tr>
<tr id="S4.T4.1.16.16" class="ltx_tr">
<td id="S4.T4.1.16.16.1" class="ltx_td ltx_align_center ltx_border_t">Overall (A-MPT)</td>
<td id="S4.T4.1.16.16.2" class="ltx_td ltx_align_center ltx_border_t">67.81</td>
<td id="S4.T4.1.16.16.3" class="ltx_td ltx_align_center ltx_border_t">67.90</td>
<td id="S4.T4.1.16.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.11</td>
<td id="S4.T4.1.16.16.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.16.16.5.1" class="ltx_text ltx_font_bold">71.56</span></td>
</tr>
<tr id="S4.T4.1.17.17" class="ltx_tr">
<td id="S4.T4.1.17.17.1" class="ltx_td ltx_align_center">Overall (H-MPT)</td>
<td id="S4.T4.1.17.17.2" class="ltx_td ltx_align_center">59.00</td>
<td id="S4.T4.1.17.17.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.17.17.3.1" class="ltx_text ltx_font_bold">60.47</span></td>
<td id="S4.T4.1.17.17.4" class="ltx_td ltx_align_center ltx_border_r">60.08</td>
<td id="S4.T4.1.17.17.5" class="ltx_td ltx_align_center">59.30</td>
</tr>
<tr id="S4.T4.1.18.18" class="ltx_tr">
<td id="S4.T4.1.18.18.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Overall Accuracy</td>
<td id="S4.T4.1.18.18.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">84.26</td>
<td id="S4.T4.1.18.18.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">81.86</td>
<td id="S4.T4.1.18.18.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">85.03</td>
<td id="S4.T4.1.18.18.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T4.1.18.18.5.1" class="ltx_text ltx_font_bold">88.20</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S4.T4.3.1" class="ltx_text ltx_font_bold">State-of-the-art comparison on the TDIUC dataset.</span> *Â trained by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/1902.09487/assets/x4.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S4.F5.2.1" class="ltx_text ltx_font_bold">Qualitative evaluation of MuRel</span>. Visualization of the importance maps with colored regions related to the relational mechanism. As in Figure <a href="#S3.F3" title="Figure 3 â€£ 3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the most selected regions by the implicit attentional mechanism are shown in brighter. The green region is the most impacted by the pairwise modeling, while the red regions impact the green regions the most. These colored regions are only represented if they are greater than a certain threshold.</figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">VQA-CP v2</h4>

<div id="S4.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px3.p1.1" class="ltx_p">This dataset has been proposed to evaluate and reduce the question-oriented bias in VQA models. In particular, the distributions of answers with respect to question types differ from <span id="S4.SS3.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">train</span> to <span id="S4.SS3.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">val</span> splits.
In TableÂ <a href="#S4.T5" title="Table 5 â€£ VQA-CP v2 â€£ 4.3 State of the art comparison â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we report the scores of two recent baselines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, on which we improve significantly. In particular, we demonstrate an important gain over GVQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, whose architecture is designed to focus on Yes/No questions. However, since both methods do not use the Bottom-up features, the fairness of the comparison can be questioned. So we also train an attention model similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> using these Bottom-up region representation.
We observe that MuRel provides a substantial gain over this strong attention baseline. Given the distribution mismatch between <span id="S4.SS3.SSS0.Px3.p1.1.3" class="ltx_text ltx_font_italic">train</span> and <span id="S4.SS3.SSS0.Px3.p1.1.4" class="ltx_text ltx_font_italic">val</span> splits, models that only focus on linguistic biases to answer the question are systematically penalized on their <span id="S4.SS3.SSS0.Px3.p1.1.5" class="ltx_text ltx_font_italic">val</span> scores. This property of VQA-CP v2 implies that the pairwise iterative structure of MuRel is less prone to question-based overfitting than classical attention architectures.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T5.1.1.1.1.1" class="ltx_text">Model</span></th>
<th id="S4.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Bottom</th>
<th id="S4.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T5.1.1.1.3.1" class="ltx_text">Yes/No</span></th>
<th id="S4.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T5.1.1.1.4.1" class="ltx_text">Num.</span></th>
<th id="S4.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T5.1.1.1.5.1" class="ltx_text">Other</span></th>
<th id="S4.T5.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T5.1.1.1.6.1" class="ltx_text">All</span></th>
</tr>
<tr id="S4.T5.1.2.2" class="ltx_tr">
<th id="S4.T5.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">up</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.3.1" class="ltx_tr">
<td id="S4.T5.1.3.1.1" class="ltx_td ltx_align_center ltx_border_t">HAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>
</td>
<td id="S4.T5.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S4.T5.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">52.25</td>
<td id="S4.T5.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.1.3.1.4.1" class="ltx_text ltx_font_bold">13.79</span></td>
<td id="S4.T5.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">20.33</td>
<td id="S4.T5.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">28.65</td>
</tr>
<tr id="S4.T5.1.4.2" class="ltx_tr">
<td id="S4.T5.1.4.2.1" class="ltx_td ltx_align_center">GVQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</td>
<td id="S4.T5.1.4.2.2" class="ltx_td ltx_align_center">âœ—</td>
<td id="S4.T5.1.4.2.3" class="ltx_td ltx_align_center"><span id="S4.T5.1.4.2.3.1" class="ltx_text ltx_font_bold">57.99</span></td>
<td id="S4.T5.1.4.2.4" class="ltx_td ltx_align_center">13.68</td>
<td id="S4.T5.1.4.2.5" class="ltx_td ltx_align_center">22.14</td>
<td id="S4.T5.1.4.2.6" class="ltx_td ltx_align_center">31.30</td>
</tr>
<tr id="S4.T5.1.5.3" class="ltx_tr">
<td id="S4.T5.1.5.3.1" class="ltx_td ltx_align_center">Attention</td>
<td id="S4.T5.1.5.3.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T5.1.5.3.3" class="ltx_td ltx_align_center">41.56</td>
<td id="S4.T5.1.5.3.4" class="ltx_td ltx_align_center">12.19</td>
<td id="S4.T5.1.5.3.5" class="ltx_td ltx_align_center">43.29</td>
<td id="S4.T5.1.5.3.6" class="ltx_td ltx_align_center">38.04</td>
</tr>
<tr id="S4.T5.1.6.4" class="ltx_tr">
<td id="S4.T5.1.6.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">MuRel</td>
<td id="S4.T5.1.6.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">âœ“</td>
<td id="S4.T5.1.6.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">42.85</td>
<td id="S4.T5.1.6.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">13.17</td>
<td id="S4.T5.1.6.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.1.6.4.5.1" class="ltx_text ltx_font_bold">45.04</span></td>
<td id="S4.T5.1.6.4.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.1.6.4.6.1" class="ltx_text ltx_font_bold">39.54</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="S4.T5.3.1" class="ltx_text ltx_font_bold">State-of-the-art comparison on the VQA-CP v2 dataset.</span> The Attention model was trained by us using the Bottom-up features.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Qualitative results</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In FigureÂ <a href="#S4.F5" title="Figure 5 â€£ TDIUC â€£ 4.3 State of the art comparison â€£ 4 Experiments â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we illustrate the behaviour of a MuRel network with three shared cells.
Iterations through the MuRel cell tend to gradually discard regions, keeping only the most relevant ones.
As explained in SectionÂ <a href="#S3.SS2" title="3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, the regions that are most involved in the pairwise modeling process are shown in green and red.
Both region contributions and pairwise links match human intuition. In the first row, the most relevant relations according to our model are between the playerâ€™s hand, containing the WII controller, and the screen, which explains the prediction <span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_italic">bowling</span>. In the third row, the model answers <span id="S4.SS4.p1.1.2" class="ltx_text ltx_font_italic">kite</span> using the relation between the manâ€™s hand and the kite he is holding. Finally, in the last row, our model is able to address a third question on the same image than in Figure <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S3.F3" title="Figure 3 â€£ 3.2 MuRel network â€£ 3 MuRel approach â€£ MUREL: Multimodal Relational Reasoning for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Here, the relation between the head of the woman and her hat is used to provide the right answer. As VQA models are often subject to linguistic bias <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, this type of visualization shows that the MuRel network actually relies on the visual information to answer questions.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we introduced MuRel, a multimodal relational network for Visual Question Answering task. Our system is based on rich representations of visual image regions that are progressively merged with the question representation. We also included region relations with pairwise combinations in our fusion, and the whole system can be leveraged to define visualization schemes helping to interpret the decision process of MuRel.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We validated our approach on three challenging datasets: VQA 2.0, VQA-CP v2 and TDIUC.
We exhibited various ablation studies, clearly demonstrating the gain of our vectorial representation to model the attention, the use of pairwise combination, and the multi-step iterations in the whole process. Our final MuRel network is very competitive and outperforms state-of-the-art results on two of the most widely used datasets.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A.Â Agrawal, D.Â Batra, D.Â Parikh, and A.Â Kembhavi.

</span>
<span class="ltx_bibblock">Donâ€™t just assume; look and answer: Overcoming priors for visual
question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span>, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A.Â Agrawal, D.Â Batra, D.Â Parikh, and A.Â Kembhavi.

</span>
<span class="ltx_bibblock">Donâ€™t just assume; look and answer: Overcoming priors for visual
question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 4971â€“4980, 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
P.Â Anderson, X.Â He, C.Â Buehler, D.Â Teney, M.Â Johnson, S.Â Gould, and L.Â Zhang.

</span>
<span class="ltx_bibblock">Bottom-up and top-down attention for image captioning and visual
question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, June 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S.Â Antol, A.Â Agrawal, J.Â Lu, M.Â Mitchell, D.Â Batra, C.Â L. Zitnick, and
D.Â Parikh.

</span>
<span class="ltx_bibblock">VQA: Visual Question Answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">International Conference on Computer Vision (ICCV)</span>, 2015.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
D.Â Bahdanau, K.Â Cho, and Y.Â Bengio.

</span>
<span class="ltx_bibblock">Neural machine translation by jointly learning to align and
translate.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">ICLR 2015</span>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y.Â Bai, J.Â Fu, T.Â Zhao, and T.Â Mei.

</span>
<span class="ltx_bibblock">Deep attention neural tensor network for visual question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">The European Conference on Computer Vision (ECCV)</span>, September
2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
P.Â W. BattagliaÂ et al.

</span>
<span class="ltx_bibblock">Relational inductive biases, deep learning, and graph networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1806.01261, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H.Â Ben-Younes, R.Â CadÃ¨ne, N.Â Thome, and M.Â Cord.

</span>
<span class="ltx_bibblock">Mutan: Multimodal tucker fusion for visual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">ICCV</span>, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
X.Â Chen, L.-J. Li, L.Â Fei-Fei, and A.Â Gupta.

</span>
<span class="ltx_bibblock">Iterative visual reasoning beyond convolutions.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Z.Â Chen, Z.Â Yanpeng, H.Â Shuaiyi, T.Â Kewei, and M.Â Yi.

</span>
<span class="ltx_bibblock">Structured attentions for visual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Computer Vision (ICCV)</span>, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A.Â Fukui, D.Â H. Park, D.Â Yang, A.Â Rohrbach, T.Â Darrell, and M.Â Rohrbach.

</span>
<span class="ltx_bibblock">Multimodal compact bilinear pooling for visual question answering and
visual grounding.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">EMNLP</span>. The Association for Computational Linguistics, 2016.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y.Â Goyal, T.Â Khot, D.Â Summers-Stay, D.Â Batra, and D.Â Parikh.

</span>
<span class="ltx_bibblock">Making the V in VQA matter: Elevating the role of image
understanding in Visual Question Answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
K.Â He, X.Â Zhang, S.Â Ren, and J.Â Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, 2016.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
R.Â Hu, J.Â Andreas, M.Â Rohrbach, T.Â Darrell, and K.Â Saenko.

</span>
<span class="ltx_bibblock">Learning to reason: End-to-end module networks for visual question
answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision (ICCV)</span>, 2017.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
D.Â A. Hudson and C.Â D. Manning.

</span>
<span class="ltx_bibblock">Compositional attention networks for machine reasoning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J.Â Johnson, B.Â Hariharan, L.Â vanÂ der Maaten, L.Â Fei-Fei, C.Â L. Zitnick, and
R.Â Girshick.

</span>
<span class="ltx_bibblock">CLEVR: A diagnostic dataset for compositional language and
elementary visual reasoning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J.Â Johnson, B.Â Hariharan, L.Â vanÂ der Maaten, J.Â Hoffman, L.Â Fei-Fei, C.Â L.
Zitnick, and R.Â Girshick.

</span>
<span class="ltx_bibblock">Inferring and executing programs for visual reasoning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">ICCV</span>, 2017.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
K.Â Kafle and C.Â Kanan.

</span>
<span class="ltx_bibblock">An analysis of visual question answering algorithms.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">The IEEE International Conference on Computer Vision (ICCV)</span>,
Oct 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J.-H. Kim, J.Â Jun, and B.-T. Zhang.

</span>
<span class="ltx_bibblock">Bilinear Attention Networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1805.07932</span>, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J.-H. Kim, K.Â W. On, W.Â Lim, J.Â Kim, J.-W. Ha, and B.-T. Zhang.

</span>
<span class="ltx_bibblock">Hadamard Product for Low-rank Bilinear Pooling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">The 5th International Conference on Learning
Representations</span>, 2017.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
D.Â P. Kingma and J.Â Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2015.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
R.Â Kiros, Y.Â Zhu, R.Â Salakhutdinov, R.Â S. Zemel, A.Â Torralba, R.Â Urtasun, and
S.Â Fidler.

</span>
<span class="ltx_bibblock">Skip-thought vectors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Proceedings of the 28th International Conference on Neural
Information Processing Systems - Volume 2</span>, NIPSâ€™15, pages 3294â€“3302,
Cambridge, MA, USA, 2015. MIT Press.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
R.Â Krishna, Y.Â Zhu, O.Â Groth, J.Â Johnson, K.Â Hata, J.Â Kravitz, S.Â Chen,
Y.Â Kalantidis, L.-J. Li, D.Â A. Shamma, etÂ al.

</span>
<span class="ltx_bibblock">Visual genome: Connecting language and vision using crowdsourced
dense image annotations.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">International Journal of Computer Vision</span>, 123(1):32â€“73, 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A.Â Krizhevsky, I.Â Sutskever, and G.Â E. Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock">In F.Â Pereira, C.Â J.Â C. Burges, L.Â Bottou, and K.Â Q. Weinberger,
editors, <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems 25</span>, pages
1097â€“1105. Curran Associates, Inc., 2012.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
D.Â Lopez-Paz, R.Â Nishihara, S.Â Chintala, B.Â SchÃ¶lkopf, and L.Â Bottou.

</span>
<span class="ltx_bibblock">Discovering causal signals in images.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, Piscataway, NJ, USA, July 2017. IEEE.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
C.Â Lu, R.Â Krishna, M.Â Bernstein, and L.Â Fei-Fei.

</span>
<span class="ltx_bibblock">Visual relationship detection with language priors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, 2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
M.Â Malinowski, C.Â Doersch, A.Â Santoro, and P.Â Battaglia.

</span>
<span class="ltx_bibblock">Learning visual question answering by bootstrapping hard attention.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">The European Conference on Computer Vision (ECCV)</span>, September
2018.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
M.Â Malinowski and M.Â Fritz.

</span>
<span class="ltx_bibblock">A multi-world approach to question answering about real-world scenes
based on uncertain input.

</span>
<span class="ltx_bibblock">In Z.Â Ghahramani, M.Â Welling, C.Â Cortes, N.Â Lawrence, and
K.Â Weinberger, editors, <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing
Systems 27</span>, pages 1682â€“1690. Curran Associates, Inc., 2014.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
D.Â Mascharka, P.Â Tran, R.Â Soklaski, and A.Â Majumdar.

</span>
<span class="ltx_bibblock">Transparency by design: Closing the gap between performance and
interpretability in visual reasoning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, June 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
H.Â Noh and B.Â Han.

</span>
<span class="ltx_bibblock">Training recurrent answering units with joint loss minimization for
vqa.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1606.03647</span>, 2016.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
W.Â Norcliffe-Brown, E.Â Vafeias, and S.Â Parisot.

</span>
<span class="ltx_bibblock">Learning conditioned graph structures for interpretable visual
question answering.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
E.Â Perez, F.Â Strub, H.Â deÂ Vries, V.Â Dumoulin, and A.Â C. Courville.

</span>
<span class="ltx_bibblock">Film: Visual reasoning with a general conditioning layer.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">AAAI</span>, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
A.Â Santoro, F.Â Hill, D.Â G.Â T. Barrett, A.Â S. Morcos, and T.Â P. Lillicrap.

</span>
<span class="ltx_bibblock">Measuring abstract reasoning in neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">ICML</span>, volumeÂ 80 of <span id="bib.bib33.2.2" class="ltx_text ltx_font_italic">JMLR Workshop and Conference
Proceedings</span>, pages 4477â€“4486. JMLR.org, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A.Â Santoro, D.Â Raposo, D.Â G.Â T. Barrett, M.Â Malinowski, R.Â Pascanu,
P.Â Battaglia, and T.Â Lillicrap.

</span>
<span class="ltx_bibblock">A simple neural network module for relational reasoning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems 30: Annual
Conference on Neural Information Processing Systems 2017, 4-9 December 2017,
Long Beach, CA, USA</span>, pages 4974â€“4983, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Y.Â Shi, T.Â Furlanello, S.Â Zha, and A.Â Anandkumar.

</span>
<span class="ltx_bibblock">Question type guided attention in visual question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">The European Conference on Computer Vision (ECCV)</span>, September
2018.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
K.Â Xu, J.Â L. Ba, R.Â Kiros, K.Â Cho, A.Â Courville, R.Â Salakhutdinov, R.Â S. Zemel,
and Y.Â Bengio.

</span>
<span class="ltx_bibblock">Show, attend and tell: Neural image caption generation with visual
attention.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Proceedings of the 32Nd International Conference on
International Conference on Machine Learning - Volume 37</span>, ICMLâ€™15, pages
2048â€“2057. JMLR.org, 2015.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Z.Â Yang, X.Â He, J.Â Gao, L.Â Deng, and A.Â J. Smola.

</span>
<span class="ltx_bibblock">Stacked attention networks for image question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, 2016.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Z.Â Yu, J.Â Yu, J.Â Fan, and D.Â Tao.

</span>
<span class="ltx_bibblock">Multi-modal factorized bilinear pooling with co-attention learning
for visual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Computer Vision (ICCV)</span>, pages
1839â€“1848, 2017.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Z.Â Yu, J.Â Yu, C.Â Xiang, J.Â Fan, and D.Â Tao.

</span>
<span class="ltx_bibblock">Beyond bilinear: Generalized multi-modal factorized high-order
pooling for visual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>,
2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Yu Jiang*, Vivek Natarajan*, Xinlei Chen*, M.Â Rohrbach, D.Â Batra, and
D.Â Parikh.

</span>
<span class="ltx_bibblock">Pythia v0.1: the winning entry to the vqa challenge 2018.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1807.09956</span>, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Y.Â Zhang, J.Â Hare, and A.Â PrÃ¼gel-Bennett.

</span>
<span class="ltx_bibblock">Learning to count objects in natural images for visual question
answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2018.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1902.09486" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1902.09487" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1902.09487">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1902.09487" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1902.09488" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 13:58:40 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
