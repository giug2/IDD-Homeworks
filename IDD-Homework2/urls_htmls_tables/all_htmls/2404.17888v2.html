<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.17888] A Hybrid Approach for Document Layout Analysis in Document images</title><meta property="og:description" content="Document layout analysis involves understanding the arrangement of elements within a document. This paper navigates the complexities of understanding various elements within document images, such as text, images, tableâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Hybrid Approach for Document Layout Analysis in Document images">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Hybrid Approach for Document Layout Analysis in Document images">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.17888">

<!--Generated on Sun May  5 14:38:54 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content=" Detection Transformer Document Layout Analysis Graphical object detection">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Department of Computer Science, Technical University of Kaiserslautern, Germany </span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Mindgarage, Technical University of Kaiserslautern, Germany </span></span></span><span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>German Research Institute for Artificial Intelligence (DFKI), 67663 Kaiserslautern, Germany
<br class="ltx_break"><span id="id3.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">email: </span>{tahira.shehzadi@dfki.de}</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">A Hybrid Approach for Document Layout Analysis in Document images</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tahira Shehzadi* 
</span><span class="ltx_author_notes">112233
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-7052-979X" title="ORCID identifier" class="ltx_ref">0000-0002-7052-979X</a></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Didier Stricker
</span><span class="ltx_author_notes">112233</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Muhammad Zeshan Afzal
</span><span class="ltx_author_notes">112233
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-0536-6867" title="ORCID identifier" class="ltx_ref">0000-0002-0536-6867</a></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Document layout analysis involves understanding the arrangement of elements within a document. This paper navigates the complexities of understanding various elements within document images, such as text, images, tables, and headings. The approach employs an advanced Transformer-based object detection network as an innovative graphical page object detector for identifying tables, figures, and displayed elements. We introduce a query encoding mechanism to provide high-quality object queries for contrastive learning, enhancing efficiency in the decoder phase. We also present a hybrid matching scheme that integrates the decoderâ€™s original one-to-one matching strategy with the one-to-many matching strategy during the training phase. This approach aims to improve the modelâ€™s accuracy and versatility in detecting various graphical elements on a page. Our experiments on PubLayNet, DocLayNet, and PubTables benchmarks show that our approach outperforms current state-of-the-art methods. It achieves an average precision of <span id="id1.id1.1" class="ltx_text ltx_font_bold">97.3%</span> on PubLayNet, <span id="id1.id1.2" class="ltx_text ltx_font_bold">81.6%</span> on DocLayNet, and <span id="id1.id1.3" class="ltx_text ltx_font_bold">98.6%</span> on PubTables, demonstrating its superior performance in layout analysis. These advancements not only enhance the conversion of document images into editable and accessible formats but also streamline information retrieval and data extraction processes.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6> Detection Transformer Document Layout Analysis Graphical object detection
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2404.17888/assets/images/dino_gt.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="299" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Diverse layouts and element types in the DocLayNet Dataset, including elements such as captions, footnotes, formulas, and more. It underscores the challenges in document layout analysis, like interpreting dense text and categorizing diverse elements.</span></figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Systems for Document Intelligence (DI) is essential in enhancing the efficiency of automating large-scale document processing tasks, primarily focusing on extracting and understanding content within these documents. These systems are pivotal in key business intelligence operations such as document retrieval, text recognition, and content categorization, which rely heavily on extracting information and transforming documents into a structured, machine-readable format. This process seamlessly integrates the information extracted into further document processing workflows. As a result, significant improvements have been achieved across various industries, including banking, finance, and healthcareÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Document Layout Analysis (DLA) has become a key component in Document Intelligence due to its deriving structured formats from unstructured documents. This structuring is vital for accurately identifying and extracting essential document data. DLA encompasses two primary aspects: physical layout analysis, which identifies and spatially categorizes physical page elements like text, images, and tables, and logical layout analysis, which assigns semantic roles to these elements, such as titles, paragraphs, and headers, while understanding their hierarchical and reading order relationships. This analysis is essential for converting scanned documents into editable and searchable formats. However, it faces challenges due to the diversity of document layouts, the varying sizes and shapes of elements, and the complexity of accurately interpreting these elements across different documents.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Previously, remarkable progress has been made in document layout analysis through deep learning techniques, including advanced technologies like Faster RCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and Mask RCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, as well as other specialized frameworksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. These methods, effective in specific scenarios such as table detection and the layout analysis of academic papersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, sometimes face limitations in wider applications across various tasksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. The advancement of Transformer-based networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> marks a significant advancement over traditional convolutional neural networks (CNNs), primarily due to their global attention mechanisms and Non-Maximum Suppression (NMS) free design. However, these models still show constraints in precisely detecting textual regions, especially in identifying small-scale text areas such as headers, footers, and section titles. For example, DINOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, a leading Transformer-based detection modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, experiences a notable drop in detection accuracy for these small text regions on the DocLayNet datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows complex layouts from DocLayNet, with details like captions and footnotes. To improve DLA, we need better algorithms for handling different documents, from academic papers to magazines.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we propose an approach to address the challenges of document layout analysis, focusing on accurately identifying graphical elements within pages, such as tables, figures, and formulas. We employ an advanced Transformer-based object detection networkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, for its exceptional capability in detecting various graphical page objects. Enhancing this capability, we introduce a Query Encoding Strategy to provide high-quality object queries by taking high-level query features from the backbone. These query features provide better predictions for small graphical objects like page headers, footers, and titles, combined with the decoderâ€™s original queries to improve overall performance. This mechanism is pivotal for contrastive learning, significantly improving the efficiency of the modelâ€™s decoder phase and enabling more effective processing of complex document layouts. Furthermore, our approach introduces a novel hybrid matching scheme that merges the decoderâ€™s original one-to-one matching strategy with an auxiliary one-to-many matching strategy. This integration, implemented during the training phase, is key to boosting the modelâ€™s accuracy and adaptability in recognizing diverse classes of graphical elements. By combining the transformerâ€™s object detection capabilities with our unique encoding query and selection strategies, our method sets a new benchmark in document layout analysis, significantly advancing the fieldâ€™s ability to accurately detect and interpret graphical elements within various documents.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">We summarize the main contributions of this paper as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix1.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix1.1.1.m1.1b"><mo id="S1.I1.ix1.1.1.m1.1.1" xref="S1.I1.ix1.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix1.1.1.m1.1c"><ci id="S1.I1.ix1.1.1.m1.1.1.cmml" xref="S1.I1.ix1.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix1.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix1.p1" class="ltx_para">
<p id="S1.I1.ix1.p1.1" class="ltx_p">We introduce a Transformer-based framework for document layout analysis, incorporating a ResNet-50 backbone. This framework is augmented with an enhanced query encoding mechanism and innovative query-selection strategies. By integrating these strategies, our approach sets a new standard in document layout analysis. This significant advancement contributes to accurately detecting graphical elements in various document types.</p>
</div>
</li>
<li id="S1.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix2.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix2.1.1.m1.1b"><mo id="S1.I1.ix2.1.1.m1.1.1" xref="S1.I1.ix2.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix2.1.1.m1.1c"><ci id="S1.I1.ix2.1.1.m1.1.1.cmml" xref="S1.I1.ix2.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix2.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix2.p1" class="ltx_para">
<p id="S1.I1.ix2.p1.1" class="ltx_p">We present a unique query selection scheme that blends the decoderâ€™s original one-to-one matching strategy with a one-to-many matching strategy. This integration, crucial during the training phase, significantly enhances the modelâ€™s accuracy and adaptability in detecting and categorizing various graphical elements across different documents.</p>
</div>
</li>
<li id="S1.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix3.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix3.1.1.m1.1b"><mo id="S1.I1.ix3.1.1.m1.1.1" xref="S1.I1.ix3.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix3.1.1.m1.1c"><ci id="S1.I1.ix3.1.1.m1.1.1.cmml" xref="S1.I1.ix3.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix3.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix3.p1" class="ltx_para">
<p id="S1.I1.ix3.p1.1" class="ltx_p">We introduce an enhanced query encoding mechanism to improve the efficiency of the modelâ€™s decoder phase and enable more effective processing of complex document layouts.</p>
</div>
</li>
<li id="S1.I1.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix4.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix4.1.1.m1.1b"><mo id="S1.I1.ix4.1.1.m1.1.1" xref="S1.I1.ix4.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix4.1.1.m1.1c"><ci id="S1.I1.ix4.1.1.m1.1.1.cmml" xref="S1.I1.ix4.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix4.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix4.p1" class="ltx_para">
<p id="S1.I1.ix4.p1.1" class="ltx_p">To validate the effectiveness of our approach, we conduct comprehensive evaluations on three distinct datasets: PubLayNet, DocLayNet, and Pubtables. These evaluations demonstrate the robustness and applicability of our proposed method across various documents and layout challenges.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Layout analysis is crucial to extract data from digital documents effectively. It involves understanding the spatial arrangement and relationships between various elements like tables, text, figures, and titles. Before deep learning approachesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, heuristic rule-based algorithmsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> were emplyed in layout analysis. However, with technological advancements, convolutional neural networks (CNNs) became the primary method, providing significant improvements. More recently, transformer-based architecturesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> have emerged as the leading approach, show remarkable effectiveness in this domain. This section aims to offer an in-depth review of these cutting-edge techniques, exploring a variety of approaches in Document Layout Analysis (DLA).
<br class="ltx_break"></p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Heuristic Rule-Based DLA.</span> The document layout analysis using heuristic techniques is generally categorized into top-down, bottom-up, and hybrid approaches. Bottom-up methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> involve elementary processes such as clustering and combining pixels to form uniform regions for akin objects while segregating dissimilar ones. Conversely, top-down approachesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> iteratively divide the document image into various regions until distinct areas encompassing similar objects are formed. While bottom-up strategies are capable of handling intricate layouts, they require significant computational resources. On the other hand, top-down methods are more efficient in terms of implementation speed but lack versatility, showing optimal performance only with certain document types. Hybrid methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> combine the strengths of both bottom-up and top-down techniques, achieving both rapid and effective outcomes. Before the advent of deep learning, these heuristic strategies were the leading methods for detecting tables in documents.
<br class="ltx_break"></p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Deep Learning-based DLA.</span> With the rise of deep learning approachesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, Convolutional Neural Networks (CNNs) have performed better than traditional rule-based algorithms in document analysisÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. This development represents a significant improvement in the precision and efficiency of processing and understanding complex document layouts. Introducing Faster-RCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> marks a significant advancement in document object detection, facilitating effective page segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Subsequently, Mask-RCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> set a new benchmark in layout segmentation, particularly for newspapers. RetinaNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> further contributes to this evolution by focusing on keyword detection in document images, although its complexity limits its application to text region detection. For table detection and structural recognition, DeepDeSRTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> introduces an innovative image transformation approach that discerns table features for input into a fully convolutional network employing skip pooling. The ICDAR2017 POD (Page Object Detection) benchmark, introduced by Saha et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, utilizes a transfer learning-based Faster-RCNN architecture to detect elements like mathematical equations, tables, and figures. To address cross-domain challenges in Document Object Detection, a new benchmarkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> is established, focusing on domain adaptation strategies. More recently, a vision-based layout detection benchmarkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> employs a recurrent convolutional neural network with a VoVNet-v2 backbone, generating synthetic PDF documents from the ICDAR-2013 and GROTOAP datasets to set new standards in scientific document analysis.
<br class="ltx_break"></p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Transformer-Based DLA</span>.
Document layout analysis is rapidly advancing with Transformer architectures, known for their positional embedding and attention mechanisms. These methods are known for their unique features like positional embedding and attention mechanismÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. DiTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> has set a new standard in classifying document images, layout analysis, and table detection, employing self-supervised training on extensive collections of unlabeled document images. However, its application is limited to smaller datasets like PRIMA. Li et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> develop a method that combines different types of data to understand structured text in documents. However, this method struggles with text that has similar meanings.
Furthermore, the TILTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> model simultaneously processes textual, visual, and layout data through an encoder-decoder Transformer setup. Another implementation of a transformer encoder-decoder inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> establishes a benchmark for the PubLayNet datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, integrating text data extracted via OCR. The LayoutLMv3Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> model improves visual document understanding by jointly learning from text, layout, and visual elements. It performs better with large datasets but has limitations with smaller ones. Other recent modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> also adopt joint pre-training strategies for various tasks, including document visual question answering. The transformer-based architectures have emerged as the leading approaches, show remarkable effectiveness in object detection domainÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. However, when employing DINOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> or other Transformer-based networks in document layout analysis, thereâ€™s a noted limitation in their performance with small graphical objects like page titles, headers, and footers. To improve this, We enhance the hybrid query mechanism and matching scheme. This strategy elevates our document layout analysis, allowing for more precise and flexible detection and interpretation of various document graphical elements.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our approach consists of four integral parts: First, a CNN-based backbone network for extracting multi-scale features from document images. Second, a transformer-based model is employed to detect graphical elements like titles, figures, tables, and text on the pages. Third, we introduce an improved query encoding mechanism, optimizing the modelâ€™s decoder phase to process complex document layouts more effectively. Fourthly, we implement a unique query selection scheme, blending the decoderâ€™s one-to-one matching with a new one-to-many strategy, enhancing accuracy in identifying various graphical elements during training. These modules are collectively trained in an end-to-end manner.
The complete overview of our approach is shown in Fig.Â <a href="#S3.F2" title="Figure 2 â€£ 3.1 Backbone Multi-scale Features Network â€£ 3 Methodology â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and explained in detail in the subsequent subsections.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Backbone Multi-scale Features Network</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">For processing an input image I of size HÃ—WÃ—3, we use a ResNet-50 backbone network to generate a series of feature maps at reduced resolutions: 1/4, 1/8, 1/16, 1/32, and 1/64 of the original size. Each map is refined using a 1Ã—1 convolution layer, which is crucial for reducing the channel count. This step is essential to control the number of trainable parameters, making the process manageable, especially with limited computational resources. After this reduction, each feature map has 256 channels, which are then input into the transformer network to detect graphical objects on the page.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2404.17888/assets/images/dino.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="303" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Overview of our approach for Document Layout Analysis. The input image is processed through a CNN backbone to extract features, which are then passed to a Transformer encoder-decoder network. The encoder processes the features globally, while the decoder uses object queries to interact with the encoded features and predict bounding boxes and classes for each object in the image. Our approach incorporates an enhanced query encoding mechanism to improve decoder efficiency and a query selection scheme that combines one-to-one and one-to-many matching strategies, improving accuracy and adaptability in identifying various graphical elements across documents.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Document Layout Analysis with the transformer Framework</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Recent progress in Transformer-based object detectionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> has revolutionized document analysis. These advanced methods outperform previous models like Faster-RCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and Mask-RCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, mainly because they donâ€™t require manual techniques such as anchor generation process and NMS. Our approach employs the DINOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> model, a state-of-the-art network, to detect graphical elements in document images. Our approach includes a transformer network with a unique structure. It has an encoder that processes variously scaled feature maps from a CNN backbone and a decoder that generates the final results. The encoderâ€™s task is to generate detailed proposals for graphical elements in the pages, guiding the decoderâ€™s positional embeddings for the queries. This decoder uses a deformable attention mechanism for better efficiency in self and cross-attention processes. It also applies contrastive denoising for the object queries, helping the model learn faster. It is highly adaptable, especially during shifts in document types, and it focuses on lower-dimension image features, which often need more data to be included in traditional transformer training. The effectiveness of our transformer-based approach is validated through its impressive performance in detecting graphical page objects on well-known benchmarks like PubLayNet, DocLayNet, and PubTables.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Query Encoding Strategy</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In the query encoding strategy, we enhance the query mechanism to improve the detection of small graphical objects in document images by combining backbone query features with decoder original queries. This approach creates high-quality object queries, increasing accuracy in identifying the small elements within an image. Hereâ€™s a detailed explanation:
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.8" class="ltx_p"><span id="S3.SS3.p2.8.1" class="ltx_text ltx_font_bold">High-level Query Features from Backbone:</span>Â 
In our approach, we initially extract high-level features from the early layers of a CNN backbone, such as the ResNet-50. These initial layers are adept at capturing intricate details and textures, including edges, corners, and specific patterns. This level of granularity is crucial for identifying smaller objects within an image. For each processed image, we adjust the dimensions of feature maps <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="C4" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mrow id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml">â€‹</mo><mn id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><times id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"></times><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">ğ¶</ci><cn type="integer" id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">C4</annotation></semantics></math> and <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="C5" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mrow id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">â€‹</mo><mn id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><times id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1"></times><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ğ¶</ci><cn type="integer" id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">C5</annotation></semantics></math> to align with <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="C3" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mrow id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.cmml">â€‹</mo><mn id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><times id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1"></times><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">ğ¶</ci><cn type="integer" id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">C3</annotation></semantics></math> and then concatenate them. The combined feature map undergoes processing through two <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mrow id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mn id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.4.m4.1.1.1" xref="S3.SS3.p2.4.m4.1.1.1.cmml">Ã—</mo><mn id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><times id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1.1"></times><cn type="integer" id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">3</cn><cn type="integer" id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">3\times 3</annotation></semantics></math> convolutional layers, resulting in a feature map <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="C_{\text{h}}" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><msub id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">C</mi><mtext id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3a.cmml">h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">ğ¶</ci><ci id="S3.SS3.p2.5.m5.1.1.3a.cmml" xref="S3.SS3.p2.5.m5.1.1.3"><mtext mathsize="70%" id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">C_{\text{h}}</annotation></semantics></math> comprising 64 channels. Then, we employ the RoIAlign algorithmÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> to extract features based on its bounding box <math id="S3.SS3.p2.6.m6.4" class="ltx_Math" alttext="b_{j}=(x_{j1},y_{j1},x_{j2},y_{j2})" display="inline"><semantics id="S3.SS3.p2.6.m6.4a"><mrow id="S3.SS3.p2.6.m6.4.4" xref="S3.SS3.p2.6.m6.4.4.cmml"><msub id="S3.SS3.p2.6.m6.4.4.6" xref="S3.SS3.p2.6.m6.4.4.6.cmml"><mi id="S3.SS3.p2.6.m6.4.4.6.2" xref="S3.SS3.p2.6.m6.4.4.6.2.cmml">b</mi><mi id="S3.SS3.p2.6.m6.4.4.6.3" xref="S3.SS3.p2.6.m6.4.4.6.3.cmml">j</mi></msub><mo id="S3.SS3.p2.6.m6.4.4.5" xref="S3.SS3.p2.6.m6.4.4.5.cmml">=</mo><mrow id="S3.SS3.p2.6.m6.4.4.4.4" xref="S3.SS3.p2.6.m6.4.4.4.5.cmml"><mo stretchy="false" id="S3.SS3.p2.6.m6.4.4.4.4.5" xref="S3.SS3.p2.6.m6.4.4.4.5.cmml">(</mo><msub id="S3.SS3.p2.6.m6.1.1.1.1.1" xref="S3.SS3.p2.6.m6.1.1.1.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.1.1.1.2" xref="S3.SS3.p2.6.m6.1.1.1.1.1.2.cmml">x</mi><mrow id="S3.SS3.p2.6.m6.1.1.1.1.1.3" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p2.6.m6.1.1.1.1.1.3.2" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m6.1.1.1.1.1.3.1" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.6.m6.1.1.1.1.1.3.3" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS3.p2.6.m6.4.4.4.4.6" xref="S3.SS3.p2.6.m6.4.4.4.5.cmml">,</mo><msub id="S3.SS3.p2.6.m6.2.2.2.2.2" xref="S3.SS3.p2.6.m6.2.2.2.2.2.cmml"><mi id="S3.SS3.p2.6.m6.2.2.2.2.2.2" xref="S3.SS3.p2.6.m6.2.2.2.2.2.2.cmml">y</mi><mrow id="S3.SS3.p2.6.m6.2.2.2.2.2.3" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3.cmml"><mi id="S3.SS3.p2.6.m6.2.2.2.2.2.3.2" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m6.2.2.2.2.2.3.1" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.6.m6.2.2.2.2.2.3.3" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS3.p2.6.m6.4.4.4.4.7" xref="S3.SS3.p2.6.m6.4.4.4.5.cmml">,</mo><msub id="S3.SS3.p2.6.m6.3.3.3.3.3" xref="S3.SS3.p2.6.m6.3.3.3.3.3.cmml"><mi id="S3.SS3.p2.6.m6.3.3.3.3.3.2" xref="S3.SS3.p2.6.m6.3.3.3.3.3.2.cmml">x</mi><mrow id="S3.SS3.p2.6.m6.3.3.3.3.3.3" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3.cmml"><mi id="S3.SS3.p2.6.m6.3.3.3.3.3.3.2" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m6.3.3.3.3.3.3.1" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.6.m6.3.3.3.3.3.3.3" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3.3.cmml">2</mn></mrow></msub><mo id="S3.SS3.p2.6.m6.4.4.4.4.8" xref="S3.SS3.p2.6.m6.4.4.4.5.cmml">,</mo><msub id="S3.SS3.p2.6.m6.4.4.4.4.4" xref="S3.SS3.p2.6.m6.4.4.4.4.4.cmml"><mi id="S3.SS3.p2.6.m6.4.4.4.4.4.2" xref="S3.SS3.p2.6.m6.4.4.4.4.4.2.cmml">y</mi><mrow id="S3.SS3.p2.6.m6.4.4.4.4.4.3" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3.cmml"><mi id="S3.SS3.p2.6.m6.4.4.4.4.4.3.2" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m6.4.4.4.4.4.3.1" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.6.m6.4.4.4.4.4.3.3" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3.3.cmml">2</mn></mrow></msub><mo stretchy="false" id="S3.SS3.p2.6.m6.4.4.4.4.9" xref="S3.SS3.p2.6.m6.4.4.4.5.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.4b"><apply id="S3.SS3.p2.6.m6.4.4.cmml" xref="S3.SS3.p2.6.m6.4.4"><eq id="S3.SS3.p2.6.m6.4.4.5.cmml" xref="S3.SS3.p2.6.m6.4.4.5"></eq><apply id="S3.SS3.p2.6.m6.4.4.6.cmml" xref="S3.SS3.p2.6.m6.4.4.6"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.4.4.6.1.cmml" xref="S3.SS3.p2.6.m6.4.4.6">subscript</csymbol><ci id="S3.SS3.p2.6.m6.4.4.6.2.cmml" xref="S3.SS3.p2.6.m6.4.4.6.2">ğ‘</ci><ci id="S3.SS3.p2.6.m6.4.4.6.3.cmml" xref="S3.SS3.p2.6.m6.4.4.6.3">ğ‘—</ci></apply><vector id="S3.SS3.p2.6.m6.4.4.4.5.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4"><apply id="S3.SS3.p2.6.m6.1.1.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.1.2">ğ‘¥</ci><apply id="S3.SS3.p2.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3"><times id="S3.SS3.p2.6.m6.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3.1"></times><ci id="S3.SS3.p2.6.m6.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.6.m6.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.SS3.p2.6.m6.2.2.2.2.2.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2.2">ğ‘¦</ci><apply id="S3.SS3.p2.6.m6.2.2.2.2.2.3.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3"><times id="S3.SS3.p2.6.m6.2.2.2.2.2.3.1.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3.1"></times><ci id="S3.SS3.p2.6.m6.2.2.2.2.2.3.2.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.6.m6.2.2.2.2.2.3.3.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2.3.3">1</cn></apply></apply><apply id="S3.SS3.p2.6.m6.3.3.3.3.3.cmml" xref="S3.SS3.p2.6.m6.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.3.3.3.3.3.1.cmml" xref="S3.SS3.p2.6.m6.3.3.3.3.3">subscript</csymbol><ci id="S3.SS3.p2.6.m6.3.3.3.3.3.2.cmml" xref="S3.SS3.p2.6.m6.3.3.3.3.3.2">ğ‘¥</ci><apply id="S3.SS3.p2.6.m6.3.3.3.3.3.3.cmml" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3"><times id="S3.SS3.p2.6.m6.3.3.3.3.3.3.1.cmml" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3.1"></times><ci id="S3.SS3.p2.6.m6.3.3.3.3.3.3.2.cmml" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.6.m6.3.3.3.3.3.3.3.cmml" xref="S3.SS3.p2.6.m6.3.3.3.3.3.3.3">2</cn></apply></apply><apply id="S3.SS3.p2.6.m6.4.4.4.4.4.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.4.4.4.4.4.1.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4.4">subscript</csymbol><ci id="S3.SS3.p2.6.m6.4.4.4.4.4.2.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4.4.2">ğ‘¦</ci><apply id="S3.SS3.p2.6.m6.4.4.4.4.4.3.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3"><times id="S3.SS3.p2.6.m6.4.4.4.4.4.3.1.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3.1"></times><ci id="S3.SS3.p2.6.m6.4.4.4.4.4.3.2.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.6.m6.4.4.4.4.4.3.3.cmml" xref="S3.SS3.p2.6.m6.4.4.4.4.4.3.3">2</cn></apply></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.4c">b_{j}=(x_{j1},y_{j1},x_{j2},y_{j2})</annotation></semantics></math> with many MLPs , where <math id="S3.SS3.p2.7.m7.2" class="ltx_Math" alttext="(x_{j1},y_{j1})" display="inline"><semantics id="S3.SS3.p2.7.m7.2a"><mrow id="S3.SS3.p2.7.m7.2.2.2" xref="S3.SS3.p2.7.m7.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p2.7.m7.2.2.2.3" xref="S3.SS3.p2.7.m7.2.2.3.cmml">(</mo><msub id="S3.SS3.p2.7.m7.1.1.1.1" xref="S3.SS3.p2.7.m7.1.1.1.1.cmml"><mi id="S3.SS3.p2.7.m7.1.1.1.1.2" xref="S3.SS3.p2.7.m7.1.1.1.1.2.cmml">x</mi><mrow id="S3.SS3.p2.7.m7.1.1.1.1.3" xref="S3.SS3.p2.7.m7.1.1.1.1.3.cmml"><mi id="S3.SS3.p2.7.m7.1.1.1.1.3.2" xref="S3.SS3.p2.7.m7.1.1.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.1.1.1.1.3.1" xref="S3.SS3.p2.7.m7.1.1.1.1.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.7.m7.1.1.1.1.3.3" xref="S3.SS3.p2.7.m7.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS3.p2.7.m7.2.2.2.4" xref="S3.SS3.p2.7.m7.2.2.3.cmml">,</mo><msub id="S3.SS3.p2.7.m7.2.2.2.2" xref="S3.SS3.p2.7.m7.2.2.2.2.cmml"><mi id="S3.SS3.p2.7.m7.2.2.2.2.2" xref="S3.SS3.p2.7.m7.2.2.2.2.2.cmml">y</mi><mrow id="S3.SS3.p2.7.m7.2.2.2.2.3" xref="S3.SS3.p2.7.m7.2.2.2.2.3.cmml"><mi id="S3.SS3.p2.7.m7.2.2.2.2.3.2" xref="S3.SS3.p2.7.m7.2.2.2.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.2.2.2.2.3.1" xref="S3.SS3.p2.7.m7.2.2.2.2.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.7.m7.2.2.2.2.3.3" xref="S3.SS3.p2.7.m7.2.2.2.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="S3.SS3.p2.7.m7.2.2.2.5" xref="S3.SS3.p2.7.m7.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.2b"><interval closure="open" id="S3.SS3.p2.7.m7.2.2.3.cmml" xref="S3.SS3.p2.7.m7.2.2.2"><apply id="S3.SS3.p2.7.m7.1.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m7.1.1.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.7.m7.1.1.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.1.1.2">ğ‘¥</ci><apply id="S3.SS3.p2.7.m7.1.1.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.1.1.3"><times id="S3.SS3.p2.7.m7.1.1.1.1.3.1.cmml" xref="S3.SS3.p2.7.m7.1.1.1.1.3.1"></times><ci id="S3.SS3.p2.7.m7.1.1.1.1.3.2.cmml" xref="S3.SS3.p2.7.m7.1.1.1.1.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.7.m7.1.1.1.1.3.3.cmml" xref="S3.SS3.p2.7.m7.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.SS3.p2.7.m7.2.2.2.2.cmml" xref="S3.SS3.p2.7.m7.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m7.2.2.2.2.1.cmml" xref="S3.SS3.p2.7.m7.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.7.m7.2.2.2.2.2.cmml" xref="S3.SS3.p2.7.m7.2.2.2.2.2">ğ‘¦</ci><apply id="S3.SS3.p2.7.m7.2.2.2.2.3.cmml" xref="S3.SS3.p2.7.m7.2.2.2.2.3"><times id="S3.SS3.p2.7.m7.2.2.2.2.3.1.cmml" xref="S3.SS3.p2.7.m7.2.2.2.2.3.1"></times><ci id="S3.SS3.p2.7.m7.2.2.2.2.3.2.cmml" xref="S3.SS3.p2.7.m7.2.2.2.2.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.7.m7.2.2.2.2.3.3.cmml" xref="S3.SS3.p2.7.m7.2.2.2.2.3.3">1</cn></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.2c">(x_{j1},y_{j1})</annotation></semantics></math> and <math id="S3.SS3.p2.8.m8.2" class="ltx_Math" alttext="(x_{j2},y_{j2})" display="inline"><semantics id="S3.SS3.p2.8.m8.2a"><mrow id="S3.SS3.p2.8.m8.2.2.2" xref="S3.SS3.p2.8.m8.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p2.8.m8.2.2.2.3" xref="S3.SS3.p2.8.m8.2.2.3.cmml">(</mo><msub id="S3.SS3.p2.8.m8.1.1.1.1" xref="S3.SS3.p2.8.m8.1.1.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.1.1.2" xref="S3.SS3.p2.8.m8.1.1.1.1.2.cmml">x</mi><mrow id="S3.SS3.p2.8.m8.1.1.1.1.3" xref="S3.SS3.p2.8.m8.1.1.1.1.3.cmml"><mi id="S3.SS3.p2.8.m8.1.1.1.1.3.2" xref="S3.SS3.p2.8.m8.1.1.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.1.1.1.1.3.1" xref="S3.SS3.p2.8.m8.1.1.1.1.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.8.m8.1.1.1.1.3.3" xref="S3.SS3.p2.8.m8.1.1.1.1.3.3.cmml">2</mn></mrow></msub><mo id="S3.SS3.p2.8.m8.2.2.2.4" xref="S3.SS3.p2.8.m8.2.2.3.cmml">,</mo><msub id="S3.SS3.p2.8.m8.2.2.2.2" xref="S3.SS3.p2.8.m8.2.2.2.2.cmml"><mi id="S3.SS3.p2.8.m8.2.2.2.2.2" xref="S3.SS3.p2.8.m8.2.2.2.2.2.cmml">y</mi><mrow id="S3.SS3.p2.8.m8.2.2.2.2.3" xref="S3.SS3.p2.8.m8.2.2.2.2.3.cmml"><mi id="S3.SS3.p2.8.m8.2.2.2.2.3.2" xref="S3.SS3.p2.8.m8.2.2.2.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.2.2.2.2.3.1" xref="S3.SS3.p2.8.m8.2.2.2.2.3.1.cmml">â€‹</mo><mn id="S3.SS3.p2.8.m8.2.2.2.2.3.3" xref="S3.SS3.p2.8.m8.2.2.2.2.3.3.cmml">2</mn></mrow></msub><mo stretchy="false" id="S3.SS3.p2.8.m8.2.2.2.5" xref="S3.SS3.p2.8.m8.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.2b"><interval closure="open" id="S3.SS3.p2.8.m8.2.2.3.cmml" xref="S3.SS3.p2.8.m8.2.2.2"><apply id="S3.SS3.p2.8.m8.1.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m8.1.1.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1.1.1.2">ğ‘¥</ci><apply id="S3.SS3.p2.8.m8.1.1.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.1.1.3"><times id="S3.SS3.p2.8.m8.1.1.1.1.3.1.cmml" xref="S3.SS3.p2.8.m8.1.1.1.1.3.1"></times><ci id="S3.SS3.p2.8.m8.1.1.1.1.3.2.cmml" xref="S3.SS3.p2.8.m8.1.1.1.1.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.8.m8.1.1.1.1.3.3.cmml" xref="S3.SS3.p2.8.m8.1.1.1.1.3.3">2</cn></apply></apply><apply id="S3.SS3.p2.8.m8.2.2.2.2.cmml" xref="S3.SS3.p2.8.m8.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.2.2.2.2.1.cmml" xref="S3.SS3.p2.8.m8.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.8.m8.2.2.2.2.2.cmml" xref="S3.SS3.p2.8.m8.2.2.2.2.2">ğ‘¦</ci><apply id="S3.SS3.p2.8.m8.2.2.2.2.3.cmml" xref="S3.SS3.p2.8.m8.2.2.2.2.3"><times id="S3.SS3.p2.8.m8.2.2.2.2.3.1.cmml" xref="S3.SS3.p2.8.m8.2.2.2.2.3.1"></times><ci id="S3.SS3.p2.8.m8.2.2.2.2.3.2.cmml" xref="S3.SS3.p2.8.m8.2.2.2.2.3.2">ğ‘—</ci><cn type="integer" id="S3.SS3.p2.8.m8.2.2.2.2.3.3.cmml" xref="S3.SS3.p2.8.m8.2.2.2.2.3.3">2</cn></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.2c">(x_{j2},y_{j2})</annotation></semantics></math> are the coordinates of the upper-left and lower-right corners, respectively. The high-level query features are then defined as:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="Q_{h}=MLP(\text{RoIAlign}(F_{\text{h}},b_{j}))" display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><msub id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml">Q</mi><mi id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml">h</mi></msub><mo id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.1.4" xref="S3.E1.m1.1.1.1.4.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.2a" xref="S3.E1.m1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.1.5" xref="S3.E1.m1.1.1.1.5.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.2b" xref="S3.E1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mtext id="S3.E1.m1.1.1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.1.1.4a.cmml">RoIAlign</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml">F</mi><mtext id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3a.cmml">h</mtext></msub><mo id="S3.E1.m1.1.1.1.1.1.1.2.2.4" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.2.cmml">b</mi><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.2.2.5" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"></eq><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2">ğ‘„</ci><ci id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3">â„</ci></apply><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">ğ‘€</ci><ci id="S3.E1.m1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.4">ğ¿</ci><ci id="S3.E1.m1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.5">ğ‘ƒ</ci><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"></times><ci id="S3.E1.m1.1.1.1.1.1.1.4a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4"><mtext id="S3.E1.m1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4">RoIAlign</mtext></ci><interval closure="open" id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2">ğ¹</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3">h</mtext></ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.2">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.3">ğ‘—</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">Q_{h}=MLP(\text{RoIAlign}(F_{\text{h}},b_{j}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.14" class="ltx_p">Here, <math id="S3.SS3.p2.9.m1.1" class="ltx_Math" alttext="Q_{h}" display="inline"><semantics id="S3.SS3.p2.9.m1.1a"><msub id="S3.SS3.p2.9.m1.1.1" xref="S3.SS3.p2.9.m1.1.1.cmml"><mi id="S3.SS3.p2.9.m1.1.1.2" xref="S3.SS3.p2.9.m1.1.1.2.cmml">Q</mi><mi id="S3.SS3.p2.9.m1.1.1.3" xref="S3.SS3.p2.9.m1.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m1.1b"><apply id="S3.SS3.p2.9.m1.1.1.cmml" xref="S3.SS3.p2.9.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m1.1.1.1.cmml" xref="S3.SS3.p2.9.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.9.m1.1.1.2.cmml" xref="S3.SS3.p2.9.m1.1.1.2">ğ‘„</ci><ci id="S3.SS3.p2.9.m1.1.1.3.cmml" xref="S3.SS3.p2.9.m1.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m1.1c">Q_{h}</annotation></semantics></math> refers to the query features and <math id="S3.SS3.p2.10.m2.1" class="ltx_Math" alttext="F_{h}" display="inline"><semantics id="S3.SS3.p2.10.m2.1a"><msub id="S3.SS3.p2.10.m2.1.1" xref="S3.SS3.p2.10.m2.1.1.cmml"><mi id="S3.SS3.p2.10.m2.1.1.2" xref="S3.SS3.p2.10.m2.1.1.2.cmml">F</mi><mi id="S3.SS3.p2.10.m2.1.1.3" xref="S3.SS3.p2.10.m2.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m2.1b"><apply id="S3.SS3.p2.10.m2.1.1.cmml" xref="S3.SS3.p2.10.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m2.1.1.1.cmml" xref="S3.SS3.p2.10.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.10.m2.1.1.2.cmml" xref="S3.SS3.p2.10.m2.1.1.2">ğ¹</ci><ci id="S3.SS3.p2.10.m2.1.1.3.cmml" xref="S3.SS3.p2.10.m2.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m2.1c">F_{h}</annotation></semantics></math> denotes features from backbone. Next, we apply a self-attention mechanism, as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, to the high-level query features <math id="S3.SS3.p2.11.m3.1" class="ltx_Math" alttext="Q_{h}" display="inline"><semantics id="S3.SS3.p2.11.m3.1a"><msub id="S3.SS3.p2.11.m3.1.1" xref="S3.SS3.p2.11.m3.1.1.cmml"><mi id="S3.SS3.p2.11.m3.1.1.2" xref="S3.SS3.p2.11.m3.1.1.2.cmml">Q</mi><mi id="S3.SS3.p2.11.m3.1.1.3" xref="S3.SS3.p2.11.m3.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.11.m3.1b"><apply id="S3.SS3.p2.11.m3.1.1.cmml" xref="S3.SS3.p2.11.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.11.m3.1.1.1.cmml" xref="S3.SS3.p2.11.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.11.m3.1.1.2.cmml" xref="S3.SS3.p2.11.m3.1.1.2">ğ‘„</ci><ci id="S3.SS3.p2.11.m3.1.1.3.cmml" xref="S3.SS3.p2.11.m3.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.11.m3.1c">Q_{h}</annotation></semantics></math> and decoder orignal query features <math id="S3.SS3.p2.12.m4.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S3.SS3.p2.12.m4.1a"><msub id="S3.SS3.p2.12.m4.1.1" xref="S3.SS3.p2.12.m4.1.1.cmml"><mi id="S3.SS3.p2.12.m4.1.1.2" xref="S3.SS3.p2.12.m4.1.1.2.cmml">Q</mi><mi id="S3.SS3.p2.12.m4.1.1.3" xref="S3.SS3.p2.12.m4.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.12.m4.1b"><apply id="S3.SS3.p2.12.m4.1.1.cmml" xref="S3.SS3.p2.12.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.12.m4.1.1.1.cmml" xref="S3.SS3.p2.12.m4.1.1">subscript</csymbol><ci id="S3.SS3.p2.12.m4.1.1.2.cmml" xref="S3.SS3.p2.12.m4.1.1.2">ğ‘„</ci><ci id="S3.SS3.p2.12.m4.1.1.3.cmml" xref="S3.SS3.p2.12.m4.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.12.m4.1c">Q_{d}</annotation></semantics></math>. This mechanism enables the model to prioritize and weight the importance of different aspects of the high-level features, thus enhancing the overall feature representation. Following the self-attention step, we determine the cross-correlation (similarity) between the outputs <math id="S3.SS3.p2.13.m5.1" class="ltx_Math" alttext="Q^{\prime}_{h}" display="inline"><semantics id="S3.SS3.p2.13.m5.1a"><msubsup id="S3.SS3.p2.13.m5.1.1" xref="S3.SS3.p2.13.m5.1.1.cmml"><mi id="S3.SS3.p2.13.m5.1.1.2.2" xref="S3.SS3.p2.13.m5.1.1.2.2.cmml">Q</mi><mi id="S3.SS3.p2.13.m5.1.1.3" xref="S3.SS3.p2.13.m5.1.1.3.cmml">h</mi><mo id="S3.SS3.p2.13.m5.1.1.2.3" xref="S3.SS3.p2.13.m5.1.1.2.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.13.m5.1b"><apply id="S3.SS3.p2.13.m5.1.1.cmml" xref="S3.SS3.p2.13.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.13.m5.1.1.1.cmml" xref="S3.SS3.p2.13.m5.1.1">subscript</csymbol><apply id="S3.SS3.p2.13.m5.1.1.2.cmml" xref="S3.SS3.p2.13.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.13.m5.1.1.2.1.cmml" xref="S3.SS3.p2.13.m5.1.1">superscript</csymbol><ci id="S3.SS3.p2.13.m5.1.1.2.2.cmml" xref="S3.SS3.p2.13.m5.1.1.2.2">ğ‘„</ci><ci id="S3.SS3.p2.13.m5.1.1.2.3.cmml" xref="S3.SS3.p2.13.m5.1.1.2.3">â€²</ci></apply><ci id="S3.SS3.p2.13.m5.1.1.3.cmml" xref="S3.SS3.p2.13.m5.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.13.m5.1c">Q^{\prime}_{h}</annotation></semantics></math> and <math id="S3.SS3.p2.14.m6.1" class="ltx_Math" alttext="Q^{\prime}_{d}" display="inline"><semantics id="S3.SS3.p2.14.m6.1a"><msubsup id="S3.SS3.p2.14.m6.1.1" xref="S3.SS3.p2.14.m6.1.1.cmml"><mi id="S3.SS3.p2.14.m6.1.1.2.2" xref="S3.SS3.p2.14.m6.1.1.2.2.cmml">Q</mi><mi id="S3.SS3.p2.14.m6.1.1.3" xref="S3.SS3.p2.14.m6.1.1.3.cmml">d</mi><mo id="S3.SS3.p2.14.m6.1.1.2.3" xref="S3.SS3.p2.14.m6.1.1.2.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.14.m6.1b"><apply id="S3.SS3.p2.14.m6.1.1.cmml" xref="S3.SS3.p2.14.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.14.m6.1.1.1.cmml" xref="S3.SS3.p2.14.m6.1.1">subscript</csymbol><apply id="S3.SS3.p2.14.m6.1.1.2.cmml" xref="S3.SS3.p2.14.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.14.m6.1.1.2.1.cmml" xref="S3.SS3.p2.14.m6.1.1">superscript</csymbol><ci id="S3.SS3.p2.14.m6.1.1.2.2.cmml" xref="S3.SS3.p2.14.m6.1.1.2.2">ğ‘„</ci><ci id="S3.SS3.p2.14.m6.1.1.2.3.cmml" xref="S3.SS3.p2.14.m6.1.1.2.3">â€²</ci></apply><ci id="S3.SS3.p2.14.m6.1.1.3.cmml" xref="S3.SS3.p2.14.m6.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.14.m6.1c">Q^{\prime}_{d}</annotation></semantics></math>, using cosine similarityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. The process is formalized as follows:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="Q_{e}=similarity(Q^{\prime}_{d},Q^{\prime}_{h})" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><msub id="S3.E2.m1.2.2.4" xref="S3.E2.m1.2.2.4.cmml"><mi id="S3.E2.m1.2.2.4.2" xref="S3.E2.m1.2.2.4.2.cmml">Q</mi><mi id="S3.E2.m1.2.2.4.3" xref="S3.E2.m1.2.2.4.3.cmml">e</mi></msub><mo id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.3.cmml">=</mo><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.5" xref="S3.E2.m1.2.2.2.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3a" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.6" xref="S3.E2.m1.2.2.2.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3b" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.7" xref="S3.E2.m1.2.2.2.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3c" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.8" xref="S3.E2.m1.2.2.2.8.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3d" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.9" xref="S3.E2.m1.2.2.2.9.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3e" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.10" xref="S3.E2.m1.2.2.2.10.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3f" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.11" xref="S3.E2.m1.2.2.2.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3g" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.12" xref="S3.E2.m1.2.2.2.12.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3h" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.2.13" xref="S3.E2.m1.2.2.2.13.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3i" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">(</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml">Q</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">d</mi><mo id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml">â€²</mo></msubsup><mo id="S3.E2.m1.2.2.2.2.2.4" xref="S3.E2.m1.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.2.2.cmml">Q</mi><mi id="S3.E2.m1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.2.3.cmml">h</mi><mo id="S3.E2.m1.2.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.2.2.3.cmml">â€²</mo></msubsup><mo stretchy="false" id="S3.E2.m1.2.2.2.2.2.5" xref="S3.E2.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.3"></eq><apply id="S3.E2.m1.2.2.4.cmml" xref="S3.E2.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.4.1.cmml" xref="S3.E2.m1.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.4.2.cmml" xref="S3.E2.m1.2.2.4.2">ğ‘„</ci><ci id="S3.E2.m1.2.2.4.3.cmml" xref="S3.E2.m1.2.2.4.3">ğ‘’</ci></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><times id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"></times><ci id="S3.E2.m1.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.4">ğ‘ </ci><ci id="S3.E2.m1.2.2.2.5.cmml" xref="S3.E2.m1.2.2.2.5">ğ‘–</ci><ci id="S3.E2.m1.2.2.2.6.cmml" xref="S3.E2.m1.2.2.2.6">ğ‘š</ci><ci id="S3.E2.m1.2.2.2.7.cmml" xref="S3.E2.m1.2.2.2.7">ğ‘–</ci><ci id="S3.E2.m1.2.2.2.8.cmml" xref="S3.E2.m1.2.2.2.8">ğ‘™</ci><ci id="S3.E2.m1.2.2.2.9.cmml" xref="S3.E2.m1.2.2.2.9">ğ‘</ci><ci id="S3.E2.m1.2.2.2.10.cmml" xref="S3.E2.m1.2.2.2.10">ğ‘Ÿ</ci><ci id="S3.E2.m1.2.2.2.11.cmml" xref="S3.E2.m1.2.2.2.11">ğ‘–</ci><ci id="S3.E2.m1.2.2.2.12.cmml" xref="S3.E2.m1.2.2.2.12">ğ‘¡</ci><ci id="S3.E2.m1.2.2.2.13.cmml" xref="S3.E2.m1.2.2.2.13">ğ‘¦</ci><interval closure="open" id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2">ğ‘„</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">â€²</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">ğ‘‘</ci></apply><apply id="S3.E2.m1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2">subscript</csymbol><apply id="S3.E2.m1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2">superscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.2.2">ğ‘„</ci><ci id="S3.E2.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.2.3">â€²</ci></apply><ci id="S3.E2.m1.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3">â„</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">Q_{e}=similarity(Q^{\prime}_{d},Q^{\prime}_{h})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.17" class="ltx_p">Here, <math id="S3.SS3.p2.15.m1.1" class="ltx_Math" alttext="Q^{\prime}_{h}" display="inline"><semantics id="S3.SS3.p2.15.m1.1a"><msubsup id="S3.SS3.p2.15.m1.1.1" xref="S3.SS3.p2.15.m1.1.1.cmml"><mi id="S3.SS3.p2.15.m1.1.1.2.2" xref="S3.SS3.p2.15.m1.1.1.2.2.cmml">Q</mi><mi id="S3.SS3.p2.15.m1.1.1.3" xref="S3.SS3.p2.15.m1.1.1.3.cmml">h</mi><mo id="S3.SS3.p2.15.m1.1.1.2.3" xref="S3.SS3.p2.15.m1.1.1.2.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.15.m1.1b"><apply id="S3.SS3.p2.15.m1.1.1.cmml" xref="S3.SS3.p2.15.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.15.m1.1.1.1.cmml" xref="S3.SS3.p2.15.m1.1.1">subscript</csymbol><apply id="S3.SS3.p2.15.m1.1.1.2.cmml" xref="S3.SS3.p2.15.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.15.m1.1.1.2.1.cmml" xref="S3.SS3.p2.15.m1.1.1">superscript</csymbol><ci id="S3.SS3.p2.15.m1.1.1.2.2.cmml" xref="S3.SS3.p2.15.m1.1.1.2.2">ğ‘„</ci><ci id="S3.SS3.p2.15.m1.1.1.2.3.cmml" xref="S3.SS3.p2.15.m1.1.1.2.3">â€²</ci></apply><ci id="S3.SS3.p2.15.m1.1.1.3.cmml" xref="S3.SS3.p2.15.m1.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.15.m1.1c">Q^{\prime}_{h}</annotation></semantics></math> refers to the query features from the backbone after self-attention, while <math id="S3.SS3.p2.16.m2.1" class="ltx_Math" alttext="Q^{\prime}_{d}" display="inline"><semantics id="S3.SS3.p2.16.m2.1a"><msubsup id="S3.SS3.p2.16.m2.1.1" xref="S3.SS3.p2.16.m2.1.1.cmml"><mi id="S3.SS3.p2.16.m2.1.1.2.2" xref="S3.SS3.p2.16.m2.1.1.2.2.cmml">Q</mi><mi id="S3.SS3.p2.16.m2.1.1.3" xref="S3.SS3.p2.16.m2.1.1.3.cmml">d</mi><mo id="S3.SS3.p2.16.m2.1.1.2.3" xref="S3.SS3.p2.16.m2.1.1.2.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.16.m2.1b"><apply id="S3.SS3.p2.16.m2.1.1.cmml" xref="S3.SS3.p2.16.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.16.m2.1.1.1.cmml" xref="S3.SS3.p2.16.m2.1.1">subscript</csymbol><apply id="S3.SS3.p2.16.m2.1.1.2.cmml" xref="S3.SS3.p2.16.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.16.m2.1.1.2.1.cmml" xref="S3.SS3.p2.16.m2.1.1">superscript</csymbol><ci id="S3.SS3.p2.16.m2.1.1.2.2.cmml" xref="S3.SS3.p2.16.m2.1.1.2.2">ğ‘„</ci><ci id="S3.SS3.p2.16.m2.1.1.2.3.cmml" xref="S3.SS3.p2.16.m2.1.1.2.3">â€²</ci></apply><ci id="S3.SS3.p2.16.m2.1.1.3.cmml" xref="S3.SS3.p2.16.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.16.m2.1c">Q^{\prime}_{d}</annotation></semantics></math> denotes the original decoder queries after self-attention. The final step involves integrating these refined queries <math id="S3.SS3.p2.17.m3.1" class="ltx_Math" alttext="Q_{e}" display="inline"><semantics id="S3.SS3.p2.17.m3.1a"><msub id="S3.SS3.p2.17.m3.1.1" xref="S3.SS3.p2.17.m3.1.1.cmml"><mi id="S3.SS3.p2.17.m3.1.1.2" xref="S3.SS3.p2.17.m3.1.1.2.cmml">Q</mi><mi id="S3.SS3.p2.17.m3.1.1.3" xref="S3.SS3.p2.17.m3.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.17.m3.1b"><apply id="S3.SS3.p2.17.m3.1.1.cmml" xref="S3.SS3.p2.17.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.17.m3.1.1.1.cmml" xref="S3.SS3.p2.17.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.17.m3.1.1.2.cmml" xref="S3.SS3.p2.17.m3.1.1.2">ğ‘„</ci><ci id="S3.SS3.p2.17.m3.1.1.3.cmml" xref="S3.SS3.p2.17.m3.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.17.m3.1c">Q_{e}</annotation></semantics></math> with the original queries from the decoder, enhancing the overall feature extraction and analysis.
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.6" class="ltx_p"><span id="S3.SS3.p3.6.1" class="ltx_text ltx_font_bold">Combining Features for Enhanced Detection:</span>
In the next step, we integrate two distinct types of features to boost detection capabilities. High-level features, represented by <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="Q_{h}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">Q</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">ğ‘„</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">Q_{h}</annotation></semantics></math>, allow the model to understand the overall layout and context of the document. On the other hand, we have the original transformer query features, which are adept at capturing specific object information. The enhanced features <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="Q_{e}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">Q</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">ğ‘„</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">Q_{e}</annotation></semantics></math> are obtained from self-attention on <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="Q_{h}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">Q</mi><mi id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">ğ‘„</ci><ci id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">Q_{h}</annotation></semantics></math> and decoder original queries <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">Q</mi><mi id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">ğ‘„</ci><ci id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">Q_{d}</annotation></semantics></math>. This concatenation is particularly beneficial for detecting small graphical elements, such as page headers, footers, and titles, which might be missed by the decoderâ€™s original query features alone. Combining these features enhances the modelâ€™s detection sensitivity to these smaller elements. The combined query features, which we denote as <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="Q_{t}" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><msub id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml"><mi id="S3.SS3.p3.5.m5.1.1.2" xref="S3.SS3.p3.5.m5.1.1.2.cmml">Q</mi><mi id="S3.SS3.p3.5.m5.1.1.3" xref="S3.SS3.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2">ğ‘„</ci><ci id="S3.SS3.p3.5.m5.1.1.3.cmml" xref="S3.SS3.p3.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">Q_{t}</annotation></semantics></math>, are formed by concatenating the decoder original query features with the enhanced query features <math id="S3.SS3.p3.6.m6.1" class="ltx_Math" alttext="Q_{e}" display="inline"><semantics id="S3.SS3.p3.6.m6.1a"><msub id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml"><mi id="S3.SS3.p3.6.m6.1.1.2" xref="S3.SS3.p3.6.m6.1.1.2.cmml">Q</mi><mi id="S3.SS3.p3.6.m6.1.1.3" xref="S3.SS3.p3.6.m6.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b"><apply id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p3.6.m6.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2">ğ‘„</ci><ci id="S3.SS3.p3.6.m6.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">Q_{e}</annotation></semantics></math>:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="Q_{t}=\text{Concat}(Q_{d},Q_{e})" display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mi id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml">Q</mi><mi id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3.cmml">t</mi></msub><mo id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">=</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><mtext id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.4a.cmml">Concat</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">Q</mi><mi id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.E3.m1.2.2.2.2.2.4" xref="S3.E3.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml">Q</mi><mi id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.cmml">e</mi></msub><mo stretchy="false" id="S3.E3.m1.2.2.2.2.2.5" xref="S3.E3.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"></eq><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2">ğ‘„</ci><ci id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3">ğ‘¡</ci></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><times id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></times><ci id="S3.E3.m1.2.2.2.4a.cmml" xref="S3.E3.m1.2.2.2.4"><mtext id="S3.E3.m1.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.4">Concat</mtext></ci><interval closure="open" id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">ğ‘„</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">ğ‘‘</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2">ğ‘„</ci><ci id="S3.E3.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3">ğ‘’</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">Q_{t}=\text{Concat}(Q_{d},Q_{e})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.7" class="ltx_p">This combination of features from both the high-level and the decoder queries enriches the feature set provided to the model, leading to a more robust detection mechanism for various objects within complex documents.
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.5" class="ltx_p"><span id="S3.SS3.p4.5.1" class="ltx_text ltx_font_bold">Integration with Decoderâ€™s Original Queries:</span>
By merging previously generated queries with the original decoder queries, our model performs better in identifying elements in document images. This integration enhances the modelâ€™s ability to detect prominent and subtle features within complex document layouts, making it especially effective for predicting small or easily overlooked objects. The process of query integration and output generation is formulated as:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.2" class="ltx_Math" alttext="o=Decoder(Q_{t},E|A)" display="block"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><mi id="S3.E4.m1.2.2.4" xref="S3.E4.m1.2.2.4.cmml">o</mi><mo id="S3.E4.m1.2.2.3" xref="S3.E4.m1.2.2.3.cmml">=</mo><mrow id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml"><mi id="S3.E4.m1.2.2.2.4" xref="S3.E4.m1.2.2.2.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3" xref="S3.E4.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.2.5" xref="S3.E4.m1.2.2.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3a" xref="S3.E4.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.2.6" xref="S3.E4.m1.2.2.2.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3b" xref="S3.E4.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.2.7" xref="S3.E4.m1.2.2.2.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3c" xref="S3.E4.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.2.8" xref="S3.E4.m1.2.2.2.8.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3d" xref="S3.E4.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.2.9" xref="S3.E4.m1.2.2.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3e" xref="S3.E4.m1.2.2.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.2.10" xref="S3.E4.m1.2.2.2.10.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3f" xref="S3.E4.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E4.m1.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.3.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">Q</mi><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E4.m1.2.2.2.2.2.4" xref="S3.E4.m1.2.2.2.2.3.cmml">,</mo><mrow id="S3.E4.m1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.cmml"><mi id="S3.E4.m1.2.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.2.cmml">E</mi><mo fence="false" id="S3.E4.m1.2.2.2.2.2.2.1" xref="S3.E4.m1.2.2.2.2.2.2.1.cmml">|</mo><mi id="S3.E4.m1.2.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.2.3.cmml">A</mi></mrow><mo stretchy="false" id="S3.E4.m1.2.2.2.2.2.5" xref="S3.E4.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><eq id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2.3"></eq><ci id="S3.E4.m1.2.2.4.cmml" xref="S3.E4.m1.2.2.4">ğ‘œ</ci><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2"><times id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.3"></times><ci id="S3.E4.m1.2.2.2.4.cmml" xref="S3.E4.m1.2.2.2.4">ğ·</ci><ci id="S3.E4.m1.2.2.2.5.cmml" xref="S3.E4.m1.2.2.2.5">ğ‘’</ci><ci id="S3.E4.m1.2.2.2.6.cmml" xref="S3.E4.m1.2.2.2.6">ğ‘</ci><ci id="S3.E4.m1.2.2.2.7.cmml" xref="S3.E4.m1.2.2.2.7">ğ‘œ</ci><ci id="S3.E4.m1.2.2.2.8.cmml" xref="S3.E4.m1.2.2.2.8">ğ‘‘</ci><ci id="S3.E4.m1.2.2.2.9.cmml" xref="S3.E4.m1.2.2.2.9">ğ‘’</ci><ci id="S3.E4.m1.2.2.2.10.cmml" xref="S3.E4.m1.2.2.2.10">ğ‘Ÿ</ci><interval closure="open" id="S3.E4.m1.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2"><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2">ğ‘„</ci><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E4.m1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2"><csymbol cd="latexml" id="S3.E4.m1.2.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.2.1">conditional</csymbol><ci id="S3.E4.m1.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2">ğ¸</ci><ci id="S3.E4.m1.2.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.2.3">ğ´</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">o=Decoder(Q_{t},E|A)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p4.4" class="ltx_p">Here, our model utilizes a set of decoder queries, denoted by <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="Q_{t}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">Q</mi><mi id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">ğ‘„</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">Q_{t}</annotation></semantics></math>, and corresponding outputs from the Transformer decoder, represented as <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="o" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">o</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">ğ‘œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">o</annotation></semantics></math>. The refined image features, processed by the Transformer encoder, are symbolized by <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><mi id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><ci id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">F</annotation></semantics></math>, while <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><mi id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><ci id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">A</annotation></semantics></math> represents the attention mask, specifically designed for the denoising taskÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.
In this way, this query mechanism combines the strengths of both abstract and detailed image features, facilitating thorough and precise detection of diverse elements within intricate document structures.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Query Selection Strategy</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Our research introduces an innovative hybrid matching scheme for analyzing complex documents. This approach uniquely combines two query strategies, one-to-one and one-to-many matching, to enhance the detection and understanding of various elements in detailed documents. Initially, we observe that the one-to-many strategy led to duplicate predictions, as shown in TableÂ <a href="#S5.T5" title="Table 5 â€£ 5.4 Ablation Study â€£ 5 Results and Discussion â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. To optimize this, we utilized one-to-many matching during the first half of our training iterations, then shifted to one-to-one matching for the remainder. This transition markedly improved accuracy and reduced duplications.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">As a key feature of our hybrid approach, the one-to-many matching branch is designed to enhance object detection in complex document layouts. This innovative branch enables the association of a single detected object with multiple ground truths, a significant advancement over traditional one-to-one matching methods. We integrate original decoder queries with high-quality object queries generated in the one-to-many strategy. These object queries are generated by merging high-level query features from the backbone as explained in subsectionÂ <a href="#S3.SS3" title="3.3 Query Encoding Strategy â€£ 3 Methodology â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>. It is particularly useful in complex document layouts where traditional one-to-one matching might struggle. By enabling an object to be matched with several ground truths, the model better understands the documentâ€™s content, especially in overlapping or closely packed elements. The total loss in ono-to-many strategy is as follows:</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.5" class="ltx_Math" alttext="L^{1-m}_{cls}=\sum_{i=1}^{N_{obj}}|\hat{g}_{i}-p_{i}|\cdot BCE(p_{i},\hat{g}_{i})+\sum_{j=1}^{N_{no}}p_{j}\cdot BCE(p_{j},0)" display="block"><semantics id="S3.E5.m1.5a"><mrow id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml"><msubsup id="S3.E5.m1.5.5.6" xref="S3.E5.m1.5.5.6.cmml"><mi id="S3.E5.m1.5.5.6.2.2" xref="S3.E5.m1.5.5.6.2.2.cmml">L</mi><mrow id="S3.E5.m1.5.5.6.3" xref="S3.E5.m1.5.5.6.3.cmml"><mi id="S3.E5.m1.5.5.6.3.2" xref="S3.E5.m1.5.5.6.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.6.3.1" xref="S3.E5.m1.5.5.6.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.6.3.3" xref="S3.E5.m1.5.5.6.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.6.3.1a" xref="S3.E5.m1.5.5.6.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.6.3.4" xref="S3.E5.m1.5.5.6.3.4.cmml">s</mi></mrow><mrow id="S3.E5.m1.5.5.6.2.3" xref="S3.E5.m1.5.5.6.2.3.cmml"><mn id="S3.E5.m1.5.5.6.2.3.2" xref="S3.E5.m1.5.5.6.2.3.2.cmml">1</mn><mo id="S3.E5.m1.5.5.6.2.3.1" xref="S3.E5.m1.5.5.6.2.3.1.cmml">âˆ’</mo><mi id="S3.E5.m1.5.5.6.2.3.3" xref="S3.E5.m1.5.5.6.2.3.3.cmml">m</mi></mrow></msubsup><mo rspace="0.111em" id="S3.E5.m1.5.5.5" xref="S3.E5.m1.5.5.5.cmml">=</mo><mrow id="S3.E5.m1.5.5.4" xref="S3.E5.m1.5.5.4.cmml"><mrow id="S3.E5.m1.4.4.3.3" xref="S3.E5.m1.4.4.3.3.cmml"><munderover id="S3.E5.m1.4.4.3.3.4" xref="S3.E5.m1.4.4.3.3.4.cmml"><mo movablelimits="false" rspace="0em" id="S3.E5.m1.4.4.3.3.4.2.2" xref="S3.E5.m1.4.4.3.3.4.2.2.cmml">âˆ‘</mo><mrow id="S3.E5.m1.4.4.3.3.4.2.3" xref="S3.E5.m1.4.4.3.3.4.2.3.cmml"><mi id="S3.E5.m1.4.4.3.3.4.2.3.2" xref="S3.E5.m1.4.4.3.3.4.2.3.2.cmml">i</mi><mo id="S3.E5.m1.4.4.3.3.4.2.3.1" xref="S3.E5.m1.4.4.3.3.4.2.3.1.cmml">=</mo><mn id="S3.E5.m1.4.4.3.3.4.2.3.3" xref="S3.E5.m1.4.4.3.3.4.2.3.3.cmml">1</mn></mrow><msub id="S3.E5.m1.4.4.3.3.4.3" xref="S3.E5.m1.4.4.3.3.4.3.cmml"><mi id="S3.E5.m1.4.4.3.3.4.3.2" xref="S3.E5.m1.4.4.3.3.4.3.2.cmml">N</mi><mrow id="S3.E5.m1.4.4.3.3.4.3.3" xref="S3.E5.m1.4.4.3.3.4.3.3.cmml"><mi id="S3.E5.m1.4.4.3.3.4.3.3.2" xref="S3.E5.m1.4.4.3.3.4.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.3.3.4.3.3.1" xref="S3.E5.m1.4.4.3.3.4.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.4.4.3.3.4.3.3.3" xref="S3.E5.m1.4.4.3.3.4.3.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.3.3.4.3.3.1a" xref="S3.E5.m1.4.4.3.3.4.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.4.4.3.3.4.3.3.4" xref="S3.E5.m1.4.4.3.3.4.3.3.4.cmml">j</mi></mrow></msub></munderover><mrow id="S3.E5.m1.4.4.3.3.3" xref="S3.E5.m1.4.4.3.3.3.cmml"><mrow id="S3.E5.m1.2.2.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.cmml">g</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.2.1.cmml">|</mo></mrow><mo rspace="0.222em" id="S3.E5.m1.2.2.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.2.cmml">â‹…</mo><mi id="S3.E5.m1.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.3.cmml">B</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.3.3.3.4" xref="S3.E5.m1.4.4.3.3.3.4.cmml">â€‹</mo><mi id="S3.E5.m1.4.4.3.3.3.5" xref="S3.E5.m1.4.4.3.3.3.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.3.3.3.4a" xref="S3.E5.m1.4.4.3.3.3.4.cmml">â€‹</mo><mi id="S3.E5.m1.4.4.3.3.3.6" xref="S3.E5.m1.4.4.3.3.3.6.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.3.3.3.4b" xref="S3.E5.m1.4.4.3.3.3.4.cmml">â€‹</mo><mrow id="S3.E5.m1.4.4.3.3.3.3.2" xref="S3.E5.m1.4.4.3.3.3.3.3.cmml"><mo stretchy="false" id="S3.E5.m1.4.4.3.3.3.3.2.3" xref="S3.E5.m1.4.4.3.3.3.3.3.cmml">(</mo><msub id="S3.E5.m1.3.3.2.2.2.2.1.1" xref="S3.E5.m1.3.3.2.2.2.2.1.1.cmml"><mi id="S3.E5.m1.3.3.2.2.2.2.1.1.2" xref="S3.E5.m1.3.3.2.2.2.2.1.1.2.cmml">p</mi><mi id="S3.E5.m1.3.3.2.2.2.2.1.1.3" xref="S3.E5.m1.3.3.2.2.2.2.1.1.3.cmml">i</mi></msub><mo id="S3.E5.m1.4.4.3.3.3.3.2.4" xref="S3.E5.m1.4.4.3.3.3.3.3.cmml">,</mo><msub id="S3.E5.m1.4.4.3.3.3.3.2.2" xref="S3.E5.m1.4.4.3.3.3.3.2.2.cmml"><mover accent="true" id="S3.E5.m1.4.4.3.3.3.3.2.2.2" xref="S3.E5.m1.4.4.3.3.3.3.2.2.2.cmml"><mi id="S3.E5.m1.4.4.3.3.3.3.2.2.2.2" xref="S3.E5.m1.4.4.3.3.3.3.2.2.2.2.cmml">g</mi><mo id="S3.E5.m1.4.4.3.3.3.3.2.2.2.1" xref="S3.E5.m1.4.4.3.3.3.3.2.2.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.4.4.3.3.3.3.2.2.3" xref="S3.E5.m1.4.4.3.3.3.3.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E5.m1.4.4.3.3.3.3.2.5" xref="S3.E5.m1.4.4.3.3.3.3.3.cmml">)</mo></mrow></mrow></mrow><mo rspace="0.055em" id="S3.E5.m1.5.5.4.5" xref="S3.E5.m1.5.5.4.5.cmml">+</mo><mrow id="S3.E5.m1.5.5.4.4" xref="S3.E5.m1.5.5.4.4.cmml"><munderover id="S3.E5.m1.5.5.4.4.2" xref="S3.E5.m1.5.5.4.4.2.cmml"><mo movablelimits="false" id="S3.E5.m1.5.5.4.4.2.2.2" xref="S3.E5.m1.5.5.4.4.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E5.m1.5.5.4.4.2.2.3" xref="S3.E5.m1.5.5.4.4.2.2.3.cmml"><mi id="S3.E5.m1.5.5.4.4.2.2.3.2" xref="S3.E5.m1.5.5.4.4.2.2.3.2.cmml">j</mi><mo id="S3.E5.m1.5.5.4.4.2.2.3.1" xref="S3.E5.m1.5.5.4.4.2.2.3.1.cmml">=</mo><mn id="S3.E5.m1.5.5.4.4.2.2.3.3" xref="S3.E5.m1.5.5.4.4.2.2.3.3.cmml">1</mn></mrow><msub id="S3.E5.m1.5.5.4.4.2.3" xref="S3.E5.m1.5.5.4.4.2.3.cmml"><mi id="S3.E5.m1.5.5.4.4.2.3.2" xref="S3.E5.m1.5.5.4.4.2.3.2.cmml">N</mi><mrow id="S3.E5.m1.5.5.4.4.2.3.3" xref="S3.E5.m1.5.5.4.4.2.3.3.cmml"><mi id="S3.E5.m1.5.5.4.4.2.3.3.2" xref="S3.E5.m1.5.5.4.4.2.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.4.4.2.3.3.1" xref="S3.E5.m1.5.5.4.4.2.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.4.4.2.3.3.3" xref="S3.E5.m1.5.5.4.4.2.3.3.3.cmml">o</mi></mrow></msub></munderover><mrow id="S3.E5.m1.5.5.4.4.1" xref="S3.E5.m1.5.5.4.4.1.cmml"><mrow id="S3.E5.m1.5.5.4.4.1.3" xref="S3.E5.m1.5.5.4.4.1.3.cmml"><msub id="S3.E5.m1.5.5.4.4.1.3.2" xref="S3.E5.m1.5.5.4.4.1.3.2.cmml"><mi id="S3.E5.m1.5.5.4.4.1.3.2.2" xref="S3.E5.m1.5.5.4.4.1.3.2.2.cmml">p</mi><mi id="S3.E5.m1.5.5.4.4.1.3.2.3" xref="S3.E5.m1.5.5.4.4.1.3.2.3.cmml">j</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.5.5.4.4.1.3.1" xref="S3.E5.m1.5.5.4.4.1.3.1.cmml">â‹…</mo><mi id="S3.E5.m1.5.5.4.4.1.3.3" xref="S3.E5.m1.5.5.4.4.1.3.3.cmml">B</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.4.4.1.2" xref="S3.E5.m1.5.5.4.4.1.2.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.4.4.1.4" xref="S3.E5.m1.5.5.4.4.1.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.4.4.1.2a" xref="S3.E5.m1.5.5.4.4.1.2.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.4.4.1.5" xref="S3.E5.m1.5.5.4.4.1.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.4.4.1.2b" xref="S3.E5.m1.5.5.4.4.1.2.cmml">â€‹</mo><mrow id="S3.E5.m1.5.5.4.4.1.1.1" xref="S3.E5.m1.5.5.4.4.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.5.5.4.4.1.1.1.2" xref="S3.E5.m1.5.5.4.4.1.1.2.cmml">(</mo><msub id="S3.E5.m1.5.5.4.4.1.1.1.1" xref="S3.E5.m1.5.5.4.4.1.1.1.1.cmml"><mi id="S3.E5.m1.5.5.4.4.1.1.1.1.2" xref="S3.E5.m1.5.5.4.4.1.1.1.1.2.cmml">p</mi><mi id="S3.E5.m1.5.5.4.4.1.1.1.1.3" xref="S3.E5.m1.5.5.4.4.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.E5.m1.5.5.4.4.1.1.1.3" xref="S3.E5.m1.5.5.4.4.1.1.2.cmml">,</mo><mn id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">0</mn><mo stretchy="false" id="S3.E5.m1.5.5.4.4.1.1.1.4" xref="S3.E5.m1.5.5.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.5b"><apply id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5"><eq id="S3.E5.m1.5.5.5.cmml" xref="S3.E5.m1.5.5.5"></eq><apply id="S3.E5.m1.5.5.6.cmml" xref="S3.E5.m1.5.5.6"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.6.1.cmml" xref="S3.E5.m1.5.5.6">subscript</csymbol><apply id="S3.E5.m1.5.5.6.2.cmml" xref="S3.E5.m1.5.5.6"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.6.2.1.cmml" xref="S3.E5.m1.5.5.6">superscript</csymbol><ci id="S3.E5.m1.5.5.6.2.2.cmml" xref="S3.E5.m1.5.5.6.2.2">ğ¿</ci><apply id="S3.E5.m1.5.5.6.2.3.cmml" xref="S3.E5.m1.5.5.6.2.3"><minus id="S3.E5.m1.5.5.6.2.3.1.cmml" xref="S3.E5.m1.5.5.6.2.3.1"></minus><cn type="integer" id="S3.E5.m1.5.5.6.2.3.2.cmml" xref="S3.E5.m1.5.5.6.2.3.2">1</cn><ci id="S3.E5.m1.5.5.6.2.3.3.cmml" xref="S3.E5.m1.5.5.6.2.3.3">ğ‘š</ci></apply></apply><apply id="S3.E5.m1.5.5.6.3.cmml" xref="S3.E5.m1.5.5.6.3"><times id="S3.E5.m1.5.5.6.3.1.cmml" xref="S3.E5.m1.5.5.6.3.1"></times><ci id="S3.E5.m1.5.5.6.3.2.cmml" xref="S3.E5.m1.5.5.6.3.2">ğ‘</ci><ci id="S3.E5.m1.5.5.6.3.3.cmml" xref="S3.E5.m1.5.5.6.3.3">ğ‘™</ci><ci id="S3.E5.m1.5.5.6.3.4.cmml" xref="S3.E5.m1.5.5.6.3.4">ğ‘ </ci></apply></apply><apply id="S3.E5.m1.5.5.4.cmml" xref="S3.E5.m1.5.5.4"><plus id="S3.E5.m1.5.5.4.5.cmml" xref="S3.E5.m1.5.5.4.5"></plus><apply id="S3.E5.m1.4.4.3.3.cmml" xref="S3.E5.m1.4.4.3.3"><apply id="S3.E5.m1.4.4.3.3.4.cmml" xref="S3.E5.m1.4.4.3.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.3.3.4.1.cmml" xref="S3.E5.m1.4.4.3.3.4">superscript</csymbol><apply id="S3.E5.m1.4.4.3.3.4.2.cmml" xref="S3.E5.m1.4.4.3.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.3.3.4.2.1.cmml" xref="S3.E5.m1.4.4.3.3.4">subscript</csymbol><sum id="S3.E5.m1.4.4.3.3.4.2.2.cmml" xref="S3.E5.m1.4.4.3.3.4.2.2"></sum><apply id="S3.E5.m1.4.4.3.3.4.2.3.cmml" xref="S3.E5.m1.4.4.3.3.4.2.3"><eq id="S3.E5.m1.4.4.3.3.4.2.3.1.cmml" xref="S3.E5.m1.4.4.3.3.4.2.3.1"></eq><ci id="S3.E5.m1.4.4.3.3.4.2.3.2.cmml" xref="S3.E5.m1.4.4.3.3.4.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E5.m1.4.4.3.3.4.2.3.3.cmml" xref="S3.E5.m1.4.4.3.3.4.2.3.3">1</cn></apply></apply><apply id="S3.E5.m1.4.4.3.3.4.3.cmml" xref="S3.E5.m1.4.4.3.3.4.3"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.3.3.4.3.1.cmml" xref="S3.E5.m1.4.4.3.3.4.3">subscript</csymbol><ci id="S3.E5.m1.4.4.3.3.4.3.2.cmml" xref="S3.E5.m1.4.4.3.3.4.3.2">ğ‘</ci><apply id="S3.E5.m1.4.4.3.3.4.3.3.cmml" xref="S3.E5.m1.4.4.3.3.4.3.3"><times id="S3.E5.m1.4.4.3.3.4.3.3.1.cmml" xref="S3.E5.m1.4.4.3.3.4.3.3.1"></times><ci id="S3.E5.m1.4.4.3.3.4.3.3.2.cmml" xref="S3.E5.m1.4.4.3.3.4.3.3.2">ğ‘œ</ci><ci id="S3.E5.m1.4.4.3.3.4.3.3.3.cmml" xref="S3.E5.m1.4.4.3.3.4.3.3.3">ğ‘</ci><ci id="S3.E5.m1.4.4.3.3.4.3.3.4.cmml" xref="S3.E5.m1.4.4.3.3.4.3.3.4">ğ‘—</ci></apply></apply></apply><apply id="S3.E5.m1.4.4.3.3.3.cmml" xref="S3.E5.m1.4.4.3.3.3"><times id="S3.E5.m1.4.4.3.3.3.4.cmml" xref="S3.E5.m1.4.4.3.3.3.4"></times><apply id="S3.E5.m1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1"><ci id="S3.E5.m1.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2">â‹…</ci><apply id="S3.E5.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1"><abs id="S3.E5.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.2"></abs><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1"><minus id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1"></minus><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2"><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2">ğ‘”</ci></apply><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><ci id="S3.E5.m1.2.2.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3">ğµ</ci></apply><ci id="S3.E5.m1.4.4.3.3.3.5.cmml" xref="S3.E5.m1.4.4.3.3.3.5">ğ¶</ci><ci id="S3.E5.m1.4.4.3.3.3.6.cmml" xref="S3.E5.m1.4.4.3.3.3.6">ğ¸</ci><interval closure="open" id="S3.E5.m1.4.4.3.3.3.3.3.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2"><apply id="S3.E5.m1.3.3.2.2.2.2.1.1.cmml" xref="S3.E5.m1.3.3.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.2.2.2.2.1.1.1.cmml" xref="S3.E5.m1.3.3.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E5.m1.3.3.2.2.2.2.1.1.2.cmml" xref="S3.E5.m1.3.3.2.2.2.2.1.1.2">ğ‘</ci><ci id="S3.E5.m1.3.3.2.2.2.2.1.1.3.cmml" xref="S3.E5.m1.3.3.2.2.2.2.1.1.3">ğ‘–</ci></apply><apply id="S3.E5.m1.4.4.3.3.3.3.2.2.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.3.3.3.3.2.2.1.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2.2">subscript</csymbol><apply id="S3.E5.m1.4.4.3.3.3.3.2.2.2.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2.2.2"><ci id="S3.E5.m1.4.4.3.3.3.3.2.2.2.1.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2.2.2.1">^</ci><ci id="S3.E5.m1.4.4.3.3.3.3.2.2.2.2.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2.2.2.2">ğ‘”</ci></apply><ci id="S3.E5.m1.4.4.3.3.3.3.2.2.3.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2.2.3">ğ‘–</ci></apply></interval></apply></apply><apply id="S3.E5.m1.5.5.4.4.cmml" xref="S3.E5.m1.5.5.4.4"><apply id="S3.E5.m1.5.5.4.4.2.cmml" xref="S3.E5.m1.5.5.4.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.4.4.2.1.cmml" xref="S3.E5.m1.5.5.4.4.2">superscript</csymbol><apply id="S3.E5.m1.5.5.4.4.2.2.cmml" xref="S3.E5.m1.5.5.4.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.4.4.2.2.1.cmml" xref="S3.E5.m1.5.5.4.4.2">subscript</csymbol><sum id="S3.E5.m1.5.5.4.4.2.2.2.cmml" xref="S3.E5.m1.5.5.4.4.2.2.2"></sum><apply id="S3.E5.m1.5.5.4.4.2.2.3.cmml" xref="S3.E5.m1.5.5.4.4.2.2.3"><eq id="S3.E5.m1.5.5.4.4.2.2.3.1.cmml" xref="S3.E5.m1.5.5.4.4.2.2.3.1"></eq><ci id="S3.E5.m1.5.5.4.4.2.2.3.2.cmml" xref="S3.E5.m1.5.5.4.4.2.2.3.2">ğ‘—</ci><cn type="integer" id="S3.E5.m1.5.5.4.4.2.2.3.3.cmml" xref="S3.E5.m1.5.5.4.4.2.2.3.3">1</cn></apply></apply><apply id="S3.E5.m1.5.5.4.4.2.3.cmml" xref="S3.E5.m1.5.5.4.4.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.4.4.2.3.1.cmml" xref="S3.E5.m1.5.5.4.4.2.3">subscript</csymbol><ci id="S3.E5.m1.5.5.4.4.2.3.2.cmml" xref="S3.E5.m1.5.5.4.4.2.3.2">ğ‘</ci><apply id="S3.E5.m1.5.5.4.4.2.3.3.cmml" xref="S3.E5.m1.5.5.4.4.2.3.3"><times id="S3.E5.m1.5.5.4.4.2.3.3.1.cmml" xref="S3.E5.m1.5.5.4.4.2.3.3.1"></times><ci id="S3.E5.m1.5.5.4.4.2.3.3.2.cmml" xref="S3.E5.m1.5.5.4.4.2.3.3.2">ğ‘›</ci><ci id="S3.E5.m1.5.5.4.4.2.3.3.3.cmml" xref="S3.E5.m1.5.5.4.4.2.3.3.3">ğ‘œ</ci></apply></apply></apply><apply id="S3.E5.m1.5.5.4.4.1.cmml" xref="S3.E5.m1.5.5.4.4.1"><times id="S3.E5.m1.5.5.4.4.1.2.cmml" xref="S3.E5.m1.5.5.4.4.1.2"></times><apply id="S3.E5.m1.5.5.4.4.1.3.cmml" xref="S3.E5.m1.5.5.4.4.1.3"><ci id="S3.E5.m1.5.5.4.4.1.3.1.cmml" xref="S3.E5.m1.5.5.4.4.1.3.1">â‹…</ci><apply id="S3.E5.m1.5.5.4.4.1.3.2.cmml" xref="S3.E5.m1.5.5.4.4.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.4.4.1.3.2.1.cmml" xref="S3.E5.m1.5.5.4.4.1.3.2">subscript</csymbol><ci id="S3.E5.m1.5.5.4.4.1.3.2.2.cmml" xref="S3.E5.m1.5.5.4.4.1.3.2.2">ğ‘</ci><ci id="S3.E5.m1.5.5.4.4.1.3.2.3.cmml" xref="S3.E5.m1.5.5.4.4.1.3.2.3">ğ‘—</ci></apply><ci id="S3.E5.m1.5.5.4.4.1.3.3.cmml" xref="S3.E5.m1.5.5.4.4.1.3.3">ğµ</ci></apply><ci id="S3.E5.m1.5.5.4.4.1.4.cmml" xref="S3.E5.m1.5.5.4.4.1.4">ğ¶</ci><ci id="S3.E5.m1.5.5.4.4.1.5.cmml" xref="S3.E5.m1.5.5.4.4.1.5">ğ¸</ci><interval closure="open" id="S3.E5.m1.5.5.4.4.1.1.2.cmml" xref="S3.E5.m1.5.5.4.4.1.1.1"><apply id="S3.E5.m1.5.5.4.4.1.1.1.1.cmml" xref="S3.E5.m1.5.5.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.4.4.1.1.1.1.1.cmml" xref="S3.E5.m1.5.5.4.4.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.5.5.4.4.1.1.1.1.2.cmml" xref="S3.E5.m1.5.5.4.4.1.1.1.1.2">ğ‘</ci><ci id="S3.E5.m1.5.5.4.4.1.1.1.1.3.cmml" xref="S3.E5.m1.5.5.4.4.1.1.1.1.3">ğ‘—</ci></apply><cn type="integer" id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">0</cn></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.5c">L^{1-m}_{cls}=\sum_{i=1}^{N_{obj}}|\hat{g}_{i}-p_{i}|\cdot BCE(p_{i},\hat{g}_{i})+\sum_{j=1}^{N_{no}}p_{j}\cdot BCE(p_{j},0)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.4" class="ltx_Math" alttext="L^{1-m}_{reg}=\sum_{i=1}^{N_{obj}}\hat{g}_{i}\cdot\mathcal{L}_{GIoU}(bx_{i},\hat{bx}_{i})+\sum_{i=1}^{N_{obj}}\hat{g}_{i}\cdot\mathcal{L}_{L1}(bx_{i},\hat{bx}_{i})" display="block"><semantics id="S3.E6.m1.4a"><mrow id="S3.E6.m1.4.4" xref="S3.E6.m1.4.4.cmml"><msubsup id="S3.E6.m1.4.4.6" xref="S3.E6.m1.4.4.6.cmml"><mi id="S3.E6.m1.4.4.6.2.2" xref="S3.E6.m1.4.4.6.2.2.cmml">L</mi><mrow id="S3.E6.m1.4.4.6.3" xref="S3.E6.m1.4.4.6.3.cmml"><mi id="S3.E6.m1.4.4.6.3.2" xref="S3.E6.m1.4.4.6.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.6.3.1" xref="S3.E6.m1.4.4.6.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.4.4.6.3.3" xref="S3.E6.m1.4.4.6.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.6.3.1a" xref="S3.E6.m1.4.4.6.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.4.4.6.3.4" xref="S3.E6.m1.4.4.6.3.4.cmml">g</mi></mrow><mrow id="S3.E6.m1.4.4.6.2.3" xref="S3.E6.m1.4.4.6.2.3.cmml"><mn id="S3.E6.m1.4.4.6.2.3.2" xref="S3.E6.m1.4.4.6.2.3.2.cmml">1</mn><mo id="S3.E6.m1.4.4.6.2.3.1" xref="S3.E6.m1.4.4.6.2.3.1.cmml">âˆ’</mo><mi id="S3.E6.m1.4.4.6.2.3.3" xref="S3.E6.m1.4.4.6.2.3.3.cmml">m</mi></mrow></msubsup><mo rspace="0.111em" id="S3.E6.m1.4.4.5" xref="S3.E6.m1.4.4.5.cmml">=</mo><mrow id="S3.E6.m1.4.4.4" xref="S3.E6.m1.4.4.4.cmml"><mrow id="S3.E6.m1.2.2.2.2" xref="S3.E6.m1.2.2.2.2.cmml"><munderover id="S3.E6.m1.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E6.m1.2.2.2.2.3.2.2" xref="S3.E6.m1.2.2.2.2.3.2.2.cmml">âˆ‘</mo><mrow id="S3.E6.m1.2.2.2.2.3.2.3" xref="S3.E6.m1.2.2.2.2.3.2.3.cmml"><mi id="S3.E6.m1.2.2.2.2.3.2.3.2" xref="S3.E6.m1.2.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E6.m1.2.2.2.2.3.2.3.1" xref="S3.E6.m1.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E6.m1.2.2.2.2.3.2.3.3" xref="S3.E6.m1.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><msub id="S3.E6.m1.2.2.2.2.3.3" xref="S3.E6.m1.2.2.2.2.3.3.cmml"><mi id="S3.E6.m1.2.2.2.2.3.3.2" xref="S3.E6.m1.2.2.2.2.3.3.2.cmml">N</mi><mrow id="S3.E6.m1.2.2.2.2.3.3.3" xref="S3.E6.m1.2.2.2.2.3.3.3.cmml"><mi id="S3.E6.m1.2.2.2.2.3.3.3.2" xref="S3.E6.m1.2.2.2.2.3.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.2.3.3.3.1" xref="S3.E6.m1.2.2.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.2.2.3.3.3.3" xref="S3.E6.m1.2.2.2.2.3.3.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.2.3.3.3.1a" xref="S3.E6.m1.2.2.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.2.2.3.3.3.4" xref="S3.E6.m1.2.2.2.2.3.3.3.4.cmml">j</mi></mrow></msub></munderover><mrow id="S3.E6.m1.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.cmml"><mrow id="S3.E6.m1.2.2.2.2.2.4" xref="S3.E6.m1.2.2.2.2.2.4.cmml"><msub id="S3.E6.m1.2.2.2.2.2.4.2" xref="S3.E6.m1.2.2.2.2.2.4.2.cmml"><mover accent="true" id="S3.E6.m1.2.2.2.2.2.4.2.2" xref="S3.E6.m1.2.2.2.2.2.4.2.2.cmml"><mi id="S3.E6.m1.2.2.2.2.2.4.2.2.2" xref="S3.E6.m1.2.2.2.2.2.4.2.2.2.cmml">g</mi><mo id="S3.E6.m1.2.2.2.2.2.4.2.2.1" xref="S3.E6.m1.2.2.2.2.2.4.2.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.2.2.2.2.2.4.2.3" xref="S3.E6.m1.2.2.2.2.2.4.2.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.2.2.2.2.2.4.1" xref="S3.E6.m1.2.2.2.2.2.4.1.cmml">â‹…</mo><msub id="S3.E6.m1.2.2.2.2.2.4.3" xref="S3.E6.m1.2.2.2.2.2.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.2.2.2.2.2.4.3.2" xref="S3.E6.m1.2.2.2.2.2.4.3.2.cmml">â„’</mi><mrow id="S3.E6.m1.2.2.2.2.2.4.3.3" xref="S3.E6.m1.2.2.2.2.2.4.3.3.cmml"><mi id="S3.E6.m1.2.2.2.2.2.4.3.3.2" xref="S3.E6.m1.2.2.2.2.2.4.3.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.2.2.4.3.3.1" xref="S3.E6.m1.2.2.2.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.2.2.2.4.3.3.3" xref="S3.E6.m1.2.2.2.2.2.4.3.3.3.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.2.2.4.3.3.1a" xref="S3.E6.m1.2.2.2.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.2.2.2.4.3.3.4" xref="S3.E6.m1.2.2.2.2.2.4.3.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.2.2.4.3.3.1b" xref="S3.E6.m1.2.2.2.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.2.2.2.4.3.3.5" xref="S3.E6.m1.2.2.2.2.2.4.3.3.5.cmml">U</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E6.m1.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.2.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.2.2.3.cmml">(</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.E6.m1.2.2.2.2.2.2.2.4" xref="S3.E6.m1.2.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E6.m1.2.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.2.2.cmml"><mover accent="true" id="S3.E6.m1.2.2.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.cmml"><mrow id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.1" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.3.cmml">x</mi></mrow><mo id="S3.E6.m1.2.2.2.2.2.2.2.2.2.1" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.2.2.2.2.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E6.m1.2.2.2.2.2.2.2.5" xref="S3.E6.m1.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo rspace="0.055em" id="S3.E6.m1.4.4.4.5" xref="S3.E6.m1.4.4.4.5.cmml">+</mo><mrow id="S3.E6.m1.4.4.4.4" xref="S3.E6.m1.4.4.4.4.cmml"><munderover id="S3.E6.m1.4.4.4.4.3" xref="S3.E6.m1.4.4.4.4.3.cmml"><mo movablelimits="false" id="S3.E6.m1.4.4.4.4.3.2.2" xref="S3.E6.m1.4.4.4.4.3.2.2.cmml">âˆ‘</mo><mrow id="S3.E6.m1.4.4.4.4.3.2.3" xref="S3.E6.m1.4.4.4.4.3.2.3.cmml"><mi id="S3.E6.m1.4.4.4.4.3.2.3.2" xref="S3.E6.m1.4.4.4.4.3.2.3.2.cmml">i</mi><mo id="S3.E6.m1.4.4.4.4.3.2.3.1" xref="S3.E6.m1.4.4.4.4.3.2.3.1.cmml">=</mo><mn id="S3.E6.m1.4.4.4.4.3.2.3.3" xref="S3.E6.m1.4.4.4.4.3.2.3.3.cmml">1</mn></mrow><msub id="S3.E6.m1.4.4.4.4.3.3" xref="S3.E6.m1.4.4.4.4.3.3.cmml"><mi id="S3.E6.m1.4.4.4.4.3.3.2" xref="S3.E6.m1.4.4.4.4.3.3.2.cmml">N</mi><mrow id="S3.E6.m1.4.4.4.4.3.3.3" xref="S3.E6.m1.4.4.4.4.3.3.3.cmml"><mi id="S3.E6.m1.4.4.4.4.3.3.3.2" xref="S3.E6.m1.4.4.4.4.3.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.4.3.3.3.1" xref="S3.E6.m1.4.4.4.4.3.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.4.4.4.4.3.3.3.3" xref="S3.E6.m1.4.4.4.4.3.3.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.4.3.3.3.1a" xref="S3.E6.m1.4.4.4.4.3.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.4.4.4.4.3.3.3.4" xref="S3.E6.m1.4.4.4.4.3.3.3.4.cmml">j</mi></mrow></msub></munderover><mrow id="S3.E6.m1.4.4.4.4.2" xref="S3.E6.m1.4.4.4.4.2.cmml"><mrow id="S3.E6.m1.4.4.4.4.2.4" xref="S3.E6.m1.4.4.4.4.2.4.cmml"><msub id="S3.E6.m1.4.4.4.4.2.4.2" xref="S3.E6.m1.4.4.4.4.2.4.2.cmml"><mover accent="true" id="S3.E6.m1.4.4.4.4.2.4.2.2" xref="S3.E6.m1.4.4.4.4.2.4.2.2.cmml"><mi id="S3.E6.m1.4.4.4.4.2.4.2.2.2" xref="S3.E6.m1.4.4.4.4.2.4.2.2.2.cmml">g</mi><mo id="S3.E6.m1.4.4.4.4.2.4.2.2.1" xref="S3.E6.m1.4.4.4.4.2.4.2.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.4.4.4.4.2.4.2.3" xref="S3.E6.m1.4.4.4.4.2.4.2.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.4.4.4.4.2.4.1" xref="S3.E6.m1.4.4.4.4.2.4.1.cmml">â‹…</mo><msub id="S3.E6.m1.4.4.4.4.2.4.3" xref="S3.E6.m1.4.4.4.4.2.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.4.4.4.4.2.4.3.2" xref="S3.E6.m1.4.4.4.4.2.4.3.2.cmml">â„’</mi><mrow id="S3.E6.m1.4.4.4.4.2.4.3.3" xref="S3.E6.m1.4.4.4.4.2.4.3.3.cmml"><mi id="S3.E6.m1.4.4.4.4.2.4.3.3.2" xref="S3.E6.m1.4.4.4.4.2.4.3.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.4.2.4.3.3.1" xref="S3.E6.m1.4.4.4.4.2.4.3.3.1.cmml">â€‹</mo><mn id="S3.E6.m1.4.4.4.4.2.4.3.3.3" xref="S3.E6.m1.4.4.4.4.2.4.3.3.3.cmml">1</mn></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.4.2.3" xref="S3.E6.m1.4.4.4.4.2.3.cmml">â€‹</mo><mrow id="S3.E6.m1.4.4.4.4.2.2.2" xref="S3.E6.m1.4.4.4.4.2.2.3.cmml"><mo stretchy="false" id="S3.E6.m1.4.4.4.4.2.2.2.3" xref="S3.E6.m1.4.4.4.4.2.2.3.cmml">(</mo><mrow id="S3.E6.m1.3.3.3.3.1.1.1.1" xref="S3.E6.m1.3.3.3.3.1.1.1.1.cmml"><mi id="S3.E6.m1.3.3.3.3.1.1.1.1.2" xref="S3.E6.m1.3.3.3.3.1.1.1.1.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.3.3.1.1.1.1.1" xref="S3.E6.m1.3.3.3.3.1.1.1.1.1.cmml">â€‹</mo><msub id="S3.E6.m1.3.3.3.3.1.1.1.1.3" xref="S3.E6.m1.3.3.3.3.1.1.1.1.3.cmml"><mi id="S3.E6.m1.3.3.3.3.1.1.1.1.3.2" xref="S3.E6.m1.3.3.3.3.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E6.m1.3.3.3.3.1.1.1.1.3.3" xref="S3.E6.m1.3.3.3.3.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.E6.m1.4.4.4.4.2.2.2.4" xref="S3.E6.m1.4.4.4.4.2.2.3.cmml">,</mo><msub id="S3.E6.m1.4.4.4.4.2.2.2.2" xref="S3.E6.m1.4.4.4.4.2.2.2.2.cmml"><mover accent="true" id="S3.E6.m1.4.4.4.4.2.2.2.2.2" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.cmml"><mrow id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.cmml"><mi id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.2" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.1" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.1.cmml">â€‹</mo><mi id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.3" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.3.cmml">x</mi></mrow><mo id="S3.E6.m1.4.4.4.4.2.2.2.2.2.1" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.4.4.4.4.2.2.2.2.3" xref="S3.E6.m1.4.4.4.4.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E6.m1.4.4.4.4.2.2.2.5" xref="S3.E6.m1.4.4.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.4b"><apply id="S3.E6.m1.4.4.cmml" xref="S3.E6.m1.4.4"><eq id="S3.E6.m1.4.4.5.cmml" xref="S3.E6.m1.4.4.5"></eq><apply id="S3.E6.m1.4.4.6.cmml" xref="S3.E6.m1.4.4.6"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.6.1.cmml" xref="S3.E6.m1.4.4.6">subscript</csymbol><apply id="S3.E6.m1.4.4.6.2.cmml" xref="S3.E6.m1.4.4.6"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.6.2.1.cmml" xref="S3.E6.m1.4.4.6">superscript</csymbol><ci id="S3.E6.m1.4.4.6.2.2.cmml" xref="S3.E6.m1.4.4.6.2.2">ğ¿</ci><apply id="S3.E6.m1.4.4.6.2.3.cmml" xref="S3.E6.m1.4.4.6.2.3"><minus id="S3.E6.m1.4.4.6.2.3.1.cmml" xref="S3.E6.m1.4.4.6.2.3.1"></minus><cn type="integer" id="S3.E6.m1.4.4.6.2.3.2.cmml" xref="S3.E6.m1.4.4.6.2.3.2">1</cn><ci id="S3.E6.m1.4.4.6.2.3.3.cmml" xref="S3.E6.m1.4.4.6.2.3.3">ğ‘š</ci></apply></apply><apply id="S3.E6.m1.4.4.6.3.cmml" xref="S3.E6.m1.4.4.6.3"><times id="S3.E6.m1.4.4.6.3.1.cmml" xref="S3.E6.m1.4.4.6.3.1"></times><ci id="S3.E6.m1.4.4.6.3.2.cmml" xref="S3.E6.m1.4.4.6.3.2">ğ‘Ÿ</ci><ci id="S3.E6.m1.4.4.6.3.3.cmml" xref="S3.E6.m1.4.4.6.3.3">ğ‘’</ci><ci id="S3.E6.m1.4.4.6.3.4.cmml" xref="S3.E6.m1.4.4.6.3.4">ğ‘”</ci></apply></apply><apply id="S3.E6.m1.4.4.4.cmml" xref="S3.E6.m1.4.4.4"><plus id="S3.E6.m1.4.4.4.5.cmml" xref="S3.E6.m1.4.4.4.5"></plus><apply id="S3.E6.m1.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2"><apply id="S3.E6.m1.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.3.1.cmml" xref="S3.E6.m1.2.2.2.2.3">superscript</csymbol><apply id="S3.E6.m1.2.2.2.2.3.2.cmml" xref="S3.E6.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.3.2.1.cmml" xref="S3.E6.m1.2.2.2.2.3">subscript</csymbol><sum id="S3.E6.m1.2.2.2.2.3.2.2.cmml" xref="S3.E6.m1.2.2.2.2.3.2.2"></sum><apply id="S3.E6.m1.2.2.2.2.3.2.3.cmml" xref="S3.E6.m1.2.2.2.2.3.2.3"><eq id="S3.E6.m1.2.2.2.2.3.2.3.1.cmml" xref="S3.E6.m1.2.2.2.2.3.2.3.1"></eq><ci id="S3.E6.m1.2.2.2.2.3.2.3.2.cmml" xref="S3.E6.m1.2.2.2.2.3.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E6.m1.2.2.2.2.3.2.3.3.cmml" xref="S3.E6.m1.2.2.2.2.3.2.3.3">1</cn></apply></apply><apply id="S3.E6.m1.2.2.2.2.3.3.cmml" xref="S3.E6.m1.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.3.3.1.cmml" xref="S3.E6.m1.2.2.2.2.3.3">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.3.3.2.cmml" xref="S3.E6.m1.2.2.2.2.3.3.2">ğ‘</ci><apply id="S3.E6.m1.2.2.2.2.3.3.3.cmml" xref="S3.E6.m1.2.2.2.2.3.3.3"><times id="S3.E6.m1.2.2.2.2.3.3.3.1.cmml" xref="S3.E6.m1.2.2.2.2.3.3.3.1"></times><ci id="S3.E6.m1.2.2.2.2.3.3.3.2.cmml" xref="S3.E6.m1.2.2.2.2.3.3.3.2">ğ‘œ</ci><ci id="S3.E6.m1.2.2.2.2.3.3.3.3.cmml" xref="S3.E6.m1.2.2.2.2.3.3.3.3">ğ‘</ci><ci id="S3.E6.m1.2.2.2.2.3.3.3.4.cmml" xref="S3.E6.m1.2.2.2.2.3.3.3.4">ğ‘—</ci></apply></apply></apply><apply id="S3.E6.m1.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2"><times id="S3.E6.m1.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.3"></times><apply id="S3.E6.m1.2.2.2.2.2.4.cmml" xref="S3.E6.m1.2.2.2.2.2.4"><ci id="S3.E6.m1.2.2.2.2.2.4.1.cmml" xref="S3.E6.m1.2.2.2.2.2.4.1">â‹…</ci><apply id="S3.E6.m1.2.2.2.2.2.4.2.cmml" xref="S3.E6.m1.2.2.2.2.2.4.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.2.4.2.1.cmml" xref="S3.E6.m1.2.2.2.2.2.4.2">subscript</csymbol><apply id="S3.E6.m1.2.2.2.2.2.4.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.4.2.2"><ci id="S3.E6.m1.2.2.2.2.2.4.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.2.4.2.2.1">^</ci><ci id="S3.E6.m1.2.2.2.2.2.4.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.4.2.2.2">ğ‘”</ci></apply><ci id="S3.E6.m1.2.2.2.2.2.4.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.4.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.2.2.2.2.2.4.3.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.2.4.3.1.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.2.4.3.2.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3.2">â„’</ci><apply id="S3.E6.m1.2.2.2.2.2.4.3.3.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3.3"><times id="S3.E6.m1.2.2.2.2.2.4.3.3.1.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3.3.1"></times><ci id="S3.E6.m1.2.2.2.2.2.4.3.3.2.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3.3.2">ğº</ci><ci id="S3.E6.m1.2.2.2.2.2.4.3.3.3.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3.3.3">ğ¼</ci><ci id="S3.E6.m1.2.2.2.2.2.4.3.3.4.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3.3.4">ğ‘œ</ci><ci id="S3.E6.m1.2.2.2.2.2.4.3.3.5.cmml" xref="S3.E6.m1.2.2.2.2.2.4.3.3.5">ğ‘ˆ</ci></apply></apply></apply><interval closure="open" id="S3.E6.m1.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2"><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1"><times id="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2">ğ‘</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply><apply id="S3.E6.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2">subscript</csymbol><apply id="S3.E6.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2"><ci id="S3.E6.m1.2.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.1">^</ci><apply id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2"><times id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.1"></times><ci id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.2">ğ‘</ci><ci id="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2.2.2.3">ğ‘¥</ci></apply></apply><ci id="S3.E6.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply></apply><apply id="S3.E6.m1.4.4.4.4.cmml" xref="S3.E6.m1.4.4.4.4"><apply id="S3.E6.m1.4.4.4.4.3.cmml" xref="S3.E6.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.4.3.1.cmml" xref="S3.E6.m1.4.4.4.4.3">superscript</csymbol><apply id="S3.E6.m1.4.4.4.4.3.2.cmml" xref="S3.E6.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.4.3.2.1.cmml" xref="S3.E6.m1.4.4.4.4.3">subscript</csymbol><sum id="S3.E6.m1.4.4.4.4.3.2.2.cmml" xref="S3.E6.m1.4.4.4.4.3.2.2"></sum><apply id="S3.E6.m1.4.4.4.4.3.2.3.cmml" xref="S3.E6.m1.4.4.4.4.3.2.3"><eq id="S3.E6.m1.4.4.4.4.3.2.3.1.cmml" xref="S3.E6.m1.4.4.4.4.3.2.3.1"></eq><ci id="S3.E6.m1.4.4.4.4.3.2.3.2.cmml" xref="S3.E6.m1.4.4.4.4.3.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E6.m1.4.4.4.4.3.2.3.3.cmml" xref="S3.E6.m1.4.4.4.4.3.2.3.3">1</cn></apply></apply><apply id="S3.E6.m1.4.4.4.4.3.3.cmml" xref="S3.E6.m1.4.4.4.4.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.4.3.3.1.cmml" xref="S3.E6.m1.4.4.4.4.3.3">subscript</csymbol><ci id="S3.E6.m1.4.4.4.4.3.3.2.cmml" xref="S3.E6.m1.4.4.4.4.3.3.2">ğ‘</ci><apply id="S3.E6.m1.4.4.4.4.3.3.3.cmml" xref="S3.E6.m1.4.4.4.4.3.3.3"><times id="S3.E6.m1.4.4.4.4.3.3.3.1.cmml" xref="S3.E6.m1.4.4.4.4.3.3.3.1"></times><ci id="S3.E6.m1.4.4.4.4.3.3.3.2.cmml" xref="S3.E6.m1.4.4.4.4.3.3.3.2">ğ‘œ</ci><ci id="S3.E6.m1.4.4.4.4.3.3.3.3.cmml" xref="S3.E6.m1.4.4.4.4.3.3.3.3">ğ‘</ci><ci id="S3.E6.m1.4.4.4.4.3.3.3.4.cmml" xref="S3.E6.m1.4.4.4.4.3.3.3.4">ğ‘—</ci></apply></apply></apply><apply id="S3.E6.m1.4.4.4.4.2.cmml" xref="S3.E6.m1.4.4.4.4.2"><times id="S3.E6.m1.4.4.4.4.2.3.cmml" xref="S3.E6.m1.4.4.4.4.2.3"></times><apply id="S3.E6.m1.4.4.4.4.2.4.cmml" xref="S3.E6.m1.4.4.4.4.2.4"><ci id="S3.E6.m1.4.4.4.4.2.4.1.cmml" xref="S3.E6.m1.4.4.4.4.2.4.1">â‹…</ci><apply id="S3.E6.m1.4.4.4.4.2.4.2.cmml" xref="S3.E6.m1.4.4.4.4.2.4.2"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.4.2.4.2.1.cmml" xref="S3.E6.m1.4.4.4.4.2.4.2">subscript</csymbol><apply id="S3.E6.m1.4.4.4.4.2.4.2.2.cmml" xref="S3.E6.m1.4.4.4.4.2.4.2.2"><ci id="S3.E6.m1.4.4.4.4.2.4.2.2.1.cmml" xref="S3.E6.m1.4.4.4.4.2.4.2.2.1">^</ci><ci id="S3.E6.m1.4.4.4.4.2.4.2.2.2.cmml" xref="S3.E6.m1.4.4.4.4.2.4.2.2.2">ğ‘”</ci></apply><ci id="S3.E6.m1.4.4.4.4.2.4.2.3.cmml" xref="S3.E6.m1.4.4.4.4.2.4.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.4.4.4.4.2.4.3.cmml" xref="S3.E6.m1.4.4.4.4.2.4.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.4.2.4.3.1.cmml" xref="S3.E6.m1.4.4.4.4.2.4.3">subscript</csymbol><ci id="S3.E6.m1.4.4.4.4.2.4.3.2.cmml" xref="S3.E6.m1.4.4.4.4.2.4.3.2">â„’</ci><apply id="S3.E6.m1.4.4.4.4.2.4.3.3.cmml" xref="S3.E6.m1.4.4.4.4.2.4.3.3"><times id="S3.E6.m1.4.4.4.4.2.4.3.3.1.cmml" xref="S3.E6.m1.4.4.4.4.2.4.3.3.1"></times><ci id="S3.E6.m1.4.4.4.4.2.4.3.3.2.cmml" xref="S3.E6.m1.4.4.4.4.2.4.3.3.2">ğ¿</ci><cn type="integer" id="S3.E6.m1.4.4.4.4.2.4.3.3.3.cmml" xref="S3.E6.m1.4.4.4.4.2.4.3.3.3">1</cn></apply></apply></apply><interval closure="open" id="S3.E6.m1.4.4.4.4.2.2.3.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2"><apply id="S3.E6.m1.3.3.3.3.1.1.1.1.cmml" xref="S3.E6.m1.3.3.3.3.1.1.1.1"><times id="S3.E6.m1.3.3.3.3.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.3.3.1.1.1.1.1"></times><ci id="S3.E6.m1.3.3.3.3.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.3.3.1.1.1.1.2">ğ‘</ci><apply id="S3.E6.m1.3.3.3.3.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.3.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.3.3.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.3.3.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E6.m1.3.3.3.3.1.1.1.1.3.3.cmml" xref="S3.E6.m1.3.3.3.3.1.1.1.1.3.3">ğ‘–</ci></apply></apply><apply id="S3.E6.m1.4.4.4.4.2.2.2.2.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.4.2.2.2.2.1.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2">subscript</csymbol><apply id="S3.E6.m1.4.4.4.4.2.2.2.2.2.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2"><ci id="S3.E6.m1.4.4.4.4.2.2.2.2.2.1.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.1">^</ci><apply id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2"><times id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.1.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.1"></times><ci id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.2">ğ‘</ci><ci id="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2.2.2.3">ğ‘¥</ci></apply></apply><ci id="S3.E6.m1.4.4.4.4.2.2.2.2.3.cmml" xref="S3.E6.m1.4.4.4.4.2.2.2.2.3">ğ‘–</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.4c">L^{1-m}_{reg}=\sum_{i=1}^{N_{obj}}\hat{g}_{i}\cdot\mathcal{L}_{GIoU}(bx_{i},\hat{bx}_{i})+\sum_{i=1}^{N_{obj}}\hat{g}_{i}\cdot\mathcal{L}_{L1}(bx_{i},\hat{bx}_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="L^{1-m}=L^{1-m}_{cls}+L^{1-m}_{reg}" display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><msup id="S3.E7.m1.1.1.2" xref="S3.E7.m1.1.1.2.cmml"><mi id="S3.E7.m1.1.1.2.2" xref="S3.E7.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.2.3" xref="S3.E7.m1.1.1.2.3.cmml"><mn id="S3.E7.m1.1.1.2.3.2" xref="S3.E7.m1.1.1.2.3.2.cmml">1</mn><mo id="S3.E7.m1.1.1.2.3.1" xref="S3.E7.m1.1.1.2.3.1.cmml">âˆ’</mo><mi id="S3.E7.m1.1.1.2.3.3" xref="S3.E7.m1.1.1.2.3.3.cmml">m</mi></mrow></msup><mo id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml">=</mo><mrow id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.3.cmml"><msubsup id="S3.E7.m1.1.1.3.2" xref="S3.E7.m1.1.1.3.2.cmml"><mi id="S3.E7.m1.1.1.3.2.2.2" xref="S3.E7.m1.1.1.3.2.2.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.3.2.3" xref="S3.E7.m1.1.1.3.2.3.cmml"><mi id="S3.E7.m1.1.1.3.2.3.2" xref="S3.E7.m1.1.1.3.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.2.3.1" xref="S3.E7.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.3.2.3.3" xref="S3.E7.m1.1.1.3.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.2.3.1a" xref="S3.E7.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.3.2.3.4" xref="S3.E7.m1.1.1.3.2.3.4.cmml">s</mi></mrow><mrow id="S3.E7.m1.1.1.3.2.2.3" xref="S3.E7.m1.1.1.3.2.2.3.cmml"><mn id="S3.E7.m1.1.1.3.2.2.3.2" xref="S3.E7.m1.1.1.3.2.2.3.2.cmml">1</mn><mo id="S3.E7.m1.1.1.3.2.2.3.1" xref="S3.E7.m1.1.1.3.2.2.3.1.cmml">âˆ’</mo><mi id="S3.E7.m1.1.1.3.2.2.3.3" xref="S3.E7.m1.1.1.3.2.2.3.3.cmml">m</mi></mrow></msubsup><mo id="S3.E7.m1.1.1.3.1" xref="S3.E7.m1.1.1.3.1.cmml">+</mo><msubsup id="S3.E7.m1.1.1.3.3" xref="S3.E7.m1.1.1.3.3.cmml"><mi id="S3.E7.m1.1.1.3.3.2.2" xref="S3.E7.m1.1.1.3.3.2.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.3.3.3" xref="S3.E7.m1.1.1.3.3.3.cmml"><mi id="S3.E7.m1.1.1.3.3.3.2" xref="S3.E7.m1.1.1.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.3.3.1" xref="S3.E7.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.3.3.3.3" xref="S3.E7.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.3.3.1a" xref="S3.E7.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.3.3.3.4" xref="S3.E7.m1.1.1.3.3.3.4.cmml">g</mi></mrow><mrow id="S3.E7.m1.1.1.3.3.2.3" xref="S3.E7.m1.1.1.3.3.2.3.cmml"><mn id="S3.E7.m1.1.1.3.3.2.3.2" xref="S3.E7.m1.1.1.3.3.2.3.2.cmml">1</mn><mo id="S3.E7.m1.1.1.3.3.2.3.1" xref="S3.E7.m1.1.1.3.3.2.3.1.cmml">âˆ’</mo><mi id="S3.E7.m1.1.1.3.3.2.3.3" xref="S3.E7.m1.1.1.3.3.2.3.3.cmml">m</mi></mrow></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"><eq id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"></eq><apply id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.2">superscript</csymbol><ci id="S3.E7.m1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.2.2">ğ¿</ci><apply id="S3.E7.m1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.2.3"><minus id="S3.E7.m1.1.1.2.3.1.cmml" xref="S3.E7.m1.1.1.2.3.1"></minus><cn type="integer" id="S3.E7.m1.1.1.2.3.2.cmml" xref="S3.E7.m1.1.1.2.3.2">1</cn><ci id="S3.E7.m1.1.1.2.3.3.cmml" xref="S3.E7.m1.1.1.2.3.3">ğ‘š</ci></apply></apply><apply id="S3.E7.m1.1.1.3.cmml" xref="S3.E7.m1.1.1.3"><plus id="S3.E7.m1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.3.1"></plus><apply id="S3.E7.m1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.3.2">subscript</csymbol><apply id="S3.E7.m1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.2.1.cmml" xref="S3.E7.m1.1.1.3.2">superscript</csymbol><ci id="S3.E7.m1.1.1.3.2.2.2.cmml" xref="S3.E7.m1.1.1.3.2.2.2">ğ¿</ci><apply id="S3.E7.m1.1.1.3.2.2.3.cmml" xref="S3.E7.m1.1.1.3.2.2.3"><minus id="S3.E7.m1.1.1.3.2.2.3.1.cmml" xref="S3.E7.m1.1.1.3.2.2.3.1"></minus><cn type="integer" id="S3.E7.m1.1.1.3.2.2.3.2.cmml" xref="S3.E7.m1.1.1.3.2.2.3.2">1</cn><ci id="S3.E7.m1.1.1.3.2.2.3.3.cmml" xref="S3.E7.m1.1.1.3.2.2.3.3">ğ‘š</ci></apply></apply><apply id="S3.E7.m1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.3.2.3"><times id="S3.E7.m1.1.1.3.2.3.1.cmml" xref="S3.E7.m1.1.1.3.2.3.1"></times><ci id="S3.E7.m1.1.1.3.2.3.2.cmml" xref="S3.E7.m1.1.1.3.2.3.2">ğ‘</ci><ci id="S3.E7.m1.1.1.3.2.3.3.cmml" xref="S3.E7.m1.1.1.3.2.3.3">ğ‘™</ci><ci id="S3.E7.m1.1.1.3.2.3.4.cmml" xref="S3.E7.m1.1.1.3.2.3.4">ğ‘ </ci></apply></apply><apply id="S3.E7.m1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3">subscript</csymbol><apply id="S3.E7.m1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.3.2.1.cmml" xref="S3.E7.m1.1.1.3.3">superscript</csymbol><ci id="S3.E7.m1.1.1.3.3.2.2.cmml" xref="S3.E7.m1.1.1.3.3.2.2">ğ¿</ci><apply id="S3.E7.m1.1.1.3.3.2.3.cmml" xref="S3.E7.m1.1.1.3.3.2.3"><minus id="S3.E7.m1.1.1.3.3.2.3.1.cmml" xref="S3.E7.m1.1.1.3.3.2.3.1"></minus><cn type="integer" id="S3.E7.m1.1.1.3.3.2.3.2.cmml" xref="S3.E7.m1.1.1.3.3.2.3.2">1</cn><ci id="S3.E7.m1.1.1.3.3.2.3.3.cmml" xref="S3.E7.m1.1.1.3.3.2.3.3">ğ‘š</ci></apply></apply><apply id="S3.E7.m1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3"><times id="S3.E7.m1.1.1.3.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3.3.1"></times><ci id="S3.E7.m1.1.1.3.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3.3.2">ğ‘Ÿ</ci><ci id="S3.E7.m1.1.1.3.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3.3">ğ‘’</ci><ci id="S3.E7.m1.1.1.3.3.3.4.cmml" xref="S3.E7.m1.1.1.3.3.3.4">ğ‘”</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">L^{1-m}=L^{1-m}_{cls}+L^{1-m}_{reg}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p5.2" class="ltx_p">where <math id="S3.SS4.p5.1.m1.1" class="ltx_Math" alttext="\hat{g}_{i}" display="inline"><semantics id="S3.SS4.p5.1.m1.1a"><msub id="S3.SS4.p5.1.m1.1.1" xref="S3.SS4.p5.1.m1.1.1.cmml"><mover accent="true" id="S3.SS4.p5.1.m1.1.1.2" xref="S3.SS4.p5.1.m1.1.1.2.cmml"><mi id="S3.SS4.p5.1.m1.1.1.2.2" xref="S3.SS4.p5.1.m1.1.1.2.2.cmml">g</mi><mo id="S3.SS4.p5.1.m1.1.1.2.1" xref="S3.SS4.p5.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS4.p5.1.m1.1.1.3" xref="S3.SS4.p5.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.1.m1.1b"><apply id="S3.SS4.p5.1.m1.1.1.cmml" xref="S3.SS4.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p5.1.m1.1.1.1.cmml" xref="S3.SS4.p5.1.m1.1.1">subscript</csymbol><apply id="S3.SS4.p5.1.m1.1.1.2.cmml" xref="S3.SS4.p5.1.m1.1.1.2"><ci id="S3.SS4.p5.1.m1.1.1.2.1.cmml" xref="S3.SS4.p5.1.m1.1.1.2.1">^</ci><ci id="S3.SS4.p5.1.m1.1.1.2.2.cmml" xref="S3.SS4.p5.1.m1.1.1.2.2">ğ‘”</ci></apply><ci id="S3.SS4.p5.1.m1.1.1.3.cmml" xref="S3.SS4.p5.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.1.m1.1c">\hat{g}_{i}</annotation></semantics></math> is the ground truth, <math id="S3.SS4.p5.2.m2.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS4.p5.2.m2.1a"><msub id="S3.SS4.p5.2.m2.1.1" xref="S3.SS4.p5.2.m2.1.1.cmml"><mi id="S3.SS4.p5.2.m2.1.1.2" xref="S3.SS4.p5.2.m2.1.1.2.cmml">p</mi><mi id="S3.SS4.p5.2.m2.1.1.3" xref="S3.SS4.p5.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.2.m2.1b"><apply id="S3.SS4.p5.2.m2.1.1.cmml" xref="S3.SS4.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p5.2.m2.1.1.1.cmml" xref="S3.SS4.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p5.2.m2.1.1.2.cmml" xref="S3.SS4.p5.2.m2.1.1.2">ğ‘</ci><ci id="S3.SS4.p5.2.m2.1.1.3.cmml" xref="S3.SS4.p5.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.2.m2.1c">p_{i}</annotation></semantics></math> is the actual prediction.
In the one-to-one matching branch, a traditional approach in object detection models, each detected object is directly aligned with a corresponding ground truth. This method is straightforward and effective in scenarios where objects are clearly separated and easily identifiable. It eliminates duplications generated in the one-to-many strategy, ensuring more accurate predictions. The total loss in the one-to-one matching strategy is as follows:</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.1" class="ltx_Math" alttext="L^{1-1}=L^{1-1}_{cls}+L^{1-1}_{reg}" display="block"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1" xref="S3.E8.m1.1.1.cmml"><msup id="S3.E8.m1.1.1.2" xref="S3.E8.m1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.2.2" xref="S3.E8.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E8.m1.1.1.2.3" xref="S3.E8.m1.1.1.2.3.cmml"><mn id="S3.E8.m1.1.1.2.3.2" xref="S3.E8.m1.1.1.2.3.2.cmml">1</mn><mo id="S3.E8.m1.1.1.2.3.1" xref="S3.E8.m1.1.1.2.3.1.cmml">âˆ’</mo><mn id="S3.E8.m1.1.1.2.3.3" xref="S3.E8.m1.1.1.2.3.3.cmml">1</mn></mrow></msup><mo id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.cmml">=</mo><mrow id="S3.E8.m1.1.1.3" xref="S3.E8.m1.1.1.3.cmml"><msubsup id="S3.E8.m1.1.1.3.2" xref="S3.E8.m1.1.1.3.2.cmml"><mi id="S3.E8.m1.1.1.3.2.2.2" xref="S3.E8.m1.1.1.3.2.2.2.cmml">L</mi><mrow id="S3.E8.m1.1.1.3.2.3" xref="S3.E8.m1.1.1.3.2.3.cmml"><mi id="S3.E8.m1.1.1.3.2.3.2" xref="S3.E8.m1.1.1.3.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.2.3.1" xref="S3.E8.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.3.2.3.3" xref="S3.E8.m1.1.1.3.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.2.3.1a" xref="S3.E8.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.3.2.3.4" xref="S3.E8.m1.1.1.3.2.3.4.cmml">s</mi></mrow><mrow id="S3.E8.m1.1.1.3.2.2.3" xref="S3.E8.m1.1.1.3.2.2.3.cmml"><mn id="S3.E8.m1.1.1.3.2.2.3.2" xref="S3.E8.m1.1.1.3.2.2.3.2.cmml">1</mn><mo id="S3.E8.m1.1.1.3.2.2.3.1" xref="S3.E8.m1.1.1.3.2.2.3.1.cmml">âˆ’</mo><mn id="S3.E8.m1.1.1.3.2.2.3.3" xref="S3.E8.m1.1.1.3.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S3.E8.m1.1.1.3.1" xref="S3.E8.m1.1.1.3.1.cmml">+</mo><msubsup id="S3.E8.m1.1.1.3.3" xref="S3.E8.m1.1.1.3.3.cmml"><mi id="S3.E8.m1.1.1.3.3.2.2" xref="S3.E8.m1.1.1.3.3.2.2.cmml">L</mi><mrow id="S3.E8.m1.1.1.3.3.3" xref="S3.E8.m1.1.1.3.3.3.cmml"><mi id="S3.E8.m1.1.1.3.3.3.2" xref="S3.E8.m1.1.1.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.3.1" xref="S3.E8.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.3.3.3.3" xref="S3.E8.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.3.1a" xref="S3.E8.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.3.3.3.4" xref="S3.E8.m1.1.1.3.3.3.4.cmml">g</mi></mrow><mrow id="S3.E8.m1.1.1.3.3.2.3" xref="S3.E8.m1.1.1.3.3.2.3.cmml"><mn id="S3.E8.m1.1.1.3.3.2.3.2" xref="S3.E8.m1.1.1.3.3.2.3.2.cmml">1</mn><mo id="S3.E8.m1.1.1.3.3.2.3.1" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">âˆ’</mo><mn id="S3.E8.m1.1.1.3.3.2.3.3" xref="S3.E8.m1.1.1.3.3.2.3.3.cmml">1</mn></mrow></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.1.1"><eq id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"></eq><apply id="S3.E8.m1.1.1.2.cmml" xref="S3.E8.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.2">superscript</csymbol><ci id="S3.E8.m1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.2.2">ğ¿</ci><apply id="S3.E8.m1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.2.3"><minus id="S3.E8.m1.1.1.2.3.1.cmml" xref="S3.E8.m1.1.1.2.3.1"></minus><cn type="integer" id="S3.E8.m1.1.1.2.3.2.cmml" xref="S3.E8.m1.1.1.2.3.2">1</cn><cn type="integer" id="S3.E8.m1.1.1.2.3.3.cmml" xref="S3.E8.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E8.m1.1.1.3.cmml" xref="S3.E8.m1.1.1.3"><plus id="S3.E8.m1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.3.1"></plus><apply id="S3.E8.m1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.2.1.cmml" xref="S3.E8.m1.1.1.3.2">subscript</csymbol><apply id="S3.E8.m1.1.1.3.2.2.cmml" xref="S3.E8.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.2.2.1.cmml" xref="S3.E8.m1.1.1.3.2">superscript</csymbol><ci id="S3.E8.m1.1.1.3.2.2.2.cmml" xref="S3.E8.m1.1.1.3.2.2.2">ğ¿</ci><apply id="S3.E8.m1.1.1.3.2.2.3.cmml" xref="S3.E8.m1.1.1.3.2.2.3"><minus id="S3.E8.m1.1.1.3.2.2.3.1.cmml" xref="S3.E8.m1.1.1.3.2.2.3.1"></minus><cn type="integer" id="S3.E8.m1.1.1.3.2.2.3.2.cmml" xref="S3.E8.m1.1.1.3.2.2.3.2">1</cn><cn type="integer" id="S3.E8.m1.1.1.3.2.2.3.3.cmml" xref="S3.E8.m1.1.1.3.2.2.3.3">1</cn></apply></apply><apply id="S3.E8.m1.1.1.3.2.3.cmml" xref="S3.E8.m1.1.1.3.2.3"><times id="S3.E8.m1.1.1.3.2.3.1.cmml" xref="S3.E8.m1.1.1.3.2.3.1"></times><ci id="S3.E8.m1.1.1.3.2.3.2.cmml" xref="S3.E8.m1.1.1.3.2.3.2">ğ‘</ci><ci id="S3.E8.m1.1.1.3.2.3.3.cmml" xref="S3.E8.m1.1.1.3.2.3.3">ğ‘™</ci><ci id="S3.E8.m1.1.1.3.2.3.4.cmml" xref="S3.E8.m1.1.1.3.2.3.4">ğ‘ </ci></apply></apply><apply id="S3.E8.m1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.3.1.cmml" xref="S3.E8.m1.1.1.3.3">subscript</csymbol><apply id="S3.E8.m1.1.1.3.3.2.cmml" xref="S3.E8.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.3.2.1.cmml" xref="S3.E8.m1.1.1.3.3">superscript</csymbol><ci id="S3.E8.m1.1.1.3.3.2.2.cmml" xref="S3.E8.m1.1.1.3.3.2.2">ğ¿</ci><apply id="S3.E8.m1.1.1.3.3.2.3.cmml" xref="S3.E8.m1.1.1.3.3.2.3"><minus id="S3.E8.m1.1.1.3.3.2.3.1.cmml" xref="S3.E8.m1.1.1.3.3.2.3.1"></minus><cn type="integer" id="S3.E8.m1.1.1.3.3.2.3.2.cmml" xref="S3.E8.m1.1.1.3.3.2.3.2">1</cn><cn type="integer" id="S3.E8.m1.1.1.3.3.2.3.3.cmml" xref="S3.E8.m1.1.1.3.3.2.3.3">1</cn></apply></apply><apply id="S3.E8.m1.1.1.3.3.3.cmml" xref="S3.E8.m1.1.1.3.3.3"><times id="S3.E8.m1.1.1.3.3.3.1.cmml" xref="S3.E8.m1.1.1.3.3.3.1"></times><ci id="S3.E8.m1.1.1.3.3.3.2.cmml" xref="S3.E8.m1.1.1.3.3.3.2">ğ‘Ÿ</ci><ci id="S3.E8.m1.1.1.3.3.3.3.cmml" xref="S3.E8.m1.1.1.3.3.3.3">ğ‘’</ci><ci id="S3.E8.m1.1.1.3.3.3.4.cmml" xref="S3.E8.m1.1.1.3.3.3.4">ğ‘”</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">L^{1-1}=L^{1-1}_{cls}+L^{1-1}_{reg}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p5.3" class="ltx_p">This hybrid approach retains the benefits of the traditional method, like eliminating the need for Non-Maximum Suppression (NMS), and does not add any extra computational cost. The combination of these two methods in a single model allows for more accurate and efficient object detection in a wide range of scenarios, significantly improving the performance of document analysis tasks.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_bold">Datasets and Evaluation Criteria.</span>

Our study employs three benchmark datasets to evaluate the efficacy of the proposed method: PubLayNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> PubTablesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> and DocLayNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
We adopt the mean Average Precision (mAP) metric in line with COCO-styleÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> standards to evaluate our approach. We compute precision across a spectrum of Intersection over Union (IoU) thresholds, from 0.50 to 0.95, increasing in 0.05 steps. This IoU range is essential for evaluating our modelâ€™s accuracy in category-specific tasks. Our mAP calculation, averaged across these IoU levels, follows the established Microsoft COCO benchmark, facilitating a standardized comparison with other models. We further refine our assessment by calculating Average Precision (AP) at specific IoU thresholds of 0.50 and 0.75, offering a focused analysis of the modelâ€™s performance at these recognized benchmarks. It clearly explains our modelâ€™s proficiency in accurately classifying various categories.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Implementation Details.</span>

Our network is trained on RTXA600 GPUs, utilizing a ResNet-50 network as the backbone, which is pre-trained on ImageNet. We employ the AdamW algorithm for optimization, with a batch size of 16. The training duration is set to 12 epochs for both PubLayNet and PubTables datasets, and extended to 24 epochs for the DocLayNet dataset. We implement a learning rate reduction strategy, decreasing it by a factor of 10 later in the training process. Our approach includes a multi-scale training technique, where images are resized to various lengths without exceeding a maximum size limit. For the testing phase, we resize images to have a shorter side of 640, optimizing image handling during model evaluation.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Evaluation on the DocLayNet Benchmark.<span id="S4.T1.4.2.1" class="ltx_text ltx_font_medium"> A comparative analysis of outcomes on the DocLayNet Test Dataset. Here, Mask represents Mask R-CNN and Faster indicates Faster R-CNN.
In this comparison, the performances of Mask R-CNN, Faster R-CNN, and YOLOv5 are referenced fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, and the results for the DINO model are derived fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. The best results are highlighted in bold.</span></span></figcaption>
<table id="S4.T1.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.5.1.1" class="ltx_tr">
<th id="S4.T1.5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T1.5.1.1.1.1" class="ltx_text ltx_font_bold">Classes</span></th>
<th id="S4.T1.5.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.5.1.1.2.1" class="ltx_text ltx_font_bold">Mask</span></th>
<th id="S4.T1.5.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.5.1.1.3.1" class="ltx_text ltx_font_bold">Faster</span></th>
<th id="S4.T1.5.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.5.1.1.4.1" class="ltx_text ltx_font_bold">YOLOv5</span></th>
<th id="S4.T1.5.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.5.1.1.5.1" class="ltx_text ltx_font_bold">DINO</span></th>
<th id="S4.T1.5.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T1.5.1.1.6.1" class="ltx_text ltx_font_bold">Zhong et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</th>
<th id="S4.T1.5.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.5.1.1.7.1" class="ltx_text ltx_font_bold">Ours</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.5.2.1" class="ltx_tr">
<th id="S4.T1.5.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Caption</th>
<td id="S4.T1.5.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.5</td>
<td id="S4.T1.5.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.1</td>
<td id="S4.T1.5.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.7</td>
<td id="S4.T1.5.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.5</td>
<td id="S4.T1.5.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.2</td>
<td id="S4.T1.5.2.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.2.1.7.1" class="ltx_text ltx_font_bold">85.6</span></td>
</tr>
<tr id="S4.T1.5.3.2" class="ltx_tr">
<th id="S4.T1.5.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Footnote</th>
<td id="S4.T1.5.3.2.2" class="ltx_td ltx_align_center ltx_border_r">71.8</td>
<td id="S4.T1.5.3.2.3" class="ltx_td ltx_align_center ltx_border_r">73.7</td>
<td id="S4.T1.5.3.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.3.2.4.1" class="ltx_text ltx_font_bold">77.2</span></td>
<td id="S4.T1.5.3.2.5" class="ltx_td ltx_align_center ltx_border_r">69.2</td>
<td id="S4.T1.5.3.2.6" class="ltx_td ltx_align_center ltx_border_r">69.7</td>
<td id="S4.T1.5.3.2.7" class="ltx_td ltx_align_center">70.0</td>
</tr>
<tr id="S4.T1.5.4.3" class="ltx_tr">
<th id="S4.T1.5.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Formula</th>
<td id="S4.T1.5.4.3.2" class="ltx_td ltx_align_center ltx_border_r">63.4</td>
<td id="S4.T1.5.4.3.3" class="ltx_td ltx_align_center ltx_border_r">63.5</td>
<td id="S4.T1.5.4.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.4.3.4.1" class="ltx_text ltx_font_bold">66.2</span></td>
<td id="S4.T1.5.4.3.5" class="ltx_td ltx_align_center ltx_border_r">63.8</td>
<td id="S4.T1.5.4.3.6" class="ltx_td ltx_align_center ltx_border_r">63.4</td>
<td id="S4.T1.5.4.3.7" class="ltx_td ltx_align_center">64.7</td>
</tr>
<tr id="S4.T1.5.5.4" class="ltx_tr">
<th id="S4.T1.5.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">List-item</th>
<td id="S4.T1.5.5.4.2" class="ltx_td ltx_align_center ltx_border_r">80.8</td>
<td id="S4.T1.5.5.4.3" class="ltx_td ltx_align_center ltx_border_r">81.0</td>
<td id="S4.T1.5.5.4.4" class="ltx_td ltx_align_center ltx_border_r">86.2</td>
<td id="S4.T1.5.5.4.5" class="ltx_td ltx_align_center ltx_border_r">80.9</td>
<td id="S4.T1.5.5.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.5.4.6.1" class="ltx_text ltx_font_bold">88.6</span></td>
<td id="S4.T1.5.5.4.7" class="ltx_td ltx_align_center">83.5</td>
</tr>
<tr id="S4.T1.5.6.5" class="ltx_tr">
<th id="S4.T1.5.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Page-footer</th>
<td id="S4.T1.5.6.5.2" class="ltx_td ltx_align_center ltx_border_r">59.3</td>
<td id="S4.T1.5.6.5.3" class="ltx_td ltx_align_center ltx_border_r">58.9</td>
<td id="S4.T1.5.6.5.4" class="ltx_td ltx_align_center ltx_border_r">61.1</td>
<td id="S4.T1.5.6.5.5" class="ltx_td ltx_align_center ltx_border_r">54.2</td>
<td id="S4.T1.5.6.5.6" class="ltx_td ltx_align_center ltx_border_r">90.0</td>
<td id="S4.T1.5.6.5.7" class="ltx_td ltx_align_center"><span id="S4.T1.5.6.5.7.1" class="ltx_text ltx_font_bold">91.3</span></td>
</tr>
<tr id="S4.T1.5.7.6" class="ltx_tr">
<th id="S4.T1.5.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Page-header</th>
<td id="S4.T1.5.7.6.2" class="ltx_td ltx_align_center ltx_border_r">70.0</td>
<td id="S4.T1.5.7.6.3" class="ltx_td ltx_align_center ltx_border_r">72.0</td>
<td id="S4.T1.5.7.6.4" class="ltx_td ltx_align_center ltx_border_r">67.9</td>
<td id="S4.T1.5.7.6.5" class="ltx_td ltx_align_center ltx_border_r">63.7</td>
<td id="S4.T1.5.7.6.6" class="ltx_td ltx_align_center ltx_border_r">76.3</td>
<td id="S4.T1.5.7.6.7" class="ltx_td ltx_align_center"><span id="S4.T1.5.7.6.7.1" class="ltx_text ltx_font_bold">77.8</span></td>
</tr>
<tr id="S4.T1.5.8.7" class="ltx_tr">
<th id="S4.T1.5.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Picture</th>
<td id="S4.T1.5.8.7.2" class="ltx_td ltx_align_center ltx_border_r">72.7</td>
<td id="S4.T1.5.8.7.3" class="ltx_td ltx_align_center ltx_border_r">72.0</td>
<td id="S4.T1.5.8.7.4" class="ltx_td ltx_align_center ltx_border_r">77.1</td>
<td id="S4.T1.5.8.7.5" class="ltx_td ltx_align_center ltx_border_r">84.1</td>
<td id="S4.T1.5.8.7.6" class="ltx_td ltx_align_center ltx_border_r">81.6</td>
<td id="S4.T1.5.8.7.7" class="ltx_td ltx_align_center"><span id="S4.T1.5.8.7.7.1" class="ltx_text ltx_font_bold">84.7</span></td>
</tr>
<tr id="S4.T1.5.9.8" class="ltx_tr">
<th id="S4.T1.5.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Section-header</th>
<td id="S4.T1.5.9.8.2" class="ltx_td ltx_align_center ltx_border_r">69.3</td>
<td id="S4.T1.5.9.8.3" class="ltx_td ltx_align_center ltx_border_r">68.4</td>
<td id="S4.T1.5.9.8.4" class="ltx_td ltx_align_center ltx_border_r">74.6</td>
<td id="S4.T1.5.9.8.5" class="ltx_td ltx_align_center ltx_border_r">64.3</td>
<td id="S4.T1.5.9.8.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.9.8.6.1" class="ltx_text ltx_font_bold">83.2</span></td>
<td id="S4.T1.5.9.8.7" class="ltx_td ltx_align_center">82.9</td>
</tr>
<tr id="S4.T1.5.10.9" class="ltx_tr">
<th id="S4.T1.5.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Table</th>
<td id="S4.T1.5.10.9.2" class="ltx_td ltx_align_center ltx_border_r">82.9</td>
<td id="S4.T1.5.10.9.3" class="ltx_td ltx_align_center ltx_border_r">82.2</td>
<td id="S4.T1.5.10.9.4" class="ltx_td ltx_align_center ltx_border_r">86.3</td>
<td id="S4.T1.5.10.9.5" class="ltx_td ltx_align_center ltx_border_r">85.7</td>
<td id="S4.T1.5.10.9.6" class="ltx_td ltx_align_center ltx_border_r">84.8</td>
<td id="S4.T1.5.10.9.7" class="ltx_td ltx_align_center"><span id="S4.T1.5.10.9.7.1" class="ltx_text ltx_font_bold">86.1</span></td>
</tr>
<tr id="S4.T1.5.11.10" class="ltx_tr">
<th id="S4.T1.5.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Text</th>
<td id="S4.T1.5.11.10.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.5.11.10.2.1" class="ltx_text ltx_font_bold">85.8</span></td>
<td id="S4.T1.5.11.10.3" class="ltx_td ltx_align_center ltx_border_r">85.4</td>
<td id="S4.T1.5.11.10.4" class="ltx_td ltx_align_center ltx_border_r">88.1</td>
<td id="S4.T1.5.11.10.5" class="ltx_td ltx_align_center ltx_border_r">83.3</td>
<td id="S4.T1.5.11.10.6" class="ltx_td ltx_align_center ltx_border_r">84.8</td>
<td id="S4.T1.5.11.10.7" class="ltx_td ltx_align_center">85.4</td>
</tr>
<tr id="S4.T1.5.12.11" class="ltx_tr">
<th id="S4.T1.5.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Title</th>
<td id="S4.T1.5.12.11.2" class="ltx_td ltx_align_center ltx_border_r">80.4</td>
<td id="S4.T1.5.12.11.3" class="ltx_td ltx_align_center ltx_border_r">79.9</td>
<td id="S4.T1.5.12.11.4" class="ltx_td ltx_align_center ltx_border_r">82.7</td>
<td id="S4.T1.5.12.11.5" class="ltx_td ltx_align_center ltx_border_r">82.8</td>
<td id="S4.T1.5.12.11.6" class="ltx_td ltx_align_center ltx_border_r">84.9</td>
<td id="S4.T1.5.12.11.7" class="ltx_td ltx_align_center"><span id="S4.T1.5.12.11.7.1" class="ltx_text ltx_font_bold">86.3</span></td>
</tr>
<tr id="S4.T1.5.13.12" class="ltx_tr">
<th id="S4.T1.5.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.5.13.12.1.1" class="ltx_text ltx_font_bold">All</span></th>
<td id="S4.T1.5.13.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">73.5</td>
<td id="S4.T1.5.13.12.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">73.4</td>
<td id="S4.T1.5.13.12.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">76.8</td>
<td id="S4.T1.5.13.12.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">74.3</td>
<td id="S4.T1.5.13.12.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">81.0</td>
<td id="S4.T1.5.13.12.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.5.13.12.7.1" class="ltx_text ltx_font_bold">81.6</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results and Discussion</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>DocLayNet</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">TableÂ <a href="#S4.T1" title="Table 1 â€£ 4 Experimental Setup â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the performance of our approach compared to other approaches on the DocLayNet dataset, with results measured in mean Average Precision (mAP) for different document elements. Our method outperforms previous networks like Mask R-CNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, Faster R-CNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, YOLOv5Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, DINO, and the document analysis approach of Zhong et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, particularly in recognizing â€™Caption,â€™ â€™Page-footer,â€™ â€™Page-header,â€™ and â€™Title,â€™ achieving the highest overall mAP at 81.6%. This comprehensive evaluation across various classes highlights the effectiveness of our approach in accurately detecting and classifying elements in a wide array of document layouts.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2404.17888/assets/images/dino-results-final.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="515" height="543" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S5.F3.3.2" class="ltx_text" style="font-size:90%;">Visual analysis of our approach on the DocLayNet dataset. Here, blue color represents ground truth, red denotes prediction by our approach. It illustrates the modelâ€™s proficiency in identifying small layout elements, specifically highlighting its accuracy in detecting page titles, headers, and footers.</span></figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Fig.Â <a href="#S5.F3" title="Figure 3 â€£ 5.1 DocLayNet â€£ 5 Results and Discussion â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the visual results of our document layout analysis approach on the DocLayNet dataset. It displays document page with our modelâ€™s predictions compared to the actual ground truth (GT). In these visual examples, ground truth annotations are outlined in blue, and our modelâ€™s predictions are in red. This comparison aims to showcase our modelâ€™s precision in identifying small layout elements, such as page titles, headers, and footers. Using contrasting colors demonstrates the accuracy of our approach in detecting and classifying the intricate details of document layouts.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>PubLayNet</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We also evaluate and compare our approach with previous document analysis approaches on the PubLayNet dataset. The results of these comparisons are detailed in TableÂ <a href="#S5.T2" title="Table 2 â€£ 5.2 PubLayNet â€£ 5 Results and Discussion â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Evaluation on the PubLayNet Benchmark.<span id="S5.T2.4.2.1" class="ltx_text ltx_font_medium"> A comparative analysis of results on the PubLayNet Validation Set. The results highlight the effectiveness of our approach. The best results are highlighted in bold.</span></span></figcaption>
<table id="S5.T2.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.5.1.1" class="ltx_tr">
<th id="S5.T2.5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T2.5.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S5.T2.5.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.5.1.1.2.1" class="ltx_text ltx_font_bold">Text</span></th>
<th id="S5.T2.5.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.5.1.1.3.1" class="ltx_text ltx_font_bold">Title</span></th>
<th id="S5.T2.5.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.5.1.1.4.1" class="ltx_text ltx_font_bold">List</span></th>
<th id="S5.T2.5.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.5.1.1.5.1" class="ltx_text ltx_font_bold">Table</span></th>
<th id="S5.T2.5.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.5.1.1.6.1" class="ltx_text ltx_font_bold">Figure</span></th>
<th id="S5.T2.5.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.5.1.1.7.1" class="ltx_text ltx_font_bold">mAP</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.5.2.1" class="ltx_tr">
<th id="S5.T2.5.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Faster R-CNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</th>
<td id="S5.T2.5.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.0</td>
<td id="S5.T2.5.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">82.6</td>
<td id="S5.T2.5.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.3</td>
<td id="S5.T2.5.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.4</td>
<td id="S5.T2.5.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.7</td>
<td id="S5.T2.5.2.1.7" class="ltx_td ltx_align_center ltx_border_t">90.2</td>
</tr>
<tr id="S5.T2.5.3.2" class="ltx_tr">
<th id="S5.T2.5.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mask R-CNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</th>
<td id="S5.T2.5.3.2.2" class="ltx_td ltx_align_center ltx_border_r">91.6</td>
<td id="S5.T2.5.3.2.3" class="ltx_td ltx_align_center ltx_border_r">84.0</td>
<td id="S5.T2.5.3.2.4" class="ltx_td ltx_align_center ltx_border_r">88.6</td>
<td id="S5.T2.5.3.2.5" class="ltx_td ltx_align_center ltx_border_r">96.0</td>
<td id="S5.T2.5.3.2.6" class="ltx_td ltx_align_center ltx_border_r">94.9</td>
<td id="S5.T2.5.3.2.7" class="ltx_td ltx_align_center">91.0</td>
</tr>
<tr id="S5.T2.5.4.3" class="ltx_tr">
<th id="S5.T2.5.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Naik et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</th>
<td id="S5.T2.5.4.3.2" class="ltx_td ltx_align_center ltx_border_r">94.3</td>
<td id="S5.T2.5.4.3.3" class="ltx_td ltx_align_center ltx_border_r">88.7</td>
<td id="S5.T2.5.4.3.4" class="ltx_td ltx_align_center ltx_border_r">94.3</td>
<td id="S5.T2.5.4.3.5" class="ltx_td ltx_align_center ltx_border_r">97.6</td>
<td id="S5.T2.5.4.3.6" class="ltx_td ltx_align_center ltx_border_r">96.1</td>
<td id="S5.T2.5.4.3.7" class="ltx_td ltx_align_center">94.2</td>
</tr>
<tr id="S5.T2.5.5.4" class="ltx_tr">
<th id="S5.T2.5.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Minouei et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>
</th>
<td id="S5.T2.5.5.4.2" class="ltx_td ltx_align_center ltx_border_r">94.4</td>
<td id="S5.T2.5.5.4.3" class="ltx_td ltx_align_center ltx_border_r">90.8</td>
<td id="S5.T2.5.5.4.4" class="ltx_td ltx_align_center ltx_border_r">94.0</td>
<td id="S5.T2.5.5.4.5" class="ltx_td ltx_align_center ltx_border_r">97.4</td>
<td id="S5.T2.5.5.4.6" class="ltx_td ltx_align_center ltx_border_r">96.6</td>
<td id="S5.T2.5.5.4.7" class="ltx_td ltx_align_center">94.6</td>
</tr>
<tr id="S5.T2.5.6.5" class="ltx_tr">
<th id="S5.T2.5.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DiT-LÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>
</th>
<td id="S5.T2.5.6.5.2" class="ltx_td ltx_align_center ltx_border_r">94.4</td>
<td id="S5.T2.5.6.5.3" class="ltx_td ltx_align_center ltx_border_r">89.3</td>
<td id="S5.T2.5.6.5.4" class="ltx_td ltx_align_center ltx_border_r">96.0</td>
<td id="S5.T2.5.6.5.5" class="ltx_td ltx_align_center ltx_border_r">97.8</td>
<td id="S5.T2.5.6.5.6" class="ltx_td ltx_align_center ltx_border_r">97.2</td>
<td id="S5.T2.5.6.5.7" class="ltx_td ltx_align_center">94.9</td>
</tr>
<tr id="S5.T2.5.7.6" class="ltx_tr">
<th id="S5.T2.5.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SRRVÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>
</th>
<td id="S5.T2.5.7.6.2" class="ltx_td ltx_align_center ltx_border_r">95.8</td>
<td id="S5.T2.5.7.6.3" class="ltx_td ltx_align_center ltx_border_r">90.1</td>
<td id="S5.T2.5.7.6.4" class="ltx_td ltx_align_center ltx_border_r">95.0</td>
<td id="S5.T2.5.7.6.5" class="ltx_td ltx_align_center ltx_border_r">97.6</td>
<td id="S5.T2.5.7.6.6" class="ltx_td ltx_align_center ltx_border_r">96.7</td>
<td id="S5.T2.5.7.6.7" class="ltx_td ltx_align_center">95.0</td>
</tr>
<tr id="S5.T2.5.8.7" class="ltx_tr">
<th id="S5.T2.5.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DINOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</th>
<td id="S5.T2.5.8.7.2" class="ltx_td ltx_align_center ltx_border_r">94.9</td>
<td id="S5.T2.5.8.7.3" class="ltx_td ltx_align_center ltx_border_r">91.4</td>
<td id="S5.T2.5.8.7.4" class="ltx_td ltx_align_center ltx_border_r">96.0</td>
<td id="S5.T2.5.8.7.5" class="ltx_td ltx_align_center ltx_border_r">98.0</td>
<td id="S5.T2.5.8.7.6" class="ltx_td ltx_align_center ltx_border_r">97.3</td>
<td id="S5.T2.5.8.7.7" class="ltx_td ltx_align_center">95.5</td>
</tr>
<tr id="S5.T2.5.9.8" class="ltx_tr">
<th id="S5.T2.5.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TRDLUÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</th>
<td id="S5.T2.5.9.8.2" class="ltx_td ltx_align_center ltx_border_r">95.8</td>
<td id="S5.T2.5.9.8.3" class="ltx_td ltx_align_center ltx_border_r">92.1</td>
<td id="S5.T2.5.9.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.5.9.8.4.1" class="ltx_text ltx_font_bold">97.6</span></td>
<td id="S5.T2.5.9.8.5" class="ltx_td ltx_align_center ltx_border_r">97.6</td>
<td id="S5.T2.5.9.8.6" class="ltx_td ltx_align_center ltx_border_r">96.6</td>
<td id="S5.T2.5.9.8.7" class="ltx_td ltx_align_center">96.0</td>
</tr>
<tr id="S5.T2.5.10.9" class="ltx_tr">
<th id="S5.T2.5.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">UDocÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</th>
<td id="S5.T2.5.10.9.2" class="ltx_td ltx_align_center ltx_border_r">93.9</td>
<td id="S5.T2.5.10.9.3" class="ltx_td ltx_align_center ltx_border_r">88.5</td>
<td id="S5.T2.5.10.9.4" class="ltx_td ltx_align_center ltx_border_r">93.7</td>
<td id="S5.T2.5.10.9.5" class="ltx_td ltx_align_center ltx_border_r">97.3</td>
<td id="S5.T2.5.10.9.6" class="ltx_td ltx_align_center ltx_border_r">96.4</td>
<td id="S5.T2.5.10.9.7" class="ltx_td ltx_align_center">93.9</td>
</tr>
<tr id="S5.T2.5.11.10" class="ltx_tr">
<th id="S5.T2.5.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">LayoutLMv3Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>
</th>
<td id="S5.T2.5.11.10.2" class="ltx_td ltx_align_center ltx_border_r">94.5</td>
<td id="S5.T2.5.11.10.3" class="ltx_td ltx_align_center ltx_border_r">90.6</td>
<td id="S5.T2.5.11.10.4" class="ltx_td ltx_align_center ltx_border_r">95.5</td>
<td id="S5.T2.5.11.10.5" class="ltx_td ltx_align_center ltx_border_r">97.9</td>
<td id="S5.T2.5.11.10.6" class="ltx_td ltx_align_center ltx_border_r">97.0</td>
<td id="S5.T2.5.11.10.7" class="ltx_td ltx_align_center">95.1</td>
</tr>
<tr id="S5.T2.5.12.11" class="ltx_tr">
<th id="S5.T2.5.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VSRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>
</th>
<td id="S5.T2.5.12.11.2" class="ltx_td ltx_align_center ltx_border_r">96.7</td>
<td id="S5.T2.5.12.11.3" class="ltx_td ltx_align_center ltx_border_r">93.1</td>
<td id="S5.T2.5.12.11.4" class="ltx_td ltx_align_center ltx_border_r">94.7</td>
<td id="S5.T2.5.12.11.5" class="ltx_td ltx_align_center ltx_border_r">97.4</td>
<td id="S5.T2.5.12.11.6" class="ltx_td ltx_align_center ltx_border_r">96.4</td>
<td id="S5.T2.5.12.11.7" class="ltx_td ltx_align_center">95.7</td>
</tr>
<tr id="S5.T2.5.13.12" class="ltx_tr">
<th id="S5.T2.5.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Zhong et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</th>
<td id="S5.T2.5.13.12.2" class="ltx_td ltx_align_center ltx_border_r">97.4</td>
<td id="S5.T2.5.13.12.3" class="ltx_td ltx_align_center ltx_border_r">93.5</td>
<td id="S5.T2.5.13.12.4" class="ltx_td ltx_align_center ltx_border_r">96.4</td>
<td id="S5.T2.5.13.12.5" class="ltx_td ltx_align_center ltx_border_r">98.2</td>
<td id="S5.T2.5.13.12.6" class="ltx_td ltx_align_center ltx_border_r">97.2</td>
<td id="S5.T2.5.13.12.7" class="ltx_td ltx_align_center">96.5</td>
</tr>
<tr id="S5.T2.5.14.13" class="ltx_tr">
<th id="S5.T2.5.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">Our</th>
<td id="S5.T2.5.14.13.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T2.5.14.13.2.1" class="ltx_text ltx_font_bold">98.0</span></td>
<td id="S5.T2.5.14.13.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T2.5.14.13.3.1" class="ltx_text ltx_font_bold">94.2</span></td>
<td id="S5.T2.5.14.13.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">97.3</td>
<td id="S5.T2.5.14.13.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T2.5.14.13.5.1" class="ltx_text ltx_font_bold">98.6</span></td>
<td id="S5.T2.5.14.13.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T2.5.14.13.6.1" class="ltx_text ltx_font_bold">98.5</span></td>
<td id="S5.T2.5.14.13.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S5.T2.5.14.13.7.1" class="ltx_text ltx_font_bold">97.3</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The results indicate that our approach significantly outperforms previous methods, demonstrating its superior performance in document analysis.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>PubTables</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We also evaluate our approach and compare it with previous table detection approaches on PubTables dataset. The results of these comparisons are detailed in TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.3 PubTables â€£ 5 Results and Discussion â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
The results clearly demonstrate that our approach outperforms previous table detection approaches, highlighting its effectiveness and efficiency in accurately identifying and classifying table elements within complex documents.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S5.T3.3.2" class="ltx_text" style="font-size:90%;">Comparative Analysis of Results on the PubTables Validation Set. The best results are highlighted in bold.</span></figcaption>
<table id="S5.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.4.1.1" class="ltx_tr">
<th id="S5.T3.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.4.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S5.T3.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.4.1.1.2.1" class="ltx_text ltx_font_bold">Detector</span></th>
<th id="S5.T3.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.4.1.1.3.1" class="ltx_text ltx_font_bold">mAP</span></th>
<th id="S5.T3.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.4.1.1.4.1" class="ltx_text ltx_font_bold">AP<sup id="S5.T3.4.1.1.4.1.1" class="ltx_sup">50</sup></span></th>
<th id="S5.T3.4.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.4.1.1.5.1" class="ltx_text ltx_font_bold">AP<sup id="S5.T3.4.1.1.5.1.1" class="ltx_sup">75</sup></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.4.2.1" class="ltx_tr">
<td id="S5.T3.4.2.1.1" class="ltx_td ltx_align_center ltx_border_tt">Smock et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>
</td>
<td id="S5.T3.4.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">Faster R-CNN</td>
<td id="S5.T3.4.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">82.5</td>
<td id="S5.T3.4.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">98.5</td>
<td id="S5.T3.4.2.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">92.7</td>
</tr>
<tr id="S5.T3.4.3.2" class="ltx_tr">
<td id="S5.T3.4.3.2.1" class="ltx_td ltx_align_center">Smock et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>
</td>
<td id="S5.T3.4.3.2.2" class="ltx_td ltx_align_center">DETR</td>
<td id="S5.T3.4.3.2.3" class="ltx_td ltx_align_center">96.6</td>
<td id="S5.T3.4.3.2.4" class="ltx_td ltx_align_center">995</td>
<td id="S5.T3.4.3.2.5" class="ltx_td ltx_nopad_r ltx_align_center">98.8</td>
</tr>
<tr id="S5.T3.4.4.3" class="ltx_tr">
<td id="S5.T3.4.4.3.1" class="ltx_td ltx_align_center">Minouei et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S5.T3.4.4.3.2" class="ltx_td ltx_align_center">Sparse R-CNN+PVT</td>
<td id="S5.T3.4.4.3.3" class="ltx_td ltx_align_center">98.2</td>
<td id="S5.T3.4.4.3.4" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.4.4.3.5" class="ltx_td ltx_nopad_r ltx_align_center">-</td>
</tr>
<tr id="S5.T3.4.5.4" class="ltx_tr">
<td id="S5.T3.4.5.4.1" class="ltx_td ltx_align_center ltx_border_bb">Our</td>
<td id="S5.T3.4.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">DINO</td>
<td id="S5.T3.4.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.4.5.4.3.1" class="ltx_text ltx_font_bold">98.6</span></td>
<td id="S5.T3.4.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.4.5.4.4.1" class="ltx_text ltx_font_bold">99.8</span></td>
<td id="S5.T3.4.5.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S5.T3.4.5.4.5.1" class="ltx_text ltx_font_bold">99.1</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Ablation Study</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">In our ablation study, we explore the impact of object query selection, the effectiveness of matching strategies, and the influence of the quantity of learnable queries in our Transformer-based model. This investigation is designed to observe how these key components individually and collectively affect our modelâ€™s precision and functionality in analyzing complex document layouts.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.4.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S5.T4.5.2" class="ltx_text" style="font-size:90%;">Detailed Ablation Analysis on the PubLayNet Validation Dataset.</span></figcaption>
<table id="S5.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.2.3.1" class="ltx_tr">
<th id="S5.T4.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T4.2.3.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S5.T4.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T4.2.3.1.2.1" class="ltx_text ltx_font_bold">Text</span></th>
<th id="S5.T4.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T4.2.3.1.3.1" class="ltx_text ltx_font_bold">Title</span></th>
<th id="S5.T4.2.3.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T4.2.3.1.4.1" class="ltx_text ltx_font_bold">List</span></th>
<th id="S5.T4.2.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T4.2.3.1.5.1" class="ltx_text ltx_font_bold">Table</span></th>
<th id="S5.T4.2.3.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T4.2.3.1.6.1" class="ltx_text ltx_font_bold">Figure</span></th>
<th id="S5.T4.2.3.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T4.2.3.1.7.1" class="ltx_text ltx_font_bold">mAP</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">DINO-Queries (<math id="S5.T4.1.1.1.m1.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S5.T4.1.1.1.m1.1a"><msub id="S5.T4.1.1.1.m1.1.1" xref="S5.T4.1.1.1.m1.1.1.cmml"><mi id="S5.T4.1.1.1.m1.1.1.2" xref="S5.T4.1.1.1.m1.1.1.2.cmml">Q</mi><mi id="S5.T4.1.1.1.m1.1.1.3" xref="S5.T4.1.1.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.m1.1b"><apply id="S5.T4.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T4.1.1.1.m1.1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T4.1.1.1.m1.1.1.2.cmml" xref="S5.T4.1.1.1.m1.1.1.2">ğ‘„</ci><ci id="S5.T4.1.1.1.m1.1.1.3.cmml" xref="S5.T4.1.1.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.m1.1c">Q_{d}</annotation></semantics></math>)</th>
<td id="S5.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.9</td>
<td id="S5.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">91.4</td>
<td id="S5.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">96.0</td>
<td id="S5.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.0</td>
<td id="S5.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">97.3</td>
<td id="S5.T4.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.52</td>
</tr>
<tr id="S5.T4.2.2" class="ltx_tr">
<th id="S5.T4.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b" style="padding-top:2.5pt;padding-bottom:2.5pt;">Hybrid-Queries (<math id="S5.T4.2.2.1.m1.1" class="ltx_Math" alttext="Q_{d}+Q_{e}" display="inline"><semantics id="S5.T4.2.2.1.m1.1a"><mrow id="S5.T4.2.2.1.m1.1.1" xref="S5.T4.2.2.1.m1.1.1.cmml"><msub id="S5.T4.2.2.1.m1.1.1.2" xref="S5.T4.2.2.1.m1.1.1.2.cmml"><mi id="S5.T4.2.2.1.m1.1.1.2.2" xref="S5.T4.2.2.1.m1.1.1.2.2.cmml">Q</mi><mi id="S5.T4.2.2.1.m1.1.1.2.3" xref="S5.T4.2.2.1.m1.1.1.2.3.cmml">d</mi></msub><mo id="S5.T4.2.2.1.m1.1.1.1" xref="S5.T4.2.2.1.m1.1.1.1.cmml">+</mo><msub id="S5.T4.2.2.1.m1.1.1.3" xref="S5.T4.2.2.1.m1.1.1.3.cmml"><mi id="S5.T4.2.2.1.m1.1.1.3.2" xref="S5.T4.2.2.1.m1.1.1.3.2.cmml">Q</mi><mi id="S5.T4.2.2.1.m1.1.1.3.3" xref="S5.T4.2.2.1.m1.1.1.3.3.cmml">e</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.1.m1.1b"><apply id="S5.T4.2.2.1.m1.1.1.cmml" xref="S5.T4.2.2.1.m1.1.1"><plus id="S5.T4.2.2.1.m1.1.1.1.cmml" xref="S5.T4.2.2.1.m1.1.1.1"></plus><apply id="S5.T4.2.2.1.m1.1.1.2.cmml" xref="S5.T4.2.2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.2.2.1.m1.1.1.2.1.cmml" xref="S5.T4.2.2.1.m1.1.1.2">subscript</csymbol><ci id="S5.T4.2.2.1.m1.1.1.2.2.cmml" xref="S5.T4.2.2.1.m1.1.1.2.2">ğ‘„</ci><ci id="S5.T4.2.2.1.m1.1.1.2.3.cmml" xref="S5.T4.2.2.1.m1.1.1.2.3">ğ‘‘</ci></apply><apply id="S5.T4.2.2.1.m1.1.1.3.cmml" xref="S5.T4.2.2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T4.2.2.1.m1.1.1.3.1.cmml" xref="S5.T4.2.2.1.m1.1.1.3">subscript</csymbol><ci id="S5.T4.2.2.1.m1.1.1.3.2.cmml" xref="S5.T4.2.2.1.m1.1.1.3.2">ğ‘„</ci><ci id="S5.T4.2.2.1.m1.1.1.3.3.cmml" xref="S5.T4.2.2.1.m1.1.1.3.3">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.1.m1.1c">Q_{d}+Q_{e}</annotation></semantics></math>)</th>
<td id="S5.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.0</td>
<td id="S5.T4.2.2.3" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.2</td>
<td id="S5.T4.2.2.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:2.5pt;padding-bottom:2.5pt;">97.3</td>
<td id="S5.T4.2.2.5" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.6</td>
<td id="S5.T4.2.2.6" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.5</td>
<td id="S5.T4.2.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b" style="padding-top:2.5pt;padding-bottom:2.5pt;">97.3</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS4.p2" class="ltx_para ltx_noindent">
<p id="S5.SS4.p2.1" class="ltx_p"><span id="S5.SS4.p2.1.1" class="ltx_text ltx_font_bold">Influence of object query selection</span>
In the ablation study, we observe the impact of object query selection, which is crucial for detecting small graphical objects like page headers, footers, and titles in document layout analysis. The study examines the enhanced query mechanism that combines high-level backbone features with decoder original query features. By integrating the refined query features with the original queries, we observe a significant improvement, as shown in TableÂ <a href="#S5.T4" title="Table 4 â€£ 5.4 Ablation Study â€£ 5 Results and Discussion â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, to accurately predict and identify smaller elements within document layouts. This comparison shows how high-quality object queries improve document analysis. It demonstrates that modifying query integration can significantly enhance the modelâ€™s performance and accuracy.</p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T5.12.5.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S5.T5.8.4" class="ltx_text" style="font-size:90%;">Performance comparison using various query combinations as input to the decoder on PubLayNet dataset. Here, <math id="S5.T5.5.1.m1.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S5.T5.5.1.m1.1b"><msub id="S5.T5.5.1.m1.1.1" xref="S5.T5.5.1.m1.1.1.cmml"><mi id="S5.T5.5.1.m1.1.1.2" xref="S5.T5.5.1.m1.1.1.2.cmml">Q</mi><mi id="S5.T5.5.1.m1.1.1.3" xref="S5.T5.5.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T5.5.1.m1.1c"><apply id="S5.T5.5.1.m1.1.1.cmml" xref="S5.T5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T5.5.1.m1.1.1.1.cmml" xref="S5.T5.5.1.m1.1.1">subscript</csymbol><ci id="S5.T5.5.1.m1.1.1.2.cmml" xref="S5.T5.5.1.m1.1.1.2">ğ‘„</ci><ci id="S5.T5.5.1.m1.1.1.3.cmml" xref="S5.T5.5.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.5.1.m1.1d">Q_{d}</annotation></semantics></math> represents the original decoder queries, while <math id="S5.T5.6.2.m2.1" class="ltx_Math" alttext="Q_{e}" display="inline"><semantics id="S5.T5.6.2.m2.1b"><msub id="S5.T5.6.2.m2.1.1" xref="S5.T5.6.2.m2.1.1.cmml"><mi id="S5.T5.6.2.m2.1.1.2" xref="S5.T5.6.2.m2.1.1.2.cmml">Q</mi><mi id="S5.T5.6.2.m2.1.1.3" xref="S5.T5.6.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T5.6.2.m2.1c"><apply id="S5.T5.6.2.m2.1.1.cmml" xref="S5.T5.6.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T5.6.2.m2.1.1.1.cmml" xref="S5.T5.6.2.m2.1.1">subscript</csymbol><ci id="S5.T5.6.2.m2.1.1.2.cmml" xref="S5.T5.6.2.m2.1.1.2">ğ‘„</ci><ci id="S5.T5.6.2.m2.1.1.3.cmml" xref="S5.T5.6.2.m2.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.6.2.m2.1d">Q_{e}</annotation></semantics></math> signifies the enhanced queries. The highest mean Average Precision (mAP) is achieved by combining the original DINO queries with the enhanced queries, indicating improved performance during training with overlap in predictions. A training approach that uses <math id="S5.T5.7.3.m3.1" class="ltx_Math" alttext="Q_{d}+Q_{e}" display="inline"><semantics id="S5.T5.7.3.m3.1b"><mrow id="S5.T5.7.3.m3.1.1" xref="S5.T5.7.3.m3.1.1.cmml"><msub id="S5.T5.7.3.m3.1.1.2" xref="S5.T5.7.3.m3.1.1.2.cmml"><mi id="S5.T5.7.3.m3.1.1.2.2" xref="S5.T5.7.3.m3.1.1.2.2.cmml">Q</mi><mi id="S5.T5.7.3.m3.1.1.2.3" xref="S5.T5.7.3.m3.1.1.2.3.cmml">d</mi></msub><mo id="S5.T5.7.3.m3.1.1.1" xref="S5.T5.7.3.m3.1.1.1.cmml">+</mo><msub id="S5.T5.7.3.m3.1.1.3" xref="S5.T5.7.3.m3.1.1.3.cmml"><mi id="S5.T5.7.3.m3.1.1.3.2" xref="S5.T5.7.3.m3.1.1.3.2.cmml">Q</mi><mi id="S5.T5.7.3.m3.1.1.3.3" xref="S5.T5.7.3.m3.1.1.3.3.cmml">e</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.7.3.m3.1c"><apply id="S5.T5.7.3.m3.1.1.cmml" xref="S5.T5.7.3.m3.1.1"><plus id="S5.T5.7.3.m3.1.1.1.cmml" xref="S5.T5.7.3.m3.1.1.1"></plus><apply id="S5.T5.7.3.m3.1.1.2.cmml" xref="S5.T5.7.3.m3.1.1.2"><csymbol cd="ambiguous" id="S5.T5.7.3.m3.1.1.2.1.cmml" xref="S5.T5.7.3.m3.1.1.2">subscript</csymbol><ci id="S5.T5.7.3.m3.1.1.2.2.cmml" xref="S5.T5.7.3.m3.1.1.2.2">ğ‘„</ci><ci id="S5.T5.7.3.m3.1.1.2.3.cmml" xref="S5.T5.7.3.m3.1.1.2.3">ğ‘‘</ci></apply><apply id="S5.T5.7.3.m3.1.1.3.cmml" xref="S5.T5.7.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.T5.7.3.m3.1.1.3.1.cmml" xref="S5.T5.7.3.m3.1.1.3">subscript</csymbol><ci id="S5.T5.7.3.m3.1.1.3.2.cmml" xref="S5.T5.7.3.m3.1.1.3.2">ğ‘„</ci><ci id="S5.T5.7.3.m3.1.1.3.3.cmml" xref="S5.T5.7.3.m3.1.1.3.3">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.7.3.m3.1d">Q_{d}+Q_{e}</annotation></semantics></math> for the initial half of training epochs before switching to <math id="S5.T5.8.4.m4.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S5.T5.8.4.m4.1b"><msub id="S5.T5.8.4.m4.1.1" xref="S5.T5.8.4.m4.1.1.cmml"><mi id="S5.T5.8.4.m4.1.1.2" xref="S5.T5.8.4.m4.1.1.2.cmml">Q</mi><mi id="S5.T5.8.4.m4.1.1.3" xref="S5.T5.8.4.m4.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T5.8.4.m4.1c"><apply id="S5.T5.8.4.m4.1.1.cmml" xref="S5.T5.8.4.m4.1.1"><csymbol cd="ambiguous" id="S5.T5.8.4.m4.1.1.1.cmml" xref="S5.T5.8.4.m4.1.1">subscript</csymbol><ci id="S5.T5.8.4.m4.1.1.2.cmml" xref="S5.T5.8.4.m4.1.1.2">ğ‘„</ci><ci id="S5.T5.8.4.m4.1.1.3.cmml" xref="S5.T5.8.4.m4.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.8.4.m4.1d">Q_{d}</annotation></semantics></math> is shown to be effective.</span></figcaption>
<table id="S5.T5.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T5.10.2" class="ltx_tr">
<th id="S5.T5.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S5.T5.9.1.1.m1.1" class="ltx_Math" alttext="\mathbf{Q_{d}}" display="inline"><semantics id="S5.T5.9.1.1.m1.1a"><msub id="S5.T5.9.1.1.m1.1.1" xref="S5.T5.9.1.1.m1.1.1.cmml"><mi id="S5.T5.9.1.1.m1.1.1.2" xref="S5.T5.9.1.1.m1.1.1.2.cmml">ğ</mi><mi id="S5.T5.9.1.1.m1.1.1.3" xref="S5.T5.9.1.1.m1.1.1.3.cmml">ğ</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T5.9.1.1.m1.1b"><apply id="S5.T5.9.1.1.m1.1.1.cmml" xref="S5.T5.9.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T5.9.1.1.m1.1.1.1.cmml" xref="S5.T5.9.1.1.m1.1.1">subscript</csymbol><ci id="S5.T5.9.1.1.m1.1.1.2.cmml" xref="S5.T5.9.1.1.m1.1.1.2">ğ</ci><ci id="S5.T5.9.1.1.m1.1.1.3.cmml" xref="S5.T5.9.1.1.m1.1.1.3">ğ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.9.1.1.m1.1c">\mathbf{Q_{d}}</annotation></semantics></math></th>
<th id="S5.T5.10.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S5.T5.10.2.2.m1.1" class="ltx_Math" alttext="\mathbf{Q_{d}+Q_{e}}" display="inline"><semantics id="S5.T5.10.2.2.m1.1a"><mrow id="S5.T5.10.2.2.m1.1.1" xref="S5.T5.10.2.2.m1.1.1.cmml"><msub id="S5.T5.10.2.2.m1.1.1.2" xref="S5.T5.10.2.2.m1.1.1.2.cmml"><mi id="S5.T5.10.2.2.m1.1.1.2.2" xref="S5.T5.10.2.2.m1.1.1.2.2.cmml">ğ</mi><mi id="S5.T5.10.2.2.m1.1.1.2.3" xref="S5.T5.10.2.2.m1.1.1.2.3.cmml">ğ</mi></msub><mo id="S5.T5.10.2.2.m1.1.1.1" xref="S5.T5.10.2.2.m1.1.1.1.cmml">+</mo><msub id="S5.T5.10.2.2.m1.1.1.3" xref="S5.T5.10.2.2.m1.1.1.3.cmml"><mi id="S5.T5.10.2.2.m1.1.1.3.2" xref="S5.T5.10.2.2.m1.1.1.3.2.cmml">ğ</mi><mi id="S5.T5.10.2.2.m1.1.1.3.3" xref="S5.T5.10.2.2.m1.1.1.3.3.cmml">ğ</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.10.2.2.m1.1b"><apply id="S5.T5.10.2.2.m1.1.1.cmml" xref="S5.T5.10.2.2.m1.1.1"><plus id="S5.T5.10.2.2.m1.1.1.1.cmml" xref="S5.T5.10.2.2.m1.1.1.1"></plus><apply id="S5.T5.10.2.2.m1.1.1.2.cmml" xref="S5.T5.10.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T5.10.2.2.m1.1.1.2.1.cmml" xref="S5.T5.10.2.2.m1.1.1.2">subscript</csymbol><ci id="S5.T5.10.2.2.m1.1.1.2.2.cmml" xref="S5.T5.10.2.2.m1.1.1.2.2">ğ</ci><ci id="S5.T5.10.2.2.m1.1.1.2.3.cmml" xref="S5.T5.10.2.2.m1.1.1.2.3">ğ</ci></apply><apply id="S5.T5.10.2.2.m1.1.1.3.cmml" xref="S5.T5.10.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T5.10.2.2.m1.1.1.3.1.cmml" xref="S5.T5.10.2.2.m1.1.1.3">subscript</csymbol><ci id="S5.T5.10.2.2.m1.1.1.3.2.cmml" xref="S5.T5.10.2.2.m1.1.1.3.2">ğ</ci><ci id="S5.T5.10.2.2.m1.1.1.3.3.cmml" xref="S5.T5.10.2.2.m1.1.1.3.3">ğ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.10.2.2.m1.1c">\mathbf{Q_{d}+Q_{e}}</annotation></semantics></math></th>
<th id="S5.T5.10.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T5.10.2.3.1" class="ltx_text ltx_font_bold">NMS-free</span></th>
<th id="S5.T5.10.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T5.10.2.4.1" class="ltx_text ltx_font_bold">mAP</span></th>
<th id="S5.T5.10.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T5.10.2.5.1" class="ltx_text ltx_font_bold">AP<sup id="S5.T5.10.2.5.1.1" class="ltx_sup">50</sup></span></th>
<th id="S5.T5.10.2.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T5.10.2.6.1" class="ltx_text ltx_font_bold">AP<sup id="S5.T5.10.2.6.1.1" class="ltx_sup">75</sup></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T5.10.3.1" class="ltx_tr">
<td id="S5.T5.10.3.1.1" class="ltx_td ltx_align_center ltx_border_tt">âœ“</td>
<td id="S5.T5.10.3.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T5.10.3.1.2.1" class="ltx_text" style="color:#000000;">âœ—</span></td>
<td id="S5.T5.10.3.1.3" class="ltx_td ltx_align_center ltx_border_tt">âœ“</td>
<td id="S5.T5.10.3.1.4" class="ltx_td ltx_align_center ltx_border_tt">95.5</td>
<td id="S5.T5.10.3.1.5" class="ltx_td ltx_align_center ltx_border_tt">-</td>
<td id="S5.T5.10.3.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">-</td>
</tr>
<tr id="S5.T5.10.4.2" class="ltx_tr">
<td id="S5.T5.10.4.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.10.4.2.1.1" class="ltx_text" style="color:#000000;">âœ—</span></td>
<td id="S5.T5.10.4.2.2" class="ltx_td ltx_align_center ltx_border_t">âœ“</td>
<td id="S5.T5.10.4.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.10.4.2.3.1" class="ltx_text" style="color:#000000;">âœ—</span></td>
<td id="S5.T5.10.4.2.4" class="ltx_td ltx_align_center ltx_border_t">98.4</td>
<td id="S5.T5.10.4.2.5" class="ltx_td ltx_align_center ltx_border_t">98.8</td>
<td id="S5.T5.10.4.2.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">97.7</td>
</tr>
<tr id="S5.T5.10.5.3" class="ltx_tr">
<td id="S5.T5.10.5.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">âœ“</td>
<td id="S5.T5.10.5.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">âœ“</td>
<td id="S5.T5.10.5.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">âœ“</td>
<td id="S5.T5.10.5.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">97.3</td>
<td id="S5.T5.10.5.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">98.5</td>
<td id="S5.T5.10.5.3.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t">97.4</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS4.p3" class="ltx_para ltx_noindent">
<p id="S5.SS4.p3.7" class="ltx_p"><span id="S5.SS4.p3.7.1" class="ltx_text ltx_font_bold">Influence of matching strategy</span>
In our document layout analysis approach, employing one-to-one and one-to-many matching strategies provides a comprehensive approach, as shown in TableÂ <a href="#S5.T5" title="Table 5 â€£ 5.4 Ablation Study â€£ 5 Results and Discussion â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. In our setup, <math id="S5.SS4.p3.1.m1.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S5.SS4.p3.1.m1.1a"><msub id="S5.SS4.p3.1.m1.1.1" xref="S5.SS4.p3.1.m1.1.1.cmml"><mi id="S5.SS4.p3.1.m1.1.1.2" xref="S5.SS4.p3.1.m1.1.1.2.cmml">Q</mi><mi id="S5.SS4.p3.1.m1.1.1.3" xref="S5.SS4.p3.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.1.m1.1b"><apply id="S5.SS4.p3.1.m1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.1.m1.1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS4.p3.1.m1.1.1.2.cmml" xref="S5.SS4.p3.1.m1.1.1.2">ğ‘„</ci><ci id="S5.SS4.p3.1.m1.1.1.3.cmml" xref="S5.SS4.p3.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.1.m1.1c">Q_{d}</annotation></semantics></math> represents the standard decoder queries, while <math id="S5.SS4.p3.2.m2.1" class="ltx_Math" alttext="Q_{e}" display="inline"><semantics id="S5.SS4.p3.2.m2.1a"><msub id="S5.SS4.p3.2.m2.1.1" xref="S5.SS4.p3.2.m2.1.1.cmml"><mi id="S5.SS4.p3.2.m2.1.1.2" xref="S5.SS4.p3.2.m2.1.1.2.cmml">Q</mi><mi id="S5.SS4.p3.2.m2.1.1.3" xref="S5.SS4.p3.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.2.m2.1b"><apply id="S5.SS4.p3.2.m2.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.2.m2.1.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1">subscript</csymbol><ci id="S5.SS4.p3.2.m2.1.1.2.cmml" xref="S5.SS4.p3.2.m2.1.1.2">ğ‘„</ci><ci id="S5.SS4.p3.2.m2.1.1.3.cmml" xref="S5.SS4.p3.2.m2.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.2.m2.1c">Q_{e}</annotation></semantics></math> represents the enhanced queries. The data indicates that the best mean Average Precision (mAP) is obtained when these two sets of queries are used together, which leads to better training results. Itâ€™s particularly effective to start training with <math id="S5.SS4.p3.3.m3.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S5.SS4.p3.3.m3.1a"><msub id="S5.SS4.p3.3.m3.1.1" xref="S5.SS4.p3.3.m3.1.1.cmml"><mi id="S5.SS4.p3.3.m3.1.1.2" xref="S5.SS4.p3.3.m3.1.1.2.cmml">Q</mi><mi id="S5.SS4.p3.3.m3.1.1.3" xref="S5.SS4.p3.3.m3.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.3.m3.1b"><apply id="S5.SS4.p3.3.m3.1.1.cmml" xref="S5.SS4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.3.m3.1.1.1.cmml" xref="S5.SS4.p3.3.m3.1.1">subscript</csymbol><ci id="S5.SS4.p3.3.m3.1.1.2.cmml" xref="S5.SS4.p3.3.m3.1.1.2">ğ‘„</ci><ci id="S5.SS4.p3.3.m3.1.1.3.cmml" xref="S5.SS4.p3.3.m3.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.3.m3.1c">Q_{d}</annotation></semantics></math> and <math id="S5.SS4.p3.4.m4.1" class="ltx_Math" alttext="Q_{e}" display="inline"><semantics id="S5.SS4.p3.4.m4.1a"><msub id="S5.SS4.p3.4.m4.1.1" xref="S5.SS4.p3.4.m4.1.1.cmml"><mi id="S5.SS4.p3.4.m4.1.1.2" xref="S5.SS4.p3.4.m4.1.1.2.cmml">Q</mi><mi id="S5.SS4.p3.4.m4.1.1.3" xref="S5.SS4.p3.4.m4.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.4.m4.1b"><apply id="S5.SS4.p3.4.m4.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.4.m4.1.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1">subscript</csymbol><ci id="S5.SS4.p3.4.m4.1.1.2.cmml" xref="S5.SS4.p3.4.m4.1.1.2">ğ‘„</ci><ci id="S5.SS4.p3.4.m4.1.1.3.cmml" xref="S5.SS4.p3.4.m4.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.4.m4.1c">Q_{e}</annotation></semantics></math> and then transition to using just <math id="S5.SS4.p3.5.m5.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S5.SS4.p3.5.m5.1a"><msub id="S5.SS4.p3.5.m5.1.1" xref="S5.SS4.p3.5.m5.1.1.cmml"><mi id="S5.SS4.p3.5.m5.1.1.2" xref="S5.SS4.p3.5.m5.1.1.2.cmml">Q</mi><mi id="S5.SS4.p3.5.m5.1.1.3" xref="S5.SS4.p3.5.m5.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.5.m5.1b"><apply id="S5.SS4.p3.5.m5.1.1.cmml" xref="S5.SS4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.5.m5.1.1.1.cmml" xref="S5.SS4.p3.5.m5.1.1">subscript</csymbol><ci id="S5.SS4.p3.5.m5.1.1.2.cmml" xref="S5.SS4.p3.5.m5.1.1.2">ğ‘„</ci><ci id="S5.SS4.p3.5.m5.1.1.3.cmml" xref="S5.SS4.p3.5.m5.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.5.m5.1c">Q_{d}</annotation></semantics></math> halfway through the training process. One-to-one matching using <math id="S5.SS4.p3.6.m6.1" class="ltx_Math" alttext="Q_{d}" display="inline"><semantics id="S5.SS4.p3.6.m6.1a"><msub id="S5.SS4.p3.6.m6.1.1" xref="S5.SS4.p3.6.m6.1.1.cmml"><mi id="S5.SS4.p3.6.m6.1.1.2" xref="S5.SS4.p3.6.m6.1.1.2.cmml">Q</mi><mi id="S5.SS4.p3.6.m6.1.1.3" xref="S5.SS4.p3.6.m6.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.6.m6.1b"><apply id="S5.SS4.p3.6.m6.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.6.m6.1.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1">subscript</csymbol><ci id="S5.SS4.p3.6.m6.1.1.2.cmml" xref="S5.SS4.p3.6.m6.1.1.2">ğ‘„</ci><ci id="S5.SS4.p3.6.m6.1.1.3.cmml" xref="S5.SS4.p3.6.m6.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.6.m6.1c">Q_{d}</annotation></semantics></math>, aligning each prediction with a single ground truth, is efficient for clear, distinct objects, ensuring straightforward training. On the other hand, one-to-many matching employing <math id="S5.SS4.p3.7.m7.1" class="ltx_Math" alttext="Q_{d}+Q_{e}" display="inline"><semantics id="S5.SS4.p3.7.m7.1a"><mrow id="S5.SS4.p3.7.m7.1.1" xref="S5.SS4.p3.7.m7.1.1.cmml"><msub id="S5.SS4.p3.7.m7.1.1.2" xref="S5.SS4.p3.7.m7.1.1.2.cmml"><mi id="S5.SS4.p3.7.m7.1.1.2.2" xref="S5.SS4.p3.7.m7.1.1.2.2.cmml">Q</mi><mi id="S5.SS4.p3.7.m7.1.1.2.3" xref="S5.SS4.p3.7.m7.1.1.2.3.cmml">d</mi></msub><mo id="S5.SS4.p3.7.m7.1.1.1" xref="S5.SS4.p3.7.m7.1.1.1.cmml">+</mo><msub id="S5.SS4.p3.7.m7.1.1.3" xref="S5.SS4.p3.7.m7.1.1.3.cmml"><mi id="S5.SS4.p3.7.m7.1.1.3.2" xref="S5.SS4.p3.7.m7.1.1.3.2.cmml">Q</mi><mi id="S5.SS4.p3.7.m7.1.1.3.3" xref="S5.SS4.p3.7.m7.1.1.3.3.cmml">e</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.7.m7.1b"><apply id="S5.SS4.p3.7.m7.1.1.cmml" xref="S5.SS4.p3.7.m7.1.1"><plus id="S5.SS4.p3.7.m7.1.1.1.cmml" xref="S5.SS4.p3.7.m7.1.1.1"></plus><apply id="S5.SS4.p3.7.m7.1.1.2.cmml" xref="S5.SS4.p3.7.m7.1.1.2"><csymbol cd="ambiguous" id="S5.SS4.p3.7.m7.1.1.2.1.cmml" xref="S5.SS4.p3.7.m7.1.1.2">subscript</csymbol><ci id="S5.SS4.p3.7.m7.1.1.2.2.cmml" xref="S5.SS4.p3.7.m7.1.1.2.2">ğ‘„</ci><ci id="S5.SS4.p3.7.m7.1.1.2.3.cmml" xref="S5.SS4.p3.7.m7.1.1.2.3">ğ‘‘</ci></apply><apply id="S5.SS4.p3.7.m7.1.1.3.cmml" xref="S5.SS4.p3.7.m7.1.1.3"><csymbol cd="ambiguous" id="S5.SS4.p3.7.m7.1.1.3.1.cmml" xref="S5.SS4.p3.7.m7.1.1.3">subscript</csymbol><ci id="S5.SS4.p3.7.m7.1.1.3.2.cmml" xref="S5.SS4.p3.7.m7.1.1.3.2">ğ‘„</ci><ci id="S5.SS4.p3.7.m7.1.1.3.3.cmml" xref="S5.SS4.p3.7.m7.1.1.3.3">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.7.m7.1c">Q_{d}+Q_{e}</annotation></semantics></math> allows a single prediction to correspond to several ground truths, adeptly handling complex layouts with overlapping or closely packed elements. This dual strategy leverages the strengths of both approaches, enhancing the modelâ€™s ability to accurately detect and classify a wide range of object types in various document layouts.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para ltx_noindent">
<p id="S5.SS4.p4.1" class="ltx_p"><span id="S5.SS4.p4.1.1" class="ltx_text ltx_font_bold">Influence of Learnable queries Quantity</span>
The quantity of learnable queries in Transformer-based models like DINO significantly affects their performance in document layout analysis, as observed in TableÂ <a href="#S5.T6" title="Table 6 â€£ 5.4 Ablation Study â€£ 5 Results and Discussion â€£ A Hybrid Approach for Document Layout Analysis in Document images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. More queries enable finer detection of detailed elements and improve overall accuracy, but thereâ€™s a need for balance. Excessive queries can increase computational demands and risk overfitting, while too few may miss intricate details. Thus, optimizing the number of queries is crucial for efficient processing, balancing computational resources, and ensuring adaptability across various document types and complexities.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S5.T6.3.2" class="ltx_text" style="font-size:90%;">Performance comparison using different numbers of learnable queries to the decoder input on PubLayNet Dataset. The best-performing results are highlighted in bold, illustrating the optimal number of queries required for best model performance. As indicated, the model generally improves with more queries, up to a point, after which the performance decreases, suggesting an optimal query range for efficient detection across various object sizes.</span></figcaption>
<table id="S5.T6.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.4.1.1" class="ltx_tr">
<th id="S5.T6.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S5.T6.4.1.1.1.1" class="ltx_text ltx_font_bold">N</span></th>
<th id="S5.T6.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.4.1.1.2.1" class="ltx_text ltx_font_bold">AP</span></th>
<th id="S5.T6.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.4.1.1.3.1" class="ltx_text ltx_font_bold">AP<sup id="S5.T6.4.1.1.3.1.1" class="ltx_sup">50</sup></span></th>
<th id="S5.T6.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.4.1.1.4.1" class="ltx_text ltx_font_bold">AP<sup id="S5.T6.4.1.1.4.1.1" class="ltx_sup">75</sup></span></th>
<th id="S5.T6.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.4.1.1.5.1" class="ltx_text ltx_font_bold">AP<sub id="S5.T6.4.1.1.5.1.1" class="ltx_sub">s</sub></span></th>
<th id="S5.T6.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.4.1.1.6.1" class="ltx_text ltx_font_bold">AP<sub id="S5.T6.4.1.1.6.1.1" class="ltx_sub">m</sub></span></th>
<th id="S5.T6.4.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.4.1.1.7.1" class="ltx_text ltx_font_bold">AP<sub id="S5.T6.4.1.1.7.1.1" class="ltx_sub">l</sub></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.4.2.1" class="ltx_tr">
<th id="S5.T6.4.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">100</th>
<td id="S5.T6.4.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">95.3</td>
<td id="S5.T6.4.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">96.7</td>
<td id="S5.T6.4.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">95.8</td>
<td id="S5.T6.4.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">35.8</td>
<td id="S5.T6.4.2.1.6" class="ltx_td ltx_align_center ltx_border_tt">65.3</td>
<td id="S5.T6.4.2.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">89.2</td>
</tr>
<tr id="S5.T6.4.3.2" class="ltx_tr">
<th id="S5.T6.4.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">200</th>
<td id="S5.T6.4.3.2.2" class="ltx_td ltx_align_center">96.5</td>
<td id="S5.T6.4.3.2.3" class="ltx_td ltx_align_center">97.3</td>
<td id="S5.T6.4.3.2.4" class="ltx_td ltx_align_center">96.6</td>
<td id="S5.T6.4.3.2.5" class="ltx_td ltx_align_center">43.5</td>
<td id="S5.T6.4.3.2.6" class="ltx_td ltx_align_center">71.8</td>
<td id="S5.T6.4.3.2.7" class="ltx_td ltx_nopad_r ltx_align_center">96.4</td>
</tr>
<tr id="S5.T6.4.4.3" class="ltx_tr">
<th id="S5.T6.4.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T6.4.4.3.1.1" class="ltx_text ltx_font_bold">300</span></th>
<td id="S5.T6.4.4.3.2" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.3.2.1" class="ltx_text ltx_font_bold">97.3</span></td>
<td id="S5.T6.4.4.3.3" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.3.3.1" class="ltx_text ltx_font_bold">98.5</span></td>
<td id="S5.T6.4.4.3.4" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.3.4.1" class="ltx_text ltx_font_bold">97.4</span></td>
<td id="S5.T6.4.4.3.5" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.3.5.1" class="ltx_text ltx_font_bold">43.8</span></td>
<td id="S5.T6.4.4.3.6" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.3.6.1" class="ltx_text ltx_font_bold">72.7</span></td>
<td id="S5.T6.4.4.3.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T6.4.4.3.7.1" class="ltx_text ltx_font_bold">96.7</span></td>
</tr>
<tr id="S5.T6.4.5.4" class="ltx_tr">
<th id="S5.T6.4.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">400</th>
<td id="S5.T6.4.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">96.4</td>
<td id="S5.T6.4.5.4.3" class="ltx_td ltx_align_center ltx_border_bb">98.2</td>
<td id="S5.T6.4.5.4.4" class="ltx_td ltx_align_center ltx_border_bb">97.0</td>
<td id="S5.T6.4.5.4.5" class="ltx_td ltx_align_center ltx_border_bb">43.1</td>
<td id="S5.T6.4.5.4.6" class="ltx_td ltx_align_center ltx_border_bb">60.7</td>
<td id="S5.T6.4.5.4.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">96.1</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This paper introduces a approach for analyzing document layouts, focusing on accurately identifying elements like text, images, tables, and headings in documents. We introduce a hybrid query mechanism that enhances object queries for contrastive learning, improving the efficiency of the decoder phase in the model. Moreover, during training, our approach features a hybrid matching scheme that combines the decoderâ€™s original one-to-one matching with a one-to-many matching branch, aiming to increase the modelâ€™s accuracy and flexibility in detecting diverse graphical elements on a page. We evaluate our approach on benchmark datasets like PubLayNet, DocLayNet, and PubTables. It demonstrates superior accuracy and precision in layout analysis, outperforming current state-of-the-art methods. These advancements significantly aid in transforming document images into editable and accessible formats, streamlining information retrieval and data extraction processes. The implications of our research are substantial, affecting areas such as digital archiving, automated form processing, and content management systems. This work represents a significant contribution to document analysis and digital information management, setting new benchmarks and paving the way for future advancements.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
L.Â Cui, Y.Â Xu, T.Â Lv, and F.Â Wei, â€œDocument AI: benchmarks, models and applications,â€ <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2111.08609, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2111.08609" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2111.08609</a>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
T.Â Shehzadi, A.Â Majid, M.Â Hameed, A.Â Farooq, and A.Â Yousaf, â€œIntelligent predictor using cancer-related biologically information extraction from cancer transcriptomes,â€ in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2020 International Symposium on Recent Advances in Electrical Engineering &amp; Computer Sciences (RAEE &amp; CS)</em>, vol.Â 5, 2020, pp. 1â€“5.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S.Â Ren, K.Â He, R.Â B. Girshick, and J.Â Sun, â€œFaster R-CNN: towards real-time object detection with region proposal networks,â€ <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1506.01497, 2015. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1506.01497" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1506.01497</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
K.Â He, G.Â Gkioxari, P.Â DollÃ¡r, and R.Â B. Girshick, â€œMask R-CNN,â€ <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1703.06870, 2017. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1703.06870" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1703.06870</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Z.Â Cai and N.Â Vasconcelos, â€œCascade R-CNN: delving into high quality object detection,â€ <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1712.00726, 2017. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1712.00726" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1712.00726</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
N.Â Ma, X.Â Zhang, H.Â Zheng, and J.Â Sun, â€œShufflenet V2: practical guidelines for efficient CNN architecture design,â€ <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1807.11164, 2018. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1807.11164" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1807.11164</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
S.Â Schreiber, S.Â Agne, I.Â Wolf, A.Â Dengel, and S.Â Ahmed, â€œDeepdesrt: Deep learning for detection and structure recognition of tables in document images,â€ in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</em>, vol.Â 01, 2017, pp. 1162â€“1167.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M.Â Minouei, K.Â A. Hashmi, M.Â R. Soheili, M.Â Z. Afzal, and D.Â Stricker, â€œContinual learning for table detection in document images,â€ <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 12, no.Â 18, 2022. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2076-3417/12/18/8969" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/2076-3417/12/18/8969</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S.Â Sinha, K.Â A. Hashmi, A.Â Pagani, M.Â Liwicki, D.Â Stricker, and M.Â Z. Afzal, â€œRethinking learnable proposals for graphical object detection in scanned document images,â€ <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 12, no.Â 20, 2022. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2076-3417/12/20/10578" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/2076-3417/12/20/10578</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
T.Â Shehzadi, K.Â A. Hashmi, A.Â Pagani, M.Â Liwicki, D.Â Stricker, and M.Â Z. Afzal, â€œMask-aware semi-supervised object detection in floor plans,â€ <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 12, no.Â 19, 2022. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2076-3417/12/19/9398" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/2076-3417/12/19/9398</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S.Â Naik, K.Â A. Hashmi, A.Â Pagani, M.Â Liwicki, D.Â Stricker, and M.Â Z. Afzal, â€œInvestigating attention mechanism for page object detection in document images,â€ <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 12, no.Â 15, 2022. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2076-3417/12/15/7486" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/2076-3417/12/15/7486</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L.Â Alzubaidi, J.Â Zhang, A.Â J. Humaidi, A.Â Al-dujaili, Y.Â Duan, O.Â Al-Shamma, J.Â I. SantamarÃ­a, M.Â A. Fadhel, M.Â Al-Amidie, and L.Â Farhan, â€œReview of deep learning: concepts, cnn architectures, challenges, applications, future directions,â€ <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Journal of Big Data</em>, vol.Â 8, 2021. [Online]. Available: <a target="_blank" href="https://api.semanticscholar.org/CorpusID:232434552" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:232434552</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
X.Â Zhu, W.Â Su, L.Â Lu, B.Â Li, X.Â Wang, and J.Â Dai, â€œDeformable {detr}: Deformable transformers for end-to-end object detection,â€ in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021. [Online]. Available: <a target="_blank" href="https://openreview.net/forum?id=gZ9hCDWe6ke" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=gZ9hCDWe6ke</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Z.Â Dai, B.Â Cai, Y.Â Lin, and J.Â Chen, â€œUp-detr: Unsupervised pre-training for object detection with transformers,â€ <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp. 1601â€“1610, 2020. [Online]. Available: <a target="_blank" href="https://api.semanticscholar.org/CorpusID:227011943" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:227011943</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T.Â Wang, L.Â Yuan, Y.Â Chen, J.Â Feng, and S.Â Yan, â€œPnp-detr: Towards efficient visual analysis with transformers,â€ <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2109.07036, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2109.07036" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2109.07036</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y.Â Fang, B.Â Liao, X.Â Wang, J.Â Fang, J.Â Qi, R.Â Wu, J.Â Niu, and W.Â Liu, â€œYou only look at one sequence: Rethinking transformer in vision through object detection,â€ <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2106.00666, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2106.00666" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2106.00666</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
T.Â Shehzadi, K.Â AzeemÂ Hashmi, D.Â Stricker, M.Â Liwicki, and M.Â ZeshanÂ Afzal, â€œTowards end-to-end semi-supervised table detection with deformable transformer,â€ in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Document Analysis and Recognition - ICDAR 2023</em>, G.Â A. Fink, R.Â Jain, K.Â Kise, and R.Â Zanibbi, Eds.Â Â Â Cham: Springer Nature Switzerland, 2023, pp. 51â€“76.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Z.Â Chen, J.Â Zhang, and D.Â Tao, â€œRecurrent glimpse-based decoder for detection with transformer,â€ <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2112.04632, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2112.04632" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2112.04632</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
H.Â Zhang, F.Â Li, S.Â Liu, L.Â Zhang, H.Â Su, J.Â Zhu, L.Â M. Ni, and H.-Y. Shum, â€œDino: Detr with improved denoising anchor boxes for end-to-end object detection,â€ 2022. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2203.03605" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2203.03605</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
T.Â Shehzadi, K.Â A. Hashmi, D.Â Stricker, and M.Â Z. Afzal, â€œ2d object detection with transformers: A review,â€ <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04670</em>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
B.Â Pfitzmann, C.Â Auer, M.Â Dolfi, A.Â S. Nassar, and P.Â Staar, â€œDoclaynet: A large human-annotated dataset for document-layout segmentation,â€ in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2022, pp. 3743â€“3751.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
T.Â Lin, P.Â Goyal, R.Â B. Girshick, K.Â He, and P.Â DollÃ¡r, â€œFocal loss for dense object detection,â€ <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1708.02002, 2017. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1708.02002" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1708.02002</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
A.Â Asi, R.Â Cohen, K.Â Kedem, and J.Â El-Sana, â€œSimplifying the reading of historical manuscripts,â€ in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2015 13th International Conference on Document Analysis and Recognition (ICDAR)</em>, 2015, pp. 826â€“830.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
R.Â Saabni and J.Â El-Sana, â€œLanguage-independent text lines extraction using seam carving,â€ in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">2011 International Conference on Document Analysis and Recognition</em>, 2011, pp. 563â€“568.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
P.Â Gao, M.Â Zheng, X.Â Wang, J.Â Dai, and H.Â Li, â€œFast convergence of DETR with spatially modulated co-attention,â€ <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2101.07448, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2101.07448" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2101.07448</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
D.Â Meng, X.Â Chen, Z.Â Fan, G.Â Zeng, H.Â Li, Y.Â Yuan, L.Â Sun, and J.Â Wang, â€œConditional DETR for fast training convergence,â€ <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2108.06152, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2108.06152" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2108.06152</a>

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
F.Â Liu, H.Â Wei, W.Â Zhao, G.Â Li, J.Â Peng, and Z.Â Li, â€œWb-detr: Transformer-based detector without backbone,â€ in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2021, pp. 2959â€“2967.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
W.Â Wang, Y.Â Cao, J.Â Zhang, and D.Â Tao, â€œFP-DETR: Detection transformer advanced by fully pre-training,â€ in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2022. [Online]. Available: <a target="_blank" href="https://openreview.net/forum?id=yjMQuLLcGWK" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=yjMQuLLcGWK</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
N.Â Journet, V.Â Eglin, J.Â Ramel, and R.Â Mullot, â€œText/graphic labelling of ancient printed documents,â€ in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Eighth International Conference on Document Analysis and Recognition (ICDARâ€™05)</em>, 2005, pp. 1010â€“1014 Vol. 2.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
K.Â Kise, A.Â Sato, and M.Â Iwata, â€œSegmentation of page images using the area voronoi diagram,â€ <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Computer Vision and Image Understanding</em>, vol.Â 70, no.Â 3, pp. 370â€“382, 1998. [Online]. Available: <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S1077314298906841" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S1077314298906841</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J.Â Chen and D.Â Lopresti, â€œTable detection in noisy off-line handwritten documents,â€ in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">2011 International Conference on Document Analysis and Recognition</em>, 2011, pp. 399â€“403.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J.Â Fang, L.Â Gao, K.Â Bai, R.Â Qiu, X.Â Tao, and Z.Â Tang, â€œA table detection method for multipage pdf documents via visual seperators and tabular structures,â€ in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">2011 International Conference on Document Analysis and Recognition</em>, 2011, pp. 779â€“783.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
M.Â Minouei, K.Â A. Hashmi, M.Â R. Soheili, M.Â Z. Afzal, and D.Â Stricker, â€œContinual learning for table detection in document images,â€ <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 12, no.Â 18, 2022. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2076-3417/12/18/8969" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/2076-3417/12/18/8969</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
G.Â Kallempudi, K.Â A. Hashmi, A.Â Pagani, M.Â Liwicki, D.Â Stricker, and M.Â Z. Afzal, â€œToward semi-supervised graphical object detection in document images,â€ <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Future Internet</em>, vol.Â 14, no.Â 6, 2022. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/1999-5903/14/6/176" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/1999-5903/14/6/176</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
K.Â A. Hashmi, A.Â Pagani, M.Â Liwicki, D.Â Stricker, and M.Â Z. Afzal, â€œCastabdetectors: Cascade network for table detection in document images with recursive feature pyramid and switchable atrous convolution,â€ <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Journal of Imaging</em>, vol.Â 7, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
D.Â Nazir, K.Â A. Hashmi, A.Â Pagani, M.Â Liwicki, D.Â Stricker, and M.Â Z. Afzal, â€œHybridtabnet: Towards better table detection in scanned document images,â€ <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 11, no.Â 18, 2021. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2076-3417/11/18/8396" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/2076-3417/11/18/8396</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
K.Â A. Hashmi, A.Â Pagani, M.Â Liwicki, D.Â Stricker, and M.Â Z. Afzal, â€œCascade network with deformable composite backbone for formula detection in scanned document images,â€ <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 11, no.Â 16, 2021. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2076-3417/11/16/7610" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/2076-3417/11/16/7610</a>

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
K.Â A. Hashmi, D.Â Stricker, M.Â Liwicki, M.Â N. Afzal, and M.Â Z. Afzal, â€œGuided table structure recognition through anchor optimization,â€ <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2104.10538, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2104.10538" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2104.10538</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A.Â KÃ¶lsch, M.Â Z. Afzal, M.Â Ebbecke, and M.Â Liwicki, â€œReal-time document image classification using deep cnn and extreme learning machines,â€ in <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</em>, vol.Â 01, 2017, pp. 1318â€“1323.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
X.-H. Li, F.Â Yin, and C.-L. Liu, â€œPage segmentation using convolutional neural network and graphical model,â€ in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Document Analysis Systems</em>, X.Â Bai, D.Â Karatzas, and D.Â Lopresti, Eds.Â Â Â Cham: Springer International Publishing, 2020, pp. 231â€“245.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
R.Â Saha, A.Â Mondal, and C.Â V. Jawahar, â€œGraphical object detection in document images,â€ <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2008.10843, 2020. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2008.10843" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2008.10843</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
K.Â Li, C.Â Wigington, C.Â Tensmeyer, H.Â Zhao, N.Â Barmpalios, V.Â I. Morariu, V.Â Manjunatha, T.Â Sun, and Y.Â Fu, â€œCross-domain document object detection: Benchmark suite and method,â€ in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2020, pp. 12â€‰915â€“12â€‰924.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
H.Â Yang and W.Â H. Hsu, â€œVision-based layout detection from scientific literature using recurrent convolutional neural networks,â€ in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">2020 25th international conference on pattern recognition (ICPR)</em>.Â Â Â IEEE, 2021, pp. 6455â€“6462.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
A.Â Vaswani, N.Â Shazeer, N.Â Parmar, J.Â Uszkoreit, L.Â Jones, A.Â N. Gomez, L.Â u. Kaiser, and I.Â Polosukhin, â€œAttention is all you need,â€ in <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, I.Â Guyon, U.Â V. Luxburg, S.Â Bengio, H.Â Wallach, R.Â Fergus, S.Â Vishwanathan, and R.Â Garnett, Eds., vol.Â 30.Â Â Â Curran Associates, Inc., 2017. [Online]. Available: <a target="_blank" href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
J.Â Li, Y.Â Xu, T.Â Lv, L.Â Cui, C.Â Zhang, and F.Â Wei, â€œDit: Self-supervised pre-training for document image transformer,â€ 2022. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2203.02378" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2203.02378</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Y.Â Li, Y.Â Qian, Y.Â Yu, X.Â Qin, C.Â Zhang, Y.Â Liu, K.Â Yao, J.Â Han, J.Â Liu, and E.Â Ding, â€œStructext: Structured text understanding with multi-modal transformers,â€ <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th ACM International Conference on Multimedia</em>, 2021. [Online]. Available: <a target="_blank" href="https://api.semanticscholar.org/CorpusID:236950714" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:236950714</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
R.Â Powalski, Å.Â Borchmann, D.Â Jurkiewicz, T.Â Dwojak, M.Â Pietruszka, and G.Â PaÅ‚ka, â€œGoing full-tilt boogie on document understanding with text-image-layout transformer,â€ in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Document Analysis and Recognitionâ€“ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5â€“10, 2021, Proceedings, Part II 16</em>.Â Â Â Springer, 2021, pp. 732â€“747.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
H.Â Yang and W.Â Hsu, â€œTransformer-based approach for document layout understanding,â€ in <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on Image Processing (ICIP)</em>, 2022, pp. 4043â€“4047.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
X.Â Zhong, J.Â Tang, and A.Â J. Yepes, â€œPublaynet: largest dataset ever for document layout analysis,â€ in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">2019 International Conference on Document Analysis and Recognition (ICDAR)</em>.Â Â Â IEEE, Sep. 2019, pp. 1015â€“1022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Y.Â Huang, T.Â Lv, L.Â Cui, Y.Â Lu, and F.Â Wei, â€œLayoutlmv3: Pre-training for document ai with unified text and image masking,â€ 2022. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2204.08387" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2204.08387</a>

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
S.Â Appalaraju, B.Â Jasani, B.Â U. Kota, Y.Â Xie, and R.Â Manmatha, â€œDocformer: End-to-end transformer for document understanding,â€ in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on computer vision</em>, 2021, pp. 993â€“1003.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
G.Â Kim, T.Â Hong, M.Â Yim, J.Â Park, J.Â Yim, W.Â Hwang, S.Â Yun, D.Â Han, and S.Â Park, â€œDonut: Document understanding transformer without OCR,â€ <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2111.15664, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2111.15664" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2111.15664</a>

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
J.Â Gu, J.Â Kuen, V.Â I. Morariu, H.Â Zhao, R.Â Jain, N.Â Barmpalios, A.Â Nenkova, and T.Â Sun, â€œUnidoc: Unified pretraining framework for document understanding,â€ <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol.Â 34, pp. 39â€“50, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Z.Â Gu, C.Â Meng, K.Â Wang, J.Â Lan, W.Â Wang, M.Â Gu, and L.Â Zhang, â€œXylayoutlm: Towards layout-aware multimodal networks for visually-rich document understanding,â€ in <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022, pp. 4583â€“4592.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
T.Â Shehzadi, K.Â A. Hashmi, D.Â Stricker, M.Â Liwicki, and M.Â Z. Afzal, â€œBridging the performance gap between detr and r-cnn for graphical object detection in document images,â€ <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.13526</em>, 2023.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
T.Â Shehzadi, K.Â A. Hashmi, D.Â Stricker, and M.Â Z. Afzal, â€œSparse semi-detr: Sparse learnable queries for semi-supervised object detection,â€ <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.01819</em>, 2024.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
K.Â He, G.Â Gkioxari, P.Â DollÃ¡r, and R.Â Girshick, â€œMask r-cnn,â€ in <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Computer Vision (ICCV)</em>, 2017, pp. 2980â€“2988.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
D.Â Gunawan, C.Â A. Sembiring, and M.Â A. Budiman, â€œThe implementation of cosine similarity to calculate text relevance between two documents,â€ <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Journal of Physics: Conference Series</em>, vol. 978, no.Â 1, p. 012120, mar 2018. [Online]. Available: <a target="_blank" href="https://dx.doi.org/10.1088/1742-6596/978/1/012120" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dx.doi.org/10.1088/1742-6596/978/1/012120</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
F.Â Li, H.Â Zhang, S.Â Liu, J.Â Guo, L.Â M. Ni, and L.Â Zhang, â€œDn-detr: Accelerate detr training by introducing query denoising,â€ in <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022, pp. 13â€‰619â€“13â€‰627.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
B.Â Smock, R.Â Pesala, and R.Â Abraham, â€œPubTables-1M: Towards comprehensive table extraction from unstructured documents,â€ in <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, June 2022, pp. 4634â€“4642.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
T.Â Lin, M.Â Maire, S.Â J. Belongie, L.Â D. Bourdev, R.Â B. Girshick, J.Â Hays, P.Â Perona, D.Â Ramanan, P.Â DollÃ¡r, and C.Â L. Zitnick, â€œMicrosoft COCO: common objects in context,â€ <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1405.0312, 2014. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1405.0312" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1405.0312</a>

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Z.Â Zhong, J.Â Wang, H.Â Sun, K.Â Hu, E.Â Zhang, L.Â Sun, and Q.Â Huo, â€œA hybrid approach to document layout analysis for heterogeneous document images,â€ in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Document Analysis and Recognition - ICDAR 2023</em>, G.Â A. Fink, R.Â Jain, K.Â Kise, and R.Â Zanibbi, Eds.Â Â Â Cham: Springer Nature Switzerland, 2023, pp. 189â€“206.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
N.Â Sun, Y.Â Zhu, and X.Â Hu, â€œFaster r-cnn based table detection combining corner locating,â€ <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">2019 International Conference on Document Analysis and Recognition (ICDAR)</em>, pp. 1314â€“1319, 2019.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
A.Â Bochkovskiy, C.Â Wang, and H.Â M. Liao, â€œYolov4: Optimal speed and accuracy of object detection,â€ <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2004.10934, 2020. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2004.10934" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2004.10934</a>

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
M.Â Minouei, M.Â R. Soheili, and D.Â Stricker, â€œDocument layout analysis with an enhanced object detector,â€ in <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">2021 5th International Conference on Pattern Recognition and Image Analysis (IPRIA)</em>, 2021, pp. 1â€“5.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
H.Â Bi, C.Â Xu, C.Â Shi, G.Â Liu, Y.Â Li, H.Â Zhang, and J.Â Qu, â€œSrrv: A novel document object detector based on spatial-related relation and vision,â€ <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, vol.Â 25, pp. 3788â€“3798, 2023.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
P.Â Zhang, C.Â Li, L.Â Qiao, Z.Â Cheng, S.Â Pu, Y.Â Niu, and F.Â Wu, â€œVSR: A unified framework for document layout analysis combining vision, semantics and relations,â€ <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2105.06220, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2105.06220" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2105.06220</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.17887" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.17888" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.17888">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.17888" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.17889" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 14:38:54 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
