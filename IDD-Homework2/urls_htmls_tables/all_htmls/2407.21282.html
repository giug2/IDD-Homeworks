<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.21282] FedBChain: A Blockchain-enabled Federated Learning Framework for Improving DeepConvLSTM with Comparative Strategy Insights*</title><meta property="og:description" content="Recent research in the field of Human Activity Recognition has shown that an improvement in prediction performance can be achieved by reducing the number of LSTM layers. However, this kind of enhancement is only signif…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedBChain: A Blockchain-enabled Federated Learning Framework for Improving DeepConvLSTM with Comparative Strategy Insights*">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedBChain: A Blockchain-enabled Federated Learning Framework for Improving DeepConvLSTM with Comparative Strategy Insights*">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.21282">

<!--Generated on Mon Aug  5 17:02:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">FedBChain: A Blockchain-enabled Federated Learning Framework for Improving DeepConvLSTM with Comparative Strategy Insights*
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gaoxuan Li<sup id="id11.11.id1" class="ltx_sup"><span id="id11.11.id1.1" class="ltx_text ltx_font_italic">1</span></sup>, Chern Hong Lim<sup id="id12.12.id2" class="ltx_sup"><span id="id12.12.id2.1" class="ltx_text ltx_font_italic">2</span></sup>, Qiyao Ma<sup id="id13.13.id3" class="ltx_sup"><span id="id13.13.id3.1" class="ltx_text ltx_font_italic">3</span></sup>, Xinyu Tang<sup id="id14.14.id4" class="ltx_sup"><span id="id14.14.id4.1" class="ltx_text ltx_font_italic">4</span></sup> and Hwa Hui Tew<sup id="id15.15.id5" class="ltx_sup"><span id="id15.15.id5.1" class="ltx_text ltx_font_italic">5</span></sup>
</span><span class="ltx_author_notes">*This work was not supported by any organization<sup id="id16.16.id1" class="ltx_sup"><span id="id16.16.id1.1" class="ltx_text ltx_font_italic">1</span></sup>Gaoxuan Li is with the School of Information Technology, Monash University, Selangor, Malaysia
<span id="id17.17.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">glii0053@student.monash.edu</span><sup id="id18.18.id1" class="ltx_sup"><span id="id18.18.id1.1" class="ltx_text ltx_font_italic">2</span></sup>Chern Hong Lim is with the School of Information Technology, Monash University, Selangor, Malaysia
<span id="id19.19.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">lim.chernhong@monash.edu</span><sup id="id20.20.id1" class="ltx_sup"><span id="id20.20.id1.1" class="ltx_text ltx_font_italic">3</span></sup>Qiyao Ma is with the Arts College, Sichuan University, Sichuan, China
<span id="id21.21.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">1115744893@qq.com</span><sup id="id22.22.id1" class="ltx_sup"><span id="id22.22.id1.1" class="ltx_text ltx_font_italic">4</span></sup>Xinyu Tang is with the School of Information Technology, Monash University, Selangor, Malaysia
<span id="id23.23.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">xtan0132@student.monash.edu</span><sup id="id24.24.id1" class="ltx_sup"><span id="id24.24.id1.1" class="ltx_text ltx_font_italic">5</span></sup>Hwa Hui Tew is with the School of Information Technology, Monash University, Selangor, Malaysia
<span id="id25.25.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">hwa.tew@monash.edu</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id26.id1" class="ltx_p">Recent research in the field of Human Activity Recognition has shown that an improvement in prediction performance can be achieved by reducing the number of LSTM layers. However, this kind of enhancement is only significant on monolithic architectures, and when it runs on large-scale distributed training, data security and privacy issues will be reconsidered, and its prediction performance is unknown. In this paper, we introduce a novel framework: FedBChain, which integrates the federated learning paradigm based on a modified DeepConvLSTM architecture with a single LSTM layer. This framework performs comparative tests of prediction performance on three different real-world datasets based on three different hidden layer units (128, 256, and 512) combined with five different federated learning strategies, respectively. The results show that our architecture has significant improvements in Precision, Recall and F1-score compared to the centralized training approach on all datasets with all hidden layer units for all strategies: FedAvg strategy improves on average by 4.54%, FedProx improves on average by 4.57%, FedTrimmedAvg improves on average by 4.35%, Krum improves by 4.18% on average, and FedAvgM improves by 4.46% on average. Based on our results, it can be seen that FedBChain not only improves in performance, but also guarantees the security and privacy of user data compared to centralized training methods during the training process. The code for our experiments is publicly available (https://github.com/Glen909/FedBChain).</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">INTRODUCTION</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Human activity recognition(HAR) [1] has a wide range of applications and importance in several fields. In the field of digital health, recognizing human activities, especially for the elderly, can help maintain or improve their health; in the field of smart home, HAR can help automation systems better coordinate collaboration among devices in the home; in the field of human-computer interaction, clearly recognizing human activities can better understand human intentions and make timely and accurate responses. In a world where machine learning and deep learning are becoming increasingly fast and iterative, a larger number of researchers are applying them to the field of HAR to empower the recognition function and make it more efficient.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Among these researchers, DeepConvLSTM proposed by [2] is one of the deep learning architectures that has attracted a lot of attention in the study of HAR. This innovative architecture incorporates convolutional and recurrent layers. It shows excellent performance and outstanding results on several real-world datasets (Opportunity [3] and Skoda Mini Checkpoint datasets [4]). Specifically, [2] designed the LSTM layers in the DeepConvLSTM architecture as a two-layer structure and 128 more hidden units in each layer. As pointed out by [5] and further confirmed by [6]. It is generally accepted that at least two LSTM layers are required for optimal modelling during sequential data processing in the field of HAR.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, this was doubted and reassessed by [7], whose study used a single LSTM layer in a recurrent layer structure for model training. The results showed that the DeepConvLSTM structure based on a two-layer LSTM was outperformed by the single-layer DeepConvLSTM (with the LSTM module of the second layer removed) in terms of accuracy, recall, and F1-scores for four of the five datasets. Specifically, [7] achieved an average of 62% fewer trainable parameters across the architecture with this adaptation and reduced the overall training time by 48%. Although [7] achieved remarkable success on the DeepConvLSTM architecture based on single-layer LSTM, it is only applicable to monolithic servers, and in the large-scale distributed training environments, even if the performance of monolithic architectures is optimized again, it cannot effectively stifle the security and privacy issues of personal data. Therefore, in order to better handle the privacy and security of user data during training, federated learning [8] is proposed as an effective solution in large-scale distributed training environments. Federated learning is a decentralized machine learning technique that allows collaborative model training among multiple data owners while the data is always stored locally at the data owner.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Therefore, this project develops FedBChain, a federated learning framework specialized for large-scale distributed training environments, on top of DeepConvLSTM. This framework employs distributed training instead of the centralized training approach, thus enhancing data privacy and security. In addition, compared to the general federated learning process, FedBChain employs blockchain technology [9] as the global model in designing the global model. Generally, federated learning usually relies on a central node for aggregation and distribution of model parameters, which may have a single point of failure that jeopardizes the overall system performance, therefore, the design of this framework uses blockchain technology instead of a centralized global model. Meanwhile, the deployment and execution of smart contracts automatically performs model aggregation and distribution of the latest parameters to further ensure the robustness and availability of the system.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The contributions of this paper are summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">This project introduces the FedBChain framework, which is based on a single-layer DeepConvLSTM architecture for federated learning training approach to ensure that data security and privacy are enhanced throughout the training process. The framework is suitable for large-scale distributed federated training.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Within the FedBChain framework, this project integrates a blockchain module to replace the centralized global model. This modification minimizes the risk of single point of failure and ensures that each model parameter update is securely recorded on the blockchain, making it traceable, reproducible and tamper-proof.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Based on the proposed FedBChain framework, this project analyses the DeepConvLSTM under five different federated learning strategies in comparison with centralized training methods, and tests the DeepConvLSTM on three datasets with three different configurations of hidden layer units. The results show that FedBChain significantly outperforms the centralized training method.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">RELATED WORK</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Federated Learning (FL) has risen as a crucial framework for decentralized machine learning, designed to address data privacy issues while leveraging data from diverse sources for model training. Initially introduced by [10] in 2016, this approach ensures that data remains on local devices, with only model updates being shared to a central server, thereby significantly diminishing the risks associated with centralized data storage. Subsequent research has broadened to tackle various challenges in FL, including minimizing communication overhead as discussed by [11], ensuring equitable resource distribution among participants as explored by [12], and fortifying model security against adversarial attacks in distributed environments as identified by [13]. Additionally, advancements have been made with techniques that employ sophisticated encryption methods like secure multi-party computation and differential privacy to enhance the privacy protections of federated models, as demonstrated by [14].</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Human Activity Recognition</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">HAR has garnered significant attention due to its applications in health monitoring and automated systems. Traditionally, HAR systems have relied heavily on sensor data, which is aggregated and processed on centralized servers [15]. However, privacy concerns and the logistical complexities associated with centralized data aggregation have spurred the exploration of decentralized methodologies, particularly through federated learning. For example, [16] illustrated the application of federated learning in HAR using mobile sensors, substantially enhancing privacy by keeping sensitive data on the devices themselves. More recent studies have furthered the field by integrating deep learning techniques to boost recognition accuracy while maintaining the decentralized framework of federated learning [17]. These developments suggest a shift toward more secure and efficient methods for implementing HAR in privacy-sensitive environments.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Blockchain</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In the realm of HAR, the integration of blockchain technology has surfaced as an innovative trend aimed at bolstering system security and privacy. For example, [18] showcased a blockchain-based HAR system that employs smart contracts to verify and log sensor data, thereby enhancing transparency and trust in data management. [19] investigated how blockchain could safeguard user privacy through its distributed ledger technology, mitigating risks linked to centralized data storage. Meanwhile, [20] merged machine learning with blockchain to strengthen the immutability and automation of verification processes for HAR data on smart devices. Collectively, these studies not only underscore blockchain’s potential to fortify privacy and security but also illustrate its role in improving the efficiency and transparency of data management.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">METHODS</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Datasets</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To evaluate the effectiveness of the DeepConvLSTM architecture after integrating the federated learning strategy, this project uses three well-known datasets processed in the same way as [7]: the Heterogeneous Activity Recognition (HHAR) dataset [21], the Real-World HAR (RWHAR)[22], and the Smartphone-based Human Activity and Pose Transition Recognition ( SBHAR) [23].</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">RWHAR: The RWHAR dataset contains data from 15 participants performing eight different activities (going up stairs, going down stairs, jumping, lying down, standing, sitting, running, and walking), as well as an empty class. According to the experimental parameters mentioned in [7], the present analysis was limited to 3D acceleration data recorded at 50Hz using wrist-worn sensors.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">SBHAR: The SBHAR dataset contains data from 30 individuals engaged in daily activities such as standing, sitting, lying down, walking, walking up stairs and walking down stairs as shown in [23]. In addition to these six activities, the dataset includes six types of postural transitions (from standing to sitting, from sitting to standing, from sitting to lying, from lying to sitting, from standing to lying, and from lying to standing) and an empty category. To maintain comparability, this analysis also focuses only on the raw 3D acceleration data collected at a 50Hz sampling rate.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">HHAR: Similar to the RWHAR dataset, the HHAR dataset contains data from nine individuals involved in daily activities, including six activities (cycling, sitting, standing, walking, and climbing up and down stairs) and the null category for prediction purposes. Consistent with the methodology of the previous dataset, the current analysis focused solely on 3D acceleration data recorded at 100Hz by a wrist-worn sensor unit.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2407.21282/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="233" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>OVERVIEW OF FEDBCHAIN BASED ON FEDERATED LEARNING</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Architecture</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The novel framework, FedBChain, is illustrated in Fig. 1 and is structured around M servers and N clients. The M servers collaboratively establish a global model that is tasked with gathering model parameters, which are locally trained by the clients. Following specific strategies, these parameters are aggregated, and the resultant model parameters are subsequently redistributed to each client. The local models at the client sites then update their parameters from the global model before continuing training on local data. This cycle repeats until the model reaches convergence. Throughout this process, local data of the clients remains exclusively local and only weight parameters of the model are transmitted to the global model for aggregation.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Specifically, the FedBChain leverages the Flower framework [24] for implementation, where model parameter aggregation tasks are managed using FedAvg [25], FedProx [26], FedTrimmedAvg [27], Krum [28], and FedAvgM [29] strategies. Additionally, we evaluate these strategies across three different datasets and three distinct hidden layer sizes (128, 256, and 512) as depicted in Fig. 2. The baseline model for this experiment is established using the centralized training method based on the DeepConvLSTM architecture, with equivalent hidden layer units applied across the datasets.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">To ensure consistent result comparability, in line with [7], this project uses an Adam optimizer with a reduced weight decay (1e-6) and learning rate (1e-4), and employ Glorot initialization [30] for network weight setup. During the training, Five-Fold Cross-Validation was applied to calculate loss, enabling the network to adapt to unbalanced datasets. This study primarily investigates differences between centralized and federated training methods and compares outcomes across various federated strategies without excessively adjusting the hyperparameters for the RWHAR, SBHAR, and HHAR datasets. However, since the HHAR dataset samples at 100 Hz, we adjust the size of the convolution filters to 21 to preserve the relationship between filter size and the sliding window duration, ensuring that each filter captures a consistent amount of information across all datasets.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">In this project, Hyperledger Fabric [31] will be deployed to structure the decentralized global model consisting of M servers. This decentralized network configuration will include two peer nodes, one order node, and one channel, namely Ledger. The process unfolds as follows: Initially, the global model parameters are proposed to the peer nodes as the inaugural proposal, where they are processed using the Chain Code installed on these nodes. The order node then encapsulates this proposal into the genesis block, which is subsequently dispatched to each peer node for independent verification. Once verified, the proposal is added to the ledger. This procedure is replicated for each round of global model updates, thereby ensuring the traceability, trackability, and security of the model parameters. Additionally, this approach mitigates the risk of single points of failure, enhancing overall system stability.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2407.21282/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="122" height="110" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>CONFIGURATION STRUCTURE OF THE EXPERIMENTAL TASKS</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">RESULTS</span>
</h2>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>COMPARISON OF FEDERATED LEARNING WITH CENTRALIZED TRAINING ON HHAR </figcaption>
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T1.1.1.1.2" class="ltx_td ltx_align_left"><span id="S4.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Hidden Units</span></td>
<td id="S4.T1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.3.1.1" class="ltx_p" style="width:0.0pt;"><span id="S4.T1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Metrics</span></span>
</span>
</td>
<td id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">Centralized Training &amp; Federated Learning with Five Strategies</span></td>
<td id="S4.T1.1.1.1.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.1.1.1.6" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.1.1.1.7" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.1.1.1.8" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.1.1.1.9" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="S4.T1.1.2.2" class="ltx_tr">
<td id="S4.T1.1.2.2.1" class="ltx_td"></td>
<td id="S4.T1.1.2.2.2" class="ltx_td"></td>
<td id="S4.T1.1.2.2.3" class="ltx_td ltx_align_top"></td>
<td id="S4.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.2.2.4.1" class="ltx_text ltx_font_bold ltx_font_italic">Centralized</span></td>
<td id="S4.T1.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.2.2.5.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvg</span></td>
<td id="S4.T1.1.2.2.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.2.2.6.1" class="ltx_text ltx_font_bold ltx_font_italic">FedProx</span></td>
<td id="S4.T1.1.2.2.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.2.2.7.1" class="ltx_text ltx_font_bold ltx_font_italic">FedTrimmedAvg</span></td>
<td id="S4.T1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.2.2.8.1" class="ltx_text ltx_font_bold ltx_font_italic">Krum</span></td>
<td id="S4.T1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.2.2.9.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvgM</span></td>
</tr>
<tr id="S4.T1.1.3.3" class="ltx_tr">
<td id="S4.T1.1.3.3.1" class="ltx_td ltx_align_center">HHAR</td>
<td id="S4.T1.1.3.3.2" class="ltx_td ltx_align_left">128</td>
<td id="S4.T1.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.3.3.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r">76.24%</td>
<td id="S4.T1.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r">80.61%</td>
<td id="S4.T1.1.3.3.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.3.3.6.1" class="ltx_text ltx_font_bold">80.78%</span></td>
<td id="S4.T1.1.3.3.7" class="ltx_td ltx_align_left ltx_border_r">80.32%</td>
<td id="S4.T1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r">80.30%</td>
<td id="S4.T1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.3.3.9.1" class="ltx_text ltx_font_bold">80.74%</span></td>
</tr>
<tr id="S4.T1.1.4.4" class="ltx_tr">
<td id="S4.T1.1.4.4.1" class="ltx_td"></td>
<td id="S4.T1.1.4.4.2" class="ltx_td"></td>
<td id="S4.T1.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.4.4.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">76.66%</td>
<td id="S4.T1.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r">80.98%</td>
<td id="S4.T1.1.4.4.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.4.4.6.1" class="ltx_text ltx_font_bold">81.10%</span></td>
<td id="S4.T1.1.4.4.7" class="ltx_td ltx_align_left ltx_border_r">80.75%</td>
<td id="S4.T1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r">80.64%</td>
<td id="S4.T1.1.4.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.4.4.9.1" class="ltx_text ltx_font_bold">81.06%</span></td>
</tr>
<tr id="S4.T1.1.5.5" class="ltx_tr">
<td id="S4.T1.1.5.5.1" class="ltx_td"></td>
<td id="S4.T1.1.5.5.2" class="ltx_td"></td>
<td id="S4.T1.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.5.5.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">76.33%</td>
<td id="S4.T1.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r">80.70%</td>
<td id="S4.T1.1.5.5.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.5.5.6.1" class="ltx_text ltx_font_bold">80.81%</span></td>
<td id="S4.T1.1.5.5.7" class="ltx_td ltx_align_left ltx_border_r">80.42%</td>
<td id="S4.T1.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r">80.34%</td>
<td id="S4.T1.1.5.5.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.5.5.9.1" class="ltx_text ltx_font_bold">80.76%</span></td>
</tr>
<tr id="S4.T1.1.6.6" class="ltx_tr">
<td id="S4.T1.1.6.6.1" class="ltx_td"></td>
<td id="S4.T1.1.6.6.2" class="ltx_td ltx_align_left">256</td>
<td id="S4.T1.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.6.6.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">77.24%</td>
<td id="S4.T1.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.6.6.5.1" class="ltx_text ltx_font_bold">81.75%</span></td>
<td id="S4.T1.1.6.6.6" class="ltx_td ltx_align_left ltx_border_r">81.57%</td>
<td id="S4.T1.1.6.6.7" class="ltx_td ltx_align_left ltx_border_r">80.99%</td>
<td id="S4.T1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r">81.24%</td>
<td id="S4.T1.1.6.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.6.6.9.1" class="ltx_text ltx_font_bold">81.65%</span></td>
</tr>
<tr id="S4.T1.1.7.7" class="ltx_tr">
<td id="S4.T1.1.7.7.1" class="ltx_td"></td>
<td id="S4.T1.1.7.7.2" class="ltx_td"></td>
<td id="S4.T1.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.7.7.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">77.55%</td>
<td id="S4.T1.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.7.7.5.1" class="ltx_text ltx_font_bold">82.09%</span></td>
<td id="S4.T1.1.7.7.6" class="ltx_td ltx_align_left ltx_border_r">81.90%</td>
<td id="S4.T1.1.7.7.7" class="ltx_td ltx_align_left ltx_border_r">81.45%</td>
<td id="S4.T1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r">81.47%</td>
<td id="S4.T1.1.7.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.7.7.9.1" class="ltx_text ltx_font_bold">81.93%</span></td>
</tr>
<tr id="S4.T1.1.8.8" class="ltx_tr">
<td id="S4.T1.1.8.8.1" class="ltx_td"></td>
<td id="S4.T1.1.8.8.2" class="ltx_td"></td>
<td id="S4.T1.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.8.8.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">77.28%</td>
<td id="S4.T1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.8.8.5.1" class="ltx_text ltx_font_bold">81.84%</span></td>
<td id="S4.T1.1.8.8.6" class="ltx_td ltx_align_left ltx_border_r">81.64%</td>
<td id="S4.T1.1.8.8.7" class="ltx_td ltx_align_left ltx_border_r">81.12%</td>
<td id="S4.T1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r">81.23%</td>
<td id="S4.T1.1.8.8.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.8.9.1" class="ltx_text ltx_font_bold">81.70%</span></td>
</tr>
<tr id="S4.T1.1.9.9" class="ltx_tr">
<td id="S4.T1.1.9.9.1" class="ltx_td"></td>
<td id="S4.T1.1.9.9.2" class="ltx_td ltx_align_left">512</td>
<td id="S4.T1.1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.9.9.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T1.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">78.02%</td>
<td id="S4.T1.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r">82.33%</td>
<td id="S4.T1.1.9.9.6" class="ltx_td ltx_align_left ltx_border_r">82.27%</td>
<td id="S4.T1.1.9.9.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.9.9.7.1" class="ltx_text ltx_font_bold">82.34%</span></td>
<td id="S4.T1.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r">82.29%</td>
<td id="S4.T1.1.9.9.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.9.9.9.1" class="ltx_text ltx_font_bold">82.37%</span></td>
</tr>
<tr id="S4.T1.1.10.10" class="ltx_tr">
<td id="S4.T1.1.10.10.1" class="ltx_td"></td>
<td id="S4.T1.1.10.10.2" class="ltx_td"></td>
<td id="S4.T1.1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.10.10.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">78.32%</td>
<td id="S4.T1.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.10.10.5.1" class="ltx_text ltx_font_bold">82.69%</span></td>
<td id="S4.T1.1.10.10.6" class="ltx_td ltx_align_left ltx_border_r">82.55%</td>
<td id="S4.T1.1.10.10.7" class="ltx_td ltx_align_left ltx_border_r">82.65%</td>
<td id="S4.T1.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r">82.59%</td>
<td id="S4.T1.1.10.10.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.10.10.9.1" class="ltx_text ltx_font_bold">82.72%</span></td>
</tr>
<tr id="S4.T1.1.11.11" class="ltx_tr">
<td id="S4.T1.1.11.11.1" class="ltx_td"></td>
<td id="S4.T1.1.11.11.2" class="ltx_td"></td>
<td id="S4.T1.1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.11.11.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T1.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">78.05%</td>
<td id="S4.T1.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.1.11.11.5.1" class="ltx_text ltx_font_bold">82.43%</span></td>
<td id="S4.T1.1.11.11.6" class="ltx_td ltx_align_left ltx_border_r">82.34%</td>
<td id="S4.T1.1.11.11.7" class="ltx_td ltx_align_left ltx_border_r">82.42%</td>
<td id="S4.T1.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r">82.34%</td>
<td id="S4.T1.1.11.11.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.11.11.9.1" class="ltx_text ltx_font_bold">82.46%</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In both centralized and federated learning training methods, K-Fold Cross-Validation (specifically Five-Fold) is uniformly applied across each dataset. This approach ensures that every data point serves both as part of the training and the validation set, which is particularly advantageous when data volumes are limited. Additionally, the data preprocessing in federated training is consistent with that of centralized methods across each dataset.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">As illustrated in Fig. 2, this study compares the training results of three different hidden layer units (128, 256, and 512) using a single-layer DeepConvLSTM architecture under centralized and federated learning methods (across five different strategies). The results for each strategy represent the average performance of three clients, with outcomes averaged over five runs. This experiment employs precision, recall, and F1-score as the evaluation metric.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Table I displays that all five federated learning strategies outperformed the centralized training approach on HHAR. Notably, FedAvgM achieved superior performance not only compared to centralized training but also excelled over the other strategies under various hidden unit settings. Moreover, with 128 hidden units, FedProx delivered Precision, Recall, and F1 scores of 80.78%, 81.10%, and 80.81% respectively, showing a significant improvement over the other three federated strategies. With 256 hidden units, FedAvg surpassed the others, with increases of 5.84%, 5.85%, and 5.90% in the three metrics respectively. Therefore, when implementing DeepConvLSTM on a single layer using one of these five federated learning strategies, the overall performance on the HHAR dataset exceeded that of the centralized approach, with specific outcomes depending on the number of hidden units.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">In the RWHAR training set(Table II), the outcomes of the five federated training methods consistently surpass those of centralized training. Unlike the results seen in the HHAR dataset, for the RWHAR dataset, irrespective of the federated strategy employed, the F1-score for models with 128 hidden layer units consistently outperforms those with 256 and 512 units. For instance, under federation strategy FedAvg, the F1-score improvement at 128 units is 4.49%, compared to 4.01% and 4.18% for 256 and 512 units, respectively. Similarly, in FedAvgM, the F1-score for 128 units rose by 4.56%, while increases for 256 and 512 units were 4.01% and 4.24%, respectively.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>COMPARISON OF FEDERATED LEARNING WITH CENTRALIZED TRAINING ON RWHAR</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T2.1.1.1.2" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Hidden Units</span></td>
<td id="S4.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.1.1.3.1.1" class="ltx_p" style="width:0.0pt;"><span id="S4.T2.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Metrics</span></span>
</span>
</td>
<td id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">Centralized Training &amp; Federated Learning with Five Strategies</span></td>
<td id="S4.T2.1.1.1.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T2.1.1.1.6" class="ltx_td ltx_border_r"></td>
<td id="S4.T2.1.1.1.7" class="ltx_td ltx_border_r"></td>
<td id="S4.T2.1.1.1.8" class="ltx_td ltx_border_r"></td>
<td id="S4.T2.1.1.1.9" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="S4.T2.1.2.2" class="ltx_tr">
<td id="S4.T2.1.2.2.1" class="ltx_td"></td>
<td id="S4.T2.1.2.2.2" class="ltx_td"></td>
<td id="S4.T2.1.2.2.3" class="ltx_td ltx_align_top"></td>
<td id="S4.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.2.2.4.1" class="ltx_text ltx_font_bold ltx_font_italic">Centralized</span></td>
<td id="S4.T2.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.2.2.5.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvg</span></td>
<td id="S4.T2.1.2.2.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.2.2.6.1" class="ltx_text ltx_font_bold ltx_font_italic">FedProx</span></td>
<td id="S4.T2.1.2.2.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.2.2.7.1" class="ltx_text ltx_font_bold ltx_font_italic">FedTrimmedAvg</span></td>
<td id="S4.T2.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.2.2.8.1" class="ltx_text ltx_font_bold ltx_font_italic">Krum</span></td>
<td id="S4.T2.1.2.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.2.2.9.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvgM</span></td>
</tr>
<tr id="S4.T2.1.3.3" class="ltx_tr">
<td id="S4.T2.1.3.3.1" class="ltx_td ltx_align_center">RWHAR</td>
<td id="S4.T2.1.3.3.2" class="ltx_td ltx_align_left">128</td>
<td id="S4.T2.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.3.3.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r">84.31%</td>
<td id="S4.T2.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.3.3.5.1" class="ltx_text ltx_font_bold">88.00%</span></td>
<td id="S4.T2.1.3.3.6" class="ltx_td ltx_align_left ltx_border_r">87.90%</td>
<td id="S4.T2.1.3.3.7" class="ltx_td ltx_align_left ltx_border_r">87.89%</td>
<td id="S4.T2.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r">87.71%</td>
<td id="S4.T2.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.3.3.9.1" class="ltx_text ltx_font_bold">87.97%</span></td>
</tr>
<tr id="S4.T2.1.4.4" class="ltx_tr">
<td id="S4.T2.1.4.4.1" class="ltx_td"></td>
<td id="S4.T2.1.4.4.2" class="ltx_td"></td>
<td id="S4.T2.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.4.4.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">83.71%</td>
<td id="S4.T2.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r">87.55%</td>
<td id="S4.T2.1.4.4.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.4.4.6.1" class="ltx_text ltx_font_bold">87.66%</span></td>
<td id="S4.T2.1.4.4.7" class="ltx_td ltx_align_left ltx_border_r">87.63%</td>
<td id="S4.T2.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r">87.30%</td>
<td id="S4.T2.1.4.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.4.4.9.1" class="ltx_text ltx_font_bold">87.69%</span></td>
</tr>
<tr id="S4.T2.1.5.5" class="ltx_tr">
<td id="S4.T2.1.5.5.1" class="ltx_td"></td>
<td id="S4.T2.1.5.5.2" class="ltx_td"></td>
<td id="S4.T2.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.5.5.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T2.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">83.81%</td>
<td id="S4.T2.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r">87.58%</td>
<td id="S4.T2.1.5.5.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.5.5.6.1" class="ltx_text ltx_font_bold">87.61%</span></td>
<td id="S4.T2.1.5.5.7" class="ltx_td ltx_align_left ltx_border_r">87.58%</td>
<td id="S4.T2.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r">87.32%</td>
<td id="S4.T2.1.5.5.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.5.5.9.1" class="ltx_text ltx_font_bold">87.63%</span></td>
</tr>
<tr id="S4.T2.1.6.6" class="ltx_tr">
<td id="S4.T2.1.6.6.1" class="ltx_td"></td>
<td id="S4.T2.1.6.6.2" class="ltx_td ltx_align_left">256</td>
<td id="S4.T2.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.6.6.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">85.33%</td>
<td id="S4.T2.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.6.6.5.1" class="ltx_text ltx_font_bold">88.51%</span></td>
<td id="S4.T2.1.6.6.6" class="ltx_td ltx_align_left ltx_border_r">88.46%</td>
<td id="S4.T2.1.6.6.7" class="ltx_td ltx_align_left ltx_border_r">88.41%</td>
<td id="S4.T2.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r">88.25%</td>
<td id="S4.T2.1.6.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.6.6.9.1" class="ltx_text ltx_font_bold">88.51%</span></td>
</tr>
<tr id="S4.T2.1.7.7" class="ltx_tr">
<td id="S4.T2.1.7.7.1" class="ltx_td"></td>
<td id="S4.T2.1.7.7.2" class="ltx_td"></td>
<td id="S4.T2.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.7.7.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T2.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">84.74%</td>
<td id="S4.T2.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.7.7.5.1" class="ltx_text ltx_font_bold">88.34%</span></td>
<td id="S4.T2.1.7.7.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.7.7.6.1" class="ltx_text ltx_font_bold">88.29%</span></td>
<td id="S4.T2.1.7.7.7" class="ltx_td ltx_align_left ltx_border_r">88.22%</td>
<td id="S4.T2.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r">88.15%</td>
<td id="S4.T2.1.7.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.7.7.9.1" class="ltx_text ltx_font_bold">88.29%</span></td>
</tr>
<tr id="S4.T2.1.8.8" class="ltx_tr">
<td id="S4.T2.1.8.8.1" class="ltx_td"></td>
<td id="S4.T2.1.8.8.2" class="ltx_td"></td>
<td id="S4.T2.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.8.8.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T2.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">84.85%</td>
<td id="S4.T2.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.8.8.5.1" class="ltx_text ltx_font_bold">88.25%</span></td>
<td id="S4.T2.1.8.8.6" class="ltx_td ltx_align_left ltx_border_r">88.21%</td>
<td id="S4.T2.1.8.8.7" class="ltx_td ltx_align_left ltx_border_r">88.17%</td>
<td id="S4.T2.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r">88.01%</td>
<td id="S4.T2.1.8.8.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.8.8.9.1" class="ltx_text ltx_font_bold">88.25%</span></td>
</tr>
<tr id="S4.T2.1.9.9" class="ltx_tr">
<td id="S4.T2.1.9.9.1" class="ltx_td"></td>
<td id="S4.T2.1.9.9.2" class="ltx_td ltx_align_left">512</td>
<td id="S4.T2.1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.9.9.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T2.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">85.79%</td>
<td id="S4.T2.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.9.9.5.1" class="ltx_text ltx_font_bold">89.16%</span></td>
<td id="S4.T2.1.9.9.6" class="ltx_td ltx_align_left ltx_border_r">89.02%</td>
<td id="S4.T2.1.9.9.7" class="ltx_td ltx_align_left ltx_border_r">89.12%</td>
<td id="S4.T2.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r">89.06%</td>
<td id="S4.T2.1.9.9.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.9.9.9.1" class="ltx_text ltx_font_bold">89.18%</span></td>
</tr>
<tr id="S4.T2.1.10.10" class="ltx_tr">
<td id="S4.T2.1.10.10.1" class="ltx_td"></td>
<td id="S4.T2.1.10.10.2" class="ltx_td"></td>
<td id="S4.T2.1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.10.10.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T2.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">85.43%</td>
<td id="S4.T2.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r">89.08%</td>
<td id="S4.T2.1.10.10.6" class="ltx_td ltx_align_left ltx_border_r">89.08%</td>
<td id="S4.T2.1.10.10.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.10.10.7.1" class="ltx_text ltx_font_bold">89.15%</span></td>
<td id="S4.T2.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r">89.11%</td>
<td id="S4.T2.1.10.10.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.10.10.9.1" class="ltx_text ltx_font_bold">89.18%</span></td>
</tr>
<tr id="S4.T2.1.11.11" class="ltx_tr">
<td id="S4.T2.1.11.11.1" class="ltx_td"></td>
<td id="S4.T2.1.11.11.2" class="ltx_td"></td>
<td id="S4.T2.1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.11.11.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T2.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">85.47%</td>
<td id="S4.T2.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.11.11.5.1" class="ltx_text ltx_font_bold">89.04%</span></td>
<td id="S4.T2.1.11.11.6" class="ltx_td ltx_align_left ltx_border_r">88.93%</td>
<td id="S4.T2.1.11.11.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.1.11.11.7.1" class="ltx_text ltx_font_bold">89.04%</span></td>
<td id="S4.T2.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r">88.98%</td>
<td id="S4.T2.1.11.11.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.11.11.9.1" class="ltx_text ltx_font_bold">89.09%</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>COMPARISON OF FEDERATED LEARNING WITH CENTRALIZED TRAINING ON SBHAR</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_align_left"><span id="S4.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Hidden Units</span></td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.3.1.1" class="ltx_p" style="width:0.0pt;"><span id="S4.T3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Metrics</span></span>
</span>
</td>
<td id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">Centralized Training &amp; Federated Learning with Five Strategies</span></td>
<td id="S4.T3.1.1.1.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.1.1.1.6" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.1.1.1.7" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.1.1.1.8" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.1.1.1.9" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="S4.T3.1.2.2" class="ltx_tr">
<td id="S4.T3.1.2.2.1" class="ltx_td"></td>
<td id="S4.T3.1.2.2.2" class="ltx_td"></td>
<td id="S4.T3.1.2.2.3" class="ltx_td ltx_align_top"></td>
<td id="S4.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.2.2.4.1" class="ltx_text ltx_font_bold ltx_font_italic">Centralized</span></td>
<td id="S4.T3.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.2.2.5.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvg</span></td>
<td id="S4.T3.1.2.2.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.2.2.6.1" class="ltx_text ltx_font_bold ltx_font_italic">FedProx</span></td>
<td id="S4.T3.1.2.2.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.2.2.7.1" class="ltx_text ltx_font_bold ltx_font_italic">FedTrimmedAvg</span></td>
<td id="S4.T3.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.2.2.8.1" class="ltx_text ltx_font_bold ltx_font_italic">Krum</span></td>
<td id="S4.T3.1.2.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.2.2.9.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvgM</span></td>
</tr>
<tr id="S4.T3.1.3.3" class="ltx_tr">
<td id="S4.T3.1.3.3.1" class="ltx_td ltx_align_center">SBHAR</td>
<td id="S4.T3.1.3.3.2" class="ltx_td ltx_align_left">128</td>
<td id="S4.T3.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.3.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T3.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r">51.65%</td>
<td id="S4.T3.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.3.3.5.1" class="ltx_text ltx_font_bold">54.27%</span></td>
<td id="S4.T3.1.3.3.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.3.3.6.1" class="ltx_text ltx_font_bold">54.20%</span></td>
<td id="S4.T3.1.3.3.7" class="ltx_td ltx_align_left ltx_border_r">54.16%</td>
<td id="S4.T3.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r">53.39%</td>
<td id="S4.T3.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r">53.51%</td>
</tr>
<tr id="S4.T3.1.4.4" class="ltx_tr">
<td id="S4.T3.1.4.4.1" class="ltx_td"></td>
<td id="S4.T3.1.4.4.2" class="ltx_td"></td>
<td id="S4.T3.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.4.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T3.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">61.59%</td>
<td id="S4.T3.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r">63.55%</td>
<td id="S4.T3.1.4.4.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.4.4.6.1" class="ltx_text ltx_font_bold">64.18%</span></td>
<td id="S4.T3.1.4.4.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.4.4.7.1" class="ltx_text ltx_font_bold">64.30%</span></td>
<td id="S4.T3.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r">63.09%</td>
<td id="S4.T3.1.4.4.9" class="ltx_td ltx_align_center ltx_border_r">63.06%</td>
</tr>
<tr id="S4.T3.1.5.5" class="ltx_tr">
<td id="S4.T3.1.5.5.1" class="ltx_td"></td>
<td id="S4.T3.1.5.5.2" class="ltx_td"></td>
<td id="S4.T3.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.5.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T3.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">53.38%</td>
<td id="S4.T3.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r">55.91%</td>
<td id="S4.T3.1.5.5.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.5.5.6.1" class="ltx_text ltx_font_bold">55.96%</span></td>
<td id="S4.T3.1.5.5.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.5.5.7.1" class="ltx_text ltx_font_bold">56.02%</span></td>
<td id="S4.T3.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r">54.93%</td>
<td id="S4.T3.1.5.5.9" class="ltx_td ltx_align_center ltx_border_r">55.11%</td>
</tr>
<tr id="S4.T3.1.6.6" class="ltx_tr">
<td id="S4.T3.1.6.6.1" class="ltx_td"></td>
<td id="S4.T3.1.6.6.2" class="ltx_td ltx_align_left">256</td>
<td id="S4.T3.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.6.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T3.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">53.08%</td>
<td id="S4.T3.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r">55.15%</td>
<td id="S4.T3.1.6.6.6" class="ltx_td ltx_align_left ltx_border_r">55.77%</td>
<td id="S4.T3.1.6.6.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.6.6.7.1" class="ltx_text ltx_font_bold">55.88%</span></td>
<td id="S4.T3.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r">55.29%</td>
<td id="S4.T3.1.6.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.6.6.9.1" class="ltx_text ltx_font_bold">55.90%</span></td>
</tr>
<tr id="S4.T3.1.7.7" class="ltx_tr">
<td id="S4.T3.1.7.7.1" class="ltx_td"></td>
<td id="S4.T3.1.7.7.2" class="ltx_td"></td>
<td id="S4.T3.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.7.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T3.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">64.53%</td>
<td id="S4.T3.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r">65.28%</td>
<td id="S4.T3.1.7.7.6" class="ltx_td ltx_align_left ltx_border_r">66.12%</td>
<td id="S4.T3.1.7.7.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.7.7.7.1" class="ltx_text ltx_font_bold">66.27%</span></td>
<td id="S4.T3.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r">65.91%</td>
<td id="S4.T3.1.7.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.7.7.9.1" class="ltx_text ltx_font_bold">66.32%</span></td>
</tr>
<tr id="S4.T3.1.8.8" class="ltx_tr">
<td id="S4.T3.1.8.8.1" class="ltx_td"></td>
<td id="S4.T3.1.8.8.2" class="ltx_td"></td>
<td id="S4.T3.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.8.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T3.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">54.97%</td>
<td id="S4.T3.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r">57.18%</td>
<td id="S4.T3.1.8.8.6" class="ltx_td ltx_align_left ltx_border_r">57.98%</td>
<td id="S4.T3.1.8.8.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.8.8.7.1" class="ltx_text ltx_font_bold">58.09%</span></td>
<td id="S4.T3.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r">57.57%</td>
<td id="S4.T3.1.8.8.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.8.8.9.1" class="ltx_text ltx_font_bold">58.12%</span></td>
</tr>
<tr id="S4.T3.1.9.9" class="ltx_tr">
<td id="S4.T3.1.9.9.1" class="ltx_td"></td>
<td id="S4.T3.1.9.9.2" class="ltx_td ltx_align_left">512</td>
<td id="S4.T3.1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.9.3.1.1" class="ltx_p" style="width:0.0pt;">Precision</span>
</span>
</td>
<td id="S4.T3.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">53.70%</td>
<td id="S4.T3.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.9.9.5.1" class="ltx_text ltx_font_bold">56.20%</span></td>
<td id="S4.T3.1.9.9.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.9.9.6.1" class="ltx_text ltx_font_bold">55.83%</span></td>
<td id="S4.T3.1.9.9.7" class="ltx_td ltx_align_left ltx_border_r">55.74%</td>
<td id="S4.T3.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r">55.32%</td>
<td id="S4.T3.1.9.9.9" class="ltx_td ltx_align_center ltx_border_r">55.72%</td>
</tr>
<tr id="S4.T3.1.10.10" class="ltx_tr">
<td id="S4.T3.1.10.10.1" class="ltx_td"></td>
<td id="S4.T3.1.10.10.2" class="ltx_td"></td>
<td id="S4.T3.1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.10.3.1.1" class="ltx_p" style="width:0.0pt;">Recall</span>
</span>
</td>
<td id="S4.T3.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">65.53%</td>
<td id="S4.T3.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.10.10.5.1" class="ltx_text ltx_font_bold">66.76%</span></td>
<td id="S4.T3.1.10.10.6" class="ltx_td ltx_align_left ltx_border_r">65.89%</td>
<td id="S4.T3.1.10.10.7" class="ltx_td ltx_align_left ltx_border_r">65.92%</td>
<td id="S4.T3.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r">65.51%</td>
<td id="S4.T3.1.10.10.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.10.10.9.1" class="ltx_text ltx_font_bold">65.99%</span></td>
</tr>
<tr id="S4.T3.1.11.11" class="ltx_tr">
<td id="S4.T3.1.11.11.1" class="ltx_td"></td>
<td id="S4.T3.1.11.11.2" class="ltx_td"></td>
<td id="S4.T3.1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.11.3.1.1" class="ltx_p" style="width:0.0pt;">F1</span>
</span>
</td>
<td id="S4.T3.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">55.87%</td>
<td id="S4.T3.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.11.11.5.1" class="ltx_text ltx_font_bold">58.55%</span></td>
<td id="S4.T3.1.11.11.6" class="ltx_td ltx_align_left ltx_border_r">57.98%</td>
<td id="S4.T3.1.11.11.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T3.1.11.11.7.1" class="ltx_text ltx_font_bold">57.90%</span></td>
<td id="S4.T3.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r">57.40%</td>
<td id="S4.T3.1.11.11.9" class="ltx_td ltx_align_center ltx_border_r">57.81%</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">Contrasting with these two datasets, the SBHAR dataset(Table III) does not show a significant improvement in recall. Notably, when employing 512 hidden layer units under Krum, there is even a slight decline of 0.02%. Specifically, in FedAvg, the recall for 128 units increased by 3.18%, for 256 by 1.16%, and for 512 by 1.87%. In FedProx, the recall enhancements for 128 and 256 hidden units are more pronounced, at 4.2% and 2.45% respectively, while the improvement for 512 units is only 0.54%. Therefore, in the SBHAR dataset, reducing the number of hidden layers significantly enhances performance improvements. This trend is also evident across different federated strategies.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>COMPARISON OF AVERAGING THREE DATASETS AND THREE TYPES OF HIDDEN UNITS</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Metrics</span></td>
<td id="S4.T4.1.1.1.2" class="ltx_td ltx_align_left"><span id="S4.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">Centralized Training &amp; Federated Learning with Five Strategies</span></td>
<td id="S4.T4.1.1.1.3" class="ltx_td ltx_align_top"></td>
<td id="S4.T4.1.1.1.4" class="ltx_td ltx_border_r"></td>
<td id="S4.T4.1.1.1.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T4.1.1.1.6" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="S4.T4.1.2.2" class="ltx_tr">
<td id="S4.T4.1.2.2.1" class="ltx_td"></td>
<td id="S4.T4.1.2.2.2" class="ltx_td ltx_align_left"><span id="S4.T4.1.2.2.2.1" class="ltx_text ltx_font_bold">FedAvg</span></td>
<td id="S4.T4.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T4.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.1.2.2.3.1.1" class="ltx_p" style="width:0.0pt;"><span id="S4.T4.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">FedProx</span></span>
</span>
</td>
<td id="S4.T4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.1.2.2.4.1" class="ltx_text ltx_font_bold">FedTrimmedAvg</span></td>
<td id="S4.T4.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T4.1.2.2.5.1" class="ltx_text ltx_font_bold">Krum</span></td>
<td id="S4.T4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.1.2.2.6.1" class="ltx_text ltx_font_bold">FedAvgM</span></td>
</tr>
<tr id="S4.T4.1.3.3" class="ltx_tr">
<td id="S4.T4.1.3.3.1" class="ltx_td ltx_align_center">Precision</td>
<td id="S4.T4.1.3.3.2" class="ltx_td ltx_align_left"><span id="S4.T4.1.3.3.2.1" class="ltx_text ltx_font_bold">4.75%</span></td>
<td id="S4.T4.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T4.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.1.3.3.3.1.1" class="ltx_p" style="width:0.0pt;">4.74%</span>
</span>
</td>
<td id="S4.T4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r">4.60%</td>
<td id="S4.T4.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r">4.65%</td>
<td id="S4.T4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r">4.65%</td>
</tr>
<tr id="S4.T4.1.4.4" class="ltx_tr">
<td id="S4.T4.1.4.4.1" class="ltx_td ltx_align_center">Recall</td>
<td id="S4.T4.1.4.4.2" class="ltx_td ltx_align_left">4.04%</td>
<td id="S4.T4.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T4.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.1.4.4.3.1.1" class="ltx_p" style="width:0.0pt;">4.13%</span>
</span>
</td>
<td id="S4.T4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T4.1.4.4.4.1" class="ltx_text ltx_font_bold">4.20</span>%</td>
<td id="S4.T4.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r">3.65%</td>
<td id="S4.T4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r">4.02%</td>
</tr>
<tr id="S4.T4.1.5.5" class="ltx_tr">
<td id="S4.T4.1.5.5.1" class="ltx_td ltx_align_center">F1</td>
<td id="S4.T4.1.5.5.2" class="ltx_td ltx_align_left">4.83%</td>
<td id="S4.T4.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T4.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.1.5.5.3.1.1" class="ltx_p" style="width:0.0pt;"><span id="S4.T4.1.5.5.3.1.1.1" class="ltx_text ltx_font_bold">4.85%</span></span>
</span>
</td>
<td id="S4.T4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">4.25%</td>
<td id="S4.T4.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r">4.25%</td>
<td id="S4.T4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r">4.72%</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">Thus far, we perform a side-by-side comparison of the experimental results, i.e., a comparison of the results of the five federated learning strategies on Precision, Recall, and F1-score based on three different hidden layer units running on three datasets. The results(Table IV) show that FedAvg improves the most significantly on Precision, i.e., 4.75%. Compared to the other strategies, FedTrimmedAvg performs best on Recall, with an improvement of 0.55 percentage points compared to Krum. And on F1-score, the best strategy for improvement was FedProx, which improved by 4.85% compared to the centralized training method.</p>
</div>
<div id="S4.p7" class="ltx_para">
<p id="S4.p7.1" class="ltx_p">In summary, regardless of the federated learning strategy adopted, results consistently outperform centralized training methods. Specifically, on the HHAR dataset with 512 hidden layer units, the five federated learning strategies yielded average improvements of 5.51% in precision, 5.52% in recall, and 5.57% in F1-score. On the RWHAR dataset with 128 hidden layer units, the strategies averaged improvements of 4.25% in precision, 4.60% in recall, and 4.46% in F1-score. Meanwhile, on the SBHAR dataset with 256 hidden layer units, the improvements were 4.76% in precision, 2.24% in recall, and 5.12% in F1-score. These results highlight nuanced variations across different federated learning strategies and datasets, influenced by the number of hidden layer units employed.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">CONCLUSION AND FUTURE WORK</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In conclusion, this paper explores federated transformation and centralized training using the single-layer LSTM architecture proposed by [12], applying the Flower framework to execute five distinct federated learning strategies across three real datasets, each with three varying sizes of hidden units (128, 256, and 512). The experimental results demonstrate that, compared to centralized training methods, the single-layer DeepConvLSTM employing federated learning exhibits improvements in Precision, Recall, and F1-Score to varying extents. Additionally, this project also conducted a horizontal comparison of performance enhancements across different federated strategies, FedAvg, FedTrimmedAvg and FedProx have different levels of improvement in Precision, Recall and F1-score evaluation criteria respectively compared to other strategies.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Furthermore, This paper has replaced the centralized global model in federated learning with a decentralized structure using Hyperledger Fabric. This adjustment not only mitigates the risk of single points of failure but also enhances the tamper-proofing and traceability of model parameters.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">In ongoing research, we aim to further bolster security and privacy in the federated learning process. On one hand, we plan to employ advanced encryption protocols, such as homomorphic encryption or secure multi-party computation, during data transmission between clients and the server to protect against theft and reverse engineering of model parameters. On the other hand, we seek to refine the consensus strategy within the server’s decentralized structure to enhance the verification efficiency and processing speed of the entire network. Through these improvements, we hope to effectively advance the application of federated learning and blockchain technologies in the wearable sector, significantly enhancing the protection of user privacy and security.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"> G. Saleem, U. I. Bajwa, and R. H. Raza, “Toward human activity recognition: a survey,” Neural Computing and Applications, Oct. 2022, doi: https://doi.org/10.1007/s00521-022-07937-4.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"> F. Ordóñez and D. Roggen, “Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition,” Sensors, vol. 16, no. 1, p. 115, Jan. 2016, doi: https://doi.org/10.3390/s16010115.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"> D. Roggen et al., “Collecting complex activity datasets in highly rich networked sensor environments,” 2010 Seventh International Conference on Networked Sensing Systems (INSS), Jun. 2010, doi: https://doi.org/10.1109/inss.2010.5573462.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"> P. Zappi et al., “Activity Recognition from On-Body Sensors: Accuracy-Power Trade-Off by Dynamic Sensor Selection,” Lecture Notes in Computer Science, pp. 17–33, doi: https://doi.org/10.1007/978-3-540-77690-1_2.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"> K. Chen, D. Zhang, L. Yao, B. Guo, Z. Yu, and Y. Liu, “Deep Learning for Sensor-based Human Activity Recognition,” ACM Computing Surveys, vol. 54, no. 4, pp. 1–40, May 2021, doi: https://doi.org/10.1145/3447744.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"> Andrej Karpathy, J. C. Johnson, and L. Fei-Fei, “Visualizing and Understanding Recurrent Networks,” arXiv (Cornell University), Jun. 2015, doi: https://doi.org/10.48550/arxiv.1506.02078.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"> M. Bock, A. Hoelzemann, M. Moeller, and K. Van Laerhoven, “Improving Deep Learning for HAR with shallow LSTMs,” arXiv.org, Sep. 21, 2021. https://arxiv.org/abs/2108.00702.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"> Y. Liu et al., “Vertical Federated Learning: Concepts, Advances, and Challenges,” IEEE transactions on knowledge and data engineering, pp. 1–20, Jan. 2024, doi: https://doi.org/10.1109/tkde.2024.3352628.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"> A. Qammar, A. Karim, H. Ning, and J. Ding, “Securing federated learning with blockchain: a systematic literature review,” Artificial Intelligence Review, Sep. 2022, doi: https://doi.org/10.1007/s10462-022-10271-9.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"> B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. Aguera y Arcas, ”Communication-Efficient Learning of Deep Networks from Decentralized Data,” in Proc. 20th Int. Conf. Artif. Intell. Statist. (AISTATS), PMLR 54, 2017, pp. 1273-1282.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"> J. Konečný, H. Mcmahan, F. Yu, A. Theertha, D. Google, and P. Richtárik, “FEDERATED LEARNING: STRATEGIES FOR IMPROVING COMMUNICATION EFFICIENCY.” Available: https://arxiv.org/pdf/1610.05492.pdf.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"> T. Li, M. Sanjabi, A. Beirami, and V. Smith, “Fair Resource Allocation in Federated Learning,” arXiv:1905.10497 [cs, stat], Feb. 2020, Available: https://arxiv.org/abs/1905.10497.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"> K. Bonawitz et al., “Practical Secure Aggregation for Privacy-Preserving Machine Learning,” Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, Oct. 2017, doi: https://doi.org/10.1145/3133956.3133982.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"> R. C. Geyer, T. Klein, and M. Nabi, “Differentially Private Federated Learning: A Client Level Perspective,” arXiv:1712.07557 [cs, stat], Mar. 2018, Available: https://arxiv.org/abs/1712.07557.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"> A. Bulling, U. Blanke, and B. Schiele, “A tutorial on human activity recognition using body-worn inertial sensors,” ACM Computing Surveys, vol. 46, no. 3, pp. 1–33, Jan. 2014, doi: https://doi.org/10.1145/2499621.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"> G. Gad and Z. Fadlullah, “Federated Learning via Augmented Knowledge Distillation for Heterogenous Deep Human Activity Recognition Systems,” Sensors, vol. 23, no. 1, p. 6, Dec. 2022, doi: https://doi.org/10.3390/s23010006.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"> Nikola Simić et al., “Enhancing Emotion Recognition through Federated Learning: A Multimodal Approach with Convolutional Neural Networks,” Applied sciences, vol. 14, no. 4, pp. 1325–1325, Feb. 2024, doi: https://doi.org/10.3390/app14041325.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"> A. Khatoon, “A Blockchain-Based Smart Contract System for Healthcare Management,” Electronics, vol. 9, no. 1, p. 94, Jan. 2020, doi: https://doi.org/10.3390/electronics9010094.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"> Q. Liu, Y. Liu, M. Luo, D. He, H. Wang, and K.-K. R. Choo, “The Security of Blockchain-Based Medical Systems: Research Challenges and Opportunities,” IEEE Systems Journal, pp. 1–12, 2022, doi: https://doi.org/10.1109/JSYST.2022.3155156.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"> D. M. Patel, C. K. Sahu, and R. Rai, “Security in modern manufacturing systems: integrating blockchain in artificial intelligence-assisted manufacturing,” International Journal of Production Research, pp. 1–31, Sep. 2023, doi: https://doi.org/10.1080/00207543.2023.2262050.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"> A. Stisen et al., “Smart Devices are Different,” Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems, Nov. 2015, doi: https://doi.org/10.1145/2809695.2809718.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"> Timo Sztyler and Heiner Stuckenschmidt, “On-body localization of wearable devices: An investigation of position-aware activity recognition,” Mar. 2016, doi: https://doi.org/10.1109/percom.2016.7456521.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"> M. Núñez-Regueiro, “Yaşlı Kadınlarda Üreme Sağlığı,” DergiPark (Istanbul University), vol. 1, no. 1, Feb. 2015, doi: https://doi.org/10.1016/j.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"> D. J. Beutel et al., “Flower: A Friendly Federated Learning Research Framework,” arXiv:2007.14390 [cs, stat], Apr. 2021, Available: https://arxiv.org/abs/2007.14390.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"> M. H. Brendan, E. Moore, D. Ramage, S. Hampson, and Arcas, Blaise Agüera y, “Communication-Efficient Learning of Deep Networks from Decentralized Data,” arXiv.org, 2016. https://arxiv.org/abs/1602.05629.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"> T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith, “Federated Optimization in Heterogeneous Networks,” arXiv:1812.06127 [cs, stat], Apr. 2020, Available: https://arxiv.org/abs/1812.06127.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"> D. Yin, Y. Chen, K. Ramchandran, and P. Bartlett, “Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,” arXiv.org, Feb. 25, 2021. https://arxiv.org/abs/1803.01498.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"> P. Blanchard, E. M. E. Mhamdi, R. Guerraoui, and J. Stainer, “Byzantine-Tolerant Machine Learning,” arXiv.org, Mar. 08, 2017. https://arxiv.org/abs/1703.02757.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"> T.-M. H. Hsu, H. Qi, and M. Brown, “Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification,” arXiv:1909.06335 [cs, stat], Sep. 2019, Available: https://arxiv.org/abs/1909.06335.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"> X. Glorot and Y. Bengio, “Understanding the difficulty of training deep feedforward neural networks,” proceedings.mlr.press, Mar. 31, 2010. http://proceedings.mlr.press/v9/glorot10a.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"> E. Androulaki et al., “Hyperledger fabric,” Proceedings of the Thirteenth EuroSys Conference on - EuroSys ’18, 2018, doi: https://doi.org/10.1145/3190508.3190538.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.21280" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.21282" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.21282">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.21282" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.21283" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 17:02:21 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
