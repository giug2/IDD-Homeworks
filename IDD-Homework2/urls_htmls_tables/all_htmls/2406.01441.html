<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation</title>
<!--Generated on Tue Jul  2 06:30:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.01441v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S1" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S2" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S2.SS0.SSS0.Px1" title="In 2 Related Work â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">Data Selection for NMT.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S2.SS0.SSS0.Px2" title="In 2 Related Work â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">LLMs for MT.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S2.SS0.SSS0.Px3" title="In 2 Related Work â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">Bilingual Dictionary for NMT.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S3" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S3.SS1" title="In 3 Method â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data Retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S3.SS2" title="In 3 Method â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Data Augmentation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S4" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Instruction Fine-tuning LLM for MT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.SS1" title="In 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Setting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.SS2" title="In 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Main Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.SS2.SSS0.Px1" title="In 5.2 Main Results â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">Seen Language Directions.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.SS2.SSS0.Px2" title="In 5.2 Main Results â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">Unseen Language Directions.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.SS2.SSS0.Px3" title="In 5.2 Main Results â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">Disambiguation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.SS2.SSS0.Px4" title="In 5.2 Main Results â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">Terminology.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.SS1" title="In 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Effect of <math alttext="K" class="ltx_Math" display="inline"><semantics><mi>K</mi><annotation-xml encoding="MathML-Content"><ci>ğ¾</ci></annotation-xml><annotation encoding="application/x-tex">K</annotation><annotation encoding="application/x-llamapun">italic_K</annotation></semantics></math></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.SS2" title="In 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Alternative Data Selection Strategies</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.SS2.SSS0.Px1" title="In 6.2 Alternative Data Selection Strategies â€£ 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title">Word Frequency Distribution</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.SS3" title="In 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.SS4" title="In 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Combination with Other LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.SS5" title="In 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>Compositional Generalization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S7" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S8" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A1" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Computational Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A2" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Prompts Used for Manipulating ChatGPT and Terminology Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A3" title="In LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Corpus Preprocessing</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document" lang="en">
<h1 class="ltx_title ltx_title_document">LexMatcher: Dictionary-centric Data Curation 
<br class="ltx_break"/>for LLM-based Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yongjing Yin<sup class="ltx_sup" id="id10.10.id1"><span class="ltx_text ltx_font_italic" id="id10.10.id1.1">1,2</span></sup>, Jiali Zeng<sup class="ltx_sup" id="id11.11.id2"><span class="ltx_text ltx_font_italic" id="id11.11.id2.1">4</span></sup>, Yafu Li<sup class="ltx_sup" id="id12.12.id3"><span class="ltx_text ltx_font_italic" id="id12.12.id3.1">2</span></sup>, Fandong Meng<sup class="ltx_sup" id="id13.13.id4"><span class="ltx_text ltx_font_italic" id="id13.13.id4.1">4</span></sup>, Yue Zhang<sup class="ltx_sup" id="id14.14.id5"><span class="ltx_text ltx_font_italic" id="id14.14.id5.1">2,3</span></sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.id6"><span class="ltx_text ltx_font_italic" id="id15.15.id6.1">1</span></sup>Zhejiang University 
<br class="ltx_break"/><sup class="ltx_sup" id="id16.16.id7"><span class="ltx_text ltx_font_italic" id="id16.16.id7.1">2</span></sup>School of Engineering, Westlake University 
<br class="ltx_break"/><sup class="ltx_sup" id="id17.17.id8"><span class="ltx_text ltx_font_italic" id="id17.17.id8.1">3</span></sup>Institute of Advanced Technology, Westlake Institute for Advanced Study
<br class="ltx_break"/><sup class="ltx_sup" id="id18.18.id9"><span class="ltx_text ltx_font_italic" id="id18.18.id9.1">4</span></sup>Pattern Recognition Center, WeChat AI, Tencent Inc 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id19.19.id10">{yinyongjing,liyafu}@westlake.edu.cn</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id20.20.id11">{lemonzeng,fandongmeng}@tencent.com</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id21.21.id12">yue.zhang@wias.org.cn </span>
</span><span class="ltx_author_notes">Corresponding author</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id22.id1"><span class="ltx_text" id="id22.id1.1">The fine-tuning of open-source large language models (LLMs) for machine translation has recently received considerable attention, marking a shift towards data-centric research from traditional neural machine translation.
However, the area of data collection for instruction fine-tuning in machine translation remains relatively underexplored.
In this paper, we present LexMatcher, a simple yet effective method for data curation,
the design of which is driven by the coverage of senses found in bilingual dictionaries.
The construction process comprises data retrieval from an existing corpus and data augmentation that supplements the infrequent senses of polysemous words.
Utilizing LLaMA2 as our base model, our approach outperforms the established baselines on the WMT2022 test sets and also exhibits remarkable performance in tasks related to word sense disambiguation and specialized terminology translation.
These results underscore the effectiveness of LexMatcher in enhancing LLM-based machine translation.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.9">
<p class="ltx_p" id="p1.9.10"><span class="ltx_text ltx_font_bold" id="p1.9.10.1">LexMatcher: Dictionary-centric Data Curation 
<br class="ltx_break"/>for LLM-based Machine Translation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.9.9" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.9.9.9" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.9.9.9.9">
<span class="ltx_tr" id="p1.5.5.5.5.5">
<span class="ltx_td ltx_align_center" id="p1.5.5.5.5.5.5"><span class="ltx_text ltx_font_bold" id="p1.5.5.5.5.5.5.5">Yongjing Yin<sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.1.1">1,2</span></sup>, Jiali Zeng<sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.2"><span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.2.1">4</span></sup>, Yafu Li<sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.3"><span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.3.1">2</span></sup>, Fandong Meng<sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.4"><span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.4.1">4</span></sup>, Yue Zhang<math alttext="{}^{2,3}\lx@make@thanks{Correspondingauthor}" class="ltx_Math" display="inline" id="p1.5.5.5.5.5.5.5.m5.2"><semantics id="p1.5.5.5.5.5.5.5.m5.2a"><mmultiscripts id="p1.5.5.5.5.5.5.5.m5.2.3" xref="p1.5.5.5.5.5.5.5.m5.2.3.cmml"><mtext class="ltx_mathvariant_bold" id="p1.5.5.5.5.5.5.5.m5.2.3.2" xref="p1.5.5.5.5.5.5.5.m5.2.3.2u.cmml"><span class="ltx_note ltx_role_thanks" id="p1.5.5.5.5.5.5.5.m5.2.3.2.1nest"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>Correspondingauthor</span></span></span></mtext><mprescripts id="p1.5.5.5.5.5.5.5.m5.2.3a" xref="p1.5.5.5.5.5.5.5.m5.2.3.cmml"></mprescripts><mrow id="p1.5.5.5.5.5.5.5.m5.2.3b" xref="p1.5.5.5.5.5.5.5.m5.2.3.cmml"></mrow><mrow id="p1.5.5.5.5.5.5.5.m5.2.2.2.4" xref="p1.5.5.5.5.5.5.5.m5.2.2.2.3.cmml"><mn id="p1.5.5.5.5.5.5.5.m5.1.1.1.1" xref="p1.5.5.5.5.5.5.5.m5.1.1.1.1.cmml">2</mn><mo id="p1.5.5.5.5.5.5.5.m5.2.2.2.4.1" xref="p1.5.5.5.5.5.5.5.m5.2.2.2.3.cmml">,</mo><mn id="p1.5.5.5.5.5.5.5.m5.2.2.2.2" xref="p1.5.5.5.5.5.5.5.m5.2.2.2.2.cmml">3</mn></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="p1.5.5.5.5.5.5.5.m5.2b"><apply id="p1.5.5.5.5.5.5.5.m5.2.3.cmml" xref="p1.5.5.5.5.5.5.5.m5.2.3"><csymbol cd="ambiguous" id="p1.5.5.5.5.5.5.5.m5.2.3.1.cmml" xref="p1.5.5.5.5.5.5.5.m5.2.3">superscript</csymbol><ci id="p1.5.5.5.5.5.5.5.m5.2.3.2u.cmml" xref="p1.5.5.5.5.5.5.5.m5.2.3.2"><mtext class="ltx_mathvariant_bold" id="p1.5.5.5.5.5.5.5.m5.2.3.2.cmml" xref="p1.5.5.5.5.5.5.5.m5.2.3.2"><span class="ltx_note ltx_role_thanks" id="p1.5.5.5.5.5.5.5.m5.2.3.2.1anest"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>Correspondingauthor</span></span></span></mtext></ci><list id="p1.5.5.5.5.5.5.5.m5.2.2.2.3.cmml" xref="p1.5.5.5.5.5.5.5.m5.2.2.2.4"><cn id="p1.5.5.5.5.5.5.5.m5.1.1.1.1.cmml" type="integer" xref="p1.5.5.5.5.5.5.5.m5.1.1.1.1">2</cn><cn id="p1.5.5.5.5.5.5.5.m5.2.2.2.2.cmml" type="integer" xref="p1.5.5.5.5.5.5.5.m5.2.2.2.2">3</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.5.5.5.5.5.5.5.m5.2c">{}^{2,3}\lx@make@thanks{Correspondingauthor}</annotation><annotation encoding="application/x-llamapun" id="p1.5.5.5.5.5.5.5.m5.2d">start_FLOATSUPERSCRIPT 2 , 3 end_FLOATSUPERSCRIPT Correspondingauthor</annotation></semantics></math></span></span></span>
<span class="ltx_tr" id="p1.6.6.6.6.6">
<span class="ltx_td ltx_align_center" id="p1.6.6.6.6.6.1"><sup class="ltx_sup" id="p1.6.6.6.6.6.1.1"><span class="ltx_text ltx_font_italic" id="p1.6.6.6.6.6.1.1.1">1</span></sup>Zhejiang University</span></span>
<span class="ltx_tr" id="p1.7.7.7.7.7">
<span class="ltx_td ltx_align_center" id="p1.7.7.7.7.7.1"><sup class="ltx_sup" id="p1.7.7.7.7.7.1.1"><span class="ltx_text ltx_font_italic" id="p1.7.7.7.7.7.1.1.1">2</span></sup>School of Engineering, Westlake University</span></span>
<span class="ltx_tr" id="p1.8.8.8.8.8">
<span class="ltx_td ltx_align_center" id="p1.8.8.8.8.8.1"><sup class="ltx_sup" id="p1.8.8.8.8.8.1.1"><span class="ltx_text ltx_font_italic" id="p1.8.8.8.8.8.1.1.1">3</span></sup>Institute of Advanced Technology, Westlake Institute for Advanced Study</span></span>
<span class="ltx_tr" id="p1.9.9.9.9.9">
<span class="ltx_td ltx_align_center" id="p1.9.9.9.9.9.1"><sup class="ltx_sup" id="p1.9.9.9.9.9.1.1"><span class="ltx_text ltx_font_italic" id="p1.9.9.9.9.9.1.1.1">4</span></sup>Pattern Recognition Center, WeChat AI, Tencent Inc</span></span>
<span class="ltx_tr" id="p1.9.9.9.9.10">
<span class="ltx_td ltx_align_center" id="p1.9.9.9.9.10.1"><span class="ltx_text ltx_font_typewriter" id="p1.9.9.9.9.10.1.1">{yinyongjing,liyafu}@westlake.edu.cn</span></span></span>
<span class="ltx_tr" id="p1.9.9.9.9.11">
<span class="ltx_td ltx_align_center" id="p1.9.9.9.9.11.1"><span class="ltx_text ltx_font_typewriter" id="p1.9.9.9.9.11.1.1">{lemonzeng,fandongmeng}@tencent.com</span></span></span>
<span class="ltx_tr" id="p1.9.9.9.9.12">
<span class="ltx_td ltx_align_center" id="p1.9.9.9.9.12.1"><span class="ltx_text ltx_font_typewriter" id="p1.9.9.9.9.12.1.1">yue.zhang@wias.org.cn</span></span></span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">{CJK}</span>
<p class="ltx_p" id="p2.2">UTF8gbsn</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The emergence of large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">Brown etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib3" title="">2020</a>); Touvron etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib30" title="">2023b</a>); OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib23" title="">2023</a>)</cite> has brought about new opportunities for machine translation
and improving the translation performance of smaller-sized LLMs (7B or 13B) has attracted a lot of attention <cite class="ltx_cite ltx_citemacro_cite">Jiao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib13" title="">2023</a>); Zeng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib36" title="">2024</a>); Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib38" title="">2023</a>); Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>.
Unlike traditional neural machine translation (NMT)
which relies heavily on abundant parallel data <cite class="ltx_cite ltx_citemacro_cite">Sennrich etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib28" title="">2016</a>); Edunov etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib5" title="">2018</a>); Gordon etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib8" title="">2021</a>); Fernandes etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib6" title="">2023</a>)</cite>.
LLMs have demonstrated less dependency on vast amounts of supervised data to achieve competitive performance.
Similar to other tasks by LLMs <cite class="ltx_cite ltx_citemacro_cite">Zhou etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib40" title="">2023</a>); Gunasekar etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib9" title="">2023</a>)</cite>, the quality of fine-tuning data plays a more crucial role in NMT <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib38" title="">2023</a>); Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Current work primarily focuses on constructing fine-tuning data by leveraging human-written development sets, and creating refined instruction data for special purposes such as contrastive translation pairs and interactive translation <cite class="ltx_cite ltx_citemacro_cite">Zeng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib36" title="">2024</a>); Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib38" title="">2023</a>)</cite>.
However, these methods do not fully exploit the potentially valuable information embedded within the existing large parallel corpus.
It has been demonstrated that fine-tuning LLMs with extensive parallel data can impair their inherent translation capabilities <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>.
Moreover, the quality of data distributions has been emphasized to have a more significant impact on the model performance than quantity alone <cite class="ltx_cite ltx_citemacro_cite">Gunasekar etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib9" title="">2023</a>); Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib17" title="">2023</a>)</cite>, with more uniform data distributions contributing to improved generalization for unseen compositions <cite class="ltx_cite ltx_citemacro_cite">Patel etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib25" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Motivated by the above observations, we investigate a principled method, LexMatcher, for curating supervised fine-tuning data for LLM-based translation.
The objective is to collect a small yet carefully selected dataset that follows a proper distribution for maximizing translation quality.
To this end, we leverage a bilingual dictionary as a pivotal resource to ensure comprehensive coverage of word or phrase senses in bilingual contexts.
The construction of the dataset involves two steps: data retrieval and data augmentation.
In the data retrieval step, we traverse commonly-used corpora (e.g., WMT training data) and <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">identify</span> sentence pairs that are guided by the coverage of dictionary senses.
Inevitably, however, there may be uncovered senses of polysemous words,
representing long-tail knowledge essential for accurate translation.
In the data augmentation step, we employ a commercial LLM (e.g., ChatGPT) to <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">generate</span> precise and concise sentence pairs that contain the uncovered senses.
Finally, we fine-tune LLMs using a combination of the retrieved and generated data.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.3">We conduct extensive experiments on six language directions including Zh<math alttext="\Leftrightarrow" class="ltx_Math" display="inline" id="S1.p4.1.m1.1"><semantics id="S1.p4.1.m1.1a"><mo id="S1.p4.1.m1.1.1" stretchy="false" xref="S1.p4.1.m1.1.1.cmml">â‡”</mo><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">â‡”</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">\Leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S1.p4.1.m1.1d">â‡”</annotation></semantics></math>En, En<math alttext="\Leftrightarrow" class="ltx_Math" display="inline" id="S1.p4.2.m2.1"><semantics id="S1.p4.2.m2.1a"><mo id="S1.p4.2.m2.1.1" stretchy="false" xref="S1.p4.2.m2.1.1.cmml">â‡”</mo><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><ci id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1">â‡”</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">\Leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S1.p4.2.m2.1d">â‡”</annotation></semantics></math>De, and En<math alttext="\Leftrightarrow" class="ltx_Math" display="inline" id="S1.p4.3.m3.1"><semantics id="S1.p4.3.m3.1a"><mo id="S1.p4.3.m3.1.1" stretchy="false" xref="S1.p4.3.m3.1.1.cmml">â‡”</mo><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><ci id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1">â‡”</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">\Leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S1.p4.3.m3.1d">â‡”</annotation></semantics></math>Ru.
By employing LexMatcher, we extract 0.1% of the WMT data, totaling
1 million samples across all six language directions.
Results of fine-tuned LLMs on the test sets show the superiority of our method over the baselines in both standard and zero-shot settings.
The fine-tuned models also achieve comparable or better performance in terminology translation and translation disambiguation compared to the dedicated or commercial systems.
Further analyses of different data collection methods and composition generalization underscore the significance of high-quality data distributions.
We will release the code, data, and models upon acceptance.
</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Data Selection for NMT.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">For traditional neural machine translation models, augmenting the volume of parallel data often leads to improvements in performance <cite class="ltx_cite ltx_citemacro_cite">Sennrich etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib28" title="">2016</a>); Edunov etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib5" title="">2018</a>); Gordon etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib8" title="">2021</a>); Fernandes etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib6" title="">2023</a>)</cite>.
Conversely, there have also been studies exploring data selection to reduce the size of the training corpus.
For instance, <cite class="ltx_cite ltx_citemacro_citet">vanÂ der Wees etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib31" title="">2017</a>)</cite> gradually reduces the training data to a cleaner subset, determined by external scorers.
<cite class="ltx_cite ltx_citemacro_citet">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib33" title="">2018</a>)</cite> introduce curriculum-based data selection that employs a trusted clean dataset to assess the noise level of each sample.
<cite class="ltx_cite ltx_citemacro_citet">Kumar etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib14" title="">2019</a>)</cite> employ reinforcement learning to simultaneously learn a denoising curriculum and improve the NMT model.
<cite class="ltx_cite ltx_citemacro_citet">Mohiuddin etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib22" title="">2022</a>)</cite> initially train a base NMT model on the entire available data and subsequently fine-tune the base model using selected subsets.
Compared to traditional NMT, data curation is more critical for LLM-based MT, for which we make the first investigation by proposing a simple and practical method.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">LLMs for MT.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">The usage of LLM-based MT is significantly different from the conventional NMT.
LLMs, particularly large ones like GPT-4, serve as interfaces that can perform translation with simple translation instructions or in-context learning (ICL) <cite class="ltx_cite ltx_citemacro_cite">Lin etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib18" title="">2022</a>); Hendy etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib10" title="">2023</a>); Zhu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib41" title="">2023</a>); Agrawal etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib1" title="">2022</a>)</cite>.
For ICL, the influence of data selection methods on model performance is not significantly noticeable <cite class="ltx_cite ltx_citemacro_cite">Zhu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib41" title="">2023</a>); Agrawal etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib1" title="">2022</a>); Lin etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib18" title="">2022</a>)</cite>.
Fine-tuning smaller-sized LLMs such as LLaMA <cite class="ltx_cite ltx_citemacro_cite">Touvron etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib29" title="">2023a</a>)</cite> for translation has garnered increasing attention <cite class="ltx_cite ltx_citemacro_cite">Jiao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib13" title="">2023</a>); Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib38" title="">2023</a>)</cite>,
which has the potential to achieve an improved trade-off between quality and efficiency.
TIM <cite class="ltx_cite ltx_citemacro_cite">Zeng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib36" title="">2024</a>)</cite> constructs translation pairs for comparison and introduces an additional preference loss.
Bayling <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib38" title="">2023</a>)</cite> automatically generates interactive translation instructions.
<cite class="ltx_cite ltx_citemacro_citet">Mao and Yu (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib20" title="">2024</a>)</cite> construct an additional cross-lingual discrimination task using word alignment for low-resource languages.
<cite class="ltx_cite ltx_citemacro_citet">Yang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib35" title="">2023</a>)</cite> fine-tune LLMs using more than 300 million parallel instances while <cite class="ltx_cite ltx_citemacro_citet">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite> indicate that such strategy could potentially impair the translation capabilities of LLMs.
Instead, they propose a two-stage process that involves further post-training LLMs using a substantial amount of mixed monolingual data, followed by a subsequent step of fine-tuning with human-written parallel data.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">In line with the above efforts, we also aim to improve the open-source LLMs.
The difference is that we propose specific parallel data collection methods, following the principle of achieving uniform coverage of semantic units in the dictionary.
Moreover, our approach achieves a better balance between efficiency and performance, and we can obtain a high-quality translation model using fewer computational resources compared to continual pretraining.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Bilingual Dictionary for NMT.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Bilingual dictionaries have been employed to enhance translation quality, particularly for rare words or domain-specific entities.
One approach involves augmenting the training data with pseudo-parallel sentences generated based on the dictionary.
For example, <cite class="ltx_cite ltx_citemacro_citet">Zhao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib39" title="">2020</a>)</cite> enhance the parallel corpus with the help of paired entities extracted from multilingual knowledge graphs.
<cite class="ltx_cite ltx_citemacro_citet">Hu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib11" title="">2022</a>)</cite> propose denoising entity pretraining for NMT using monolingual data and paired entities.
These methods do not consult bilingual dictionaries for translation candidates during the inference stage.
Another approach involves leveraging bilingual alignments as lexical constraints <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib16" title="">2022</a>); Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib32" title="">2022</a>); Zeng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib37" title="">2023</a>)</cite>.
For LLMs, bilingual dictionaries have been used as a part of prompts <cite class="ltx_cite ltx_citemacro_cite">Lu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib19" title="">2023</a>); Ghazvininejad etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib7" title="">2023</a>)</cite> for the LLMs of more than 100B.
In contrast, we aim to improve LLMsâ€™ fine-tuning performance on translation tasks. The dictionaries serve as a pivot for data collection and can also be added in prompts when needed.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="837" id="S2.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Illustration of our LexMatcher for instruction fine-tuning smaller LLMs (e.g., LLaMA).
</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The overview of LexMatcher is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S2.F1" title="Figure 1 â€£ Bilingual Dictionary for NMT. â€£ 2 Related Work â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>, which takes data retrieval (Â§<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S3.SS1" title="3.1 Data Retrieval â€£ 3 Method â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">3.1</span></a>) and data augmentation (Â§<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S3.SS2" title="3.2 Data Augmentation â€£ 3 Method â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">3.2</span></a>) steps for curating a compact parallel dataset for instruction fine-tuning.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Retrieval</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.7">Given a dictionary <math alttext="\Phi={(s,t)}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.2"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3" xref="S3.SS1.p1.1.m1.2.3.cmml"><mi id="S3.SS1.p1.1.m1.2.3.2" mathvariant="normal" xref="S3.SS1.p1.1.m1.2.3.2.cmml">Î¦</mi><mo id="S3.SS1.p1.1.m1.2.3.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.2.3.3.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml"><mo id="S3.SS1.p1.1.m1.2.3.3.2.1" stretchy="false" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">s</mi><mo id="S3.SS1.p1.1.m1.2.3.3.2.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">t</mi><mo id="S3.SS1.p1.1.m1.2.3.3.2.3" stretchy="false" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.3"><eq id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.1"></eq><ci id="S3.SS1.p1.1.m1.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.3.2">Î¦</ci><interval closure="open" id="S3.SS1.p1.1.m1.2.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.2"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘ </ci><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">\Phi={(s,t)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.2d">roman_Î¦ = ( italic_s , italic_t )</annotation></semantics></math>, where <math alttext="\Phi=\{(s_{1},t_{1}),(s_{2},t_{2}),\ldots,(s_{n},t_{n})\}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.4"><semantics id="S3.SS1.p1.2.m2.4a"><mrow id="S3.SS1.p1.2.m2.4.4" xref="S3.SS1.p1.2.m2.4.4.cmml"><mi id="S3.SS1.p1.2.m2.4.4.5" mathvariant="normal" xref="S3.SS1.p1.2.m2.4.4.5.cmml">Î¦</mi><mo id="S3.SS1.p1.2.m2.4.4.4" xref="S3.SS1.p1.2.m2.4.4.4.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.4.4.3.3" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml"><mo id="S3.SS1.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">{</mo><mrow id="S3.SS1.p1.2.m2.2.2.1.1.1.2" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml"><mo id="S3.SS1.p1.2.m2.2.2.1.1.1.2.3" stretchy="false" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml">(</mo><msub id="S3.SS1.p1.2.m2.2.2.1.1.1.1.1" xref="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.2.cmml">s</mi><mn id="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.2.m2.2.2.1.1.1.2.4" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml">,</mo><msub id="S3.SS1.p1.2.m2.2.2.1.1.1.2.2" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.cmml"><mi id="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.2" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.2.cmml">t</mi><mn id="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.3" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S3.SS1.p1.2.m2.2.2.1.1.1.2.5" stretchy="false" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml">)</mo></mrow><mo id="S3.SS1.p1.2.m2.4.4.3.3.5" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><mrow id="S3.SS1.p1.2.m2.3.3.2.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml"><mo id="S3.SS1.p1.2.m2.3.3.2.2.2.2.3" stretchy="false" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml">(</mo><msub id="S3.SS1.p1.2.m2.3.3.2.2.2.1.1" xref="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.2.cmml">s</mi><mn id="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.3" xref="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.3.cmml">2</mn></msub><mo id="S3.SS1.p1.2.m2.3.3.2.2.2.2.4" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.2.m2.3.3.2.2.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.2.cmml">t</mi><mn id="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.2.m2.3.3.2.2.2.2.5" stretchy="false" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml">)</mo></mrow><mo id="S3.SS1.p1.2.m2.4.4.3.3.6" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><mi id="S3.SS1.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS1.p1.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS1.p1.2.m2.4.4.3.3.7" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><mrow id="S3.SS1.p1.2.m2.4.4.3.3.3.2" xref="S3.SS1.p1.2.m2.4.4.3.3.3.3.cmml"><mo id="S3.SS1.p1.2.m2.4.4.3.3.3.2.3" stretchy="false" xref="S3.SS1.p1.2.m2.4.4.3.3.3.3.cmml">(</mo><msub id="S3.SS1.p1.2.m2.4.4.3.3.3.1.1" xref="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.cmml"><mi id="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.2" xref="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.2.cmml">s</mi><mi id="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.3" xref="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.3.cmml">n</mi></msub><mo id="S3.SS1.p1.2.m2.4.4.3.3.3.2.4" xref="S3.SS1.p1.2.m2.4.4.3.3.3.3.cmml">,</mo><msub id="S3.SS1.p1.2.m2.4.4.3.3.3.2.2" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.cmml"><mi id="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.2" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.2.cmml">t</mi><mi id="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.3" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.3.cmml">n</mi></msub><mo id="S3.SS1.p1.2.m2.4.4.3.3.3.2.5" stretchy="false" xref="S3.SS1.p1.2.m2.4.4.3.3.3.3.cmml">)</mo></mrow><mo id="S3.SS1.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.4b"><apply id="S3.SS1.p1.2.m2.4.4.cmml" xref="S3.SS1.p1.2.m2.4.4"><eq id="S3.SS1.p1.2.m2.4.4.4.cmml" xref="S3.SS1.p1.2.m2.4.4.4"></eq><ci id="S3.SS1.p1.2.m2.4.4.5.cmml" xref="S3.SS1.p1.2.m2.4.4.5">Î¦</ci><set id="S3.SS1.p1.2.m2.4.4.3.4.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3"><interval closure="open" id="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2"><apply id="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.2">ğ‘ </ci><cn id="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.2">ğ‘¡</ci><cn id="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.2.3">1</cn></apply></interval><interval closure="open" id="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2"><apply id="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.2">ğ‘ </ci><cn id="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.3.3.2.2.2.1.1.3">2</cn></apply><apply id="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.2">ğ‘¡</ci><cn id="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.2.3">2</cn></apply></interval><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">â€¦</ci><interval closure="open" id="S3.SS1.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2"><apply id="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.1.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.2.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.2">ğ‘ </ci><ci id="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.1.1.3">ğ‘›</ci></apply><apply id="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.1.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.2.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.2">ğ‘¡</ci><ci id="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.2.3">ğ‘›</ci></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.4c">\Phi=\{(s_{1},t_{1}),(s_{2},t_{2}),\ldots,(s_{n},t_{n})\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.4d">roman_Î¦ = { ( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , ( italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , â€¦ , ( italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) }</annotation></semantics></math> and each <math alttext="(s_{i},t_{i})" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.2"><semantics id="S3.SS1.p1.3.m3.2a"><mrow id="S3.SS1.p1.3.m3.2.2.2" xref="S3.SS1.p1.3.m3.2.2.3.cmml"><mo id="S3.SS1.p1.3.m3.2.2.2.3" stretchy="false" xref="S3.SS1.p1.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS1.p1.3.m3.1.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.1.1.2" xref="S3.SS1.p1.3.m3.1.1.1.1.2.cmml">s</mi><mi id="S3.SS1.p1.3.m3.1.1.1.1.3" xref="S3.SS1.p1.3.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p1.3.m3.2.2.2.4" xref="S3.SS1.p1.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.3.m3.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS1.p1.3.m3.2.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.2.cmml">t</mi><mi id="S3.SS1.p1.3.m3.2.2.2.2.3" xref="S3.SS1.p1.3.m3.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS1.p1.3.m3.2.2.2.5" stretchy="false" xref="S3.SS1.p1.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.2b"><interval closure="open" id="S3.SS1.p1.3.m3.2.2.3.cmml" xref="S3.SS1.p1.3.m3.2.2.2"><apply id="S3.SS1.p1.3.m3.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2">ğ‘ </ci><ci id="S3.SS1.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS1.p1.3.m3.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2">ğ‘¡</ci><ci id="S3.SS1.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.3">ğ‘–</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.2c">(s_{i},t_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.2d">( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> represents a source-target segment pair, we aim to ground each pair in parallel contexts by retrieving data from a bilingual parallel dataset <math alttext="D=\{(x,y)\}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.3"><semantics id="S3.SS1.p1.4.m4.3a"><mrow id="S3.SS1.p1.4.m4.3.3" xref="S3.SS1.p1.4.m4.3.3.cmml"><mi id="S3.SS1.p1.4.m4.3.3.3" xref="S3.SS1.p1.4.m4.3.3.3.cmml">D</mi><mo id="S3.SS1.p1.4.m4.3.3.2" xref="S3.SS1.p1.4.m4.3.3.2.cmml">=</mo><mrow id="S3.SS1.p1.4.m4.3.3.1.1" xref="S3.SS1.p1.4.m4.3.3.1.2.cmml"><mo id="S3.SS1.p1.4.m4.3.3.1.1.2" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.1.2.cmml">{</mo><mrow id="S3.SS1.p1.4.m4.3.3.1.1.1.2" xref="S3.SS1.p1.4.m4.3.3.1.1.1.1.cmml"><mo id="S3.SS1.p1.4.m4.3.3.1.1.1.2.1" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.1.1.1.1.cmml">(</mo><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">x</mi><mo id="S3.SS1.p1.4.m4.3.3.1.1.1.2.2" xref="S3.SS1.p1.4.m4.3.3.1.1.1.1.cmml">,</mo><mi id="S3.SS1.p1.4.m4.2.2" xref="S3.SS1.p1.4.m4.2.2.cmml">y</mi><mo id="S3.SS1.p1.4.m4.3.3.1.1.1.2.3" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS1.p1.4.m4.3.3.1.1.3" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.3b"><apply id="S3.SS1.p1.4.m4.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3"><eq id="S3.SS1.p1.4.m4.3.3.2.cmml" xref="S3.SS1.p1.4.m4.3.3.2"></eq><ci id="S3.SS1.p1.4.m4.3.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3.3">ğ·</ci><set id="S3.SS1.p1.4.m4.3.3.1.2.cmml" xref="S3.SS1.p1.4.m4.3.3.1.1"><interval closure="open" id="S3.SS1.p1.4.m4.3.3.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.3.3.1.1.1.2"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ‘¥</ci><ci id="S3.SS1.p1.4.m4.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2">ğ‘¦</ci></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.3c">D=\{(x,y)\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.3d">italic_D = { ( italic_x , italic_y ) }</annotation></semantics></math>.
The dictionary <math alttext="\Phi" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" mathvariant="normal" xref="S3.SS1.p1.5.m5.1.1.cmml">Î¦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">Î¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\Phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">roman_Î¦</annotation></semantics></math> shares the same source and target languages with <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_D</annotation></semantics></math>.
The segments can be words (e.g., â€œcountryâ€), phrases (e.g., â€œtake overâ€), or named entities (e.g., â€œWorld Trade Organizationâ€) in the dictionary.
Ideally, the objective is to find a subset <math alttext="S_{r}\subseteq D" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><msub id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2.2" xref="S3.SS1.p1.7.m7.1.1.2.2.cmml">S</mi><mi id="S3.SS1.p1.7.m7.1.1.2.3" xref="S3.SS1.p1.7.m7.1.1.2.3.cmml">r</mi></msub><mo id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">âŠ†</mo><mi id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><subset id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></subset><apply id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.2.1.cmml" xref="S3.SS1.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2.2">ğ‘†</ci><ci id="S3.SS1.p1.7.m7.1.1.2.3.cmml" xref="S3.SS1.p1.7.m7.1.1.2.3">ğ‘Ÿ</ci></apply><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">S_{r}\subseteq D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT âŠ† italic_D</annotation></semantics></math> such that:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\forall(s,t)\in\Phi,\exists(x,y)\in S_{r}:s\subseteq x\wedge t\subseteq y," class="ltx_Math" display="block" id="S3.E1.m1.5"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.2.2" xref="S3.E1.m1.5.5.1.1.2.3.cmml"><mrow id="S3.E1.m1.5.5.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.5.5.1.1.1.1.1.2.1" xref="S3.E1.m1.5.5.1.1.1.1.1.2.1.cmml">âˆ€</mo><mrow id="S3.E1.m1.5.5.1.1.1.1.1.2.2.2" xref="S3.E1.m1.5.5.1.1.1.1.1.2.2.1.cmml"><mo id="S3.E1.m1.5.5.1.1.1.1.1.2.2.2.1" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.1.2.2.1.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">s</mi><mo id="S3.E1.m1.5.5.1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.5.5.1.1.1.1.1.2.2.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">t</mi><mo id="S3.E1.m1.5.5.1.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.1.2.2.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml">âˆˆ</mo><mi id="S3.E1.m1.5.5.1.1.1.1.1.3" mathvariant="normal" xref="S3.E1.m1.5.5.1.1.1.1.1.3.cmml">Î¦</mi></mrow><mo id="S3.E1.m1.5.5.1.1.2.2.3" xref="S3.E1.m1.5.5.1.1.2.3a.cmml">,</mo><mrow id="S3.E1.m1.5.5.1.1.2.2.2" xref="S3.E1.m1.5.5.1.1.2.2.2.cmml"><mrow id="S3.E1.m1.5.5.1.1.2.2.2.2" xref="S3.E1.m1.5.5.1.1.2.2.2.2.cmml"><mo id="S3.E1.m1.5.5.1.1.2.2.2.2.1" xref="S3.E1.m1.5.5.1.1.2.2.2.2.1.cmml">âˆƒ</mo><mrow id="S3.E1.m1.5.5.1.1.2.2.2.2.2.2" xref="S3.E1.m1.5.5.1.1.2.2.2.2.2.1.cmml"><mo id="S3.E1.m1.5.5.1.1.2.2.2.2.2.2.1" stretchy="false" xref="S3.E1.m1.5.5.1.1.2.2.2.2.2.1.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">x</mi><mo id="S3.E1.m1.5.5.1.1.2.2.2.2.2.2.2" xref="S3.E1.m1.5.5.1.1.2.2.2.2.2.1.cmml">,</mo><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">y</mi><mo id="S3.E1.m1.5.5.1.1.2.2.2.2.2.2.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.2.2.2.2.2.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.2.2.2.1" xref="S3.E1.m1.5.5.1.1.2.2.2.1.cmml">âˆˆ</mo><msub id="S3.E1.m1.5.5.1.1.2.2.2.3" xref="S3.E1.m1.5.5.1.1.2.2.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.2.2.2.3.2" xref="S3.E1.m1.5.5.1.1.2.2.2.3.2.cmml">S</mi><mi id="S3.E1.m1.5.5.1.1.2.2.2.3.3" xref="S3.E1.m1.5.5.1.1.2.2.2.3.3.cmml">r</mi></msub></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.3" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.5.5.1.1.3.cmml">:</mo><mrow id="S3.E1.m1.5.5.1.1.4" xref="S3.E1.m1.5.5.1.1.4.cmml"><mi id="S3.E1.m1.5.5.1.1.4.2" xref="S3.E1.m1.5.5.1.1.4.2.cmml">s</mi><mo id="S3.E1.m1.5.5.1.1.4.3" xref="S3.E1.m1.5.5.1.1.4.3.cmml">âŠ†</mo><mrow id="S3.E1.m1.5.5.1.1.4.4" xref="S3.E1.m1.5.5.1.1.4.4.cmml"><mi id="S3.E1.m1.5.5.1.1.4.4.2" xref="S3.E1.m1.5.5.1.1.4.4.2.cmml">x</mi><mo id="S3.E1.m1.5.5.1.1.4.4.1" xref="S3.E1.m1.5.5.1.1.4.4.1.cmml">âˆ§</mo><mi id="S3.E1.m1.5.5.1.1.4.4.3" xref="S3.E1.m1.5.5.1.1.4.4.3.cmml">t</mi></mrow><mo id="S3.E1.m1.5.5.1.1.4.5" xref="S3.E1.m1.5.5.1.1.4.5.cmml">âŠ†</mo><mi id="S3.E1.m1.5.5.1.1.4.6" xref="S3.E1.m1.5.5.1.1.4.6.cmml">y</mi></mrow></mrow><mo id="S3.E1.m1.5.5.1.2" xref="S3.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.1.1.cmml" xref="S3.E1.m1.5.5.1"><ci id="S3.E1.m1.5.5.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3">:</ci><apply id="S3.E1.m1.5.5.1.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.3a.cmml" xref="S3.E1.m1.5.5.1.1.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.5.5.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1"><in id="S3.E1.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1"></in><apply id="S3.E1.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.2"><csymbol cd="latexml" id="S3.E1.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.2.1">for-all</csymbol><interval closure="open" id="S3.E1.m1.5.5.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.2.2.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ‘ </ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğ‘¡</ci></interval></apply><ci id="S3.E1.m1.5.5.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.3">Î¦</ci></apply><apply id="S3.E1.m1.5.5.1.1.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2"><in id="S3.E1.m1.5.5.1.1.2.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.1"></in><apply id="S3.E1.m1.5.5.1.1.2.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.2"><exists id="S3.E1.m1.5.5.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.2.1"></exists><interval closure="open" id="S3.E1.m1.5.5.1.1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.2.2.2"><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">ğ‘¥</ci><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">ğ‘¦</ci></interval></apply><apply id="S3.E1.m1.5.5.1.1.2.2.2.3.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.2.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.2.2.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.3.2">ğ‘†</ci><ci id="S3.E1.m1.5.5.1.1.2.2.2.3.3.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2.3.3">ğ‘Ÿ</ci></apply></apply></apply><apply id="S3.E1.m1.5.5.1.1.4.cmml" xref="S3.E1.m1.5.5.1.1.4"><and id="S3.E1.m1.5.5.1.1.4a.cmml" xref="S3.E1.m1.5.5.1.1.4"></and><apply id="S3.E1.m1.5.5.1.1.4b.cmml" xref="S3.E1.m1.5.5.1.1.4"><subset id="S3.E1.m1.5.5.1.1.4.3.cmml" xref="S3.E1.m1.5.5.1.1.4.3"></subset><ci id="S3.E1.m1.5.5.1.1.4.2.cmml" xref="S3.E1.m1.5.5.1.1.4.2">ğ‘ </ci><apply id="S3.E1.m1.5.5.1.1.4.4.cmml" xref="S3.E1.m1.5.5.1.1.4.4"><and id="S3.E1.m1.5.5.1.1.4.4.1.cmml" xref="S3.E1.m1.5.5.1.1.4.4.1"></and><ci id="S3.E1.m1.5.5.1.1.4.4.2.cmml" xref="S3.E1.m1.5.5.1.1.4.4.2">ğ‘¥</ci><ci id="S3.E1.m1.5.5.1.1.4.4.3.cmml" xref="S3.E1.m1.5.5.1.1.4.4.3">ğ‘¡</ci></apply></apply><apply id="S3.E1.m1.5.5.1.1.4c.cmml" xref="S3.E1.m1.5.5.1.1.4"><subset id="S3.E1.m1.5.5.1.1.4.5.cmml" xref="S3.E1.m1.5.5.1.1.4.5"></subset><share href="https://arxiv.org/html/2406.01441v2#S3.E1.m1.5.5.1.1.4.4.cmml" id="S3.E1.m1.5.5.1.1.4d.cmml" xref="S3.E1.m1.5.5.1.1.4"></share><ci id="S3.E1.m1.5.5.1.1.4.6.cmml" xref="S3.E1.m1.5.5.1.1.4.6">ğ‘¦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">\forall(s,t)\in\Phi,\exists(x,y)\in S_{r}:s\subseteq x\wedge t\subseteq y,</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.5d">âˆ€ ( italic_s , italic_t ) âˆˆ roman_Î¦ , âˆƒ ( italic_x , italic_y ) âˆˆ italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT : italic_s âŠ† italic_x âˆ§ italic_t âŠ† italic_y ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.9">where <math alttext="x=\{x_{1},x_{2},...,x_{|x|}\}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m1.5"><semantics id="S3.SS1.p1.8.m1.5a"><mrow id="S3.SS1.p1.8.m1.5.5" xref="S3.SS1.p1.8.m1.5.5.cmml"><mi id="S3.SS1.p1.8.m1.5.5.5" xref="S3.SS1.p1.8.m1.5.5.5.cmml">x</mi><mo id="S3.SS1.p1.8.m1.5.5.4" xref="S3.SS1.p1.8.m1.5.5.4.cmml">=</mo><mrow id="S3.SS1.p1.8.m1.5.5.3.3" xref="S3.SS1.p1.8.m1.5.5.3.4.cmml"><mo id="S3.SS1.p1.8.m1.5.5.3.3.4" stretchy="false" xref="S3.SS1.p1.8.m1.5.5.3.4.cmml">{</mo><msub id="S3.SS1.p1.8.m1.3.3.1.1.1" xref="S3.SS1.p1.8.m1.3.3.1.1.1.cmml"><mi id="S3.SS1.p1.8.m1.3.3.1.1.1.2" xref="S3.SS1.p1.8.m1.3.3.1.1.1.2.cmml">x</mi><mn id="S3.SS1.p1.8.m1.3.3.1.1.1.3" xref="S3.SS1.p1.8.m1.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.8.m1.5.5.3.3.5" xref="S3.SS1.p1.8.m1.5.5.3.4.cmml">,</mo><msub id="S3.SS1.p1.8.m1.4.4.2.2.2" xref="S3.SS1.p1.8.m1.4.4.2.2.2.cmml"><mi id="S3.SS1.p1.8.m1.4.4.2.2.2.2" xref="S3.SS1.p1.8.m1.4.4.2.2.2.2.cmml">x</mi><mn id="S3.SS1.p1.8.m1.4.4.2.2.2.3" xref="S3.SS1.p1.8.m1.4.4.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.8.m1.5.5.3.3.6" xref="S3.SS1.p1.8.m1.5.5.3.4.cmml">,</mo><mi id="S3.SS1.p1.8.m1.2.2" mathvariant="normal" xref="S3.SS1.p1.8.m1.2.2.cmml">â€¦</mi><mo id="S3.SS1.p1.8.m1.5.5.3.3.7" xref="S3.SS1.p1.8.m1.5.5.3.4.cmml">,</mo><msub id="S3.SS1.p1.8.m1.5.5.3.3.3" xref="S3.SS1.p1.8.m1.5.5.3.3.3.cmml"><mi id="S3.SS1.p1.8.m1.5.5.3.3.3.2" xref="S3.SS1.p1.8.m1.5.5.3.3.3.2.cmml">x</mi><mrow id="S3.SS1.p1.8.m1.1.1.1.3" xref="S3.SS1.p1.8.m1.1.1.1.2.cmml"><mo id="S3.SS1.p1.8.m1.1.1.1.3.1" stretchy="false" xref="S3.SS1.p1.8.m1.1.1.1.2.1.cmml">|</mo><mi id="S3.SS1.p1.8.m1.1.1.1.1" xref="S3.SS1.p1.8.m1.1.1.1.1.cmml">x</mi><mo id="S3.SS1.p1.8.m1.1.1.1.3.2" stretchy="false" xref="S3.SS1.p1.8.m1.1.1.1.2.1.cmml">|</mo></mrow></msub><mo id="S3.SS1.p1.8.m1.5.5.3.3.8" stretchy="false" xref="S3.SS1.p1.8.m1.5.5.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m1.5b"><apply id="S3.SS1.p1.8.m1.5.5.cmml" xref="S3.SS1.p1.8.m1.5.5"><eq id="S3.SS1.p1.8.m1.5.5.4.cmml" xref="S3.SS1.p1.8.m1.5.5.4"></eq><ci id="S3.SS1.p1.8.m1.5.5.5.cmml" xref="S3.SS1.p1.8.m1.5.5.5">ğ‘¥</ci><set id="S3.SS1.p1.8.m1.5.5.3.4.cmml" xref="S3.SS1.p1.8.m1.5.5.3.3"><apply id="S3.SS1.p1.8.m1.3.3.1.1.1.cmml" xref="S3.SS1.p1.8.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m1.3.3.1.1.1.1.cmml" xref="S3.SS1.p1.8.m1.3.3.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m1.3.3.1.1.1.2.cmml" xref="S3.SS1.p1.8.m1.3.3.1.1.1.2">ğ‘¥</ci><cn id="S3.SS1.p1.8.m1.3.3.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.8.m1.3.3.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.8.m1.4.4.2.2.2.cmml" xref="S3.SS1.p1.8.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m1.4.4.2.2.2.1.cmml" xref="S3.SS1.p1.8.m1.4.4.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.8.m1.4.4.2.2.2.2.cmml" xref="S3.SS1.p1.8.m1.4.4.2.2.2.2">ğ‘¥</ci><cn id="S3.SS1.p1.8.m1.4.4.2.2.2.3.cmml" type="integer" xref="S3.SS1.p1.8.m1.4.4.2.2.2.3">2</cn></apply><ci id="S3.SS1.p1.8.m1.2.2.cmml" xref="S3.SS1.p1.8.m1.2.2">â€¦</ci><apply id="S3.SS1.p1.8.m1.5.5.3.3.3.cmml" xref="S3.SS1.p1.8.m1.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m1.5.5.3.3.3.1.cmml" xref="S3.SS1.p1.8.m1.5.5.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.8.m1.5.5.3.3.3.2.cmml" xref="S3.SS1.p1.8.m1.5.5.3.3.3.2">ğ‘¥</ci><apply id="S3.SS1.p1.8.m1.1.1.1.2.cmml" xref="S3.SS1.p1.8.m1.1.1.1.3"><abs id="S3.SS1.p1.8.m1.1.1.1.2.1.cmml" xref="S3.SS1.p1.8.m1.1.1.1.3.1"></abs><ci id="S3.SS1.p1.8.m1.1.1.1.1.cmml" xref="S3.SS1.p1.8.m1.1.1.1.1">ğ‘¥</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m1.5c">x=\{x_{1},x_{2},...,x_{|x|}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m1.5d">italic_x = { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT | italic_x | end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="y=\{y_{1},y_{2},...,y_{|y|}\}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m2.5"><semantics id="S3.SS1.p1.9.m2.5a"><mrow id="S3.SS1.p1.9.m2.5.5" xref="S3.SS1.p1.9.m2.5.5.cmml"><mi id="S3.SS1.p1.9.m2.5.5.5" xref="S3.SS1.p1.9.m2.5.5.5.cmml">y</mi><mo id="S3.SS1.p1.9.m2.5.5.4" xref="S3.SS1.p1.9.m2.5.5.4.cmml">=</mo><mrow id="S3.SS1.p1.9.m2.5.5.3.3" xref="S3.SS1.p1.9.m2.5.5.3.4.cmml"><mo id="S3.SS1.p1.9.m2.5.5.3.3.4" stretchy="false" xref="S3.SS1.p1.9.m2.5.5.3.4.cmml">{</mo><msub id="S3.SS1.p1.9.m2.3.3.1.1.1" xref="S3.SS1.p1.9.m2.3.3.1.1.1.cmml"><mi id="S3.SS1.p1.9.m2.3.3.1.1.1.2" xref="S3.SS1.p1.9.m2.3.3.1.1.1.2.cmml">y</mi><mn id="S3.SS1.p1.9.m2.3.3.1.1.1.3" xref="S3.SS1.p1.9.m2.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.9.m2.5.5.3.3.5" xref="S3.SS1.p1.9.m2.5.5.3.4.cmml">,</mo><msub id="S3.SS1.p1.9.m2.4.4.2.2.2" xref="S3.SS1.p1.9.m2.4.4.2.2.2.cmml"><mi id="S3.SS1.p1.9.m2.4.4.2.2.2.2" xref="S3.SS1.p1.9.m2.4.4.2.2.2.2.cmml">y</mi><mn id="S3.SS1.p1.9.m2.4.4.2.2.2.3" xref="S3.SS1.p1.9.m2.4.4.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.9.m2.5.5.3.3.6" xref="S3.SS1.p1.9.m2.5.5.3.4.cmml">,</mo><mi id="S3.SS1.p1.9.m2.2.2" mathvariant="normal" xref="S3.SS1.p1.9.m2.2.2.cmml">â€¦</mi><mo id="S3.SS1.p1.9.m2.5.5.3.3.7" xref="S3.SS1.p1.9.m2.5.5.3.4.cmml">,</mo><msub id="S3.SS1.p1.9.m2.5.5.3.3.3" xref="S3.SS1.p1.9.m2.5.5.3.3.3.cmml"><mi id="S3.SS1.p1.9.m2.5.5.3.3.3.2" xref="S3.SS1.p1.9.m2.5.5.3.3.3.2.cmml">y</mi><mrow id="S3.SS1.p1.9.m2.1.1.1.3" xref="S3.SS1.p1.9.m2.1.1.1.2.cmml"><mo id="S3.SS1.p1.9.m2.1.1.1.3.1" stretchy="false" xref="S3.SS1.p1.9.m2.1.1.1.2.1.cmml">|</mo><mi id="S3.SS1.p1.9.m2.1.1.1.1" xref="S3.SS1.p1.9.m2.1.1.1.1.cmml">y</mi><mo id="S3.SS1.p1.9.m2.1.1.1.3.2" stretchy="false" xref="S3.SS1.p1.9.m2.1.1.1.2.1.cmml">|</mo></mrow></msub><mo id="S3.SS1.p1.9.m2.5.5.3.3.8" stretchy="false" xref="S3.SS1.p1.9.m2.5.5.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m2.5b"><apply id="S3.SS1.p1.9.m2.5.5.cmml" xref="S3.SS1.p1.9.m2.5.5"><eq id="S3.SS1.p1.9.m2.5.5.4.cmml" xref="S3.SS1.p1.9.m2.5.5.4"></eq><ci id="S3.SS1.p1.9.m2.5.5.5.cmml" xref="S3.SS1.p1.9.m2.5.5.5">ğ‘¦</ci><set id="S3.SS1.p1.9.m2.5.5.3.4.cmml" xref="S3.SS1.p1.9.m2.5.5.3.3"><apply id="S3.SS1.p1.9.m2.3.3.1.1.1.cmml" xref="S3.SS1.p1.9.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m2.3.3.1.1.1.1.cmml" xref="S3.SS1.p1.9.m2.3.3.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m2.3.3.1.1.1.2.cmml" xref="S3.SS1.p1.9.m2.3.3.1.1.1.2">ğ‘¦</ci><cn id="S3.SS1.p1.9.m2.3.3.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.9.m2.3.3.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.9.m2.4.4.2.2.2.cmml" xref="S3.SS1.p1.9.m2.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m2.4.4.2.2.2.1.cmml" xref="S3.SS1.p1.9.m2.4.4.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.9.m2.4.4.2.2.2.2.cmml" xref="S3.SS1.p1.9.m2.4.4.2.2.2.2">ğ‘¦</ci><cn id="S3.SS1.p1.9.m2.4.4.2.2.2.3.cmml" type="integer" xref="S3.SS1.p1.9.m2.4.4.2.2.2.3">2</cn></apply><ci id="S3.SS1.p1.9.m2.2.2.cmml" xref="S3.SS1.p1.9.m2.2.2">â€¦</ci><apply id="S3.SS1.p1.9.m2.5.5.3.3.3.cmml" xref="S3.SS1.p1.9.m2.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m2.5.5.3.3.3.1.cmml" xref="S3.SS1.p1.9.m2.5.5.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.9.m2.5.5.3.3.3.2.cmml" xref="S3.SS1.p1.9.m2.5.5.3.3.3.2">ğ‘¦</ci><apply id="S3.SS1.p1.9.m2.1.1.1.2.cmml" xref="S3.SS1.p1.9.m2.1.1.1.3"><abs id="S3.SS1.p1.9.m2.1.1.1.2.1.cmml" xref="S3.SS1.p1.9.m2.1.1.1.3.1"></abs><ci id="S3.SS1.p1.9.m2.1.1.1.1.cmml" xref="S3.SS1.p1.9.m2.1.1.1.1">ğ‘¦</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m2.5c">y=\{y_{1},y_{2},...,y_{|y|}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m2.5d">italic_y = { italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_y start_POSTSUBSCRIPT | italic_y | end_POSTSUBSCRIPT }</annotation></semantics></math>.
In practice, however,
it is not guaranteed that the existing bilingual corpora can cover all dictionary senses. Therefore, we extract a subset that strives to fulfill this objective.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.4">We traverse the corpus in sequential order and search for potential matches with segment pairs in the dictionary.
To prioritize the extraction of high-quality sentence pairs, we rank the corpus with model-based translation quality metrics, e.g., COMET-KIWI <cite class="ltx_cite ltx_citemacro_citep">(Rei etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib26" title="">2022</a>)</cite>.
Specifically, for each segment<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We use unigram and bigram excluding stopwords.</span></span></span> in a source sentence, we perform a dictionary lookup for all the aligned target words.
If one of the aligned target segments exists in the target sentence, we put the sentence pair into the translation candidate subset <math alttext="S_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">S</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ğ‘†</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">S_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>.
We lemmatize each word in the source and target sentence to alleviate the effect of morphological textual variations.
In addition, we introduce a threshold <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_K</annotation></semantics></math> to skip the sentence if all the segment pairs in it have already been matched <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_K</annotation></semantics></math> times.
<math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_K</annotation></semantics></math> enables convenient control over the size of the subset and is used to encourage even distribution of segment pairs.
The matching procedure is illustrated in AlgorithmÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#alg1" title="Algorithm 1 â€£ 3.1 Data Retrieval â€£ 3 Method â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Data retrieval in LexMatcher</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span><span class="ltx_text ltx_font_bold" id="alg1.l1.1">Input:</span> Parallel dataset <math alttext="D" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">D</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">italic_D</annotation></semantics></math>, dictionary <math alttext="\Phi" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><mi id="alg1.l1.m2.1.1" mathvariant="normal" xref="alg1.l1.m2.1.1.cmml">Î¦</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><ci id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1">Î¦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">\Phi</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">roman_Î¦</annotation></semantics></math>, threshold <math alttext="K" class="ltx_Math" display="inline" id="alg1.l1.m3.1"><semantics id="alg1.l1.m3.1a"><mi id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><ci id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m3.1d">italic_K</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span><span class="ltx_text ltx_font_bold" id="alg1.l2.1">Output:</span> Subset <math alttext="S_{r}\subseteq D" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mrow id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><msub id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml"><mi id="alg1.l2.m1.1.1.2.2" xref="alg1.l2.m1.1.1.2.2.cmml">S</mi><mi id="alg1.l2.m1.1.1.2.3" xref="alg1.l2.m1.1.1.2.3.cmml">r</mi></msub><mo id="alg1.l2.m1.1.1.1" xref="alg1.l2.m1.1.1.1.cmml">âŠ†</mo><mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><subset id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1"></subset><apply id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.2.1.cmml" xref="alg1.l2.m1.1.1.2">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.2.cmml" xref="alg1.l2.m1.1.1.2.2">ğ‘†</ci><ci id="alg1.l2.m1.1.1.2.3.cmml" xref="alg1.l2.m1.1.1.2.3">ğ‘Ÿ</ci></apply><ci id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">S_{r}\subseteq D</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT âŠ† italic_D</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span>Initialize <math alttext="S_{r}\leftarrow\emptyset" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><msub id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml"><mi id="alg1.l3.m1.1.1.2.2" xref="alg1.l3.m1.1.1.2.2.cmml">S</mi><mi id="alg1.l3.m1.1.1.2.3" xref="alg1.l3.m1.1.1.2.3.cmml">r</mi></msub><mo id="alg1.l3.m1.1.1.1" stretchy="false" xref="alg1.l3.m1.1.1.1.cmml">â†</mo><mi id="alg1.l3.m1.1.1.3" mathvariant="normal" xref="alg1.l3.m1.1.1.3.cmml">âˆ…</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><ci id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1">â†</ci><apply id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.2.1.cmml" xref="alg1.l3.m1.1.1.2">subscript</csymbol><ci id="alg1.l3.m1.1.1.2.2.cmml" xref="alg1.l3.m1.1.1.2.2">ğ‘†</ci><ci id="alg1.l3.m1.1.1.2.3.cmml" xref="alg1.l3.m1.1.1.2.3">ğ‘Ÿ</ci></apply><emptyset id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">S_{r}\leftarrow\emptyset</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT â† âˆ…</annotation></semantics></math>ï¼Œfrequency count <math alttext="C\leftarrow\{\}" class="ltx_Math" display="inline" id="alg1.l3.m2.1"><semantics id="alg1.l3.m2.1a"><mrow id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml"><mi id="alg1.l3.m2.1.1.2" xref="alg1.l3.m2.1.1.2.cmml">C</mi><mo id="alg1.l3.m2.1.1.1" stretchy="false" xref="alg1.l3.m2.1.1.1.cmml">â†</mo><mrow id="alg1.l3.m2.1.1.3.2" xref="alg1.l3.m2.1.1.cmml"><mo id="alg1.l3.m2.1.1.3.2.1" stretchy="false" xref="alg1.l3.m2.1.1.3.1.cmml">{</mo><mo id="alg1.l3.m2.1.1.3.2.2" stretchy="false" xref="alg1.l3.m2.1.1.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><apply id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1"><ci id="alg1.l3.m2.1.1.1.cmml" xref="alg1.l3.m2.1.1.1">â†</ci><ci id="alg1.l3.m2.1.1.2.cmml" xref="alg1.l3.m2.1.1.2">ğ¶</ci><list id="alg1.l3.m2.1.1.3.1.cmml" xref="alg1.l3.m2.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">C\leftarrow\{\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m2.1d">italic_C â† { }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span><span class="ltx_text ltx_font_bold" id="alg1.l4.1">for</span>Â each <math alttext="(x,y)\in D" class="ltx_Math" display="inline" id="alg1.l4.m1.2"><semantics id="alg1.l4.m1.2a"><mrow id="alg1.l4.m1.2.3" xref="alg1.l4.m1.2.3.cmml"><mrow id="alg1.l4.m1.2.3.2.2" xref="alg1.l4.m1.2.3.2.1.cmml"><mo id="alg1.l4.m1.2.3.2.2.1" stretchy="false" xref="alg1.l4.m1.2.3.2.1.cmml">(</mo><mi id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">x</mi><mo id="alg1.l4.m1.2.3.2.2.2" xref="alg1.l4.m1.2.3.2.1.cmml">,</mo><mi id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml">y</mi><mo id="alg1.l4.m1.2.3.2.2.3" stretchy="false" xref="alg1.l4.m1.2.3.2.1.cmml">)</mo></mrow><mo id="alg1.l4.m1.2.3.1" xref="alg1.l4.m1.2.3.1.cmml">âˆˆ</mo><mi id="alg1.l4.m1.2.3.3" xref="alg1.l4.m1.2.3.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.2b"><apply id="alg1.l4.m1.2.3.cmml" xref="alg1.l4.m1.2.3"><in id="alg1.l4.m1.2.3.1.cmml" xref="alg1.l4.m1.2.3.1"></in><interval closure="open" id="alg1.l4.m1.2.3.2.1.cmml" xref="alg1.l4.m1.2.3.2.2"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">ğ‘¥</ci><ci id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2">ğ‘¦</ci></interval><ci id="alg1.l4.m1.2.3.3.cmml" xref="alg1.l4.m1.2.3.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.2c">(x,y)\in D</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.2d">( italic_x , italic_y ) âˆˆ italic_D</annotation></semantics></math>Â <span class="ltx_text ltx_font_bold" id="alg1.l4.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>Â Â Â Â Â <span class="ltx_text ltx_font_italic" id="alg1.l5.1">Found<math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l5.1.m1.1"><semantics id="alg1.l5.1.m1.1a"><mo id="alg1.l5.1.m1.1.1" stretchy="false" xref="alg1.l5.1.m1.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l5.1.m1.1b"><ci id="alg1.l5.1.m1.1.1.cmml" xref="alg1.l5.1.m1.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.1.m1.1d">â†</annotation></semantics></math></span>false

</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline">6:</span>Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l6.1">for</span>Â each segment <math alttext="\hat{x_{i}}" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mover accent="true" id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><msub id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mi id="alg1.l6.m1.1.1.2.2" xref="alg1.l6.m1.1.1.2.2.cmml">x</mi><mi id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><ci id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1">^</ci><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">ğ‘¥</ci><ci id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\hat{x_{i}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">over^ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> in Lemmatize(<math alttext="x" class="ltx_Math" display="inline" id="alg1.l6.m2.1"><semantics id="alg1.l6.m2.1a"><mi id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><ci id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m2.1d">italic_x</annotation></semantics></math>)Â <span class="ltx_text ltx_font_bold" id="alg1.l6.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span>Â Â Â Â Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l7.1">for</span>Â each <math alttext="t_{n}" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><msub id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><mi id="alg1.l7.m1.1.1.2" xref="alg1.l7.m1.1.1.2.cmml">t</mi><mi id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1">subscript</csymbol><ci id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1.2">ğ‘¡</ci><ci id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">t_{n}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> in <math alttext="\Phi[\hat{x_{i}}]" class="ltx_Math" display="inline" id="alg1.l7.m2.1"><semantics id="alg1.l7.m2.1a"><mrow id="alg1.l7.m2.1.2" xref="alg1.l7.m2.1.2.cmml"><mi id="alg1.l7.m2.1.2.2" mathvariant="normal" xref="alg1.l7.m2.1.2.2.cmml">Î¦</mi><mo id="alg1.l7.m2.1.2.1" xref="alg1.l7.m2.1.2.1.cmml">â¢</mo><mrow id="alg1.l7.m2.1.2.3.2" xref="alg1.l7.m2.1.2.3.1.cmml"><mo id="alg1.l7.m2.1.2.3.2.1" stretchy="false" xref="alg1.l7.m2.1.2.3.1.1.cmml">[</mo><mover accent="true" id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml"><msub id="alg1.l7.m2.1.1.2" xref="alg1.l7.m2.1.1.2.cmml"><mi id="alg1.l7.m2.1.1.2.2" xref="alg1.l7.m2.1.1.2.2.cmml">x</mi><mi id="alg1.l7.m2.1.1.2.3" xref="alg1.l7.m2.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l7.m2.1.1.1" xref="alg1.l7.m2.1.1.1.cmml">^</mo></mover><mo id="alg1.l7.m2.1.2.3.2.2" stretchy="false" xref="alg1.l7.m2.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><apply id="alg1.l7.m2.1.2.cmml" xref="alg1.l7.m2.1.2"><times id="alg1.l7.m2.1.2.1.cmml" xref="alg1.l7.m2.1.2.1"></times><ci id="alg1.l7.m2.1.2.2.cmml" xref="alg1.l7.m2.1.2.2">Î¦</ci><apply id="alg1.l7.m2.1.2.3.1.cmml" xref="alg1.l7.m2.1.2.3.2"><csymbol cd="latexml" id="alg1.l7.m2.1.2.3.1.1.cmml" xref="alg1.l7.m2.1.2.3.2.1">delimited-[]</csymbol><apply id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1"><ci id="alg1.l7.m2.1.1.1.cmml" xref="alg1.l7.m2.1.1.1">^</ci><apply id="alg1.l7.m2.1.1.2.cmml" xref="alg1.l7.m2.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m2.1.1.2.1.cmml" xref="alg1.l7.m2.1.1.2">subscript</csymbol><ci id="alg1.l7.m2.1.1.2.2.cmml" xref="alg1.l7.m2.1.1.2.2">ğ‘¥</ci><ci id="alg1.l7.m2.1.1.2.3.cmml" xref="alg1.l7.m2.1.1.2.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">\Phi[\hat{x_{i}}]</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m2.1d">roman_Î¦ [ over^ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG ]</annotation></semantics></math>Â <span class="ltx_text ltx_font_bold" id="alg1.l7.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l8.1">if</span>Â <math alttext="C[(\hat{x_{i}},t_{n})]&lt;K" class="ltx_Math" display="inline" id="alg1.l8.m1.2"><semantics id="alg1.l8.m1.2a"><mrow id="alg1.l8.m1.2.2" xref="alg1.l8.m1.2.2.cmml"><mrow id="alg1.l8.m1.2.2.1" xref="alg1.l8.m1.2.2.1.cmml"><mi id="alg1.l8.m1.2.2.1.3" xref="alg1.l8.m1.2.2.1.3.cmml">C</mi><mo id="alg1.l8.m1.2.2.1.2" xref="alg1.l8.m1.2.2.1.2.cmml">â¢</mo><mrow id="alg1.l8.m1.2.2.1.1.1" xref="alg1.l8.m1.2.2.1.1.2.cmml"><mo id="alg1.l8.m1.2.2.1.1.1.2" stretchy="false" xref="alg1.l8.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="alg1.l8.m1.2.2.1.1.1.1.1" xref="alg1.l8.m1.2.2.1.1.1.1.2.cmml"><mo id="alg1.l8.m1.2.2.1.1.1.1.1.2" stretchy="false" xref="alg1.l8.m1.2.2.1.1.1.1.2.cmml">(</mo><mover accent="true" id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><msub id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml"><mi id="alg1.l8.m1.1.1.2.2" xref="alg1.l8.m1.1.1.2.2.cmml">x</mi><mi id="alg1.l8.m1.1.1.2.3" xref="alg1.l8.m1.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml">^</mo></mover><mo id="alg1.l8.m1.2.2.1.1.1.1.1.3" xref="alg1.l8.m1.2.2.1.1.1.1.2.cmml">,</mo><msub id="alg1.l8.m1.2.2.1.1.1.1.1.1" xref="alg1.l8.m1.2.2.1.1.1.1.1.1.cmml"><mi id="alg1.l8.m1.2.2.1.1.1.1.1.1.2" xref="alg1.l8.m1.2.2.1.1.1.1.1.1.2.cmml">t</mi><mi id="alg1.l8.m1.2.2.1.1.1.1.1.1.3" xref="alg1.l8.m1.2.2.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="alg1.l8.m1.2.2.1.1.1.1.1.4" stretchy="false" xref="alg1.l8.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow><mo id="alg1.l8.m1.2.2.1.1.1.3" stretchy="false" xref="alg1.l8.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="alg1.l8.m1.2.2.2" xref="alg1.l8.m1.2.2.2.cmml">&lt;</mo><mi id="alg1.l8.m1.2.2.3" xref="alg1.l8.m1.2.2.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.2b"><apply id="alg1.l8.m1.2.2.cmml" xref="alg1.l8.m1.2.2"><lt id="alg1.l8.m1.2.2.2.cmml" xref="alg1.l8.m1.2.2.2"></lt><apply id="alg1.l8.m1.2.2.1.cmml" xref="alg1.l8.m1.2.2.1"><times id="alg1.l8.m1.2.2.1.2.cmml" xref="alg1.l8.m1.2.2.1.2"></times><ci id="alg1.l8.m1.2.2.1.3.cmml" xref="alg1.l8.m1.2.2.1.3">ğ¶</ci><apply id="alg1.l8.m1.2.2.1.1.2.cmml" xref="alg1.l8.m1.2.2.1.1.1"><csymbol cd="latexml" id="alg1.l8.m1.2.2.1.1.2.1.cmml" xref="alg1.l8.m1.2.2.1.1.1.2">delimited-[]</csymbol><interval closure="open" id="alg1.l8.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.1"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><ci id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1">^</ci><apply id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.2.1.cmml" xref="alg1.l8.m1.1.1.2">subscript</csymbol><ci id="alg1.l8.m1.1.1.2.2.cmml" xref="alg1.l8.m1.1.1.2.2">ğ‘¥</ci><ci id="alg1.l8.m1.1.1.2.3.cmml" xref="alg1.l8.m1.1.1.2.3">ğ‘–</ci></apply></apply><apply id="alg1.l8.m1.2.2.1.1.1.1.1.1.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l8.m1.2.2.1.1.1.1.1.1.1.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l8.m1.2.2.1.1.1.1.1.1.2.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="alg1.l8.m1.2.2.1.1.1.1.1.1.3.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.1.1.3">ğ‘›</ci></apply></interval></apply></apply><ci id="alg1.l8.m1.2.2.3.cmml" xref="alg1.l8.m1.2.2.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.2c">C[(\hat{x_{i}},t_{n})]&lt;K</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.2d">italic_C [ ( over^ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG , italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ] &lt; italic_K</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l8.2">and</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â <math alttext="t_{n}" class="ltx_Math" display="inline" id="alg1.l9.m1.1"><semantics id="alg1.l9.m1.1a"><msub id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><mi id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml">t</mi><mi id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1">subscript</csymbol><ci id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2">ğ‘¡</ci><ci id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">t_{n}</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m1.1d">italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> in Lemmatize(<math alttext="y" class="ltx_Math" display="inline" id="alg1.l9.m2.1"><semantics id="alg1.l9.m2.1a"><mi id="alg1.l9.m2.1.1" xref="alg1.l9.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="alg1.l9.m2.1b"><ci id="alg1.l9.m2.1.1.cmml" xref="alg1.l9.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m2.1d">italic_y</annotation></semantics></math>)Â <span class="ltx_text ltx_font_bold" id="alg1.l9.1">then</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â <math alttext="C[(\hat{x_{i}},t_{n})]" class="ltx_Math" display="inline" id="alg1.l10.m1.2"><semantics id="alg1.l10.m1.2a"><mrow id="alg1.l10.m1.2.2" xref="alg1.l10.m1.2.2.cmml"><mi id="alg1.l10.m1.2.2.3" xref="alg1.l10.m1.2.2.3.cmml">C</mi><mo id="alg1.l10.m1.2.2.2" xref="alg1.l10.m1.2.2.2.cmml">â¢</mo><mrow id="alg1.l10.m1.2.2.1.1" xref="alg1.l10.m1.2.2.1.2.cmml"><mo id="alg1.l10.m1.2.2.1.1.2" stretchy="false" xref="alg1.l10.m1.2.2.1.2.1.cmml">[</mo><mrow id="alg1.l10.m1.2.2.1.1.1.1" xref="alg1.l10.m1.2.2.1.1.1.2.cmml"><mo id="alg1.l10.m1.2.2.1.1.1.1.2" stretchy="false" xref="alg1.l10.m1.2.2.1.1.1.2.cmml">(</mo><mover accent="true" id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><msub id="alg1.l10.m1.1.1.2" xref="alg1.l10.m1.1.1.2.cmml"><mi id="alg1.l10.m1.1.1.2.2" xref="alg1.l10.m1.1.1.2.2.cmml">x</mi><mi id="alg1.l10.m1.1.1.2.3" xref="alg1.l10.m1.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l10.m1.1.1.1" xref="alg1.l10.m1.1.1.1.cmml">^</mo></mover><mo id="alg1.l10.m1.2.2.1.1.1.1.3" xref="alg1.l10.m1.2.2.1.1.1.2.cmml">,</mo><msub id="alg1.l10.m1.2.2.1.1.1.1.1" xref="alg1.l10.m1.2.2.1.1.1.1.1.cmml"><mi id="alg1.l10.m1.2.2.1.1.1.1.1.2" xref="alg1.l10.m1.2.2.1.1.1.1.1.2.cmml">t</mi><mi id="alg1.l10.m1.2.2.1.1.1.1.1.3" xref="alg1.l10.m1.2.2.1.1.1.1.1.3.cmml">n</mi></msub><mo id="alg1.l10.m1.2.2.1.1.1.1.4" stretchy="false" xref="alg1.l10.m1.2.2.1.1.1.2.cmml">)</mo></mrow><mo id="alg1.l10.m1.2.2.1.1.3" stretchy="false" xref="alg1.l10.m1.2.2.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.2b"><apply id="alg1.l10.m1.2.2.cmml" xref="alg1.l10.m1.2.2"><times id="alg1.l10.m1.2.2.2.cmml" xref="alg1.l10.m1.2.2.2"></times><ci id="alg1.l10.m1.2.2.3.cmml" xref="alg1.l10.m1.2.2.3">ğ¶</ci><apply id="alg1.l10.m1.2.2.1.2.cmml" xref="alg1.l10.m1.2.2.1.1"><csymbol cd="latexml" id="alg1.l10.m1.2.2.1.2.1.cmml" xref="alg1.l10.m1.2.2.1.1.2">delimited-[]</csymbol><interval closure="open" id="alg1.l10.m1.2.2.1.1.1.2.cmml" xref="alg1.l10.m1.2.2.1.1.1.1"><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><ci id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1">^</ci><apply id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.2.1.cmml" xref="alg1.l10.m1.1.1.2">subscript</csymbol><ci id="alg1.l10.m1.1.1.2.2.cmml" xref="alg1.l10.m1.1.1.2.2">ğ‘¥</ci><ci id="alg1.l10.m1.1.1.2.3.cmml" xref="alg1.l10.m1.1.1.2.3">ğ‘–</ci></apply></apply><apply id="alg1.l10.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l10.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m1.2.2.1.1.1.1.1.1.cmml" xref="alg1.l10.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="alg1.l10.m1.2.2.1.1.1.1.1.2.cmml" xref="alg1.l10.m1.2.2.1.1.1.1.1.2">ğ‘¡</ci><ci id="alg1.l10.m1.2.2.1.1.1.1.1.3.cmml" xref="alg1.l10.m1.2.2.1.1.1.1.1.3">ğ‘›</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.2c">C[(\hat{x_{i}},t_{n})]</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.2d">italic_C [ ( over^ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG , italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ]</annotation></semantics></math><math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l10.m2.1"><semantics id="alg1.l10.m2.1a"><mo id="alg1.l10.m2.1.1" stretchy="false" xref="alg1.l10.m2.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.1b"><ci id="alg1.l10.m2.1.1.cmml" xref="alg1.l10.m2.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m2.1d">â†</annotation></semantics></math><math alttext="C[(\hat{x_{i}},t_{n})]+1" class="ltx_Math" display="inline" id="alg1.l10.m3.2"><semantics id="alg1.l10.m3.2a"><mrow id="alg1.l10.m3.2.2" xref="alg1.l10.m3.2.2.cmml"><mrow id="alg1.l10.m3.2.2.1" xref="alg1.l10.m3.2.2.1.cmml"><mi id="alg1.l10.m3.2.2.1.3" xref="alg1.l10.m3.2.2.1.3.cmml">C</mi><mo id="alg1.l10.m3.2.2.1.2" xref="alg1.l10.m3.2.2.1.2.cmml">â¢</mo><mrow id="alg1.l10.m3.2.2.1.1.1" xref="alg1.l10.m3.2.2.1.1.2.cmml"><mo id="alg1.l10.m3.2.2.1.1.1.2" stretchy="false" xref="alg1.l10.m3.2.2.1.1.2.1.cmml">[</mo><mrow id="alg1.l10.m3.2.2.1.1.1.1.1" xref="alg1.l10.m3.2.2.1.1.1.1.2.cmml"><mo id="alg1.l10.m3.2.2.1.1.1.1.1.2" stretchy="false" xref="alg1.l10.m3.2.2.1.1.1.1.2.cmml">(</mo><mover accent="true" id="alg1.l10.m3.1.1" xref="alg1.l10.m3.1.1.cmml"><msub id="alg1.l10.m3.1.1.2" xref="alg1.l10.m3.1.1.2.cmml"><mi id="alg1.l10.m3.1.1.2.2" xref="alg1.l10.m3.1.1.2.2.cmml">x</mi><mi id="alg1.l10.m3.1.1.2.3" xref="alg1.l10.m3.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l10.m3.1.1.1" xref="alg1.l10.m3.1.1.1.cmml">^</mo></mover><mo id="alg1.l10.m3.2.2.1.1.1.1.1.3" xref="alg1.l10.m3.2.2.1.1.1.1.2.cmml">,</mo><msub id="alg1.l10.m3.2.2.1.1.1.1.1.1" xref="alg1.l10.m3.2.2.1.1.1.1.1.1.cmml"><mi id="alg1.l10.m3.2.2.1.1.1.1.1.1.2" xref="alg1.l10.m3.2.2.1.1.1.1.1.1.2.cmml">t</mi><mi id="alg1.l10.m3.2.2.1.1.1.1.1.1.3" xref="alg1.l10.m3.2.2.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="alg1.l10.m3.2.2.1.1.1.1.1.4" stretchy="false" xref="alg1.l10.m3.2.2.1.1.1.1.2.cmml">)</mo></mrow><mo id="alg1.l10.m3.2.2.1.1.1.3" stretchy="false" xref="alg1.l10.m3.2.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="alg1.l10.m3.2.2.2" xref="alg1.l10.m3.2.2.2.cmml">+</mo><mn id="alg1.l10.m3.2.2.3" xref="alg1.l10.m3.2.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m3.2b"><apply id="alg1.l10.m3.2.2.cmml" xref="alg1.l10.m3.2.2"><plus id="alg1.l10.m3.2.2.2.cmml" xref="alg1.l10.m3.2.2.2"></plus><apply id="alg1.l10.m3.2.2.1.cmml" xref="alg1.l10.m3.2.2.1"><times id="alg1.l10.m3.2.2.1.2.cmml" xref="alg1.l10.m3.2.2.1.2"></times><ci id="alg1.l10.m3.2.2.1.3.cmml" xref="alg1.l10.m3.2.2.1.3">ğ¶</ci><apply id="alg1.l10.m3.2.2.1.1.2.cmml" xref="alg1.l10.m3.2.2.1.1.1"><csymbol cd="latexml" id="alg1.l10.m3.2.2.1.1.2.1.cmml" xref="alg1.l10.m3.2.2.1.1.1.2">delimited-[]</csymbol><interval closure="open" id="alg1.l10.m3.2.2.1.1.1.1.2.cmml" xref="alg1.l10.m3.2.2.1.1.1.1.1"><apply id="alg1.l10.m3.1.1.cmml" xref="alg1.l10.m3.1.1"><ci id="alg1.l10.m3.1.1.1.cmml" xref="alg1.l10.m3.1.1.1">^</ci><apply id="alg1.l10.m3.1.1.2.cmml" xref="alg1.l10.m3.1.1.2"><csymbol cd="ambiguous" id="alg1.l10.m3.1.1.2.1.cmml" xref="alg1.l10.m3.1.1.2">subscript</csymbol><ci id="alg1.l10.m3.1.1.2.2.cmml" xref="alg1.l10.m3.1.1.2.2">ğ‘¥</ci><ci id="alg1.l10.m3.1.1.2.3.cmml" xref="alg1.l10.m3.1.1.2.3">ğ‘–</ci></apply></apply><apply id="alg1.l10.m3.2.2.1.1.1.1.1.1.cmml" xref="alg1.l10.m3.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m3.2.2.1.1.1.1.1.1.1.cmml" xref="alg1.l10.m3.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l10.m3.2.2.1.1.1.1.1.1.2.cmml" xref="alg1.l10.m3.2.2.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="alg1.l10.m3.2.2.1.1.1.1.1.1.3.cmml" xref="alg1.l10.m3.2.2.1.1.1.1.1.1.3">ğ‘›</ci></apply></interval></apply></apply><cn id="alg1.l10.m3.2.2.3.cmml" type="integer" xref="alg1.l10.m3.2.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m3.2c">C[(\hat{x_{i}},t_{n})]+1</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m3.2d">italic_C [ ( over^ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG , italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ] + 1</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline">11:</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â <span class="ltx_text ltx_font_italic" id="alg1.l11.1">Found<math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l11.1.m1.1"><semantics id="alg1.l11.1.m1.1a"><mo id="alg1.l11.1.m1.1.1" stretchy="false" xref="alg1.l11.1.m1.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l11.1.m1.1b"><ci id="alg1.l11.1.m1.1.1.cmml" xref="alg1.l11.1.m1.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.1.m1.1d">â†</annotation></semantics></math></span>true

</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline">12:</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l12.1">end</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l12.2">if</span>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline">13:</span>Â Â Â Â Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l13.1">end</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l13.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline">14:</span>Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l14.1">end</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l14.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l15">
<span class="ltx_tag ltx_tag_listingline">15:</span>Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l15.1">if</span>Â <span class="ltx_text ltx_font_italic" id="alg1.l15.2">Found</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l15.3">then</span>
</div>
<div class="ltx_listingline" id="alg1.l16">
<span class="ltx_tag ltx_tag_listingline">16:</span>Â Â Â Â Â Â Â Â Â Add <math alttext="(x,y)" class="ltx_Math" display="inline" id="alg1.l16.m1.2"><semantics id="alg1.l16.m1.2a"><mrow id="alg1.l16.m1.2.3.2" xref="alg1.l16.m1.2.3.1.cmml"><mo id="alg1.l16.m1.2.3.2.1" stretchy="false" xref="alg1.l16.m1.2.3.1.cmml">(</mo><mi id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml">x</mi><mo id="alg1.l16.m1.2.3.2.2" xref="alg1.l16.m1.2.3.1.cmml">,</mo><mi id="alg1.l16.m1.2.2" xref="alg1.l16.m1.2.2.cmml">y</mi><mo id="alg1.l16.m1.2.3.2.3" stretchy="false" xref="alg1.l16.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.2b"><interval closure="open" id="alg1.l16.m1.2.3.1.cmml" xref="alg1.l16.m1.2.3.2"><ci id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1">ğ‘¥</ci><ci id="alg1.l16.m1.2.2.cmml" xref="alg1.l16.m1.2.2">ğ‘¦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.2c">(x,y)</annotation><annotation encoding="application/x-llamapun" id="alg1.l16.m1.2d">( italic_x , italic_y )</annotation></semantics></math> to <math alttext="S_{r}" class="ltx_Math" display="inline" id="alg1.l16.m2.1"><semantics id="alg1.l16.m2.1a"><msub id="alg1.l16.m2.1.1" xref="alg1.l16.m2.1.1.cmml"><mi id="alg1.l16.m2.1.1.2" xref="alg1.l16.m2.1.1.2.cmml">S</mi><mi id="alg1.l16.m2.1.1.3" xref="alg1.l16.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l16.m2.1b"><apply id="alg1.l16.m2.1.1.cmml" xref="alg1.l16.m2.1.1"><csymbol cd="ambiguous" id="alg1.l16.m2.1.1.1.cmml" xref="alg1.l16.m2.1.1">subscript</csymbol><ci id="alg1.l16.m2.1.1.2.cmml" xref="alg1.l16.m2.1.1.2">ğ‘†</ci><ci id="alg1.l16.m2.1.1.3.cmml" xref="alg1.l16.m2.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m2.1c">S_{r}</annotation><annotation encoding="application/x-llamapun" id="alg1.l16.m2.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l17">
<span class="ltx_tag ltx_tag_listingline">17:</span>Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l17.1">end</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l17.2">if</span>
</div>
<div class="ltx_listingline" id="alg1.l18">
<span class="ltx_tag ltx_tag_listingline">18:</span><span class="ltx_text ltx_font_bold" id="alg1.l18.1">end</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l18.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l19">
<span class="ltx_tag ltx_tag_listingline">19:</span><span class="ltx_text ltx_font_bold" id="alg1.l19.1">return</span> <math alttext="S_{r}" class="ltx_Math" display="inline" id="alg1.l19.m1.1"><semantics id="alg1.l19.m1.1a"><msub id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml"><mi id="alg1.l19.m1.1.1.2" xref="alg1.l19.m1.1.1.2.cmml">S</mi><mi id="alg1.l19.m1.1.1.3" xref="alg1.l19.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><apply id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.1.cmml" xref="alg1.l19.m1.1.1">subscript</csymbol><ci id="alg1.l19.m1.1.1.2.cmml" xref="alg1.l19.m1.1.1.2">ğ‘†</ci><ci id="alg1.l19.m1.1.1.3.cmml" xref="alg1.l19.m1.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">S_{r}</annotation><annotation encoding="application/x-llamapun" id="alg1.l19.m1.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Augmentation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2">Using a partial set of open-source corpora cannot cover all the senses in the dictionary, which can be rare named entities or low-frequency occurrence of distinctive senses of certain words.
The translation of rare entities is generally unique and can be solved effectively by prompting LLMs during inference, and the lack of training data for these cases may have minimal impact.
However, the senses of polysemous words are context-sensitive and may require specific training data to strengthen the modelâ€™s understanding and translation of them.
To compensate for the missing senses, we leverage ChatGPT<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>GPT-3.5-turbo-0314</span></span></span> to construct translation demonstrations for each sense, thus creating the subset <math alttext="S_{c}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">S</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘†</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">S_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>.
Concretely, we prompt ChatGPT with a sense expressed in source and target languages and the senseâ€™s definition.
The prompt is shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A0.F6" title="Figure 6 â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A2" title="Appendix B Prompts Used for Manipulating ChatGPT and Terminology Translation â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">B</span></a>).
Only nouns and verbs with more than three senses are considered due to their highly polysemous nature <cite class="ltx_cite ltx_citemacro_cite">Campolungo etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib4" title="">2022</a>)</cite>.
Note that the subset <math alttext="S_{c}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">S</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ‘†</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">S_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> only takes up a neglectable portion of the whole dataset (e.g., 225 sentence pairs for English-Germen, and the specific numbers are reported in Â§<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5" title="5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Instruction Fine-tuning LLM for MT</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.5">Instruction fine-tuning has become standard practice in LLM-based translation <cite class="ltx_cite ltx_citemacro_cite">Zeng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib36" title="">2024</a>); Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>); Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib38" title="">2023</a>)</cite>.
Our instruction-following data is constructed based on <math alttext="S=S_{r}\cup S_{c}" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mi id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">S</mi><mo id="S4.p1.1.m1.1.1.1" xref="S4.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml"><msub id="S4.p1.1.m1.1.1.3.2" xref="S4.p1.1.m1.1.1.3.2.cmml"><mi id="S4.p1.1.m1.1.1.3.2.2" xref="S4.p1.1.m1.1.1.3.2.2.cmml">S</mi><mi id="S4.p1.1.m1.1.1.3.2.3" xref="S4.p1.1.m1.1.1.3.2.3.cmml">r</mi></msub><mo id="S4.p1.1.m1.1.1.3.1" xref="S4.p1.1.m1.1.1.3.1.cmml">âˆª</mo><msub id="S4.p1.1.m1.1.1.3.3" xref="S4.p1.1.m1.1.1.3.3.cmml"><mi id="S4.p1.1.m1.1.1.3.3.2" xref="S4.p1.1.m1.1.1.3.3.2.cmml">S</mi><mi id="S4.p1.1.m1.1.1.3.3.3" xref="S4.p1.1.m1.1.1.3.3.3.cmml">c</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><eq id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></eq><ci id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">ğ‘†</ci><apply id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3"><union id="S4.p1.1.m1.1.1.3.1.cmml" xref="S4.p1.1.m1.1.1.3.1"></union><apply id="S4.p1.1.m1.1.1.3.2.cmml" xref="S4.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.p1.1.m1.1.1.3.2.1.cmml" xref="S4.p1.1.m1.1.1.3.2">subscript</csymbol><ci id="S4.p1.1.m1.1.1.3.2.2.cmml" xref="S4.p1.1.m1.1.1.3.2.2">ğ‘†</ci><ci id="S4.p1.1.m1.1.1.3.2.3.cmml" xref="S4.p1.1.m1.1.1.3.2.3">ğ‘Ÿ</ci></apply><apply id="S4.p1.1.m1.1.1.3.3.cmml" xref="S4.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.p1.1.m1.1.1.3.3.1.cmml" xref="S4.p1.1.m1.1.1.3.3">subscript</csymbol><ci id="S4.p1.1.m1.1.1.3.3.2.cmml" xref="S4.p1.1.m1.1.1.3.3.2">ğ‘†</ci><ci id="S4.p1.1.m1.1.1.3.3.3.cmml" xref="S4.p1.1.m1.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">S=S_{r}\cup S_{c}</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">italic_S = italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT âˆª italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> (Â§<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S3" title="3 Method â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>).
Generally, each instance comprises an â€œinstructionâ€ <math alttext="c" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">italic_c</annotation></semantics></math> describing the task the model should perform (e.g., â€œTranslate the sentences from English to Chinese.â€), an â€œinputâ€ <math alttext="x" class="ltx_Math" display="inline" id="S4.p1.3.m3.1"><semantics id="S4.p1.3.m3.1a"><mi id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><ci id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.p1.3.m3.1d">italic_x</annotation></semantics></math> indicating the source sentence, and a corresponding output <math alttext="y" class="ltx_Math" display="inline" id="S4.p1.4.m4.1"><semantics id="S4.p1.4.m4.1a"><mi id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><ci id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.p1.4.m4.1d">italic_y</annotation></semantics></math> indicating the answer to the instruction, i.e., the target sentence.
The LLMs are optimized by minimizing the negative log-likelihood of the output <math alttext="y" class="ltx_Math" display="inline" id="S4.p1.5.m5.1"><semantics id="S4.p1.5.m5.1a"><mi id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b"><ci id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.p1.5.m5.1d">italic_y</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L=-\sum_{(x,y)\in S}\frac{1}{|y|}\sum_{i}^{|y|}\log p(y_{i}|c,x;\theta)," class="ltx_Math" display="block" id="S4.E2.m1.8"><semantics id="S4.E2.m1.8a"><mrow id="S4.E2.m1.8.8.1" xref="S4.E2.m1.8.8.1.1.cmml"><mrow id="S4.E2.m1.8.8.1.1" xref="S4.E2.m1.8.8.1.1.cmml"><mi id="S4.E2.m1.8.8.1.1.3" xref="S4.E2.m1.8.8.1.1.3.cmml">L</mi><mo id="S4.E2.m1.8.8.1.1.2" xref="S4.E2.m1.8.8.1.1.2.cmml">=</mo><mrow id="S4.E2.m1.8.8.1.1.1" xref="S4.E2.m1.8.8.1.1.1.cmml"><mo id="S4.E2.m1.8.8.1.1.1a" xref="S4.E2.m1.8.8.1.1.1.cmml">âˆ’</mo><mrow id="S4.E2.m1.8.8.1.1.1.1" xref="S4.E2.m1.8.8.1.1.1.1.cmml"><munder id="S4.E2.m1.8.8.1.1.1.1.2" xref="S4.E2.m1.8.8.1.1.1.1.2.cmml"><mo id="S4.E2.m1.8.8.1.1.1.1.2.2" movablelimits="false" xref="S4.E2.m1.8.8.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S4.E2.m1.2.2.2" xref="S4.E2.m1.2.2.2.cmml"><mrow id="S4.E2.m1.2.2.2.4.2" xref="S4.E2.m1.2.2.2.4.1.cmml"><mo id="S4.E2.m1.2.2.2.4.2.1" stretchy="false" xref="S4.E2.m1.2.2.2.4.1.cmml">(</mo><mi id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml">x</mi><mo id="S4.E2.m1.2.2.2.4.2.2" xref="S4.E2.m1.2.2.2.4.1.cmml">,</mo><mi id="S4.E2.m1.2.2.2.2" xref="S4.E2.m1.2.2.2.2.cmml">y</mi><mo id="S4.E2.m1.2.2.2.4.2.3" stretchy="false" xref="S4.E2.m1.2.2.2.4.1.cmml">)</mo></mrow><mo id="S4.E2.m1.2.2.2.3" xref="S4.E2.m1.2.2.2.3.cmml">âˆˆ</mo><mi id="S4.E2.m1.2.2.2.5" xref="S4.E2.m1.2.2.2.5.cmml">S</mi></mrow></munder><mrow id="S4.E2.m1.8.8.1.1.1.1.1" xref="S4.E2.m1.8.8.1.1.1.1.1.cmml"><mfrac id="S4.E2.m1.3.3" xref="S4.E2.m1.3.3.cmml"><mn id="S4.E2.m1.3.3.3" xref="S4.E2.m1.3.3.3.cmml">1</mn><mrow id="S4.E2.m1.3.3.1.3" xref="S4.E2.m1.3.3.1.2.cmml"><mo id="S4.E2.m1.3.3.1.3.1" stretchy="false" xref="S4.E2.m1.3.3.1.2.1.cmml">|</mo><mi id="S4.E2.m1.3.3.1.1" xref="S4.E2.m1.3.3.1.1.cmml">y</mi><mo id="S4.E2.m1.3.3.1.3.2" stretchy="false" xref="S4.E2.m1.3.3.1.2.1.cmml">|</mo></mrow></mfrac><mo id="S4.E2.m1.8.8.1.1.1.1.1.2" xref="S4.E2.m1.8.8.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S4.E2.m1.8.8.1.1.1.1.1.1" xref="S4.E2.m1.8.8.1.1.1.1.1.1.cmml"><munderover id="S4.E2.m1.8.8.1.1.1.1.1.1.2" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2.cmml"><mo id="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.2" movablelimits="false" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mi id="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.3" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.3.cmml">i</mi><mrow id="S4.E2.m1.4.4.1.3" xref="S4.E2.m1.4.4.1.2.cmml"><mo id="S4.E2.m1.4.4.1.3.1" stretchy="false" xref="S4.E2.m1.4.4.1.2.1.cmml">|</mo><mi id="S4.E2.m1.4.4.1.1" xref="S4.E2.m1.4.4.1.1.cmml">y</mi><mo id="S4.E2.m1.4.4.1.3.2" stretchy="false" xref="S4.E2.m1.4.4.1.2.1.cmml">|</mo></mrow></munderover><mrow id="S4.E2.m1.8.8.1.1.1.1.1.1.1" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.cmml"><mrow id="S4.E2.m1.8.8.1.1.1.1.1.1.1.3" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.1" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.1.cmml">log</mi><mo id="S4.E2.m1.8.8.1.1.1.1.1.1.1.3a" lspace="0.167em" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.cmml">â¡</mo><mi id="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.2" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.2.cmml">p</mi></mrow><mo id="S4.E2.m1.8.8.1.1.1.1.1.1.1.2" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mrow id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.1.cmml"><mi id="S4.E2.m1.5.5" xref="S4.E2.m1.5.5.cmml">c</mi><mo id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S4.E2.m1.6.6" xref="S4.E2.m1.6.6.cmml">x</mi><mo id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.1.cmml">;</mo><mi id="S4.E2.m1.7.7" xref="S4.E2.m1.7.7.cmml">Î¸</mi></mrow></mrow><mo id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S4.E2.m1.8.8.1.2" xref="S4.E2.m1.8.8.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.8b"><apply id="S4.E2.m1.8.8.1.1.cmml" xref="S4.E2.m1.8.8.1"><eq id="S4.E2.m1.8.8.1.1.2.cmml" xref="S4.E2.m1.8.8.1.1.2"></eq><ci id="S4.E2.m1.8.8.1.1.3.cmml" xref="S4.E2.m1.8.8.1.1.3">ğ¿</ci><apply id="S4.E2.m1.8.8.1.1.1.cmml" xref="S4.E2.m1.8.8.1.1.1"><minus id="S4.E2.m1.8.8.1.1.1.2.cmml" xref="S4.E2.m1.8.8.1.1.1"></minus><apply id="S4.E2.m1.8.8.1.1.1.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1"><apply id="S4.E2.m1.8.8.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.1.1.1.1.2.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.2">subscript</csymbol><sum id="S4.E2.m1.8.8.1.1.1.1.2.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.2.2"></sum><apply id="S4.E2.m1.2.2.2.cmml" xref="S4.E2.m1.2.2.2"><in id="S4.E2.m1.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.3"></in><interval closure="open" id="S4.E2.m1.2.2.2.4.1.cmml" xref="S4.E2.m1.2.2.2.4.2"><ci id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1">ğ‘¥</ci><ci id="S4.E2.m1.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2">ğ‘¦</ci></interval><ci id="S4.E2.m1.2.2.2.5.cmml" xref="S4.E2.m1.2.2.2.5">ğ‘†</ci></apply></apply><apply id="S4.E2.m1.8.8.1.1.1.1.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1"><times id="S4.E2.m1.8.8.1.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.2"></times><apply id="S4.E2.m1.3.3.cmml" xref="S4.E2.m1.3.3"><divide id="S4.E2.m1.3.3.2.cmml" xref="S4.E2.m1.3.3"></divide><cn id="S4.E2.m1.3.3.3.cmml" type="integer" xref="S4.E2.m1.3.3.3">1</cn><apply id="S4.E2.m1.3.3.1.2.cmml" xref="S4.E2.m1.3.3.1.3"><abs id="S4.E2.m1.3.3.1.2.1.cmml" xref="S4.E2.m1.3.3.1.3.1"></abs><ci id="S4.E2.m1.3.3.1.1.cmml" xref="S4.E2.m1.3.3.1.1">ğ‘¦</ci></apply></apply><apply id="S4.E2.m1.8.8.1.1.1.1.1.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1"><apply id="S4.E2.m1.8.8.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2">superscript</csymbol><apply id="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2">subscript</csymbol><sum id="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.2"></sum><ci id="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.2.2.3">ğ‘–</ci></apply><apply id="S4.E2.m1.4.4.1.2.cmml" xref="S4.E2.m1.4.4.1.3"><abs id="S4.E2.m1.4.4.1.2.1.cmml" xref="S4.E2.m1.4.4.1.3.1"></abs><ci id="S4.E2.m1.4.4.1.1.cmml" xref="S4.E2.m1.4.4.1.1">ğ‘¦</ci></apply></apply><apply id="S4.E2.m1.8.8.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1"><times id="S4.E2.m1.8.8.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.2"></times><apply id="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.3"><log id="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.1"></log><ci id="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.3.2">ğ‘</ci></apply><apply id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘¦</ci><ci id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><list id="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.8.8.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S4.E2.m1.5.5.cmml" xref="S4.E2.m1.5.5">ğ‘</ci><ci id="S4.E2.m1.6.6.cmml" xref="S4.E2.m1.6.6">ğ‘¥</ci><ci id="S4.E2.m1.7.7.cmml" xref="S4.E2.m1.7.7">ğœƒ</ci></list></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.8c">L=-\sum_{(x,y)\in S}\frac{1}{|y|}\sum_{i}^{|y|}\log p(y_{i}|c,x;\theta),</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.8d">italic_L = - âˆ‘ start_POSTSUBSCRIPT ( italic_x , italic_y ) âˆˆ italic_S end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG | italic_y | end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_y | end_POSTSUPERSCRIPT roman_log italic_p ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_c , italic_x ; italic_Î¸ ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p1.6">where <math alttext="\theta" class="ltx_Math" display="inline" id="S4.p1.6.m1.1"><semantics id="S4.p1.6.m1.1a"><mi id="S4.p1.6.m1.1.1" xref="S4.p1.6.m1.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S4.p1.6.m1.1b"><ci id="S4.p1.6.m1.1.1.cmml" xref="S4.p1.6.m1.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.6.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S4.p1.6.m1.1d">italic_Î¸</annotation></semantics></math> is the trainable parameters.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.5">We use two kinds of translation instructions: 1) general translation instructions mainly used to indicate translation directions (e.g., â€œTranslate the following sentence to Englishâ€),
and 2) constrained translation instructions that specify word translations from a given dictionary or based on specific user requirements.
(e.g., â€˜Translate the following sentence to English using the given reference translations.â€)
For the latter, we randomly sample a small number of sentence pairs to incorporate specified word translations<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The maximum number of sentences under the constrained translation instructions for each direction is set to 10,000.</span></span></span>.
For each sample, we introduce at most 3 segment pairs matched in the dictionary and orgnize them with a template:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="c=\text{Template}(\{(s_{i},t_{i})\}_{i=1}^{N})," class="ltx_Math" display="block" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.3.cmml">c</mi><mo id="S4.E3.m1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.cmml"><mtext id="S4.E3.m1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.3a.cmml">Template</mtext><mo id="S4.E3.m1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S4.E3.m1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E3.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S4.E3.m1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">{</mo><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.4" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">,</mo><msub id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">t</mi><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3.cmml">N</mi></msubsup><mo id="S4.E3.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><eq id="S4.E3.m1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.2"></eq><ci id="S4.E3.m1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.3">ğ‘</ci><apply id="S4.E3.m1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1"><times id="S4.E3.m1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.2"></times><ci id="S4.E3.m1.1.1.1.1.1.3a.cmml" xref="S4.E3.m1.1.1.1.1.1.3"><mtext id="S4.E3.m1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.3">Template</mtext></ci><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1">subscript</csymbol><set id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1"><interval closure="open" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘ </ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">ğ‘¡</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3">ğ‘–</ci></apply></interval></set><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3"><eq id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.1"></eq><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2">ğ‘–</ci><cn id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">c=\text{Template}(\{(s_{i},t_{i})\}_{i=1}^{N}),</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">italic_c = Template ( { ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p2.4">where <math alttext="s_{i}" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><msub id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">s</mi><mi id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1">subscript</csymbol><ci id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2">ğ‘ </ci><ci id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="t_{i}" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><msub id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">t</mi><mi id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">ğ‘¡</ci><ci id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">t_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denote the segment pair following Section <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S3" title="3 Method â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>.
We simply use â€œmeansâ€ to connect <math alttext="s_{i}" class="ltx_Math" display="inline" id="S4.p2.3.m3.1"><semantics id="S4.p2.3.m3.1a"><msub id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">s</mi><mi id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">ğ‘ </ci><ci id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="t_{i}" class="ltx_Math" display="inline" id="S4.p2.4.m4.1"><semantics id="S4.p2.4.m4.1a"><msub id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><mi id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml">t</mi><mi id="S4.p2.4.m4.1.1.3" xref="S4.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1">subscript</csymbol><ci id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2">ğ‘¡</ci><ci id="S4.p2.4.m4.1.1.3.cmml" xref="S4.p2.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">t_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.4.m4.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, and prepend the constraint to the translation instruction.
An example is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A0.F6" title="Figure 6 â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>(b) (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A2" title="Appendix B Prompts Used for Manipulating ChatGPT and Terminology Translation â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">B</span></a>).
During inference, we can choose whether to use the constrained translation instructions to incorporate translations from the dictionary or terminology, depending on the situation.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Setting</h3>
<figure class="ltx_table" id="S5.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T1.1">
<tr class="ltx_tr" id="S5.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.1.1.1" rowspan="2"><span class="ltx_text" id="S5.T1.1.1.1.1">Lang</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.1.1.2" rowspan="2"><span class="ltx_text" id="S5.T1.1.1.2.1">Raw</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T1.1.1.3">Retrieval</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.1.1.4" rowspan="2"><span class="ltx_text" id="S5.T1.1.1.4.1">Supplement</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.2">
<td class="ltx_td ltx_align_center" id="S5.T1.1.2.1">K=1</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.2.2">K=2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.2.3">K=3</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.3.1">Zh</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.3.2">33M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.3.3">75k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.3.4">188k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.3.5">281k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.3.6">2.2k</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4">
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.1">De</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.2">278M</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.3">93k</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.4">233k</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.5">351k</td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.6">0.2k</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.5.1">Ru</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.5.2">227M</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.5.3">98k</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.5.4">246k</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.5.5">367k</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.5.6">0.7k</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
The number of parallel sentences of different data sets.
</figcaption>
</figure>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.11" style="width:433.6pt;height:149.9pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-201.1pt,69.3pt) scale(0.518855653657937,0.518855653657937) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.11.11">
<tr class="ltx_tr" id="S5.T2.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.6.6.6.7" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.6.6.6.7.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.1">Zh<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T2.1.1.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.1.1.m1.1a"><mo id="S5.T2.1.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T2.1.1.1.1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.1.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.2.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.2.2.2.2.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T2.2.2.2.2.1.m1.1"><semantics id="S5.T2.2.2.2.2.1.m1.1a"><mo id="S5.T2.2.2.2.2.1.m1.1.1" stretchy="false" xref="S5.T2.2.2.2.2.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.1.m1.1b"><ci id="S5.T2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.2.2.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.2.1.m1.1d">â‡’</annotation></semantics></math>Zh</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.3.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.3.3.3.3.1">De<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T2.3.3.3.3.1.m1.1"><semantics id="S5.T2.3.3.3.3.1.m1.1a"><mo id="S5.T2.3.3.3.3.1.m1.1.1" stretchy="false" xref="S5.T2.3.3.3.3.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.1.m1.1b"><ci id="S5.T2.3.3.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.3.3.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.3.3.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.4.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.4.4.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T2.4.4.4.4.1.m1.1"><semantics id="S5.T2.4.4.4.4.1.m1.1a"><mo id="S5.T2.4.4.4.4.1.m1.1.1" stretchy="false" xref="S5.T2.4.4.4.4.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.4.1.m1.1b"><ci id="S5.T2.4.4.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.4.4.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.4.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.4.4.1.m1.1d">â‡’</annotation></semantics></math>De</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.5.5.5.1">Ru<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T2.5.5.5.5.1.m1.1"><semantics id="S5.T2.5.5.5.5.1.m1.1a"><mo id="S5.T2.5.5.5.5.1.m1.1.1" stretchy="false" xref="S5.T2.5.5.5.5.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.5.1.m1.1b"><ci id="S5.T2.5.5.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.5.5.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.5.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.5.5.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.6.6.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.6.6.6.6.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T2.6.6.6.6.1.m1.1"><semantics id="S5.T2.6.6.6.6.1.m1.1a"><mo id="S5.T2.6.6.6.6.1.m1.1.1" stretchy="false" xref="S5.T2.6.6.6.6.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.6.6.1.m1.1b"><ci id="S5.T2.6.6.6.6.1.m1.1.1.cmml" xref="S5.T2.6.6.6.6.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.6.6.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.6.6.6.1.m1.1d">â‡’</annotation></semantics></math>Ru</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.12">
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.12.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.7.7.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math alttext="\text{GPT-3.5}^{{\dagger}}" class="ltx_Math" display="inline" id="S5.T2.7.7.7.1.m1.1"><semantics id="S5.T2.7.7.7.1.m1.1a"><msup id="S5.T2.7.7.7.1.m1.1.1" xref="S5.T2.7.7.7.1.m1.1.1.cmml"><mtext id="S5.T2.7.7.7.1.m1.1.1.2" xref="S5.T2.7.7.7.1.m1.1.1.2a.cmml">GPT-3.5</mtext><mo id="S5.T2.7.7.7.1.m1.1.1.3" xref="S5.T2.7.7.7.1.m1.1.1.3.cmml">â€ </mo></msup><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.7.1.m1.1b"><apply id="S5.T2.7.7.7.1.m1.1.1.cmml" xref="S5.T2.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.7.7.7.1.m1.1.1.1.cmml" xref="S5.T2.7.7.7.1.m1.1.1">superscript</csymbol><ci id="S5.T2.7.7.7.1.m1.1.1.2a.cmml" xref="S5.T2.7.7.7.1.m1.1.1.2"><mtext id="S5.T2.7.7.7.1.m1.1.1.2.cmml" xref="S5.T2.7.7.7.1.m1.1.1.2">GPT-3.5</mtext></ci><ci id="S5.T2.7.7.7.1.m1.1.1.3.cmml" xref="S5.T2.7.7.7.1.m1.1.1.3">â€ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.7.1.m1.1c">\text{GPT-3.5}^{{\dagger}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.7.7.1.m1.1d">GPT-3.5 start_POSTSUPERSCRIPT â€  end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.7.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.60/82.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.7.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">44.90/87.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.7.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.10/85.50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.7.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">34.40/87.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.7.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.40/86.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.7.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">34.40/87.00</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.8.8">
<td class="ltx_td ltx_align_left" id="S5.T2.8.8.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math alttext="\text{GPT-4}^{{\dagger}}" class="ltx_Math" display="inline" id="S5.T2.8.8.8.1.m1.1"><semantics id="S5.T2.8.8.8.1.m1.1a"><msup id="S5.T2.8.8.8.1.m1.1.1" xref="S5.T2.8.8.8.1.m1.1.1.cmml"><mtext id="S5.T2.8.8.8.1.m1.1.1.2" xref="S5.T2.8.8.8.1.m1.1.1.2a.cmml">GPT-4</mtext><mo id="S5.T2.8.8.8.1.m1.1.1.3" xref="S5.T2.8.8.8.1.m1.1.1.3.cmml">â€ </mo></msup><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.8.1.m1.1b"><apply id="S5.T2.8.8.8.1.m1.1.1.cmml" xref="S5.T2.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.8.8.8.1.m1.1.1.1.cmml" xref="S5.T2.8.8.8.1.m1.1.1">superscript</csymbol><ci id="S5.T2.8.8.8.1.m1.1.1.2a.cmml" xref="S5.T2.8.8.8.1.m1.1.1.2"><mtext id="S5.T2.8.8.8.1.m1.1.1.2.cmml" xref="S5.T2.8.8.8.1.m1.1.1.2">GPT-4</mtext></ci><ci id="S5.T2.8.8.8.1.m1.1.1.3.cmml" xref="S5.T2.8.8.8.1.m1.1.1.3">â€ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.8.1.m1.1c">\text{GPT-4}^{{\dagger}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.8.8.8.1.m1.1d">GPT-4 start_POSTSUPERSCRIPT â€  end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.20/82.79</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">43.98/87.49</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.87/85.62</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">35.38/87.44</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">43.51/86.18</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.45/88.87</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.9.9">
<td class="ltx_td ltx_align_left" id="S5.T2.9.9.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math alttext="\text{NLLB-54B}^{{\dagger}}" class="ltx_Math" display="inline" id="S5.T2.9.9.9.1.m1.1"><semantics id="S5.T2.9.9.9.1.m1.1a"><msup id="S5.T2.9.9.9.1.m1.1.1" xref="S5.T2.9.9.9.1.m1.1.1.cmml"><mtext id="S5.T2.9.9.9.1.m1.1.1.2" xref="S5.T2.9.9.9.1.m1.1.1.2a.cmml">NLLB-54B</mtext><mo id="S5.T2.9.9.9.1.m1.1.1.3" xref="S5.T2.9.9.9.1.m1.1.1.3.cmml">â€ </mo></msup><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.9.1.m1.1b"><apply id="S5.T2.9.9.9.1.m1.1.1.cmml" xref="S5.T2.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.9.9.9.1.m1.1.1.1.cmml" xref="S5.T2.9.9.9.1.m1.1.1">superscript</csymbol><ci id="S5.T2.9.9.9.1.m1.1.1.2a.cmml" xref="S5.T2.9.9.9.1.m1.1.1.2"><mtext id="S5.T2.9.9.9.1.m1.1.1.2.cmml" xref="S5.T2.9.9.9.1.m1.1.1.2">NLLB-54B</mtext></ci><ci id="S5.T2.9.9.9.1.m1.1.1.3.cmml" xref="S5.T2.9.9.9.1.m1.1.1.3">â€ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.9.1.m1.1c">\text{NLLB-54B}^{{\dagger}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.9.9.9.1.m1.1d">NLLB-54B start_POSTSUPERSCRIPT â€  end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">16.56/70.70</td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.38/78.91</td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.89/78.94</td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">34.50/86.45</td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.89/78.94</td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.96/87.92</td>
</tr>
<tr class="ltx_tr" id="S5.T2.10.10.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.10.10.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math alttext="\text{LLaMA2-7B}^{{\dagger}}" class="ltx_Math" display="inline" id="S5.T2.10.10.10.1.m1.1"><semantics id="S5.T2.10.10.10.1.m1.1a"><msup id="S5.T2.10.10.10.1.m1.1.1" xref="S5.T2.10.10.10.1.m1.1.1.cmml"><mtext id="S5.T2.10.10.10.1.m1.1.1.2" xref="S5.T2.10.10.10.1.m1.1.1.2a.cmml">LLaMA2-7B</mtext><mo id="S5.T2.10.10.10.1.m1.1.1.3" xref="S5.T2.10.10.10.1.m1.1.1.3.cmml">â€ </mo></msup><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.10.1.m1.1b"><apply id="S5.T2.10.10.10.1.m1.1.1.cmml" xref="S5.T2.10.10.10.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.10.10.10.1.m1.1.1.1.cmml" xref="S5.T2.10.10.10.1.m1.1.1">superscript</csymbol><ci id="S5.T2.10.10.10.1.m1.1.1.2a.cmml" xref="S5.T2.10.10.10.1.m1.1.1.2"><mtext id="S5.T2.10.10.10.1.m1.1.1.2.cmml" xref="S5.T2.10.10.10.1.m1.1.1.2">LLaMA2-7B</mtext></ci><ci id="S5.T2.10.10.10.1.m1.1.1.3.cmml" xref="S5.T2.10.10.10.1.m1.1.1.3">â€ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.10.1.m1.1c">\text{LLaMA2-7B}^{{\dagger}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.10.10.10.1.m1.1d">LLaMA2-7B start_POSTSUPERSCRIPT â€  end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">18.19/75.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">16.97/71.80</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.42/82.74</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.10.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">19.00/76.39</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.10.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.02/82.84</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.10.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">16.00/73.24</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.13">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.13.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Parrot-7B <cite class="ltx_cite ltx_citemacro_cite">Jiao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib13" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.13.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">20.20/75.90</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.13.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.30/80.30</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.13.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.30/82.40</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.13.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.10/81.60</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.13.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.13.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.14">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.14.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">TIM-7B <cite class="ltx_cite ltx_citemacro_cite">Zeng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib36" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.14.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.51/79.71</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.14.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.83/85.10</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.14.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.12/78.94</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.14.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">20.90/74.91</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.14.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.14.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.15">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.15.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">ALMA-7B <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.15.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.52/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.15.2.1">79.73</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.15.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.48/85.05</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.15.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.49/83.98</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.15.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.31/85.59</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.15.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.93/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.15.6.1">84.81</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.15.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.09/87.17</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.16">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.16.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">LexMatcher-7B</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.16.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.2.1">24.81</span>/79.13</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.16.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.3.1">40.34</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.3.2">86.11</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.16.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.4.1">32.33</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.4.2">84.29</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.16.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.5.1">33.56</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.5.2">86.31</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.16.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.6.1">41.01</span>/84.43</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.16.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.7.1">28.97</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.16.7.2">87.23</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.11.11.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math alttext="\text{LLaMA2-13B}^{{\dagger}}" class="ltx_Math" display="inline" id="S5.T2.11.11.11.1.m1.1"><semantics id="S5.T2.11.11.11.1.m1.1a"><msup id="S5.T2.11.11.11.1.m1.1.1" xref="S5.T2.11.11.11.1.m1.1.1.cmml"><mtext id="S5.T2.11.11.11.1.m1.1.1.2" xref="S5.T2.11.11.11.1.m1.1.1.2a.cmml">LLaMA2-13B</mtext><mo id="S5.T2.11.11.11.1.m1.1.1.3" xref="S5.T2.11.11.11.1.m1.1.1.3.cmml">â€ </mo></msup><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.11.1.m1.1b"><apply id="S5.T2.11.11.11.1.m1.1.1.cmml" xref="S5.T2.11.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.11.11.11.1.m1.1.1.1.cmml" xref="S5.T2.11.11.11.1.m1.1.1">superscript</csymbol><ci id="S5.T2.11.11.11.1.m1.1.1.2a.cmml" xref="S5.T2.11.11.11.1.m1.1.1.2"><mtext id="S5.T2.11.11.11.1.m1.1.1.2.cmml" xref="S5.T2.11.11.11.1.m1.1.1.2">LLaMA2-13B</mtext></ci><ci id="S5.T2.11.11.11.1.m1.1.1.3.cmml" xref="S5.T2.11.11.11.1.m1.1.1.3">â€ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.11.1.m1.1c">\text{LLaMA2-13B}^{{\dagger}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.11.11.11.1.m1.1d">LLaMA2-13B start_POSTSUPERSCRIPT â€  end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">21.81/78.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.00/79.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.06/83.01</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">13.69/75.55</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.11.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.50/82.91</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.11.11.11.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.59/63.84</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.17">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.17.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DictPrompt-13B <cite class="ltx_cite ltx_citemacro_cite">Ghazvininejad etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib7" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.17.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">17.55/74.12</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.17.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.75/83.46</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.17.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.36/83.31</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.17.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.24/80.89</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.17.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.70/81.95</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.17.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">21.98/81.00</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.18">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.18.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">BigTrans-13B <cite class="ltx_cite ltx_citemacro_cite">Yang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib35" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.18.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">14.16/74.26</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.18.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.56/81.31</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.18.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.35/80.68</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.18.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">21.48/78.81</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.18.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.81/77.80</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.18.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">17.66/78.21</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.19">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.19.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Bayling-13B <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib38" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.19.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">20.12/77.72</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.19.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.92/84.62</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.19.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.34/83.02</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.19.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.62/82.69</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.19.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.95/82.07</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.19.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">12.77/71.01</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.20">
<td class="ltx_td ltx_align_left" id="S5.T2.11.11.20.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">ALMA-13B <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.20.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.46/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.20.2.1">80.21</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.20.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">39.84/85.96</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.20.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.14/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.20.4.1">84.56</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.20.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.47/85.62</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.20.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.27/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.20.6.1">85.27</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.20.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.96/87.53</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.11.21">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.11.11.21.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">LexMatcher-13B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.11.11.21.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.2.1">26.15</span>/79.88</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.11.11.21.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.3.1">41.13</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.3.2">86.58</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.11.11.21.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.4.1">32.59</span>/84.55</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.11.11.21.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.5.1">34.82</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.5.2">86.45</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.11.11.21.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.6.1">41.53</span>/84.91</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.11.11.21.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.7.1">30.20</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.11.11.21.7.2">87.83</span>
</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>

Evaluation results on WMT22 test sets. Higher scores (BLEU and COMET) denote better translation performance.
Bold numbers indicate the best scores among models of the same sizes.
The numbers with the dagger symbol represent the results from <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>.
LexMatcher-7B outperforms Parrot-7B and ALMA-7B with p-value&lt;0.01, and LexMatcher-13B outperforms ALMA-13B with p-value&lt;0.01.
</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.5">For parallel training data, we use the open-source data from WMT22<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://www.statmt.org/wmt22/translation-task.html</span></span></span> in German<math alttext="\Leftrightarrow" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mo id="S5.SS1.p1.1.m1.1.1" stretchy="false" xref="S5.SS1.p1.1.m1.1.1.cmml">â‡”</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">â‡”</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\Leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">â‡”</annotation></semantics></math>English, Chinese<math alttext="\Leftrightarrow" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mo id="S5.SS1.p1.2.m2.1.1" stretchy="false" xref="S5.SS1.p1.2.m2.1.1.cmml">â‡”</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><ci id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">â‡”</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">\Leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">â‡”</annotation></semantics></math>English, and Russian<math alttext="\Leftrightarrow" class="ltx_Math" display="inline" id="S5.SS1.p1.3.m3.1"><semantics id="S5.SS1.p1.3.m3.1a"><mo id="S5.SS1.p1.3.m3.1.1" stretchy="false" xref="S5.SS1.p1.3.m3.1.1.cmml">â‡”</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><ci id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">â‡”</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">\Leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.3.m3.1d">â‡”</annotation></semantics></math>English.
The detail of data preprocessing is shown in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A3" title="Appendix C Corpus Preprocessing â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">C</span></a>.
We use bilingual dictionaries provided by Open Multilingual WordNet <cite class="ltx_cite ltx_citemacro_cite">Bond etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib2" title="">2016</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://www.nltk.org/howto/wordnet.html</span></span></span>.
In addition, we take Wikititles<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://data.statmt.org/wikititles/v3/</span></span></span> as an entity dictionary.
Table <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.T1" title="Table 1 â€£ 5.1 Setting â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> presents the number of sentence pairs for each language pair in different subsets, including the original training set, subsets extracted based on different <math alttext="K" class="ltx_Math" display="inline" id="S5.SS1.p1.4.m4.1"><semantics id="S5.SS1.p1.4.m4.1a"><mi id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><ci id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.4.m4.1d">italic_K</annotation></semantics></math>, and the ChatGPT-generated data.
It can be observed that our method achieves a high compression rate.
The subset <math alttext="K" class="ltx_Math" display="inline" id="S5.SS1.p1.5.m5.1"><semantics id="S5.SS1.p1.5.m5.1a"><mi id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><ci id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.5.m5.1d">italic_K</annotation></semantics></math>=3 is used for the main experiment, and the extracted data for Chinese, German, and Russian accounts for only 0.57%, 0.08%, and 0.11% of the original data, respectively.
The development sets from the previous WMT competitions are used by default <cite class="ltx_cite ltx_citemacro_cite">Jiao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib13" title="">2023</a>); Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">We use LLaMA2-7B and LLaMA2-13B for comparing to the related methods, and one model is used for all of the translation directions.
We fine tune all of our models for 1 epoch with the collected multilingual instruction data.
The batch size is 128 and the learning rate is 2e-5.
The final checkpoint is used for evaluation, and we use beam search with a beam size of 4 during inference.
For automatic evaluations, we use BLEU <cite class="ltx_cite ltx_citemacro_cite">Papineni etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib24" title="">2002</a>)</cite> <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://github.com/mjpost/sacrebleu</span></span></span> and COMET<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>https://huggingface.co/Unbabel/wmt22-comet-da</span></span></span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Main Results</h3>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Seen Language Directions.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.5">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.T2" title="Table 2 â€£ 5.1 Setting â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a> presents the translation performance on the WMT22 test sets.
The LLaMA2 models fine-tuned on the instruction data collected by LexMatcher significantly outperform their original zero-shot performance, especially for the En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S5.SS2.SSS0.Px1.p1.1.m1.1a"><mo id="S5.SS2.SSS0.Px1.p1.1.m1.1.1" stretchy="false" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px1.p1.1.m1.1d">â‡’</annotation></semantics></math>xx.
Concretely, LexMatcher-7B improves LLaMA2-7B by an average of 17.02 BLEU points and 12.68 COMET points in En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S5.SS2.SSS0.Px1.p1.2.m2.1a"><mo id="S5.SS2.SSS0.Px1.p1.2.m2.1.1" stretchy="false" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.2.m2.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px1.p1.2.m2.1d">â‡’</annotation></semantics></math>xx, and by 4.45 BLEU points and 2.42 COMET points in xx<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S5.SS2.SSS0.Px1.p1.3.m3.1a"><mo id="S5.SS2.SSS0.Px1.p1.3.m3.1.1" stretchy="false" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.3.m3.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px1.p1.3.m3.1d">â‡’</annotation></semantics></math>En.
LLaMA2-13B performs significantly worse than its 7B counterpart in En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.4.m4.1"><semantics id="S5.SS2.SSS0.Px1.p1.4.m4.1a"><mo id="S5.SS2.SSS0.Px1.p1.4.m4.1.1" stretchy="false" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.4.m4.1b"><ci id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.4.m4.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px1.p1.4.m4.1d">â‡’</annotation></semantics></math>xx directions due to severe off-target issues, while LexMatcher-13B improves this performance significantly.
We also consider an ICL method DictPrompt <cite class="ltx_cite ltx_citemacro_cite">Ghazvininejad etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib7" title="">2023</a>)</cite> which provides dictionary translations for each source word<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>They use Bloom-176B as the backbone and we re-implement the method on LLaMA2-13B.</span></span></span>, and the result shows that using dictionary translations as hints yields notable improvements in En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p1.5.m5.1"><semantics id="S5.SS2.SSS0.Px1.p1.5.m5.1a"><mo id="S5.SS2.SSS0.Px1.p1.5.m5.1.1" stretchy="false" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.5.m5.1b"><ci id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.5.m5.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px1.p1.5.m5.1d">â‡’</annotation></semantics></math>xx.
In contrast, LexMatcher-13B achieves better performance and is more efficient due to a much shorter context during inference.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p2.2">LexMatcher demonstrates superior performance compared to other instruction fine-tuned baselines. Specifically, LexMatcher-7B outperforms Parrot-7B and TIM-7B, which construct additional translation pairs and utilize specialized instructions.
In the En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p2.1.m1.1"><semantics id="S5.SS2.SSS0.Px1.p2.1.m1.1a"><mo id="S5.SS2.SSS0.Px1.p2.1.m1.1.1" stretchy="false" xref="S5.SS2.SSS0.Px1.p2.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p2.1.m1.1b"><ci id="S5.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p2.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p2.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px1.p2.1.m1.1d">â‡’</annotation></semantics></math>De translation task, LexMatcher-7B surpasses TIM-7B by more than 10 BLEU and COMET points.
Moreover, LexMatcher outperforms BigTrans and ALMA consistently across the En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px1.p2.2.m2.1"><semantics id="S5.SS2.SSS0.Px1.p2.2.m2.1a"><mo id="S5.SS2.SSS0.Px1.p2.2.m2.1.1" stretchy="false" xref="S5.SS2.SSS0.Px1.p2.2.m2.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p2.2.m2.1b"><ci id="S5.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px1.p2.2.m2.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p2.2.m2.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px1.p2.2.m2.1d">â‡’</annotation></semantics></math>xx tasks, which incorporate a large amount of data for continual pretraining.
While LexMatcher-7B still underperforms GPT-3.5<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>GPT-3.5-turbo-0301</span></span></span> and GPT-4<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>GPT-4-0314</span></span></span>, the COMET scores for LexMatcher-7B are merely lower than GPT-3.5 within 2 points, and LexMatcher-13B further narrows the gap.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="480" id="S5.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
Zero-shot translation.
</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Unseen Language Directions.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.3">To evaluate performance in translation directions never seen previously, i.e., zero-shot multilingual capability, we further conduct experiments on
Czech-to-English (cs<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S5.SS2.SSS0.Px2.p1.1.m1.1a"><mo id="S5.SS2.SSS0.Px2.p1.1.m1.1.1" stretchy="false" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px2.p1.1.m1.1d">â‡’</annotation></semantics></math>en), Japanese-to-English (ja<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S5.SS2.SSS0.Px2.p1.2.m2.1a"><mo id="S5.SS2.SSS0.Px2.p1.2.m2.1.1" stretchy="false" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.2.m2.1b"><ci id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.2.m2.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px2.p1.2.m2.1d">â‡’</annotation></semantics></math>en), and Ukrainian-to-English (uk<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px2.p1.3.m3.1"><semantics id="S5.SS2.SSS0.Px2.p1.3.m3.1a"><mo id="S5.SS2.SSS0.Px2.p1.3.m3.1.1" stretchy="false" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.3.m3.1b"><ci id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.3.m3.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px2.p1.3.m3.1d">â‡’</annotation></semantics></math>en).
As depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.F2" title="Figure 2 â€£ Seen Language Directions. â€£ 5.2 Main Results â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>,
LexMatcher-(*) exhibits superior zero-shot multilingual capability over the LLM baselines, highlighting that better aligning training languages strengthens the alignment of other languages as a by-product.
</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Disambiguation.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px3.p1.1">By comparing the different senses of a word and multilingual expressions of meaning, the model possibly learns more precise word usage in translation.
To investigate it, we submit the models to a challenging disambiguation leaderboard, DiBiMT <cite class="ltx_cite ltx_citemacro_cite">Campolungo etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib4" title="">2022</a>)</cite>.
It compares the performance of NMT systems when translating sentences with ambiguous words and the performance is evaluated by accuracy.
For comparison, we display the performance of top-ranked systems including <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p1.1.1">DeepL<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote12.1.1.1">12</span></span><span class="ltx_text ltx_font_upright" id="footnote12.5">https://www.deepl.com/en/translator</span></span></span></span></span>, <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p1.1.2">Google Translate<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote13.1.1.1">13</span></span><span class="ltx_text ltx_font_upright" id="footnote13.5">https://translate.google.com</span></span></span></span></span>, and <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p1.1.3">NLLB-54B</span>.
The results of LLMs are from <cite class="ltx_cite ltx_citemacro_citet">Iyer etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib12" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.1">
<tr class="ltx_tr" id="S5.T3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T3.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.1">Zh</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.3.1">De</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.4.1">Ru</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.2.1">DeepL</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2">58.42</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.2.3.1">76.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.4">67.53</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3">
<td class="ltx_td ltx_align_left" id="S5.T3.1.3.1">Google-Translate</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2">52.09</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.3">67.35</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.4">62.03</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4">
<td class="ltx_td ltx_align_left" id="S5.T3.1.4.1">OPUS</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.2">25.94</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3">27.04</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.4">28.71</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5">
<td class="ltx_td ltx_align_left" id="S5.T3.1.5.1">NLLB-54B</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.2">48.02</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.3">67.97</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4">67.88</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.6.1">LLaMA-7B-ICL(1)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.6.2">30.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.6.3">57.41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.6.4">60.65</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.7">
<td class="ltx_td ltx_align_left" id="S5.T3.1.7.1">LLaMA-7B-ICL(5)</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.7.2">27.92</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.7.3">55.26</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.7.4">56.83</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.8">
<td class="ltx_td ltx_align_left" id="S5.T3.1.8.1">LLaMA-65B-ICL(1)</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.8.2">44.73</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.8.3">62.05</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.8.4">65.71</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.9">
<td class="ltx_td ltx_align_left" id="S5.T3.1.9.1">LLaMA-65B-ICL(5)</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.9.2">42.49</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.9.3">62.98</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.9.4">66.31</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.10">
<td class="ltx_td ltx_align_left" id="S5.T3.1.10.1">Alpaca-7B</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.10.2">29.63</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.10.3">51.52</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.10.4">55.23</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.11.1">LexMatcher-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.11.2">53.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.11.3">63.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.11.4">67.72</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T3.1.12.1">LexMatcher-13B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.12.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.12.2.1">59.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.12.3">66.98</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.12.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.12.4.1">69.93</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>
Accuracies on the DiBiMT benchmark which is dedicated for evaluating word disambiguation in MT.
The number following ICL denotes the number of translation demonstrations.
</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.SSS0.Px3.p2">
<p class="ltx_p" id="S5.SS2.SSS0.Px3.p2.1">The result is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.T3" title="Table 3 â€£ Disambiguation. â€£ 5.2 Main Results â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>.
For the LLaMA models, increasing model size improves the performance, and <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.1">LLaMA-65B</span> matches <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.2">Google Tranlate</span> and <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.3">NLLB-54B</span> with few-shot prompting.
<span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.4">Alpaca-7B</span> works well without demonstration (i.e., zero-shot prompting) and significantly outperforms the supervised NMT system OPUS, which indicates its potential for further improvement through fine-tuning on translation data.
<span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.5">LexMatcher-7B</span> significantly outperforms <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.6">Alpaca-7B</span> and surpasses <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.7">Google Translate</span> in Chinese and Russian disambiguation.
With a scale of 13B, it also outperforms the best <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px3.p2.1.8">DEEPL</span> system in Chinese and Russian, achieving accuracy rates of 59.09% and 69.93%, respectively.
This result demonstrates the advantage of our data construction principle.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Terminology.</h4>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.3">
<tr class="ltx_tr" id="S5.T4.2.2">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T4.2.2.3" rowspan="2" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.2.2.3.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T4.1.1.1" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.1">Zh<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T4.1.1.1.1.m1.1"><semantics id="S5.T4.1.1.1.1.m1.1a"><mo id="S5.T4.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T4.1.1.1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><ci id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T4.2.2.2" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.2.2.2.1">De<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.T4.2.2.2.1.m1.1"><semantics id="S5.T4.2.2.2.1.m1.1a"><mo id="S5.T4.2.2.2.1.m1.1.1" stretchy="false" xref="S5.T4.2.2.2.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.1.m1.1b"><ci id="S5.T4.2.2.2.1.m1.1.1.cmml" xref="S5.T4.2.2.2.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.2.2.2.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.4">
<td class="ltx_td ltx_align_center" id="S5.T4.3.4.1" style="padding-left:2.3pt;padding-right:2.3pt;">ChrF/COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.4.2" style="padding-left:2.3pt;padding-right:2.3pt;">Suc</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.4.3" style="padding-left:2.3pt;padding-right:2.3pt;">ChrF/COMET</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.4.4" style="padding-left:2.3pt;padding-right:2.3pt;">Suc</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.3.5.1" style="padding-left:2.3pt;padding-right:2.3pt;">Lingua Custodia</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.5.2" style="padding-left:2.3pt;padding-right:2.3pt;">32.6/60.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.5.3" style="padding-left:2.3pt;padding-right:2.3pt;">74.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.5.4" style="padding-left:2.3pt;padding-right:2.3pt;">61.8/73.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.5.5" style="padding-left:2.3pt;padding-right:2.3pt;">62.2</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.6">
<td class="ltx_td ltx_align_left" id="S5.T4.3.6.1" style="padding-left:2.3pt;padding-right:2.3pt;">VARCO</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.6.2" style="padding-left:2.3pt;padding-right:2.3pt;">40.5/71.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.6.3" style="padding-left:2.3pt;padding-right:2.3pt;">80.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.6.4" style="padding-left:2.3pt;padding-right:2.3pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.6.5" style="padding-left:2.3pt;padding-right:2.3pt;">-</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.3">
<td class="ltx_td ltx_align_left" id="S5.T4.3.3.1" style="padding-left:2.3pt;padding-right:2.3pt;"><math alttext="\text{UEDIN}_{LLM}" class="ltx_Math" display="inline" id="S5.T4.3.3.1.m1.1"><semantics id="S5.T4.3.3.1.m1.1a"><msub id="S5.T4.3.3.1.m1.1.1" xref="S5.T4.3.3.1.m1.1.1.cmml"><mtext id="S5.T4.3.3.1.m1.1.1.2" xref="S5.T4.3.3.1.m1.1.1.2a.cmml">UEDIN</mtext><mrow id="S5.T4.3.3.1.m1.1.1.3" xref="S5.T4.3.3.1.m1.1.1.3.cmml"><mi id="S5.T4.3.3.1.m1.1.1.3.2" xref="S5.T4.3.3.1.m1.1.1.3.2.cmml">L</mi><mo id="S5.T4.3.3.1.m1.1.1.3.1" xref="S5.T4.3.3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.T4.3.3.1.m1.1.1.3.3" xref="S5.T4.3.3.1.m1.1.1.3.3.cmml">L</mi><mo id="S5.T4.3.3.1.m1.1.1.3.1a" xref="S5.T4.3.3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.T4.3.3.1.m1.1.1.3.4" xref="S5.T4.3.3.1.m1.1.1.3.4.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.1.m1.1b"><apply id="S5.T4.3.3.1.m1.1.1.cmml" xref="S5.T4.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T4.3.3.1.m1.1.1.1.cmml" xref="S5.T4.3.3.1.m1.1.1">subscript</csymbol><ci id="S5.T4.3.3.1.m1.1.1.2a.cmml" xref="S5.T4.3.3.1.m1.1.1.2"><mtext id="S5.T4.3.3.1.m1.1.1.2.cmml" xref="S5.T4.3.3.1.m1.1.1.2">UEDIN</mtext></ci><apply id="S5.T4.3.3.1.m1.1.1.3.cmml" xref="S5.T4.3.3.1.m1.1.1.3"><times id="S5.T4.3.3.1.m1.1.1.3.1.cmml" xref="S5.T4.3.3.1.m1.1.1.3.1"></times><ci id="S5.T4.3.3.1.m1.1.1.3.2.cmml" xref="S5.T4.3.3.1.m1.1.1.3.2">ğ¿</ci><ci id="S5.T4.3.3.1.m1.1.1.3.3.cmml" xref="S5.T4.3.3.1.m1.1.1.3.3">ğ¿</ci><ci id="S5.T4.3.3.1.m1.1.1.3.4.cmml" xref="S5.T4.3.3.1.m1.1.1.3.4">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.1.m1.1c">\text{UEDIN}_{LLM}</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.3.1.m1.1d">UEDIN start_POSTSUBSCRIPT italic_L italic_L italic_M end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.3.2" style="padding-left:2.3pt;padding-right:2.3pt;">
<span class="ltx_text ltx_font_bold" id="S5.T4.3.3.2.1">41.2</span>/<span class="ltx_text ltx_font_bold" id="S5.T4.3.3.2.2">75.7</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.3.3" style="padding-left:2.3pt;padding-right:2.3pt;">75.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.3.4" style="padding-left:2.3pt;padding-right:2.3pt;">60.0/81.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.3.3.5" style="padding-left:2.3pt;padding-right:2.3pt;">58.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.3.7.1" style="padding-left:2.3pt;padding-right:2.3pt;">LexMatcher-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.7.2" style="padding-left:2.3pt;padding-right:2.3pt;">38.2/73.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.7.3" style="padding-left:2.3pt;padding-right:2.3pt;">84.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.7.4" style="padding-left:2.3pt;padding-right:2.3pt;">64.3/81.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.7.5" style="padding-left:2.3pt;padding-right:2.3pt;">80.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T4.3.8.1" style="padding-left:2.3pt;padding-right:2.3pt;">LexMatcher-13B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.3.8.2" style="padding-left:2.3pt;padding-right:2.3pt;">39.1/73.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.3.8.3" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.3.8.3.1">85.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.3.8.4" style="padding-left:2.3pt;padding-right:2.3pt;">
<span class="ltx_text ltx_font_bold" id="S5.T4.3.8.4.1">64.5</span>/<span class="ltx_text ltx_font_bold" id="S5.T4.3.8.4.2">82.0</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.3.8.5" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.3.8.5.1">81.5</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>
Performance on WMT23 terminology translation test sets.
â€œSucâ€ indicates Terminology Success Rate.
</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px4.p1.8">During training, we introduce special instructions to train the model to use the provided segment pairs.
In this experiment, we evaluate the effectiveness of the instructions on a terminology translation test set from WMT23<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>https://wmt-terminology-task.github.io/</span></span></span>.
The numbers of sentences on Zh<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.1.m1.1"><semantics id="S5.SS2.SSS0.Px4.p1.1.m1.1a"><mo id="S5.SS2.SSS0.Px4.p1.1.m1.1.1" stretchy="false" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.1.m1.1b"><ci id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.1.m1.1d">â‡’</annotation></semantics></math>En and De<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.2.m2.1"><semantics id="S5.SS2.SSS0.Px4.p1.2.m2.1a"><mo id="S5.SS2.SSS0.Px4.p1.2.m2.1.1" stretchy="false" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.2.m2.1b"><ci id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.2.m2.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.2.m2.1d">â‡’</annotation></semantics></math>En are 2640 and 2963, respectively.
The average numbers of terms per segment on Zh<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.3.m3.1"><semantics id="S5.SS2.SSS0.Px4.p1.3.m3.1a"><mo id="S5.SS2.SSS0.Px4.p1.3.m3.1.1" stretchy="false" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.3.m3.1b"><ci id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.3.m3.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.3.m3.1d">â‡’</annotation></semantics></math>En and De<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.4.m4.1"><semantics id="S5.SS2.SSS0.Px4.p1.4.m4.1a"><mo id="S5.SS2.SSS0.Px4.p1.4.m4.1.1" stretchy="false" xref="S5.SS2.SSS0.Px4.p1.4.m4.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.4.m4.1b"><ci id="S5.SS2.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.4.m4.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.4.m4.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.4.m4.1d">â‡’</annotation></semantics></math>En are 3.8 and 1.1, respectively.
The result is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S5.T4" title="Table 4 â€£ Terminology. â€£ 5.2 Main Results â€£ 5 Experiments â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>, and
we only present the systems achieving the best performance on a specific metric <cite class="ltx_cite ltx_citemacro_cite">Semenov etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib27" title="">2023</a>)</cite>.
<span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px4.p1.8.1">Lingua Custodia</span> and <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px4.p1.8.2">VARCO</span> are specialized Transformer architectures to ensure the appearance of given terminology in the translation, and <math alttext="\text{UEDIN}_{\rm LLM}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.5.m5.1"><semantics id="S5.SS2.SSS0.Px4.p1.5.m5.1a"><msub id="S5.SS2.SSS0.Px4.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2a.cmml">UEDIN</mtext><mi id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.3" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.3.cmml">LLM</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.5.m5.1b"><apply id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2a.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2"><mtext class="ltx_mathvariant_italic" id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.2">UEDIN</mtext></ci><ci id="S5.SS2.SSS0.Px4.p1.5.m5.1.1.3.cmml" xref="S5.SS2.SSS0.Px4.p1.5.m5.1.1.3">LLM</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.5.m5.1c">\text{UEDIN}_{\rm LLM}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.5.m5.1d">UEDIN start_POSTSUBSCRIPT roman_LLM end_POSTSUBSCRIPT</annotation></semantics></math> uses ChatGPT with terminology translation prompts.
Compared to them, our models achieve significantly higher terminology success rates, indicating a superior ability to accurately respond to the given domain-specific terminology.
On the quality metrics, our models are inferior to <math alttext="\text{UEDIN}_{\rm LLM}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.6.m6.1"><semantics id="S5.SS2.SSS0.Px4.p1.6.m6.1a"><msub id="S5.SS2.SSS0.Px4.p1.6.m6.1.1" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2a.cmml">UEDIN</mtext><mi id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.3" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.3.cmml">LLM</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.6.m6.1b"><apply id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2a.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2"><mtext class="ltx_mathvariant_italic" id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.2">UEDIN</mtext></ci><ci id="S5.SS2.SSS0.Px4.p1.6.m6.1.1.3.cmml" xref="S5.SS2.SSS0.Px4.p1.6.m6.1.1.3">LLM</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.6.m6.1c">\text{UEDIN}_{\rm LLM}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.6.m6.1d">UEDIN start_POSTSUBSCRIPT roman_LLM end_POSTSUBSCRIPT</annotation></semantics></math> on Zh<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.7.m7.1"><semantics id="S5.SS2.SSS0.Px4.p1.7.m7.1a"><mo id="S5.SS2.SSS0.Px4.p1.7.m7.1.1" stretchy="false" xref="S5.SS2.SSS0.Px4.p1.7.m7.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.7.m7.1b"><ci id="S5.SS2.SSS0.Px4.p1.7.m7.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.7.m7.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.7.m7.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.7.m7.1d">â‡’</annotation></semantics></math>En, and achieve the best results on De<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px4.p1.8.m8.1"><semantics id="S5.SS2.SSS0.Px4.p1.8.m8.1a"><mo id="S5.SS2.SSS0.Px4.p1.8.m8.1.1" stretchy="false" xref="S5.SS2.SSS0.Px4.p1.8.m8.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.8.m8.1b"><ci id="S5.SS2.SSS0.Px4.p1.8.m8.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.8.m8.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.8.m8.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px4.p1.8.m8.1d">â‡’</annotation></semantics></math>En.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Analysis</h2>
<figure class="ltx_figure" id="S6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="885" id="S6.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>
BLEU and COMET on the WMT22 test sets with varying <math alttext="K" class="ltx_Math" display="inline" id="S6.F3.2.m1.1"><semantics id="S6.F3.2.m1.1b"><mi id="S6.F3.2.m1.1.1" xref="S6.F3.2.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.F3.2.m1.1c"><ci id="S6.F3.2.m1.1.1.cmml" xref="S6.F3.2.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.2.m1.1d">K</annotation><annotation encoding="application/x-llamapun" id="S6.F3.2.m1.1e">italic_K</annotation></semantics></math> and model sizes.
</figcaption>
</figure>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Effect of <math alttext="K" class="ltx_Math" display="inline" id="S6.SS1.1.m1.1"><semantics id="S6.SS1.1.m1.1b"><mi id="S6.SS1.1.m1.1.1" xref="S6.SS1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.1.m1.1c"><ci id="S6.SS1.1.m1.1.1.cmml" xref="S6.SS1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.1.m1.1d">K</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.1.m1.1e">italic_K</annotation></semantics></math>
</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.3">The maximal number of bilingual contexts of each matched sense is influenced by <math alttext="K" class="ltx_Math" display="inline" id="S6.SS1.p1.1.m1.1"><semantics id="S6.SS1.p1.1.m1.1a"><mi id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><ci id="S6.SS1.p1.1.m1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p1.1.m1.1d">italic_K</annotation></semantics></math>.
We show the performance of varying <math alttext="K" class="ltx_Math" display="inline" id="S6.SS1.p1.2.m2.1"><semantics id="S6.SS1.p1.2.m2.1a"><mi id="S6.SS1.p1.2.m2.1.1" xref="S6.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.2.m2.1b"><ci id="S6.SS1.p1.2.m2.1.1.cmml" xref="S6.SS1.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p1.2.m2.1d">italic_K</annotation></semantics></math>s across different model sizes on the
WMT22 test sets (Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.F3" title="Figure 3 â€£ 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>).
Regardless of the amount of training data used, the larger models perform better and require less data for fine-tuning.
In addition, the modelâ€™s performance improves as <math alttext="K" class="ltx_Math" display="inline" id="S6.SS1.p1.3.m3.1"><semantics id="S6.SS1.p1.3.m3.1a"><mi id="S6.SS1.p1.3.m3.1.1" xref="S6.SS1.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.3.m3.1b"><ci id="S6.SS1.p1.3.m3.1.1.cmml" xref="S6.SS1.p1.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p1.3.m3.1d">italic_K</annotation></semantics></math> increases from 1 to 3.
With the addition of more parallel data, the performance gains begin to plateau or even slightly decrease, which aligns with the conclusions of the previous study <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>.
Thanks to the strong few-shot learning capability of the backbones, we do not need to provide as many training examples as before when training the NMT model.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Alternative Data Selection Strategies</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">In this experiment, we investigate two intuitive data collection methods:
1) random selection (<span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.1">RAND</span>), in which the training data are randomly sampled from the corpus; and 2) quality-based selection (<span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.2">TOP</span>), in which the training samples are selected based on the COMET-KIWI scores in descending order.
Specifically, we use these two methods to extract the same sample quantity as LexMatcher to mitigate the impact of sample quantity.
We use LLaMA2-7B as the backbone, and the result on WMT test sets is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.F4" title="Figure 4 â€£ 6.2 Alternative Data Selection Strategies â€£ 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>.
The performance of <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.3">RAND</span> is inferior to the other two methods.
Random selection ensures a certain degree of diversity but the performance is uncontrollable and non-reproducible.
<span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.4">TOP</span> performs better than <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.5">RAND</span>,
demonstrating the importance of data quality for instruction tuning.
<span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.6">LexMatcher</span> can simultaneously consider both quality and diversity and achieve the best performance.</p>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="783" id="S6.F4.g1" src="x4.png" width="681"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>
Performance of different data selection strategies.
</figcaption>
</figure>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S6.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>

Word frequency distributions.
The blue and gray curves denote the distributions calculated on the data selected by <span class="ltx_text" id="S6.F5.2.1" style="color:#0000FF;">LexMatcher (K=1)</span> and randomly selected data, respectively.
</figcaption>
</figure>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Word Frequency Distribution</h4>
<div class="ltx_para" id="S6.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p1.2">We are interested in whether the collected data has a different word frequency distribution from the general (randomly selected) one.
We use the English data of the EN<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S6.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S6.SS2.SSS0.Px1.p1.1.m1.1a"><mo id="S6.SS2.SSS0.Px1.p1.1.m1.1.1" stretchy="false" xref="S6.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S6.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S6.SS2.SSS0.Px1.p1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px1.p1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px1.p1.1.m1.1d">â‡’</annotation></semantics></math>ZH translation task with <math alttext="K" class="ltx_Math" display="inline" id="S6.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S6.SS2.SSS0.Px1.p1.2.m2.1a"><mi id="S6.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S6.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S6.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S6.SS2.SSS0.Px1.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px1.p1.2.m2.1d">italic_K</annotation></semantics></math>=1, and plot the word frequency distributions of the collected data (blue curve) and the corresponding random data (gray curve).
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.F5" title="Figure 5 â€£ 6.2 Alternative Data Selection Strategies â€£ 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>, the blue curve tends to be smoother than the gray one, and the blue curve has more flat segments.
For words with higher frequency rankings, the word frequency of the data selected based on the dictionary is lower than that of the random data.
This phenomenon indicates that the dictionary-based method has generated a less skewed data distribution, which could be the reason for better fine-tuning performance.
Additionally, the dictionary-based data contains 98k unique words while the random data only includes 62k unique words, indicating that the dictionary-based data covers more semantic units, thus diluting the word frequency.</p>
</div>
<figure class="ltx_table" id="S6.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T5.2">
<tr class="ltx_tr" id="S6.T5.2.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" id="S6.T5.2.2.3" rowspan="2" style="padding-left:1.4pt;padding-right:1.4pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.2.2.3.1">Model</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S6.T5.1.1.1" style="padding-left:1.4pt;padding-right:1.4pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.1">xx<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S6.T5.1.1.1.1.m1.1"><semantics id="S6.T5.1.1.1.1.m1.1a"><mo id="S6.T5.1.1.1.1.m1.1.1" stretchy="false" xref="S6.T5.1.1.1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S6.T5.1.1.1.1.m1.1b"><ci id="S6.T5.1.1.1.1.m1.1.1.cmml" xref="S6.T5.1.1.1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.1.1.1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S6.T5.1.1.1.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S6.T5.2.2.2" style="padding-left:1.4pt;padding-right:1.4pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.2.2.2.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S6.T5.2.2.2.1.m1.1"><semantics id="S6.T5.2.2.2.1.m1.1a"><mo id="S6.T5.2.2.2.1.m1.1.1" stretchy="false" xref="S6.T5.2.2.2.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S6.T5.2.2.2.1.m1.1b"><ci id="S6.T5.2.2.2.1.m1.1.1.cmml" xref="S6.T5.2.2.2.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.2.2.2.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S6.T5.2.2.2.1.m1.1d">â‡’</annotation></semantics></math>xx</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S6.T5.2.2.4" rowspan="2" style="padding-left:1.4pt;padding-right:1.4pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.2.2.4.1">DiBi-Acc</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.3.1" style="padding-left:1.4pt;padding-right:1.4pt;">BLEU/COMET</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.3.2" style="padding-left:1.4pt;padding-right:1.4pt;">BLEU/COMET</td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S6.T5.2.4.1" style="padding-left:1.4pt;padding-right:1.4pt;">Dev</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T5.2.4.2" style="padding-left:1.4pt;padding-right:1.4pt;">29.77/82.05</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T5.2.4.3" style="padding-left:1.4pt;padding-right:1.4pt;">29.41/84.63</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T5.2.4.4" style="padding-left:1.4pt;padding-right:1.4pt;">55.51</td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T5.2.5.1" style="padding-left:1.4pt;padding-right:1.4pt;">+Supplement</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.5.2" style="padding-left:1.4pt;padding-right:1.4pt;">30.39/82.22</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.5.3" style="padding-left:1.4pt;padding-right:1.4pt;">30.10/84.55</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.5.4" style="padding-left:1.4pt;padding-right:1.4pt;">55.96</td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T5.2.6.1" style="padding-left:1.4pt;padding-right:1.4pt;">+Retrieval</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.6.2" style="padding-left:1.4pt;padding-right:1.4pt;">32.86/82.71</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.6.3" style="padding-left:1.4pt;padding-right:1.4pt;">34.13/86.27</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T5.2.6.4" style="padding-left:1.4pt;padding-right:1.4pt;">59.98</td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S6.T5.2.7.1" style="padding-left:1.4pt;padding-right:1.4pt;">LexMatcher(3)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T5.2.7.2" style="padding-left:1.4pt;padding-right:1.4pt;">32.71/82.61</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T5.2.7.3" style="padding-left:1.4pt;padding-right:1.4pt;">34.29/86.55</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T5.2.7.4" style="padding-left:1.4pt;padding-right:1.4pt;">61.44</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>

Ablation study on different data subsets.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Ablation Study</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">The ablation experiment of different data subsets is presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.T5" title="Table 5 â€£ Word Frequency Distribution â€£ 6.2 Alternative Data Selection Strategies â€£ 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>.
We use LLaMA2-7B as the backbone.
Based on the development data, simply incorporating the small amount of synthesized data generated during the data augmentation phase does not have a significant impact on the performance.
This is possible because the data is predominantly focused on low-frequency senses, and the model is unable to effectively leverage this knowledge.
In comparison, adding the retrieved data leads to a significant performance improvement, and further introducing the synthesized data helps the model learn word disambiguation better, increasing the disambiguation accuracy from 59.98 to 61.44.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Combination with Other LLMs</h3>
<figure class="ltx_table" id="S6.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T6.2">
<tr class="ltx_tr" id="S6.T6.2.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" id="S6.T6.2.2.3" rowspan="2" style="padding-left:1.4pt;padding-right:1.4pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.2.2.3.1">Model</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S6.T6.1.1.1" style="padding-left:1.4pt;padding-right:1.4pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.1.1">xx<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S6.T6.1.1.1.1.m1.1"><semantics id="S6.T6.1.1.1.1.m1.1a"><mo id="S6.T6.1.1.1.1.m1.1.1" stretchy="false" xref="S6.T6.1.1.1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S6.T6.1.1.1.1.m1.1b"><ci id="S6.T6.1.1.1.1.m1.1.1.cmml" xref="S6.T6.1.1.1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.1.1.1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S6.T6.1.1.1.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S6.T6.2.2.2" style="padding-left:1.4pt;padding-right:1.4pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.2.2.2.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="S6.T6.2.2.2.1.m1.1"><semantics id="S6.T6.2.2.2.1.m1.1a"><mo id="S6.T6.2.2.2.1.m1.1.1" stretchy="false" xref="S6.T6.2.2.2.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="S6.T6.2.2.2.1.m1.1b"><ci id="S6.T6.2.2.2.1.m1.1.1.cmml" xref="S6.T6.2.2.2.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.2.2.2.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="S6.T6.2.2.2.1.m1.1d">â‡’</annotation></semantics></math>xx</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.3.1" style="padding-left:1.4pt;padding-right:1.4pt;">BLEU/COMET</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.3.2" style="padding-left:1.4pt;padding-right:1.4pt;">BLEU/COMET</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S6.T6.2.4.1" style="padding-left:1.4pt;padding-right:1.4pt;">ALMA</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.2.4.2" style="padding-left:1.4pt;padding-right:1.4pt;">30.64/82.84</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.2.4.3" style="padding-left:1.4pt;padding-right:1.4pt;">31.29/85.93</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.5.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(1)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.5.2" style="padding-left:1.4pt;padding-right:1.4pt;">32.34/83.11</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.5.3" style="padding-left:1.4pt;padding-right:1.4pt;">33.50/86.42</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.6.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(2)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.6.2" style="padding-left:1.4pt;padding-right:1.4pt;">31.88/83.07</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.6.3" style="padding-left:1.4pt;padding-right:1.4pt;">33.31/86.47</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.7.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(3)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.7.2" style="padding-left:1.4pt;padding-right:1.4pt;">33.37/83.32</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.7.3" style="padding-left:1.4pt;padding-right:1.4pt;">35.30/87.09</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.8">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.8.1" style="padding-left:1.4pt;padding-right:1.4pt;">LLaMA3-8B</td>
<td class="ltx_td" id="S6.T6.2.8.2" style="padding-left:1.4pt;padding-right:1.4pt;"></td>
<td class="ltx_td" id="S6.T6.2.8.3" style="padding-left:1.4pt;padding-right:1.4pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.9">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.9.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(1)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.9.2" style="padding-left:1.4pt;padding-right:1.4pt;">33.15/83.26</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.9.3" style="padding-left:1.4pt;padding-right:1.4pt;">34.20/86.58</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.10.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(2)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.10.2" style="padding-left:1.4pt;padding-right:1.4pt;">33.29/83.26</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.10.3" style="padding-left:1.4pt;padding-right:1.4pt;">35.12/87.00</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.11">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.11.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(3)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.11.2" style="padding-left:1.4pt;padding-right:1.4pt;">33.74/83.29</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.11.3" style="padding-left:1.4pt;padding-right:1.4pt;">35.38/86.97</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.12">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.12.1" style="padding-left:1.4pt;padding-right:1.4pt;">Gemma-2B</td>
<td class="ltx_td" id="S6.T6.2.12.2" style="padding-left:1.4pt;padding-right:1.4pt;"></td>
<td class="ltx_td" id="S6.T6.2.12.3" style="padding-left:1.4pt;padding-right:1.4pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.13">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.13.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(1)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.13.2" style="padding-left:1.4pt;padding-right:1.4pt;">31.68/82.42</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.13.3" style="padding-left:1.4pt;padding-right:1.4pt;">31.01/84.83</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.14">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.T6.2.14.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(2)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.14.2" style="padding-left:1.4pt;padding-right:1.4pt;">31.83/82.39</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.2.14.3" style="padding-left:1.4pt;padding-right:1.4pt;">32.13/85.50</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.15">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S6.T6.2.15.1" style="padding-left:1.4pt;padding-right:1.4pt;">+LexMatcher(3)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T6.2.15.2" style="padding-left:1.4pt;padding-right:1.4pt;">31.93/82.43</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T6.2.15.3" style="padding-left:1.4pt;padding-right:1.4pt;">32.33/85.66</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>

The performance of LexMatcher combined with different LLMs.
</figcaption>
</figure>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">In this section, we investigate the performance of our data curation on different LLMs including ALMA-7B <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite>, LLaMA3-8B, and Gemma-2B <cite class="ltx_cite ltx_citemacro_cite">Mesnard etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib21" title="">2024</a>)</cite>, and the results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.T6" title="Table 6 â€£ 6.4 Combination with Other LLMs â€£ 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>.
ALMA <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib34" title="">2024</a>)</cite> is the post-trained LLaMA2 on a large amount of monolingual data mixed by different languages.
We find that adding the parallel sentences constructed by LexMatcher further enhance its performance, indicating the compatibility of monolingual continual pretraining and supervised fine-tuning.
Although the use of monolingual data during pretraining can reduce the dependency on bilingual data, the direct application of bilingual data for fine-tuning can be more resource-efficient.
The size of parallel data collected by LexMatcher is considerably smaller than that of mixed monolingual data, and the training process is only a single stage.
Furthermore,
</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Compositional Generalization</h3>
<figure class="ltx_table" id="S6.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T7.1">
<tr class="ltx_tr" id="S6.T7.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T7.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T7.1.1.2">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T7.1.1.3">Instance</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T7.1.1.4">Aggregate</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T7.1.2.1">Transformer</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.2.2">59.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.2.3">28.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.2.4">62.9</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.3">
<td class="ltx_td ltx_align_left" id="S6.T7.1.3.1">Transformer+CReg</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.3.2">61.3</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.3.3">20.2</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.3.4">48.3</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T7.1.4.1">LLaMA2-ICL</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.4.2">38.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.4.3">68.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.4.4">87.4</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.5">
<td class="ltx_td ltx_align_left" id="S6.T7.1.5.1">LLaMA2-SFT</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.2">62.4</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.3">18.5</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.4">43.9</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T7.1.6.1">LexMatcher</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T7.1.6.2">63.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T7.1.6.3">15.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T7.1.6.4">37.3</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>
Compound translation error rates (CTERs) on CoGnition.
Instance and Aggregate denote the instance-level and aggregate-level CTERs, respectively.
</figcaption>
</figure>
<div class="ltx_para" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1">We investiage the effect of a more balanced atom distribution on CoGnition <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#bib.bib15" title="">2021</a>)</cite>.
The evaluation metrics include instance-level CTER which denotes the translation accuracy of novel compounds, and aggregate-level CTER which measures the translation consistency across different contexts.
We use the data retrieval of LexMatcher to obtain 70,272 parallel sentences from the full training data (196,246) with <math alttext="K" class="ltx_Math" display="inline" id="S6.SS5.p1.1.m1.1"><semantics id="S6.SS5.p1.1.m1.1a"><mi id="S6.SS5.p1.1.m1.1.1" xref="S6.SS5.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.1.m1.1b"><ci id="S6.SS5.p1.1.m1.1.1.cmml" xref="S6.SS5.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.1.m1.1d">italic_K</annotation></semantics></math>=50.
For LLM, we apply ICL with 8 examples and fine-tune LLaMA2-7B on the randomly sampled training data, of which the size is similar to the retrieved data.
The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#S6.T7" title="Table 7 â€£ 6.5 Compositional Generalization â€£ 6 Analysis â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a>.
ICL does not yield good compositional generalization performance, while the fine-tuned LLaMA2 outperforms the previous NMT models significantly.
<span class="ltx_text ltx_font_italic" id="S6.SS5.p1.1.1">LexMatcher</span> achieves lower compound translation error rates than SFT with the same amount of training data, demonstrating the positive effect of the more balanced data distribution.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we presented LexMatcher, a dictionary-centric data curation method for supervised fine-tuning smaller-sized LLMs to better translation models.
We use the bilingual dictionary as the pivot and try to collect limited parallel sentence pairs to cover the senses uniformly.
Experiments and analyses validate the effectiveness of LexMatcher from multiple perspectives including zero-shot translation, disambiguation, and terminology translation.
One potential avenue for future research involves extending LexMatcher to low-resource scenarios, where the utilization of monolingual data is crucial for achieving satisfactory translation performance.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">This work focuses solely on improving translation performance for medium and high-resource language pairs.
For low-resource language pairs that inherently lack parallel data, it is crucial to explore how to optimize LLMs on such translation tasks by integrating dictionaries, monolingual, and possible bilingual data.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal etÂ al. (2022)</span>
<span class="ltx_bibblock">
Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, and Marjan
Ghazvininejad. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2212.02437" title="">In-context
examples selection for machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">CoRR</em>, abs/2212.02437.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bond etÂ al. (2016)</span>
<span class="ltx_bibblock">
Francis Bond, Piek Vossen, John McCrae, and Christiane Fellbaum. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2016.gwc-1.9" title="">CILI: the
collaborative interlingual index</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 8th Global WordNet Conference (GWC)</em>,
pages 50â€“57, Bucharest, Romania. Global Wordnet Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. (2020)</span>
<span class="ltx_bibblock">
TomÂ B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom
Henighan, Rewon Child, Aditya Ramesh, DanielÂ M. Ziegler, Jeffrey Wu, Clemens
Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott
Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec
Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Advances in Neural Information Processing Systems 33: Annual
Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
December 6-12, 2020, virtual</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Campolungo etÂ al. (2022)</span>
<span class="ltx_bibblock">
NiccolÃ² Campolungo, Federico Martelli, Francesco Saina, and Roberto
Navigli. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.298" title="">DiBiMT:
A novel benchmark for measuring Word Sense Disambiguation biases in
Machine Translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 4331â€“4352,
Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edunov etÂ al. (2018)</span>
<span class="ltx_bibblock">
Sergey Edunov, Myle Ott, Michael Auli, and David Grangier. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/D18-1045" title="">Understanding
back-translation at scale</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing, Brussels, Belgium, October 31 - November 4,
2018</em>, pages 489â€“500. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernandes etÂ al. (2023)</span>
<span class="ltx_bibblock">
Patrick Fernandes, Behrooz Ghorbani, Xavier Garcia, Markus Freitag, and Orhan
Firat. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v202/fernandes23a.html" title="">Scaling
laws for multilingual neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International Conference on Machine Learning, ICML 2023,
23-29 July 2023, Honolulu, Hawaii, USA</em>, volume 202 of <em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2">Proceedings of
Machine Learning Research</em>, pages 10053â€“10071. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghazvininejad etÂ al. (2023)</span>
<span class="ltx_bibblock">
Marjan Ghazvininejad, Hila Gonen, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2302.07856" title="">Dictionary-based
phrase-level prompting of large language models for machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">CoRR</em>, abs/2302.07856.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gordon etÂ al. (2021)</span>
<span class="ltx_bibblock">
MitchellÂ A Gordon, Kevin Duh, and Jared Kaplan. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.478" title="">Data and
parameter scaling laws for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 5915â€“5922, Online and Punta Cana,
Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunasekar etÂ al. (2023)</span>
<span class="ltx_bibblock">
Suriya Gunasekar, YiÂ Zhang, Jyoti Aneja, Caio CÃ©sarÂ Teodoro Mendes,
AllieÂ Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo
deÂ Rosa, Olli Saarikivi, Adil Salim, Shital Shah, HarkiratÂ Singh Behl, Xin
Wang, SÃ©bastien Bubeck, Ronen Eldan, AdamÂ Tauman Kalai, YinÂ Tat Lee,
and Yuanzhi Li. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2306.11644" title="">Textbooks are all
you need</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">CoRR</em>, abs/2306.11644.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendy etÂ al. (2023)</span>
<span class="ltx_bibblock">
Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu
Matsushita, YoungÂ Jin Kim, Mohamed Afify, and HanyÂ Hassan Awadalla. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2302.09210" title="">How good are GPT
models at machine translation? A comprehensive evaluation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">CoRR</em>, abs/2302.09210.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Junjie Hu, Hiroaki Hayashi, Kyunghyun Cho, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.123" title="">DEEP:
DEnoising entity pre-training for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1753â€“1766,
Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyer etÂ al. (2023)</span>
<span class="ltx_bibblock">
Vivek Iyer, Pinzhen Chen, and Alexandra Birch. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.44" title="">Towards effective
disambiguation for machine translation with large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the Eighth Conference on Machine
Translation</em>, pages 482â€“495, Singapore. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Wenxiang Jiao, Jen-tse Huang, Wenxuan Wang, Zhiwei He, Tian Liang, Xing Wang,
Shuming Shi, and Zhaopeng Tu. 2023.

</span>
<span class="ltx_bibblock">ParroT: Translating during chat using large language models tuned
with human translation and feedback.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Findings of the Association for Computational Linguistics:
EMNLP 2023</em>, pages 15009â€“15020, Singapore. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar etÂ al. (2019)</span>
<span class="ltx_bibblock">
Gaurav Kumar, George Foster, Colin Cherry, and Maxim Krikun. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1208" title="">Reinforcement learning
based curriculum optimization for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 2054â€“2061,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2021)</span>
<span class="ltx_bibblock">
Yafu Li, Yongjing Yin, Yulong Chen, and Yue Zhang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.368" title="">On
compositional generalization of neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 59th Annual Meeting of the Association
for Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing (Volume 1: Long Papers)</em>, pages 4767â€“4780,
Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yafu Li, Yongjing Yin, Jing Li, and Yue Zhang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-acl.203" title="">Prompt-driven neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Findings of the Association for Computational Linguistics:
ACL 2022</em>, pages 2579â€“2590, Dublin, Ireland. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yuanzhi Li, SÃ©bastien Bubeck, Ronen Eldan, AllieÂ Del Giorno, Suriya
Gunasekar, and YinÂ Tat Lee. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.05463" title="">Textbooks are all
you need II: phi-1.5 technical report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">CoRR</em>, abs/2309.05463.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2022)</span>
<span class="ltx_bibblock">
XiÂ Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen,
Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth
Pasunuru, Sam Shleifer, PunitÂ Singh Koura, Vishrav Chaudhary, Brian Oâ€™Horo,
Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, MonaÂ T. Diab, Veselin
Stoyanov, and Xian Li. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.emnlp-main.616" title="">Few-shot
learning with multilingual generative language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">EMNLP 2022</em>, pages 9019â€“9052.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, and Furu Wei.
2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.06575" title="">Chain-of-dictionary prompting elicits translation in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">CoRR</em>, abs/2305.06575.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mao and Yu (2024)</span>
<span class="ltx_bibblock">
Zhuoyuan Mao and Yen Yu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2401.05811" title="">Tuning llms with
contrastive alignment instructions for machine translation in unseen,
low-resource languages</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">CoRR</em>, abs/2401.05811.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mesnard etÂ al. (2024)</span>
<span class="ltx_bibblock">
Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, and
ShreyaÂ Pathak etÂ al. 2024.

</span>
<span class="ltx_bibblock">Gemma: Open models based on gemini research and technology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">CoRR</em>, abs/2403.08295.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohiuddin etÂ al. (2022)</span>
<span class="ltx_bibblock">
Tasnim Mohiuddin, Philipp Koehn, Vishrav Chaudhary, James Cross, Shruti
Bhosale, and Shafiq Joty. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-emnlp.113" title="">Data
selection curriculum for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Findings of the Association for Computational Linguistics:
EMNLP 2022</em>, pages 1569â€“1582, Abu Dhabi, United Arab Emirates. Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2303.08774" title="">GPT-4 technical
report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">CoRR</em>, abs/2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni etÂ al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for
automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 40th Annual Meeting of the Association
for Computational Linguistics</em>, pages 311â€“318. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patel etÂ al. (2022)</span>
<span class="ltx_bibblock">
Arkil Patel, Satwik Bhattamishra, Phil Blunsom, and Navin Goyal. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-short.46" title="">Revisiting the
compositional generalization abilities of neural sequence models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)</em>, pages 424â€“434,
Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei etÂ al. (2022)</span>
<span class="ltx_bibblock">
Ricardo Rei, JosÃ© G.Â C. deÂ Souza, DuarteÂ M. Alves, Chrysoula Zerva,
AnaÂ C. Farinha, Taisiya Glushkova, Alon Lavie, LuÃ­sa Coheur, and
AndrÃ© F.Â T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.52" title="">COMET-22:
unbabel-ist 2022 submission for the metrics shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the Seventh Conference on Machine
Translation, WMT 2022, Abu Dhabi, United Arab Emirates (Hybrid), December
7-8, 2022</em>, pages 578â€“585. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Semenov etÂ al. (2023)</span>
<span class="ltx_bibblock">
Kirill Semenov, VilÃ©m Zouhar, Tom Kocmi, Dongdong Zhang, Wangchunshu Zhou, and
YuchenÂ Eleanor Jiang. 2023.

</span>
<span class="ltx_bibblock">Findings of the wmt 2023 shared task on machine translation with
terminologies.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the Eight Conference on Machine Translation
(WMT)</em>. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich etÂ al. (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/P16-1009" title="">Improving neural
machine translation models with monolingual data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 54th Annual Meeting of the Association
for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin,
Germany, Volume 1: Long Papers</em>. The Association for Computer Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric
Hambro, Faisal Azhar, AurÃ©lien Rodriguez, Armand Joulin, Edouard Grave,
and Guillaume Lample. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2302.13971" title="">Llama: Open and
efficient foundation language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">CoRR</em>, abs/2302.13971.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem
Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar
Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, PunitÂ Singh Koura, Marie-Anne Lachaux,
Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier
Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew
Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan
Silva, EricÂ Michael Smith, Ranjan Subramanian, XiaoqingÂ Ellen Tan, Binh Tang,
Ross Taylor, Adina Williams, JianÂ Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan
Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
AurÃ©lien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom.
2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2307.09288" title="">Llama 2: Open
foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">CoRR</em>, abs/2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">vanÂ der Wees etÂ al. (2017)</span>
<span class="ltx_bibblock">
Marlies vanÂ der Wees, Arianna Bisazza, and Christof Monz. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D17-1147" title="">Dynamic data selection
for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 1400â€“1410, Copenhagen, Denmark.
Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Shuo Wang, Zhixing Tan, and Yang Liu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.487" title="">Integrating
vectorized lexical constraints for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 7063â€“7073,
Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Wei Wang, Taro Watanabe, Macduff Hughes, Tetsuji Nakagawa, and Ciprian Chelba.
2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-6314" title="">Denoising neural
machine translation training with trusted data and online data selection</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the Third Conference on Machine Translation:
Research Papers</em>, pages 133â€“143, Brussels, Belgium. Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Haoran Xu, YoungÂ Jin Kim, Amr Sharaf, and HanyÂ Hassan Awadalla. 2024.

</span>
<span class="ltx_bibblock">A paradigm shift in machine translation: Boosting translation
performance of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Wen Yang, Chong Li, Jiajun Zhang, and Chengqing Zong. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.18098" title="">Bigtrans:
Augmenting large language models with multilingual translation capability
over 100 languages</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">CoRR</em>, abs/2305.18098.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng etÂ al. (2024)</span>
<span class="ltx_bibblock">
Jiali Zeng, Fandong Meng, Yongjing Yin, and Jie Zhou. 2024.

</span>
<span class="ltx_bibblock">TIM: teaching large language models to translate with comparison.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">AAAI2024</em>, pages 19488â€“19496. AAAI Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zixin Zeng, Rui Wang, Yichong Leng, Junliang Guo, Shufang Xie, XuÂ Tan, Tao Qin,
and Tie-Yan Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.107" title="">Extract
and attend: Improving entity translation in neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Findings of the Association for Computational Linguistics:
ACL 2023</em>, pages 1697â€“1710, Toronto, Canada. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin
Huang, Mengyu Bu, Shangtong Gui, Yunji Chen, Xilin Chen, and Yang Feng. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2306.10968" title="">Bayling: Bridging
cross-lingual alignment and instruction following through interactive
translation for large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">CoRR</em>, abs/2306.10968.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yang Zhao, Jiajun Zhang, YuÂ Zhou, and Chengqing Zong. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.24963/IJCAI.2020/559" title="">Knowledge graphs
enhanced neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the Twenty-Ninth International Joint
Conference on Artificial Intelligence, IJCAI 2020</em>, pages 4039â€“4045.
ijcai.org.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe
Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke
Zettlemoyer, and Omer Levy. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.11206" title="">LIMA: less is
more for alignment</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">CoRR</em>, abs/2305.11206.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Lingpeng Kong, Jiajun Chen,
Lei Li, and Shujian Huang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2304.04675" title="">Multilingual
machine translation with large language models: Empirical results and
analysis</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">CoRR</em>, abs/2304.04675.

</span>
</li>
</ul>
</section>
<figure class="ltx_figure" id="A0.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="493" id="A0.F6.g1" src="x6.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Prompts used for (a) manipulating ChatGPT to generate translation demonstrations and (b) terminology translation.
</figcaption>
</figure>
<figure class="ltx_table" id="A0.T8">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A0.T8.6" style="width:433.6pt;height:232.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-85.7pt,45.9pt) scale(0.716725963138061,0.716725963138061) ;">
<table class="ltx_tabular ltx_align_middle" id="A0.T8.6.6">
<tr class="ltx_tr" id="A0.T8.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A0.T8.6.6.6.7" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A0.T8.6.6.6.7.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A0.T8.1.1.1.1.1">Zh<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="A0.T8.1.1.1.1.1.m1.1"><semantics id="A0.T8.1.1.1.1.1.m1.1a"><mo id="A0.T8.1.1.1.1.1.m1.1.1" stretchy="false" xref="A0.T8.1.1.1.1.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="A0.T8.1.1.1.1.1.m1.1b"><ci id="A0.T8.1.1.1.1.1.m1.1.1.cmml" xref="A0.T8.1.1.1.1.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.T8.1.1.1.1.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="A0.T8.1.1.1.1.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.2.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A0.T8.2.2.2.2.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="A0.T8.2.2.2.2.1.m1.1"><semantics id="A0.T8.2.2.2.2.1.m1.1a"><mo id="A0.T8.2.2.2.2.1.m1.1.1" stretchy="false" xref="A0.T8.2.2.2.2.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="A0.T8.2.2.2.2.1.m1.1b"><ci id="A0.T8.2.2.2.2.1.m1.1.1.cmml" xref="A0.T8.2.2.2.2.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.T8.2.2.2.2.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="A0.T8.2.2.2.2.1.m1.1d">â‡’</annotation></semantics></math>Zh</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.3.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A0.T8.3.3.3.3.1">De<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="A0.T8.3.3.3.3.1.m1.1"><semantics id="A0.T8.3.3.3.3.1.m1.1a"><mo id="A0.T8.3.3.3.3.1.m1.1.1" stretchy="false" xref="A0.T8.3.3.3.3.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="A0.T8.3.3.3.3.1.m1.1b"><ci id="A0.T8.3.3.3.3.1.m1.1.1.cmml" xref="A0.T8.3.3.3.3.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.T8.3.3.3.3.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="A0.T8.3.3.3.3.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.4.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A0.T8.4.4.4.4.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="A0.T8.4.4.4.4.1.m1.1"><semantics id="A0.T8.4.4.4.4.1.m1.1a"><mo id="A0.T8.4.4.4.4.1.m1.1.1" stretchy="false" xref="A0.T8.4.4.4.4.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="A0.T8.4.4.4.4.1.m1.1b"><ci id="A0.T8.4.4.4.4.1.m1.1.1.cmml" xref="A0.T8.4.4.4.4.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.T8.4.4.4.4.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="A0.T8.4.4.4.4.1.m1.1d">â‡’</annotation></semantics></math>De</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.5.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A0.T8.5.5.5.5.1">Ru<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="A0.T8.5.5.5.5.1.m1.1"><semantics id="A0.T8.5.5.5.5.1.m1.1a"><mo id="A0.T8.5.5.5.5.1.m1.1.1" stretchy="false" xref="A0.T8.5.5.5.5.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="A0.T8.5.5.5.5.1.m1.1b"><ci id="A0.T8.5.5.5.5.1.m1.1.1.cmml" xref="A0.T8.5.5.5.5.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.T8.5.5.5.5.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="A0.T8.5.5.5.5.1.m1.1d">â‡’</annotation></semantics></math>En</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.6.6.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="A0.T8.6.6.6.6.1">En<math alttext="\Rightarrow" class="ltx_Math" display="inline" id="A0.T8.6.6.6.6.1.m1.1"><semantics id="A0.T8.6.6.6.6.1.m1.1a"><mo id="A0.T8.6.6.6.6.1.m1.1.1" stretchy="false" xref="A0.T8.6.6.6.6.1.m1.1.1.cmml">â‡’</mo><annotation-xml encoding="MathML-Content" id="A0.T8.6.6.6.6.1.m1.1b"><ci id="A0.T8.6.6.6.6.1.m1.1.1.cmml" xref="A0.T8.6.6.6.6.1.m1.1.1">â‡’</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.T8.6.6.6.6.1.m1.1c">\Rightarrow</annotation><annotation encoding="application/x-llamapun" id="A0.T8.6.6.6.6.1.m1.1d">â‡’</annotation></semantics></math>Ru</span></td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.7">
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">BLEU/COMET</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T8.6.6.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Dev</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.6.6.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.59/78.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.6.6.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">35.43/84.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.6.6.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.04/83.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.6.6.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.58/84.09</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.6.6.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.68/83.58</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.6.6.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.23/85.54</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.9">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+Supplement</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.69/79.05</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.50/84.20</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.45/83.82</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.67/83.98</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.03/83.80</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.14/85.49</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.10">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+Retrieval</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.36/79.46</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.14/86.01</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.37/84.31</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.10.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.26/85.77</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.10.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.86/84.36</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.10.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.00/87.03</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.11">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">LexMatcher(3)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.81/79.13</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.34/86.11</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.33/84.29</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.56/86.31</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.11.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.01/84.43</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.11.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.97/87.23</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.12">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T8.6.6.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">ALMA-7B</td>
<td class="ltx_td ltx_border_t" id="A0.T8.6.6.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A0.T8.6.6.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A0.T8.6.6.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A0.T8.6.6.12.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A0.T8.6.6.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A0.T8.6.6.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.13">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.13.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(1)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.13.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.27/79.82</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.13.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.77/84.52</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.13.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.00/85.01</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.13.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.61/85.83</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.13.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.12/86.19</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.13.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.77/87.25</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.14">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.14.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(2)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.14.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.04/79.88</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.14.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.27/85.93</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.14.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.39/84.32</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.14.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.85/86.14</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.14.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.61/85.07</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.14.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.82/87.34</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.15">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.15.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(3)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.15.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.20/80.21</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.15.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.40/86.59</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.15.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.49/84.49</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.15.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">34.44/86.66</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.15.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.42/85.28</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.15.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.07/88.02</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.16">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.16.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">LLaMA3-8B</td>
<td class="ltx_td" id="A0.T8.6.6.16.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.16.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.16.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.16.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.16.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.16.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.17">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.17.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(1)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.17.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.40/80.47</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.17.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.30/86.11</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.17.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.44/84.52</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.17.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.16/86.09</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.17.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.63/84.79</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.17.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.15/87.54</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.18">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.18.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(2)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.18.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.33/80.31</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.18.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.34/86.94</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.18.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.36/84.54</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.18.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.68/86.37</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.18.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.19/84.93</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.18.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.36/87.69</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.19">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.19.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(3)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.19.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.89/80.51</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.19.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.88/86.74</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.19.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">32.95/84.46</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.19.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">34.22/86.49</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.19.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.39/84.92</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.19.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.04/87.70</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.20">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.20.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Gemma-2B</td>
<td class="ltx_td" id="A0.T8.6.6.20.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.20.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.20.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.20.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.20.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td" id="A0.T8.6.6.20.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.21">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.21.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(1)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.21.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.88/79.75</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.21.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.89/85.01</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.21.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.35/83.77</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.21.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.27/83.95</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.21.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.81/83.75</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.21.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.87/85.53</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.22">
<td class="ltx_td ltx_align_left" id="A0.T8.6.6.22.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(2)</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.22.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.19/79.60</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.22.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">39.53/85.92</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.22.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.43/83.77</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.22.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.35/84.51</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.22.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.87/83.81</td>
<td class="ltx_td ltx_align_center" id="A0.T8.6.6.22.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.53/86.09</td>
</tr>
<tr class="ltx_tr" id="A0.T8.6.6.23">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T8.6.6.23.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">+LexMatcher(3)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.6.6.23.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.84/79.55</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.6.6.23.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">39.19/85.98</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.6.6.23.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.77/83.80</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.6.6.23.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.81/85.04</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.6.6.23.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">39.18/83.95</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.6.6.23.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.00/85.98</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>

Detailed results of ablation study and combination with different LLMs.
</figcaption>
</figure>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Computational Details</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">We conducted experiments using the Huggingface Transformers.
The experiments are performed on NVIDIA A100 GPU, and all the results are run once with the random seed 42.
According to the data license of WMT22, the data released for the General MT task can be freely used for research purposes.</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Prompts Used for Manipulating ChatGPT and Terminology Translation</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">The prompt used to manipulate ChatGPT consists of three parts (Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A0.F6" title="Figure 6 â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> (a)).
The first part is used to describe the task: generate a pair of parallel sentences, which can reflect the meaning of a given segment pair accurately.
The second part is an example to demonstrate the format of the input and output including a segment pair, a definition of the sense, and a sentence pair.
The third part is the segment pair requires translation demonstration.</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">The prompt for terminology translation is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.01441v2#A0.F6" title="Figure 6 â€£ LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> (b).</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Corpus Preprocessing</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Since the filtered data of Russian<math alttext="\Leftrightarrow" class="ltx_Math" display="inline" id="A3.p1.1.m1.1"><semantics id="A3.p1.1.m1.1a"><mo id="A3.p1.1.m1.1.1" stretchy="false" xref="A3.p1.1.m1.1.1.cmml">â‡”</mo><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><ci id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1">â‡”</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">\Leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="A3.p1.1.m1.1d">â‡”</annotation></semantics></math>English is significantly less than the other language pairs, we introduce the training set from Tatoeba translation challenge 2021<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/v2021-08-07/data</span></span></span>.
We filter data with the commonly used rule-based methods
and model-based QE.
The rules include the following categories:
(1) sentence-level deduplication,
(2) filter out the sentences longer than 100 words or contain a single word exceeding 40 characters,
(3) remove sentence pairs where the ratio of source sentence length to target sentence length is significantly different, i.e., below 1/3 or above 3,
(4) filter out the sentences with high repeat ratio, i.e., the proportion of the frequency of the most frequent word in a sentence to the total word frequency greater than 0.3,
and
(5) filter out the sentences in which the proportion of the content words is between 0.3 and 0.8.
In this way, low-quality data can be efficiently filtered out, saving time and resources for the subsequent model-based QE.
</p>
</div>
<div class="ltx_para" id="A3.p2">
<p class="ltx_p" id="A3.p2.1">We utilize one of the state-of-the-art QE models, COMET-KIWI<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span>https://huggingface.co/Unbabel/wmt22-cometkiwi-da</span></span></span>, to obtain sentence-level quality scores.
For every sentence pair in the training data, we calculate the QE score for the translation from English to the foreign language.
These scores are utilized for both translation directions, as evaluating both directions of the training data can be computationally expensive.
We remove sentence pairs with low data quality, e.g., those that have a score below 40.
We use spaCy<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span>https://spacy.io/</span></span></span> for the lemmatization.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul  2 06:30:46 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
