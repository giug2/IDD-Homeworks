<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.02936] EdgeFL: A Lightweight Decentralized Federated Learning Framework</title><meta property="og:description" content="Federated Learning (FL) has emerged as a promising approach for collaborative machine learning, addressing data privacy concerns. However, existing FL platforms and frameworks often present challenges for software engi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EdgeFL: A Lightweight Decentralized Federated Learning Framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="EdgeFL: A Lightweight Decentralized Federated Learning Framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.02936">

<!--Generated on Wed Feb 28 07:47:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Machine Learning,  Software Engineering,  Decentralized Architecture
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">EdgeFL: A Lightweight Decentralized Federated Learning Framework</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Hongyi Zhang1, Jan Bosch1, Helena Holmström Olsson2
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">1<span id="id1.1.id1" class="ltx_text ltx_font_italic">Chalmers University of Technology</span>, Gothenburg, Sweden. Email: {hongyiz, jan.bosch}@chalmers.se
</span>
<span class="ltx_contact ltx_role_affiliation">2<span id="id2.2.id1" class="ltx_text ltx_font_italic">Malmö University</span>, Malmö, Sweden. Email: helena.holmstrom.olsson@mau.se
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Federated Learning (FL) has emerged as a promising approach for collaborative machine learning, addressing data privacy concerns. However, existing FL platforms and frameworks often present challenges for software engineers in terms of complexity, limited customization options, and scalability limitations. In this paper, we introduce EdgeFL, an edge-only lightweight decentralized FL framework, designed to overcome the limitations of centralized aggregation and scalability in FL deployments. By adopting an edge-only model training and aggregation approach, EdgeFL eliminates the need for a central server, enabling seamless scalability across diverse use cases. With a straightforward integration process requiring just four lines of code (LOC), software engineers can easily incorporate FL functionalities into their AI products. Furthermore, EdgeFL offers the flexibility to customize aggregation functions, empowering engineers to adapt them to specific needs. Based on the results, we demonstrate that EdgeFL achieves superior performance compared to existing FL platforms/frameworks. Our results show that EdgeFL reduces weights update latency and enables faster model evolution, enhancing the efficiency of edge devices. Moreover, EdgeFL exhibits improved classification accuracy compared to traditional centralized FL approaches. By leveraging EdgeFL, software engineers can harness the benefits of federated learning while overcoming the challenges associated with existing FL platforms/frameworks.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Machine Learning, Software Engineering, Decentralized Architecture

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning is a machine learning approach that enables training models on decentralized data sources while preserving data privacy. Traditional machine learning models typically require centralizing all the data in one location for training, which can be challenging due to data privacy concerns, legal restrictions, and computational constraints. Federated learning addresses these limitations by allowing models to be trained directly on the devices or servers where the data is generated or stored, without the need to transfer it to a central location <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The key advantage of federated learning is its ability to preserve data privacy. Since the data remains on the client devices or servers, it alleviates concerns related to data exposure or sharing sensitive information. Instead of sharing raw data, only the updates to the model parameters, often encrypted or anonymized, are communicated during the training process. This decentralized approach enables organizations and individuals to collaborate on model training without compromising the privacy and security of their data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated learning finds applications in various domains, such as healthcare, finance, Internet of Things (IoT), and edge computing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. It allows organizations to leverage the collective knowledge of distributed datasets without violating privacy regulations or exposing sensitive information. Additionally, federated learning can reduce the reliance on costly data transfers and enable training on resource-constrained devices.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Despite the benefits of Federated Learning, Federated learning presents unique challenges for software engineers involved in AI engineering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. They need to design and develop distributed systems that can effectively handle the communication, coordination, and synchronization between multiple clients and a central server. This requires scalable and fault-tolerant systems to accommodate large-scale deployments while optimizing network utilization and ensuring data consistency across distributed nodes.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In addition, algorithmic development and optimization are essential for efficient federated learning. Software engineers need to understand and implement federated learning algorithms and optimization techniques, including Federated Averaging and adaptive learning rate strategies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Developing algorithms that converge to high-quality models while minimizing resource consumption is a challenging task for software engineers.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Integration with edge devices and IoT environments adds another layer of complexity. Software engineers must consider the resource constraints of these devices, such as limited computational power and energy consumption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. They need to optimize models and algorithms to fit within these constraints and devise efficient mechanisms for model deployment, updates, and synchronization on edge devices.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Moreover, software engineers may face challenges related to the availability of comprehensive tooling and frameworks for federated learning. They may need to adapt existing tools, develop custom solutions, or contribute to open-source projects to address specific needs. Building efficient workflows, debugging mechanisms, and monitoring tools tailored to federated learning systems is a demanding task.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The existing federated learning (FL) platforms and frameworks from both academia and industry are usually complex to use. FL involves distributed systems, optimization algorithms, privacy techniques, and machine learning models. Integrating these components into a cohesive platform or framework can result in intricate systems with numerous dependencies and configurations. Understanding and navigating these technical intricacies can be challenging for users, especially those without a strong background in distributed systems or machine learning. In addition, FL is applied across a wide range of domains and use cases, each with its specific requirements and constraints. Designing a platform or framework that accommodates this heterogeneity can lead to increased complexity. It becomes a challenge to strike a balance between providing flexibility for customization and maintaining simplicity for ease of use. Last but not least, most of the existing FL frameworks use centralized aggregation in federated learning application development. Relying on a central server creates problems when deploying into production, such as single point of failure, large communication overhead, lack of scalability, etc. In this paper, we present EdgeFL, a lightweight federated learning (FL) framework designed specifically for edge computing environments, aiming to address the challenges associated with centralized aggregation. By adopting an edge-only model training and aggregation approach, EdgeFL eliminates the need for a central server, thereby enabling seamless scalability across diverse use cases. The framework offers a straightforward integration process, requiring only four lines of code (LOC) for software engineers to incorporate FL functionalities into their AI products. Moreover, EdgeFL facilitates the customization of aggregation functions, empowering engineers to customize according to their needs. Thus, the contributions of the paper are the following:</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparison between existing FL platforms/frameworks and our proposed EdgeFL</figcaption>
<table id="S1.T1.5.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.5.5.6" class="ltx_tr">
<td id="S1.T1.5.5.6.1" class="ltx_td ltx_border_tt"></td>
<td id="S1.T1.5.5.6.2" class="ltx_td ltx_align_center ltx_border_tt">TFF</td>
<td id="S1.T1.5.5.6.3" class="ltx_td ltx_align_center ltx_border_tt">PySyft</td>
<td id="S1.T1.5.5.6.4" class="ltx_td ltx_align_center ltx_border_tt">FATE</td>
<td id="S1.T1.5.5.6.5" class="ltx_td ltx_align_center ltx_border_tt">LEAF</td>
<td id="S1.T1.5.5.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">PaddleFL</td>
<td id="S1.T1.5.5.6.7" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S1.T1.5.5.6.7.1" class="ltx_text"></span> <span id="S1.T1.5.5.6.7.2" class="ltx_text">
<span id="S1.T1.5.5.6.7.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.5.5.6.7.2.1.1" class="ltx_tr">
<span id="S1.T1.5.5.6.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">EdgeFL<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span></span></span>
<span id="S1.T1.5.5.6.7.2.1.2" class="ltx_tr">
<span id="S1.T1.5.5.6.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(Proposed Framework)</span></span>
</span></span><span id="S1.T1.5.5.6.7.3" class="ltx_text"></span></td>
</tr>
<tr id="S1.T1.5.5.5" class="ltx_tr">
<td id="S1.T1.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t">Line of Code (LOC) for FL Feature</td>
<td id="S1.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S1.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\thicksim" display="inline"><semantics id="S1.T1.1.1.1.1.m1.1a"><mo id="S1.T1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.m1.1b"><ci id="S1.T1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.m1.1.1">∼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.m1.1c">\thicksim</annotation></semantics></math>50</td>
<td id="S1.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="S1.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\thicksim" display="inline"><semantics id="S1.T1.2.2.2.2.m1.1a"><mo id="S1.T1.2.2.2.2.m1.1.1" xref="S1.T1.2.2.2.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.T1.2.2.2.2.m1.1b"><ci id="S1.T1.2.2.2.2.m1.1.1.cmml" xref="S1.T1.2.2.2.2.m1.1.1">∼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.2.2.2.m1.1c">\thicksim</annotation></semantics></math>150</td>
<td id="S1.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">
<math id="S1.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\thicksim" display="inline"><semantics id="S1.T1.3.3.3.3.m1.1a"><mo id="S1.T1.3.3.3.3.m1.1.1" xref="S1.T1.3.3.3.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.T1.3.3.3.3.m1.1b"><ci id="S1.T1.3.3.3.3.m1.1.1.cmml" xref="S1.T1.3.3.3.3.m1.1.1">∼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.3.3.3.3.m1.1c">\thicksim</annotation></semantics></math>100</td>
<td id="S1.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<math id="S1.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\thicksim" display="inline"><semantics id="S1.T1.4.4.4.4.m1.1a"><mo id="S1.T1.4.4.4.4.m1.1.1" xref="S1.T1.4.4.4.4.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.T1.4.4.4.4.m1.1b"><ci id="S1.T1.4.4.4.4.m1.1.1.cmml" xref="S1.T1.4.4.4.4.m1.1.1">∼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.4.4.4.4.m1.1c">\thicksim</annotation></semantics></math>350</td>
<td id="S1.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S1.T1.5.5.5.5.m1.1" class="ltx_Math" alttext="\thicksim" display="inline"><semantics id="S1.T1.5.5.5.5.m1.1a"><mo id="S1.T1.5.5.5.5.m1.1.1" xref="S1.T1.5.5.5.5.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.T1.5.5.5.5.m1.1b"><ci id="S1.T1.5.5.5.5.m1.1.1.cmml" xref="S1.T1.5.5.5.5.m1.1.1">∼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.5.5.5.5.m1.1c">\thicksim</annotation></semantics></math>100</td>
<td id="S1.T1.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.5.5.5.7.1" class="ltx_text ltx_font_bold">4</span></td>
</tr>
<tr id="S1.T1.5.5.7" class="ltx_tr">
<td id="S1.T1.5.5.7.1" class="ltx_td ltx_align_center">Centralized Server required</td>
<td id="S1.T1.5.5.7.2" class="ltx_td ltx_align_center">Yes</td>
<td id="S1.T1.5.5.7.3" class="ltx_td ltx_align_center">Yes</td>
<td id="S1.T1.5.5.7.4" class="ltx_td ltx_align_center">Yes</td>
<td id="S1.T1.5.5.7.5" class="ltx_td ltx_align_center">Yes</td>
<td id="S1.T1.5.5.7.6" class="ltx_td ltx_align_center ltx_border_r">Yes</td>
<td id="S1.T1.5.5.7.7" class="ltx_td ltx_align_center"><span id="S1.T1.5.5.7.7.1" class="ltx_text ltx_font_bold">No</span></td>
</tr>
<tr id="S1.T1.5.5.8" class="ltx_tr">
<td id="S1.T1.5.5.8.1" class="ltx_td ltx_align_center">Asynchronous Node Join</td>
<td id="S1.T1.5.5.8.2" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.8.3" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.8.4" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.8.5" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.8.6" class="ltx_td ltx_align_center ltx_border_r">No</td>
<td id="S1.T1.5.5.8.7" class="ltx_td ltx_align_center"><span id="S1.T1.5.5.8.7.1" class="ltx_text ltx_font_bold">Yes</span></td>
</tr>
<tr id="S1.T1.5.5.9" class="ltx_tr">
<td id="S1.T1.5.5.9.1" class="ltx_td ltx_align_center">Heterogeneous Environment Support</td>
<td id="S1.T1.5.5.9.2" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.9.3" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.9.4" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.9.5" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.9.6" class="ltx_td ltx_align_center ltx_border_r">Limited</td>
<td id="S1.T1.5.5.9.7" class="ltx_td ltx_align_center"><span id="S1.T1.5.5.9.7.1" class="ltx_text ltx_font_bold">Yes</span></td>
</tr>
<tr id="S1.T1.5.5.10" class="ltx_tr">
<td id="S1.T1.5.5.10.1" class="ltx_td ltx_align_center">Customizable Aggregation</td>
<td id="S1.T1.5.5.10.2" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.10.3" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.10.4" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.10.5" class="ltx_td ltx_align_center">No</td>
<td id="S1.T1.5.5.10.6" class="ltx_td ltx_align_center ltx_border_r">No</td>
<td id="S1.T1.5.5.10.7" class="ltx_td ltx_align_center"><span id="S1.T1.5.5.10.7.1" class="ltx_text ltx_font_bold">Yes</span></td>
</tr>
<tr id="S1.T1.5.5.11" class="ltx_tr">
<td id="S1.T1.5.5.11.1" class="ltx_td ltx_align_center ltx_border_bb">Containerized Edge Deployability</td>
<td id="S1.T1.5.5.11.2" class="ltx_td ltx_align_center ltx_border_bb">No</td>
<td id="S1.T1.5.5.11.3" class="ltx_td ltx_align_center ltx_border_bb">No</td>
<td id="S1.T1.5.5.11.4" class="ltx_td ltx_align_center ltx_border_bb">Limited</td>
<td id="S1.T1.5.5.11.5" class="ltx_td ltx_align_center ltx_border_bb">No</td>
<td id="S1.T1.5.5.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Limited</td>
<td id="S1.T1.5.5.11.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.5.5.11.7.1" class="ltx_text ltx_font_bold">Yes</span></td>
</tr>
</table>
</figure>
<div id="S1.p9" class="ltx_para ltx_noindent">
<p id="S1.p9.1" class="ltx_p">1). We introduce EdgeFL<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/HarryME-zh/EdgeFL.git</span></span></span>, the first scalable edge-only FL framework. To accomplish easy-implementation and scalable model training capacity, simple API design and learning flow abstraction are built.</p>
</div>
<div id="S1.p10" class="ltx_para ltx_noindent">
<p id="S1.p10.1" class="ltx_p">2). To expedite industrial FL training and support large-scale node communication among edges, we suggested a decentralized FL architecture and learning algorithm which enables asynchronous model training. The architecture could serve as a model for future edge-only FL development and study.</p>
</div>
<div id="S1.p11" class="ltx_para ltx_noindent">
<p id="S1.p11.1" class="ltx_p">3). Based on flexible user definitions, engineers and researchers can quickly construct a customizable model and aggregation approach for diverse needs.</p>
</div>
<div id="S1.p12" class="ltx_para ltx_noindent">
<p id="S1.p12.1" class="ltx_p">4). EdgeFL offers scalable and seamless deployment capabilities to facilitate rapid prototyping and production-level training for both industrial and research purposes.</p>
</div>
<div id="S1.p13" class="ltx_para">
<p id="S1.p13.1" class="ltx_p">The remainder of this paper is structured as follows.
In Section II, we introduce the background and related work of this study. Section III details our research method, including the implementation, data distribution, machine learning methods applied and evaluation metrics. Section IV presents the system design of our proposed EdgeFL. Section V evaluates our proposed framework and compared it with existing Federated Learning frameworks/platforms. Section VI outlines the discussion on our observed results. Finally, Section VII presents conclusions and future work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background and Related Work</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Federated learning (FL) is a machine learning paradigm that allows multiple decentralized devices or entities to collaboratively train a shared model without sharing their raw data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. In traditional machine learning approaches, a central server or data aggregator collects and stores all the training data from different sources. The central server then trains a global model using the combined data. However, this centralized approach raises concerns regarding data privacy, security, and the practicality of transferring large volumes of data to a central location <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. With the rise of edge computing and distributed data sources, there is a growing need to leverage data that resides on various devices or entities while respecting data ownership and privacy. Federated learning addresses this challenge by allowing local devices, such as smartphones, IoT devices, or edge servers, to train a shared model using their locally stored data. As shown in Figure <a href="#S2.F1" title="Figure 1 ‣ II-A Federated Learning ‣ II Background and Related Work ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the FL process typically involves the following steps:</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<p id="S2.F1.1" class="ltx_p ltx_align_center"><span id="S2.F1.1.1" class="ltx_text"><img src="/html/2309.02936/assets/fl-diag.png" id="S2.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="526" height="280" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Diagram of Federated Learning training process</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">1). Initialization: The central server initializes a global model and distributes it to the participating devices or entities.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">2). Local Model Training: Each device or entity independently trains the global model using its local data, without sharing the raw data. The local model is trained using gradient descent or other optimization algorithms, updating the model parameters based on its local data.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">3). Model Aggregation: After local training, the devices or entities send their locally computed model updates (such as gradients) to the central server. The central server aggregates these updates using techniques like Federated Averaging or Secure Aggregation to obtain a refined global model.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">4). Iterative Process: The model training and aggregation process iterates over multiple rounds, allowing the global model to improve over time. Each round typically consists of local model training, model aggregation, and communication between devices and the central server.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.1" class="ltx_p">FL enables collaborative learning from a diverse range of devices or entities, each having its unique data distribution and characteristics. This diversity helps improve the generalization and robustness of the global model by capturing a more comprehensive representation of the data.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Existing Federated Learning Platform/Framework</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">There are several existing federated learning (FL) platforms and frameworks available that facilitate the development and deployment of FL systems. TensorFlow Federated is an open-source research-oriented framework developed by Google. It extends TensorFlow with FL capabilities, enabling the implementation of FL algorithms and protocols. TFF provides a programming model and APIs for expressing federated computations, along with tools for simulation and evaluation of FL algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. PySyft is an open-source library built on top of PyTorch that focuses on privacy-preserving FL and secure multi-party computation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. It provides a high-level API for expressing FL computations and offers privacy techniques like differential privacy and secure aggregation. It allows users to work with remote data and models, enabling collaborative learning while protecting privacy. FATE is an industrial-grade FL framework developed by Webank Research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. It provides a secure and flexible infrastructure for collaborative model training across distributed entities while preserving data privacy. FATE supports a wide range of machine learning algorithms and provides functionalities for data preprocessing, model evaluation, and privacy protection. It has been widely adopted in industries such as finance, healthcare, and telecommunications. LEAF is an open-source FL framework developed by NVIDIA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. It offers a comprehensive set of tools and functionalities for researchers and practitioners to experiment with and evaluate FL algorithms. PaddleFL is a FL framework developed by PaddlePaddle, an open-source deep-learning platform <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. It provides a distributed infrastructure for training large-scale FL models. PaddleFL supports various optimization algorithms, model architectures, and communication protocols.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">However, the current FL platforms and frameworks available in academia and industry are complex, demanding a thorough understanding of FL concepts. As shown in Table <a href="#S1.T1" title="TABLE I ‣ I Introduction ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, the majority of existing FL systems require the implementation of more than 100 lines of code (LOC) to deploy a FL application, providing limited flexibility for aggregation function customization and lacking support for asynchronous communication schemes. These constraints present significant challenges to software engineers attempting to integrate FL into production environments. Furthermore, because all of these platforms/frameworks rely on a centralized aggregation server, issues such as single-point failure and scalability constraints arise.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Research Method</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this research, we adopted the empirical methodology and learning procedure outlined by Zhang <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to conduct a comprehensive quantitative measurement and evaluation of our proposed EdgeFL framework in comparison to existing Federated Learning platforms/frameworks. We aim to present a thorough and robust assessment of the performance and effectiveness of the EdgeFL framework. In the subsequent sections, we provide detailed insights into our implementation approach, present the method employed for dataset partitioning and distribution for heterogeneous simulation, discuss the evaluation metrics employed, and elaborate on the machine learning methods utilized during the experimental analysis.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Implementation</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In order to thoroughly evaluate the performance and capabilities of the EdgeFL framework, we conducted experiments using two widely recognized machine learning applications: digit recognition and object recognition. For these experiments, we leveraged the MNIST and CIFAR-10 datasets, which are extensively used in the research field. To facilitate deep learning training and testing, we developed the applications using the PyTorch backend. With the integration of EdgeFL, the FL functionality is seamlessly integrated into these machine learning applications with the addition of just four lines of code (LOC). Furthermore, we containerized the applications, enabling easy deployment on edge devices while maintaining their functionality and performance.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The flexibility of the EdgeFL framework allows it to be constructed on various container orchestration clusters, such as Kubernetes, Docker Swarm, etc. In this paper, we utilized Docker Swarm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> as the cluster of choice. Docker Swarm offers an efficient and scalable environment for managing containerized applications. The services within Docker Swarm facilitate seamless communication among containers, while an internal DNS resolver ensures peer node service communication. By utilizing the capabilities of Docker Swarm, we were able to create a robust and scalable deployment environment for the EdgeFL framework, ensuring its suitability for edge devices and distributed computing scenarios.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Dataset Distribution</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">For the purpose of this study, we used two kinds of edge data distribution to analyze system performance for heterogeneous simulation.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.4.1.1" class="ltx_text">III-B</span>1 </span>Uniform Distribution</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Within this experimental setup, the training data samples were distributed among the edge nodes following a uniform distribution. This distribution ensured an equal likelihood of data samples from each target class.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.7.1.1" class="ltx_text">III-B</span>2 </span>Normal Distribution</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Within this configuration, the number of samples in each class within each edge node follows a normal density function. Mathematically, this can be expressed as:</p>
</div>
<div id="S3.SS2.SSS2.1" class="ltx_para">
<p id="S3.SS2.SSS2.1.1" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS2.1.1.m1.2" class="ltx_Math" alttext="X\sim\mathcal{N}(\mu,\sigma^{2})" display="inline"><semantics id="S3.SS2.SSS2.1.1.m1.2a"><mrow id="S3.SS2.SSS2.1.1.m1.2.2" xref="S3.SS2.SSS2.1.1.m1.2.2.cmml"><mi id="S3.SS2.SSS2.1.1.m1.2.2.3" xref="S3.SS2.SSS2.1.1.m1.2.2.3.cmml">X</mi><mo id="S3.SS2.SSS2.1.1.m1.2.2.2" xref="S3.SS2.SSS2.1.1.m1.2.2.2.cmml">∼</mo><mrow id="S3.SS2.SSS2.1.1.m1.2.2.1" xref="S3.SS2.SSS2.1.1.m1.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.1.1.m1.2.2.1.3" xref="S3.SS2.SSS2.1.1.m1.2.2.1.3.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.1.1.m1.2.2.1.2" xref="S3.SS2.SSS2.1.1.m1.2.2.1.2.cmml">​</mo><mrow id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.2" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.2.cmml">(</mo><mi id="S3.SS2.SSS2.1.1.m1.1.1" xref="S3.SS2.SSS2.1.1.m1.1.1.cmml">μ</mi><mo id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.3" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.2.cmml">,</mo><msup id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.2" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.2.cmml">σ</mi><mn id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.3" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.4" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.1.1.m1.2b"><apply id="S3.SS2.SSS2.1.1.m1.2.2.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2"><csymbol cd="latexml" id="S3.SS2.SSS2.1.1.m1.2.2.2.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.2">similar-to</csymbol><ci id="S3.SS2.SSS2.1.1.m1.2.2.3.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.3">𝑋</ci><apply id="S3.SS2.SSS2.1.1.m1.2.2.1.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1"><times id="S3.SS2.SSS2.1.1.m1.2.2.1.2.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1.2"></times><ci id="S3.SS2.SSS2.1.1.m1.2.2.1.3.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1.3">𝒩</ci><interval closure="open" id="S3.SS2.SSS2.1.1.m1.2.2.1.1.2.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1"><ci id="S3.SS2.SSS2.1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.1.1.m1.1.1">𝜇</ci><apply id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.2">𝜎</ci><cn type="integer" id="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.1.1.m1.2.2.1.1.1.1.3">2</cn></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.1.1.m1.2c">X\sim\mathcal{N}(\mu,\sigma^{2})</annotation></semantics></math></p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.2" class="ltx_p">where <math id="S3.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mi id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><ci id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">\mu</annotation></semantics></math> and <math id="S3.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mi id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><ci id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">\sigma</annotation></semantics></math> are defined as:</p>
</div>
<div id="S3.SS2.SSS2.3" class="ltx_para">
<p id="S3.SS2.SSS2.3.2" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS2.2.1.m1.1" class="ltx_Math" alttext="\mu=\frac{k\times N}{K}" display="inline"><semantics id="S3.SS2.SSS2.2.1.m1.1a"><mrow id="S3.SS2.SSS2.2.1.m1.1.1" xref="S3.SS2.SSS2.2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.2.1.m1.1.1.2" xref="S3.SS2.SSS2.2.1.m1.1.1.2.cmml">μ</mi><mo id="S3.SS2.SSS2.2.1.m1.1.1.1" xref="S3.SS2.SSS2.2.1.m1.1.1.1.cmml">=</mo><mfrac id="S3.SS2.SSS2.2.1.m1.1.1.3" xref="S3.SS2.SSS2.2.1.m1.1.1.3.cmml"><mrow id="S3.SS2.SSS2.2.1.m1.1.1.3.2" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2.cmml"><mi id="S3.SS2.SSS2.2.1.m1.1.1.3.2.2" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2.2.cmml">k</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.2.1.m1.1.1.3.2.1" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2.1.cmml">×</mo><mi id="S3.SS2.SSS2.2.1.m1.1.1.3.2.3" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2.3.cmml">N</mi></mrow><mi id="S3.SS2.SSS2.2.1.m1.1.1.3.3" xref="S3.SS2.SSS2.2.1.m1.1.1.3.3.cmml">K</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.2.1.m1.1b"><apply id="S3.SS2.SSS2.2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1"><eq id="S3.SS2.SSS2.2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.1"></eq><ci id="S3.SS2.SSS2.2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.2">𝜇</ci><apply id="S3.SS2.SSS2.2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.3"><divide id="S3.SS2.SSS2.2.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.3"></divide><apply id="S3.SS2.SSS2.2.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2"><times id="S3.SS2.SSS2.2.1.m1.1.1.3.2.1.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2.1"></times><ci id="S3.SS2.SSS2.2.1.m1.1.1.3.2.2.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2.2">𝑘</ci><ci id="S3.SS2.SSS2.2.1.m1.1.1.3.2.3.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.3.2.3">𝑁</ci></apply><ci id="S3.SS2.SSS2.2.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS2.2.1.m1.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.2.1.m1.1c">\mu=\frac{k\times N}{K}</annotation></semantics></math>, <math id="S3.SS2.SSS2.3.2.m2.1" class="ltx_Math" alttext="\sigma=0.2\times N" display="inline"><semantics id="S3.SS2.SSS2.3.2.m2.1a"><mrow id="S3.SS2.SSS2.3.2.m2.1.1" xref="S3.SS2.SSS2.3.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.3.2.m2.1.1.2" xref="S3.SS2.SSS2.3.2.m2.1.1.2.cmml">σ</mi><mo id="S3.SS2.SSS2.3.2.m2.1.1.1" xref="S3.SS2.SSS2.3.2.m2.1.1.1.cmml">=</mo><mrow id="S3.SS2.SSS2.3.2.m2.1.1.3" xref="S3.SS2.SSS2.3.2.m2.1.1.3.cmml"><mn id="S3.SS2.SSS2.3.2.m2.1.1.3.2" xref="S3.SS2.SSS2.3.2.m2.1.1.3.2.cmml">0.2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.3.2.m2.1.1.3.1" xref="S3.SS2.SSS2.3.2.m2.1.1.3.1.cmml">×</mo><mi id="S3.SS2.SSS2.3.2.m2.1.1.3.3" xref="S3.SS2.SSS2.3.2.m2.1.1.3.3.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.3.2.m2.1b"><apply id="S3.SS2.SSS2.3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.3.2.m2.1.1"><eq id="S3.SS2.SSS2.3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.3.2.m2.1.1.1"></eq><ci id="S3.SS2.SSS2.3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.3.2.m2.1.1.2">𝜎</ci><apply id="S3.SS2.SSS2.3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.3.2.m2.1.1.3"><times id="S3.SS2.SSS2.3.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS2.3.2.m2.1.1.3.1"></times><cn type="float" id="S3.SS2.SSS2.3.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS2.3.2.m2.1.1.3.2">0.2</cn><ci id="S3.SS2.SSS2.3.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS2.3.2.m2.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.3.2.m2.1c">\sigma=0.2\times N</annotation></semantics></math></p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.3" class="ltx_p">In the above equations, <math id="S3.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><mi id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><ci id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">k</annotation></semantics></math> represents the ID of each edge node, <math id="S3.SS2.SSS2.p3.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><mi id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><ci id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">K</annotation></semantics></math> denotes the total number of edge nodes, and <math id="S3.SS2.SSS2.p3.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><mi id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><ci id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">N</annotation></semantics></math> corresponds to the total number of target classes in the training data. This configuration aims to provide varied distributions and different numbers of samples among different edge nodes, allowing each class to have a probability of having the majority of samples in a specific node.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Machine Learning Method</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The implementation of the models in this study utilized Python and relied on the following libraries: torch 1.6.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, torchvision 0.7.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, and scikit-learn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, which were applied in model construction and evaluation.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">To achieve satisfactory classification results, two distinct convolutional neural networks (CNN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> were trained for the MNIST and CIFAR-10 datasets. For the MNIST application, the CNN architecture comprised two 5x5 convolutional layers (with 10 output channels in the first layer and 20 in the second), each followed by 2x2 max pooling. Additionally, a fully connected layer with 50 units employing the ReLU activation function and a linear output layer were included.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">For the CIFAR-10 application, the CNN architecture featured four 5x5 convolutional layers (with 66 output channels in the first layer, 128 in the second with a stride of 2, 192 in the third, and 256 in the fourth with a stride of 2). Furthermore, two fully connected layers utilizing the ReLU activation function, with 3000 and 1500 units respectively, were incorporated along with a linear output layer.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.4.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.5.2" class="ltx_text ltx_font_italic">Evaluation Metrics</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">To assess the effectiveness of EdgeFL, three key metrics were selected: weights update latency, model evolution time, and model classification performance.</p>
</div>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS1.4.1.1" class="ltx_text">III-D</span>1 </span>Weights update latency</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">Weights update latency measures the time it takes for the model to be transmitted. In centralized architectures which applied by existing FL platforms/frameworks, the central aggregation server collects the models. However, in the decentralized architecture of EdgeFL, where the aggregation function is moved to the edge, a peer node is ready to receive the updated model. The average weights update latency across all edge nodes during one training round is calculated. This metric provides insights into the network situation and communication overhead of each architecture option. Measurement of this metric involves checking the sending and receiving timestamps in all model receivers.</p>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS2.4.1.1" class="ltx_text">III-D</span>2 </span>Model Evolution time</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">Model evolution time represents the time difference between two different versions of the deployed model at the edge nodes. Similar to weights update latency, the average model evolution time across all edge nodes during one training round is determined. This metric highlights the speed at which local edge devices update their knowledge, which is crucial for systems requiring quick adaptation to rapidly changing environments. Model evolution time is measured in all edge nodes by examining the model deployment timestamp.</p>
</div>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS3.4.1.1" class="ltx_text">III-D</span>3 </span>Model Classification Performance</h4>

<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p id="S3.SS4.SSS3.p1.1" class="ltx_p">Model classification performance is a vital metric that indicates the quality of the trained model. It measures the percentage of correctly recognized images among the total number of testing images. The classification performance is evaluated on each edge device using their updated models. The test sample distribution should align with the training samples (local test set). The average classification performance across all edge nodes is reported.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">System Design of EdgeFL</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present a comprehensive overview of the system design of EdgeFL. In addition, the APIs, functions and EdgeFL learning life-cycle are also presented in this section.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">System Design</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The EdgeFL allows for easy scalability, fault tolerance, and customization of the FL process. The framework consists of two main components: FL edge nodes and registration nodes. Edge nodes serve as independent participants, facilitating distributed and privacy-preserving model training without the need for a centralized server. The registration nodes act as coordination points to connect the FL edge nodes, enabling them to discover and communicate with each other in a decentralized manner.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">FL Edge Nodes: The FL edge nodes are deployed on edge devices and play a crucial role in the FL process. Each FL edge node serves as a participant in the federated learning system. The FL edge nodes execute the FL training algorithm, exchange models with other nodes, and perform local model updates. The FL edge node code provided in the implementation utilizes the Flask framework to serve requested machine-learning model files from other peers.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Registration Nodes: The registration nodes act as coordinators for the FL edge nodes. It maintains a list of active peers and provides services for registration, unregistration, and retrieval of peer information. The registration nodes enable FL client nodes to discover and communicate with each other. The implementation of the tracker server utilizes the Flask framework which exposes several APIs to facilitate the FL process.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">APIs and Services</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Table <a href="#S4.T2" title="TABLE II ‣ IV-B APIs and Services ‣ IV System Design of EdgeFL ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> summarises the most important APIs and services for EdgeFL, including edge node registration and registration, peer information retrieval and model file serving.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>APIs and services of EdgeFL</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">Name</td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Endpoint</td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Method</td>
</tr>
<tr id="S4.T2.1.2" class="ltx_tr">
<td id="S4.T2.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Registration API</td>
<td id="S4.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_t">/register</td>
<td id="S4.T2.1.2.3" class="ltx_td ltx_align_center ltx_border_t">POST</td>
</tr>
<tr id="S4.T2.1.3" class="ltx_tr">
<td id="S4.T2.1.3.1" class="ltx_td ltx_align_center">Unregistration API</td>
<td id="S4.T2.1.3.2" class="ltx_td ltx_align_center">/unregister</td>
<td id="S4.T2.1.3.3" class="ltx_td ltx_align_center">POST</td>
</tr>
<tr id="S4.T2.1.4" class="ltx_tr">
<td id="S4.T2.1.4.1" class="ltx_td ltx_align_center">Peer Information Retrieval API:</td>
<td id="S4.T2.1.4.2" class="ltx_td ltx_align_center">/peers</td>
<td id="S4.T2.1.4.3" class="ltx_td ltx_align_center">GET</td>
</tr>
<tr id="S4.T2.1.5" class="ltx_tr">
<td id="S4.T2.1.5.1" class="ltx_td ltx_align_center ltx_border_bb">Model File Serving API</td>
<td id="S4.T2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb">/latest_model</td>
<td id="S4.T2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb">GET</td>
</tr>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">Registration API: FL edge nodes send a registration request to the registration nodes through this API. The request includes the hostname of the FL edge node. Upon successful registration, the registration nodes add the peer information to their list of active peers.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">Unregistration API: FL edge nodes use this API to send an unregistration request to the registration nodes when they no longer participate in the FL process. The request includes the hostname of the FL edge node. The registration nodes remove the corresponding peer information from their list of active peers.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">Peer Information Retrieval API: FL edge nodes can query the registration nodes for a list of active peers using this API. The registration nodes respond with the list of active peer information, allowing FL edge nodes to discover and communicate with other peers.</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.1" class="ltx_p">Model File Serving API: FL edge nodes expose this API to serve the requested model file. When a peer requests the latest model, the FL edge node responds by sending the machine-learning model file through HTTP response.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Function Details and Example Usage</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The proposed EdgeFL framework allows software engineers to easily incorporate federated learning (FL) functionalities into their AI products. In contrast to complex FL platforms and frameworks, EdgeFL provides a streamlined implementation that requires only four lines of code (LOC). Because of this simplicity, software engineers can quickly integrate FL capabilities into their existing AI applications without requiring significant code changes or extensive re-engineering efforts. The following Listing 1 illustrates the example usage of the EdgeFL.</p>
</div>
<figure id="LST1" class="ltx_float ltx_lstlisting">
<div id="LST1.1" class="ltx_listing ltx_lst_language_Python ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,IyAtLS0gQ29udGludWUgZnJvbSBub2RlIHRyYWluaW5nIHBhcnQgLS0tCiMgLS0tIEluaXRpYWxpemUgcGVlciBpbnN0YW5jZSAtLS0KQFx0ZXh0YmZ7cGVlciA9IFBlZXIoY29uZmlnKX1ACgojIC0tLSBTdGFydCBwZWVyIGluc3RhbmNlIC0tLQpAXHRleHRiZntwZWVyLnN0YXJ0KCl9QAoKZm9yIGVwb2NoIGluIHJhbmdlKG51bWJlcl9vZl9lcG9jaHMpOgoKICAgICMgLS0tIFB1bGwgbW9kZWwgZnJvbSBhY3RpdmUgcGVlcnMgYW5kIHN0YXJ0IGFnZ3JlZ2F0aW9uCiAgICBAXHRleHRiZnt3XF9sYXRlc3QgPSBwZWVyLmFnZ3JlZ2F0aW9uXF9mdW5jKCl9QAoKICAgIG1vZGVsLmxvYWRfc3RhdGVfZGljdCh3X2xhdGVzdCkKCiAgICB0cmFpbihtb2RlbCwgdG9yY2guZGV2aWNlKCJjcHUiKSwgdHJhaW5fbG9hZGVyLCBvcHRpbWl6ZXIsIGVwb2NoKQogICAgdGVzdChtb2RlbCwgdG9yY2guZGV2aWNlKCJjcHUiKSwgdGVzdF9sb2FkZXIpCiAgICBzY2hlZHVsZXIuc3RlcCgpCgogICAgdG9yY2guc2F2ZShtb2RlbC5zdGF0ZV9kaWN0KCksICJtb2RlbC1sYXRlc3QucHRoIikKCiMgLS0tIHVucmVnaXN0ZXIgZnJvbSB0aGUgcmVnaXN0cmF0aW9uIG5vZGUgaWYgbGVhdmUKQFx0ZXh0YmZ7cGVlci51bnJlZ2lzdGVyXF9wZWVyKCl9QAo=" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:80%;color:#009900;">#<span id="lstnumberx1.1.1" class="ltx_text ltx_lst_space"> </span>---<span id="lstnumberx1.1.2" class="ltx_text ltx_lst_space"> </span>Continue<span id="lstnumberx1.1.3" class="ltx_text ltx_lst_space"> </span>from<span id="lstnumberx1.1.4" class="ltx_text ltx_lst_space"> </span>node<span id="lstnumberx1.1.5" class="ltx_text ltx_lst_space"> </span>training<span id="lstnumberx1.1.6" class="ltx_text ltx_lst_space"> </span>part<span id="lstnumberx1.1.7" class="ltx_text ltx_lst_space"> </span>---</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:80%;color:#009900;">#<span id="lstnumberx2.1.1" class="ltx_text ltx_lst_space"> </span>---<span id="lstnumberx2.1.2" class="ltx_text ltx_lst_space"> </span>Initialize<span id="lstnumberx2.1.3" class="ltx_text ltx_lst_space"> </span>peer<span id="lstnumberx2.1.4" class="ltx_text ltx_lst_space"> </span>instance<span id="lstnumberx2.1.5" class="ltx_text ltx_lst_space"> </span>---</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_font_typewriter ltx_font_bold" style="font-size:80%;">peer = Peer(config)</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:80%;color:#009900;">#<span id="lstnumberx5.1.1" class="ltx_text ltx_lst_space"> </span>---<span id="lstnumberx5.1.2" class="ltx_text ltx_lst_space"> </span>Start<span id="lstnumberx5.1.3" class="ltx_text ltx_lst_space"> </span>peer<span id="lstnumberx5.1.4" class="ltx_text ltx_lst_space"> </span>instance<span id="lstnumberx5.1.5" class="ltx_text ltx_lst_space"> </span>---</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text ltx_font_typewriter ltx_font_bold" style="font-size:80%;">peer.start()</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:80%;color:#FF00FF;">for</span><span id="lstnumberx8.2" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx8.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">epoch</span><span id="lstnumberx8.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx8.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="font-size:80%;color:#FF00FF;">in</span><span id="lstnumberx8.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx8.7" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="font-size:80%;color:#FF00FF;">range</span><span id="lstnumberx8.8" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(</span><span id="lstnumberx8.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">number_of_epochs</span><span id="lstnumberx8.10" class="ltx_text ltx_font_typewriter" style="font-size:80%;">):</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx10.2" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:80%;color:#009900;">#<span id="lstnumberx10.2.1" class="ltx_text ltx_lst_space"> </span>---<span id="lstnumberx10.2.2" class="ltx_text ltx_lst_space"> </span>Pull<span id="lstnumberx10.2.3" class="ltx_text ltx_lst_space"> </span>model<span id="lstnumberx10.2.4" class="ltx_text ltx_lst_space"> </span>from<span id="lstnumberx10.2.5" class="ltx_text ltx_lst_space"> </span>active<span id="lstnumberx10.2.6" class="ltx_text ltx_lst_space"> </span>peers<span id="lstnumberx10.2.7" class="ltx_text ltx_lst_space"> </span>and<span id="lstnumberx10.2.8" class="ltx_text ltx_lst_space"> </span>start<span id="lstnumberx10.2.9" class="ltx_text ltx_lst_space"> </span>aggregation</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx11.2" class="ltx_text ltx_font_typewriter ltx_font_bold" style="font-size:80%;">w_latest = peer.aggregation_func()</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx13.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">model</span><span id="lstnumberx13.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">.</span><span id="lstnumberx13.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">load_state_dict</span><span id="lstnumberx13.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(</span><span id="lstnumberx13.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">w_latest</span><span id="lstnumberx13.7" class="ltx_text ltx_font_typewriter" style="font-size:80%;">)</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span id="lstnumberx15.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx15.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">train</span><span id="lstnumberx15.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(</span><span id="lstnumberx15.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">model</span><span id="lstnumberx15.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">,</span><span id="lstnumberx15.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx15.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">torch</span><span id="lstnumberx15.8" class="ltx_text ltx_font_typewriter" style="font-size:80%;">.</span><span id="lstnumberx15.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">device</span><span id="lstnumberx15.10" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(</span><span id="lstnumberx15.11" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:80%;color:#9400D1;">"cpu"</span><span id="lstnumberx15.12" class="ltx_text ltx_font_typewriter" style="font-size:80%;">),</span><span id="lstnumberx15.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx15.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">train_loader</span><span id="lstnumberx15.15" class="ltx_text ltx_font_typewriter" style="font-size:80%;">,</span><span id="lstnumberx15.16" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx15.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">optimizer</span><span id="lstnumberx15.18" class="ltx_text ltx_font_typewriter" style="font-size:80%;">,</span><span id="lstnumberx15.19" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx15.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">epoch</span><span id="lstnumberx15.21" class="ltx_text ltx_font_typewriter" style="font-size:80%;">)</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx16.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">test</span><span id="lstnumberx16.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(</span><span id="lstnumberx16.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">model</span><span id="lstnumberx16.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">,</span><span id="lstnumberx16.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">torch</span><span id="lstnumberx16.8" class="ltx_text ltx_font_typewriter" style="font-size:80%;">.</span><span id="lstnumberx16.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">device</span><span id="lstnumberx16.10" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(</span><span id="lstnumberx16.11" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:80%;color:#9400D1;">"cpu"</span><span id="lstnumberx16.12" class="ltx_text ltx_font_typewriter" style="font-size:80%;">),</span><span id="lstnumberx16.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">test_loader</span><span id="lstnumberx16.15" class="ltx_text ltx_font_typewriter" style="font-size:80%;">)</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx17.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">scheduler</span><span id="lstnumberx17.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">.</span><span id="lstnumberx17.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">step</span><span id="lstnumberx17.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">()</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx19.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">torch</span><span id="lstnumberx19.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">.</span><span id="lstnumberx19.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">save</span><span id="lstnumberx19.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(</span><span id="lstnumberx19.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">model</span><span id="lstnumberx19.7" class="ltx_text ltx_font_typewriter" style="font-size:80%;">.</span><span id="lstnumberx19.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">state_dict</span><span id="lstnumberx19.9" class="ltx_text ltx_font_typewriter" style="font-size:80%;">(),</span><span id="lstnumberx19.10" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx19.11" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:80%;color:#9400D1;">"model-latest.pth"</span><span id="lstnumberx19.12" class="ltx_text ltx_font_typewriter" style="font-size:80%;">)</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_lst_comment ltx_font_typewriter" style="font-size:80%;color:#009900;">#<span id="lstnumberx21.1.1" class="ltx_text ltx_lst_space"> </span>---<span id="lstnumberx21.1.2" class="ltx_text ltx_lst_space"> </span>unregister<span id="lstnumberx21.1.3" class="ltx_text ltx_lst_space"> </span>from<span id="lstnumberx21.1.4" class="ltx_text ltx_lst_space"> </span>the<span id="lstnumberx21.1.5" class="ltx_text ltx_lst_space"> </span>registration<span id="lstnumberx21.1.6" class="ltx_text ltx_lst_space"> </span>node<span id="lstnumberx21.1.7" class="ltx_text ltx_lst_space"> </span>if<span id="lstnumberx21.1.8" class="ltx_text ltx_lst_space"> </span>leave</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span id="lstnumberx22.1" class="ltx_text ltx_font_typewriter ltx_font_bold" style="font-size:80%;">peer.unregister_peer()</span>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Listing 1: </span>Usage example of EdgeFL.</figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">peer = Peer(configs)</span>: Initializing and creating an instance of the Peer class, representing a participant in the EdgeFL framework. The configs include addresses of registration nodes and the configuration of the customized aggregation function. This initialization step ensures that the FL edge node is properly configured to connect to the registration nodes and participate in the FL training and aggregation tasks. The peer object serves as a handle through which the FL edge node can interact with other peers, fetch models, register with the registration nodes, and perform aggregation operations.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_italic">peer.start()</span>: The function initiates the execution of the FL edge node within the EdgeFL framework. When invoked, this function triggers a series of actions that enable the FL edge node to participate in the FL process. It includes registering the FL edge node with the registration nodes, establishing connections with other peers and starting a background instance to serve asynchronous file requests from peers. By calling “peer.start()”, the FL edge node becomes an active participant in the EdgeFL framework, contributing to the collaborative model learning while leveraging edge devices’ capabilities.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_italic">peer.aggregation_func()</span>: The function performs the aggregation process. When called, this function retrieves models from other FL edge nodes, as identified through the registration nodes, and applies the aggregation algorithm to combine these models into a single updated model. The aggregation function facilitates the collaborative nature of FL by leveraging the contributions of multiple peers to improve the overall model’s accuracy and performance. By executing “peer.aggregation_func()”, the FL edge node actively contributes to the iterative model aggregation process, promoting the collective intelligence of the EdgeFL framework and enhancing the final model’s quality.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_italic">peer.unregister_peer()</span>: The function enables the FL edge node to gracefully exit from the EdgeFL framework. When invoked, this function notifies the registration nodes about the intention to unregister, providing the necessary information such as the hostname of the FL edge node. By calling “peer.unregister_peer()”, the FL client node initiates the process of removing itself from the active participant list maintained by the registration nodes. This action ensures the proper management of participants within the EdgeFL framework and allows for efficient resource allocation and coordination among the remaining active peers.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">EdgeFL Learning Life-Cycle</span>
</h3>

<figure id="S4.F2" class="ltx_figure">
<p id="S4.F2.1" class="ltx_p ltx_align_center"><span id="S4.F2.1.1" class="ltx_text"><img src="/html/2309.02936/assets/fl-lifecycle.png" id="S4.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="876" height="164" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The Learning Life-Cycle of EdgeFL, including joining the FL process, model training, sharing, aggregation, and eventual node leaving. These stages collectively define the operational flow of EdgeFL within an edge node.</figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The life cycle of the EdgeFL framework involves several key steps for an individual edge node to join, train, share models, aggregate, and eventually leave the FL process. Algorithm <a href="#alg1" title="In IV-D EdgeFL Learning Life-Cycle ‣ IV System Design of EdgeFL ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides a detailed FL learning process of an individual edge node. The following is the description of each step:</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<ol id="S4.I3" class="ltx_enumerate">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p">Edge Node Joining: The edge node initializes by creating an instance of the Peer class and background instance for model requests. The node then connects to the registration nodes, registers itself as an active participant, and obtains information about other peers.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p">Model Training: The edge node starts the FL training process, performing local model training using its own dataset. It iteratively updates its local model to improve its performance.</p>
</div>
</li>
<li id="S4.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I3.i3.p1" class="ltx_para">
<p id="S4.I3.i3.p1.1" class="ltx_p">Sharing Models: The FL client node retrieves models from other peers in the FL framework identified through the registration nodes. It fetches the latest models from other peers and incorporates them into its local model updates, benefiting from the knowledge and insights of other participants. It is worth noting that the model retrieval process occurs without disrupting the ongoing model training of the edge nodes, thanks to the background serving instance. This asynchronous model aggregation mechanism ensures uninterrupted model training while enabling the FL client node to actively contribute to the collaborative learning process.</p>
</div>
</li>
<li id="S4.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S4.I3.i4.p1" class="ltx_para">
<p id="S4.I3.i4.p1.1" class="ltx_p">Model Aggregation: The FL client node executes an aggregation function, combining the locally updated models with the models obtained from other peers. The aggregation function integrates the diverse models to generate a new aggregated model that captures the collective knowledge of all participating nodes. It is important to highlight that the aggregation function in the EdgeFL framework can be customized to specific analysis and case requirements, providing software engineers with the flexibility to define and implement alternative aggregation functions that align with their specific needs. This paper utilizes a default averaging function for general performance analysis.</p>
</div>
</li>
<li id="S4.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S4.I3.i5.p1" class="ltx_para">
<p id="S4.I3.i5.p1.1" class="ltx_p">Edge Node Leaving: When an edge node intends to leave the EdgeFL system, the FL client node notifies the registration server of its hostname for identification. The registration server updates the active participant list, removing the leaving edge node. However, it is worth noting that edge nodes have the option to remain in the system even after completing their learning process. By choosing to stay, these nodes contribute by providing their completed learning models to accommodate newly joined nodes. This approach ensures that the system benefits from the availability of finished-learning models, facilitating a seamless on-boarding experience for new participants in the EdgeFL framework.</p>
</div>
</li>
</ol>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">This life cycle repeats as new edge nodes join the FL framework, contribute to the training and aggregation processes, share their models, and eventually leave when they decide to end their participation. The EdgeFL allows for continuous collaborative learning and model improvement while maintaining the privacy and autonomy of individual edge nodes.</p>
</div>
<figure id="alg1" class="ltx_float ltx_algorithm">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.8" class="ltx_listing ltx_figure_panel ltx_lst_numbers_left ltx_listing">
<div id="alg1.8.1" class="ltx_listingline">

</div>
<div id="alg1.8.2" class="ltx_listingline">

</div>
<div id="alg1.8.3" class="ltx_listingline">




















































<div id="alg1.8.3.1" class="ltx_listing ltx_listing">
</div>
</div>
<div id="alg1.8.4" class="ltx_listingline">
</div>
<div id="alg1.l1" class="ltx_listingline">  Initialize <math id="alg1.l1.m1.1" class="ltx_Math" alttext="w_{0}" display="inline"><semantics id="alg1.l1.m1.1a"><msub id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2.cmml">w</mi><mn id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">𝑤</ci><cn type="integer" id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">w_{0}</annotation></semantics></math>

</div>
<div id="alg1.l2" class="ltx_listingline">  Initialize <math id="alg1.l2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="alg1.l2.m1.1a"><mi id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\alpha</annotation></semantics></math> as the ratio of aggregated peers

</div>
<div id="alg1.l3" class="ltx_listingline">  Initialize <math id="alg1.l3.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="alg1.l3.m1.1a"><mi id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">C</annotation></semantics></math> as the active peer list

</div>
<div id="alg1.8.5" class="ltx_listingline">

<span id="alg1.8.5.1" class="ltx_text ltx_font_bold">Function</span> <em id="alg1.8.5.2" class="ltx_emph ltx_font_typewriter">Server_Function(<em id="alg1.8.5.2.1" class="ltx_emph ltx_font_serif ltx_font_italic"></em>)</em><span id="alg1.8.5.3" class="ltx_text ltx_font_bold">:</span>
</div>
<div id="alg1.8.6" class="ltx_listingline">

</div>
<div id="alg1.l4" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span id="alg1.l4.1" class="ltx_text ltx_font_bold">for</span> each round t = 1, 2, …  <span id="alg1.l4.2" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.8.7" class="ltx_listingline">
</div>
<div id="alg1.l5" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        Node_Training(w_t)

</div>
<div id="alg1.8.8" class="ltx_listingline">
</div>
<div id="alg1.l6" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        Retrieval active peer list <math id="alg1.l6.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="alg1.l6.m1.1a"><mi id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">C</annotation></semantics></math>

</div>
<div id="alg1.8.9" class="ltx_listingline">
</div>
<div id="alg1.l7" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        <math id="alg1.l7.m1.3" class="ltx_Math" alttext="m\longleftarrow max(len(C)\times\alpha,1);" display="inline"><semantics id="alg1.l7.m1.3a"><mrow id="alg1.l7.m1.3.3.1" xref="alg1.l7.m1.3.3.1.1.cmml"><mrow id="alg1.l7.m1.3.3.1.1" xref="alg1.l7.m1.3.3.1.1.cmml"><mi id="alg1.l7.m1.3.3.1.1.3" xref="alg1.l7.m1.3.3.1.1.3.cmml">m</mi><mo stretchy="false" id="alg1.l7.m1.3.3.1.1.2" xref="alg1.l7.m1.3.3.1.1.2.cmml">⟵</mo><mrow id="alg1.l7.m1.3.3.1.1.1" xref="alg1.l7.m1.3.3.1.1.1.cmml"><mi id="alg1.l7.m1.3.3.1.1.1.3" xref="alg1.l7.m1.3.3.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.1.1.1.2" xref="alg1.l7.m1.3.3.1.1.1.2.cmml">​</mo><mi id="alg1.l7.m1.3.3.1.1.1.4" xref="alg1.l7.m1.3.3.1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.1.1.1.2a" xref="alg1.l7.m1.3.3.1.1.1.2.cmml">​</mo><mi id="alg1.l7.m1.3.3.1.1.1.5" xref="alg1.l7.m1.3.3.1.1.1.5.cmml">x</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.1.1.1.2b" xref="alg1.l7.m1.3.3.1.1.1.2.cmml">​</mo><mrow id="alg1.l7.m1.3.3.1.1.1.1.1" xref="alg1.l7.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="alg1.l7.m1.3.3.1.1.1.1.1.2" xref="alg1.l7.m1.3.3.1.1.1.1.2.cmml">(</mo><mrow id="alg1.l7.m1.3.3.1.1.1.1.1.1" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="alg1.l7.m1.3.3.1.1.1.1.1.1.2" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.2" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.3" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1a" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.4" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1b" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.5.2" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.5.2.1" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><mi id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">C</mi><mo rspace="0.055em" stretchy="false" id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.5.2.2" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="alg1.l7.m1.3.3.1.1.1.1.1.1.1" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.1.cmml">×</mo><mi id="alg1.l7.m1.3.3.1.1.1.1.1.1.3" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo id="alg1.l7.m1.3.3.1.1.1.1.1.3" xref="alg1.l7.m1.3.3.1.1.1.1.2.cmml">,</mo><mn id="alg1.l7.m1.2.2" xref="alg1.l7.m1.2.2.cmml">1</mn><mo stretchy="false" id="alg1.l7.m1.3.3.1.1.1.1.1.4" xref="alg1.l7.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="alg1.l7.m1.3.3.1.2" xref="alg1.l7.m1.3.3.1.1.cmml">;</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.3b"><apply id="alg1.l7.m1.3.3.1.1.cmml" xref="alg1.l7.m1.3.3.1"><ci id="alg1.l7.m1.3.3.1.1.2.cmml" xref="alg1.l7.m1.3.3.1.1.2">⟵</ci><ci id="alg1.l7.m1.3.3.1.1.3.cmml" xref="alg1.l7.m1.3.3.1.1.3">𝑚</ci><apply id="alg1.l7.m1.3.3.1.1.1.cmml" xref="alg1.l7.m1.3.3.1.1.1"><times id="alg1.l7.m1.3.3.1.1.1.2.cmml" xref="alg1.l7.m1.3.3.1.1.1.2"></times><ci id="alg1.l7.m1.3.3.1.1.1.3.cmml" xref="alg1.l7.m1.3.3.1.1.1.3">𝑚</ci><ci id="alg1.l7.m1.3.3.1.1.1.4.cmml" xref="alg1.l7.m1.3.3.1.1.1.4">𝑎</ci><ci id="alg1.l7.m1.3.3.1.1.1.5.cmml" xref="alg1.l7.m1.3.3.1.1.1.5">𝑥</ci><interval closure="open" id="alg1.l7.m1.3.3.1.1.1.1.2.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1"><apply id="alg1.l7.m1.3.3.1.1.1.1.1.1.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1"><times id="alg1.l7.m1.3.3.1.1.1.1.1.1.1.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.1"></times><apply id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2"><times id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.1"></times><ci id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.2">𝑙</ci><ci id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.3">𝑒</ci><ci id="alg1.l7.m1.3.3.1.1.1.1.1.1.2.4.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.2.4">𝑛</ci><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">𝐶</ci></apply><ci id="alg1.l7.m1.3.3.1.1.1.1.1.1.3.cmml" xref="alg1.l7.m1.3.3.1.1.1.1.1.1.3">𝛼</ci></apply><cn type="integer" id="alg1.l7.m1.2.2.cmml" xref="alg1.l7.m1.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.3c">m\longleftarrow max(len(C)\times\alpha,1);</annotation></semantics></math>

</div>
<div id="alg1.8.10" class="ltx_listingline">
</div>
<div id="alg1.l8" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        <math id="alg1.l8.m1.1" class="ltx_Math" alttext="N_{t}\longleftarrow" display="inline"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><msub id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml"><mi id="alg1.l8.m1.1.1.2.2" xref="alg1.l8.m1.1.1.2.2.cmml">N</mi><mi id="alg1.l8.m1.1.1.2.3" xref="alg1.l8.m1.1.1.2.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml">⟵</mo><mi id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><ci id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1">⟵</ci><apply id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.2.1.cmml" xref="alg1.l8.m1.1.1.2">subscript</csymbol><ci id="alg1.l8.m1.1.1.2.2.cmml" xref="alg1.l8.m1.1.1.2.2">𝑁</ci><ci id="alg1.l8.m1.1.1.2.3.cmml" xref="alg1.l8.m1.1.1.2.3">𝑡</ci></apply><csymbol cd="latexml" id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">N_{t}\longleftarrow</annotation></semantics></math>(random set of <math id="alg1.l8.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="alg1.l8.m2.1a"><mi id="alg1.l8.m2.1.1" xref="alg1.l8.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b"><ci id="alg1.l8.m2.1.1.cmml" xref="alg1.l8.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m2.1c">m</annotation></semantics></math> peers from <math id="alg1.l8.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="alg1.l8.m3.1a"><mi id="alg1.l8.m3.1.1" xref="alg1.l8.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m3.1b"><ci id="alg1.l8.m3.1.1.cmml" xref="alg1.l8.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m3.1c">C</annotation></semantics></math>);

</div>
<div id="alg1.8.11" class="ltx_listingline">
</div>
<div id="alg1.l9" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        <span id="alg1.l9.1" class="ltx_text ltx_font_bold">for</span> each node <math id="alg1.l9.m1.1" class="ltx_Math" alttext="k\in N_{t}" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><mi id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml">k</mi><mo id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">∈</mo><msub id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml"><mi id="alg1.l9.m1.1.1.3.2" xref="alg1.l9.m1.1.1.3.2.cmml">N</mi><mi id="alg1.l9.m1.1.1.3.3" xref="alg1.l9.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><in id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1"></in><ci id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2">𝑘</ci><apply id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.1.cmml" xref="alg1.l9.m1.1.1.3">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.2.cmml" xref="alg1.l9.m1.1.1.3.2">𝑁</ci><ci id="alg1.l9.m1.1.1.3.3.cmml" xref="alg1.l9.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">k\in N_{t}</annotation></semantics></math> <span id="alg1.l9.2" class="ltx_text ltx_font_bold">in parallel</span> <span id="alg1.l9.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.8.12" class="ltx_listingline">
</div>
<div id="alg1.l10" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>           Fetch <math id="alg1.l10.m1.1" class="ltx_Math" alttext="w_{t+1}^{k}" display="inline"><semantics id="alg1.l10.m1.1a"><msubsup id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><mi id="alg1.l10.m1.1.1.2.2" xref="alg1.l10.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l10.m1.1.1.2.3" xref="alg1.l10.m1.1.1.2.3.cmml"><mi id="alg1.l10.m1.1.1.2.3.2" xref="alg1.l10.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l10.m1.1.1.2.3.1" xref="alg1.l10.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l10.m1.1.1.2.3.3" xref="alg1.l10.m1.1.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l10.m1.1.1.3" xref="alg1.l10.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1">superscript</csymbol><apply id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.2.1.cmml" xref="alg1.l10.m1.1.1">subscript</csymbol><ci id="alg1.l10.m1.1.1.2.2.cmml" xref="alg1.l10.m1.1.1.2.2">𝑤</ci><apply id="alg1.l10.m1.1.1.2.3.cmml" xref="alg1.l10.m1.1.1.2.3"><plus id="alg1.l10.m1.1.1.2.3.1.cmml" xref="alg1.l10.m1.1.1.2.3.1"></plus><ci id="alg1.l10.m1.1.1.2.3.2.cmml" xref="alg1.l10.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l10.m1.1.1.2.3.3.cmml" xref="alg1.l10.m1.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.l10.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">w_{t+1}^{k}</annotation></semantics></math>

</div>
<div id="alg1.8.13" class="ltx_listingline">
</div>
<div id="alg1.l11" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        <span id="alg1.l11.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l11.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.8.14" class="ltx_listingline">
</div>
<div id="alg1.l12" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        <math id="alg1.l12.m1.1" class="ltx_Math" alttext="w_{t+1}\longleftarrow\sum_{k=1}^{K}\frac{1}{K}w_{t+1}^{k};" display="inline"><semantics id="alg1.l12.m1.1a"><mrow id="alg1.l12.m1.1.1.1" xref="alg1.l12.m1.1.1.1.1.cmml"><mrow id="alg1.l12.m1.1.1.1.1" xref="alg1.l12.m1.1.1.1.1.cmml"><msub id="alg1.l12.m1.1.1.1.1.2" xref="alg1.l12.m1.1.1.1.1.2.cmml"><mi id="alg1.l12.m1.1.1.1.1.2.2" xref="alg1.l12.m1.1.1.1.1.2.2.cmml">w</mi><mrow id="alg1.l12.m1.1.1.1.1.2.3" xref="alg1.l12.m1.1.1.1.1.2.3.cmml"><mi id="alg1.l12.m1.1.1.1.1.2.3.2" xref="alg1.l12.m1.1.1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l12.m1.1.1.1.1.2.3.1" xref="alg1.l12.m1.1.1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l12.m1.1.1.1.1.2.3.3" xref="alg1.l12.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo rspace="0.111em" stretchy="false" id="alg1.l12.m1.1.1.1.1.1" xref="alg1.l12.m1.1.1.1.1.1.cmml">⟵</mo><mrow id="alg1.l12.m1.1.1.1.1.3" xref="alg1.l12.m1.1.1.1.1.3.cmml"><msubsup id="alg1.l12.m1.1.1.1.1.3.1" xref="alg1.l12.m1.1.1.1.1.3.1.cmml"><mo id="alg1.l12.m1.1.1.1.1.3.1.2.2" xref="alg1.l12.m1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="alg1.l12.m1.1.1.1.1.3.1.2.3" xref="alg1.l12.m1.1.1.1.1.3.1.2.3.cmml"><mi id="alg1.l12.m1.1.1.1.1.3.1.2.3.2" xref="alg1.l12.m1.1.1.1.1.3.1.2.3.2.cmml">k</mi><mo id="alg1.l12.m1.1.1.1.1.3.1.2.3.1" xref="alg1.l12.m1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="alg1.l12.m1.1.1.1.1.3.1.2.3.3" xref="alg1.l12.m1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l12.m1.1.1.1.1.3.1.3" xref="alg1.l12.m1.1.1.1.1.3.1.3.cmml">K</mi></msubsup><mrow id="alg1.l12.m1.1.1.1.1.3.2" xref="alg1.l12.m1.1.1.1.1.3.2.cmml"><mfrac id="alg1.l12.m1.1.1.1.1.3.2.2" xref="alg1.l12.m1.1.1.1.1.3.2.2.cmml"><mn id="alg1.l12.m1.1.1.1.1.3.2.2.2" xref="alg1.l12.m1.1.1.1.1.3.2.2.2.cmml">1</mn><mi id="alg1.l12.m1.1.1.1.1.3.2.2.3" xref="alg1.l12.m1.1.1.1.1.3.2.2.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.1.1.3.2.1" xref="alg1.l12.m1.1.1.1.1.3.2.1.cmml">​</mo><msubsup id="alg1.l12.m1.1.1.1.1.3.2.3" xref="alg1.l12.m1.1.1.1.1.3.2.3.cmml"><mi id="alg1.l12.m1.1.1.1.1.3.2.3.2.2" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.2.cmml">w</mi><mrow id="alg1.l12.m1.1.1.1.1.3.2.3.2.3" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3.cmml"><mi id="alg1.l12.m1.1.1.1.1.3.2.3.2.3.2" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3.2.cmml">t</mi><mo id="alg1.l12.m1.1.1.1.1.3.2.3.2.3.1" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3.1.cmml">+</mo><mn id="alg1.l12.m1.1.1.1.1.3.2.3.2.3.3" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3.3.cmml">1</mn></mrow><mi id="alg1.l12.m1.1.1.1.1.3.2.3.3" xref="alg1.l12.m1.1.1.1.1.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow><mo id="alg1.l12.m1.1.1.1.2" xref="alg1.l12.m1.1.1.1.1.cmml">;</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1"><ci id="alg1.l12.m1.1.1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1.1.1">⟵</ci><apply id="alg1.l12.m1.1.1.1.1.2.cmml" xref="alg1.l12.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.2.1.cmml" xref="alg1.l12.m1.1.1.1.1.2">subscript</csymbol><ci id="alg1.l12.m1.1.1.1.1.2.2.cmml" xref="alg1.l12.m1.1.1.1.1.2.2">𝑤</ci><apply id="alg1.l12.m1.1.1.1.1.2.3.cmml" xref="alg1.l12.m1.1.1.1.1.2.3"><plus id="alg1.l12.m1.1.1.1.1.2.3.1.cmml" xref="alg1.l12.m1.1.1.1.1.2.3.1"></plus><ci id="alg1.l12.m1.1.1.1.1.2.3.2.cmml" xref="alg1.l12.m1.1.1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l12.m1.1.1.1.1.2.3.3.cmml" xref="alg1.l12.m1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l12.m1.1.1.1.1.3.cmml" xref="alg1.l12.m1.1.1.1.1.3"><apply id="alg1.l12.m1.1.1.1.1.3.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.3.1.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.1">superscript</csymbol><apply id="alg1.l12.m1.1.1.1.1.3.1.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.3.1.2.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.1">subscript</csymbol><sum id="alg1.l12.m1.1.1.1.1.3.1.2.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.1.2.2"></sum><apply id="alg1.l12.m1.1.1.1.1.3.1.2.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.1.2.3"><eq id="alg1.l12.m1.1.1.1.1.3.1.2.3.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.1.2.3.1"></eq><ci id="alg1.l12.m1.1.1.1.1.3.1.2.3.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="alg1.l12.m1.1.1.1.1.3.1.2.3.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.l12.m1.1.1.1.1.3.1.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.1.3">𝐾</ci></apply><apply id="alg1.l12.m1.1.1.1.1.3.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.2"><times id="alg1.l12.m1.1.1.1.1.3.2.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.1"></times><apply id="alg1.l12.m1.1.1.1.1.3.2.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.2"><divide id="alg1.l12.m1.1.1.1.1.3.2.2.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.2"></divide><cn type="integer" id="alg1.l12.m1.1.1.1.1.3.2.2.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.2.2">1</cn><ci id="alg1.l12.m1.1.1.1.1.3.2.2.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.2.3">𝐾</ci></apply><apply id="alg1.l12.m1.1.1.1.1.3.2.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.3.2.3.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3">superscript</csymbol><apply id="alg1.l12.m1.1.1.1.1.3.2.3.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.3.2.3.2.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="alg1.l12.m1.1.1.1.1.3.2.3.2.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.2">𝑤</ci><apply id="alg1.l12.m1.1.1.1.1.3.2.3.2.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3"><plus id="alg1.l12.m1.1.1.1.1.3.2.3.2.3.1.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3.1"></plus><ci id="alg1.l12.m1.1.1.1.1.3.2.3.2.3.2.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3.2">𝑡</ci><cn type="integer" id="alg1.l12.m1.1.1.1.1.3.2.3.2.3.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3.2.3.3">1</cn></apply></apply><ci id="alg1.l12.m1.1.1.1.1.3.2.3.3.cmml" xref="alg1.l12.m1.1.1.1.1.3.2.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">w_{t+1}\longleftarrow\sum_{k=1}^{K}\frac{1}{K}w_{t+1}^{k};</annotation></semantics></math>

</div>
<div id="alg1.8.15" class="ltx_listingline">
</div>
<div id="alg1.l13" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span id="alg1.l13.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l13.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.8.16" class="ltx_listingline">
</div>
<div id="alg1.8.17" class="ltx_listingline">


<span id="alg1.8.17.1" class="ltx_text ltx_font_bold">Function</span> <em id="alg1.8.17.2" class="ltx_emph ltx_font_typewriter">Node_Training(<em id="alg1.8.17.2.1" class="ltx_emph ltx_font_serif ltx_font_italic">w</em>)</em><span id="alg1.8.17.3" class="ltx_text ltx_font_bold">:</span>
</div>
<div id="alg1.8.18" class="ltx_listingline">

</div>
<div id="alg1.l14" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <math id="alg1.l14.m1.1" class="ltx_Math" alttext="\beta\longleftarrow" display="inline"><semantics id="alg1.l14.m1.1a"><mrow id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml"><mi id="alg1.l14.m1.1.1.2" xref="alg1.l14.m1.1.1.2.cmml">β</mi><mo stretchy="false" id="alg1.l14.m1.1.1.1" xref="alg1.l14.m1.1.1.1.cmml">⟵</mo><mi id="alg1.l14.m1.1.1.3" xref="alg1.l14.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><apply id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1"><ci id="alg1.l14.m1.1.1.1.cmml" xref="alg1.l14.m1.1.1.1">⟵</ci><ci id="alg1.l14.m1.1.1.2.cmml" xref="alg1.l14.m1.1.1.2">𝛽</ci><csymbol cd="latexml" id="alg1.l14.m1.1.1.3.cmml" xref="alg1.l14.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">\beta\longleftarrow</annotation></semantics></math>(split <math id="alg1.l14.m2.1" class="ltx_Math" alttext="P_{k}" display="inline"><semantics id="alg1.l14.m2.1a"><msub id="alg1.l14.m2.1.1" xref="alg1.l14.m2.1.1.cmml"><mi id="alg1.l14.m2.1.1.2" xref="alg1.l14.m2.1.1.2.cmml">P</mi><mi id="alg1.l14.m2.1.1.3" xref="alg1.l14.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l14.m2.1b"><apply id="alg1.l14.m2.1.1.cmml" xref="alg1.l14.m2.1.1"><csymbol cd="ambiguous" id="alg1.l14.m2.1.1.1.cmml" xref="alg1.l14.m2.1.1">subscript</csymbol><ci id="alg1.l14.m2.1.1.2.cmml" xref="alg1.l14.m2.1.1.2">𝑃</ci><ci id="alg1.l14.m2.1.1.3.cmml" xref="alg1.l14.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m2.1c">P_{k}</annotation></semantics></math> into batches of size <math id="alg1.l14.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="alg1.l14.m3.1a"><mi id="alg1.l14.m3.1.1" xref="alg1.l14.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="alg1.l14.m3.1b"><ci id="alg1.l14.m3.1.1.cmml" xref="alg1.l14.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m3.1c">B</annotation></semantics></math>);

</div>
<div id="alg1.8.19" class="ltx_listingline">
</div>
<div id="alg1.l15" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span id="alg1.l15.1" class="ltx_text ltx_font_bold">for</span> each local epoch <math id="alg1.l15.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="alg1.l15.m1.1a"><mi id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><ci id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">i</annotation></semantics></math> from 1 to E  <span id="alg1.l15.2" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.8.20" class="ltx_listingline">
</div>
<div id="alg1.l16" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        <span id="alg1.l16.1" class="ltx_text ltx_font_bold">for</span> batch <math id="alg1.l16.m1.1" class="ltx_Math" alttext="b\in\beta" display="inline"><semantics id="alg1.l16.m1.1a"><mrow id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml"><mi id="alg1.l16.m1.1.1.2" xref="alg1.l16.m1.1.1.2.cmml">b</mi><mo id="alg1.l16.m1.1.1.1" xref="alg1.l16.m1.1.1.1.cmml">∈</mo><mi id="alg1.l16.m1.1.1.3" xref="alg1.l16.m1.1.1.3.cmml">β</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><apply id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1"><in id="alg1.l16.m1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1"></in><ci id="alg1.l16.m1.1.1.2.cmml" xref="alg1.l16.m1.1.1.2">𝑏</ci><ci id="alg1.l16.m1.1.1.3.cmml" xref="alg1.l16.m1.1.1.3">𝛽</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">b\in\beta</annotation></semantics></math> <span id="alg1.l16.2" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.8.21" class="ltx_listingline">
</div>
<div id="alg1.l17" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>           <math id="alg1.l17.m1.3" class="ltx_Math" alttext="w\longleftarrow w-\gamma\nabla l(w;b);" display="inline"><semantics id="alg1.l17.m1.3a"><mrow id="alg1.l17.m1.3.3.1" xref="alg1.l17.m1.3.3.1.1.cmml"><mrow id="alg1.l17.m1.3.3.1.1" xref="alg1.l17.m1.3.3.1.1.cmml"><mi id="alg1.l17.m1.3.3.1.1.2" xref="alg1.l17.m1.3.3.1.1.2.cmml">w</mi><mo stretchy="false" id="alg1.l17.m1.3.3.1.1.1" xref="alg1.l17.m1.3.3.1.1.1.cmml">⟵</mo><mrow id="alg1.l17.m1.3.3.1.1.3" xref="alg1.l17.m1.3.3.1.1.3.cmml"><mi id="alg1.l17.m1.3.3.1.1.3.2" xref="alg1.l17.m1.3.3.1.1.3.2.cmml">w</mi><mo id="alg1.l17.m1.3.3.1.1.3.1" xref="alg1.l17.m1.3.3.1.1.3.1.cmml">−</mo><mrow id="alg1.l17.m1.3.3.1.1.3.3" xref="alg1.l17.m1.3.3.1.1.3.3.cmml"><mi id="alg1.l17.m1.3.3.1.1.3.3.2" xref="alg1.l17.m1.3.3.1.1.3.3.2.cmml">γ</mi><mo lspace="0.167em" rspace="0em" id="alg1.l17.m1.3.3.1.1.3.3.1" xref="alg1.l17.m1.3.3.1.1.3.3.1.cmml">​</mo><mrow id="alg1.l17.m1.3.3.1.1.3.3.3" xref="alg1.l17.m1.3.3.1.1.3.3.3.cmml"><mo rspace="0.167em" id="alg1.l17.m1.3.3.1.1.3.3.3.1" xref="alg1.l17.m1.3.3.1.1.3.3.3.1.cmml">∇</mo><mi id="alg1.l17.m1.3.3.1.1.3.3.3.2" xref="alg1.l17.m1.3.3.1.1.3.3.3.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.l17.m1.3.3.1.1.3.3.1a" xref="alg1.l17.m1.3.3.1.1.3.3.1.cmml">​</mo><mrow id="alg1.l17.m1.3.3.1.1.3.3.4.2" xref="alg1.l17.m1.3.3.1.1.3.3.4.1.cmml"><mo stretchy="false" id="alg1.l17.m1.3.3.1.1.3.3.4.2.1" xref="alg1.l17.m1.3.3.1.1.3.3.4.1.cmml">(</mo><mi id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml">w</mi><mo id="alg1.l17.m1.3.3.1.1.3.3.4.2.2" xref="alg1.l17.m1.3.3.1.1.3.3.4.1.cmml">;</mo><mi id="alg1.l17.m1.2.2" xref="alg1.l17.m1.2.2.cmml">b</mi><mo stretchy="false" id="alg1.l17.m1.3.3.1.1.3.3.4.2.3" xref="alg1.l17.m1.3.3.1.1.3.3.4.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="alg1.l17.m1.3.3.1.2" xref="alg1.l17.m1.3.3.1.1.cmml">;</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.3b"><apply id="alg1.l17.m1.3.3.1.1.cmml" xref="alg1.l17.m1.3.3.1"><ci id="alg1.l17.m1.3.3.1.1.1.cmml" xref="alg1.l17.m1.3.3.1.1.1">⟵</ci><ci id="alg1.l17.m1.3.3.1.1.2.cmml" xref="alg1.l17.m1.3.3.1.1.2">𝑤</ci><apply id="alg1.l17.m1.3.3.1.1.3.cmml" xref="alg1.l17.m1.3.3.1.1.3"><minus id="alg1.l17.m1.3.3.1.1.3.1.cmml" xref="alg1.l17.m1.3.3.1.1.3.1"></minus><ci id="alg1.l17.m1.3.3.1.1.3.2.cmml" xref="alg1.l17.m1.3.3.1.1.3.2">𝑤</ci><apply id="alg1.l17.m1.3.3.1.1.3.3.cmml" xref="alg1.l17.m1.3.3.1.1.3.3"><times id="alg1.l17.m1.3.3.1.1.3.3.1.cmml" xref="alg1.l17.m1.3.3.1.1.3.3.1"></times><ci id="alg1.l17.m1.3.3.1.1.3.3.2.cmml" xref="alg1.l17.m1.3.3.1.1.3.3.2">𝛾</ci><apply id="alg1.l17.m1.3.3.1.1.3.3.3.cmml" xref="alg1.l17.m1.3.3.1.1.3.3.3"><ci id="alg1.l17.m1.3.3.1.1.3.3.3.1.cmml" xref="alg1.l17.m1.3.3.1.1.3.3.3.1">∇</ci><ci id="alg1.l17.m1.3.3.1.1.3.3.3.2.cmml" xref="alg1.l17.m1.3.3.1.1.3.3.3.2">𝑙</ci></apply><list id="alg1.l17.m1.3.3.1.1.3.3.4.1.cmml" xref="alg1.l17.m1.3.3.1.1.3.3.4.2"><ci id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1">𝑤</ci><ci id="alg1.l17.m1.2.2.cmml" xref="alg1.l17.m1.2.2">𝑏</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.3c">w\longleftarrow w-\gamma\nabla l(w;b);</annotation></semantics></math>

</div>
<div id="alg1.8.22" class="ltx_listingline">
</div>
<div id="alg1.l18" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>        <span id="alg1.l18.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l18.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.8.23" class="ltx_listingline">
</div>
<div id="alg1.l19" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span id="alg1.l19.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l19.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.8.24" class="ltx_listingline">
</div>
<div id="alg1.8.25" class="ltx_listingline">
</div>
<div id="alg1.l20" class="ltx_listingline">  <span id="alg1.l20.1" class="ltx_text ltx_font_bold">return</span> <math id="alg1.l20.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="alg1.l20.m1.1a"><mi id="alg1.l20.m1.1.1" xref="alg1.l20.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="alg1.l20.m1.1b"><ci id="alg1.l20.m1.1.1.cmml" xref="alg1.l20.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l20.m1.1c">w</annotation></semantics></math> to local storage

</div>
<div id="alg1.8.26" class="ltx_listingline">
</div>
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.9.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>EdgeFL - In the system, <math id="alg1.4.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="alg1.4.m1.1b"><mi id="alg1.4.m1.1.1" xref="alg1.4.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="alg1.4.m1.1c"><ci id="alg1.4.m1.1.1.cmml" xref="alg1.4.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.m1.1d">\alpha</annotation></semantics></math> represents the ratio of aggregated peers; <math id="alg1.5.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="alg1.5.m2.1b"><mi id="alg1.5.m2.1.1" xref="alg1.5.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.5.m2.1c"><ci id="alg1.5.m2.1.1.cmml" xref="alg1.5.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.m2.1d">C</annotation></semantics></math> is the active peer list; B is the local mini-batch size; E represents the number of local epochs, and <math id="alg1.6.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="alg1.6.m3.1b"><mi id="alg1.6.m3.1.1" xref="alg1.6.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="alg1.6.m3.1c"><ci id="alg1.6.m3.1.1.cmml" xref="alg1.6.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.m3.1d">\gamma</annotation></semantics></math> is the learning rate.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.10" class="ltx_listingline ltx_figure_panel">
</div>
</div>
</div>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.4.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.5.2" class="ltx_text ltx_font_italic">Containerization and Scalable Deployment</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">To ensure easy deployment on edge devices, the EdgeFL framework was containerized using containerization technologies, namely, Docker. The containerization process involved encapsulating all the necessary components, dependencies, and configurations of EdgeFL into a lightweight and portable container image. This approach allows for seamless deployment across a variety of edge devices, regardless of the underlying operating system or hardware architecture.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<p id="S4.F3.1" class="ltx_p ltx_align_center"><span id="S4.F3.1.1" class="ltx_text"><img src="/html/2309.02936/assets/Container.png" id="S4.F3.1.1.g1" class="ltx_graphics ltx_img_square" width="483" height="544" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Containerized architecture for seamless and scalable deployment of the EdgeFL framework</figcaption>
</figure>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">The architectural diagram illustrated in Figure <a href="#S4.F3" title="Figure 3 ‣ IV-E Containerization and Scalable Deployment ‣ IV System Design of EdgeFL ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> showcases the seamless and scalable deployment of the EdgeFL framework. Within this architecture, each edge node container includes services such as local model training, model aggregation, and model serving. Simultaneously, the registration node container contains services for registration and peer discovery. Through inter-connectivity, seamless communication is facilitated among all nodes within the framework. It is important to note that the number of registration nodes can be expanded in alignment with the number of participating edge nodes. This expansion enables efficient coordination and management within the EdgeFL framework, ensuring smooth coordination.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p">By containerizing EdgeFL, software engineers can easily distribute and deploy the framework on edge devices without worrying about intricate installation procedures or compatibility issues. The containerized EdgeFL image contains all the required software libraries, frameworks, and configurations, providing a self-contained environment for running the FL client nodes. Additionally, containerization ensures that the EdgeFL framework remains isolated and independent, preventing conflicts with other software components on the edge device.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Evaluation Results</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This section presents the experimental results of EdgeFL, focusing on three key aspects as defined in Section <a href="#S3.SS4" title="III-D Evaluation Metrics ‣ III Research Method ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span></span></a>: (1) Weights update latency, which measures the time required to transmit model weights; (2) Model evolution time, which quantifies the duration for obtaining a new version of the model; and (3) Classification accuracy, evaluated on the edge dataset. To ensure an adequate number of samples on each edge node, our simulations involve a total of 10 nodes, with all nodes actively participating in the training procedure in both MNIST and CIFAR10 applications. This configuration enables comprehensive analysis and evaluation of the EdgeFL framework, providing valuable insights into its performance and effectiveness in real-world scenarios.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Comparison of weight update latency and model evolution time by leveraging existing FL platforms/frameworks and our proposed EdgeFL framework</figcaption>
<table id="S5.T3.3.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T3.3.3.4" class="ltx_tr">
<td id="S5.T3.3.3.4.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T3.3.3.4.1.1" class="ltx_text">FL Frameworks/Platforms</span></td>
<td id="S5.T3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">MNIST</td>
<td id="S5.T3.3.3.4.3" class="ltx_td ltx_border_tt"></td>
<td id="S5.T3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">CIFAR10</td>
</tr>
<tr id="S5.T3.3.3.5" class="ltx_tr">
<td id="S5.T3.3.3.5.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T3.3.3.5.1.1" class="ltx_text"></span> <span id="S5.T3.3.3.5.1.2" class="ltx_text">
<span id="S5.T3.3.3.5.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.3.3.5.1.2.1.1" class="ltx_tr">
<span id="S5.T3.3.3.5.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Weights Update Latency</span></span>
<span id="S5.T3.3.3.5.1.2.1.2" class="ltx_tr">
<span id="S5.T3.3.3.5.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(sec)</span></span>
</span></span><span id="S5.T3.3.3.5.1.3" class="ltx_text"></span></td>
<td id="S5.T3.3.3.5.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T3.3.3.5.2.1" class="ltx_text"></span> <span id="S5.T3.3.3.5.2.2" class="ltx_text">
<span id="S5.T3.3.3.5.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.3.3.5.2.2.1.1" class="ltx_tr">
<span id="S5.T3.3.3.5.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Model Evolution Time</span></span>
<span id="S5.T3.3.3.5.2.2.1.2" class="ltx_tr">
<span id="S5.T3.3.3.5.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(sec)</span></span>
</span></span><span id="S5.T3.3.3.5.2.3" class="ltx_text"></span></td>
<td id="S5.T3.3.3.5.3" class="ltx_td"></td>
<td id="S5.T3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T3.3.3.5.4.1" class="ltx_text"></span> <span id="S5.T3.3.3.5.4.2" class="ltx_text">
<span id="S5.T3.3.3.5.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.3.3.5.4.2.1.1" class="ltx_tr">
<span id="S5.T3.3.3.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Weights Update Latency</span></span>
<span id="S5.T3.3.3.5.4.2.1.2" class="ltx_tr">
<span id="S5.T3.3.3.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(sec)</span></span>
</span></span><span id="S5.T3.3.3.5.4.3" class="ltx_text"></span></td>
<td id="S5.T3.3.3.5.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T3.3.3.5.5.1" class="ltx_text"></span> <span id="S5.T3.3.3.5.5.2" class="ltx_text">
<span id="S5.T3.3.3.5.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.3.3.5.5.2.1.1" class="ltx_tr">
<span id="S5.T3.3.3.5.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Model Evolution Time</span></span>
<span id="S5.T3.3.3.5.5.2.1.2" class="ltx_tr">
<span id="S5.T3.3.3.5.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(sec)</span></span>
</span></span><span id="S5.T3.3.3.5.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T3.1.1.1" class="ltx_tr">
<td id="S5.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">TFF<sup id="S5.T3.1.1.1.1.1" class="ltx_sup">⋆</sup>
</td>
<td id="S5.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">7.76</td>
<td id="S5.T3.1.1.1.4" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">16.372</td>
</tr>
<tr id="S5.T3.3.3.6" class="ltx_tr">
<td id="S5.T3.3.3.6.1" class="ltx_td ltx_align_center">PySyft</td>
<td id="S5.T3.3.3.6.2" class="ltx_td ltx_align_center">0.0247</td>
<td id="S5.T3.3.3.6.3" class="ltx_td ltx_align_center">9.05</td>
<td id="S5.T3.3.3.6.4" class="ltx_td"></td>
<td id="S5.T3.3.3.6.5" class="ltx_td ltx_align_center">0.0311</td>
<td id="S5.T3.3.3.6.6" class="ltx_td ltx_align_center">18.292</td>
</tr>
<tr id="S5.T3.3.3.7" class="ltx_tr">
<td id="S5.T3.3.3.7.1" class="ltx_td ltx_align_center">FATE</td>
<td id="S5.T3.3.3.7.2" class="ltx_td ltx_align_center">0.0326</td>
<td id="S5.T3.3.3.7.3" class="ltx_td ltx_align_center">13.868</td>
<td id="S5.T3.3.3.7.4" class="ltx_td"></td>
<td id="S5.T3.3.3.7.5" class="ltx_td ltx_align_center">0.0473</td>
<td id="S5.T3.3.3.7.6" class="ltx_td ltx_align_center">31.689</td>
</tr>
<tr id="S5.T3.2.2.2" class="ltx_tr">
<td id="S5.T3.2.2.2.1" class="ltx_td ltx_align_center">LEAF<sup id="S5.T3.2.2.2.1.1" class="ltx_sup">⋆</sup>
</td>
<td id="S5.T3.2.2.2.2" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.2.2.2.3" class="ltx_td ltx_align_center">10.239</td>
<td id="S5.T3.2.2.2.4" class="ltx_td"></td>
<td id="S5.T3.2.2.2.5" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.2.2.2.6" class="ltx_td ltx_align_center">27.362</td>
</tr>
<tr id="S5.T3.3.3.8" class="ltx_tr">
<td id="S5.T3.3.3.8.1" class="ltx_td ltx_align_center">PaddelFL</td>
<td id="S5.T3.3.3.8.2" class="ltx_td ltx_align_center">0.0258</td>
<td id="S5.T3.3.3.8.3" class="ltx_td ltx_align_center">11.667</td>
<td id="S5.T3.3.3.8.4" class="ltx_td"></td>
<td id="S5.T3.3.3.8.5" class="ltx_td ltx_align_center">0.0412</td>
<td id="S5.T3.3.3.8.6" class="ltx_td ltx_align_center">25.581</td>
</tr>
<tr id="S5.T3.3.3.9" class="ltx_tr">
<td id="S5.T3.3.3.9.1" class="ltx_td ltx_align_center"><span id="S5.T3.3.3.9.1.1" class="ltx_text ltx_font_bold">EdgeFL</span></td>
<td id="S5.T3.3.3.9.2" class="ltx_td ltx_align_center"><span id="S5.T3.3.3.9.2.1" class="ltx_text ltx_font_bold">0.0092</span></td>
<td id="S5.T3.3.3.9.3" class="ltx_td ltx_align_center"><span id="S5.T3.3.3.9.3.1" class="ltx_text ltx_font_bold">5.093</span></td>
<td id="S5.T3.3.3.9.4" class="ltx_td"></td>
<td id="S5.T3.3.3.9.5" class="ltx_td ltx_align_center"><span id="S5.T3.3.3.9.5.1" class="ltx_text ltx_font_bold">0.0148</span></td>
<td id="S5.T3.3.3.9.6" class="ltx_td ltx_align_center"><span id="S5.T3.3.3.9.6.1" class="ltx_text ltx_font_bold">10.753</span></td>
</tr>
<tr id="S5.T3.3.3.3" class="ltx_tr">
<td id="S5.T3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_tt" colspan="6">
<span id="S5.T3.3.3.3.1.2" class="ltx_text"></span><span id="S5.T3.3.3.3.1.1" class="ltx_text">
<span id="S5.T3.3.3.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.3.3.3.1.1.1.1" class="ltx_tr">
<span id="S5.T3.3.3.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><math id="S5.T3.3.3.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S5.T3.3.3.3.1.1.1.1.1.m1.1a"><mo id="S5.T3.3.3.3.1.1.1.1.1.m1.1.1" xref="S5.T3.3.3.3.1.1.1.1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.1.1.1.1.1.m1.1b"><ci id="S5.T3.3.3.3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.3.3.3.1.1.1.1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.1.1.1.1.1.m1.1c">\star</annotation></semantics></math> TFF and LEAF frameworks do not include actual server and client implementations but rather provide simulations of the FL process.</span></span>
<span id="S5.T3.3.3.3.1.1.1.2" class="ltx_tr">
<span id="S5.T3.3.3.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Therefore, measuring weight latency is not feasible within these frameworks.</span></span>
</span></span><span id="S5.T3.3.3.3.1.3" class="ltx_text"></span></td>
</tr>
</table>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">First, we examine the weights update latency and model evolution time. Our experimental results (Table <a href="#S5.T3" title="TABLE III ‣ V Evaluation Results ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>) show that our proposed EdgeFL framework outperforms existing federated learning platforms/frameworks in terms of weights update delay and model evolution time in both MNIST and CIFAR10 applications. EdgeFL has smaller delays across the board when it comes to weights update delays. The reduced model delay indicates improved efficiency in transmitting models among edge nodes, demonstrating the effectiveness of our decentralized architecture. EdgeFL also excels at achieving rapid model evolution in scenarios with unequally distributed datasets. EdgeFL enables rapid model evolution by leveraging its decentralized architecture and effectively capitalizing on the pull-based model-sharing mechanism. This mechanism allows edges to promptly update their local models, enhancing their knowledge based on the available data. Consequently, EdgeFL outperforms other frameworks by reducing the time required for model evolution in situations where dataset distribution is imbalanced.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">These findings highlight the advantages of EdgeFL over traditional federated learning approaches. The superior performance in terms of model delay and evolution time can be attributed to the streamlined communication and aggregation processes within EdgeFL. By utilizing the power of edge computing, EdgeFL minimizes the network overhead and facilitates efficient model updates.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">The observed improvements in model delay and evolution time have significant implications for real-world applications. The reduced delays enable faster transmission of updated models, ensuring timely access to the most recent knowledge across the edge network. Additionally, the shortened evolution time empowers edge devices to promptly adapt to evolving data features, making EdgeFL highly suitable for use cases that require quick model evolution and responsiveness to changing environments.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S5.F4.sf1.1" class="ltx_block ltx_minipage ltx_align_top" style="width:208.1pt;">
<img src="/html/2309.02936/assets/mnist.png" id="S5.F4.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="359" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf1.3.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S5.F4.sf1.4.2" class="ltx_text" style="font-size:80%;">MNIST</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S5.F4.sf2.1" class="ltx_block ltx_minipage ltx_align_top" style="width:208.1pt;">
<img src="/html/2309.02936/assets/cifar10.png" id="S5.F4.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="359" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf2.3.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S5.F4.sf2.4.2" class="ltx_text" style="font-size:80%;">CIFAR-10</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The comparison of classification accuracy by utilizing FedAvg (commonly used by existing FL platforms/frameworks) and EdgeFL framework</figcaption>
</figure>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">In addition to evaluating weights update delay and model evolution time, we conducted extensive accuracy comparisons between EdgeFL’s decentralized averaging and the widely used FedAvg algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> found in existing federated learning platforms/frameworks. Figure <a href="#S5.F4" title="Figure 4 ‣ V Evaluation Results ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates the results, which reveal that decentralized averaging outperforms the centralized FedAvg approach when testing the models on edge devices. Notably, the average accuracy achieved by EdgeFL’s decentralized averaging is approximately 2% higher for MNIST and 5% for CIFAR-10 datasets.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">The observed increase in accuracy showcases the efficacy of EdgeFL’s decentralized averaging mechanism in improving model performance. With the collective knowledge and insights from distributed edge devices, EdgeFL facilitates enhanced model convergence. As a result, EdgeFL enables more accurate and refined models, which are better equipped to handle the challenges of edge computing environments.</p>
</div>
<figure id="S5.F5" class="ltx_figure">
<p id="S5.F5.1" class="ltx_p ltx_align_center"><span id="S5.F5.1.1" class="ltx_text"><img src="/html/2309.02936/assets/midway.png" id="S5.F5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="1050" height="630" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Midway joined node classification performance in both MNIST and CIFAR-10 application</figcaption>
</figure>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">Furthermore, our study demonstrates the effectiveness of the asynchronous join feature in EdgeFL, which enables new nodes to seamlessly participate in the existing system and quickly acquire the latest knowledge without requiring retraining from scratch. As shown in Figure <a href="#S5.F5" title="Figure 5 ‣ V Evaluation Results ‣ EdgeFL: A Lightweight Decentralized Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we observe that when new nodes (node id: 11, 12) join the system midway through the training process, they promptly attain the same accuracy level as the system accuracy. This outcome showcases the capability of EdgeFL to facilitate efficient knowledge transfer and rapid model convergence for newly joined nodes.</p>
</div>
<div id="S5.p8" class="ltx_para">
<p id="S5.p8.1" class="ltx_p">The asynchronous join functionality in EdgeFL offers significant advantages in terms of scalability and time-to-adaptability. By allowing new nodes to directly benefit from the collective intelligence of the system without the need for extensive training, EdgeFL significantly reduces the computational burden and time required for onboarding new participants. This feature is particularly valuable in dynamic environments where nodes frequently join and leave the system.</p>
</div>
<div id="S5.p9" class="ltx_para">
<p id="S5.p9.1" class="ltx_p">The demonstration of the asynchronous join capability in EdgeFL emphasizes its potential for real-world deployments, especially in scenarios where rapid knowledge transfer and quick integration of new nodes are crucial. By leveraging the existing knowledge base and facilitating seamless incorporation of new nodes, EdgeFL empowers federated learning systems to efficiently adapt and evolve over time. These findings highlight the practical benefits of EdgeFL’s asynchronous join mechanism and its ability to enhance the scalability and flexibility of federated learning in dynamic edge computing environments.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Discussion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This paper focuses on analyzing and interpreting the results obtained from the experiments conducted with the EdgeFL framework. The evaluation of EdgeFL was performed using various metrics. Regarding weights update latency, EdgeFL demonstrated superior performance compared to existing Federated Learning platforms/frameworks. The decentralized communication mechanism employed in EdgeFL effectively reduced weights update delay by about 50%, outperforming centralized alternatives.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">In terms of model evolution time, EdgeFL showcased notable advantages when dealing with unequally distributed datasets. The decentralized averaging approach facilitated faster model evolution compared to traditional Federated Learning methods, such as FedAvg. By utilizing the inherent pull-based mechanism, EdgeFL enables edge devices to swiftly acquire the latest knowledge from the system without the need to retrain from scratch. This capability is crucial for rapidly adapting to dynamically changing environments, making EdgeFL well-suited for real-world deployments.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">The evaluation of classification accuracy revealed that EdgeFL’s decentralized averaging mechanism consistently outperformed the centralized FedAvg algorithm when testing the model on edge devices. The observed increase of approximately 2% and 5% in average accuracy for MNIST and CIFAR-10 datasets demonstrates the effectiveness of EdgeFL in achieving better classification performance. Moreover, the framework enabled faster model convergence, contributing to improved overall efficiency and effectiveness.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">Additionally, our experiments demonstrated the asynchronous join feature of EdgeFL, whereby a new node joining the system can promptly access the latest knowledge without requiring retraining from scratch. The experimental results showed that a newly joined node quickly achieved a high accuracy level, even when joining the system halfway through the training process. This feature highlights the scalability and efficiency of EdgeFL, as it enables seamless integration of new nodes into the existing network, without compromising overall performance.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">Overall, the evaluation and analysis of the EdgeFL framework demonstrated its efficacy in addressing the challenges of scalable and efficient edge deployment in Federated Learning. The framework exhibited better performance in terms of weight update latency, model evolution time, and classification accuracy when compared to existing solutions. The decentralized averaging mechanism, along with its pull-based model-sharing approach, proved to be particularly advantageous for achieving faster model updates and improved convergence. These findings highlight the potential of EdgeFL for various real-world applications, particularly in industrial scenarios where timely and accurate model updates are critical.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we presented EdgeFL, a novel edge-only decentralized federated learning framework that addresses the challenges of scalability, integration, and efficiency in edge deployments. By leveraging the edge-only model training and aggregation approach, EdgeFL eliminates the need for a central server, allowing for seamless scalability across diverse use cases. The framework offers a straightforward integration process, requiring only four lines of code (LOC) for software engineers to incorporate FL functionalities into their AI products. Additionally, EdgeFL provides engineers with the flexibility to customize aggregation functions according to their specific needs and requirements, enhancing the adaptability and versatility of the framework. Our experimental results and evaluation have highlighted the key strengths and advantages of EdgeFL. The framework outperforms existing FL platforms/frameworks in various aspects. It exhibits the capabilities of EdgeFL in reducing weight update latency and model evolution time by 50% and improving classification accuracy by 2% for the MNIST dataset and 5% for the CIFAR dataset compared to existing FL platforms/frameworks. These findings emphasize the potential of EdgeFL in real-world applications, particularly in industrial scenarios where timely and accurate model updates are critical.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">In future work, we will further validate and expand the capabilities of the proposed EdgeFL framework with more cases. We also intend to investigate resource optimization techniques such as model compression and quantization to enhance the communication efficiency of edge devices in EdgeFL. Furthermore, the adaptive aggregation strategies that dynamically adjust the aggregation process based on network conditions, device capabilities, and data heterogeneity will also be explored.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. L’heureux, K. Grolinger, H. F. Elyamany, and M. A. Capretz, “Machine
learning with big data: Challenges and approaches,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>,
vol. 5, pp. 7776–7797, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S. Lu, Y. Yao, and W. Shi, “Collaborative learning on the edges: A case study
on connected vehicles,” in <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">2nd <math id="bib.bib2.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib2.1.1.m1.1a"><mo stretchy="false" id="bib.bib2.1.1.m1.1.1" xref="bib.bib2.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib2.1.1.m1.1b"><ci id="bib.bib2.1.1.m1.1.1.cmml" xref="bib.bib2.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib2.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib2.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib2.2.2.m2.1a"><mo stretchy="false" id="bib.bib2.2.2.m2.1.1" xref="bib.bib2.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib2.2.2.m2.1b"><ci id="bib.bib2.2.2.m2.1.1.cmml" xref="bib.bib2.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib2.2.2.m2.1c">\}</annotation></semantics></math> Workshop on Hot Topics
in Edge Computing (HotEdge 19)</em>, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. Hu, Y. Gao, L. Liu, and H. Ma, “Federated region-learning: An edge
computing based framework for urban environment sensing,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">2018 IEEE
Global Communications Conference (GLOBECOM)</em>.   IEEE, 2018, pp. 1–7.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. S. Brisimi, R. Chen, T. Mela, A. Olshevsky, I. C. Paschalidis, and W. Shi,
“Federated learning of predictive models from federated electronic health
records,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International journal of medical informatics</em>, vol. 112, pp.
59–67, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
L. E. Lwakatare, A. Raj, J. Bosch, H. H. Olsson, and I. Crnkovic, “A taxonomy
of software engineering challenges for machine learning systems: An empirical
investigation,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">International Conference on Agile Software
Development</em>.   Springer, Cham, 2019,
pp. 227–243.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. Kiddon, J. Konecny, S. Mazzocchi, H. B. McMahan <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards
federated learning at scale: System design,” <em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1902.01046</em>, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. K. Rodrigues, K. Suto, H. Nishiyama, J. Liu, and N. Kato, “Machine learning
meets computation and communication control in evolving edge and cloud:
Challenges and future perspective,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp;
Tutorials</em>, vol. 22, no. 1, pp. 38–67, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, 2017, pp.
1273–1282.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Li, Y. Fan, M. Tse, and K.-Y. Lin, “A review of applications in federated
learning,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Industrial Engineering</em>, vol. 149, p. 106854,
2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on federated
learning,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 216, p. 106775, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
TensorFlow, “Tensorflow federated, machine learning on decentralized data,”
2021.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A. Ziller, A. Trask, A. Lopardo, B. Szymkow, B. Wagner, E. Bluemke, J.-M.
Nounahon, J. Passerat-Palmbach, K. Prakash, N. Rose <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Pysyft:
A library for easy federated learning,” <em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">Federated Learning Systems:
Towards Next-Generation AI</em>, pp. 111–139, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y. Liu, T. Fan, T. Chen, Q. Xu, and Q. Yang, “Fate: An industrial grade
platform for collaborative learning with data protection,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">The Journal
of Machine Learning Research</em>, vol. 22, no. 1, pp. 10 320–10 325, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan,
V. Smith, and A. Talwalkar, “Leaf: A benchmark for federated settings,”
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Ma, D. Yu, T. Wu, and H. Wang, “Paddlepaddle: An open-source deep learning
platform from industrial practice,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Frontiers of Data and Domputing</em>,
vol. 1, no. 1, pp. 105–115, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
D. Zhang and J. J. Tsai, “Machine learning and software engineering,”
<em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Software Quality Journal</em>, vol. 11, no. 2, pp. 87–119, 2003.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
F. Soppelsa and C. Kaewkasi, <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Native docker clustering with swarm</em>.   Packt Publishing Ltd, 2016.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
Z. Lin, N. Gimelshein, L. Antiga <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Pytorch: An imperative
style, high-performance deep learning library,” in <em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic">Advances in neural
information processing systems</em>, 2019, pp. 8026–8037.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
S. Marcel and Y. Rodriguez, “Torchvision the machine-vision package of
torch,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 18th ACM international conference on
Multimedia</em>, 2010, pp. 1485–1488.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Scikit-learn: Machine learning in python,” <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">the Journal of machine
Learning research</em>, vol. 12, pp. 2825–2830, 2011.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with
deep convolutional neural networks,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Advances in neural information
processing systems</em>, vol. 25, pp. 1097–1105, 2012.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2309.02934" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2309.02936" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2309.02936">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.02936" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2309.02937" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 07:47:00 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
