<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1905.01351] In Defense of Synthetic Data</title><meta property="og:description" content="Synthetic datasets have long been thought of as second-rate, to be used only when “real” data collected directly from the real world is unavailable. But this perspective assumes that raw data is clean, unbiased, and tr…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="In Defense of Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="In Defense of Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1905.01351">

<!--Generated on Sat Mar 16 17:20:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">In Defense of Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Luke Rodriguez
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:rodriglr@uw.edu">rodriglr@uw.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">University of Washington Information School</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Seattle</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_state">WA</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bill Howe
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:billhowe@uw.edu">billhowe@uw.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">University of Washington Information School</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Seattle</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_state">WA</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id7.id1" class="ltx_p">Synthetic datasets have long been thought of as second-rate, to be used only when “real” data collected directly from the real world is unavailable. But this perspective assumes that raw data is clean, unbiased, and trustworthy, which it rarely is. Moreover, the benefits of synthetic data for privacy and for bias correction are becoming increasingly important in any domain that works with people. Curated synthetic datasets — synthetic data derived from minimal perturbations of real data — enable early stage product development and collaboration, protect privacy, afford reproducibility, increase dataset diversity in research, and protect disadvantaged groups from problematic inferences on the original data that reflects systematic discrimination. Rather than representing a departure from the true state of the world, in this paper we argue that properly generated synthetic data is a step towards responsible and equitable research and development of machine learning systems.</p>
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>; May 13–14, 2019; San Francisco, CA</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As researchers in computer science continue to develop new methods and apply them to other domains, the nature and types of insights that we can make are shaped by the datasets to which we have access. Traditionally the trick has been to collect (or gain access to) some representative real-world dataset on the phenomenon that you wish to analyze or predict, and then use it to develop and train a state-of-the-art approach. With this approach has always come a baseline assumption that data sampled from the real world — unaltered — is the gold standard for algorithm development. In this paper, we challenge that assumption and explore common scenarios in which altering real datasets to produce a synthetic version can not only improve their usefulness, but prevent significant errors resulting from bias and protect the interests of individuals. Curated synthetic datasets derived from real data can be used for early-stage pipeline development and exploratory analysis, and can also ensure that systemic biases or unfairness in the raw data are not propagated to trained models.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">By focusing on how researchers and policymakers interact with data in practice rather than focusing on properties of a fictional dataset a priori we can investigate other desirable properties of datasets.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Benefits of synthetic data</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We explore the benefits of synthetic data directly, rather than making negative comparisons to the utility of other datasets. Each of the following subsections highlights a distinct benefit of this approach.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Protecting privacy</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Synthetic data has long been used as a mechanism to protect privacy of the individuals represented in the data. In practice, aggregation and anonymization are assumed to be sufficient, but more recently research efforts have focused on achieving synthetic data with provable guarantees using differential privacy. While generating synthetic data of this type can be a delicate process <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2009</a>)</cite>, algorithms to do so are readily available <cite class="ltx_cite ltx_citemacro_citep">(Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2012</a>)</cite>. Exploration of such datasets protects against leaking sensitive or harmful information about individuals.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Enabling exploratory development</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">As long as a dataset can offer insight to analysts or developers, there will be limitations to how widely it can be shared. Less sensitive (privacy-protected) synthetic data offers developers who often only need data for system design and testing an opportunity to start their work without access to the data their system will ingest once deployed. This data is more than sufficient for the purposes of tool design and debugging. Though this synthetic data loses some of the signal present in the original dataset, the encoded schematic information is what is relevant to this situation and the privacy risk incurred by using the unaltered data instead need not be taken on <cite class="ltx_cite ltx_citemacro_citep">(Howe
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">In practice, leveraging the privacy guarantees of synthetic data allows us to share data without being encumbered by data sharing agreements whose drafting and establishment might take months or even years <cite class="ltx_cite ltx_citemacro_citep">(Young et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>. Less sensitive data can be shared much more freely and without the same legal encumbrances that real datasets carry.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Focusing CS research attention on problems of national priority</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Much of the research done in computer science relies on high-quality granular datasets for algorithm testing. These datasets also must be publicly available for publishing transparent and reproducible evaluations of algorithms, but this necessarily means that data from potentially sensitive domains cannot be used in this kind of research. This tension creates a fundamental disconnect between the kinds of problems analyzed in many machine learning publications (e.g. plant classification, income prediction, wine quality <cite class="ltx_cite ltx_citemacro_citep">(Dua and
Karra Taniskidou, <a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite>) and problems of keen national and public interest (e.g. homelessness, mobility, education).</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Synthetic data allows us to produce datasets from these sensitive domains of interest, and helps computer science research not “overfit” to simplified, unrealistic application domains. Any loss of utility in the sense of individual-level signals that occurs in creating synthetic data does not diminish the utility of these datasets as algorithmic benchmarks. Algorithmic research focuses on evaluating the performance of the algorithms rather than reaching conclusions about the domain that the data is drawn from.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Ensuring reproducibility</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">In the current research environment, some research done in machine learning looks to address the problem of applicability by using datasets from sensitive domains. Such papers fail to be reproducible, however, as the data cannot be publicly shared. Synthetic data provides access to a more diverse set of data for research <cite class="ltx_cite ltx_citemacro_citep">(Bellovin
et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite>, while not compromising on the principle of reproducibility.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5. </span>Reducing multiple hypothesis issues</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">Best practice in data exploration looks to mitigate false discoveries that come as a result of multiple hypothesis testing. In theory, this is done through specifying a test procedure before accessing the data. In practice, however, exploratory analysis of data is a much more fluid process, and questions are often asked in response to discoveries made in the process of analysis. To accommodate this, Dwork et al. have shown that a single holdout set can be safely reused to test multiple hypotheses as long as it is only accessed through differentially private queries <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2015</a>)</cite>. Thus, a synthetic dataset generated according to differential privacy serves as a reusable holdout, as any queries made against the synthetic dataset are by guaranteed to be differentially private as a result of the data generation process.</p>
</div>
</section>
<section id="S2.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6. </span>Avoiding propagation of bias</h3>

<div id="S2.SS6.p1" class="ltx_para">
<p id="S2.SS6.p1.1" class="ltx_p">Datasets will inevitably contain bias, whether for methodological reasons such as sampling or because of systemic discrimination or oppression. For example, historical data about incomes in the United States will indicate that white males have more earning potential than females or minority groups. These are not desirable signals to have in datasets, and their inclusion risks the propagation of this discrimination when used to train algorithmic decision systems.</p>
</div>
<div id="S2.SS6.p2" class="ltx_para">
<p id="S2.SS6.p2.1" class="ltx_p">While methods have been developed recently to mitigate these biases in classification tasks <cite class="ltx_cite ltx_citemacro_citep">(Kilbertus et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>; Nabi and Shpitser, <a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>, we argue that this is not sufficient. These approaches do avoid reifying biases through classification, but they do not protect against a data analyst or project manager discovering this signal in the data and internalizing it as meaningful. Thus we suggest that biased signals should be accounted for in the creation of a synthetic dataset <cite class="ltx_cite ltx_citemacro_citep">(Feldman et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2015</a>; Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2016</a>)</cite>, which could then be used for exploratory analysis or classification.</p>
</div>
<div id="S2.SS6.p3" class="ltx_para">
<p id="S2.SS6.p3.1" class="ltx_p">This approach to generating synthetic data does raise a significant problem: who gets to decide which relationships in a dataset are problematic and which ought to remain unchanged? We believe it is important to understand the role of synthetic data in a broader sociotechnical system, and the process of creating it should involve both domain experts intimately familiar with the problems at hand and stakeholders who represent the populations present in the data. But there are scenarios in which such a decision should not be controversial. For example, when choosing synthetic data to support decisions that do not privilege white men above other groups. We intend that decisions about which biases to mitigate will be made in a transparent way, and that the conditions enforced on a dataset are made readily apparent to those who use it.</p>
</div>
</section>
<section id="S2.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.7. </span>Suppressing sensitive signals</h3>

<div id="S2.SS7.p1" class="ltx_para">
<p id="S2.SS7.p1.1" class="ltx_p">In practice, many datasets that we would hope to gain access to are collected by companies and other organizations who could have their own business practices or operating strategies reflected in the data they collect. In response, these companies invest heavily to fight attempts to release their data publicly. But synthetic datasets offer a scalpel rather than a hatchet to protecting competitive advantage; by treating the sensitive relationships as a form of bias in the original data, we can use the same techniques as used to avoid discrimination to create synthetic datasets that protect companies’ sensitive information while releasing the rest of the data.
Empirically, failing to protect against the leak of this information means that the data will be entirely unavailable for research, despite any good faith interest in supporting research.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Conclusion</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Synthetic datasets generated in order to protect privacy or to correct problematic signals will by definition differ from data as it was originally collected, but this does not imply inferiority or decreased utility. As a research community, we have an opportunity to establish the usefulness of synthetic data. A repository to collaboratively collect and manage data, equipped with algorithms for generating and curating synthetic versions would help make our community more FATE-aware. As we continue to think more critically about the role that our algorithms are playing in sociotechnical systems, it is imperative that we treat our data in the same light.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellovin
et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Steven M Bellovin,
Preetam K Dutta, and Nathan Reitinger.
2018.

</span>
<span class="ltx_bibblock">Privacy and Synthetic Datasets.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic">Stanford Technology Law Review,
Forthcoming</span> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua and
Karra Taniskidou (2017)</span>
<span class="ltx_bibblock">
Dheeru Dua and Efi
Karra Taniskidou. 2017.

</span>
<span class="ltx_bibblock">UCI Machine Learning Repository.

</span>
<span class="ltx_bibblock">(2017).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://archive.ics.uci.edu/ml" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://archive.ics.uci.edu/ml</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Vitaly
Feldman, Moritz Hardt, Toniann Pitassi,
Omer Reingold, and Aaron Roth.
2015.

</span>
<span class="ltx_bibblock">The reusable holdout: Preserving validity in
adaptive data analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic">Science</span> 349,
6248 (2015), 636–638.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Moni Naor,
Omer Reingold, Guy N Rothblum, and
Salil Vadhan. 2009.

</span>
<span class="ltx_bibblock">On the complexity of differentially private data
release: efficient algorithms and hardness results. In
<span id="bib.bib5.3.1" class="ltx_text ltx_font_italic">Proceedings of the forty-first annual ACM symposium
on Theory of computing</span>. ACM, 381–390.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feldman et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Michael Feldman, Sorelle A
Friedler, John Moeller, Carlos
Scheidegger, and Suresh Venkatasubramanian.
2015.

</span>
<span class="ltx_bibblock">Certifying and removing disparate impact. In
<span id="bib.bib6.3.1" class="ltx_text ltx_font_italic">Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining</span>. ACM,
259–268.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt
et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Moritz Hardt, Katrina
Ligett, and Frank McSherry.
2012.

</span>
<span class="ltx_bibblock">A simple and practical algorithm for differentially
private data release. In <span id="bib.bib7.3.1" class="ltx_text ltx_font_italic">Advances in Neural
Information Processing Systems</span>. 2339–2347.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt
et al<span id="bib.bib8.3.3.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Moritz Hardt, Eric Price,
Nati Srebro, et al<span id="bib.bib8.4.1" class="ltx_text">.</span>
2016.

</span>
<span class="ltx_bibblock">Equality of opportunity in supervised learning. In
<span id="bib.bib8.5.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>.
3315–3323.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Howe
et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Bill Howe, Julia
Stoyanovich, Haoyue Ping, Bernease
Herman, and Matt Gee. 2017.

</span>
<span class="ltx_bibblock">Synthetic Data for Social Good.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1710.08874</span>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kilbertus et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Niki Kilbertus,
Mateo Rojas Carulla, Giambattista
Parascandolo, Moritz Hardt, Dominik
Janzing, and Bernhard Schölkopf.
2017.

</span>
<span class="ltx_bibblock">Avoiding discrimination through causal reasoning.
In <span id="bib.bib10.3.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing
Systems</span>. 656–666.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nabi and Shpitser (2018)</span>
<span class="ltx_bibblock">
Razieh Nabi and Ilya
Shpitser. 2018.

</span>
<span class="ltx_bibblock">Fair inference on outcomes. In
<span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the… AAAI Conference on Artificial
Intelligence. AAAI Conference on Artificial Intelligence</span>,
Vol. 2018. NIH Public Access, 1931.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Young et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Meg Young, Luke
Rodriguez, Emily Keller, Feiyang Sun,
Boyang Sa, Jan Whittington, and
Bill Howe. 2019.

</span>
<span class="ltx_bibblock">Beyond Open vs. Closed: Balancing
Individual Privacy and Public Accountability in Data Sharing. In
<span id="bib.bib12.3.1" class="ltx_text ltx_font_italic">Proceedings of the Conference on Fairness,
Accountability, and Transparency - FAT* ’19</span>. ACM
Press, Atlanta, GA, USA, 191–200.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3287560.3287577" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3287560.3287577</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1905.01350" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1905.01351" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1905.01351">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1905.01351" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1905.01353" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 17:20:15 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
