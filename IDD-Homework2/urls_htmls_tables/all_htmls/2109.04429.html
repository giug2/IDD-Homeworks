<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2109.04429] A deep learned nanowire segmentation model using synthetic data augmentation</title><meta property="og:description" content="Automatized object identification and feature analysis of experimental image data are indispensable for data-driven material science; deep learning-based segmentation algorithms have been shown to be a promising techniâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A deep learned nanowire segmentation model using synthetic data augmentation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A deep learned nanowire segmentation model using synthetic data augmentation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2109.04429">

<!--Generated on Sat Mar  2 03:47:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A deep learned nanowire segmentation model using synthetic data augmentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">B. Lin*, N. Emami*, D. A. Santos**, Y. Luo**, S. Banerjee**, B.-X. Xu*
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_affiliation_institution">*Institute of Materials Science, Technische UniversitÃ¤t Darmstadt</span><span id="id6.2.id2" class="ltx_text ltx_affiliation_streetaddress">Otto-Berndt-Str. 3</span><span id="id7.3.id3" class="ltx_text ltx_affiliation_city">64287 Darmstadt </span><span id="id8.4.id4" class="ltx_text ltx_affiliation_country">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:b.lin@mfm.tu-darmstadt.de">b.lin@mfm.tu-darmstadt.de</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id9.5.id1" class="ltx_text ltx_affiliation_institution">**Department of Chemistry, Texas A&amp;M University,</span><span id="id10.6.id2" class="ltx_text ltx_affiliation_streetaddress">College Station</span><span id="id11.7.id3" class="ltx_text ltx_affiliation_city">TX 77843-3255</span><span id="id12.8.id4" class="ltx_text ltx_affiliation_country">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:banerjee@chem.tamu.edu">banerjee@chem.tamu.edu</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id4.4" class="ltx_p">Automatized object identification and feature analysis of experimental image data are indispensable for data-driven material science; deep learning-based segmentation algorithms have been shown to be a promising technique to achieve this goal. However, acquiring of high-resolution experimental images and assigning labels in order to train such algorithms is challenging and costly in terms of both time and labor expense. In the present work, we apply synthetic images, which resemble the experimental image data in terms of geometrical and visual features, to train state-of-art deep learning-based Mask R-CNN algorithms to segment vanadium pentoxide (V<sub id="id4.4.1" class="ltx_sub">2</sub>O<sub id="id4.4.2" class="ltx_sub">5</sub>) nanowires, a canonical cathode material within optical intensity-based images from spectromicroscopy. The performance evaluation demonstrates that even though the deep learning model is trained on pure synthetically generated structures, it can segment real optical intensity-based spectromicroscopy images of complex V<sub id="id4.4.3" class="ltx_sub">2</sub>O<sub id="id4.4.4" class="ltx_sub">5</sub> nanowire structures in overlapped particle networks, thus providing reliable statistical information. The model can further be used to segment nanowires in scanning electron microscopy (SEM) images, which are fundamentally different from the training dataset known to the model. The proposed methodology of using a purely synthetic dataset to train the deep learning model can be extended to any optical intensity-based images of variable particle morphology, extent of agglomeration, material class, and beyond.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Understanding the design rules that dictate materials chemistry is critical to enabling the rational design of energy storage systems. Moreover, connecting single-entity and ensemble measurements is paramount to understanding how structure-function relationships propagate across length scales and dictate the performance of hierarchical systems in battery materials <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib1" title="" class="ltx_ref">baker2018perspective, </a>; <a href="#bib.bib2" title="" class="ltx_ref">li2020peering, </a>)</cite>. The ability to probe a multitude of contrast mechanisms from a single measurement has enabled many insights into the working principles of electrochemically active materials <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib3" title="" class="ltx_ref">wolf2017visualization, </a>)</cite>. Spectromicroscopy techniques such as scanning transmission X-ray microscopy (STXM) and X-ray ptychography, for example, leverage X-absorption and scattering events to capture morphological and electronic structure information which can be colocalized at the nanometer level to provide chemical maps for a region of interest<cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib4" title="" class="ltx_ref">yu2018three, </a>; <a href="#bib.bib5" title="" class="ltx_ref">santos2020bending, </a>; <a href="#bib.bib6" title="" class="ltx_ref">andrews2020curvature, </a>)</cite>. The application of such information-rich measurements to particle networks has been limited, in part, due to the complexity of extracting morphological and chemical features from large and complex datasets.Dataset dimensionality reduction techniques such as principal component analysis considerably improve the ease of deciphering chemical markers often contained within spectraÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib7" title="" class="ltx_ref">lerotic2014mantis, </a>)</cite>. Nevertheless, there is a need for more efficient and effective workflows to obtain size and shape descriptors that can be utilized with chemical information to explore physio-chemical phenomena as a function of various descriptors.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In recent years, image segmentation algorithms that leverage the parallel processing capability of neural networks have garnered significant attention because of their potential to enable automated image analysis Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib8" title="" class="ltx_ref">lecun2015deep, </a>; <a href="#bib.bib9" title="" class="ltx_ref">he2016deep, </a>)</cite>. For example, the well-received Mask R-CNN algorithmÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib10" title="" class="ltx_ref">he2017mask, </a>)</cite> is now utilized routinely for segmentation tasks. Common Object in Context (COCO)Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib11" title="" class="ltx_ref">lin2014microsoft, </a>)</cite> and PASCAL Visual Object Classes (VOC)Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib12" title="" class="ltx_ref">pascal-voc-2010, </a>)</cite> have been developed in concert to train and benchmark the performance of algorithms for object detection, semantic segmentation, and general classification tasks in the field of computer vision. However, the requirement of large datasets to train deep-learning algorithms has been challenging to meet with experimental microscopy data in the material-chemistry community due to an inherent complexity in generation and the time-consuming nature of human annotation. Nevertheless, deep-learning algorithms based on empirical data and human annotation have been developed for several material classes, such as graphene flakes Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib13" title="" class="ltx_ref">masubuchi2020deep, </a>)</cite> imaged by optical microscopy, carbon nano-fibersÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib14" title="" class="ltx_ref">frei2021fiber, </a>)</cite> imaged by SEM and a further collection of electron microscopy images for various material class Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib15" title="" class="ltx_ref">yildirim2021bayesian, </a>)</cite>. Similarly, attempts to augment real image datasets of polycrystalline grainsÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib16" title="" class="ltx_ref">ma2020data, </a>)</cite>, or usage of image rendering techniques on nano-particles imagesÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib17" title="" class="ltx_ref">decost2017characterizing, </a>; <a href="#bib.bib18" title="" class="ltx_ref">mill2020synthetic, </a>)</cite> to counteract the prohibitive data acquisition step, have been proven to be successful.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.6" class="ltx_p">To overcome the challenges associated with limited training data we have developed a deep learning model, based on the Mask R-CNN algorithm, which has been trained entirely on synthetically generated microstructures. By applying an optical density compression step, the algorithm can segment and obtain statistical information from both electron and X-ray microscopy images of vanadium pentoxide
(V<sub id="S1.p3.6.1" class="ltx_sub">2</sub>O<sub id="S1.p3.6.2" class="ltx_sub">5</sub>), a canonical cathode material. From an image segmentation perspective, the V<sub id="S1.p3.6.3" class="ltx_sub">2</sub>O<sub id="S1.p3.6.4" class="ltx_sub">5</sub> nanoparticle dispersions shown in Fig.<a href="#S2.F1" title="Figure 1 â€£ 2.1. Synthesis and Imaging of Nanowires Particles â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> represent a fundamentally case study against â€idealâ€ monodispersion of nanoparticles characterized by a nearly spherical geometry for which the automated size determination process is documentedÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib19" title="" class="ltx_ref">ruhle2021workflow, </a>; <a href="#bib.bib15" title="" class="ltx_ref">yildirim2021bayesian, </a>)</cite>. Through the lens of chemistry-mechanics coupling, V<sub id="S1.p3.6.5" class="ltx_sub">2</sub>O<sub id="S1.p3.6.6" class="ltx_sub">5</sub> appears as a fascinating case study of image analysis, specifically, it is well known that the patterns of lithiation in these systems are strongly modified by dimensional and morphological features such as particle geometry, curvature, and interconnectsÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">santos2020bending, </a>; <a href="#bib.bib6" title="" class="ltx_ref">andrews2020curvature, </a>; <a href="#bib.bib20" title="" class="ltx_ref">horrocks2013finite, </a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In the present work, we consider three different types of microscopy images generated by X-ray ptychography, scanning transmission X-ray microscopy (STXM) and scanning electron microscopy (SEM) techniques. While each imaging technique is fundamentally different, the algorithm developed in this work demonstrates a remarkable robustness when segmenting nanorod-like structures. The present work is organized as follows: in section 2.1 we briefly outline the experimental methodology and introduce the experimental datasets, which are later utilized to validate the performance of the model. For the model training, we generate a series of synthetic images. The workflow of data generation is explained in section 2.2, whereas the details on the training of Mask R-CNN model are presented in section 2.3. In section 3, results on training, evaluation, and segmentation of considered microscopy images from the above mentioned imaging techniques are provided and discussed.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Material and Methods</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Synthesis and Imaging of Nanowires Particles </h3>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2109.04429/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="184" height="500" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Overview of the microscopy images: (a) SEM (b) X-ray ptychography (c) STXM (d)-(f) Corresponding manual annotation</figcaption>
</figure>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1. </span>Synthesis of V<sub id="S2.SS1.SSS1.5.1" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.6.2" class="ltx_sub">5</sub> Nanowires</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.28" class="ltx_p">Nanowires of <math id="S2.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS1.SSS1.p1.1.m1.1a"><mi id="S2.SS1.SSS1.p1.1.m1.1.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.1.m1.1b"><ci id="S2.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.1.m1.1c">\alpha</annotation></semantics></math>-V<sub id="S2.SS1.SSS1.p1.28.1" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.2" class="ltx_sub">5</sub>, the thermodynamic sink for binary vanadium oxides, were synthesized by a hydrothermal growth process. Briefly, V<sub id="S2.SS1.SSS1.p1.28.3" class="ltx_sub">3</sub>O<sub id="S2.SS1.SSS1.p1.28.4" class="ltx_sub">7</sub>Â·H<sub id="S2.SS1.SSS1.p1.28.5" class="ltx_sub">2</sub>O nanowires were initially prepared and calcined in air to obtain <math id="S2.SS1.SSS1.p1.7.m7.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS1.SSS1.p1.7.m7.1a"><mi id="S2.SS1.SSS1.p1.7.m7.1.1" xref="S2.SS1.SSS1.p1.7.m7.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.7.m7.1b"><ci id="S2.SS1.SSS1.p1.7.m7.1.1.cmml" xref="S2.SS1.SSS1.p1.7.m7.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.7.m7.1c">\alpha</annotation></semantics></math>-V<sub id="S2.SS1.SSS1.p1.28.6" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.7" class="ltx_sub">5</sub> nanowires crystallized in the orthorhombic phase, as reported previouslyÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">santos2020bending, </a>)</cite>. Typical dimensions span from 50 to 400 nm in width and up to several microns in length. Chemical lithiation was achieved via submersion into a 0.01M n-butyllithium solution in heptane. Metastable <math id="S2.SS1.SSS1.p1.10.m10.1" class="ltx_Math" alttext="\zeta" display="inline"><semantics id="S2.SS1.SSS1.p1.10.m10.1a"><mi id="S2.SS1.SSS1.p1.10.m10.1.1" xref="S2.SS1.SSS1.p1.10.m10.1.1.cmml">Î¶</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.10.m10.1b"><ci id="S2.SS1.SSS1.p1.10.m10.1.1.cmml" xref="S2.SS1.SSS1.p1.10.m10.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.10.m10.1c">\zeta</annotation></semantics></math>-V<sub id="S2.SS1.SSS1.p1.28.8" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.9" class="ltx_sub">5</sub> nanowires were prepared by a series of hydrothermal reactions as described in previous workÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib21" title="" class="ltx_ref">andrews2018reversible, </a>)</cite>. Briefly, bulk V<sub id="S2.SS1.SSS1.p1.28.10" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.11" class="ltx_sub">5</sub> and silver acetate were hydrothermally reacted to form an intermediate <math id="S2.SS1.SSS1.p1.15.m15.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.SS1.SSS1.p1.15.m15.1a"><mi id="S2.SS1.SSS1.p1.15.m15.1.1" xref="S2.SS1.SSS1.p1.15.m15.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.15.m15.1b"><ci id="S2.SS1.SSS1.p1.15.m15.1.1.cmml" xref="S2.SS1.SSS1.p1.15.m15.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.15.m15.1c">\beta</annotation></semantics></math>-Ag<sub id="S2.SS1.SSS1.p1.28.12" class="ltx_sub"><span id="S2.SS1.SSS1.p1.28.12.1" class="ltx_text ltx_font_italic">0.33</span></sub>V<sub id="S2.SS1.SSS1.p1.28.13" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.14" class="ltx_sub">5</sub> product. To create the tunnel-structured <math id="S2.SS1.SSS1.p1.19.m19.1" class="ltx_Math" alttext="\zeta" display="inline"><semantics id="S2.SS1.SSS1.p1.19.m19.1a"><mi id="S2.SS1.SSS1.p1.19.m19.1.1" xref="S2.SS1.SSS1.p1.19.m19.1.1.cmml">Î¶</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.19.m19.1b"><ci id="S2.SS1.SSS1.p1.19.m19.1.1.cmml" xref="S2.SS1.SSS1.p1.19.m19.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.19.m19.1c">\zeta</annotation></semantics></math>-V<sub id="S2.SS1.SSS1.p1.28.15" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.16" class="ltx_sub">5</sub>, <math id="S2.SS1.SSS1.p1.22.m22.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.SS1.SSS1.p1.22.m22.1a"><mi id="S2.SS1.SSS1.p1.22.m22.1.1" xref="S2.SS1.SSS1.p1.22.m22.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.22.m22.1b"><ci id="S2.SS1.SSS1.p1.22.m22.1.1.cmml" xref="S2.SS1.SSS1.p1.22.m22.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.22.m22.1c">\beta</annotation></semantics></math>-Ag<sub id="S2.SS1.SSS1.p1.28.17" class="ltx_sub"><span id="S2.SS1.SSS1.p1.28.17.1" class="ltx_text ltx_font_italic">0.33</span></sub>V<sub id="S2.SS1.SSS1.p1.28.18" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.19" class="ltx_sub">5</sub> was hydrothermally reacted with HCl in aqueous conditions to leach the Ag from the structure. For electrochemical sodiation, CR2032 coin cells were prepared under an inert argon environment. The working electrode was prepared by casting a mixture of the active material (<math id="S2.SS1.SSS1.p1.26.m26.1" class="ltx_Math" alttext="\zeta" display="inline"><semantics id="S2.SS1.SSS1.p1.26.m26.1a"><mi id="S2.SS1.SSS1.p1.26.m26.1.1" xref="S2.SS1.SSS1.p1.26.m26.1.1.cmml">Î¶</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.26.m26.1b"><ci id="S2.SS1.SSS1.p1.26.m26.1.1.cmml" xref="S2.SS1.SSS1.p1.26.m26.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.26.m26.1c">\zeta</annotation></semantics></math>-V<sub id="S2.SS1.SSS1.p1.28.20" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS1.p1.28.21" class="ltx_sub">5</sub>, 70 wt.%), conductive carbon (Super C45, 20 wt.%), and binder [poly(vinylidene fluoride) 10 wt.%] dispersed in N-methyl-2-pyrrolidone onto an Al foil substrate. Sodium metal and glass fiber were used for the counter electrode and separator, respectively. For the electrolyte, 1M NaPF6 solution was prepared using a solvent mixture of ethylene carbonate and diethyl carbonate (1:1 volumetric ratio). The extent of sodiation was controlled by galvanostatic discharging using a LANHE (CT2001A) battery testing system. Cells were disassembled, washed with dimethyl carbonate (DME), and dried for 24 h in an inert argon environment.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2. </span>Scanning Electron Microscopy (SEM)</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.6" class="ltx_p">Before imaging, dispersions of <math id="S2.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS1.SSS2.p1.1.m1.1a"><mi id="S2.SS1.SSS2.p1.1.m1.1.1" xref="S2.SS1.SSS2.p1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.1.m1.1b"><ci id="S2.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.1.m1.1c">\alpha</annotation></semantics></math>-V<sub id="S2.SS1.SSS2.p1.6.1" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS2.p1.6.2" class="ltx_sub">5</sub> and <math id="S2.SS1.SSS2.p1.4.m4.1" class="ltx_Math" alttext="\zeta" display="inline"><semantics id="S2.SS1.SSS2.p1.4.m4.1a"><mi id="S2.SS1.SSS2.p1.4.m4.1.1" xref="S2.SS1.SSS2.p1.4.m4.1.1.cmml">Î¶</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.4.m4.1b"><ci id="S2.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.4.m4.1c">\zeta</annotation></semantics></math>-V<sub id="S2.SS1.SSS2.p1.6.3" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS2.p1.6.4" class="ltx_sub">5</sub> nanowires were created by drop-casting onto a silicon nitride substrateÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">santos2020bending, </a>)</cite>. The SEM image shown in Fig.Â <a href="#S2.F1" title="Figure 1 â€£ 2.1. Synthesis and Imaging of Nanowires Particles â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(a) was collected on a Tescan LYRA-3 instrument equipped with a Schottky field-emission source and a low aberration conical objective lens.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3. </span>X-ray ptychography</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p id="S2.SS1.SSS3.p1.2" class="ltx_p">X-ray ptychography measurements were performed at the coherent scattering and microscopy beamline of the Advanced Light Source in Berkeley, CA. An optic with a 60 nm outer zone width, and a 40 nm step-size of the field of view was utilized. The image shown in Fig.Â <a href="#S2.F1" title="Figure 1 â€£ 2.1. Synthesis and Imaging of Nanowires Particles â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b) depicts the ratio between the t<math id="S2.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="{}_{2}g" display="inline"><semantics id="S2.SS1.SSS3.p1.1.m1.1a"><mmultiscripts id="S2.SS1.SSS3.p1.1.m1.1.1" xref="S2.SS1.SSS3.p1.1.m1.1.1.cmml"><mi id="S2.SS1.SSS3.p1.1.m1.1.1.2" xref="S2.SS1.SSS3.p1.1.m1.1.1.2.cmml">g</mi><mprescripts id="S2.SS1.SSS3.p1.1.m1.1.1a" xref="S2.SS1.SSS3.p1.1.m1.1.1.cmml"></mprescripts><mn id="S2.SS1.SSS3.p1.1.m1.1.1.3" xref="S2.SS1.SSS3.p1.1.m1.1.1.3.cmml">2</mn><mrow id="S2.SS1.SSS3.p1.1.m1.1.1b" xref="S2.SS1.SSS3.p1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p1.1.m1.1b"><apply id="S2.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS3.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS3.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS3.p1.1.m1.1.1.2">ğ‘”</ci><cn type="integer" id="S2.SS1.SSS3.p1.1.m1.1.1.3.cmml" xref="S2.SS1.SSS3.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.1.m1.1c">{}_{2}g</annotation></semantics></math> (527 eV) and e<math id="S2.SS1.SSS3.p1.2.m2.1" class="ltx_math_unparsed" alttext="{}_{g}*" display="inline"><semantics id="S2.SS1.SSS3.p1.2.m2.1a"><mmultiscripts id="S2.SS1.SSS3.p1.2.m2.1.1"><mo id="S2.SS1.SSS3.p1.2.m2.1.1.2">âˆ—</mo><mprescripts id="S2.SS1.SSS3.p1.2.m2.1.1a"></mprescripts><mi id="S2.SS1.SSS3.p1.2.m2.1.1.3">g</mi><mrow id="S2.SS1.SSS3.p1.2.m2.1.1b"></mrow></mmultiscripts><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p1.2.m2.1b">{}_{g}*</annotation></semantics></math> (529.8 eV) fine structure features at the O K-edge which correspond to transitions from O 1s core states to O 2p states hybridized with V 3d states and is indicative of the extent of intercalation.</p>
</div>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4. </span>Scanning transmission X-ray microscopy (STXM)</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para">
<p id="S2.SS1.SSS4.p1.1" class="ltx_p">The STXM measurements were performed at the spectromicroscopy beamline 10D-1 of the Canadian Light Source in Saskatoon, SK utilizing a 7 mm generalized Apple II elliptically polarizing undulator source (EPU). Here, a focused beam spot was raster-scanned across the field of view with a 35nm step size (thus determining the spatial resolution). A series of images were collected from 508 eV to 560 eV in 0.2 eV increments. The STXM image shown in Fig.Â <a href="#S2.F1" title="Figure 1 â€£ 2.1. Synthesis and Imaging of Nanowires Particles â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(c) depicts the average absorption (optical density) contrast from 508 eV to 560 eV <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">santos2020bending, </a>)</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.5. </span>Human annotation of the V<sub id="S2.SS1.SSS5.5.1" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS5.6.2" class="ltx_sub">5</sub> dataset</h4>

<div id="S2.SS1.SSS5.p1" class="ltx_para">
<p id="S2.SS1.SSS5.p1.2" class="ltx_p">Manual annotation of the V<sub id="S2.SS1.SSS5.p1.2.1" class="ltx_sub">2</sub>O<sub id="S2.SS1.SSS5.p1.2.2" class="ltx_sub">5</sub> datasets was facilitated by the web-based annotation tool Makesense.ai <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib22" title="" class="ltx_ref">makesense, </a>)</cite> in a polygon format, where points along a particle border are set to form the shape of the particles (see Fig.<a href="#S2.F1" title="Figure 1 â€£ 2.1. Synthesis and Imaging of Nanowires Particles â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). This step is performed for every particle in the present images, and the annotated file is saved in JSON formats to serve the validation purpose. It is worth noting that some limitations of the manual annotation process such as a sensitivity to human error and a dependence on spatial resolution of the native images naturally exist. Further sources of error stem from the inherent complexity of the dispersion, which results in many instances where particles are overlapped.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Synthetic dataset generation</h3>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2109.04429/assets/figures/generation_workflow.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="290" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Synthetically generated dataset for training procedure. The 3D-microstructure was compressed to create optical density-based image as input data. The individually labelled nanowires in correlation with the optical density-based image are then used to create the binary masks for output data.</figcaption>
</figure>
<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.2" class="ltx_p">To generate synthetic image datasets reminiscent of the V<sub id="S2.SS2.p1.2.1" class="ltx_sub">2</sub>O<sub id="S2.SS2.p1.2.2" class="ltx_sub">5</sub> experimental datsets particles, we have developed a random nanowire generator using the software Geodict<sup id="S2.SS2.p1.2.3" class="ltx_sup">Â®</sup>. In the generation step, for each training sample, the number of particles, length, shape distribution was specified to create 3D voxel-based structures, Fig.Â <a href="#S2.F2" title="Figure 2 â€£ 2.2. Synthetic dataset generation â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The chosen size of the domain was 512x512x200 (WxBxH). For the present work, the number of particles, diversity of morphology, and resolution, approximate the experimental information contained in the X-ray ptychography data in FigÂ <a href="#S2.F1" title="Figure 1 â€£ 2.1. Synthesis and Imaging of Nanowires Particles â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b). Higher resolution i.e. larger domain size, can be chosen at cost of longer generation time and image file size. The height of the domain for the synthetic 3D microstructure was chosen such that it exceeded the total height of the overlapped nanowires. Further, the nanowires were internally enumerated and deposited one after another. This workflow ensures that the labels are predetermined, thus bypassing the need for human annotation at a later phase. In order to mirror the transmission intensity generated by X-ray ptychography, an optical density compression step was applied to emulate thickness information. Here, voxels were first compressed along the out-of-plane direction then summed and divided by the total thickness of the microstructure. The pixel values comprising the projected optical density image map in the in-plane directions were therefore normalized, and further transformed to a gray color scale, expressed as a value from 0 to 255. Accordingly, regions where two or more particles are overlapped can be distinguished by a sudden change in optical density (i.e. pixel intensity). In a subsequent step, a standard Gaussian filter (filter size of 2) was applied to the images to account for blurring of the particle edges. As shown in Fig.Â <a href="#S2.F2" title="Figure 2 â€£ 2.2. Synthetic dataset generation â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the ground truth sample was split into individual binary masks for each nanowire contained in the synthetic ground truth image. Therefore, for each training sample, the dataset consists of one input image and N output binary mask images with N as the number of particles in that image. These binary mask images can be further used to obtain statistical information about the morphology descriptors. Before evaluation, initial dataset size of 250 images were generated for training purposes. After an initial evaluation, additional images were generated in recursive steps involving a greater diversity of particle morphology to closely replicate the experimental data. A final dataset of 1000 synthetic images were obtained for the training and validation steps. Details on the training dataset can be found in the section data and code availability.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Deep learning procedures</h3>

<figure id="S2.F3" class="ltx_figure"><img src="/html/2109.04429/assets/figures/Workflow_MRCNN.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="1079" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Workflow of the Mask-RCNN</figcaption>
</figure>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1. </span>Basic components</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">The Mask R-CNN architecture utilized in this work is based on the Detectron2 implementation by Facebook AI ResearchÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib23" title="" class="ltx_ref">wu2019detectron2, </a>)</cite>. In the following section, the basic structure of Mask R-CNN model and its workflow are briefly introduced. The model architecture can be divided into 3 main partsÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib10" title="" class="ltx_ref">he2017mask, </a>)</cite>, as illustrated in Fig.Â <a href="#S2.F3" title="Figure 3 â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>:</p>
</div>
<div id="S2.SS3.SSS1.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Feature extraction step</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Region of interest proposal and alignment</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">Overhead for mask and bounding box prediction and classification</p>
</div>
</li>
</ul>
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">This step is usually referred to as the backbone of the model and is constructed with multiple CNN layers. The input image is introduced and passed through the CNNs to extract representative features of the entire image. The CNN layers are usually deep and contain most of the model weights updated during the training steps. The backbone used here can easily be tailored to the desired segmentation task in order to improve speed and performance. The backbone used for the training in this work is a FPN with the ResNet-50 network pretrained on COCO-dataset <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib10" title="" class="ltx_ref">he2017mask, </a>)</cite>.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">This step in the model is designed to identify and extract instances from feature maps produced by the backbone. The Region proposal network (RPN) achieves this by generating a series of region of interest (ROIs), each encapsulating a single instance. The model generates hundreds of ROIs and an associated a confidence score to quantify the probability of encompassing an object for the given ROI. After filtering and modifying the coordinates of each ROI, RPN advances portions of the feature map (corresponding to each ROI) with a fixed size to the model prediction head in order to determine the properties (e,g, bounding box, and instance mask, etc.) of each instance.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">The so-called prediction heads are functions that predicts the characteristics of that proposed instance. For object detection purpose, most common R-CNN structures typically provide two instance heads, namely bounding box regression head, which draws a bounding box around an instance, and the instance classification head to classify the object class. The typical prediction head of Mask R-CNN is therefore a extension of R-CNN models with the mask segmentation, in which a binary mask is generated to label the predicted instance.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2. </span>Loss functions</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.9" class="ltx_p">During training, the difference between model prediction and ground truth should be minimized. This optimization procedure requires the definition of a function to perform this calculation, -usually referred to a loss function or a cost function. Typically, in neural networks, the optimization goal is to minimize this loss function. Different loss functions can be used for different tasks based on the input data and the desired output of the model. In the Mask R-CNN model used in this work, the defined loss function is based on the summation of 3 individual loss functionsÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib10" title="" class="ltx_ref">he2017mask, </a>)</cite>:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}=\mathcal{L}_{bbox}+\mathcal{L}_{cls}+\mathcal{L}_{mask}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml">â„’</mi><mo id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><msub id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.3.2.2" xref="S2.E1.m1.1.1.3.2.2.cmml">â„’</mi><mrow id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2" xref="S2.E1.m1.1.1.3.2.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.2.3.1" xref="S2.E1.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.2.3.3" xref="S2.E1.m1.1.1.3.2.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.2.3.1a" xref="S2.E1.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.2.3.4" xref="S2.E1.m1.1.1.3.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.2.3.1b" xref="S2.E1.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.2.3.5" xref="S2.E1.m1.1.1.3.2.3.5.cmml">x</mi></mrow></msub><mo id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml">+</mo><msub id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.3.3.2" xref="S2.E1.m1.1.1.3.3.2.cmml">â„’</mi><mrow id="S2.E1.m1.1.1.3.3.3" xref="S2.E1.m1.1.1.3.3.3.cmml"><mi id="S2.E1.m1.1.1.3.3.3.2" xref="S2.E1.m1.1.1.3.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.3.3.1" xref="S2.E1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.3.3.3" xref="S2.E1.m1.1.1.3.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.3.3.1a" xref="S2.E1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.3.3.4" xref="S2.E1.m1.1.1.3.3.3.4.cmml">s</mi></mrow></msub><mo id="S2.E1.m1.1.1.3.1a" xref="S2.E1.m1.1.1.3.1.cmml">+</mo><msub id="S2.E1.m1.1.1.3.4" xref="S2.E1.m1.1.1.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.3.4.2" xref="S2.E1.m1.1.1.3.4.2.cmml">â„’</mi><mrow id="S2.E1.m1.1.1.3.4.3" xref="S2.E1.m1.1.1.3.4.3.cmml"><mi id="S2.E1.m1.1.1.3.4.3.2" xref="S2.E1.m1.1.1.3.4.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.4.3.1" xref="S2.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.4.3.3" xref="S2.E1.m1.1.1.3.4.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.4.3.1a" xref="S2.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.4.3.4" xref="S2.E1.m1.1.1.3.4.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.4.3.1b" xref="S2.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.1.1.3.4.3.5" xref="S2.E1.m1.1.1.3.4.3.5.cmml">k</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></eq><ci id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2">â„’</ci><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><plus id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"></plus><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2">â„’</ci><apply id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3"><times id="S2.E1.m1.1.1.3.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3.1"></times><ci id="S2.E1.m1.1.1.3.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2">ğ‘</ci><ci id="S2.E1.m1.1.1.3.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.3">ğ‘</ci><ci id="S2.E1.m1.1.1.3.2.3.4.cmml" xref="S2.E1.m1.1.1.3.2.3.4">ğ‘œ</ci><ci id="S2.E1.m1.1.1.3.2.3.5.cmml" xref="S2.E1.m1.1.1.3.2.3.5">ğ‘¥</ci></apply></apply><apply id="S2.E1.m1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.3.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.3.3.2">â„’</ci><apply id="S2.E1.m1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.3.3.3"><times id="S2.E1.m1.1.1.3.3.3.1.cmml" xref="S2.E1.m1.1.1.3.3.3.1"></times><ci id="S2.E1.m1.1.1.3.3.3.2.cmml" xref="S2.E1.m1.1.1.3.3.3.2">ğ‘</ci><ci id="S2.E1.m1.1.1.3.3.3.3.cmml" xref="S2.E1.m1.1.1.3.3.3.3">ğ‘™</ci><ci id="S2.E1.m1.1.1.3.3.3.4.cmml" xref="S2.E1.m1.1.1.3.3.3.4">ğ‘ </ci></apply></apply><apply id="S2.E1.m1.1.1.3.4.cmml" xref="S2.E1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.4.1.cmml" xref="S2.E1.m1.1.1.3.4">subscript</csymbol><ci id="S2.E1.m1.1.1.3.4.2.cmml" xref="S2.E1.m1.1.1.3.4.2">â„’</ci><apply id="S2.E1.m1.1.1.3.4.3.cmml" xref="S2.E1.m1.1.1.3.4.3"><times id="S2.E1.m1.1.1.3.4.3.1.cmml" xref="S2.E1.m1.1.1.3.4.3.1"></times><ci id="S2.E1.m1.1.1.3.4.3.2.cmml" xref="S2.E1.m1.1.1.3.4.3.2">ğ‘š</ci><ci id="S2.E1.m1.1.1.3.4.3.3.cmml" xref="S2.E1.m1.1.1.3.4.3.3">ğ‘</ci><ci id="S2.E1.m1.1.1.3.4.3.4.cmml" xref="S2.E1.m1.1.1.3.4.3.4">ğ‘ </ci><ci id="S2.E1.m1.1.1.3.4.3.5.cmml" xref="S2.E1.m1.1.1.3.4.3.5">ğ‘˜</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\mathcal{L}=\mathcal{L}_{bbox}+\mathcal{L}_{cls}+\mathcal{L}_{mask}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS3.SSS2.p1.3" class="ltx_p">where <math id="S2.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{bbox}" display="inline"><semantics id="S2.SS3.SSS2.p1.1.m1.1a"><msub id="S2.SS3.SSS2.p1.1.m1.1.1" xref="S2.SS3.SSS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p1.1.m1.1.1.2" xref="S2.SS3.SSS2.p1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S2.SS3.SSS2.p1.1.m1.1.1.3" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.cmml"><mi id="S2.SS3.SSS2.p1.1.m1.1.1.3.2" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.1.m1.1.1.3.1" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.1.m1.1.1.3.3" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.1.m1.1.1.3.1a" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.1.m1.1.1.3.4" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.1.m1.1.1.3.1b" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.1.m1.1.1.3.5" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.5.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.1.m1.1b"><apply id="S2.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1.2">â„’</ci><apply id="S2.SS3.SSS2.p1.1.m1.1.1.3.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1.3"><times id="S2.SS3.SSS2.p1.1.m1.1.1.3.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.1"></times><ci id="S2.SS3.SSS2.p1.1.m1.1.1.3.2.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.2">ğ‘</ci><ci id="S2.SS3.SSS2.p1.1.m1.1.1.3.3.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.3">ğ‘</ci><ci id="S2.SS3.SSS2.p1.1.m1.1.1.3.4.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.4">ğ‘œ</ci><ci id="S2.SS3.SSS2.p1.1.m1.1.1.3.5.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1.3.5">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.1.m1.1c">\mathcal{L}_{bbox}</annotation></semantics></math> is smooth <math id="S2.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="L^{1}" display="inline"><semantics id="S2.SS3.SSS2.p1.2.m2.1a"><msup id="S2.SS3.SSS2.p1.2.m2.1.1" xref="S2.SS3.SSS2.p1.2.m2.1.1.cmml"><mi id="S2.SS3.SSS2.p1.2.m2.1.1.2" xref="S2.SS3.SSS2.p1.2.m2.1.1.2.cmml">L</mi><mn id="S2.SS3.SSS2.p1.2.m2.1.1.3" xref="S2.SS3.SSS2.p1.2.m2.1.1.3.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.2.m2.1b"><apply id="S2.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS2.p1.2.m2.1.1.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1">superscript</csymbol><ci id="S2.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1.2">ğ¿</ci><cn type="integer" id="S2.SS3.SSS2.p1.2.m2.1.1.3.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.2.m2.1c">L^{1}</annotation></semantics></math> loss function used for predicting bounding box coordinates, while <math id="S2.SS3.SSS2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{cls}" display="inline"><semantics id="S2.SS3.SSS2.p1.3.m3.1a"><msub id="S2.SS3.SSS2.p1.3.m3.1.1" xref="S2.SS3.SSS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p1.3.m3.1.1.2" xref="S2.SS3.SSS2.p1.3.m3.1.1.2.cmml">â„’</mi><mrow id="S2.SS3.SSS2.p1.3.m3.1.1.3" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.cmml"><mi id="S2.SS3.SSS2.p1.3.m3.1.1.3.2" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.3.m3.1.1.3.1" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.3.m3.1.1.3.3" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.3.m3.1.1.3.1a" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.3.m3.1.1.3.4" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.3.m3.1b"><apply id="S2.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS2.p1.3.m3.1.1.1.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.SSS2.p1.3.m3.1.1.2.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1.2">â„’</ci><apply id="S2.SS3.SSS2.p1.3.m3.1.1.3.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1.3"><times id="S2.SS3.SSS2.p1.3.m3.1.1.3.1.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.1"></times><ci id="S2.SS3.SSS2.p1.3.m3.1.1.3.2.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.2">ğ‘</ci><ci id="S2.SS3.SSS2.p1.3.m3.1.1.3.3.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.3">ğ‘™</ci><ci id="S2.SS3.SSS2.p1.3.m3.1.1.3.4.cmml" xref="S2.SS3.SSS2.p1.3.m3.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.3.m3.1c">\mathcal{L}_{cls}</annotation></semantics></math> is a cross entropy loss function to measure the classification of multiple classes and returns a probability between 0 and 1. In the case of a binary segmentation (in this case, the nanowire and the background), the cross-entropy loss function can be written as:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.5" class="ltx_Math" alttext="\mathcal{L}_{cls}=-(y\log{(p)}+\log{(1-y)}\log{(1-p)})" display="block"><semantics id="S2.E2.m1.5a"><mrow id="S2.E2.m1.5.5" xref="S2.E2.m1.5.5.cmml"><msub id="S2.E2.m1.5.5.3" xref="S2.E2.m1.5.5.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.5.5.3.2" xref="S2.E2.m1.5.5.3.2.cmml">â„’</mi><mrow id="S2.E2.m1.5.5.3.3" xref="S2.E2.m1.5.5.3.3.cmml"><mi id="S2.E2.m1.5.5.3.3.2" xref="S2.E2.m1.5.5.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.3.3.1" xref="S2.E2.m1.5.5.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.5.5.3.3.3" xref="S2.E2.m1.5.5.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.3.3.1a" xref="S2.E2.m1.5.5.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.5.5.3.3.4" xref="S2.E2.m1.5.5.3.3.4.cmml">s</mi></mrow></msub><mo id="S2.E2.m1.5.5.2" xref="S2.E2.m1.5.5.2.cmml">=</mo><mrow id="S2.E2.m1.5.5.1" xref="S2.E2.m1.5.5.1.cmml"><mo id="S2.E2.m1.5.5.1a" xref="S2.E2.m1.5.5.1.cmml">âˆ’</mo><mrow id="S2.E2.m1.5.5.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.5.5.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.cmml"><mrow id="S2.E2.m1.5.5.1.1.1.1.4" xref="S2.E2.m1.5.5.1.1.1.1.4.cmml"><mi id="S2.E2.m1.5.5.1.1.1.1.4.2" xref="S2.E2.m1.5.5.1.1.1.1.4.2.cmml">y</mi><mo lspace="0.167em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.4.1" xref="S2.E2.m1.5.5.1.1.1.1.4.1.cmml">â€‹</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.4.3.2" xref="S2.E2.m1.5.5.1.1.1.1.4.3.1.cmml"><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">log</mi><mo id="S2.E2.m1.5.5.1.1.1.1.4.3.2a" xref="S2.E2.m1.5.5.1.1.1.1.4.3.1.cmml">â¡</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.4.3.2.1" xref="S2.E2.m1.5.5.1.1.1.1.4.3.1.cmml"><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.4.3.2.1.1" xref="S2.E2.m1.5.5.1.1.1.1.4.3.1.cmml">(</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">p</mi><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.4.3.2.1.2" xref="S2.E2.m1.5.5.1.1.1.1.4.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E2.m1.5.5.1.1.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.3.cmml">+</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.2.cmml"><mrow id="S2.E2.m1.5.5.1.1.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">log</mi><mo id="S2.E2.m1.5.5.1.1.1.1.1.1.1a" xref="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml">â¡</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><mn id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo lspace="0.167em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.2.3" xref="S2.E2.m1.5.5.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.2.2.1" xref="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml"><mi id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml">log</mi><mo id="S2.E2.m1.5.5.1.1.1.1.2.2.1a" xref="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml">â¡</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1" xref="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml"><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml">(</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.cmml"><mn id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.2.cmml">1</mn><mo id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.1.cmml">âˆ’</mo><mi id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.3.cmml">p</mi></mrow><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.5b"><apply id="S2.E2.m1.5.5.cmml" xref="S2.E2.m1.5.5"><eq id="S2.E2.m1.5.5.2.cmml" xref="S2.E2.m1.5.5.2"></eq><apply id="S2.E2.m1.5.5.3.cmml" xref="S2.E2.m1.5.5.3"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.3.1.cmml" xref="S2.E2.m1.5.5.3">subscript</csymbol><ci id="S2.E2.m1.5.5.3.2.cmml" xref="S2.E2.m1.5.5.3.2">â„’</ci><apply id="S2.E2.m1.5.5.3.3.cmml" xref="S2.E2.m1.5.5.3.3"><times id="S2.E2.m1.5.5.3.3.1.cmml" xref="S2.E2.m1.5.5.3.3.1"></times><ci id="S2.E2.m1.5.5.3.3.2.cmml" xref="S2.E2.m1.5.5.3.3.2">ğ‘</ci><ci id="S2.E2.m1.5.5.3.3.3.cmml" xref="S2.E2.m1.5.5.3.3.3">ğ‘™</ci><ci id="S2.E2.m1.5.5.3.3.4.cmml" xref="S2.E2.m1.5.5.3.3.4">ğ‘ </ci></apply></apply><apply id="S2.E2.m1.5.5.1.cmml" xref="S2.E2.m1.5.5.1"><minus id="S2.E2.m1.5.5.1.2.cmml" xref="S2.E2.m1.5.5.1"></minus><apply id="S2.E2.m1.5.5.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1"><plus id="S2.E2.m1.5.5.1.1.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.3"></plus><apply id="S2.E2.m1.5.5.1.1.1.1.4.cmml" xref="S2.E2.m1.5.5.1.1.1.1.4"><times id="S2.E2.m1.5.5.1.1.1.1.4.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.4.1"></times><ci id="S2.E2.m1.5.5.1.1.1.1.4.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.4.2">ğ‘¦</ci><apply id="S2.E2.m1.5.5.1.1.1.1.4.3.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.4.3.2"><log id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"></log><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">ğ‘</ci></apply></apply><apply id="S2.E2.m1.5.5.1.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2"><times id="S2.E2.m1.5.5.1.1.1.1.2.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.3"></times><apply id="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1"><log id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3"></log><apply id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1"><minus id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.1.1.3">ğ‘¦</ci></apply></apply><apply id="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1"><log id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4"></log><apply id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1"><minus id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.1"></minus><cn type="integer" id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.2">1</cn><ci id="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.1.1.3">ğ‘</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.5c">\mathcal{L}_{cls}=-(y\log{(p)}+\log{(1-y)}\log{(1-p)})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS3.SSS2.p1.8" class="ltx_p">where the <math id="S2.SS3.SSS2.p1.4.m1.1" class="ltx_Math" alttext="\log" display="inline"><semantics id="S2.SS3.SSS2.p1.4.m1.1a"><mi id="S2.SS3.SSS2.p1.4.m1.1.1" xref="S2.SS3.SSS2.p1.4.m1.1.1.cmml">log</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.4.m1.1b"><log id="S2.SS3.SSS2.p1.4.m1.1.1.cmml" xref="S2.SS3.SSS2.p1.4.m1.1.1"></log></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.4.m1.1c">\log</annotation></semantics></math> is the natural log, <math id="S2.SS3.SSS2.p1.5.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS3.SSS2.p1.5.m2.1a"><mi id="S2.SS3.SSS2.p1.5.m2.1.1" xref="S2.SS3.SSS2.p1.5.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.5.m2.1b"><ci id="S2.SS3.SSS2.p1.5.m2.1.1.cmml" xref="S2.SS3.SSS2.p1.5.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.5.m2.1c">y</annotation></semantics></math> is a binary value (0 or 1) indicating the class of observation, and <math id="S2.SS3.SSS2.p1.6.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS3.SSS2.p1.6.m3.1a"><mi id="S2.SS3.SSS2.p1.6.m3.1.1" xref="S2.SS3.SSS2.p1.6.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.6.m3.1b"><ci id="S2.SS3.SSS2.p1.6.m3.1.1.cmml" xref="S2.SS3.SSS2.p1.6.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.6.m3.1c">p</annotation></semantics></math> is the predicted probability for the given observation. As for <math id="S2.SS3.SSS2.p1.7.m4.1" class="ltx_Math" alttext="\mathcal{L}_{mask}" display="inline"><semantics id="S2.SS3.SSS2.p1.7.m4.1a"><msub id="S2.SS3.SSS2.p1.7.m4.1.1" xref="S2.SS3.SSS2.p1.7.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p1.7.m4.1.1.2" xref="S2.SS3.SSS2.p1.7.m4.1.1.2.cmml">â„’</mi><mrow id="S2.SS3.SSS2.p1.7.m4.1.1.3" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.cmml"><mi id="S2.SS3.SSS2.p1.7.m4.1.1.3.2" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.7.m4.1.1.3.1" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.7.m4.1.1.3.3" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.7.m4.1.1.3.1a" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.7.m4.1.1.3.4" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p1.7.m4.1.1.3.1b" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.SSS2.p1.7.m4.1.1.3.5" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.7.m4.1b"><apply id="S2.SS3.SSS2.p1.7.m4.1.1.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS2.p1.7.m4.1.1.1.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1">subscript</csymbol><ci id="S2.SS3.SSS2.p1.7.m4.1.1.2.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1.2">â„’</ci><apply id="S2.SS3.SSS2.p1.7.m4.1.1.3.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1.3"><times id="S2.SS3.SSS2.p1.7.m4.1.1.3.1.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.1"></times><ci id="S2.SS3.SSS2.p1.7.m4.1.1.3.2.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.2">ğ‘š</ci><ci id="S2.SS3.SSS2.p1.7.m4.1.1.3.3.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.3">ğ‘</ci><ci id="S2.SS3.SSS2.p1.7.m4.1.1.3.4.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.4">ğ‘ </ci><ci id="S2.SS3.SSS2.p1.7.m4.1.1.3.5.cmml" xref="S2.SS3.SSS2.p1.7.m4.1.1.3.5">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.7.m4.1c">\mathcal{L}_{mask}</annotation></semantics></math>, it is a binary cross-entropy for the generated binary mask of size <math id="S2.SS3.SSS2.p1.8.m5.1" class="ltx_Math" alttext="m\times m" display="inline"><semantics id="S2.SS3.SSS2.p1.8.m5.1a"><mrow id="S2.SS3.SSS2.p1.8.m5.1.1" xref="S2.SS3.SSS2.p1.8.m5.1.1.cmml"><mi id="S2.SS3.SSS2.p1.8.m5.1.1.2" xref="S2.SS3.SSS2.p1.8.m5.1.1.2.cmml">m</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.SSS2.p1.8.m5.1.1.1" xref="S2.SS3.SSS2.p1.8.m5.1.1.1.cmml">Ã—</mo><mi id="S2.SS3.SSS2.p1.8.m5.1.1.3" xref="S2.SS3.SSS2.p1.8.m5.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.8.m5.1b"><apply id="S2.SS3.SSS2.p1.8.m5.1.1.cmml" xref="S2.SS3.SSS2.p1.8.m5.1.1"><times id="S2.SS3.SSS2.p1.8.m5.1.1.1.cmml" xref="S2.SS3.SSS2.p1.8.m5.1.1.1"></times><ci id="S2.SS3.SSS2.p1.8.m5.1.1.2.cmml" xref="S2.SS3.SSS2.p1.8.m5.1.1.2">ğ‘š</ci><ci id="S2.SS3.SSS2.p1.8.m5.1.1.3.cmml" xref="S2.SS3.SSS2.p1.8.m5.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.8.m5.1c">m\times m</annotation></semantics></math> for each ROI.</p>
</div>
</section>
<section id="S2.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3. </span>Input augmentations</h4>

<div id="S2.SS3.SSS3.p1" class="ltx_para">
<p id="S2.SS3.SSS3.p1.1" class="ltx_p">In order to introduce further variability in the dataset, standard augmentation techniques have been applied as the dataset is fed forward to the dataloader. Note here, we do not create an additional dataset in the training process. To account for intrinsic variability in the contrast and brightness of experimental microscopy datasets, we applied a random brightness and a random contrast filter ranging from 0.7 to 1.2. A random flip in both horizontal and vertical direction with a probability of 0.5 has been applied.</p>
</div>
</section>
<section id="S2.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.4. </span>Training</h4>

<div id="S2.SS3.SSS4.p1" class="ltx_para">
<p id="S2.SS3.SSS4.p1.1" class="ltx_p">It is important to note that while the synthetic datasets were modeled after experimental microscopy images, the training steps for the model developed in this work were performed solely on synthetic datasets. The stochastic gradient descent method was used with the default setting provided by the Detectron2 implementation of Mask R-CNN algorithmÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib23" title="" class="ltx_ref">wu2019detectron2, </a>)</cite>. The hyperparameters modified in the parameter study can be found in Tab.Â <a href="#S2.T1" title="Table 1 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The training was performed on 4 A100/V100 Nvidia GPUs at Lichtenberg Cluster, TU Darmstadt for a total time of 5-10 hours with a batch size of 8 images per GPU. The training time here should only provide an approximation; Study and optimization on the performance speed was not the objective of this work.</p>
</div>
</section>
<section id="S2.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.5. </span>Evaluation metrics</h4>

<div id="S2.SS3.SSS5.p1" class="ltx_para">
<p id="S2.SS3.SSS5.p1.1" class="ltx_p">To evaluate the segmentation results, we make use of three metrics. The segmentation accuracy defined in Eq.Â <a href="#S2.E3" title="In 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> is used here as simple pixel-wise correctness, which only examines the true predicted pixels with predictions made from all the objects in the foreground. TP denotes the true positive, FP the false positive, and FN the false negative predictions. Note that this metric is only applied to the foreground, which differs from the common use considering the background pixels likewise.</p>
</div>
<div id="S2.SS3.SSS5.p2" class="ltx_para">
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.1" class="ltx_Math" alttext="\mathrm{Accuracy}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}+\mathrm{FN}}" display="block"><semantics id="S2.E3.m1.1a"><mrow id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml"><mi id="S2.E3.m1.1.1.2" xref="S2.E3.m1.1.1.2.cmml">Accuracy</mi><mo id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.cmml">=</mo><mfrac id="S2.E3.m1.1.1.3" xref="S2.E3.m1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.3.2" xref="S2.E3.m1.1.1.3.2.cmml">TP</mi><mrow id="S2.E3.m1.1.1.3.3" xref="S2.E3.m1.1.1.3.3.cmml"><mi id="S2.E3.m1.1.1.3.3.2" xref="S2.E3.m1.1.1.3.3.2.cmml">TP</mi><mo id="S2.E3.m1.1.1.3.3.1" xref="S2.E3.m1.1.1.3.3.1.cmml">+</mo><mi id="S2.E3.m1.1.1.3.3.3" xref="S2.E3.m1.1.1.3.3.3.cmml">FP</mi><mo id="S2.E3.m1.1.1.3.3.1a" xref="S2.E3.m1.1.1.3.3.1.cmml">+</mo><mi id="S2.E3.m1.1.1.3.3.4" xref="S2.E3.m1.1.1.3.3.4.cmml">FN</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.1b"><apply id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1"><eq id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"></eq><ci id="S2.E3.m1.1.1.2.cmml" xref="S2.E3.m1.1.1.2">Accuracy</ci><apply id="S2.E3.m1.1.1.3.cmml" xref="S2.E3.m1.1.1.3"><divide id="S2.E3.m1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.3"></divide><ci id="S2.E3.m1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.3.2">TP</ci><apply id="S2.E3.m1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.3.3"><plus id="S2.E3.m1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.3.3.1"></plus><ci id="S2.E3.m1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.3.3.2">TP</ci><ci id="S2.E3.m1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.3.3.3">FP</ci><ci id="S2.E3.m1.1.1.3.3.4.cmml" xref="S2.E3.m1.1.1.3.3.4">FN</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.1c">\mathrm{Accuracy}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}+\mathrm{FN}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.SSS5.p3" class="ltx_para">
<p id="S2.SS3.SSS5.p3.4" class="ltx_p">The second evaluation scheme is according to COCO datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib11" title="" class="ltx_ref">lin2014microsoft, </a>)</cite> based on mean average precision (mAP). This is introduced briefly in the following section. Firstly, to confirm a correct prediction of bounding box or mask, intersection over Union is used (IoU). It is defined by the area of intersection between bounding boxes divided by their union as shown in Fig.<a href="#S2.F4" title="Figure 4 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Predictions are true positive, if IoU is higher than a given threshold, and false negative if that is lower than that threshold. The most common thresholds used are IoU<math id="S2.SS3.SSS5.p3.1.m1.1" class="ltx_Math" alttext="&gt;50" display="inline"><semantics id="S2.SS3.SSS5.p3.1.m1.1a"><mrow id="S2.SS3.SSS5.p3.1.m1.1.1" xref="S2.SS3.SSS5.p3.1.m1.1.1.cmml"><mi id="S2.SS3.SSS5.p3.1.m1.1.1.2" xref="S2.SS3.SSS5.p3.1.m1.1.1.2.cmml"></mi><mo id="S2.SS3.SSS5.p3.1.m1.1.1.1" xref="S2.SS3.SSS5.p3.1.m1.1.1.1.cmml">&gt;</mo><mn id="S2.SS3.SSS5.p3.1.m1.1.1.3" xref="S2.SS3.SSS5.p3.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p3.1.m1.1b"><apply id="S2.SS3.SSS5.p3.1.m1.1.1.cmml" xref="S2.SS3.SSS5.p3.1.m1.1.1"><gt id="S2.SS3.SSS5.p3.1.m1.1.1.1.cmml" xref="S2.SS3.SSS5.p3.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.SS3.SSS5.p3.1.m1.1.1.2.cmml" xref="S2.SS3.SSS5.p3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S2.SS3.SSS5.p3.1.m1.1.1.3.cmml" xref="S2.SS3.SSS5.p3.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p3.1.m1.1c">&gt;50</annotation></semantics></math> (<math id="S2.SS3.SSS5.p3.2.m2.1" class="ltx_Math" alttext="\mathrm{AP_{50}}" display="inline"><semantics id="S2.SS3.SSS5.p3.2.m2.1a"><msub id="S2.SS3.SSS5.p3.2.m2.1.1" xref="S2.SS3.SSS5.p3.2.m2.1.1.cmml"><mi id="S2.SS3.SSS5.p3.2.m2.1.1.2" xref="S2.SS3.SSS5.p3.2.m2.1.1.2.cmml">AP</mi><mn id="S2.SS3.SSS5.p3.2.m2.1.1.3" xref="S2.SS3.SSS5.p3.2.m2.1.1.3.cmml">50</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p3.2.m2.1b"><apply id="S2.SS3.SSS5.p3.2.m2.1.1.cmml" xref="S2.SS3.SSS5.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p3.2.m2.1.1.1.cmml" xref="S2.SS3.SSS5.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.SSS5.p3.2.m2.1.1.2.cmml" xref="S2.SS3.SSS5.p3.2.m2.1.1.2">AP</ci><cn type="integer" id="S2.SS3.SSS5.p3.2.m2.1.1.3.cmml" xref="S2.SS3.SSS5.p3.2.m2.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p3.2.m2.1c">\mathrm{AP_{50}}</annotation></semantics></math>) and IoU<math id="S2.SS3.SSS5.p3.3.m3.1" class="ltx_Math" alttext="&gt;75" display="inline"><semantics id="S2.SS3.SSS5.p3.3.m3.1a"><mrow id="S2.SS3.SSS5.p3.3.m3.1.1" xref="S2.SS3.SSS5.p3.3.m3.1.1.cmml"><mi id="S2.SS3.SSS5.p3.3.m3.1.1.2" xref="S2.SS3.SSS5.p3.3.m3.1.1.2.cmml"></mi><mo id="S2.SS3.SSS5.p3.3.m3.1.1.1" xref="S2.SS3.SSS5.p3.3.m3.1.1.1.cmml">&gt;</mo><mn id="S2.SS3.SSS5.p3.3.m3.1.1.3" xref="S2.SS3.SSS5.p3.3.m3.1.1.3.cmml">75</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p3.3.m3.1b"><apply id="S2.SS3.SSS5.p3.3.m3.1.1.cmml" xref="S2.SS3.SSS5.p3.3.m3.1.1"><gt id="S2.SS3.SSS5.p3.3.m3.1.1.1.cmml" xref="S2.SS3.SSS5.p3.3.m3.1.1.1"></gt><csymbol cd="latexml" id="S2.SS3.SSS5.p3.3.m3.1.1.2.cmml" xref="S2.SS3.SSS5.p3.3.m3.1.1.2">absent</csymbol><cn type="integer" id="S2.SS3.SSS5.p3.3.m3.1.1.3.cmml" xref="S2.SS3.SSS5.p3.3.m3.1.1.3">75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p3.3.m3.1c">&gt;75</annotation></semantics></math> (<math id="S2.SS3.SSS5.p3.4.m4.1" class="ltx_Math" alttext="\mathrm{AP_{75}}" display="inline"><semantics id="S2.SS3.SSS5.p3.4.m4.1a"><msub id="S2.SS3.SSS5.p3.4.m4.1.1" xref="S2.SS3.SSS5.p3.4.m4.1.1.cmml"><mi id="S2.SS3.SSS5.p3.4.m4.1.1.2" xref="S2.SS3.SSS5.p3.4.m4.1.1.2.cmml">AP</mi><mn id="S2.SS3.SSS5.p3.4.m4.1.1.3" xref="S2.SS3.SSS5.p3.4.m4.1.1.3.cmml">75</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p3.4.m4.1b"><apply id="S2.SS3.SSS5.p3.4.m4.1.1.cmml" xref="S2.SS3.SSS5.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p3.4.m4.1.1.1.cmml" xref="S2.SS3.SSS5.p3.4.m4.1.1">subscript</csymbol><ci id="S2.SS3.SSS5.p3.4.m4.1.1.2.cmml" xref="S2.SS3.SSS5.p3.4.m4.1.1.2">AP</ci><cn type="integer" id="S2.SS3.SSS5.p3.4.m4.1.1.3.cmml" xref="S2.SS3.SSS5.p3.4.m4.1.1.3">75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p3.4.m4.1c">\mathrm{AP_{75}}</annotation></semantics></math>).</p>
</div>
<div id="S2.SS3.SSS5.p4" class="ltx_para">
<p id="S2.SS3.SSS5.p4.1" class="ltx_p">To further understand mAP, precision and recall are defined as follows:</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2109.04429/assets/figures/IoU.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Intersection over union</figcaption>
</figure>
<div id="S2.SS3.SSS5.p5" class="ltx_para">
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.1" class="ltx_Math" alttext="\mathrm{Precision}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}\ " display="block"><semantics id="S2.E4.m1.1a"><mrow id="S2.E4.m1.1.1" xref="S2.E4.m1.1.1.cmml"><mi id="S2.E4.m1.1.1.2" xref="S2.E4.m1.1.1.2.cmml">Precision</mi><mo id="S2.E4.m1.1.1.1" xref="S2.E4.m1.1.1.1.cmml">=</mo><mfrac id="S2.E4.m1.1.1.3" xref="S2.E4.m1.1.1.3.cmml"><mi id="S2.E4.m1.1.1.3.2" xref="S2.E4.m1.1.1.3.2.cmml">TP</mi><mrow id="S2.E4.m1.1.1.3.3" xref="S2.E4.m1.1.1.3.3.cmml"><mi id="S2.E4.m1.1.1.3.3.2" xref="S2.E4.m1.1.1.3.3.2.cmml">TP</mi><mo id="S2.E4.m1.1.1.3.3.1" xref="S2.E4.m1.1.1.3.3.1.cmml">+</mo><mi id="S2.E4.m1.1.1.3.3.3" xref="S2.E4.m1.1.1.3.3.3.cmml">FP</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.1b"><apply id="S2.E4.m1.1.1.cmml" xref="S2.E4.m1.1.1"><eq id="S2.E4.m1.1.1.1.cmml" xref="S2.E4.m1.1.1.1"></eq><ci id="S2.E4.m1.1.1.2.cmml" xref="S2.E4.m1.1.1.2">Precision</ci><apply id="S2.E4.m1.1.1.3.cmml" xref="S2.E4.m1.1.1.3"><divide id="S2.E4.m1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.3"></divide><ci id="S2.E4.m1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.3.2">TP</ci><apply id="S2.E4.m1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.3.3"><plus id="S2.E4.m1.1.1.3.3.1.cmml" xref="S2.E4.m1.1.1.3.3.1"></plus><ci id="S2.E4.m1.1.1.3.3.2.cmml" xref="S2.E4.m1.1.1.3.3.2">TP</ci><ci id="S2.E4.m1.1.1.3.3.3.cmml" xref="S2.E4.m1.1.1.3.3.3">FP</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.1c">\mathrm{Precision}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}\ </annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E5.m1.1" class="ltx_Math" alttext="\mathrm{Recall}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}" display="block"><semantics id="S2.E5.m1.1a"><mrow id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml"><mi id="S2.E5.m1.1.1.2" xref="S2.E5.m1.1.1.2.cmml">Recall</mi><mo id="S2.E5.m1.1.1.1" xref="S2.E5.m1.1.1.1.cmml">=</mo><mfrac id="S2.E5.m1.1.1.3" xref="S2.E5.m1.1.1.3.cmml"><mi id="S2.E5.m1.1.1.3.2" xref="S2.E5.m1.1.1.3.2.cmml">TP</mi><mrow id="S2.E5.m1.1.1.3.3" xref="S2.E5.m1.1.1.3.3.cmml"><mi id="S2.E5.m1.1.1.3.3.2" xref="S2.E5.m1.1.1.3.3.2.cmml">TP</mi><mo id="S2.E5.m1.1.1.3.3.1" xref="S2.E5.m1.1.1.3.3.1.cmml">+</mo><mi id="S2.E5.m1.1.1.3.3.3" xref="S2.E5.m1.1.1.3.3.3.cmml">FN</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.1b"><apply id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1"><eq id="S2.E5.m1.1.1.1.cmml" xref="S2.E5.m1.1.1.1"></eq><ci id="S2.E5.m1.1.1.2.cmml" xref="S2.E5.m1.1.1.2">Recall</ci><apply id="S2.E5.m1.1.1.3.cmml" xref="S2.E5.m1.1.1.3"><divide id="S2.E5.m1.1.1.3.1.cmml" xref="S2.E5.m1.1.1.3"></divide><ci id="S2.E5.m1.1.1.3.2.cmml" xref="S2.E5.m1.1.1.3.2">TP</ci><apply id="S2.E5.m1.1.1.3.3.cmml" xref="S2.E5.m1.1.1.3.3"><plus id="S2.E5.m1.1.1.3.3.1.cmml" xref="S2.E5.m1.1.1.3.3.1"></plus><ci id="S2.E5.m1.1.1.3.3.2.cmml" xref="S2.E5.m1.1.1.3.3.2">TP</ci><ci id="S2.E5.m1.1.1.3.3.3.cmml" xref="S2.E5.m1.1.1.3.3.3">FN</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.1c">\mathrm{Recall}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS3.SSS5.p5.2" class="ltx_p">Recall is considered as true positive prediction rate, i.e., the ratio between true positive predictions and all ground truths. Precision is defined as the ratio between true positive predictions and all predictions that are made. Further, the obtained precision and recall are plotted to obtain the so-called precision-recall (PR) curve with the area under it referred to as average precision (AP). In VOC2010Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib12" title="" class="ltx_ref">pascal-voc-2010, </a>)</cite>, a modified PR curve was introduced, where precision for a given recall <math id="S2.SS3.SSS5.p5.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.SS3.SSS5.p5.1.m1.1a"><mi id="S2.SS3.SSS5.p5.1.m1.1.1" xref="S2.SS3.SSS5.p5.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p5.1.m1.1b"><ci id="S2.SS3.SSS5.p5.1.m1.1.1.cmml" xref="S2.SS3.SSS5.p5.1.m1.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p5.1.m1.1c">r</annotation></semantics></math> is set to the maximum precision for any <math id="S2.SS3.SSS5.p5.2.m2.1" class="ltx_Math" alttext="\tilde{r}\geq r" display="inline"><semantics id="S2.SS3.SSS5.p5.2.m2.1a"><mrow id="S2.SS3.SSS5.p5.2.m2.1.1" xref="S2.SS3.SSS5.p5.2.m2.1.1.cmml"><mover accent="true" id="S2.SS3.SSS5.p5.2.m2.1.1.2" xref="S2.SS3.SSS5.p5.2.m2.1.1.2.cmml"><mi id="S2.SS3.SSS5.p5.2.m2.1.1.2.2" xref="S2.SS3.SSS5.p5.2.m2.1.1.2.2.cmml">r</mi><mo id="S2.SS3.SSS5.p5.2.m2.1.1.2.1" xref="S2.SS3.SSS5.p5.2.m2.1.1.2.1.cmml">~</mo></mover><mo id="S2.SS3.SSS5.p5.2.m2.1.1.1" xref="S2.SS3.SSS5.p5.2.m2.1.1.1.cmml">â‰¥</mo><mi id="S2.SS3.SSS5.p5.2.m2.1.1.3" xref="S2.SS3.SSS5.p5.2.m2.1.1.3.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p5.2.m2.1b"><apply id="S2.SS3.SSS5.p5.2.m2.1.1.cmml" xref="S2.SS3.SSS5.p5.2.m2.1.1"><geq id="S2.SS3.SSS5.p5.2.m2.1.1.1.cmml" xref="S2.SS3.SSS5.p5.2.m2.1.1.1"></geq><apply id="S2.SS3.SSS5.p5.2.m2.1.1.2.cmml" xref="S2.SS3.SSS5.p5.2.m2.1.1.2"><ci id="S2.SS3.SSS5.p5.2.m2.1.1.2.1.cmml" xref="S2.SS3.SSS5.p5.2.m2.1.1.2.1">~</ci><ci id="S2.SS3.SSS5.p5.2.m2.1.1.2.2.cmml" xref="S2.SS3.SSS5.p5.2.m2.1.1.2.2">ğ‘Ÿ</ci></apply><ci id="S2.SS3.SSS5.p5.2.m2.1.1.3.cmml" xref="S2.SS3.SSS5.p5.2.m2.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p5.2.m2.1c">\tilde{r}\geq r</annotation></semantics></math>. Afterward, the AP can be computed by numerical integration for the area under the curve (AUC) as shown in Fig.Â <a href="#S2.F5" title="Figure 5 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. mAP is later defined as the average of AP for all classes in each image, if more than one class is present.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="/html/2109.04429/assets/x2.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>PR Curve</figcaption>
</figure>
<div id="S2.SS3.SSS5.p6" class="ltx_para">
<p id="S2.SS3.SSS5.p6.2" class="ltx_p">For VOC, usually IoUÂ <math id="S2.SS3.SSS5.p6.1.m1.1" class="ltx_Math" alttext="&gt;50" display="inline"><semantics id="S2.SS3.SSS5.p6.1.m1.1a"><mrow id="S2.SS3.SSS5.p6.1.m1.1.1" xref="S2.SS3.SSS5.p6.1.m1.1.1.cmml"><mi id="S2.SS3.SSS5.p6.1.m1.1.1.2" xref="S2.SS3.SSS5.p6.1.m1.1.1.2.cmml"></mi><mo id="S2.SS3.SSS5.p6.1.m1.1.1.1" xref="S2.SS3.SSS5.p6.1.m1.1.1.1.cmml">&gt;</mo><mn id="S2.SS3.SSS5.p6.1.m1.1.1.3" xref="S2.SS3.SSS5.p6.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.1.m1.1b"><apply id="S2.SS3.SSS5.p6.1.m1.1.1.cmml" xref="S2.SS3.SSS5.p6.1.m1.1.1"><gt id="S2.SS3.SSS5.p6.1.m1.1.1.1.cmml" xref="S2.SS3.SSS5.p6.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.SS3.SSS5.p6.1.m1.1.1.2.cmml" xref="S2.SS3.SSS5.p6.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S2.SS3.SSS5.p6.1.m1.1.1.3.cmml" xref="S2.SS3.SSS5.p6.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.1.m1.1c">&gt;50</annotation></semantics></math> is considered considered true positive prediction, which results in true predictions with any IoU higher than 0.5 contributing equally to the AP. To rectify this problem, COCO uses different thresholds for IoU ranging from 0.5 to 0.95 with a step size of 0.05 and then reports the average of all computed APs to varying thresholds as mAP, see Eq.<a href="#S2.E6" title="In 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. In this work, we use AP for <math id="S2.SS3.SSS5.p6.2.m2.1" class="ltx_Math" alttext="\mathrm{mAP_{coco}}" display="inline"><semantics id="S2.SS3.SSS5.p6.2.m2.1a"><msub id="S2.SS3.SSS5.p6.2.m2.1.1" xref="S2.SS3.SSS5.p6.2.m2.1.1.cmml"><mi id="S2.SS3.SSS5.p6.2.m2.1.1.2" xref="S2.SS3.SSS5.p6.2.m2.1.1.2.cmml">mAP</mi><mi id="S2.SS3.SSS5.p6.2.m2.1.1.3" xref="S2.SS3.SSS5.p6.2.m2.1.1.3.cmml">coco</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.2.m2.1b"><apply id="S2.SS3.SSS5.p6.2.m2.1.1.cmml" xref="S2.SS3.SSS5.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.2.m2.1.1.1.cmml" xref="S2.SS3.SSS5.p6.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.SSS5.p6.2.m2.1.1.2.cmml" xref="S2.SS3.SSS5.p6.2.m2.1.1.2">mAP</ci><ci id="S2.SS3.SSS5.p6.2.m2.1.1.3.cmml" xref="S2.SS3.SSS5.p6.2.m2.1.1.3">coco</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.2.m2.1c">\mathrm{mAP_{coco}}</annotation></semantics></math> and assume the difference is clear from the context. COCO evaluator also reports more detailed results based on the scale of the detected objects.</p>
<table id="S2.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E6.m1.1" class="ltx_Math" alttext="\mathrm{mAP_{coco}}=\frac{\mathrm{mAP_{50}}+\mathrm{mAP_{55}}+...+\mathrm{mAP_{95}}}{10}" display="block"><semantics id="S2.E6.m1.1a"><mrow id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml"><msub id="S2.E6.m1.1.1.2" xref="S2.E6.m1.1.1.2.cmml"><mi id="S2.E6.m1.1.1.2.2" xref="S2.E6.m1.1.1.2.2.cmml">mAP</mi><mi id="S2.E6.m1.1.1.2.3" xref="S2.E6.m1.1.1.2.3.cmml">coco</mi></msub><mo id="S2.E6.m1.1.1.1" xref="S2.E6.m1.1.1.1.cmml">=</mo><mfrac id="S2.E6.m1.1.1.3" xref="S2.E6.m1.1.1.3.cmml"><mrow id="S2.E6.m1.1.1.3.2" xref="S2.E6.m1.1.1.3.2.cmml"><msub id="S2.E6.m1.1.1.3.2.2" xref="S2.E6.m1.1.1.3.2.2.cmml"><mi id="S2.E6.m1.1.1.3.2.2.2" xref="S2.E6.m1.1.1.3.2.2.2.cmml">mAP</mi><mn id="S2.E6.m1.1.1.3.2.2.3" xref="S2.E6.m1.1.1.3.2.2.3.cmml">50</mn></msub><mo id="S2.E6.m1.1.1.3.2.1" xref="S2.E6.m1.1.1.3.2.1.cmml">+</mo><msub id="S2.E6.m1.1.1.3.2.3" xref="S2.E6.m1.1.1.3.2.3.cmml"><mi id="S2.E6.m1.1.1.3.2.3.2" xref="S2.E6.m1.1.1.3.2.3.2.cmml">mAP</mi><mn id="S2.E6.m1.1.1.3.2.3.3" xref="S2.E6.m1.1.1.3.2.3.3.cmml">55</mn></msub><mo id="S2.E6.m1.1.1.3.2.1a" xref="S2.E6.m1.1.1.3.2.1.cmml">+</mo><mi mathvariant="normal" id="S2.E6.m1.1.1.3.2.4" xref="S2.E6.m1.1.1.3.2.4.cmml">â€¦</mi><mo id="S2.E6.m1.1.1.3.2.1b" xref="S2.E6.m1.1.1.3.2.1.cmml">+</mo><msub id="S2.E6.m1.1.1.3.2.5" xref="S2.E6.m1.1.1.3.2.5.cmml"><mi id="S2.E6.m1.1.1.3.2.5.2" xref="S2.E6.m1.1.1.3.2.5.2.cmml">mAP</mi><mn id="S2.E6.m1.1.1.3.2.5.3" xref="S2.E6.m1.1.1.3.2.5.3.cmml">95</mn></msub></mrow><mn id="S2.E6.m1.1.1.3.3" xref="S2.E6.m1.1.1.3.3.cmml">10</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m1.1b"><apply id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1"><eq id="S2.E6.m1.1.1.1.cmml" xref="S2.E6.m1.1.1.1"></eq><apply id="S2.E6.m1.1.1.2.cmml" xref="S2.E6.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.2.1.cmml" xref="S2.E6.m1.1.1.2">subscript</csymbol><ci id="S2.E6.m1.1.1.2.2.cmml" xref="S2.E6.m1.1.1.2.2">mAP</ci><ci id="S2.E6.m1.1.1.2.3.cmml" xref="S2.E6.m1.1.1.2.3">coco</ci></apply><apply id="S2.E6.m1.1.1.3.cmml" xref="S2.E6.m1.1.1.3"><divide id="S2.E6.m1.1.1.3.1.cmml" xref="S2.E6.m1.1.1.3"></divide><apply id="S2.E6.m1.1.1.3.2.cmml" xref="S2.E6.m1.1.1.3.2"><plus id="S2.E6.m1.1.1.3.2.1.cmml" xref="S2.E6.m1.1.1.3.2.1"></plus><apply id="S2.E6.m1.1.1.3.2.2.cmml" xref="S2.E6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.3.2.2.1.cmml" xref="S2.E6.m1.1.1.3.2.2">subscript</csymbol><ci id="S2.E6.m1.1.1.3.2.2.2.cmml" xref="S2.E6.m1.1.1.3.2.2.2">mAP</ci><cn type="integer" id="S2.E6.m1.1.1.3.2.2.3.cmml" xref="S2.E6.m1.1.1.3.2.2.3">50</cn></apply><apply id="S2.E6.m1.1.1.3.2.3.cmml" xref="S2.E6.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.3.2.3.1.cmml" xref="S2.E6.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.E6.m1.1.1.3.2.3.2.cmml" xref="S2.E6.m1.1.1.3.2.3.2">mAP</ci><cn type="integer" id="S2.E6.m1.1.1.3.2.3.3.cmml" xref="S2.E6.m1.1.1.3.2.3.3">55</cn></apply><ci id="S2.E6.m1.1.1.3.2.4.cmml" xref="S2.E6.m1.1.1.3.2.4">â€¦</ci><apply id="S2.E6.m1.1.1.3.2.5.cmml" xref="S2.E6.m1.1.1.3.2.5"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.3.2.5.1.cmml" xref="S2.E6.m1.1.1.3.2.5">subscript</csymbol><ci id="S2.E6.m1.1.1.3.2.5.2.cmml" xref="S2.E6.m1.1.1.3.2.5.2">mAP</ci><cn type="integer" id="S2.E6.m1.1.1.3.2.5.3.cmml" xref="S2.E6.m1.1.1.3.2.5.3">95</cn></apply></apply><cn type="integer" id="S2.E6.m1.1.1.3.3.cmml" xref="S2.E6.m1.1.1.3.3">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.1c">\mathrm{mAP_{coco}}=\frac{\mathrm{mAP_{50}}+\mathrm{mAP_{55}}+...+\mathrm{mAP_{95}}}{10}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS3.SSS5.p6.9" class="ltx_p">With reported <math id="S2.SS3.SSS5.p6.3.m1.1" class="ltx_Math" alttext="\mathrm{AP_{small}}" display="inline"><semantics id="S2.SS3.SSS5.p6.3.m1.1a"><msub id="S2.SS3.SSS5.p6.3.m1.1.1" xref="S2.SS3.SSS5.p6.3.m1.1.1.cmml"><mi id="S2.SS3.SSS5.p6.3.m1.1.1.2" xref="S2.SS3.SSS5.p6.3.m1.1.1.2.cmml">AP</mi><mi id="S2.SS3.SSS5.p6.3.m1.1.1.3" xref="S2.SS3.SSS5.p6.3.m1.1.1.3.cmml">small</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.3.m1.1b"><apply id="S2.SS3.SSS5.p6.3.m1.1.1.cmml" xref="S2.SS3.SSS5.p6.3.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.3.m1.1.1.1.cmml" xref="S2.SS3.SSS5.p6.3.m1.1.1">subscript</csymbol><ci id="S2.SS3.SSS5.p6.3.m1.1.1.2.cmml" xref="S2.SS3.SSS5.p6.3.m1.1.1.2">AP</ci><ci id="S2.SS3.SSS5.p6.3.m1.1.1.3.cmml" xref="S2.SS3.SSS5.p6.3.m1.1.1.3">small</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.3.m1.1c">\mathrm{AP_{small}}</annotation></semantics></math> for objects with area smaller than <math id="S2.SS3.SSS5.p6.4.m2.1" class="ltx_Math" alttext="32^{2}" display="inline"><semantics id="S2.SS3.SSS5.p6.4.m2.1a"><msup id="S2.SS3.SSS5.p6.4.m2.1.1" xref="S2.SS3.SSS5.p6.4.m2.1.1.cmml"><mn id="S2.SS3.SSS5.p6.4.m2.1.1.2" xref="S2.SS3.SSS5.p6.4.m2.1.1.2.cmml">32</mn><mn id="S2.SS3.SSS5.p6.4.m2.1.1.3" xref="S2.SS3.SSS5.p6.4.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.4.m2.1b"><apply id="S2.SS3.SSS5.p6.4.m2.1.1.cmml" xref="S2.SS3.SSS5.p6.4.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.4.m2.1.1.1.cmml" xref="S2.SS3.SSS5.p6.4.m2.1.1">superscript</csymbol><cn type="integer" id="S2.SS3.SSS5.p6.4.m2.1.1.2.cmml" xref="S2.SS3.SSS5.p6.4.m2.1.1.2">32</cn><cn type="integer" id="S2.SS3.SSS5.p6.4.m2.1.1.3.cmml" xref="S2.SS3.SSS5.p6.4.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.4.m2.1c">32^{2}</annotation></semantics></math> pixels, <math id="S2.SS3.SSS5.p6.5.m3.1" class="ltx_Math" alttext="\mathrm{AP_{medium}}" display="inline"><semantics id="S2.SS3.SSS5.p6.5.m3.1a"><msub id="S2.SS3.SSS5.p6.5.m3.1.1" xref="S2.SS3.SSS5.p6.5.m3.1.1.cmml"><mi id="S2.SS3.SSS5.p6.5.m3.1.1.2" xref="S2.SS3.SSS5.p6.5.m3.1.1.2.cmml">AP</mi><mi id="S2.SS3.SSS5.p6.5.m3.1.1.3" xref="S2.SS3.SSS5.p6.5.m3.1.1.3.cmml">medium</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.5.m3.1b"><apply id="S2.SS3.SSS5.p6.5.m3.1.1.cmml" xref="S2.SS3.SSS5.p6.5.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.5.m3.1.1.1.cmml" xref="S2.SS3.SSS5.p6.5.m3.1.1">subscript</csymbol><ci id="S2.SS3.SSS5.p6.5.m3.1.1.2.cmml" xref="S2.SS3.SSS5.p6.5.m3.1.1.2">AP</ci><ci id="S2.SS3.SSS5.p6.5.m3.1.1.3.cmml" xref="S2.SS3.SSS5.p6.5.m3.1.1.3">medium</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.5.m3.1c">\mathrm{AP_{medium}}</annotation></semantics></math> for objects with area between <math id="S2.SS3.SSS5.p6.6.m4.1" class="ltx_Math" alttext="32^{2}" display="inline"><semantics id="S2.SS3.SSS5.p6.6.m4.1a"><msup id="S2.SS3.SSS5.p6.6.m4.1.1" xref="S2.SS3.SSS5.p6.6.m4.1.1.cmml"><mn id="S2.SS3.SSS5.p6.6.m4.1.1.2" xref="S2.SS3.SSS5.p6.6.m4.1.1.2.cmml">32</mn><mn id="S2.SS3.SSS5.p6.6.m4.1.1.3" xref="S2.SS3.SSS5.p6.6.m4.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.6.m4.1b"><apply id="S2.SS3.SSS5.p6.6.m4.1.1.cmml" xref="S2.SS3.SSS5.p6.6.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.6.m4.1.1.1.cmml" xref="S2.SS3.SSS5.p6.6.m4.1.1">superscript</csymbol><cn type="integer" id="S2.SS3.SSS5.p6.6.m4.1.1.2.cmml" xref="S2.SS3.SSS5.p6.6.m4.1.1.2">32</cn><cn type="integer" id="S2.SS3.SSS5.p6.6.m4.1.1.3.cmml" xref="S2.SS3.SSS5.p6.6.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.6.m4.1c">32^{2}</annotation></semantics></math> and <math id="S2.SS3.SSS5.p6.7.m5.1" class="ltx_Math" alttext="69^{2}" display="inline"><semantics id="S2.SS3.SSS5.p6.7.m5.1a"><msup id="S2.SS3.SSS5.p6.7.m5.1.1" xref="S2.SS3.SSS5.p6.7.m5.1.1.cmml"><mn id="S2.SS3.SSS5.p6.7.m5.1.1.2" xref="S2.SS3.SSS5.p6.7.m5.1.1.2.cmml">69</mn><mn id="S2.SS3.SSS5.p6.7.m5.1.1.3" xref="S2.SS3.SSS5.p6.7.m5.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.7.m5.1b"><apply id="S2.SS3.SSS5.p6.7.m5.1.1.cmml" xref="S2.SS3.SSS5.p6.7.m5.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.7.m5.1.1.1.cmml" xref="S2.SS3.SSS5.p6.7.m5.1.1">superscript</csymbol><cn type="integer" id="S2.SS3.SSS5.p6.7.m5.1.1.2.cmml" xref="S2.SS3.SSS5.p6.7.m5.1.1.2">69</cn><cn type="integer" id="S2.SS3.SSS5.p6.7.m5.1.1.3.cmml" xref="S2.SS3.SSS5.p6.7.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.7.m5.1c">69^{2}</annotation></semantics></math> pixels and <math id="S2.SS3.SSS5.p6.8.m6.1" class="ltx_Math" alttext="\mathrm{AP_{large}}" display="inline"><semantics id="S2.SS3.SSS5.p6.8.m6.1a"><msub id="S2.SS3.SSS5.p6.8.m6.1.1" xref="S2.SS3.SSS5.p6.8.m6.1.1.cmml"><mi id="S2.SS3.SSS5.p6.8.m6.1.1.2" xref="S2.SS3.SSS5.p6.8.m6.1.1.2.cmml">AP</mi><mi id="S2.SS3.SSS5.p6.8.m6.1.1.3" xref="S2.SS3.SSS5.p6.8.m6.1.1.3.cmml">large</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.8.m6.1b"><apply id="S2.SS3.SSS5.p6.8.m6.1.1.cmml" xref="S2.SS3.SSS5.p6.8.m6.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.8.m6.1.1.1.cmml" xref="S2.SS3.SSS5.p6.8.m6.1.1">subscript</csymbol><ci id="S2.SS3.SSS5.p6.8.m6.1.1.2.cmml" xref="S2.SS3.SSS5.p6.8.m6.1.1.2">AP</ci><ci id="S2.SS3.SSS5.p6.8.m6.1.1.3.cmml" xref="S2.SS3.SSS5.p6.8.m6.1.1.3">large</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.8.m6.1c">\mathrm{AP_{large}}</annotation></semantics></math> for objects with area greater than <math id="S2.SS3.SSS5.p6.9.m7.1" class="ltx_Math" alttext="69^{2}" display="inline"><semantics id="S2.SS3.SSS5.p6.9.m7.1a"><msup id="S2.SS3.SSS5.p6.9.m7.1.1" xref="S2.SS3.SSS5.p6.9.m7.1.1.cmml"><mn id="S2.SS3.SSS5.p6.9.m7.1.1.2" xref="S2.SS3.SSS5.p6.9.m7.1.1.2.cmml">69</mn><mn id="S2.SS3.SSS5.p6.9.m7.1.1.3" xref="S2.SS3.SSS5.p6.9.m7.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS5.p6.9.m7.1b"><apply id="S2.SS3.SSS5.p6.9.m7.1.1.cmml" xref="S2.SS3.SSS5.p6.9.m7.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS5.p6.9.m7.1.1.1.cmml" xref="S2.SS3.SSS5.p6.9.m7.1.1">superscript</csymbol><cn type="integer" id="S2.SS3.SSS5.p6.9.m7.1.1.2.cmml" xref="S2.SS3.SSS5.p6.9.m7.1.1.2">69</cn><cn type="integer" id="S2.SS3.SSS5.p6.9.m7.1.1.3.cmml" xref="S2.SS3.SSS5.p6.9.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS5.p6.9.m7.1c">69^{2}</annotation></semantics></math> pixels, one can evaluate the model performance on segmenting objects in different scales.</p>
</div>
<div id="S2.SS3.SSS5.p7" class="ltx_para">
<p id="S2.SS3.SSS5.p7.1" class="ltx_p">Finally, given the fundamental motivation to extract particle statistics from image datasets, the performance of the model is further evaluated based on the accuracy of the predicted statistics.. Computation is made based on the segmented masks of each particle. Statistical information obtained from the predictions are then compared to the manually annotated results.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Hyperparameter study in the training procedure</figcaption>
<table id="S2.T1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">No.</th>
<th id="S2.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">No. Epochs</th>
<th id="S2.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Dataset Size</th>
<th id="S2.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Learning Rate</th>
<th id="S2.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">ROI Head</th>
<th id="S2.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">IOU THR</th>
<th id="S2.T1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">NMS</th>
<th id="S2.T1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP BBOX</th>
<th id="S2.T1.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP SEGM</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.1.2.1" class="ltx_tr">
<td id="S2.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S2.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">250</td>
<td id="S2.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">250</td>
<td id="S2.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.02</td>
<td id="S2.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">256</td>
<td id="S2.T1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">0.6</td>
<td id="S2.T1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">0.7</td>
<td id="S2.T1.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t">89.442</td>
<td id="S2.T1.1.2.1.9" class="ltx_td ltx_align_center ltx_border_t">87.392</td>
</tr>
<tr id="S2.T1.1.3.2" class="ltx_tr">
<td id="S2.T1.1.3.2.1" class="ltx_td ltx_align_center">2</td>
<td id="S2.T1.1.3.2.2" class="ltx_td ltx_align_center">250</td>
<td id="S2.T1.1.3.2.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.3.2.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.3.2.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.3.2.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.3.2.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.3.2.8" class="ltx_td ltx_align_center">91.843</td>
<td id="S2.T1.1.3.2.9" class="ltx_td ltx_align_center">88.878</td>
</tr>
<tr id="S2.T1.1.4.3" class="ltx_tr">
<td id="S2.T1.1.4.3.1" class="ltx_td ltx_align_center">3</td>
<td id="S2.T1.1.4.3.2" class="ltx_td ltx_align_center">250</td>
<td id="S2.T1.1.4.3.3" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.4.3.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.4.3.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.4.3.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.4.3.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.4.3.8" class="ltx_td ltx_align_center">92.219</td>
<td id="S2.T1.1.4.3.9" class="ltx_td ltx_align_center">89.568</td>
</tr>
<tr id="S2.T1.1.5.4" class="ltx_tr">
<td id="S2.T1.1.5.4.1" class="ltx_td ltx_align_center">4</td>
<td id="S2.T1.1.5.4.2" class="ltx_td ltx_align_center">250</td>
<td id="S2.T1.1.5.4.3" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T1.1.5.4.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.5.4.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.5.4.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.5.4.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.5.4.8" class="ltx_td ltx_align_center">93.541</td>
<td id="S2.T1.1.5.4.9" class="ltx_td ltx_align_center">90.195</td>
</tr>
<tr id="S2.T1.1.6.5" class="ltx_tr">
<td id="S2.T1.1.6.5.1" class="ltx_td ltx_align_center">5</td>
<td id="S2.T1.1.6.5.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.6.5.3" class="ltx_td ltx_align_center">250</td>
<td id="S2.T1.1.6.5.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.6.5.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.6.5.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.6.5.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.6.5.8" class="ltx_td ltx_align_center">90.949</td>
<td id="S2.T1.1.6.5.9" class="ltx_td ltx_align_center">87.908</td>
</tr>
<tr id="S2.T1.1.7.6" class="ltx_tr">
<td id="S2.T1.1.7.6.1" class="ltx_td ltx_align_center">6</td>
<td id="S2.T1.1.7.6.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.7.6.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.7.6.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.7.6.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.7.6.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.7.6.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.7.6.8" class="ltx_td ltx_align_center">92.831</td>
<td id="S2.T1.1.7.6.9" class="ltx_td ltx_align_center">89.872</td>
</tr>
<tr id="S2.T1.1.8.7" class="ltx_tr">
<td id="S2.T1.1.8.7.1" class="ltx_td ltx_align_center">7</td>
<td id="S2.T1.1.8.7.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.8.7.3" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.8.7.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.8.7.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.8.7.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.8.7.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.8.7.8" class="ltx_td ltx_align_center">93.336</td>
<td id="S2.T1.1.8.7.9" class="ltx_td ltx_align_center">90.034</td>
</tr>
<tr id="S2.T1.1.9.8" class="ltx_tr">
<td id="S2.T1.1.9.8.1" class="ltx_td ltx_align_center">8</td>
<td id="S2.T1.1.9.8.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.9.8.3" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T1.1.9.8.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.9.8.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.9.8.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.9.8.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.9.8.8" class="ltx_td ltx_align_center">93.878</td>
<td id="S2.T1.1.9.8.9" class="ltx_td ltx_align_center">90.254</td>
</tr>
<tr id="S2.T1.1.10.9" class="ltx_tr">
<td id="S2.T1.1.10.9.1" class="ltx_td ltx_align_center">9</td>
<td id="S2.T1.1.10.9.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.10.9.3" class="ltx_td ltx_align_center">250</td>
<td id="S2.T1.1.10.9.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.10.9.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.10.9.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.10.9.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.10.9.8" class="ltx_td ltx_align_center">92.219</td>
<td id="S2.T1.1.10.9.9" class="ltx_td ltx_align_center">89.568</td>
</tr>
<tr id="S2.T1.1.11.10" class="ltx_tr">
<td id="S2.T1.1.11.10.1" class="ltx_td ltx_align_center">10</td>
<td id="S2.T1.1.11.10.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.11.10.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.11.10.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.11.10.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.11.10.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.11.10.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.11.10.8" class="ltx_td ltx_align_center">92.820</td>
<td id="S2.T1.1.11.10.9" class="ltx_td ltx_align_center">90.095</td>
</tr>
<tr id="S2.T1.1.12.11" class="ltx_tr">
<td id="S2.T1.1.12.11.1" class="ltx_td ltx_align_center">11</td>
<td id="S2.T1.1.12.11.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.12.11.3" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.12.11.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.12.11.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.12.11.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.12.11.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.12.11.8" class="ltx_td ltx_align_center">93.454</td>
<td id="S2.T1.1.12.11.9" class="ltx_td ltx_align_center">89.958</td>
</tr>
<tr id="S2.T1.1.13.12" class="ltx_tr">
<td id="S2.T1.1.13.12.1" class="ltx_td ltx_align_center">12</td>
<td id="S2.T1.1.13.12.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.13.12.3" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T1.1.13.12.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.13.12.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.13.12.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.13.12.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.13.12.8" class="ltx_td ltx_align_center">94.002</td>
<td id="S2.T1.1.13.12.9" class="ltx_td ltx_align_center">90.487</td>
</tr>
<tr id="S2.T1.1.14.13" class="ltx_tr">
<td id="S2.T1.1.14.13.1" class="ltx_td ltx_align_center">13</td>
<td id="S2.T1.1.14.13.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.14.13.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.14.13.4" class="ltx_td ltx_align_center">0.01</td>
<td id="S2.T1.1.14.13.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.14.13.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.14.13.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.14.13.8" class="ltx_td ltx_align_center">93.564</td>
<td id="S2.T1.1.14.13.9" class="ltx_td ltx_align_center">89.72</td>
</tr>
<tr id="S2.T1.1.15.14" class="ltx_tr">
<td id="S2.T1.1.15.14.1" class="ltx_td ltx_align_center">14</td>
<td id="S2.T1.1.15.14.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.15.14.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.15.14.4" class="ltx_td ltx_align_center">0.03</td>
<td id="S2.T1.1.15.14.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.15.14.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.15.14.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.15.14.8" class="ltx_td ltx_align_center">93.279</td>
<td id="S2.T1.1.15.14.9" class="ltx_td ltx_align_center">89.87</td>
</tr>
<tr id="S2.T1.1.16.15" class="ltx_tr">
<td id="S2.T1.1.16.15.1" class="ltx_td ltx_align_center">15</td>
<td id="S2.T1.1.16.15.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.16.15.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.16.15.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.16.15.5" class="ltx_td ltx_align_center">128</td>
<td id="S2.T1.1.16.15.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.16.15.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.16.15.8" class="ltx_td ltx_align_center">92.582</td>
<td id="S2.T1.1.16.15.9" class="ltx_td ltx_align_center">89.614</td>
</tr>
<tr id="S2.T1.1.17.16" class="ltx_tr">
<td id="S2.T1.1.17.16.1" class="ltx_td ltx_align_center">16</td>
<td id="S2.T1.1.17.16.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.17.16.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.17.16.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.17.16.5" class="ltx_td ltx_align_center">512</td>
<td id="S2.T1.1.17.16.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.17.16.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.17.16.8" class="ltx_td ltx_align_center">93.513</td>
<td id="S2.T1.1.17.16.9" class="ltx_td ltx_align_center">89.932</td>
</tr>
<tr id="S2.T1.1.18.17" class="ltx_tr">
<td id="S2.T1.1.18.17.1" class="ltx_td ltx_align_center">17</td>
<td id="S2.T1.1.18.17.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.18.17.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.18.17.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.18.17.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.18.17.6" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.18.17.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.18.17.8" class="ltx_td ltx_align_center">93.278</td>
<td id="S2.T1.1.18.17.9" class="ltx_td ltx_align_center">89.945</td>
</tr>
<tr id="S2.T1.1.19.18" class="ltx_tr">
<td id="S2.T1.1.19.18.1" class="ltx_td ltx_align_center">18</td>
<td id="S2.T1.1.19.18.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.19.18.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.19.18.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.19.18.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.19.18.6" class="ltx_td ltx_align_center">0.8</td>
<td id="S2.T1.1.19.18.7" class="ltx_td ltx_align_center">0.7</td>
<td id="S2.T1.1.19.18.8" class="ltx_td ltx_align_center">93.523</td>
<td id="S2.T1.1.19.18.9" class="ltx_td ltx_align_center">90.139</td>
</tr>
<tr id="S2.T1.1.20.19" class="ltx_tr">
<td id="S2.T1.1.20.19.1" class="ltx_td ltx_align_center">19</td>
<td id="S2.T1.1.20.19.2" class="ltx_td ltx_align_center">750</td>
<td id="S2.T1.1.20.19.3" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.1.20.19.4" class="ltx_td ltx_align_center">0.02</td>
<td id="S2.T1.1.20.19.5" class="ltx_td ltx_align_center">256</td>
<td id="S2.T1.1.20.19.6" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.20.19.7" class="ltx_td ltx_align_center">0.6</td>
<td id="S2.T1.1.20.19.8" class="ltx_td ltx_align_center">92.902</td>
<td id="S2.T1.1.20.19.9" class="ltx_td ltx_align_center">89.952</td>
</tr>
<tr id="S2.T1.1.21.20" class="ltx_tr">
<td id="S2.T1.1.21.20.1" class="ltx_td ltx_align_center ltx_border_bb">20</td>
<td id="S2.T1.1.21.20.2" class="ltx_td ltx_align_center ltx_border_bb">750</td>
<td id="S2.T1.1.21.20.3" class="ltx_td ltx_align_center ltx_border_bb">500</td>
<td id="S2.T1.1.21.20.4" class="ltx_td ltx_align_center ltx_border_bb">0.02</td>
<td id="S2.T1.1.21.20.5" class="ltx_td ltx_align_center ltx_border_bb">256</td>
<td id="S2.T1.1.21.20.6" class="ltx_td ltx_align_center ltx_border_bb">0.6</td>
<td id="S2.T1.1.21.20.7" class="ltx_td ltx_align_center ltx_border_bb">0.8</td>
<td id="S2.T1.1.21.20.8" class="ltx_td ltx_align_center ltx_border_bb">93.58</td>
<td id="S2.T1.1.21.20.9" class="ltx_td ltx_align_center ltx_border_bb">89.74</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S2.F6" class="ltx_figure"><img src="/html/2109.04429/assets/x3.png" id="S2.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="131" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Model prediction on V<sub id="S2.F6.7.1" class="ltx_sub">2</sub>O<sub id="S2.F6.8.2" class="ltx_sub">5</sub> nanowires within synthetic image (512x512 pixels) (a) Test image (b) Predicted instance masks with lower opacity plotted on the test images (c) Semantic binary mask, Blue: TP, Red: FN, Green: FP</figcaption>
</figure>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Results and discussions</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, the segmentation results are evaluated considering the aforementioned metrics. It is important to re-emphasize that the deep learning model has been trained solely on synthetic image datasets modeled after the X-ray ptychography and scanning transmission X-ray microscopy data. Consequently, the SEM image, which is distinctive in terms of contrast generation is foreign to the trained model. All images are, obtained from mentioned microscopy techniques as they are, and were not filtered for the evaluation purpose. The only pre-processing step applied to the ptychography and STXM images involves the conversion from transmission data to absorbance (optical density)Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib7" title="" class="ltx_ref">lerotic2014mantis, </a>)</cite>. The results obtained from the deep learning model are compared to manually annotated results, which are subject to uncertainty to certain level due to visual limitation.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Before applying the model to real microscopy images, 20 models were trained with various hyperparameters to examine their influence on the synthetic images, see Tab.Â <a href="#S2.T1" title="Table 1 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Subsequently, all 20 trained models were applied to segment the three types of microscopy image. The best performer in mask segmentation AP for each image type was selected to visualize the segmentation masks in Fig.Â <a href="#S2.F6" title="Figure 6 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>,<a href="#S3.F9" title="Figure 9 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>,<a href="#S3.F11" title="Figure 11 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>(b). We start to evaluate the model segmentation accuracy at a semantic level to estimate to what degree the model can segment the actual nanowires from the background. The inherent strength of instance segmentation is that it includes the subordinate functionality of semantic segmentation, where the semantic results can be immediately extracted from the mask predictions. As shown in Fig.Â <a href="#S2.F6" title="Figure 6 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>,<a href="#S3.F9" title="Figure 9 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>,<a href="#S3.F11" title="Figure 11 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>Â (b), fairly good segmentation results were obtained. These object masks were then used to evaluate semantic segmentation accuracy presented in Fig.Â <a href="#S2.F6" title="Figure 6 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>,<a href="#S3.F9" title="Figure 9 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>,<a href="#S3.F11" title="Figure 11 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>Â (c). The color blue denotes the true positive pixels, to which the model predicts correctly as given in the ground truth provided by human annotation. The green color indicates false positive pixels, which means the model has inaccurately predicted that these pixels belong to a particular nanowire. The red color denotes the false negatives, which depict the pixels that belong to a nanowire (based on the ground truth) but were not identified as such by the model. The performance of the trained model is discussed in more detail in the following sections.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Note that to make the model generally accessible as a segmentation tool of nanorod-like structures, we have further developed a web-based interactive application for readers to access and data-mining their own image datasets. Upon uploading the data and initializing the prediction model, statistics on predicted masks can be obtained and visualized accordingly. Details and access on the web-based interactive application can be found in data and code availability section.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Synthetic nanowire image.</span> As for the synthetic nanowires shown in Fig.Â <a href="#S2.F6" title="Figure 6 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, not surprisingly, the deep learning model correctly segments particles contained within the synthetic nanowire datasets. The obtained AP of the tested 20 models reach a AP score of around 90 for bounding box regression and mask segmentation, respectively, see Tab. <a href="#S2.T1" title="Table 1 â€£ 2.3.5. Evaluation metrics â€£ 2.3. Deep learning procedures â€£ 2. Material and Methods â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. As the synthetic image type is basically known to the model, the good accuracy are expected. Tuning the hyperparameter, dataset would generally result in a better AP in bounding box prediction and segmentation masks, however, not influence the results on synthetic image significantly.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Model performance on X-ray pytchography image (Bounding box/Segmentation mask)</figcaption>
<table id="S3.T2.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.5.5" class="ltx_tr">
<th id="S3.T2.5.5.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">No.</th>
<th id="S3.T2.5.5.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Accuracy</th>
<th id="S3.T2.5.5.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP</th>
<th id="S3.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T2.1.1.1.1" class="ltx_sub"><span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_italic">50</span></sub>
</th>
<th id="S3.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T2.2.2.2.1" class="ltx_sub"><span id="S3.T2.2.2.2.1.1" class="ltx_text ltx_font_italic">75</span></sub>
</th>
<th id="S3.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T2.3.3.3.1" class="ltx_sub"><span id="S3.T2.3.3.3.1.1" class="ltx_text ltx_font_italic">s</span></sub>
</th>
<th id="S3.T2.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T2.4.4.4.1" class="ltx_sub"><span id="S3.T2.4.4.4.1.1" class="ltx_text ltx_font_italic">m</span></sub>
</th>
<th id="S3.T2.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T2.5.5.5.1" class="ltx_sub"><span id="S3.T2.5.5.5.1.1" class="ltx_text ltx_font_italic">l</span></sub>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.5.6.1" class="ltx_tr">
<th id="S3.T2.5.6.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">13</th>
<td id="S3.T2.5.6.1.2" class="ltx_td ltx_align_center ltx_border_t">86.6</td>
<td id="S3.T2.5.6.1.3" class="ltx_td ltx_align_center ltx_border_t">39.145/42.327</td>
<td id="S3.T2.5.6.1.4" class="ltx_td ltx_align_center ltx_border_t">64.638/62.519</td>
<td id="S3.T2.5.6.1.5" class="ltx_td ltx_align_center ltx_border_t">43.965/39.964</td>
<td id="S3.T2.5.6.1.6" class="ltx_td ltx_align_center ltx_border_t">25.248/22.442</td>
<td id="S3.T2.5.6.1.7" class="ltx_td ltx_align_center ltx_border_t">52.753/58.03</td>
<td id="S3.T2.5.6.1.8" class="ltx_td ltx_align_center ltx_border_t">72.525/85.05</td>
</tr>
<tr id="S3.T2.5.7.2" class="ltx_tr">
<th id="S3.T2.5.7.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">17</th>
<td id="S3.T2.5.7.2.2" class="ltx_td ltx_align_center">85.5</td>
<td id="S3.T2.5.7.2.3" class="ltx_td ltx_align_center">41.809/41.719</td>
<td id="S3.T2.5.7.2.4" class="ltx_td ltx_align_center">74.603/67.042</td>
<td id="S3.T2.5.7.2.5" class="ltx_td ltx_align_center">43.25/40.438</td>
<td id="S3.T2.5.7.2.6" class="ltx_td ltx_align_center">28.34/19.785</td>
<td id="S3.T2.5.7.2.7" class="ltx_td ltx_align_center">52.772/52.774</td>
<td id="S3.T2.5.7.2.8" class="ltx_td ltx_align_center">62.624/70.099</td>
</tr>
<tr id="S3.T2.5.8.3" class="ltx_tr">
<th id="S3.T2.5.8.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">14</th>
<td id="S3.T2.5.8.3.2" class="ltx_td ltx_align_center ltx_border_bb">86.2</td>
<td id="S3.T2.5.8.3.3" class="ltx_td ltx_align_center ltx_border_bb">38.584/41.662</td>
<td id="S3.T2.5.8.3.4" class="ltx_td ltx_align_center ltx_border_bb">63.618/62.803</td>
<td id="S3.T2.5.8.3.5" class="ltx_td ltx_align_center ltx_border_bb">42.159/42.159</td>
<td id="S3.T2.5.8.3.6" class="ltx_td ltx_align_center ltx_border_bb">25.248/26.931</td>
<td id="S3.T2.5.8.3.7" class="ltx_td ltx_align_center ltx_border_bb">44.998/50.644</td>
<td id="S3.T2.5.8.3.8" class="ltx_td ltx_align_center ltx_border_bb">75.05/70.099</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">ggests</p>
</div>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2109.04429/assets/x4.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="164" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>Model prediction on V<sub id="S3.F7.7.1" class="ltx_sub">2</sub>O<sub id="S3.F7.8.2" class="ltx_sub">5</sub> nanowires within X-ray pytchography image (531x449 pixels). The best performer in AP segmentation mask in Tab.Â <a href="#S3.T2" title="Table 2 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> is used to visualize the prediction masks in (b)</figcaption>
</figure>
<figure id="S3.F8" class="ltx_figure"><img src="/html/2109.04429/assets/x5.png" id="S3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="132" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>Particle statistics from the X-ray ptychography image are illustrated by the statistical density as a function of area (summation of pixels corresponding to each particle mask), aspect ratio (particle length/width), and orientation (angle relative to the horizontal axis) in (a), (b), and (c), respectively.</figcaption>
</figure>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.5" class="ltx_p"><span id="S3.p6.5.1" class="ltx_text ltx_font_bold">X-ray ptychography image.</span> Although the model has been trained solely by synthetic datasets, good segmentation results are observed from experimental datasets. For X-ray ptychography images, the model predicts the overall binary mask with good accuracy and scores a segmentation score of 86.6, see Tab.Â <a href="#S3.T2" title="Table 2 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The AP, AP<sub id="S3.p6.5.2" class="ltx_sub"><span id="S3.p6.5.2.1" class="ltx_text ltx_font_italic">75</span></sub> for both the bounding box, and the segmentation mask are comparatively high and score around 40, respectively. AP<sub id="S3.p6.5.3" class="ltx_sub"><span id="S3.p6.5.3.1" class="ltx_text ltx_font_italic">50</span></sub> reaches a score of around 62. From the metrics, it is mentionable that AP<sub id="S3.p6.5.4" class="ltx_sub"><span id="S3.p6.5.4.1" class="ltx_text ltx_font_italic">l</span></sub> are greater than AP<sub id="S3.p6.5.5" class="ltx_sub"><span id="S3.p6.5.5.1" class="ltx_text ltx_font_italic">s</span></sub> and AP<sub id="S3.p6.5.6" class="ltx_sub"><span id="S3.p6.5.6.1" class="ltx_text ltx_font_italic">m</span></sub>, indicating that the image contains larger particles and they were segmented to a greater degree than smaller ones. At the instance level, two false-positive nanowires have been identified and are (shown in green) indicated by white arrows in Fig.Â <a href="#S3.F7" title="Figure 7 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>(c); the origin of this false-positive result is low pixel intensity near the threshold that separates particles from background. For the same reason, these particles were not manually annotated but nevertheless were identified by the model thus demonstrating its performance, which is competitive with careful human annotation (while being much more accurate). The two particles shown in red (indicated by yellow arrows) are missed by the model, presumably by the noise in the corresponding region. But overall, considering the optical density input, the individual particles are extracted with good accuracy. In general, the mask predictions consistently perform extremely well when particles are well separated in space while overlapping regions (notoriously more difficult to segment) are still identified with good accuracy.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.2" class="ltx_p">Some issues arise when the optical density gradient is low with less clear transitions in the overlapped region. Some issues arise when the optical density gradient is low with less clear transitions in the overlapped region. Further, the model tends to find smaller particles within larger instances as shown by the cyan arrow. The origin of this limitation stems from the broad range of particle aspect ratios and thicknesses in the experimental data (ca. 50 â€“ 500nm), thus resulting in a less continuous optical density distribution with individual particles. In the training data, particle morphologies were generated assuming a prismatic structure with little-to-no variation in the cross-sectional shape. In contrast, the experimentally synthesized V<sub id="S3.p7.2.1" class="ltx_sub">2</sub>O<sub id="S3.p7.2.2" class="ltx_sub">5</sub> are subject to defect formation, particle sintering, and intrinsic variations in the crystal growth during synthesis. This leads to a particle dispersion that is highly complex, non-prismatic and an ambiguous optical density mapping and further complicates the detection in the overlapped area and create artifacts which would possibly â€foolâ€ trained models. This also introduces additional challenges during synthetic data generation and the segmentation tasks. Nevertheless, this complexity in particle size, shape, and extent of curvature has pronounced effects on the emergent properties of these cathode particles so their correct identification remains importantÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">santos2020bending, </a>; <a href="#bib.bib6" title="" class="ltx_ref">andrews2020curvature, </a>; <a href="#bib.bib20" title="" class="ltx_ref">horrocks2013finite, </a>)</cite>. Here, over-predicted particle masks inside the larger ones can be easily removed in a post-processing step. This step was not performed here to preserve the originality of the model prediction. However, to enhance the general prediction capability of the model and avoid post-processing procedures, the generation of non-prismatic structures for training datasets can be instrumental and will remain as future work.</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p">Lastly, statistical information on particle area size, aspect ratio and orientation are compared in Fig.<a href="#S3.F8" title="Figure 8 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> in form of histogram with kernel density estimation. The area size is determined by summation of the pixels belonging to different particle masks. The aspect ratio is calculated as the ratio between image coordinates of the longer edge to the shorter edge of the corresponding predicted mask. The orientation is considered as the angle between the particle alignment to the horizontal axis and ranging from 0 to 180 degree. As can be found in Fig.<a href="#S3.F8" title="Figure 8 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the statistical information from the X-ray ptychography data is in a qualitatively good agreement. The main discrepancy is contributed by the number of additionally detected smaller particles inside the larger particles and as explained previously, leading to a higher density of the histogram for area size of 2000-4000 pixels and aspect ratio 2-4. This perturbation can be also observed for orientation for particles with 75 to 100 degree and 150 to 175 degrees. As the number of particles in the image is comparatively small, the feature distribution is becomes sensitive to the number of detected particles.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Model performance on STXM image (Bounding box/Segmentation mask)</figcaption>
<table id="S3.T3.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.5.5" class="ltx_tr">
<th id="S3.T3.5.5.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">No.</th>
<th id="S3.T3.5.5.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Accuracy</th>
<th id="S3.T3.5.5.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP</th>
<th id="S3.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T3.1.1.1.1" class="ltx_sub"><span id="S3.T3.1.1.1.1.1" class="ltx_text ltx_font_italic">50</span></sub>
</th>
<th id="S3.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T3.2.2.2.1" class="ltx_sub"><span id="S3.T3.2.2.2.1.1" class="ltx_text ltx_font_italic">75</span></sub>
</th>
<th id="S3.T3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T3.3.3.3.1" class="ltx_sub"><span id="S3.T3.3.3.3.1.1" class="ltx_text ltx_font_italic">s</span></sub>
</th>
<th id="S3.T3.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T3.4.4.4.1" class="ltx_sub"><span id="S3.T3.4.4.4.1.1" class="ltx_text ltx_font_italic">m</span></sub>
</th>
<th id="S3.T3.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T3.5.5.5.1" class="ltx_sub"><span id="S3.T3.5.5.5.1.1" class="ltx_text ltx_font_italic">l</span></sub>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.5.6.1" class="ltx_tr">
<th id="S3.T3.5.6.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="S3.T3.5.6.1.2" class="ltx_td ltx_align_center ltx_border_t">75.6</td>
<td id="S3.T3.5.6.1.3" class="ltx_td ltx_align_center ltx_border_t">27.267/21.791</td>
<td id="S3.T3.5.6.1.4" class="ltx_td ltx_align_center ltx_border_t">54.404/51.877</td>
<td id="S3.T3.5.6.1.5" class="ltx_td ltx_align_center ltx_border_t">23.423/17.587</td>
<td id="S3.T3.5.6.1.6" class="ltx_td ltx_align_center ltx_border_t">25.228/20.862</td>
<td id="S3.T3.5.6.1.7" class="ltx_td ltx_align_center ltx_border_t">37.744/28.877</td>
<td id="S3.T3.5.6.1.8" class="ltx_td ltx_align_center ltx_border_t">NaN</td>
</tr>
<tr id="S3.T3.5.7.2" class="ltx_tr">
<th id="S3.T3.5.7.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">3</th>
<td id="S3.T3.5.7.2.2" class="ltx_td ltx_align_center">73.1</td>
<td id="S3.T3.5.7.2.3" class="ltx_td ltx_align_center">30.51/21.36</td>
<td id="S3.T3.5.7.2.4" class="ltx_td ltx_align_center">53.577/52.172</td>
<td id="S3.T3.5.7.2.5" class="ltx_td ltx_align_center">29.092/15.618</td>
<td id="S3.T3.5.7.2.6" class="ltx_td ltx_align_center">24.447/17.329</td>
<td id="S3.T3.5.7.2.7" class="ltx_td ltx_align_center">48.116/32.782</td>
<td id="S3.T3.5.7.2.8" class="ltx_td ltx_align_center">NaN</td>
</tr>
<tr id="S3.T3.5.8.3" class="ltx_tr">
<th id="S3.T3.5.8.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">9</th>
<td id="S3.T3.5.8.3.2" class="ltx_td ltx_align_center ltx_border_bb">75.3</td>
<td id="S3.T3.5.8.3.3" class="ltx_td ltx_align_center ltx_border_bb">28.293/21.049</td>
<td id="S3.T3.5.8.3.4" class="ltx_td ltx_align_center ltx_border_bb">51.763/48.671</td>
<td id="S3.T3.5.8.3.5" class="ltx_td ltx_align_center ltx_border_bb">27.977/17.437</td>
<td id="S3.T3.5.8.3.6" class="ltx_td ltx_align_center ltx_border_bb">20.581/16.013</td>
<td id="S3.T3.5.8.3.7" class="ltx_td ltx_align_center ltx_border_bb">49.245/34.714</td>
<td id="S3.T3.5.8.3.8" class="ltx_td ltx_align_center ltx_border_bb">NaN</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.F9" class="ltx_figure"><img src="/html/2109.04429/assets/x6.png" id="S3.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="166" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span>Model prediction on V<sub id="S3.F9.7.1" class="ltx_sub">2</sub>O<sub id="S3.F9.8.2" class="ltx_sub">5</sub> nanowires images by STXM (531x449 pixels - rescaled). The best performer in AP segmentation mask Tab.Â <a href="#S3.T3" title="Table 3 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> is used to visualize the prediction masks in (b)</figcaption>
</figure>
<figure id="S3.F10" class="ltx_figure"><img src="/html/2109.04429/assets/x7.png" id="S3.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="132" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10. </span>Statistical distribution of features in the STXM image</figcaption>
</figure>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.1" class="ltx_p"><span id="S3.p9.1.1" class="ltx_text ltx_font_bold">STXM image.</span> Of the two X-ray microscopy techniques considered in this work, X-ray ptychography offers the greatest spatial resolution (ca. 6 nm), thus, from a purely image segmentation perspective we expect the performance of the model to be greatest for this class of images. Nevertheless, techniques such as scanning transmission X-ray microscopy which offer slightly lower spatial resolution (ca. 25 nm) but enabled more detailed mapping of spectral features (i.e. have richer chemical information) are equally important for cheminformatics. In this work, the original resolution of the STXM image was 100x100 pixels and fewer than in the X-ray pytchography image. To enable sharper manual annotation, we rescaled the STXM image to the size of pytchography image for easier visual access (it is important to note that this does not fundamentally change the resolution enabled by the experimentation). The number of particles, their variations in morphology, and the complexity of their dispersion is noticeably greater than the X-ray ptychography image making the segmentation task considerably more challenging. Nevertheless, the segmentation accuracy scores around 75 and the AP score is ca. 21. Since there exist relatively no larger particles in the image, AP<sub id="S3.p9.1.2" class="ltx_sub"><span id="S3.p9.1.2.1" class="ltx_text ltx_font_italic">l</span></sub> was not provided. The comparably lower but surprisingly good scores highlight the complexity of segmenting complex particle dispersions with several instances over overlap and agglomeration This is especially noticeable for the false positive green particles in
Fig.Â <a href="#S3.F9" title="Figure 9 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>(c), w) which were generally overlooked in the manual annotation process. The access of human annotation is strictly limited for image of such complexity. However, at the instance level, from a visual perspective, the model performs considerably well. Overlapped particles are consistently identified and agglomerations, while difficult to identify visually, are captured by the deep learning model. The statistical distribution of the features in Fig.Â <a href="#S3.F10" title="Figure 10 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> agree well both to a qualitative and quantitative extent. The shape of kernel density estimation agrees well with the manual ground truth distribution. As the model prediction captured smaller particles, which were not manually labelled (further demonstrating the performance of the model), the statistics of the prediction are shown to have a higher density distribution in each feature characteristic, observable as small peak shift of the KDE curve. The results suggest that for complicated particle networks contained in a relatively low-resolutioned and low-contrast image, deep learning models indeed deliver more comprehensive information on the statistical information than human annotations.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span>Model performance on SEM image (Bounding box/Segmentation mask)</figcaption>
<table id="S3.T4.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.5.5" class="ltx_tr">
<th id="S3.T4.5.5.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">No.</th>
<th id="S3.T4.5.5.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Accuracy</th>
<th id="S3.T4.5.5.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP</th>
<th id="S3.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T4.1.1.1.1" class="ltx_sub"><span id="S3.T4.1.1.1.1.1" class="ltx_text ltx_font_italic">50</span></sub>
</th>
<th id="S3.T4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T4.2.2.2.1" class="ltx_sub"><span id="S3.T4.2.2.2.1.1" class="ltx_text ltx_font_italic">75</span></sub>
</th>
<th id="S3.T4.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T4.3.3.3.1" class="ltx_sub"><span id="S3.T4.3.3.3.1.1" class="ltx_text ltx_font_italic">s</span></sub>
</th>
<th id="S3.T4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T4.4.4.4.1" class="ltx_sub"><span id="S3.T4.4.4.4.1.1" class="ltx_text ltx_font_italic">m</span></sub>
</th>
<th id="S3.T4.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP<sub id="S3.T4.5.5.5.1" class="ltx_sub"><span id="S3.T4.5.5.5.1.1" class="ltx_text ltx_font_italic">l</span></sub>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.5.6.1" class="ltx_tr">
<th id="S3.T4.5.6.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="S3.T4.5.6.1.2" class="ltx_td ltx_align_center ltx_border_t">59.6</td>
<td id="S3.T4.5.6.1.3" class="ltx_td ltx_align_center ltx_border_t">27.61/12.927</td>
<td id="S3.T4.5.6.1.4" class="ltx_td ltx_align_center ltx_border_t">51.8/23.126</td>
<td id="S3.T4.5.6.1.5" class="ltx_td ltx_align_center ltx_border_t">22.884/5.206</td>
<td id="S3.T4.5.6.1.6" class="ltx_td ltx_align_center ltx_border_t">20.586/7.842</td>
<td id="S3.T4.5.6.1.7" class="ltx_td ltx_align_center ltx_border_t">43.495/22.443</td>
<td id="S3.T4.5.6.1.8" class="ltx_td ltx_align_center ltx_border_t">38.356/36.634</td>
</tr>
<tr id="S3.T4.5.7.2" class="ltx_tr">
<th id="S3.T4.5.7.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">5</th>
<td id="S3.T4.5.7.2.2" class="ltx_td ltx_align_center">61.7</td>
<td id="S3.T4.5.7.2.3" class="ltx_td ltx_align_center">27.916/12.688</td>
<td id="S3.T4.5.7.2.4" class="ltx_td ltx_align_center">54.302/37.916</td>
<td id="S3.T4.5.7.2.5" class="ltx_td ltx_align_center">21.149/5.643</td>
<td id="S3.T4.5.7.2.6" class="ltx_td ltx_align_center">22.776/8.337</td>
<td id="S3.T4.5.7.2.7" class="ltx_td ltx_align_center">43.195/21.884</td>
<td id="S3.T4.5.7.2.8" class="ltx_td ltx_align_center">16.311/25.743</td>
</tr>
<tr id="S3.T4.5.8.3" class="ltx_tr">
<th id="S3.T4.5.8.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">13</th>
<td id="S3.T4.5.8.3.2" class="ltx_td ltx_align_center ltx_border_bb">33.2</td>
<td id="S3.T4.5.8.3.3" class="ltx_td ltx_align_center ltx_border_bb">21.561/12.659</td>
<td id="S3.T4.5.8.3.4" class="ltx_td ltx_align_center ltx_border_bb">47.924/35.553</td>
<td id="S3.T4.5.8.3.5" class="ltx_td ltx_align_center ltx_border_bb">15.718/5.088</td>
<td id="S3.T4.5.8.3.6" class="ltx_td ltx_align_center ltx_border_bb">14.011/8.089</td>
<td id="S3.T4.5.8.3.7" class="ltx_td ltx_align_center ltx_border_bb">44.587/23.695</td>
<td id="S3.T4.5.8.3.8" class="ltx_td ltx_align_center ltx_border_bb">15.317/12.871</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.1" class="ltx_p"><span id="S3.p10.1.1" class="ltx_text ltx_font_bold">SEM image.</span> The deep learning model shows success in segmenting the particles shown in the ptychography and STXM optical density images, in part, due to the mechanisms of contrast generation, which involves the transmission of an incident X-ray source through the bulk of the material. Here, the degree of transmission is related to the energy-specific elemental absorption cross-section, corresponding to excitation of electrons from core levels to unoccupied or partially occupied states, giving rise to similar absorption contrast for compositionally homogeneous particles and allowing the discernment of overlapped intersections (in the form of increased optical density due to thickness effects). As a point of comparison, in scanning electron microscopy, the detection of secondary electrons or backscattered electrons from the surface is sensitive to surface morphology, edge effects, and charge build-up and is fundamentally different from the X-ray ptychography and STXM images shown in previous sections. To demonstrate the versatility of the model, we introduce a scanning electron micrograph for the purposed of segmentation. Despite the fundamental differences in contrast generation between the data used to train the model and the SEM data utilized as an input here, the model performs surprisingly well and is still able to identify overlapping regions despite the absence of optical density information. Here, the deep learning model captures the contrast gradients at the particle boundaries and utilizes it as a criterion to identify individual fibers in the overlapped regions, independent of background. Much like the previous datasets, agglomerations cannot be well separated as shown by the cyan arrow in Fig.Â <a href="#S3.F11" title="Figure 11 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>(b). In addition to unidentified nanowires (indicated by yellow arrows), some issue exists in the right region of the image, where larger masks (green, false-positive pixels, indicated by white arrows) were predicted for individual fibers, presumably due to the perspective of the taken image, causing different contrast in the image. To improve the observed inconsistency, an additional class for agglomerated phase can be introduced and generated in the microstructure generation step, to further differentiate between different foreground phases and, subsequently, nanowires instances. Despite the lower AP score around 13, the statistical results seem to be less sensitive in the presence of more significant particle numbers. The main deviation lies in the number of undetected isolated particles of
smaller size and therefore leading to an underestimation of statistical density w.r.t area size up to 1000 pixels, aspect ratio from 2.5 to 7.5, and orientation from 100 - 150 degrees, as shown in Fig.Â <a href="#S3.F12" title="Figure 12 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> (a-c).</p>
</div>
<figure id="S3.F11" class="ltx_figure"><img src="/html/2109.04429/assets/x8.png" id="S3.F11.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="369" height="831" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11. </span>Model prediction on V<sub id="S3.F11.7.1" class="ltx_sub">2</sub>O<sub id="S3.F11.8.2" class="ltx_sub">5</sub> nanowires within SEM image (957x1280 pixels). The best performer in AP segmentation mask in Tab.Â <a href="#S3.T4" title="Table 4 â€£ 3. Results and discussions â€£ A deep learned nanowire segmentation model using synthetic data augmentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> is used to visualize the prediction masks in (b).</figcaption>
</figure>
<figure id="S3.F12" class="ltx_figure"><img src="/html/2109.04429/assets/x9.png" id="S3.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="132" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12. </span>Statistical distribution of features in the SEM image</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Conclusion and outlook</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Advancements in chemical imaging have enabled improvements in image collection speed, signal-to-noise, and computational power enabling the stronger connections between structure-function relationships and emergent properties. In this work, we have developed a deep learning model for instance segmentation which has been trained solely by synthetic datasets emulated after experimental microscopy data. A benchmarked assessment of the Mask R-CNN algorithm assesses the prediction accuracy of the model on experimental datasets collected by X-ray ptychography, scanning transmission X-ray microscopy, and scanning electron microscopy. Despite variations in spatial resolution, particle dispersion densities, and contrast generation, the model scores well across all the considered microscopy data thus demonstrating the versatility of the neural network in the segmentation tasks. The introduction of optical density values in the synthetic datasets utilized to train the model enables accurate predictions and individual segmentation instances for overlapping particles - a challenge which is strongly relevant to particle dispersions but has seen limited advancement due to inherent complexities. A web-based, and interactive segmentation tool based on the model developed in this work has been made publicly available at <a target="_blank" href="https://share.streamlit.io/linbinbin92/V2O5_app/V2O5_app.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://share.streamlit.io/linbinbin92/V2O5_app/V2O5_app.py</a>. Future work will focus on the introduction of noise to replicate light perturbations, angle dependencies, and variable background characteristics in order to improve the models robustness to real-life datasets. We will further seek to implement the developed methods in real-time process control settings during nanowire growth and battery operation.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Data and code availability</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The code and dataset developed in this work can be found in <a target="_blank" href="https://github.com/linbinbin92/V2O5_app/tree/master" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/linbinbin92/V2O5_app/tree/master</a>. The interactive web-based segmentation application can be found: <a target="_blank" href="https://share.streamlit.io/linbinbin92/V2O5_app/V2O5_app.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://share.streamlit.io/linbinbin92/V2O5_app/V2O5_app.py</a></p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Acknowledgments</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work was supported by German Research Foundation (DFG) B. Lin, B-X. Xu acknowledge the financial support under the grant agreement No. 405422877 of the Paper Research project (FiPRe) and National high performance computing center for computational sci- ences(NHR4CES). We acknowledge Abhishek Parija and Dr. David Schapiro for their assistance with X-ray ptychography experiments. The authors also greatly appreciate their access to the Lichtenberg High Performance Computer and the technical supports from the HHLR, Technical university Darmstadt. X-ray ptychography measurements were performed at the COherent Scattering and MICroscopy (COSMIC) branch of the Advanced Light Source (ALS). A portion of the STXM measurements utilized in this work was collected at the Canadian Light Source, which is supported by the Natural Sciences and Engineering Research Council of Canada, the National Research Council Canada, the Canadian Institutes of Health Research, the Province of Saskatchewan, Western Economic Diversification Canada, and the University of Saskatchewan. The research at Texas A&amp;M University was supported by the NSF under DMR 1627197. D.A.S. acknowledges support under a NSF Graduate Research Fellowship under grant No. 1746932.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Author contribution</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">B.L. conceived the research. B.L and N.E performed the dataset generation and model training and the formal analysis. D.A.S was involved in the conceptualization of the project. Y.L prepared the particles shown in the images. B.L, N.E, D.A.S drafted the manuscript. B.X.X and S.B reviewed and discussed the results and organized the funding.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
L.Â A. Baker, â€œPerspective and prospectus on single-entity electrochemistry,â€
<span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Journal of the American Chemical Society</span>, vol.Â 140, no.Â 46,
pp.Â 15549â€“15559, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
W.Â Li, D.Â M. Lutz, L.Â Wang, K.Â J. Takeuchi, A.Â C. Marschilok, and E.Â S.
Takeuchi, â€œPeering into batteries: electrochemical insight through in situ
and operando methods over multiple length scales,â€ <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Joule</span>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
M.Â Wolf, B.Â M. May, and J.Â Cabana, â€œVisualization of electrochemical reactions
in battery materials with x-ray microscopy and mapping,â€ <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Chemistry of
Materials</span>, vol.Â 29, no.Â 8, pp.Â 3347â€“3362, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
Y.-S. Yu, M.Â Farmand, C.Â Kim, Y.Â Liu, C.Â P. Grey, F.Â C. Strobridge,
T.Â Tyliszczak, R.Â Celestre, P.Â Denes, J.Â Joseph, <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>,
â€œThree-dimensional localization of nanoscale battery reactions using soft
x-ray tomography,â€ <span id="bib.bib4.2.2" class="ltx_text ltx_font_italic">Nature communications</span>, vol.Â 9, no.Â 1, pp.Â 1â€“7,
2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
D.Â A. Santos, J.Â L. Andrews, Y.Â Bai, P.Â Stein, Y.Â Luo, Y.Â Zhang, M.Â Pharr,
B.-X. Xu, and S.Â Banerjee, â€œBending good beats breaking bad: phase
separation patterns in individual cathode particles upon lithiation and
delithiation,â€ <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Materials Horizons</span>, vol.Â 7, no.Â 12, pp.Â 3275â€“3290,
2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
J.Â L. Andrews, P.Â Stein, D.Â A. Santos, C.Â J. Chalker, L.Â R. DeÂ Jesus, R.Â D.
Davidson, M.Â A. Gross, M.Â Pharr, J.Â D. Batteas, B.-X. Xu, <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>,
â€œCurvature-induced modification of mechano-electrochemical coupling and
nucleation kinetics in a cathode material,â€ <span id="bib.bib6.2.2" class="ltx_text ltx_font_italic">Matter</span>, vol.Â 3, no.Â 5,
pp.Â 1754â€“1773, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
M.Â Lerotic, R.Â Mak, S.Â Wirick, F.Â Meirer, and C.Â Jacobsen, â€œMantis: a program
for the analysis of x-ray spectromicroscopy data,â€ <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Journal of
synchrotron radiation</span>, vol.Â 21, no.Â 5, pp.Â 1206â€“1212, 2014.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
Y.Â LeCun, Y.Â Bengio, and G.Â Hinton, â€œDeep learning,â€ <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">nature</span>, vol.Â 521,
no.Â 7553, pp.Â 436â€“444, 2015.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
K.Â He, X.Â Zhang, S.Â Ren, and J.Â Sun, â€œDeep residual learning for image
recognition,â€ in <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision
and pattern recognition</span>, pp.Â 770â€“778, 2016.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
K.Â He, G.Â Gkioxari, P.Â DollÃ¡r, and R.Â Girshick, â€œMask r-cnn,â€ in <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE international conference on computer vision</span>,
pp.Â 2961â€“2969, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(11)</span>
<span class="ltx_bibblock">
T.-Y. Lin, M.Â Maire, S.Â Belongie, J.Â Hays, P.Â Perona, D.Â Ramanan,
P.Â DollÃ¡r, and C.Â L. Zitnick, â€œMicrosoft coco: Common objects in
context,â€ in <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">European conference on computer vision</span>, pp.Â 740â€“755,
Springer, 2014.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(12)</span>
<span class="ltx_bibblock">
M.Â Everingham, L.Â VanÂ Gool, C.Â K.Â I. Williams, J.Â Winn, and A.Â Zisserman, â€œThe
PASCAL Visual Object Classes Challenge 2010 (VOC2010)
Results.â€
http://www.pascal-network.org/challenges/VOC/voc2010/workshop/index.html.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(13)</span>
<span class="ltx_bibblock">
S.Â Masubuchi, E.Â Watanabe, Y.Â Seo, S.Â Okazaki, T.Â Sasagawa, K.Â Watanabe,
T.Â Taniguchi, and T.Â Machida, â€œDeep-learning-based image segmentation
integrated with optical microscopy for automatically searching for
two-dimensional materials,â€ <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">npj 2D Materials and Applications</span>, vol.Â 4,
no.Â 1, pp.Â 1â€“9, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(14)</span>
<span class="ltx_bibblock">
M.Â Frei and F.Â E. Kruis, â€œFiber-cnn: Expanding mask r-cnn to improve
image-based fiber analysis,â€ <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Powder Technology</span>, vol.Â 377,
pp.Â 974â€“991, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(15)</span>
<span class="ltx_bibblock">
B.Â Yildirim and J.Â M. Cole, â€œBayesian particle instance segmentation for
electron microscopy image quantification,â€ <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Journal of Chemical
Information and Modeling</span>, vol.Â 61, no.Â 3, pp.Â 1136â€“1149, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
B.Â Ma, X.Â Wei, C.Â Liu, X.Â Ban, H.Â Huang, H.Â Wang, W.Â Xue, S.Â Wu, M.Â Gao,
Q.Â Shen, <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œData augmentation in microscopic images for material
data mining,â€ <span id="bib.bib16.2.2" class="ltx_text ltx_font_italic">npj Computational Materials</span>, vol.Â 6, no.Â 1, pp.Â 1â€“9,
2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(17)</span>
<span class="ltx_bibblock">
B.Â L. DeCost and E.Â A. Holm, â€œCharacterizing powder materials using
keypoint-based computer vision methods,â€ <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Computational Materials
Science</span>, vol.Â 126, pp.Â 438â€“445, 2017.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
L.Â Mill, D.Â Wolff, N.Â Gerrits, P.Â Philipp, L.Â Kling, F.Â Vollnhals,
A.Â Ignatenko, C.Â Jaremenko, Y.Â Huang, O.Â DeÂ Castro, <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">etÂ al.</span>, â€œSynthetic
image rendering solves annotation problem in deep learning nanoparticle
segmentation,â€ <span id="bib.bib18.2.2" class="ltx_text ltx_font_italic">Small Methods</span>, p.Â 2100223, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(19)</span>
<span class="ltx_bibblock">
B.Â RÃ¼hle, J.Â F. Krumrey, and V.-D. Hodoroaba, â€œWorkflow towards automated
segmentation of agglomerated, non-spherical particles from electron
microscopy images using artificial neural networks,â€ <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Scientific
reports</span>, vol.Â 11, no.Â 1, pp.Â 1â€“10, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
G.Â A. Horrocks, M.Â F. Likely, J.Â M. Velazquez, and S.Â Banerjee, â€œFinite size
effects on the structural progression induced by lithiation of v 2 o 5: a
combined diffraction and raman spectroscopy study,â€ <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Journal of
Materials Chemistry A</span>, vol.Â 1, no.Â 48, pp.Â 15265â€“15277, 2013.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
J.Â L. Andrews, A.Â Mukherjee, H.Â D. Yoo, A.Â Parija, P.Â M. Marley, S.Â Fakra,
D.Â Prendergast, J.Â Cabana, R.Â F. Klie, and S.Â Banerjee, â€œReversible mg-ion
insertion in a metastable one-dimensional polymorph of v2o5,â€ <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Chem</span>,
vol.Â 4, no.Â 3, pp.Â 564â€“585, 2018.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(22)</span>
<span class="ltx_bibblock">
P.Â Skalski, â€œhttps://www.makesense.ai/,â€ 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(23)</span>
<span class="ltx_bibblock">
Y.Â Wu, A.Â Kirillov, F.Â Massa, W.-Y. Lo, and R.Â Girshick, â€œDetectron2.â€
<a target="_blank" href="https://github.com/facebookresearch/detectron2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebookresearch/detectron2</a>, 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2109.04428" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2109.04429" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2109.04429">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2109.04429" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2109.04430" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 03:47:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
