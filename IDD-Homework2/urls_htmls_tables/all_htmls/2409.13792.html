<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.13792] Continual Learning for Multimodal Data Fusion of a Soft Gripper</title><meta property="og:description" content="Continual learning (CL) refers to the ability of an algorithm to continuously and incrementally acquire new knowledge from its environment while retaining previously learned information. A model trained on one data mod…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Continual Learning for Multimodal Data Fusion of a Soft Gripper">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Continual Learning for Multimodal Data Fusion of a Soft Gripper">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.13792">

<!--Generated on Sun Oct  6 01:56:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\credit</span>
<p id="p1.2" class="ltx_p">Conceptualization of this study, Methodology, Software</p>
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p">[orcid=0000-0003-2416-9794]
<span id="p2.1.1" class="ltx_ERROR undefined">\cormark</span>[1]
[orcid=0000-0001-8060-8080]
1]organization=The BioRobotics Institute, Scuola Superiore Sant’Anna,
city=Pontedera,
country=Italy</p>
</div>
<div id="p3" class="ltx_para">
<p id="p3.1" class="ltx_p">2]organization=Department of
Excellence in Robotics and AI, Scuola Superiore Sant’Anna,
city=Pisa,
country=Italy
<span id="p3.1.1" class="ltx_ERROR undefined">\cortext</span>[cor1]Corresponding author</p>
</div>
<h1 class="ltx_title ltx_title_document">Continual Learning for Multimodal Data Fusion of a Soft Gripper</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nilay Kushawaha
</span><span class="ltx_author_notes">nilay.kushawaha@santannapisa.it</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Egidio Falotico
</span><span class="ltx_author_notes">egidio.falotico@santannapisa.it
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Continual learning (CL) refers to the ability of an algorithm to continuously and incrementally acquire new knowledge from its environment while retaining previously learned information. A model trained on one data modality often fails when tested with a different modality. A straightforward approach might be to fuse the two modalities by concatenating their features and training the model on the fused data. However, this requires retraining the model from scratch each time it encounters a new domain. In this paper, we introduce a continual learning algorithm capable of incrementally learning different data modalities by leveraging both class-incremental and domain-incremental learning scenarios in an artificial environment where labeled data is scarce, yet non-iid (independent and identical distribution) unlabeled data from the environment is plentiful. The proposed algorithm is efficient and only requires storing prototypes for each class. We evaluate the algorithm’s effectiveness on a challenging custom multimodal dataset comprising of tactile data from a soft pneumatic gripper, and visual data from non-stationary images of objects extracted from video sequences. Additionally, we conduct an ablation study on the custom dataset and the Core50 dataset to highlight the contributions of different components of the algorithm. To further demonstrate the robustness of the algorithm, we perform a real-time experiment for object classification using the soft gripper and an external independent camera setup, all synchronized with the Robot Operating System (ROS) framework.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Continual Learning <span id="id2.id1" class="ltx_ERROR undefined">\sep</span>Semi-supervised learning <span id="id3.id2" class="ltx_ERROR undefined">\sep</span>Multimodality <span id="id4.id3" class="ltx_ERROR undefined">\sep</span>Robot operating system <span id="id5.id4" class="ltx_ERROR undefined">\sep</span>Class prototypes

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent years, machine learning models have matched or even exceeded human-level performance on tasks such as image classification <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib1" title="" class="ltx_ref">Ahmad et al.</a></cite>, object recognition <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib2" title="" class="ltx_ref">Zou et al.</a></cite>, natural language processing (NLP) <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib3" title="" class="ltx_ref">Otter et al.</a></cite>, playing games in simulation, etc. While these models excel in static tasks where the data distribution remains constant, they encounter difficulties in adapting to changing environments and need to restart the training process whenever new data is introduced. On the other hand, humans are adept at learning from dynamic environments, continuously acquiring, updating, and applying knowledge over time. We expect AI systems to adapt in a similar fashion.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Continual learning (CL) <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib4" title="" class="ltx_ref">Wang et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib5" title="" class="ltx_ref">Lesort et al.</a></cite>, also known as lifelong learning or incremental learning, is a machine learning subfield that focuses on progressively training models on a continuous stream of data to accumulate and retain knowledge over time. However, a significant obstacle for these artificial models is their tendency to forget previously acquired skills when exposed to new tasks or data distributions. This issue, known as catastrophic forgetting, often leads to a substantial drop in performance as the new information overwrites the old knowledge or alters the data distribution. A naive solution to this problem is to save all data, shuffle it, and retrain the model offline from scratch. While this method effectively addresses catastrophic forgetting, it is time-inefficient, suboptimal, and unsustainable for modern large-scale models that require significant computational power. Continual learning aims to develop methods that balance performance and efficiency more effectively. Robots operating in unstructured real world environments will encounter new tasks and challenges over time, necessitating capabilities that cannot be fully anticipated from the outset. These robots need to learn continually, acquiring new skills without forgetting previously learned ones.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">A model trained in one domain will be ineffective when deployed in a completely different domain or used with a different data modality than it was originally trained on. One straightforward approach might be to use separate models for each data modality or to jointly train a single model on all modalities offline. However, this is not a feasible solution for agents with limited memory and computational resources that learns new domains through active exploration and interaction with its environment. Another challenge is the limited availability of labeled data for supervised incremental training.
A large research effort is dedicated towards learning from unlabeled data, which is often more readily available than labeled data in practical applications. Within this effort, the field of semi-supervised learning (SSL) <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib6" title="" class="ltx_ref">Van Engelen and Hoos</a></cite> has recently demonstrated the most promising results. In this setting, an agent can utilize a significant amount of unlabeled data from its environment. It can employ the knowledge gained from labeled data to learn new objects of the same class or to enrich its understanding of previously learned classes using the unlabeled data.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we consider a realistic continual learning problem where a single continual learning model learns different modalities of data incrementally by leveraging both class-incremental and domain-incremental learning scenarios in an artificial environment where labeled data is scarce yet non-iid (independent and identical distribution) unlabeled data from the environment is plentiful. We mainly experiment with two different SSL conditions: <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">Radom images</span>, where for each object of the same parent class we randomly sample some images from the dataset that are not included in the training data; <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">Unique objects</span>, where we sample the images of new unseen objects that belong to the same parent class. More details about the SSL conditions is provided in section <a href="#S3.SS3" title="3.3 Evaluation Metrics ‣ 3 Experimental Setup ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To perform a multimodal CL experiment, we leverage two different modalities of data mainly the tactile data coming from sensors integrated with a soft gripper and the visual data from an independent camera setup. The CL model is designed to learn the classes in both the domains incrementally. To address this issue of multimodal CL, we build on the feature covariance-aware metric (FeCAM) algorithm by <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib7" title="" class="ltx_ref">Goswami et al.</a></cite> and propose an extended version of the algorithm that employs an incremental online semi-supervised learning process for each task. We call it exFeCAM or extended FeCAM algorithm. Additionally, our algorithm includes an intra-layer feature representation mechanism to learn more generalized feature maps for each class. To the best of our knowledge, we are the first to use a continual learning model in a multimodal data setting where an agent learns both tactile data and vision data provided by respective sensors. The main contributions of this article are summarized as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We present an online non-exemplar continual learning algorithm with SSL capabilities. In addition, to enhance the feature maps from the pre-trained layers, we introduce intra-layer feature representations.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We present a new multimodal non-iid dataset for real world continual learning applications.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We demonstrate the robustness of learning different modalities as a new incremental domain rather than just combining the data from different modalities into a single fused feature vector.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We evaluate our algorithm on the custom multimodal dataset as well as the Core50 dataset <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib8" title="" class="ltx_ref">Lomonaco and Maltoni</a></cite> and perform an ablation study to verify the effectiveness of the various parts of the algorithm.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">We also perform a real-time experiment for object classification on the soft pneumatic gripper equipped with sensors and a separate camera setup, all synchronised using the ROS framework <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib9" title="" class="ltx_ref">Koubaa et al.</a></cite>. More details about the experiment is provided in section <a href="#S6" title="6 Real-Time Evaluation With ROS ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</li>
</ol>
<p id="S1.p5.2" class="ltx_p">The paper is structured as follows: In Section 2, an overview of the related works in CL, SSL, and multimodality is presented, with a focus on the recent advancements in the literature. Section 3 provides a detailed description of the experimental setup that has been adopted discussing the different cl strategies, data accumulation steps, and evaluation metrics. Following this, the proposed methodology is presented in Section 4, which includes the model architecture and the framework used in this study. The evaluation of the proposed methodology on custom multimodality dataset, as well as the Core50 dataset is provided in section 5. Moreover, in section 6 the paper showcases the real-time application of the proposed algorithm. Finally, a summary noting the advantages and disadvantages of the proposed method along with the scope for improvements and possible developments in the future are stated in the last section.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Continual Learning Strategies</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Continual learning strategies can be broadly categorized into four major types: architectural, regularization, rehearsal, and hybrid strategies, each with its own advantages and disadvantages. Architectural strategy either employs a dynamic modular network where new layers gets added upon encounter of new tasks <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib10" title="" class="ltx_ref">Rusu et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib11" title="" class="ltx_ref">Fernando et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib12" title="" class="ltx_ref">Rajasegaran et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib13" title="" class="ltx_ref">Aljundi et al.</a></cite> or performs parameter isolation to allocate a dedicated separate sub-space for each task within the same network <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib14" title="" class="ltx_ref">Mallya et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib15" title="" class="ltx_ref">Serra et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib16" title="" class="ltx_ref">Mallya and Lazebnik</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib17" title="" class="ltx_ref">Ahn et al.</a></cite>. The simplest form of architectural regularization involves freezing certain weights in the network to ensure they remain unchanged during training on new tasks. A major drawback of the architectural strategy is the increase in the size of the architecture as new tasks are learned or the potential saturation of the architecture if a fixed model is used.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Regularization strategies can be grouped into two: weight regularization and function regularization. Weight regularization constrains the update of the network weights by adding explicit regularization terms to the loss function, penalizing changes in each parameter based on its importance <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib18" title="" class="ltx_ref">Kirkpatrick et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib19" title="" class="ltx_ref">Zenke et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib20" title="" class="ltx_ref">Chaudhry et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib21" title="" class="ltx_ref">Aljundi et al.</a></cite>. Function regularization, on the other hand, employs distillation methods to maintain the knowledge between the various layers of the network. This strategy typically employs the previously-learned model as the teacher and the currently model as the student, while implementing knowledge distillation (KD) techniques <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib22" title="" class="ltx_ref">Hinton et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib23" title="" class="ltx_ref">Li and Hoiem</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib24" title="" class="ltx_ref">Rebuffi et al.</a></cite> <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib25" title="" class="ltx_ref">Dhar et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib26" title="" class="ltx_ref">Lee et al.</a></cite>. However, regularising the model can make it more challenging for the network to acquire new knowledge.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Rehearsal <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib27" title="" class="ltx_ref">Lopez-Paz and Ranzato</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib28" title="" class="ltx_ref">Bang et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib29" title="" class="ltx_ref">Kumari et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib30" title="" class="ltx_ref">Ebrahimi et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib31" title="" class="ltx_ref">Saha and Roy</a></cite> &amp; pseudo-rehearsal, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib32" title="" class="ltx_ref">Shin et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib33" title="" class="ltx_ref">Wu et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib34" title="" class="ltx_ref">Ayub and Wagner</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib35" title="" class="ltx_ref">Pfülb and Gepperth</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib36" title="" class="ltx_ref">Wang et al.</a></cite> approaches offer the most simple yet effective approach by storing a subset of the previously learned data in a memory buffer or by training a generative model to account for the previous information and replaying it during training on new tasks. However, storing the images in a replay buffer for rehearsal can raise privacy concerns. On the other hand, while using a generative model somewhat addresses the privacy issues but may result in increased training time and computational demands.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Hybrid strategies <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib37" title="" class="ltx_ref">Van de Ven et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib38" title="" class="ltx_ref">Liu et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib39" title="" class="ltx_ref">Ye and Bors</a></cite> are a combination of any of the other three strategies to compensate for catastrophic forgetting. SynapNet <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib40" title="" class="ltx_ref">Kushawaha et al.</a></cite> uses a triple model architecture incorporating knowledge distillation along with a VAE-based pseudo-episodic memory for rehearsal and a sleep phase for memory re-organization. DualNet <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib41" title="" class="ltx_ref">Pham et al.</a></cite> uses a fast learner for supervised learning and a slow learner for unsupervised learning of task-agnostic general representation using semi-supervised learning. ICARL <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib24" title="" class="ltx_ref">Rebuffi et al.</a></cite> includes an external fixed memory to store a subset of old task data based on an elaborated sample selection procedure and then employs a distillation step acting as a regularization.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">Non-exemplar continual learning strategies <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib7" title="" class="ltx_ref">Goswami et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib42" title="" class="ltx_ref">Petit et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib43" title="" class="ltx_ref">Smith et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib44" title="" class="ltx_ref">Hayes et al.</a></cite> use the idea of replay-free sequential training, instead of using a modular network or regularizing the optimization function. Exemplar-free approaches store the prototypes of the past and new classes to compensate for catastrophic forgetting of the previously acquired knowledge. A pre-trained feature extractor provides the feature maps which are then used to calculate the mean and the covariance matrix for the respective classes.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Semi-Supervised Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Semi-supervised learning describes a class of algorithms designed to learn from both labeled and unlabeled data, typically assumed to be sampled from the same or similar distributions <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib45" title="" class="ltx_ref">Yan et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib46" title="" class="ltx_ref">Mawuli et al.</a></cite>. One of the critical challenges in semi-supervised learning is how to effectively utilize labeled and unlabeled data while avoiding overfitting, preventing the effects of noise on the model, and ensuring effective model performance enhancement. Initial breakthroughs in semi-supervised learning with deep neural networks leveraged generative models such as autoencoders <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib47" title="" class="ltx_ref">Rasmus et al.</a></cite>, variational autoencoders <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib48" title="" class="ltx_ref">Kingma et al.</a></cite>, and generative adversarial networks <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib49" title="" class="ltx_ref">Odena</a></cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.3" class="ltx_p">Some approaches in semi-supervised learning <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib50" title="" class="ltx_ref">Oliver et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib51" title="" class="ltx_ref">Berthelot et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib52" title="" class="ltx_ref">Lee et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib48" title="" class="ltx_ref">Kingma et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib53" title="" class="ltx_ref">Kuo et al.</a></cite> also involve balancing a supervised loss (<math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="l_{s}" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><msub id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mi id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">l</mi><mi id="S2.SS2.p2.1.m1.1.1.3" xref="S2.SS2.p2.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2">𝑙</ci><ci id="S2.SS2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">l_{s}</annotation></semantics></math>) applied to the labeled data and an unsupervised consistency regularization loss <math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="l_{ul}" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><msub id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml"><mi id="S2.SS2.p2.2.m2.1.1.2" xref="S2.SS2.p2.2.m2.1.1.2.cmml">l</mi><mrow id="S2.SS2.p2.2.m2.1.1.3" xref="S2.SS2.p2.2.m2.1.1.3.cmml"><mi id="S2.SS2.p2.2.m2.1.1.3.2" xref="S2.SS2.p2.2.m2.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.2.m2.1.1.3.1" xref="S2.SS2.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S2.SS2.p2.2.m2.1.1.3.3" xref="S2.SS2.p2.2.m2.1.1.3.3.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><apply id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.2.m2.1.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p2.2.m2.1.1.2.cmml" xref="S2.SS2.p2.2.m2.1.1.2">𝑙</ci><apply id="S2.SS2.p2.2.m2.1.1.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3"><times id="S2.SS2.p2.2.m2.1.1.3.1.cmml" xref="S2.SS2.p2.2.m2.1.1.3.1"></times><ci id="S2.SS2.p2.2.m2.1.1.3.2.cmml" xref="S2.SS2.p2.2.m2.1.1.3.2">𝑢</ci><ci id="S2.SS2.p2.2.m2.1.1.3.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">l_{ul}</annotation></semantics></math> computed on the unlabeled data. Consistency regularization aims to improve model resilience and maintain label distribution, even in the presence of noisy images. It measures the discrepancy between predictions made on perturbed unlabeled data points. Approaches of this kind include the <math id="S2.SS2.p2.3.m3.1" class="ltx_Math" alttext="\pi" display="inline"><semantics id="S2.SS2.p2.3.m3.1a"><mi id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><ci id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">\pi</annotation></semantics></math>-model <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib54" title="" class="ltx_ref">Laine and Aila</a></cite> which augments the input data with image-based noise and self-regularizes through an additional consistency loss, mean teacher <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib55" title="" class="ltx_ref">Tarvainen and Valpola</a></cite>, which employs an exponential moving average of parameters to regularize the model. Recently, fast-SWA <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib56" title="" class="ltx_ref">Athiwaratkun et al.</a></cite> showed improved results by training with cyclic learning rates and measuring discrepancy with an ensemble of predictions from multiple checkpoints.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Two additional important approaches for semi-supervised learning, which have shown success both in the context of deep neural networks and other types of models are: self-training and conditional entropy minimization. Self-training also known as pseudo-labeling <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib52" title="" class="ltx_ref">Lee et al.</a></cite> involves assigning classes to unlabeled data by making predictions from a model trained only on labeled data. Furthermore, co-training <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib57" title="" class="ltx_ref">Xie et al.</a></cite> attempts to analyze data from different perspectives to solve the accumulative mistake issue during self-training. On the other hand, in case of conditional entropy minimization <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib58" title="" class="ltx_ref">Grandvalet and Bengio</a></cite>, all unlabeled examples are encouraged to make confident predictions on some class. This doesn’t necessarily mean the predictions are correct (because the true labels for the unlabeled data are unknown), but the model is incentivized to be decisive rather than uncertain. In this paper, we use the concept of cosine similarity between labeled and unlabeled feature representations for pseudo-labeling of the unsupervised data. We refer to <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib6" title="" class="ltx_ref">Van Engelen and Hoos</a></cite> for a comprehensive review on the topic.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Multimodality</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Our experience of the world is inherently multimodal we perceive objects through vision, hear sounds, feel textures, smell odors, and taste flavors. To develop an AI agent with similar capabilities, researchers have explored various methods <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib59" title="" class="ltx_ref">Donato et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib60" title="" class="ltx_ref">Babadian et al.</a></cite>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">The simplest method to compensate multiple domains is using the concept of joint representation where the unimodal signals are combined in the same representation space by simple concatenation <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib61" title="" class="ltx_ref">Baltrušaitis et al.</a></cite>. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib62" title="" class="ltx_ref">Ngiam et al.</a></cite> used autoencoders for multimodal domains. They employed stacked denoising autoencoders to represent each modality individually and subsequently fusing them into a unified multimodal representation using an additional autoencoder layer.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Similarly, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib63" title="" class="ltx_ref">Silberer and Lapata</a></cite> suggested a multimodal autoencoder for semantic concept grounding. They incorporated a reconstruction loss for training the representation and added a term in the loss function to predict object labels using the representation. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib64" title="" class="ltx_ref">Srivastava and Salakhutdinov</a></cite> introduced multimodal deep belief networks (DBNs) and multimodal deep boltzmann machines (DBMs) <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib65" title="" class="ltx_ref">Srivastava and Salakhutdinov</a></cite> as multimodal representations. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib66" title="" class="ltx_ref">Kim et al.</a></cite> used a deep belief network for each modality and then combined them into joint representation for audiovisual emotion recognition. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib67" title="" class="ltx_ref">Huang and Kingsbury</a></cite> used a similar model for audio-visual speech recognition (AVSR), and <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib68" title="" class="ltx_ref">Wu and Shao</a></cite> used it for audio and skeleton joint based gesture recognition. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib69" title="" class="ltx_ref">Ouyang et al.</a></cite> explored the use of multimodal DBMs for the task of human pose estimation from multi-view data. They demonstrated that integrating the data at a later stage after unimodal data, underwent nonlinear transformations, which was beneficial for the model. An alternative to a joint multimodal representation is a coordinated representation where instead of projecting the modalities together into a joint space, separate latent representations are learned for each modality and are coordinated through a constraint <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib70" title="" class="ltx_ref">Frome et al.</a></cite>.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib71" title="" class="ltx_ref">Sarfraz et al.</a></cite> recently utilized a multimodal CL dataset to learn complementary information from two different modalities. They employed the VGGSound dataset, which includes 10-second video clips along with their corresponding audio. On the other hand, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib72" title="" class="ltx_ref">Xu et al.</a></cite> developed an egocentric multimodal dataset using smart glasses equipped with sensors, combining data from cameras, accelerometers, and gyroscopes. This dataset covers 32 types of daily activities performed by 10 participants. They utilized the temporal binding network (TBN) <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib73" title="" class="ltx_ref">Kazakos et al.</a></cite> to fuse the information from different sensors into single feature vector for further training and feature extraction.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p">One of the major drawbacks of these methods is their inability to incrementally learn new domains. For example, if we train our model on two domains (sensor signals and images) and use a joint representation to learn these two modalities, introducing a new data modality later would necessitate re-training the model from scratch. Conversely, with our proposed exFeCAM model, we can add the new modality as a different domain and incrementally train the model without starting the training process anew. Additionally, our algorithm eliminates the necessity of storing data in memory for rehearsal, effectively addressing privacy concerns and storage challenges commonly encountered in exemplar-based CL methods.</p>
</div>
<div id="S2.SS3.p6" class="ltx_para">
<p id="S2.SS3.p6.1" class="ltx_p">With recent advancements in large language models (LLMs) and the introduction of GPT-4 <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib74" title="" class="ltx_ref">Achiam et al.</a></cite> and its variants, it is now possible to utilize the data coming from vision, audio, and text signals into a single model. However, these models face significant challenges, including high computational and memory demands and a lack of continual learning capabilities.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2409.13792/assets/figs/domain_class_incremental_plot.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="149" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Multimodal data comprising of two different domains, domain 1 contains the sensor information for different objects and domain 2 contains the images of those objects in different orientations, lightning conditions and different level of occlusion by the operator. Moving from left to right the model trains in a class-incremental manner, while going from top-bottom it trains in a domain-incremental manner.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setup</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe the steps involved in the creation of the multimodal continual learning dataset as well as the standard evaluation criteria for the class incremental as well as domain incremental learning scenarios.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Continual Learning Scenario</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">According to the division of incremental batches and the availability of task identities, continual learning can be broadly classified into three primary types or scenarios <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib75" title="" class="ltx_ref">Van de Ven et al.</a></cite>:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Task-Incremental Learning (TIL): It requires an algorithm to learn a set of distinct tasks progressively. Task identities/numbers are provided in both training and testing phase.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Class-Incremental Learning (CIL): The algorithm must learn to differentiate between a growing number of classes incrementally. Task identities are only provided during training phase.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Domain-Incremental Learning (DIL): The algorithm needs to learn the same tasks but in different domains. Task identities are not required.</p>
</div>
</li>
</ul>
<p id="S3.SS1.p1.2" class="ltx_p">In addition to these major scenarios, there are also other scenarios present in the literature like task-free continual learning (TFCL), online continual learning (OCL), blurred boundary continual learning (BBCL), continual pre-training (CPT), we refer to <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib4" title="" class="ltx_ref">Wang et al.</a></cite> for a thorough study.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2409.13792/assets/figs/gripper.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="229" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Commercial two fingers pneumatic gripper equipped with two force sensors and two flex sensors affixed together using stretchable nylon thread. The flex sensor measures the bending of the finger and the force sensor measures the magnitude of the force applied to the finger tip.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Multimodal Dataset</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The multimodal dataset comprises two components: sensor signals from an actuated finger and non-stationary images of objects captured by a vision camera. The two different modalities are fused into a hybrid setup that incorporates both class incremental as well as domain incremental scenarios as illustrated in Figure <a href="#S2.F1" title="Figure 1 ‣ 2.3 Multimodality ‣ 2 Related Work ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In this setup, progression from left to right represents class-incremental training, while progression from top to bottom represents domain-incremental training. Both domains encompass five tasks, with each task involving the learning of two new classes. The first domain focuses on sensor signal data for various objects encountered in each experience and follows a class-incremental learning approach. The second domain deals with visual data of the same objects and employs both domain-incremental and class-incremental learning methods. Further details on data collection for the different modalities are provided in the subsequent sections.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Sensor Signal</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">To collect the sensor signals for the different objects we utilize a soft pneumatic gripper <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib76" title="" class="ltx_ref">Hao et al.</a></cite> equipped with four sensors which are affixed together using stretchable nylon thread as illustrated in Figure 10. We have employed the commercially available flex sensors <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib77" title="" class="ltx_ref">Saggio et al.</a></cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib78" title="" class="ltx_ref">Mishra et al.</a></cite> to measure the bending of the finger and a force sensitive resistor (FSR) <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib79" title="" class="ltx_ref">Hollinger and Wanderley</a></cite> to quantify the force applied to the fingertip as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Continual Learning Scenario ‣ 3 Experimental Setup ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The outputs from the flex and force sensors are directed to an Arduino Due board, which in turn is connected to a computer for further processing and analysis. We gather the sensor data for 10 distinct objects, for each object the gripper acquires 50 data points, considering various orientations of the object. During the data collection process, for each data point the gripper holds and releases the object repeatedly at different contact points, with each cycle lasting <math id="S3.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mo id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><csymbol cd="latexml" id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">\sim</annotation></semantics></math> 39 seconds. Each data point is represented as a 600-dimensional vector, encapsulating the sensor signals recorded during that time interval. The dataset acquisition for every object takes about 37 minutes to complete on a computer equipped with an Intel Core i7 CPU @2.80GHz (GTX 1070 GPU) running Windows 10.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Image Data</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">The image data consists of the same classes but repeated with three different objects. Each object is repeated 3 times to create a more diversified dataset. Classification can be performed at object level (30 classes) or at category level (10 classes). For each trial, the images are extracted from a 15-second video sequence at a rate of 10 frames per second (FPS). Objects are hand-held by the operator and the camera point-of-view is that of the operator’s eyes. The operator extends his arm and smoothly rotates the object in front of the camera. The grabbing hand (left or right) changes throughout the sessions and relevant object occlusions are often produced by the hand itself. This creates a complex non-stationary dataset with variable lighting conditions and arbitrary amounts of occlusion produced by the operator’s hand. The final dataset consists of 13,500 RGB images each of size 128x128 extracted from the video frame. The images are further resized to 32x32 dimension to speed up the training and evaluation process.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation Metrics</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.3" class="ltx_p">The performance of the CL algorithm depends on its ability to adapt, retain, and generalize the knowledge over time. We evaluate the incremental accuracy (denoted as <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="a_{t}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">a</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑎</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">a_{t}</annotation></semantics></math>) of the model after every task as well as the average accuracy over all the tasks for each domain denoted as <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="A_{T}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">A</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝐴</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">A_{T}</annotation></semantics></math>. The average accuracy over all the domains is referred to as <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="A_{D}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><msub id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">A</mi><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">𝐴</ci><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">A_{D}</annotation></semantics></math> in the paper. We define the expressions as follows:
<br class="ltx_break"></p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E1.m1.1" class="ltx_Math" alttext="A_{T}=\frac{1}{T}\sum_{t=1}^{t=T}a_{t}\\
A_{D}=\frac{1}{D}\sum_{T=1}^{T=D}A_{T}" display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><msub id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.2.2" xref="S3.E1.m1.1.1.2.2.cmml">A</mi><mi id="S3.E1.m1.1.1.2.3" xref="S3.E1.m1.1.1.2.3.cmml">T</mi></msub><mo id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.1.1.4" xref="S3.E1.m1.1.1.4.cmml"><mfrac id="S3.E1.m1.1.1.4.2" xref="S3.E1.m1.1.1.4.2.cmml"><mn id="S3.E1.m1.1.1.4.2.2" xref="S3.E1.m1.1.1.4.2.2.cmml">1</mn><mi id="S3.E1.m1.1.1.4.2.3" xref="S3.E1.m1.1.1.4.2.3.cmml">T</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.4.1" xref="S3.E1.m1.1.1.4.1.cmml">​</mo><mrow id="S3.E1.m1.1.1.4.3" xref="S3.E1.m1.1.1.4.3.cmml"><munderover id="S3.E1.m1.1.1.4.3.1" xref="S3.E1.m1.1.1.4.3.1.cmml"><mo movablelimits="false" id="S3.E1.m1.1.1.4.3.1.2.2" xref="S3.E1.m1.1.1.4.3.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.1.1.4.3.1.2.3" xref="S3.E1.m1.1.1.4.3.1.2.3.cmml"><mi id="S3.E1.m1.1.1.4.3.1.2.3.2" xref="S3.E1.m1.1.1.4.3.1.2.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.4.3.1.2.3.1" xref="S3.E1.m1.1.1.4.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.1.1.4.3.1.2.3.3" xref="S3.E1.m1.1.1.4.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.E1.m1.1.1.4.3.1.3" xref="S3.E1.m1.1.1.4.3.1.3.cmml"><mi id="S3.E1.m1.1.1.4.3.1.3.2" xref="S3.E1.m1.1.1.4.3.1.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.4.3.1.3.1" xref="S3.E1.m1.1.1.4.3.1.3.1.cmml">=</mo><mi id="S3.E1.m1.1.1.4.3.1.3.3" xref="S3.E1.m1.1.1.4.3.1.3.3.cmml">T</mi></mrow></munderover><mrow id="S3.E1.m1.1.1.4.3.2" xref="S3.E1.m1.1.1.4.3.2.cmml"><msub id="S3.E1.m1.1.1.4.3.2.2" xref="S3.E1.m1.1.1.4.3.2.2.cmml"><mi id="S3.E1.m1.1.1.4.3.2.2.2" xref="S3.E1.m1.1.1.4.3.2.2.2.cmml">a</mi><mi id="S3.E1.m1.1.1.4.3.2.2.3" xref="S3.E1.m1.1.1.4.3.2.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.4.3.2.1" xref="S3.E1.m1.1.1.4.3.2.1.cmml">​</mo><msub id="S3.E1.m1.1.1.4.3.2.3" xref="S3.E1.m1.1.1.4.3.2.3.cmml"><mi id="S3.E1.m1.1.1.4.3.2.3.2" xref="S3.E1.m1.1.1.4.3.2.3.2.cmml">A</mi><mi id="S3.E1.m1.1.1.4.3.2.3.3" xref="S3.E1.m1.1.1.4.3.2.3.3.cmml">D</mi></msub></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.5" xref="S3.E1.m1.1.1.5.cmml">=</mo><mrow id="S3.E1.m1.1.1.6" xref="S3.E1.m1.1.1.6.cmml"><mfrac id="S3.E1.m1.1.1.6.2" xref="S3.E1.m1.1.1.6.2.cmml"><mn id="S3.E1.m1.1.1.6.2.2" xref="S3.E1.m1.1.1.6.2.2.cmml">1</mn><mi id="S3.E1.m1.1.1.6.2.3" xref="S3.E1.m1.1.1.6.2.3.cmml">D</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.6.1" xref="S3.E1.m1.1.1.6.1.cmml">​</mo><mrow id="S3.E1.m1.1.1.6.3" xref="S3.E1.m1.1.1.6.3.cmml"><munderover id="S3.E1.m1.1.1.6.3.1" xref="S3.E1.m1.1.1.6.3.1.cmml"><mo movablelimits="false" id="S3.E1.m1.1.1.6.3.1.2.2" xref="S3.E1.m1.1.1.6.3.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.1.1.6.3.1.2.3" xref="S3.E1.m1.1.1.6.3.1.2.3.cmml"><mi id="S3.E1.m1.1.1.6.3.1.2.3.2" xref="S3.E1.m1.1.1.6.3.1.2.3.2.cmml">T</mi><mo id="S3.E1.m1.1.1.6.3.1.2.3.1" xref="S3.E1.m1.1.1.6.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.1.1.6.3.1.2.3.3" xref="S3.E1.m1.1.1.6.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.E1.m1.1.1.6.3.1.3" xref="S3.E1.m1.1.1.6.3.1.3.cmml"><mi id="S3.E1.m1.1.1.6.3.1.3.2" xref="S3.E1.m1.1.1.6.3.1.3.2.cmml">T</mi><mo id="S3.E1.m1.1.1.6.3.1.3.1" xref="S3.E1.m1.1.1.6.3.1.3.1.cmml">=</mo><mi id="S3.E1.m1.1.1.6.3.1.3.3" xref="S3.E1.m1.1.1.6.3.1.3.3.cmml">D</mi></mrow></munderover><msub id="S3.E1.m1.1.1.6.3.2" xref="S3.E1.m1.1.1.6.3.2.cmml"><mi id="S3.E1.m1.1.1.6.3.2.2" xref="S3.E1.m1.1.1.6.3.2.2.cmml">A</mi><mi id="S3.E1.m1.1.1.6.3.2.3" xref="S3.E1.m1.1.1.6.3.2.3.cmml">T</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><and id="S3.E1.m1.1.1a.cmml" xref="S3.E1.m1.1.1"></and><apply id="S3.E1.m1.1.1b.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"></eq><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.2.2">𝐴</ci><ci id="S3.E1.m1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.2.3">𝑇</ci></apply><apply id="S3.E1.m1.1.1.4.cmml" xref="S3.E1.m1.1.1.4"><times id="S3.E1.m1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.4.1"></times><apply id="S3.E1.m1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.4.2"><divide id="S3.E1.m1.1.1.4.2.1.cmml" xref="S3.E1.m1.1.1.4.2"></divide><cn type="integer" id="S3.E1.m1.1.1.4.2.2.cmml" xref="S3.E1.m1.1.1.4.2.2">1</cn><ci id="S3.E1.m1.1.1.4.2.3.cmml" xref="S3.E1.m1.1.1.4.2.3">𝑇</ci></apply><apply id="S3.E1.m1.1.1.4.3.cmml" xref="S3.E1.m1.1.1.4.3"><apply id="S3.E1.m1.1.1.4.3.1.cmml" xref="S3.E1.m1.1.1.4.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.4.3.1.1.cmml" xref="S3.E1.m1.1.1.4.3.1">superscript</csymbol><apply id="S3.E1.m1.1.1.4.3.1.2.cmml" xref="S3.E1.m1.1.1.4.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.4.3.1.2.1.cmml" xref="S3.E1.m1.1.1.4.3.1">subscript</csymbol><sum id="S3.E1.m1.1.1.4.3.1.2.2.cmml" xref="S3.E1.m1.1.1.4.3.1.2.2"></sum><apply id="S3.E1.m1.1.1.4.3.1.2.3.cmml" xref="S3.E1.m1.1.1.4.3.1.2.3"><eq id="S3.E1.m1.1.1.4.3.1.2.3.1.cmml" xref="S3.E1.m1.1.1.4.3.1.2.3.1"></eq><ci id="S3.E1.m1.1.1.4.3.1.2.3.2.cmml" xref="S3.E1.m1.1.1.4.3.1.2.3.2">𝑡</ci><cn type="integer" id="S3.E1.m1.1.1.4.3.1.2.3.3.cmml" xref="S3.E1.m1.1.1.4.3.1.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.1.1.4.3.1.3.cmml" xref="S3.E1.m1.1.1.4.3.1.3"><eq id="S3.E1.m1.1.1.4.3.1.3.1.cmml" xref="S3.E1.m1.1.1.4.3.1.3.1"></eq><ci id="S3.E1.m1.1.1.4.3.1.3.2.cmml" xref="S3.E1.m1.1.1.4.3.1.3.2">𝑡</ci><ci id="S3.E1.m1.1.1.4.3.1.3.3.cmml" xref="S3.E1.m1.1.1.4.3.1.3.3">𝑇</ci></apply></apply><apply id="S3.E1.m1.1.1.4.3.2.cmml" xref="S3.E1.m1.1.1.4.3.2"><times id="S3.E1.m1.1.1.4.3.2.1.cmml" xref="S3.E1.m1.1.1.4.3.2.1"></times><apply id="S3.E1.m1.1.1.4.3.2.2.cmml" xref="S3.E1.m1.1.1.4.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.4.3.2.2.1.cmml" xref="S3.E1.m1.1.1.4.3.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.4.3.2.2.2.cmml" xref="S3.E1.m1.1.1.4.3.2.2.2">𝑎</ci><ci id="S3.E1.m1.1.1.4.3.2.2.3.cmml" xref="S3.E1.m1.1.1.4.3.2.2.3">𝑡</ci></apply><apply id="S3.E1.m1.1.1.4.3.2.3.cmml" xref="S3.E1.m1.1.1.4.3.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.4.3.2.3.1.cmml" xref="S3.E1.m1.1.1.4.3.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.4.3.2.3.2.cmml" xref="S3.E1.m1.1.1.4.3.2.3.2">𝐴</ci><ci id="S3.E1.m1.1.1.4.3.2.3.3.cmml" xref="S3.E1.m1.1.1.4.3.2.3.3">𝐷</ci></apply></apply></apply></apply></apply><apply id="S3.E1.m1.1.1c.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.5.cmml" xref="S3.E1.m1.1.1.5"></eq><share href="#S3.E1.m1.1.1.4.cmml" id="S3.E1.m1.1.1d.cmml" xref="S3.E1.m1.1.1"></share><apply id="S3.E1.m1.1.1.6.cmml" xref="S3.E1.m1.1.1.6"><times id="S3.E1.m1.1.1.6.1.cmml" xref="S3.E1.m1.1.1.6.1"></times><apply id="S3.E1.m1.1.1.6.2.cmml" xref="S3.E1.m1.1.1.6.2"><divide id="S3.E1.m1.1.1.6.2.1.cmml" xref="S3.E1.m1.1.1.6.2"></divide><cn type="integer" id="S3.E1.m1.1.1.6.2.2.cmml" xref="S3.E1.m1.1.1.6.2.2">1</cn><ci id="S3.E1.m1.1.1.6.2.3.cmml" xref="S3.E1.m1.1.1.6.2.3">𝐷</ci></apply><apply id="S3.E1.m1.1.1.6.3.cmml" xref="S3.E1.m1.1.1.6.3"><apply id="S3.E1.m1.1.1.6.3.1.cmml" xref="S3.E1.m1.1.1.6.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.6.3.1.1.cmml" xref="S3.E1.m1.1.1.6.3.1">superscript</csymbol><apply id="S3.E1.m1.1.1.6.3.1.2.cmml" xref="S3.E1.m1.1.1.6.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.6.3.1.2.1.cmml" xref="S3.E1.m1.1.1.6.3.1">subscript</csymbol><sum id="S3.E1.m1.1.1.6.3.1.2.2.cmml" xref="S3.E1.m1.1.1.6.3.1.2.2"></sum><apply id="S3.E1.m1.1.1.6.3.1.2.3.cmml" xref="S3.E1.m1.1.1.6.3.1.2.3"><eq id="S3.E1.m1.1.1.6.3.1.2.3.1.cmml" xref="S3.E1.m1.1.1.6.3.1.2.3.1"></eq><ci id="S3.E1.m1.1.1.6.3.1.2.3.2.cmml" xref="S3.E1.m1.1.1.6.3.1.2.3.2">𝑇</ci><cn type="integer" id="S3.E1.m1.1.1.6.3.1.2.3.3.cmml" xref="S3.E1.m1.1.1.6.3.1.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.1.1.6.3.1.3.cmml" xref="S3.E1.m1.1.1.6.3.1.3"><eq id="S3.E1.m1.1.1.6.3.1.3.1.cmml" xref="S3.E1.m1.1.1.6.3.1.3.1"></eq><ci id="S3.E1.m1.1.1.6.3.1.3.2.cmml" xref="S3.E1.m1.1.1.6.3.1.3.2">𝑇</ci><ci id="S3.E1.m1.1.1.6.3.1.3.3.cmml" xref="S3.E1.m1.1.1.6.3.1.3.3">𝐷</ci></apply></apply><apply id="S3.E1.m1.1.1.6.3.2.cmml" xref="S3.E1.m1.1.1.6.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.6.3.2.1.cmml" xref="S3.E1.m1.1.1.6.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.6.3.2.2.cmml" xref="S3.E1.m1.1.1.6.3.2.2">𝐴</ci><ci id="S3.E1.m1.1.1.6.3.2.3.cmml" xref="S3.E1.m1.1.1.6.3.2.3">𝑇</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">A_{T}=\frac{1}{T}\sum_{t=1}^{t=T}a_{t}\\
A_{D}=\frac{1}{D}\sum_{T=1}^{T=D}A_{T}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.5" class="ltx_p">where <math id="S3.SS3.p1.4.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS3.p1.4.m1.1a"><mi id="S3.SS3.p1.4.m1.1.1" xref="S3.SS3.p1.4.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m1.1b"><ci id="S3.SS3.p1.4.m1.1.1.cmml" xref="S3.SS3.p1.4.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m1.1c">T</annotation></semantics></math> and <math id="S3.SS3.p1.5.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS3.p1.5.m2.1a"><mi id="S3.SS3.p1.5.m2.1.1" xref="S3.SS3.p1.5.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m2.1b"><ci id="S3.SS3.p1.5.m2.1.1.cmml" xref="S3.SS3.p1.5.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m2.1c">D</annotation></semantics></math> refer to the total number of incremental tasks in each domain and the total number of domains.
<br class="ltx_break">To evaluate the SSL capabilities of the algorithm we perform two different experiments as proposed in the paper <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib80" title="" class="ltx_ref">Smith et al.</a></cite>, we use the following terminology to describe them: First, <span id="S3.SS3.p1.5.1" class="ltx_text ltx_font_italic">Random Images</span>, where we have 20% of unlabeled data and 80% labeled data for each class. To collect the unsupervised data we randomly sample 20% (about 240) data from the training dataset for each class, remove the class label, shuffle, and store it in a separate folder. Second, <span id="S3.SS3.p1.5.2" class="ltx_text ltx_font_italic">Unseen Images</span>, where we sample the images of an unseen object of the same parent class from the training dataset and repeat the above steps. A point to note is that in the first case, the model might have already seen all the objects for each class, however for the second case, the model has never seen the objects present in the unsupervised dataset and thus makes it a more challenging situation. In addition, we also perform an ablation study to show the effectiveness of the intra-layer feature representation as well as SSL on the model’s overall accuracy.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Pre-train model architecture for both the domains of the custom multimodal dataset, domain 2 represents the image data and domain 1 signifies the sensor data. The linear layers for both the models are removed once the pre-training is completed . Here, "classes" refers to the total number of output classes during the pre-training phase.</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Model type</span></span>
</span>
</td>
<td id="S3.T1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S3.T1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Layer type</span></span>
</span>
</td>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.1.1" class="ltx_p" style="width:62.6pt;"><span id="S3.T1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Activation function</span></span>
</span>
</td>
<td id="S3.T1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.1.1" class="ltx_p" style="width:52.6pt;"><span id="S3.T1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Output channel/neurons</span></span>
</span>
</td>
<td id="S3.T1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Batch Normalization</span></span>
</span>
</td>
<td id="S3.T1.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Other details</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.2" class="ltx_tr">
<td id="S3.T1.1.2.1" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S3.T1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.2.1.1" class="ltx_p" style="width:71.1pt;">Conv2D</span>
</span>
</td>
<td id="S3.T1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.4.1.1" class="ltx_p" style="width:52.6pt;">16</span>
</span>
</td>
<td id="S3.T1.1.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm2D</span>
</span>
</td>
<td id="S3.T1.1.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:3, stride:1, padding:1</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.3" class="ltx_tr">
<td id="S3.T1.1.3.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.2.1.1" class="ltx_p" style="width:71.1pt;">Conv2D</span>
</span>
</td>
<td id="S3.T1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.4.1.1" class="ltx_p" style="width:52.6pt;">32</span>
</span>
</td>
<td id="S3.T1.1.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm2D</span>
</span>
</td>
<td id="S3.T1.1.3.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:3, stride:2, padding:1</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.4" class="ltx_tr">
<td id="S3.T1.1.4.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.2.1.1" class="ltx_p" style="width:71.1pt;">Conv2D</span>
</span>
</td>
<td id="S3.T1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.4.1.1" class="ltx_p" style="width:52.6pt;">64</span>
</span>
</td>
<td id="S3.T1.1.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm2D</span>
</span>
</td>
<td id="S3.T1.1.4.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:3, stride:2, padding:1</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.5" class="ltx_tr">
<td id="S3.T1.1.5.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.5.2.1.1" class="ltx_p" style="width:71.1pt;">Conv2D</span>
</span>
</td>
<td id="S3.T1.1.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.5.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.5.4.1.1" class="ltx_p" style="width:52.6pt;">64</span>
</span>
</td>
<td id="S3.T1.1.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.5.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm2D</span>
</span>
</td>
<td id="S3.T1.1.5.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.5.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:3, stride:3, padding:0</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.6" class="ltx_tr">
<td id="S3.T1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.6.1.1.1" class="ltx_p" style="width:56.9pt;">Domain 2</span>
</span>
</td>
<td id="S3.T1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.6.2.1.1" class="ltx_p" style="width:71.1pt;">Conv2D</span>
</span>
</td>
<td id="S3.T1.1.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.6.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.6.4.1.1" class="ltx_p" style="width:52.6pt;">128</span>
</span>
</td>
<td id="S3.T1.1.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.6.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm2D</span>
</span>
</td>
<td id="S3.T1.1.6.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.6.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:2, stride:2, padding:0</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.7" class="ltx_tr">
<td id="S3.T1.1.7.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.7.2.1.1" class="ltx_p" style="width:71.1pt;">Flatten</span>
</span>
</td>
<td id="S3.T1.1.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.7.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S3.T1.1.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.7.4.1.1" class="ltx_p" style="width:52.6pt;">-</span>
</span>
</td>
<td id="S3.T1.1.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.7.5.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S3.T1.1.7.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.7.6.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.8" class="ltx_tr">
<td id="S3.T1.1.8.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.8.2.1.1" class="ltx_p" style="width:71.1pt;">Linear</span>
</span>
</td>
<td id="S3.T1.1.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.8.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.8.4.1.1" class="ltx_p" style="width:52.6pt;">2000</span>
</span>
</td>
<td id="S3.T1.1.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.8.5.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S3.T1.1.8.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.8.6.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.9" class="ltx_tr">
<td id="S3.T1.1.9.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.9.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.9.2.1.1" class="ltx_p" style="width:71.1pt;">Linear</span>
</span>
</td>
<td id="S3.T1.1.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.9.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.9.4.1.1" class="ltx_p" style="width:52.6pt;">1000</span>
</span>
</td>
<td id="S3.T1.1.9.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.9.5.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S3.T1.1.9.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.9.6.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.10" class="ltx_tr">
<td id="S3.T1.1.10.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.10.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.10.2.1.1" class="ltx_p" style="width:71.1pt;">Linear</span>
</span>
</td>
<td id="S3.T1.1.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.10.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.10.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.10.4.1.1" class="ltx_p" style="width:52.6pt;">classes</span>
</span>
</td>
<td id="S3.T1.1.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.10.5.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S3.T1.1.10.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.10.6.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.11" class="ltx_tr">
<td id="S3.T1.1.11.1" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S3.T1.1.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.11.2.1.1" class="ltx_p" style="width:71.1pt;">Conv1D</span>
</span>
</td>
<td id="S3.T1.1.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.11.3.1.1" class="ltx_p" style="width:62.6pt;">Leakyrelu (0.01)</span>
</span>
</td>
<td id="S3.T1.1.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.11.4.1.1" class="ltx_p" style="width:52.6pt;">512</span>
</span>
</td>
<td id="S3.T1.1.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.11.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm1D</span>
</span>
</td>
<td id="S3.T1.1.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.11.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:3, stride:1, padding:1</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.12" class="ltx_tr">
<td id="S3.T1.1.12.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.12.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.12.2.1.1" class="ltx_p" style="width:71.1pt;">Conv1D</span>
</span>
</td>
<td id="S3.T1.1.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.12.3.1.1" class="ltx_p" style="width:62.6pt;">Leakyrelu (0.01)</span>
</span>
</td>
<td id="S3.T1.1.12.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.12.4.1.1" class="ltx_p" style="width:52.6pt;">256</span>
</span>
</td>
<td id="S3.T1.1.12.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.12.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm1D</span>
</span>
</td>
<td id="S3.T1.1.12.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.12.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:3, stride:2, padding:1</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.13" class="ltx_tr">
<td id="S3.T1.1.13.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.13.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.13.2.1.1" class="ltx_p" style="width:71.1pt;">Conv1D</span>
</span>
</td>
<td id="S3.T1.1.13.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.13.3.1.1" class="ltx_p" style="width:62.6pt;">Leakyrelu (0.01)</span>
</span>
</td>
<td id="S3.T1.1.13.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.13.4.1.1" class="ltx_p" style="width:52.6pt;">128</span>
</span>
</td>
<td id="S3.T1.1.13.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.13.5.1.1" class="ltx_p" style="width:56.9pt;">Batchnorm1D</span>
</span>
</td>
<td id="S3.T1.1.13.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.13.6.1.1" class="ltx_p" style="width:113.8pt;">kernel:3, stride:2, padding:1</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.14" class="ltx_tr">
<td id="S3.T1.1.14.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.14.1.1.1" class="ltx_p" style="width:56.9pt;">Domain 1</span>
</span>
</td>
<td id="S3.T1.1.14.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.14.2.1.1" class="ltx_p" style="width:71.1pt;">Flatten</span>
</span>
</td>
<td id="S3.T1.1.14.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.14.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S3.T1.1.14.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.14.4.1.1" class="ltx_p" style="width:52.6pt;">-</span>
</span>
</td>
<td id="S3.T1.1.14.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.14.5.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S3.T1.1.14.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.14.6.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.15" class="ltx_tr">
<td id="S3.T1.1.15.1" class="ltx_td ltx_align_top"></td>
<td id="S3.T1.1.15.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.15.2.1.1" class="ltx_p" style="width:71.1pt;">Linear</span>
</span>
</td>
<td id="S3.T1.1.15.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.15.3.1.1" class="ltx_p" style="width:62.6pt;">Relu</span>
</span>
</td>
<td id="S3.T1.1.15.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.15.4.1.1" class="ltx_p" style="width:52.6pt;">256</span>
</span>
</td>
<td id="S3.T1.1.15.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.15.5.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S3.T1.1.15.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.1.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.15.6.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.16" class="ltx_tr">
<td id="S3.T1.1.16.1" class="ltx_td ltx_align_top ltx_border_b"></td>
<td id="S3.T1.1.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S3.T1.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.16.2.1.1" class="ltx_p" style="width:71.1pt;">Linear</span>
</span>
</td>
<td id="S3.T1.1.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S3.T1.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.16.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S3.T1.1.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S3.T1.1.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.16.4.1.1" class="ltx_p" style="width:52.6pt;">classes</span>
</span>
</td>
<td id="S3.T1.1.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S3.T1.1.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.16.5.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S3.T1.1.16.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S3.T1.1.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.16.6.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we discuss the modifications made to the FeCAM algorithm <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib7" title="" class="ltx_ref">Goswami et al.</a></cite>. Originally, the algorithm models the feature distribution of classes using a multivariate normal distribution, <math id="S4.p1.1.m1.2" class="ltx_Math" alttext="\mathcal{N}(\mu,\Sigma)" display="inline"><semantics id="S4.p1.1.m1.2a"><mrow id="S4.p1.1.m1.2.3" xref="S4.p1.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p1.1.m1.2.3.2" xref="S4.p1.1.m1.2.3.2.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S4.p1.1.m1.2.3.1" xref="S4.p1.1.m1.2.3.1.cmml">​</mo><mrow id="S4.p1.1.m1.2.3.3.2" xref="S4.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.p1.1.m1.2.3.3.2.1" xref="S4.p1.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">μ</mi><mo id="S4.p1.1.m1.2.3.3.2.2" xref="S4.p1.1.m1.2.3.3.1.cmml">,</mo><mi mathvariant="normal" id="S4.p1.1.m1.2.2" xref="S4.p1.1.m1.2.2.cmml">Σ</mi><mo stretchy="false" id="S4.p1.1.m1.2.3.3.2.3" xref="S4.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.2b"><apply id="S4.p1.1.m1.2.3.cmml" xref="S4.p1.1.m1.2.3"><times id="S4.p1.1.m1.2.3.1.cmml" xref="S4.p1.1.m1.2.3.1"></times><ci id="S4.p1.1.m1.2.3.2.cmml" xref="S4.p1.1.m1.2.3.2">𝒩</ci><interval closure="open" id="S4.p1.1.m1.2.3.3.1.cmml" xref="S4.p1.1.m1.2.3.3.2"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">𝜇</ci><ci id="S4.p1.1.m1.2.2.cmml" xref="S4.p1.1.m1.2.2">Σ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.2c">\mathcal{N}(\mu,\Sigma)</annotation></semantics></math>, and uses the Mahalanobis distance to perform classification. While the authors proposed several techniques to enhance and stabilize Mahalanobis-based distance classification, one significant limitation of FeCAM is its requirement to store batches in temporary memory and conduct training only once all data for a particular task is available. This makes it unsuitable for online learning. To address this issue and improve the algorithm’s capability for multimodal training, as well as to adapt to the semi-supervised nature of the dataset, we introduce several new features to the exFeCAM algorithm, which are detailed below.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Online Batchwise Training</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Online training involves training a model incrementally in a batch-wise manner rather than on the entire dataset for a particular task at once. In this approach, each batch of data is passed through a feature extractor to obtain feature maps, which are then used to calculate the prototypes (mean and co-variance matrix) for each class in that batch. A dictionary is initialized with class labels as keys and their corresponding prototypes as values. There are two possible scenarios when updating this dictionary:</p>
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">If a class is encountered for the first time, a new entry is added with the class label as the key and the prototypes as the value.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">If the class has been seen before, the existing prototypes for that class are retrieved and updated by averaging the previous prototypes with the new ones from the current batch.</p>
</div>
</li>
</ol>
<p id="S4.SS1.p1.2" class="ltx_p">This method avoids the need to store incoming data for each task, which is critical for continual learning (CL) objectives and is especially suitable for autonomous agents with limited cache memory. Learning prototypes in a batch-wise manner addresses the challenge of not having access to previous data points, making it a more practical solution for real-time applications.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.21.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> exFeCAM Algorithm</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.19" class="ltx_p ltx_figure_panel"><span id="alg1.19.1" class="ltx_text ltx_font_bold">Input:</span> Data stream <math id="alg1.1.m1.7" class="ltx_Math" alttext="(D_{0}^{0},D_{0}^{1},...,D_{1}^{0},D_{1}^{1},...,D_{n}^{0:t})" display="inline"><semantics id="alg1.1.m1.7a"><mrow id="alg1.1.m1.7.7.5" xref="alg1.1.m1.7.7.6.cmml"><mo stretchy="false" id="alg1.1.m1.7.7.5.6" xref="alg1.1.m1.7.7.6.cmml">(</mo><msubsup id="alg1.1.m1.3.3.1.1" xref="alg1.1.m1.3.3.1.1.cmml"><mi id="alg1.1.m1.3.3.1.1.2.2" xref="alg1.1.m1.3.3.1.1.2.2.cmml">D</mi><mn id="alg1.1.m1.3.3.1.1.2.3" xref="alg1.1.m1.3.3.1.1.2.3.cmml">0</mn><mn id="alg1.1.m1.3.3.1.1.3" xref="alg1.1.m1.3.3.1.1.3.cmml">0</mn></msubsup><mo id="alg1.1.m1.7.7.5.7" xref="alg1.1.m1.7.7.6.cmml">,</mo><msubsup id="alg1.1.m1.4.4.2.2" xref="alg1.1.m1.4.4.2.2.cmml"><mi id="alg1.1.m1.4.4.2.2.2.2" xref="alg1.1.m1.4.4.2.2.2.2.cmml">D</mi><mn id="alg1.1.m1.4.4.2.2.2.3" xref="alg1.1.m1.4.4.2.2.2.3.cmml">0</mn><mn id="alg1.1.m1.4.4.2.2.3" xref="alg1.1.m1.4.4.2.2.3.cmml">1</mn></msubsup><mo id="alg1.1.m1.7.7.5.8" xref="alg1.1.m1.7.7.6.cmml">,</mo><mi mathvariant="normal" id="alg1.1.m1.1.1" xref="alg1.1.m1.1.1.cmml">…</mi><mo id="alg1.1.m1.7.7.5.9" xref="alg1.1.m1.7.7.6.cmml">,</mo><msubsup id="alg1.1.m1.5.5.3.3" xref="alg1.1.m1.5.5.3.3.cmml"><mi id="alg1.1.m1.5.5.3.3.2.2" xref="alg1.1.m1.5.5.3.3.2.2.cmml">D</mi><mn id="alg1.1.m1.5.5.3.3.2.3" xref="alg1.1.m1.5.5.3.3.2.3.cmml">1</mn><mn id="alg1.1.m1.5.5.3.3.3" xref="alg1.1.m1.5.5.3.3.3.cmml">0</mn></msubsup><mo id="alg1.1.m1.7.7.5.10" xref="alg1.1.m1.7.7.6.cmml">,</mo><msubsup id="alg1.1.m1.6.6.4.4" xref="alg1.1.m1.6.6.4.4.cmml"><mi id="alg1.1.m1.6.6.4.4.2.2" xref="alg1.1.m1.6.6.4.4.2.2.cmml">D</mi><mn id="alg1.1.m1.6.6.4.4.2.3" xref="alg1.1.m1.6.6.4.4.2.3.cmml">1</mn><mn id="alg1.1.m1.6.6.4.4.3" xref="alg1.1.m1.6.6.4.4.3.cmml">1</mn></msubsup><mo id="alg1.1.m1.7.7.5.11" xref="alg1.1.m1.7.7.6.cmml">,</mo><mi mathvariant="normal" id="alg1.1.m1.2.2" xref="alg1.1.m1.2.2.cmml">…</mi><mo id="alg1.1.m1.7.7.5.12" xref="alg1.1.m1.7.7.6.cmml">,</mo><msubsup id="alg1.1.m1.7.7.5.5" xref="alg1.1.m1.7.7.5.5.cmml"><mi id="alg1.1.m1.7.7.5.5.2.2" xref="alg1.1.m1.7.7.5.5.2.2.cmml">D</mi><mi id="alg1.1.m1.7.7.5.5.2.3" xref="alg1.1.m1.7.7.5.5.2.3.cmml">n</mi><mrow id="alg1.1.m1.7.7.5.5.3" xref="alg1.1.m1.7.7.5.5.3.cmml"><mn id="alg1.1.m1.7.7.5.5.3.2" xref="alg1.1.m1.7.7.5.5.3.2.cmml">0</mn><mo lspace="0.278em" rspace="0.278em" id="alg1.1.m1.7.7.5.5.3.1" xref="alg1.1.m1.7.7.5.5.3.1.cmml">:</mo><mi id="alg1.1.m1.7.7.5.5.3.3" xref="alg1.1.m1.7.7.5.5.3.3.cmml">t</mi></mrow></msubsup><mo stretchy="false" id="alg1.1.m1.7.7.5.13" xref="alg1.1.m1.7.7.6.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.1.m1.7b"><vector id="alg1.1.m1.7.7.6.cmml" xref="alg1.1.m1.7.7.5"><apply id="alg1.1.m1.3.3.1.1.cmml" xref="alg1.1.m1.3.3.1.1"><csymbol cd="ambiguous" id="alg1.1.m1.3.3.1.1.1.cmml" xref="alg1.1.m1.3.3.1.1">superscript</csymbol><apply id="alg1.1.m1.3.3.1.1.2.cmml" xref="alg1.1.m1.3.3.1.1"><csymbol cd="ambiguous" id="alg1.1.m1.3.3.1.1.2.1.cmml" xref="alg1.1.m1.3.3.1.1">subscript</csymbol><ci id="alg1.1.m1.3.3.1.1.2.2.cmml" xref="alg1.1.m1.3.3.1.1.2.2">𝐷</ci><cn type="integer" id="alg1.1.m1.3.3.1.1.2.3.cmml" xref="alg1.1.m1.3.3.1.1.2.3">0</cn></apply><cn type="integer" id="alg1.1.m1.3.3.1.1.3.cmml" xref="alg1.1.m1.3.3.1.1.3">0</cn></apply><apply id="alg1.1.m1.4.4.2.2.cmml" xref="alg1.1.m1.4.4.2.2"><csymbol cd="ambiguous" id="alg1.1.m1.4.4.2.2.1.cmml" xref="alg1.1.m1.4.4.2.2">superscript</csymbol><apply id="alg1.1.m1.4.4.2.2.2.cmml" xref="alg1.1.m1.4.4.2.2"><csymbol cd="ambiguous" id="alg1.1.m1.4.4.2.2.2.1.cmml" xref="alg1.1.m1.4.4.2.2">subscript</csymbol><ci id="alg1.1.m1.4.4.2.2.2.2.cmml" xref="alg1.1.m1.4.4.2.2.2.2">𝐷</ci><cn type="integer" id="alg1.1.m1.4.4.2.2.2.3.cmml" xref="alg1.1.m1.4.4.2.2.2.3">0</cn></apply><cn type="integer" id="alg1.1.m1.4.4.2.2.3.cmml" xref="alg1.1.m1.4.4.2.2.3">1</cn></apply><ci id="alg1.1.m1.1.1.cmml" xref="alg1.1.m1.1.1">…</ci><apply id="alg1.1.m1.5.5.3.3.cmml" xref="alg1.1.m1.5.5.3.3"><csymbol cd="ambiguous" id="alg1.1.m1.5.5.3.3.1.cmml" xref="alg1.1.m1.5.5.3.3">superscript</csymbol><apply id="alg1.1.m1.5.5.3.3.2.cmml" xref="alg1.1.m1.5.5.3.3"><csymbol cd="ambiguous" id="alg1.1.m1.5.5.3.3.2.1.cmml" xref="alg1.1.m1.5.5.3.3">subscript</csymbol><ci id="alg1.1.m1.5.5.3.3.2.2.cmml" xref="alg1.1.m1.5.5.3.3.2.2">𝐷</ci><cn type="integer" id="alg1.1.m1.5.5.3.3.2.3.cmml" xref="alg1.1.m1.5.5.3.3.2.3">1</cn></apply><cn type="integer" id="alg1.1.m1.5.5.3.3.3.cmml" xref="alg1.1.m1.5.5.3.3.3">0</cn></apply><apply id="alg1.1.m1.6.6.4.4.cmml" xref="alg1.1.m1.6.6.4.4"><csymbol cd="ambiguous" id="alg1.1.m1.6.6.4.4.1.cmml" xref="alg1.1.m1.6.6.4.4">superscript</csymbol><apply id="alg1.1.m1.6.6.4.4.2.cmml" xref="alg1.1.m1.6.6.4.4"><csymbol cd="ambiguous" id="alg1.1.m1.6.6.4.4.2.1.cmml" xref="alg1.1.m1.6.6.4.4">subscript</csymbol><ci id="alg1.1.m1.6.6.4.4.2.2.cmml" xref="alg1.1.m1.6.6.4.4.2.2">𝐷</ci><cn type="integer" id="alg1.1.m1.6.6.4.4.2.3.cmml" xref="alg1.1.m1.6.6.4.4.2.3">1</cn></apply><cn type="integer" id="alg1.1.m1.6.6.4.4.3.cmml" xref="alg1.1.m1.6.6.4.4.3">1</cn></apply><ci id="alg1.1.m1.2.2.cmml" xref="alg1.1.m1.2.2">…</ci><apply id="alg1.1.m1.7.7.5.5.cmml" xref="alg1.1.m1.7.7.5.5"><csymbol cd="ambiguous" id="alg1.1.m1.7.7.5.5.1.cmml" xref="alg1.1.m1.7.7.5.5">superscript</csymbol><apply id="alg1.1.m1.7.7.5.5.2.cmml" xref="alg1.1.m1.7.7.5.5"><csymbol cd="ambiguous" id="alg1.1.m1.7.7.5.5.2.1.cmml" xref="alg1.1.m1.7.7.5.5">subscript</csymbol><ci id="alg1.1.m1.7.7.5.5.2.2.cmml" xref="alg1.1.m1.7.7.5.5.2.2">𝐷</ci><ci id="alg1.1.m1.7.7.5.5.2.3.cmml" xref="alg1.1.m1.7.7.5.5.2.3">𝑛</ci></apply><apply id="alg1.1.m1.7.7.5.5.3.cmml" xref="alg1.1.m1.7.7.5.5.3"><ci id="alg1.1.m1.7.7.5.5.3.1.cmml" xref="alg1.1.m1.7.7.5.5.3.1">:</ci><cn type="integer" id="alg1.1.m1.7.7.5.5.3.2.cmml" xref="alg1.1.m1.7.7.5.5.3.2">0</cn><ci id="alg1.1.m1.7.7.5.5.3.3.cmml" xref="alg1.1.m1.7.7.5.5.3.3">𝑡</ci></apply></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.m1.7c">(D_{0}^{0},D_{0}^{1},...,D_{1}^{0},D_{1}^{1},...,D_{n}^{0:t})</annotation></semantics></math>, where "<math id="alg1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="alg1.2.m2.1a"><mi id="alg1.2.m2.1.1" xref="alg1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="alg1.2.m2.1b"><ci id="alg1.2.m2.1.1.cmml" xref="alg1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.m2.1c">t</annotation></semantics></math>" refers to the number of tasks, "<math id="alg1.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="alg1.3.m3.1a"><mi id="alg1.3.m3.1.1" xref="alg1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg1.3.m3.1b"><ci id="alg1.3.m3.1.1.cmml" xref="alg1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.m3.1c">n</annotation></semantics></math>" refers to the number of domains.
<br class="ltx_break"><span id="alg1.19.2" class="ltx_text ltx_font_bold">Models:</span> Feature extractor <math id="alg1.4.m4.2" class="ltx_Math" alttext="f_{e}(x;\theta_{e})" display="inline"><semantics id="alg1.4.m4.2a"><mrow id="alg1.4.m4.2.2" xref="alg1.4.m4.2.2.cmml"><msub id="alg1.4.m4.2.2.3" xref="alg1.4.m4.2.2.3.cmml"><mi id="alg1.4.m4.2.2.3.2" xref="alg1.4.m4.2.2.3.2.cmml">f</mi><mi id="alg1.4.m4.2.2.3.3" xref="alg1.4.m4.2.2.3.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="alg1.4.m4.2.2.2" xref="alg1.4.m4.2.2.2.cmml">​</mo><mrow id="alg1.4.m4.2.2.1.1" xref="alg1.4.m4.2.2.1.2.cmml"><mo stretchy="false" id="alg1.4.m4.2.2.1.1.2" xref="alg1.4.m4.2.2.1.2.cmml">(</mo><mi id="alg1.4.m4.1.1" xref="alg1.4.m4.1.1.cmml">x</mi><mo id="alg1.4.m4.2.2.1.1.3" xref="alg1.4.m4.2.2.1.2.cmml">;</mo><msub id="alg1.4.m4.2.2.1.1.1" xref="alg1.4.m4.2.2.1.1.1.cmml"><mi id="alg1.4.m4.2.2.1.1.1.2" xref="alg1.4.m4.2.2.1.1.1.2.cmml">θ</mi><mi id="alg1.4.m4.2.2.1.1.1.3" xref="alg1.4.m4.2.2.1.1.1.3.cmml">e</mi></msub><mo stretchy="false" id="alg1.4.m4.2.2.1.1.4" xref="alg1.4.m4.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.4.m4.2b"><apply id="alg1.4.m4.2.2.cmml" xref="alg1.4.m4.2.2"><times id="alg1.4.m4.2.2.2.cmml" xref="alg1.4.m4.2.2.2"></times><apply id="alg1.4.m4.2.2.3.cmml" xref="alg1.4.m4.2.2.3"><csymbol cd="ambiguous" id="alg1.4.m4.2.2.3.1.cmml" xref="alg1.4.m4.2.2.3">subscript</csymbol><ci id="alg1.4.m4.2.2.3.2.cmml" xref="alg1.4.m4.2.2.3.2">𝑓</ci><ci id="alg1.4.m4.2.2.3.3.cmml" xref="alg1.4.m4.2.2.3.3">𝑒</ci></apply><list id="alg1.4.m4.2.2.1.2.cmml" xref="alg1.4.m4.2.2.1.1"><ci id="alg1.4.m4.1.1.cmml" xref="alg1.4.m4.1.1">𝑥</ci><apply id="alg1.4.m4.2.2.1.1.1.cmml" xref="alg1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.4.m4.2.2.1.1.1.1.cmml" xref="alg1.4.m4.2.2.1.1.1">subscript</csymbol><ci id="alg1.4.m4.2.2.1.1.1.2.cmml" xref="alg1.4.m4.2.2.1.1.1.2">𝜃</ci><ci id="alg1.4.m4.2.2.1.1.1.3.cmml" xref="alg1.4.m4.2.2.1.1.1.3">𝑒</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.m4.2c">f_{e}(x;\theta_{e})</annotation></semantics></math>, exFeCAM model <math id="alg1.5.m5.3" class="ltx_Math" alttext="\phi(x;\mu,\Sigma)" display="inline"><semantics id="alg1.5.m5.3a"><mrow id="alg1.5.m5.3.4" xref="alg1.5.m5.3.4.cmml"><mi id="alg1.5.m5.3.4.2" xref="alg1.5.m5.3.4.2.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="alg1.5.m5.3.4.1" xref="alg1.5.m5.3.4.1.cmml">​</mo><mrow id="alg1.5.m5.3.4.3.2" xref="alg1.5.m5.3.4.3.1.cmml"><mo stretchy="false" id="alg1.5.m5.3.4.3.2.1" xref="alg1.5.m5.3.4.3.1.cmml">(</mo><mi id="alg1.5.m5.1.1" xref="alg1.5.m5.1.1.cmml">x</mi><mo id="alg1.5.m5.3.4.3.2.2" xref="alg1.5.m5.3.4.3.1.cmml">;</mo><mi id="alg1.5.m5.2.2" xref="alg1.5.m5.2.2.cmml">μ</mi><mo id="alg1.5.m5.3.4.3.2.3" xref="alg1.5.m5.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.5.m5.3.3" xref="alg1.5.m5.3.3.cmml">Σ</mi><mo stretchy="false" id="alg1.5.m5.3.4.3.2.4" xref="alg1.5.m5.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.5.m5.3b"><apply id="alg1.5.m5.3.4.cmml" xref="alg1.5.m5.3.4"><times id="alg1.5.m5.3.4.1.cmml" xref="alg1.5.m5.3.4.1"></times><ci id="alg1.5.m5.3.4.2.cmml" xref="alg1.5.m5.3.4.2">italic-ϕ</ci><list id="alg1.5.m5.3.4.3.1.cmml" xref="alg1.5.m5.3.4.3.2"><ci id="alg1.5.m5.1.1.cmml" xref="alg1.5.m5.1.1">𝑥</ci><ci id="alg1.5.m5.2.2.cmml" xref="alg1.5.m5.2.2">𝜇</ci><ci id="alg1.5.m5.3.3.cmml" xref="alg1.5.m5.3.3">Σ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.m5.3c">\phi(x;\mu,\Sigma)</annotation></semantics></math>
<br class="ltx_break"><span id="alg1.19.3" class="ltx_text ltx_font_bold">Variables:</span> <math id="alg1.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.6.m6.1a"><mi id="alg1.6.m6.1.1" xref="alg1.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.6.m6.1b"><ci id="alg1.6.m6.1.1.cmml" xref="alg1.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.m6.1c">k</annotation></semantics></math> : number of layers of feature extractor, <math id="alg1.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="alg1.7.m7.1a"><mi id="alg1.7.m7.1.1" xref="alg1.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="alg1.7.m7.1b"><ci id="alg1.7.m7.1.1.cmml" xref="alg1.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.m7.1c">t</annotation></semantics></math>: total tasks, <math id="alg1.8.m8.1" class="ltx_Math" alttext="n" display="inline"><semantics id="alg1.8.m8.1a"><mi id="alg1.8.m8.1.1" xref="alg1.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg1.8.m8.1b"><ci id="alg1.8.m8.1.1.cmml" xref="alg1.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.m8.1c">n</annotation></semantics></math>: number of domains, <math id="alg1.9.m9.1" class="ltx_Math" alttext="T" display="inline"><semantics id="alg1.9.m9.1a"><mi id="alg1.9.m9.1.1" xref="alg1.9.m9.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.9.m9.1b"><ci id="alg1.9.m9.1.1.cmml" xref="alg1.9.m9.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.m9.1c">T</annotation></semantics></math>: total classes; <math id="alg1.10.m10.1" class="ltx_Math" alttext="b" display="inline"><semantics id="alg1.10.m10.1a"><mi id="alg1.10.m10.1.1" xref="alg1.10.m10.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="alg1.10.m10.1b"><ci id="alg1.10.m10.1.1.cmml" xref="alg1.10.m10.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.m10.1c">b</annotation></semantics></math>: batch size; <math id="alg1.11.m11.2" class="ltx_Math" alttext="l,j" display="inline"><semantics id="alg1.11.m11.2a"><mrow id="alg1.11.m11.2.3.2" xref="alg1.11.m11.2.3.1.cmml"><mi id="alg1.11.m11.1.1" xref="alg1.11.m11.1.1.cmml">l</mi><mo id="alg1.11.m11.2.3.2.1" xref="alg1.11.m11.2.3.1.cmml">,</mo><mi id="alg1.11.m11.2.2" xref="alg1.11.m11.2.2.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.11.m11.2b"><list id="alg1.11.m11.2.3.1.cmml" xref="alg1.11.m11.2.3.2"><ci id="alg1.11.m11.1.1.cmml" xref="alg1.11.m11.1.1">𝑙</ci><ci id="alg1.11.m11.2.2.cmml" xref="alg1.11.m11.2.2">𝑗</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.11.m11.2c">l,j</annotation></semantics></math> : iterative variables
<br class="ltx_break"><math id="alg1.12.m12.2" class="ltx_Math" alttext="(x_{i},y_{i})\in D_{train}^{Supervised}" display="inline"><semantics id="alg1.12.m12.2a"><mrow id="alg1.12.m12.2.2" xref="alg1.12.m12.2.2.cmml"><mrow id="alg1.12.m12.2.2.2.2" xref="alg1.12.m12.2.2.2.3.cmml"><mo stretchy="false" id="alg1.12.m12.2.2.2.2.3" xref="alg1.12.m12.2.2.2.3.cmml">(</mo><msub id="alg1.12.m12.1.1.1.1.1" xref="alg1.12.m12.1.1.1.1.1.cmml"><mi id="alg1.12.m12.1.1.1.1.1.2" xref="alg1.12.m12.1.1.1.1.1.2.cmml">x</mi><mi id="alg1.12.m12.1.1.1.1.1.3" xref="alg1.12.m12.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.12.m12.2.2.2.2.4" xref="alg1.12.m12.2.2.2.3.cmml">,</mo><msub id="alg1.12.m12.2.2.2.2.2" xref="alg1.12.m12.2.2.2.2.2.cmml"><mi id="alg1.12.m12.2.2.2.2.2.2" xref="alg1.12.m12.2.2.2.2.2.2.cmml">y</mi><mi id="alg1.12.m12.2.2.2.2.2.3" xref="alg1.12.m12.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.12.m12.2.2.2.2.5" xref="alg1.12.m12.2.2.2.3.cmml">)</mo></mrow><mo id="alg1.12.m12.2.2.3" xref="alg1.12.m12.2.2.3.cmml">∈</mo><msubsup id="alg1.12.m12.2.2.4" xref="alg1.12.m12.2.2.4.cmml"><mi id="alg1.12.m12.2.2.4.2.2" xref="alg1.12.m12.2.2.4.2.2.cmml">D</mi><mrow id="alg1.12.m12.2.2.4.2.3" xref="alg1.12.m12.2.2.4.2.3.cmml"><mi id="alg1.12.m12.2.2.4.2.3.2" xref="alg1.12.m12.2.2.4.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.2.3.1" xref="alg1.12.m12.2.2.4.2.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.2.3.3" xref="alg1.12.m12.2.2.4.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.2.3.1a" xref="alg1.12.m12.2.2.4.2.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.2.3.4" xref="alg1.12.m12.2.2.4.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.2.3.1b" xref="alg1.12.m12.2.2.4.2.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.2.3.5" xref="alg1.12.m12.2.2.4.2.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.2.3.1c" xref="alg1.12.m12.2.2.4.2.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.2.3.6" xref="alg1.12.m12.2.2.4.2.3.6.cmml">n</mi></mrow><mrow id="alg1.12.m12.2.2.4.3" xref="alg1.12.m12.2.2.4.3.cmml"><mi id="alg1.12.m12.2.2.4.3.2" xref="alg1.12.m12.2.2.4.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.3" xref="alg1.12.m12.2.2.4.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1a" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.4" xref="alg1.12.m12.2.2.4.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1b" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.5" xref="alg1.12.m12.2.2.4.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1c" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.6" xref="alg1.12.m12.2.2.4.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1d" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.7" xref="alg1.12.m12.2.2.4.3.7.cmml">v</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1e" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.8" xref="alg1.12.m12.2.2.4.3.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1f" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.9" xref="alg1.12.m12.2.2.4.3.9.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1g" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.10" xref="alg1.12.m12.2.2.4.3.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.12.m12.2.2.4.3.1h" xref="alg1.12.m12.2.2.4.3.1.cmml">​</mo><mi id="alg1.12.m12.2.2.4.3.11" xref="alg1.12.m12.2.2.4.3.11.cmml">d</mi></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.12.m12.2b"><apply id="alg1.12.m12.2.2.cmml" xref="alg1.12.m12.2.2"><in id="alg1.12.m12.2.2.3.cmml" xref="alg1.12.m12.2.2.3"></in><interval closure="open" id="alg1.12.m12.2.2.2.3.cmml" xref="alg1.12.m12.2.2.2.2"><apply id="alg1.12.m12.1.1.1.1.1.cmml" xref="alg1.12.m12.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.12.m12.1.1.1.1.1.1.cmml" xref="alg1.12.m12.1.1.1.1.1">subscript</csymbol><ci id="alg1.12.m12.1.1.1.1.1.2.cmml" xref="alg1.12.m12.1.1.1.1.1.2">𝑥</ci><ci id="alg1.12.m12.1.1.1.1.1.3.cmml" xref="alg1.12.m12.1.1.1.1.1.3">𝑖</ci></apply><apply id="alg1.12.m12.2.2.2.2.2.cmml" xref="alg1.12.m12.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.12.m12.2.2.2.2.2.1.cmml" xref="alg1.12.m12.2.2.2.2.2">subscript</csymbol><ci id="alg1.12.m12.2.2.2.2.2.2.cmml" xref="alg1.12.m12.2.2.2.2.2.2">𝑦</ci><ci id="alg1.12.m12.2.2.2.2.2.3.cmml" xref="alg1.12.m12.2.2.2.2.2.3">𝑖</ci></apply></interval><apply id="alg1.12.m12.2.2.4.cmml" xref="alg1.12.m12.2.2.4"><csymbol cd="ambiguous" id="alg1.12.m12.2.2.4.1.cmml" xref="alg1.12.m12.2.2.4">superscript</csymbol><apply id="alg1.12.m12.2.2.4.2.cmml" xref="alg1.12.m12.2.2.4"><csymbol cd="ambiguous" id="alg1.12.m12.2.2.4.2.1.cmml" xref="alg1.12.m12.2.2.4">subscript</csymbol><ci id="alg1.12.m12.2.2.4.2.2.cmml" xref="alg1.12.m12.2.2.4.2.2">𝐷</ci><apply id="alg1.12.m12.2.2.4.2.3.cmml" xref="alg1.12.m12.2.2.4.2.3"><times id="alg1.12.m12.2.2.4.2.3.1.cmml" xref="alg1.12.m12.2.2.4.2.3.1"></times><ci id="alg1.12.m12.2.2.4.2.3.2.cmml" xref="alg1.12.m12.2.2.4.2.3.2">𝑡</ci><ci id="alg1.12.m12.2.2.4.2.3.3.cmml" xref="alg1.12.m12.2.2.4.2.3.3">𝑟</ci><ci id="alg1.12.m12.2.2.4.2.3.4.cmml" xref="alg1.12.m12.2.2.4.2.3.4">𝑎</ci><ci id="alg1.12.m12.2.2.4.2.3.5.cmml" xref="alg1.12.m12.2.2.4.2.3.5">𝑖</ci><ci id="alg1.12.m12.2.2.4.2.3.6.cmml" xref="alg1.12.m12.2.2.4.2.3.6">𝑛</ci></apply></apply><apply id="alg1.12.m12.2.2.4.3.cmml" xref="alg1.12.m12.2.2.4.3"><times id="alg1.12.m12.2.2.4.3.1.cmml" xref="alg1.12.m12.2.2.4.3.1"></times><ci id="alg1.12.m12.2.2.4.3.2.cmml" xref="alg1.12.m12.2.2.4.3.2">𝑆</ci><ci id="alg1.12.m12.2.2.4.3.3.cmml" xref="alg1.12.m12.2.2.4.3.3">𝑢</ci><ci id="alg1.12.m12.2.2.4.3.4.cmml" xref="alg1.12.m12.2.2.4.3.4">𝑝</ci><ci id="alg1.12.m12.2.2.4.3.5.cmml" xref="alg1.12.m12.2.2.4.3.5">𝑒</ci><ci id="alg1.12.m12.2.2.4.3.6.cmml" xref="alg1.12.m12.2.2.4.3.6">𝑟</ci><ci id="alg1.12.m12.2.2.4.3.7.cmml" xref="alg1.12.m12.2.2.4.3.7">𝑣</ci><ci id="alg1.12.m12.2.2.4.3.8.cmml" xref="alg1.12.m12.2.2.4.3.8">𝑖</ci><ci id="alg1.12.m12.2.2.4.3.9.cmml" xref="alg1.12.m12.2.2.4.3.9">𝑠</ci><ci id="alg1.12.m12.2.2.4.3.10.cmml" xref="alg1.12.m12.2.2.4.3.10">𝑒</ci><ci id="alg1.12.m12.2.2.4.3.11.cmml" xref="alg1.12.m12.2.2.4.3.11">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.12.m12.2c">(x_{i},y_{i})\in D_{train}^{Supervised}</annotation></semantics></math>, <math id="alg1.13.m13.1" class="ltx_Math" alttext="(x_{i}^{{}^{\prime}})\in D_{train}^{Unsupervised}" display="inline"><semantics id="alg1.13.m13.1a"><mrow id="alg1.13.m13.1.1" xref="alg1.13.m13.1.1.cmml"><mrow id="alg1.13.m13.1.1.1.1" xref="alg1.13.m13.1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.13.m13.1.1.1.1.2" xref="alg1.13.m13.1.1.1.1.1.cmml">(</mo><msubsup id="alg1.13.m13.1.1.1.1.1" xref="alg1.13.m13.1.1.1.1.1.cmml"><mi id="alg1.13.m13.1.1.1.1.1.2.2" xref="alg1.13.m13.1.1.1.1.1.2.2.cmml">x</mi><mi id="alg1.13.m13.1.1.1.1.1.2.3" xref="alg1.13.m13.1.1.1.1.1.2.3.cmml">i</mi><msup id="alg1.13.m13.1.1.1.1.1.3" xref="alg1.13.m13.1.1.1.1.1.3.cmml"><mi id="alg1.13.m13.1.1.1.1.1.3a" xref="alg1.13.m13.1.1.1.1.1.3.cmml"></mi><mo id="alg1.13.m13.1.1.1.1.1.3.1" xref="alg1.13.m13.1.1.1.1.1.3.1.cmml">′</mo></msup></msubsup><mo stretchy="false" id="alg1.13.m13.1.1.1.1.3" xref="alg1.13.m13.1.1.1.1.1.cmml">)</mo></mrow><mo id="alg1.13.m13.1.1.2" xref="alg1.13.m13.1.1.2.cmml">∈</mo><msubsup id="alg1.13.m13.1.1.3" xref="alg1.13.m13.1.1.3.cmml"><mi id="alg1.13.m13.1.1.3.2.2" xref="alg1.13.m13.1.1.3.2.2.cmml">D</mi><mrow id="alg1.13.m13.1.1.3.2.3" xref="alg1.13.m13.1.1.3.2.3.cmml"><mi id="alg1.13.m13.1.1.3.2.3.2" xref="alg1.13.m13.1.1.3.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.2.3.1" xref="alg1.13.m13.1.1.3.2.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.2.3.3" xref="alg1.13.m13.1.1.3.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.2.3.1a" xref="alg1.13.m13.1.1.3.2.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.2.3.4" xref="alg1.13.m13.1.1.3.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.2.3.1b" xref="alg1.13.m13.1.1.3.2.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.2.3.5" xref="alg1.13.m13.1.1.3.2.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.2.3.1c" xref="alg1.13.m13.1.1.3.2.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.2.3.6" xref="alg1.13.m13.1.1.3.2.3.6.cmml">n</mi></mrow><mrow id="alg1.13.m13.1.1.3.3" xref="alg1.13.m13.1.1.3.3.cmml"><mi id="alg1.13.m13.1.1.3.3.2" xref="alg1.13.m13.1.1.3.3.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.3" xref="alg1.13.m13.1.1.3.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1a" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.4" xref="alg1.13.m13.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1b" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.5" xref="alg1.13.m13.1.1.3.3.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1c" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.6" xref="alg1.13.m13.1.1.3.3.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1d" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.7" xref="alg1.13.m13.1.1.3.3.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1e" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.8" xref="alg1.13.m13.1.1.3.3.8.cmml">r</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1f" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.9" xref="alg1.13.m13.1.1.3.3.9.cmml">v</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1g" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.10" xref="alg1.13.m13.1.1.3.3.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1h" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.11" xref="alg1.13.m13.1.1.3.3.11.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1i" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.12" xref="alg1.13.m13.1.1.3.3.12.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.13.m13.1.1.3.3.1j" xref="alg1.13.m13.1.1.3.3.1.cmml">​</mo><mi id="alg1.13.m13.1.1.3.3.13" xref="alg1.13.m13.1.1.3.3.13.cmml">d</mi></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.13.m13.1b"><apply id="alg1.13.m13.1.1.cmml" xref="alg1.13.m13.1.1"><in id="alg1.13.m13.1.1.2.cmml" xref="alg1.13.m13.1.1.2"></in><apply id="alg1.13.m13.1.1.1.1.1.cmml" xref="alg1.13.m13.1.1.1.1"><csymbol cd="ambiguous" id="alg1.13.m13.1.1.1.1.1.1.cmml" xref="alg1.13.m13.1.1.1.1">superscript</csymbol><apply id="alg1.13.m13.1.1.1.1.1.2.cmml" xref="alg1.13.m13.1.1.1.1"><csymbol cd="ambiguous" id="alg1.13.m13.1.1.1.1.1.2.1.cmml" xref="alg1.13.m13.1.1.1.1">subscript</csymbol><ci id="alg1.13.m13.1.1.1.1.1.2.2.cmml" xref="alg1.13.m13.1.1.1.1.1.2.2">𝑥</ci><ci id="alg1.13.m13.1.1.1.1.1.2.3.cmml" xref="alg1.13.m13.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="alg1.13.m13.1.1.1.1.1.3.cmml" xref="alg1.13.m13.1.1.1.1.1.3"><ci id="alg1.13.m13.1.1.1.1.1.3.1.cmml" xref="alg1.13.m13.1.1.1.1.1.3.1">′</ci></apply></apply><apply id="alg1.13.m13.1.1.3.cmml" xref="alg1.13.m13.1.1.3"><csymbol cd="ambiguous" id="alg1.13.m13.1.1.3.1.cmml" xref="alg1.13.m13.1.1.3">superscript</csymbol><apply id="alg1.13.m13.1.1.3.2.cmml" xref="alg1.13.m13.1.1.3"><csymbol cd="ambiguous" id="alg1.13.m13.1.1.3.2.1.cmml" xref="alg1.13.m13.1.1.3">subscript</csymbol><ci id="alg1.13.m13.1.1.3.2.2.cmml" xref="alg1.13.m13.1.1.3.2.2">𝐷</ci><apply id="alg1.13.m13.1.1.3.2.3.cmml" xref="alg1.13.m13.1.1.3.2.3"><times id="alg1.13.m13.1.1.3.2.3.1.cmml" xref="alg1.13.m13.1.1.3.2.3.1"></times><ci id="alg1.13.m13.1.1.3.2.3.2.cmml" xref="alg1.13.m13.1.1.3.2.3.2">𝑡</ci><ci id="alg1.13.m13.1.1.3.2.3.3.cmml" xref="alg1.13.m13.1.1.3.2.3.3">𝑟</ci><ci id="alg1.13.m13.1.1.3.2.3.4.cmml" xref="alg1.13.m13.1.1.3.2.3.4">𝑎</ci><ci id="alg1.13.m13.1.1.3.2.3.5.cmml" xref="alg1.13.m13.1.1.3.2.3.5">𝑖</ci><ci id="alg1.13.m13.1.1.3.2.3.6.cmml" xref="alg1.13.m13.1.1.3.2.3.6">𝑛</ci></apply></apply><apply id="alg1.13.m13.1.1.3.3.cmml" xref="alg1.13.m13.1.1.3.3"><times id="alg1.13.m13.1.1.3.3.1.cmml" xref="alg1.13.m13.1.1.3.3.1"></times><ci id="alg1.13.m13.1.1.3.3.2.cmml" xref="alg1.13.m13.1.1.3.3.2">𝑈</ci><ci id="alg1.13.m13.1.1.3.3.3.cmml" xref="alg1.13.m13.1.1.3.3.3">𝑛</ci><ci id="alg1.13.m13.1.1.3.3.4.cmml" xref="alg1.13.m13.1.1.3.3.4">𝑠</ci><ci id="alg1.13.m13.1.1.3.3.5.cmml" xref="alg1.13.m13.1.1.3.3.5">𝑢</ci><ci id="alg1.13.m13.1.1.3.3.6.cmml" xref="alg1.13.m13.1.1.3.3.6">𝑝</ci><ci id="alg1.13.m13.1.1.3.3.7.cmml" xref="alg1.13.m13.1.1.3.3.7">𝑒</ci><ci id="alg1.13.m13.1.1.3.3.8.cmml" xref="alg1.13.m13.1.1.3.3.8">𝑟</ci><ci id="alg1.13.m13.1.1.3.3.9.cmml" xref="alg1.13.m13.1.1.3.3.9">𝑣</ci><ci id="alg1.13.m13.1.1.3.3.10.cmml" xref="alg1.13.m13.1.1.3.3.10">𝑖</ci><ci id="alg1.13.m13.1.1.3.3.11.cmml" xref="alg1.13.m13.1.1.3.3.11">𝑠</ci><ci id="alg1.13.m13.1.1.3.3.12.cmml" xref="alg1.13.m13.1.1.3.3.12">𝑒</ci><ci id="alg1.13.m13.1.1.3.3.13.cmml" xref="alg1.13.m13.1.1.3.3.13">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.13.m13.1c">(x_{i}^{{}^{\prime}})\in D_{train}^{Unsupervised}</annotation></semantics></math> , <math id="alg1.14.m14.2" class="ltx_Math" alttext="(x_{i}^{{}^{\prime\prime}},y_{i}^{{}^{\prime\prime}})\in D_{test}" display="inline"><semantics id="alg1.14.m14.2a"><mrow id="alg1.14.m14.2.2" xref="alg1.14.m14.2.2.cmml"><mrow id="alg1.14.m14.2.2.2.2" xref="alg1.14.m14.2.2.2.3.cmml"><mo stretchy="false" id="alg1.14.m14.2.2.2.2.3" xref="alg1.14.m14.2.2.2.3.cmml">(</mo><msubsup id="alg1.14.m14.1.1.1.1.1" xref="alg1.14.m14.1.1.1.1.1.cmml"><mi id="alg1.14.m14.1.1.1.1.1.2.2" xref="alg1.14.m14.1.1.1.1.1.2.2.cmml">x</mi><mi id="alg1.14.m14.1.1.1.1.1.2.3" xref="alg1.14.m14.1.1.1.1.1.2.3.cmml">i</mi><msup id="alg1.14.m14.1.1.1.1.1.3" xref="alg1.14.m14.1.1.1.1.1.3.cmml"><mi id="alg1.14.m14.1.1.1.1.1.3a" xref="alg1.14.m14.1.1.1.1.1.3.cmml"></mi><mo id="alg1.14.m14.1.1.1.1.1.3.1" xref="alg1.14.m14.1.1.1.1.1.3.1.cmml">′′</mo></msup></msubsup><mo id="alg1.14.m14.2.2.2.2.4" xref="alg1.14.m14.2.2.2.3.cmml">,</mo><msubsup id="alg1.14.m14.2.2.2.2.2" xref="alg1.14.m14.2.2.2.2.2.cmml"><mi id="alg1.14.m14.2.2.2.2.2.2.2" xref="alg1.14.m14.2.2.2.2.2.2.2.cmml">y</mi><mi id="alg1.14.m14.2.2.2.2.2.2.3" xref="alg1.14.m14.2.2.2.2.2.2.3.cmml">i</mi><msup id="alg1.14.m14.2.2.2.2.2.3" xref="alg1.14.m14.2.2.2.2.2.3.cmml"><mi id="alg1.14.m14.2.2.2.2.2.3a" xref="alg1.14.m14.2.2.2.2.2.3.cmml"></mi><mo id="alg1.14.m14.2.2.2.2.2.3.1" xref="alg1.14.m14.2.2.2.2.2.3.1.cmml">′′</mo></msup></msubsup><mo stretchy="false" id="alg1.14.m14.2.2.2.2.5" xref="alg1.14.m14.2.2.2.3.cmml">)</mo></mrow><mo id="alg1.14.m14.2.2.3" xref="alg1.14.m14.2.2.3.cmml">∈</mo><msub id="alg1.14.m14.2.2.4" xref="alg1.14.m14.2.2.4.cmml"><mi id="alg1.14.m14.2.2.4.2" xref="alg1.14.m14.2.2.4.2.cmml">D</mi><mrow id="alg1.14.m14.2.2.4.3" xref="alg1.14.m14.2.2.4.3.cmml"><mi id="alg1.14.m14.2.2.4.3.2" xref="alg1.14.m14.2.2.4.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.14.m14.2.2.4.3.1" xref="alg1.14.m14.2.2.4.3.1.cmml">​</mo><mi id="alg1.14.m14.2.2.4.3.3" xref="alg1.14.m14.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.14.m14.2.2.4.3.1a" xref="alg1.14.m14.2.2.4.3.1.cmml">​</mo><mi id="alg1.14.m14.2.2.4.3.4" xref="alg1.14.m14.2.2.4.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.14.m14.2.2.4.3.1b" xref="alg1.14.m14.2.2.4.3.1.cmml">​</mo><mi id="alg1.14.m14.2.2.4.3.5" xref="alg1.14.m14.2.2.4.3.5.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.14.m14.2b"><apply id="alg1.14.m14.2.2.cmml" xref="alg1.14.m14.2.2"><in id="alg1.14.m14.2.2.3.cmml" xref="alg1.14.m14.2.2.3"></in><interval closure="open" id="alg1.14.m14.2.2.2.3.cmml" xref="alg1.14.m14.2.2.2.2"><apply id="alg1.14.m14.1.1.1.1.1.cmml" xref="alg1.14.m14.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.14.m14.1.1.1.1.1.1.cmml" xref="alg1.14.m14.1.1.1.1.1">superscript</csymbol><apply id="alg1.14.m14.1.1.1.1.1.2.cmml" xref="alg1.14.m14.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.14.m14.1.1.1.1.1.2.1.cmml" xref="alg1.14.m14.1.1.1.1.1">subscript</csymbol><ci id="alg1.14.m14.1.1.1.1.1.2.2.cmml" xref="alg1.14.m14.1.1.1.1.1.2.2">𝑥</ci><ci id="alg1.14.m14.1.1.1.1.1.2.3.cmml" xref="alg1.14.m14.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="alg1.14.m14.1.1.1.1.1.3.cmml" xref="alg1.14.m14.1.1.1.1.1.3"><ci id="alg1.14.m14.1.1.1.1.1.3.1.cmml" xref="alg1.14.m14.1.1.1.1.1.3.1">′′</ci></apply></apply><apply id="alg1.14.m14.2.2.2.2.2.cmml" xref="alg1.14.m14.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.14.m14.2.2.2.2.2.1.cmml" xref="alg1.14.m14.2.2.2.2.2">superscript</csymbol><apply id="alg1.14.m14.2.2.2.2.2.2.cmml" xref="alg1.14.m14.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.14.m14.2.2.2.2.2.2.1.cmml" xref="alg1.14.m14.2.2.2.2.2">subscript</csymbol><ci id="alg1.14.m14.2.2.2.2.2.2.2.cmml" xref="alg1.14.m14.2.2.2.2.2.2.2">𝑦</ci><ci id="alg1.14.m14.2.2.2.2.2.2.3.cmml" xref="alg1.14.m14.2.2.2.2.2.2.3">𝑖</ci></apply><apply id="alg1.14.m14.2.2.2.2.2.3.cmml" xref="alg1.14.m14.2.2.2.2.2.3"><ci id="alg1.14.m14.2.2.2.2.2.3.1.cmml" xref="alg1.14.m14.2.2.2.2.2.3.1">′′</ci></apply></apply></interval><apply id="alg1.14.m14.2.2.4.cmml" xref="alg1.14.m14.2.2.4"><csymbol cd="ambiguous" id="alg1.14.m14.2.2.4.1.cmml" xref="alg1.14.m14.2.2.4">subscript</csymbol><ci id="alg1.14.m14.2.2.4.2.cmml" xref="alg1.14.m14.2.2.4.2">𝐷</ci><apply id="alg1.14.m14.2.2.4.3.cmml" xref="alg1.14.m14.2.2.4.3"><times id="alg1.14.m14.2.2.4.3.1.cmml" xref="alg1.14.m14.2.2.4.3.1"></times><ci id="alg1.14.m14.2.2.4.3.2.cmml" xref="alg1.14.m14.2.2.4.3.2">𝑡</ci><ci id="alg1.14.m14.2.2.4.3.3.cmml" xref="alg1.14.m14.2.2.4.3.3">𝑒</ci><ci id="alg1.14.m14.2.2.4.3.4.cmml" xref="alg1.14.m14.2.2.4.3.4">𝑠</ci><ci id="alg1.14.m14.2.2.4.3.5.cmml" xref="alg1.14.m14.2.2.4.3.5">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.14.m14.2c">(x_{i}^{{}^{\prime\prime}},y_{i}^{{}^{\prime\prime}})\in D_{test}</annotation></semantics></math>
<br class="ltx_break"><math id="alg1.15.m15.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="alg1.15.m15.1a"><mi id="alg1.15.m15.1.1" xref="alg1.15.m15.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="alg1.15.m15.1b"><ci id="alg1.15.m15.1.1.cmml" xref="alg1.15.m15.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.15.m15.1c">\mu</annotation></semantics></math>, <math id="alg1.16.m16.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="alg1.16.m16.1a"><mi mathvariant="normal" id="alg1.16.m16.1.1" xref="alg1.16.m16.1.1.cmml">Σ</mi><annotation-xml encoding="MathML-Content" id="alg1.16.m16.1b"><ci id="alg1.16.m16.1.1.cmml" xref="alg1.16.m16.1.1">Σ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.16.m16.1c">\Sigma</annotation></semantics></math> = {}  <math id="alg1.17.m17.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.17.m17.1a"><mo id="alg1.17.m17.1.1" xref="alg1.17.m17.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.17.m17.1b"><ci id="alg1.17.m17.1.1.cmml" xref="alg1.17.m17.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.17.m17.1c">\triangleright</annotation></semantics></math> Initialize <math id="alg1.18.m18.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="alg1.18.m18.1a"><mi id="alg1.18.m18.1.1" xref="alg1.18.m18.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="alg1.18.m18.1b"><ci id="alg1.18.m18.1.1.cmml" xref="alg1.18.m18.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.18.m18.1c">\mu</annotation></semantics></math>, <math id="alg1.19.m19.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="alg1.19.m19.1a"><mi mathvariant="normal" id="alg1.19.m19.1.1" xref="alg1.19.m19.1.1.cmml">Σ</mi><annotation-xml encoding="MathML-Content" id="alg1.19.m19.1b"><ci id="alg1.19.m19.1.1.cmml" xref="alg1.19.m19.1.1">Σ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.19.m19.1c">\Sigma</annotation></semantics></math></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.22" class="ltx_p ltx_figure_panel"><span id="alg1.22.1" class="ltx_text ltx_font_bold ltx_font_italic">Training Phase</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.23" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="algx1.l1" class="ltx_listingline">
<span id="algx1.l1.2" class="ltx_text ltx_font_bold">for</span> <math id="algx1.l1.m1.4" class="ltx_Math" alttext="E_{i}\in[E_{0},E_{1},...,E_{t}]" display="inline"><semantics id="algx1.l1.m1.4a"><mrow id="algx1.l1.m1.4.4" xref="algx1.l1.m1.4.4.cmml"><msub id="algx1.l1.m1.4.4.5" xref="algx1.l1.m1.4.4.5.cmml"><mi id="algx1.l1.m1.4.4.5.2" xref="algx1.l1.m1.4.4.5.2.cmml">E</mi><mi id="algx1.l1.m1.4.4.5.3" xref="algx1.l1.m1.4.4.5.3.cmml">i</mi></msub><mo id="algx1.l1.m1.4.4.4" xref="algx1.l1.m1.4.4.4.cmml">∈</mo><mrow id="algx1.l1.m1.4.4.3.3" xref="algx1.l1.m1.4.4.3.4.cmml"><mo stretchy="false" id="algx1.l1.m1.4.4.3.3.4" xref="algx1.l1.m1.4.4.3.4.cmml">[</mo><msub id="algx1.l1.m1.2.2.1.1.1" xref="algx1.l1.m1.2.2.1.1.1.cmml"><mi id="algx1.l1.m1.2.2.1.1.1.2" xref="algx1.l1.m1.2.2.1.1.1.2.cmml">E</mi><mn id="algx1.l1.m1.2.2.1.1.1.3" xref="algx1.l1.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="algx1.l1.m1.4.4.3.3.5" xref="algx1.l1.m1.4.4.3.4.cmml">,</mo><msub id="algx1.l1.m1.3.3.2.2.2" xref="algx1.l1.m1.3.3.2.2.2.cmml"><mi id="algx1.l1.m1.3.3.2.2.2.2" xref="algx1.l1.m1.3.3.2.2.2.2.cmml">E</mi><mn id="algx1.l1.m1.3.3.2.2.2.3" xref="algx1.l1.m1.3.3.2.2.2.3.cmml">1</mn></msub><mo id="algx1.l1.m1.4.4.3.3.6" xref="algx1.l1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="algx1.l1.m1.1.1" xref="algx1.l1.m1.1.1.cmml">…</mi><mo id="algx1.l1.m1.4.4.3.3.7" xref="algx1.l1.m1.4.4.3.4.cmml">,</mo><msub id="algx1.l1.m1.4.4.3.3.3" xref="algx1.l1.m1.4.4.3.3.3.cmml"><mi id="algx1.l1.m1.4.4.3.3.3.2" xref="algx1.l1.m1.4.4.3.3.3.2.cmml">E</mi><mi id="algx1.l1.m1.4.4.3.3.3.3" xref="algx1.l1.m1.4.4.3.3.3.3.cmml">t</mi></msub><mo stretchy="false" id="algx1.l1.m1.4.4.3.3.8" xref="algx1.l1.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l1.m1.4b"><apply id="algx1.l1.m1.4.4.cmml" xref="algx1.l1.m1.4.4"><in id="algx1.l1.m1.4.4.4.cmml" xref="algx1.l1.m1.4.4.4"></in><apply id="algx1.l1.m1.4.4.5.cmml" xref="algx1.l1.m1.4.4.5"><csymbol cd="ambiguous" id="algx1.l1.m1.4.4.5.1.cmml" xref="algx1.l1.m1.4.4.5">subscript</csymbol><ci id="algx1.l1.m1.4.4.5.2.cmml" xref="algx1.l1.m1.4.4.5.2">𝐸</ci><ci id="algx1.l1.m1.4.4.5.3.cmml" xref="algx1.l1.m1.4.4.5.3">𝑖</ci></apply><list id="algx1.l1.m1.4.4.3.4.cmml" xref="algx1.l1.m1.4.4.3.3"><apply id="algx1.l1.m1.2.2.1.1.1.cmml" xref="algx1.l1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="algx1.l1.m1.2.2.1.1.1.1.cmml" xref="algx1.l1.m1.2.2.1.1.1">subscript</csymbol><ci id="algx1.l1.m1.2.2.1.1.1.2.cmml" xref="algx1.l1.m1.2.2.1.1.1.2">𝐸</ci><cn type="integer" id="algx1.l1.m1.2.2.1.1.1.3.cmml" xref="algx1.l1.m1.2.2.1.1.1.3">0</cn></apply><apply id="algx1.l1.m1.3.3.2.2.2.cmml" xref="algx1.l1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="algx1.l1.m1.3.3.2.2.2.1.cmml" xref="algx1.l1.m1.3.3.2.2.2">subscript</csymbol><ci id="algx1.l1.m1.3.3.2.2.2.2.cmml" xref="algx1.l1.m1.3.3.2.2.2.2">𝐸</ci><cn type="integer" id="algx1.l1.m1.3.3.2.2.2.3.cmml" xref="algx1.l1.m1.3.3.2.2.2.3">1</cn></apply><ci id="algx1.l1.m1.1.1.cmml" xref="algx1.l1.m1.1.1">…</ci><apply id="algx1.l1.m1.4.4.3.3.3.cmml" xref="algx1.l1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="algx1.l1.m1.4.4.3.3.3.1.cmml" xref="algx1.l1.m1.4.4.3.3.3">subscript</csymbol><ci id="algx1.l1.m1.4.4.3.3.3.2.cmml" xref="algx1.l1.m1.4.4.3.3.3.2">𝐸</ci><ci id="algx1.l1.m1.4.4.3.3.3.3.cmml" xref="algx1.l1.m1.4.4.3.3.3.3">𝑡</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l1.m1.4c">E_{i}\in[E_{0},E_{1},...,E_{t}]</annotation></semantics></math> <span id="algx1.l1.3" class="ltx_text ltx_font_bold">do</span> <span id="algx1.l1.1" class="ltx_text" style="float:right;"><math id="algx1.l1.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l1.1.m1.1a"><mo id="algx1.l1.1.m1.1.1" xref="algx1.l1.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l1.1.m1.1b"><ci id="algx1.l1.1.m1.1.1.cmml" xref="algx1.l1.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l1.1.m1.1c">\triangleright</annotation></semantics></math> Different tasks/experiences
</span>
</div>
<div id="algx1.l2" class="ltx_listingline">     Temporary Buffer <math id="algx1.l2.m1.1" class="ltx_Math" alttext="(\epsilon)\leftarrow\{\}" display="inline"><semantics id="algx1.l2.m1.1a"><mrow id="algx1.l2.m1.1.2" xref="algx1.l2.m1.1.2.cmml"><mrow id="algx1.l2.m1.1.2.2.2" xref="algx1.l2.m1.1.2.cmml"><mo stretchy="false" id="algx1.l2.m1.1.2.2.2.1" xref="algx1.l2.m1.1.2.cmml">(</mo><mi id="algx1.l2.m1.1.1" xref="algx1.l2.m1.1.1.cmml">ϵ</mi><mo stretchy="false" id="algx1.l2.m1.1.2.2.2.2" xref="algx1.l2.m1.1.2.cmml">)</mo></mrow><mo stretchy="false" id="algx1.l2.m1.1.2.1" xref="algx1.l2.m1.1.2.1.cmml">←</mo><mrow id="algx1.l2.m1.1.2.3.2" xref="algx1.l2.m1.1.2.cmml"><mo stretchy="false" id="algx1.l2.m1.1.2.3.2.1" xref="algx1.l2.m1.1.2.3.1.cmml">{</mo><mo stretchy="false" id="algx1.l2.m1.1.2.3.2.2" xref="algx1.l2.m1.1.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l2.m1.1b"><apply id="algx1.l2.m1.1.2.cmml" xref="algx1.l2.m1.1.2"><ci id="algx1.l2.m1.1.2.1.cmml" xref="algx1.l2.m1.1.2.1">←</ci><ci id="algx1.l2.m1.1.1.cmml" xref="algx1.l2.m1.1.1">italic-ϵ</ci><list id="algx1.l2.m1.1.2.3.1.cmml" xref="algx1.l2.m1.1.2.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l2.m1.1c">(\epsilon)\leftarrow\{\}</annotation></semantics></math> <span id="algx1.l2.1" class="ltx_text" style="float:right;"><math id="algx1.l2.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l2.1.m1.1a"><mo id="algx1.l2.1.m1.1.1" xref="algx1.l2.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l2.1.m1.1b"><ci id="algx1.l2.1.m1.1.1.cmml" xref="algx1.l2.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l2.1.m1.1c">\triangleright</annotation></semantics></math> Temporary memory buffer for feature matching
</span>
</div>
<div id="algx1.l3" class="ltx_listingline">     <span id="algx1.l3.2" class="ltx_text ltx_font_bold">for</span> <math id="algx1.l3.m1.4" class="ltx_Math" alttext="y_{i}\in[y_{0},y_{1},...,y_{T}]" display="inline"><semantics id="algx1.l3.m1.4a"><mrow id="algx1.l3.m1.4.4" xref="algx1.l3.m1.4.4.cmml"><msub id="algx1.l3.m1.4.4.5" xref="algx1.l3.m1.4.4.5.cmml"><mi id="algx1.l3.m1.4.4.5.2" xref="algx1.l3.m1.4.4.5.2.cmml">y</mi><mi id="algx1.l3.m1.4.4.5.3" xref="algx1.l3.m1.4.4.5.3.cmml">i</mi></msub><mo id="algx1.l3.m1.4.4.4" xref="algx1.l3.m1.4.4.4.cmml">∈</mo><mrow id="algx1.l3.m1.4.4.3.3" xref="algx1.l3.m1.4.4.3.4.cmml"><mo stretchy="false" id="algx1.l3.m1.4.4.3.3.4" xref="algx1.l3.m1.4.4.3.4.cmml">[</mo><msub id="algx1.l3.m1.2.2.1.1.1" xref="algx1.l3.m1.2.2.1.1.1.cmml"><mi id="algx1.l3.m1.2.2.1.1.1.2" xref="algx1.l3.m1.2.2.1.1.1.2.cmml">y</mi><mn id="algx1.l3.m1.2.2.1.1.1.3" xref="algx1.l3.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="algx1.l3.m1.4.4.3.3.5" xref="algx1.l3.m1.4.4.3.4.cmml">,</mo><msub id="algx1.l3.m1.3.3.2.2.2" xref="algx1.l3.m1.3.3.2.2.2.cmml"><mi id="algx1.l3.m1.3.3.2.2.2.2" xref="algx1.l3.m1.3.3.2.2.2.2.cmml">y</mi><mn id="algx1.l3.m1.3.3.2.2.2.3" xref="algx1.l3.m1.3.3.2.2.2.3.cmml">1</mn></msub><mo id="algx1.l3.m1.4.4.3.3.6" xref="algx1.l3.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="algx1.l3.m1.1.1" xref="algx1.l3.m1.1.1.cmml">…</mi><mo id="algx1.l3.m1.4.4.3.3.7" xref="algx1.l3.m1.4.4.3.4.cmml">,</mo><msub id="algx1.l3.m1.4.4.3.3.3" xref="algx1.l3.m1.4.4.3.3.3.cmml"><mi id="algx1.l3.m1.4.4.3.3.3.2" xref="algx1.l3.m1.4.4.3.3.3.2.cmml">y</mi><mi id="algx1.l3.m1.4.4.3.3.3.3" xref="algx1.l3.m1.4.4.3.3.3.3.cmml">T</mi></msub><mo stretchy="false" id="algx1.l3.m1.4.4.3.3.8" xref="algx1.l3.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l3.m1.4b"><apply id="algx1.l3.m1.4.4.cmml" xref="algx1.l3.m1.4.4"><in id="algx1.l3.m1.4.4.4.cmml" xref="algx1.l3.m1.4.4.4"></in><apply id="algx1.l3.m1.4.4.5.cmml" xref="algx1.l3.m1.4.4.5"><csymbol cd="ambiguous" id="algx1.l3.m1.4.4.5.1.cmml" xref="algx1.l3.m1.4.4.5">subscript</csymbol><ci id="algx1.l3.m1.4.4.5.2.cmml" xref="algx1.l3.m1.4.4.5.2">𝑦</ci><ci id="algx1.l3.m1.4.4.5.3.cmml" xref="algx1.l3.m1.4.4.5.3">𝑖</ci></apply><list id="algx1.l3.m1.4.4.3.4.cmml" xref="algx1.l3.m1.4.4.3.3"><apply id="algx1.l3.m1.2.2.1.1.1.cmml" xref="algx1.l3.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="algx1.l3.m1.2.2.1.1.1.1.cmml" xref="algx1.l3.m1.2.2.1.1.1">subscript</csymbol><ci id="algx1.l3.m1.2.2.1.1.1.2.cmml" xref="algx1.l3.m1.2.2.1.1.1.2">𝑦</ci><cn type="integer" id="algx1.l3.m1.2.2.1.1.1.3.cmml" xref="algx1.l3.m1.2.2.1.1.1.3">0</cn></apply><apply id="algx1.l3.m1.3.3.2.2.2.cmml" xref="algx1.l3.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="algx1.l3.m1.3.3.2.2.2.1.cmml" xref="algx1.l3.m1.3.3.2.2.2">subscript</csymbol><ci id="algx1.l3.m1.3.3.2.2.2.2.cmml" xref="algx1.l3.m1.3.3.2.2.2.2">𝑦</ci><cn type="integer" id="algx1.l3.m1.3.3.2.2.2.3.cmml" xref="algx1.l3.m1.3.3.2.2.2.3">1</cn></apply><ci id="algx1.l3.m1.1.1.cmml" xref="algx1.l3.m1.1.1">…</ci><apply id="algx1.l3.m1.4.4.3.3.3.cmml" xref="algx1.l3.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="algx1.l3.m1.4.4.3.3.3.1.cmml" xref="algx1.l3.m1.4.4.3.3.3">subscript</csymbol><ci id="algx1.l3.m1.4.4.3.3.3.2.cmml" xref="algx1.l3.m1.4.4.3.3.3.2">𝑦</ci><ci id="algx1.l3.m1.4.4.3.3.3.3.cmml" xref="algx1.l3.m1.4.4.3.3.3.3">𝑇</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l3.m1.4c">y_{i}\in[y_{0},y_{1},...,y_{T}]</annotation></semantics></math> <span id="algx1.l3.3" class="ltx_text ltx_font_bold">do</span> <span id="algx1.l3.1" class="ltx_text" style="float:right;"><math id="algx1.l3.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l3.1.m1.1a"><mo id="algx1.l3.1.m1.1.1" xref="algx1.l3.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l3.1.m1.1b"><ci id="algx1.l3.1.m1.1.1.cmml" xref="algx1.l3.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l3.1.m1.1c">\triangleright</annotation></semantics></math> Classes in each task
</span>
</div>
<div id="algx1.l4" class="ltx_listingline">         <span id="algx1.l4.2" class="ltx_text ltx_font_bold">for</span> <math id="algx1.l4.m1.1" class="ltx_Math" alttext="j\leftarrow" display="inline"><semantics id="algx1.l4.m1.1a"><mrow id="algx1.l4.m1.1.1" xref="algx1.l4.m1.1.1.cmml"><mi id="algx1.l4.m1.1.1.2" xref="algx1.l4.m1.1.1.2.cmml">j</mi><mo stretchy="false" id="algx1.l4.m1.1.1.1" xref="algx1.l4.m1.1.1.1.cmml">←</mo><mi id="algx1.l4.m1.1.1.3" xref="algx1.l4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algx1.l4.m1.1b"><apply id="algx1.l4.m1.1.1.cmml" xref="algx1.l4.m1.1.1"><ci id="algx1.l4.m1.1.1.1.cmml" xref="algx1.l4.m1.1.1.1">←</ci><ci id="algx1.l4.m1.1.1.2.cmml" xref="algx1.l4.m1.1.1.2">𝑗</ci><csymbol cd="latexml" id="algx1.l4.m1.1.1.3.cmml" xref="algx1.l4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l4.m1.1c">j\leftarrow</annotation></semantics></math><span id="algx1.l4.1" class="ltx_text ltx_font_typewriter"> <math id="algx1.l4.1.m1.1" class="ltx_Math" alttext="b" display="inline"><semantics id="algx1.l4.1.m1.1a"><mi id="algx1.l4.1.m1.1.1" xref="algx1.l4.1.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="algx1.l4.1.m1.1b"><ci id="algx1.l4.1.m1.1.1.cmml" xref="algx1.l4.1.m1.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l4.1.m1.1c">b</annotation></semantics></math></span> <span id="algx1.l4.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="algx1.l5" class="ltx_listingline">              <math id="algx1.l5.m1.1" class="ltx_Math" alttext="\psi_{ij}\leftarrow" display="inline"><semantics id="algx1.l5.m1.1a"><mrow id="algx1.l5.m1.1.1" xref="algx1.l5.m1.1.1.cmml"><msub id="algx1.l5.m1.1.1.2" xref="algx1.l5.m1.1.1.2.cmml"><mi id="algx1.l5.m1.1.1.2.2" xref="algx1.l5.m1.1.1.2.2.cmml">ψ</mi><mrow id="algx1.l5.m1.1.1.2.3" xref="algx1.l5.m1.1.1.2.3.cmml"><mi id="algx1.l5.m1.1.1.2.3.2" xref="algx1.l5.m1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="algx1.l5.m1.1.1.2.3.1" xref="algx1.l5.m1.1.1.2.3.1.cmml">​</mo><mi id="algx1.l5.m1.1.1.2.3.3" xref="algx1.l5.m1.1.1.2.3.3.cmml">j</mi></mrow></msub><mo stretchy="false" id="algx1.l5.m1.1.1.1" xref="algx1.l5.m1.1.1.1.cmml">←</mo><mi id="algx1.l5.m1.1.1.3" xref="algx1.l5.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algx1.l5.m1.1b"><apply id="algx1.l5.m1.1.1.cmml" xref="algx1.l5.m1.1.1"><ci id="algx1.l5.m1.1.1.1.cmml" xref="algx1.l5.m1.1.1.1">←</ci><apply id="algx1.l5.m1.1.1.2.cmml" xref="algx1.l5.m1.1.1.2"><csymbol cd="ambiguous" id="algx1.l5.m1.1.1.2.1.cmml" xref="algx1.l5.m1.1.1.2">subscript</csymbol><ci id="algx1.l5.m1.1.1.2.2.cmml" xref="algx1.l5.m1.1.1.2.2">𝜓</ci><apply id="algx1.l5.m1.1.1.2.3.cmml" xref="algx1.l5.m1.1.1.2.3"><times id="algx1.l5.m1.1.1.2.3.1.cmml" xref="algx1.l5.m1.1.1.2.3.1"></times><ci id="algx1.l5.m1.1.1.2.3.2.cmml" xref="algx1.l5.m1.1.1.2.3.2">𝑖</ci><ci id="algx1.l5.m1.1.1.2.3.3.cmml" xref="algx1.l5.m1.1.1.2.3.3">𝑗</ci></apply></apply><csymbol cd="latexml" id="algx1.l5.m1.1.1.3.cmml" xref="algx1.l5.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l5.m1.1c">\psi_{ij}\leftarrow</annotation></semantics></math><span id="algx1.l5.1" class="ltx_text ltx_font_typewriter"> <math id="algx1.l5.1.m1.6" class="ltx_Math" alttext="[f_{e}(x_{i})_{k-(l-1)},f_{e}(x_{i})_{k-(l-2)},...,f_{e}(x_{i})_{k}]" display="inline"><semantics id="algx1.l5.1.m1.6a"><mrow id="algx1.l5.1.m1.6.6.3" xref="algx1.l5.1.m1.6.6.4.cmml"><mo stretchy="false" id="algx1.l5.1.m1.6.6.3.4" xref="algx1.l5.1.m1.6.6.4.cmml">[</mo><mrow id="algx1.l5.1.m1.4.4.1.1" xref="algx1.l5.1.m1.4.4.1.1.cmml"><msub id="algx1.l5.1.m1.4.4.1.1.3" xref="algx1.l5.1.m1.4.4.1.1.3.cmml"><mi id="algx1.l5.1.m1.4.4.1.1.3.2" xref="algx1.l5.1.m1.4.4.1.1.3.2.cmml">f</mi><mi id="algx1.l5.1.m1.4.4.1.1.3.3" xref="algx1.l5.1.m1.4.4.1.1.3.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="algx1.l5.1.m1.4.4.1.1.2" xref="algx1.l5.1.m1.4.4.1.1.2.cmml">​</mo><msub id="algx1.l5.1.m1.4.4.1.1.1" xref="algx1.l5.1.m1.4.4.1.1.1.cmml"><mrow id="algx1.l5.1.m1.4.4.1.1.1.1.1" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algx1.l5.1.m1.4.4.1.1.1.1.1.2" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.cmml">(</mo><msub id="algx1.l5.1.m1.4.4.1.1.1.1.1.1" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.cmml"><mi id="algx1.l5.1.m1.4.4.1.1.1.1.1.1.2" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.2.cmml">x</mi><mi id="algx1.l5.1.m1.4.4.1.1.1.1.1.1.3" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="algx1.l5.1.m1.4.4.1.1.1.1.1.3" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="algx1.l5.1.m1.1.1.1" xref="algx1.l5.1.m1.1.1.1.cmml"><mi id="algx1.l5.1.m1.1.1.1.3" xref="algx1.l5.1.m1.1.1.1.3.cmml">k</mi><mo id="algx1.l5.1.m1.1.1.1.2" xref="algx1.l5.1.m1.1.1.1.2.cmml">−</mo><mrow id="algx1.l5.1.m1.1.1.1.1.1" xref="algx1.l5.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algx1.l5.1.m1.1.1.1.1.1.2" xref="algx1.l5.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="algx1.l5.1.m1.1.1.1.1.1.1" xref="algx1.l5.1.m1.1.1.1.1.1.1.cmml"><mi id="algx1.l5.1.m1.1.1.1.1.1.1.2" xref="algx1.l5.1.m1.1.1.1.1.1.1.2.cmml">l</mi><mo id="algx1.l5.1.m1.1.1.1.1.1.1.1" xref="algx1.l5.1.m1.1.1.1.1.1.1.1.cmml">−</mo><mn id="algx1.l5.1.m1.1.1.1.1.1.1.3" xref="algx1.l5.1.m1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="algx1.l5.1.m1.1.1.1.1.1.3" xref="algx1.l5.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow><mo id="algx1.l5.1.m1.6.6.3.5" xref="algx1.l5.1.m1.6.6.4.cmml">,</mo><mrow id="algx1.l5.1.m1.5.5.2.2" xref="algx1.l5.1.m1.5.5.2.2.cmml"><msub id="algx1.l5.1.m1.5.5.2.2.3" xref="algx1.l5.1.m1.5.5.2.2.3.cmml"><mi id="algx1.l5.1.m1.5.5.2.2.3.2" xref="algx1.l5.1.m1.5.5.2.2.3.2.cmml">f</mi><mi id="algx1.l5.1.m1.5.5.2.2.3.3" xref="algx1.l5.1.m1.5.5.2.2.3.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="algx1.l5.1.m1.5.5.2.2.2" xref="algx1.l5.1.m1.5.5.2.2.2.cmml">​</mo><msub id="algx1.l5.1.m1.5.5.2.2.1" xref="algx1.l5.1.m1.5.5.2.2.1.cmml"><mrow id="algx1.l5.1.m1.5.5.2.2.1.1.1" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.cmml"><mo stretchy="false" id="algx1.l5.1.m1.5.5.2.2.1.1.1.2" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.cmml">(</mo><msub id="algx1.l5.1.m1.5.5.2.2.1.1.1.1" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.cmml"><mi id="algx1.l5.1.m1.5.5.2.2.1.1.1.1.2" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.2.cmml">x</mi><mi id="algx1.l5.1.m1.5.5.2.2.1.1.1.1.3" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="algx1.l5.1.m1.5.5.2.2.1.1.1.3" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.cmml">)</mo></mrow><mrow id="algx1.l5.1.m1.2.2.1" xref="algx1.l5.1.m1.2.2.1.cmml"><mi id="algx1.l5.1.m1.2.2.1.3" xref="algx1.l5.1.m1.2.2.1.3.cmml">k</mi><mo id="algx1.l5.1.m1.2.2.1.2" xref="algx1.l5.1.m1.2.2.1.2.cmml">−</mo><mrow id="algx1.l5.1.m1.2.2.1.1.1" xref="algx1.l5.1.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="algx1.l5.1.m1.2.2.1.1.1.2" xref="algx1.l5.1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="algx1.l5.1.m1.2.2.1.1.1.1" xref="algx1.l5.1.m1.2.2.1.1.1.1.cmml"><mi id="algx1.l5.1.m1.2.2.1.1.1.1.2" xref="algx1.l5.1.m1.2.2.1.1.1.1.2.cmml">l</mi><mo id="algx1.l5.1.m1.2.2.1.1.1.1.1" xref="algx1.l5.1.m1.2.2.1.1.1.1.1.cmml">−</mo><mn id="algx1.l5.1.m1.2.2.1.1.1.1.3" xref="algx1.l5.1.m1.2.2.1.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="algx1.l5.1.m1.2.2.1.1.1.3" xref="algx1.l5.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow><mo id="algx1.l5.1.m1.6.6.3.6" xref="algx1.l5.1.m1.6.6.4.cmml">,</mo><mi mathvariant="normal" id="algx1.l5.1.m1.3.3" xref="algx1.l5.1.m1.3.3.cmml">…</mi><mo id="algx1.l5.1.m1.6.6.3.7" xref="algx1.l5.1.m1.6.6.4.cmml">,</mo><mrow id="algx1.l5.1.m1.6.6.3.3" xref="algx1.l5.1.m1.6.6.3.3.cmml"><msub id="algx1.l5.1.m1.6.6.3.3.3" xref="algx1.l5.1.m1.6.6.3.3.3.cmml"><mi id="algx1.l5.1.m1.6.6.3.3.3.2" xref="algx1.l5.1.m1.6.6.3.3.3.2.cmml">f</mi><mi id="algx1.l5.1.m1.6.6.3.3.3.3" xref="algx1.l5.1.m1.6.6.3.3.3.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="algx1.l5.1.m1.6.6.3.3.2" xref="algx1.l5.1.m1.6.6.3.3.2.cmml">​</mo><msub id="algx1.l5.1.m1.6.6.3.3.1" xref="algx1.l5.1.m1.6.6.3.3.1.cmml"><mrow id="algx1.l5.1.m1.6.6.3.3.1.1.1" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.cmml"><mo stretchy="false" id="algx1.l5.1.m1.6.6.3.3.1.1.1.2" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.cmml">(</mo><msub id="algx1.l5.1.m1.6.6.3.3.1.1.1.1" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.cmml"><mi id="algx1.l5.1.m1.6.6.3.3.1.1.1.1.2" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.2.cmml">x</mi><mi id="algx1.l5.1.m1.6.6.3.3.1.1.1.1.3" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="algx1.l5.1.m1.6.6.3.3.1.1.1.3" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.cmml">)</mo></mrow><mi id="algx1.l5.1.m1.6.6.3.3.1.3" xref="algx1.l5.1.m1.6.6.3.3.1.3.cmml">k</mi></msub></mrow><mo stretchy="false" id="algx1.l5.1.m1.6.6.3.8" xref="algx1.l5.1.m1.6.6.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="algx1.l5.1.m1.6b"><list id="algx1.l5.1.m1.6.6.4.cmml" xref="algx1.l5.1.m1.6.6.3"><apply id="algx1.l5.1.m1.4.4.1.1.cmml" xref="algx1.l5.1.m1.4.4.1.1"><times id="algx1.l5.1.m1.4.4.1.1.2.cmml" xref="algx1.l5.1.m1.4.4.1.1.2"></times><apply id="algx1.l5.1.m1.4.4.1.1.3.cmml" xref="algx1.l5.1.m1.4.4.1.1.3"><csymbol cd="ambiguous" id="algx1.l5.1.m1.4.4.1.1.3.1.cmml" xref="algx1.l5.1.m1.4.4.1.1.3">subscript</csymbol><ci id="algx1.l5.1.m1.4.4.1.1.3.2.cmml" xref="algx1.l5.1.m1.4.4.1.1.3.2">𝑓</ci><ci id="algx1.l5.1.m1.4.4.1.1.3.3.cmml" xref="algx1.l5.1.m1.4.4.1.1.3.3">𝑒</ci></apply><apply id="algx1.l5.1.m1.4.4.1.1.1.cmml" xref="algx1.l5.1.m1.4.4.1.1.1"><csymbol cd="ambiguous" id="algx1.l5.1.m1.4.4.1.1.1.2.cmml" xref="algx1.l5.1.m1.4.4.1.1.1">subscript</csymbol><apply id="algx1.l5.1.m1.4.4.1.1.1.1.1.1.cmml" xref="algx1.l5.1.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="algx1.l5.1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="algx1.l5.1.m1.4.4.1.1.1.1.1">subscript</csymbol><ci id="algx1.l5.1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.2">𝑥</ci><ci id="algx1.l5.1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="algx1.l5.1.m1.4.4.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="algx1.l5.1.m1.1.1.1.cmml" xref="algx1.l5.1.m1.1.1.1"><minus id="algx1.l5.1.m1.1.1.1.2.cmml" xref="algx1.l5.1.m1.1.1.1.2"></minus><ci id="algx1.l5.1.m1.1.1.1.3.cmml" xref="algx1.l5.1.m1.1.1.1.3">𝑘</ci><apply id="algx1.l5.1.m1.1.1.1.1.1.1.cmml" xref="algx1.l5.1.m1.1.1.1.1.1"><minus id="algx1.l5.1.m1.1.1.1.1.1.1.1.cmml" xref="algx1.l5.1.m1.1.1.1.1.1.1.1"></minus><ci id="algx1.l5.1.m1.1.1.1.1.1.1.2.cmml" xref="algx1.l5.1.m1.1.1.1.1.1.1.2">𝑙</ci><cn type="integer" id="algx1.l5.1.m1.1.1.1.1.1.1.3.cmml" xref="algx1.l5.1.m1.1.1.1.1.1.1.3">1</cn></apply></apply></apply></apply><apply id="algx1.l5.1.m1.5.5.2.2.cmml" xref="algx1.l5.1.m1.5.5.2.2"><times id="algx1.l5.1.m1.5.5.2.2.2.cmml" xref="algx1.l5.1.m1.5.5.2.2.2"></times><apply id="algx1.l5.1.m1.5.5.2.2.3.cmml" xref="algx1.l5.1.m1.5.5.2.2.3"><csymbol cd="ambiguous" id="algx1.l5.1.m1.5.5.2.2.3.1.cmml" xref="algx1.l5.1.m1.5.5.2.2.3">subscript</csymbol><ci id="algx1.l5.1.m1.5.5.2.2.3.2.cmml" xref="algx1.l5.1.m1.5.5.2.2.3.2">𝑓</ci><ci id="algx1.l5.1.m1.5.5.2.2.3.3.cmml" xref="algx1.l5.1.m1.5.5.2.2.3.3">𝑒</ci></apply><apply id="algx1.l5.1.m1.5.5.2.2.1.cmml" xref="algx1.l5.1.m1.5.5.2.2.1"><csymbol cd="ambiguous" id="algx1.l5.1.m1.5.5.2.2.1.2.cmml" xref="algx1.l5.1.m1.5.5.2.2.1">subscript</csymbol><apply id="algx1.l5.1.m1.5.5.2.2.1.1.1.1.cmml" xref="algx1.l5.1.m1.5.5.2.2.1.1.1"><csymbol cd="ambiguous" id="algx1.l5.1.m1.5.5.2.2.1.1.1.1.1.cmml" xref="algx1.l5.1.m1.5.5.2.2.1.1.1">subscript</csymbol><ci id="algx1.l5.1.m1.5.5.2.2.1.1.1.1.2.cmml" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.2">𝑥</ci><ci id="algx1.l5.1.m1.5.5.2.2.1.1.1.1.3.cmml" xref="algx1.l5.1.m1.5.5.2.2.1.1.1.1.3">𝑖</ci></apply><apply id="algx1.l5.1.m1.2.2.1.cmml" xref="algx1.l5.1.m1.2.2.1"><minus id="algx1.l5.1.m1.2.2.1.2.cmml" xref="algx1.l5.1.m1.2.2.1.2"></minus><ci id="algx1.l5.1.m1.2.2.1.3.cmml" xref="algx1.l5.1.m1.2.2.1.3">𝑘</ci><apply id="algx1.l5.1.m1.2.2.1.1.1.1.cmml" xref="algx1.l5.1.m1.2.2.1.1.1"><minus id="algx1.l5.1.m1.2.2.1.1.1.1.1.cmml" xref="algx1.l5.1.m1.2.2.1.1.1.1.1"></minus><ci id="algx1.l5.1.m1.2.2.1.1.1.1.2.cmml" xref="algx1.l5.1.m1.2.2.1.1.1.1.2">𝑙</ci><cn type="integer" id="algx1.l5.1.m1.2.2.1.1.1.1.3.cmml" xref="algx1.l5.1.m1.2.2.1.1.1.1.3">2</cn></apply></apply></apply></apply><ci id="algx1.l5.1.m1.3.3.cmml" xref="algx1.l5.1.m1.3.3">…</ci><apply id="algx1.l5.1.m1.6.6.3.3.cmml" xref="algx1.l5.1.m1.6.6.3.3"><times id="algx1.l5.1.m1.6.6.3.3.2.cmml" xref="algx1.l5.1.m1.6.6.3.3.2"></times><apply id="algx1.l5.1.m1.6.6.3.3.3.cmml" xref="algx1.l5.1.m1.6.6.3.3.3"><csymbol cd="ambiguous" id="algx1.l5.1.m1.6.6.3.3.3.1.cmml" xref="algx1.l5.1.m1.6.6.3.3.3">subscript</csymbol><ci id="algx1.l5.1.m1.6.6.3.3.3.2.cmml" xref="algx1.l5.1.m1.6.6.3.3.3.2">𝑓</ci><ci id="algx1.l5.1.m1.6.6.3.3.3.3.cmml" xref="algx1.l5.1.m1.6.6.3.3.3.3">𝑒</ci></apply><apply id="algx1.l5.1.m1.6.6.3.3.1.cmml" xref="algx1.l5.1.m1.6.6.3.3.1"><csymbol cd="ambiguous" id="algx1.l5.1.m1.6.6.3.3.1.2.cmml" xref="algx1.l5.1.m1.6.6.3.3.1">subscript</csymbol><apply id="algx1.l5.1.m1.6.6.3.3.1.1.1.1.cmml" xref="algx1.l5.1.m1.6.6.3.3.1.1.1"><csymbol cd="ambiguous" id="algx1.l5.1.m1.6.6.3.3.1.1.1.1.1.cmml" xref="algx1.l5.1.m1.6.6.3.3.1.1.1">subscript</csymbol><ci id="algx1.l5.1.m1.6.6.3.3.1.1.1.1.2.cmml" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.2">𝑥</ci><ci id="algx1.l5.1.m1.6.6.3.3.1.1.1.1.3.cmml" xref="algx1.l5.1.m1.6.6.3.3.1.1.1.1.3">𝑖</ci></apply><ci id="algx1.l5.1.m1.6.6.3.3.1.3.cmml" xref="algx1.l5.1.m1.6.6.3.3.1.3">𝑘</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="algx1.l5.1.m1.6c">[f_{e}(x_{i})_{k-(l-1)},f_{e}(x_{i})_{k-(l-2)},...,f_{e}(x_{i})_{k}]</annotation></semantics></math></span> <span id="algx1.l5.2" class="ltx_text" style="float:right;"><math id="algx1.l5.2.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l5.2.m1.1a"><mo id="algx1.l5.2.m1.1.1" xref="algx1.l5.2.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l5.2.m1.1b"><ci id="algx1.l5.2.m1.1.1.cmml" xref="algx1.l5.2.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l5.2.m1.1c">\triangleright</annotation></semantics></math> Concatenate intra layer feature
</span>
</div>
<div id="algx1.l6" class="ltx_listingline">              <math id="algx1.l6.m1.1" class="ltx_Math" alttext="\mu[i]\leftarrow\frac{1}{b}\sum\psi_{ij}" display="inline"><semantics id="algx1.l6.m1.1a"><mrow id="algx1.l6.m1.1.2" xref="algx1.l6.m1.1.2.cmml"><mrow id="algx1.l6.m1.1.2.2" xref="algx1.l6.m1.1.2.2.cmml"><mi id="algx1.l6.m1.1.2.2.2" xref="algx1.l6.m1.1.2.2.2.cmml">μ</mi><mo lspace="0em" rspace="0em" id="algx1.l6.m1.1.2.2.1" xref="algx1.l6.m1.1.2.2.1.cmml">​</mo><mrow id="algx1.l6.m1.1.2.2.3.2" xref="algx1.l6.m1.1.2.2.3.1.cmml"><mo stretchy="false" id="algx1.l6.m1.1.2.2.3.2.1" xref="algx1.l6.m1.1.2.2.3.1.1.cmml">[</mo><mi id="algx1.l6.m1.1.1" xref="algx1.l6.m1.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l6.m1.1.2.2.3.2.2" xref="algx1.l6.m1.1.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="algx1.l6.m1.1.2.1" xref="algx1.l6.m1.1.2.1.cmml">←</mo><mrow id="algx1.l6.m1.1.2.3" xref="algx1.l6.m1.1.2.3.cmml"><mfrac id="algx1.l6.m1.1.2.3.2" xref="algx1.l6.m1.1.2.3.2.cmml"><mn id="algx1.l6.m1.1.2.3.2.2" xref="algx1.l6.m1.1.2.3.2.2.cmml">1</mn><mi id="algx1.l6.m1.1.2.3.2.3" xref="algx1.l6.m1.1.2.3.2.3.cmml">b</mi></mfrac><mo lspace="0em" rspace="0em" id="algx1.l6.m1.1.2.3.1" xref="algx1.l6.m1.1.2.3.1.cmml">​</mo><mrow id="algx1.l6.m1.1.2.3.3" xref="algx1.l6.m1.1.2.3.3.cmml"><mo id="algx1.l6.m1.1.2.3.3.1" xref="algx1.l6.m1.1.2.3.3.1.cmml">∑</mo><msub id="algx1.l6.m1.1.2.3.3.2" xref="algx1.l6.m1.1.2.3.3.2.cmml"><mi id="algx1.l6.m1.1.2.3.3.2.2" xref="algx1.l6.m1.1.2.3.3.2.2.cmml">ψ</mi><mrow id="algx1.l6.m1.1.2.3.3.2.3" xref="algx1.l6.m1.1.2.3.3.2.3.cmml"><mi id="algx1.l6.m1.1.2.3.3.2.3.2" xref="algx1.l6.m1.1.2.3.3.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="algx1.l6.m1.1.2.3.3.2.3.1" xref="algx1.l6.m1.1.2.3.3.2.3.1.cmml">​</mo><mi id="algx1.l6.m1.1.2.3.3.2.3.3" xref="algx1.l6.m1.1.2.3.3.2.3.3.cmml">j</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l6.m1.1b"><apply id="algx1.l6.m1.1.2.cmml" xref="algx1.l6.m1.1.2"><ci id="algx1.l6.m1.1.2.1.cmml" xref="algx1.l6.m1.1.2.1">←</ci><apply id="algx1.l6.m1.1.2.2.cmml" xref="algx1.l6.m1.1.2.2"><times id="algx1.l6.m1.1.2.2.1.cmml" xref="algx1.l6.m1.1.2.2.1"></times><ci id="algx1.l6.m1.1.2.2.2.cmml" xref="algx1.l6.m1.1.2.2.2">𝜇</ci><apply id="algx1.l6.m1.1.2.2.3.1.cmml" xref="algx1.l6.m1.1.2.2.3.2"><csymbol cd="latexml" id="algx1.l6.m1.1.2.2.3.1.1.cmml" xref="algx1.l6.m1.1.2.2.3.2.1">delimited-[]</csymbol><ci id="algx1.l6.m1.1.1.cmml" xref="algx1.l6.m1.1.1">𝑖</ci></apply></apply><apply id="algx1.l6.m1.1.2.3.cmml" xref="algx1.l6.m1.1.2.3"><times id="algx1.l6.m1.1.2.3.1.cmml" xref="algx1.l6.m1.1.2.3.1"></times><apply id="algx1.l6.m1.1.2.3.2.cmml" xref="algx1.l6.m1.1.2.3.2"><divide id="algx1.l6.m1.1.2.3.2.1.cmml" xref="algx1.l6.m1.1.2.3.2"></divide><cn type="integer" id="algx1.l6.m1.1.2.3.2.2.cmml" xref="algx1.l6.m1.1.2.3.2.2">1</cn><ci id="algx1.l6.m1.1.2.3.2.3.cmml" xref="algx1.l6.m1.1.2.3.2.3">𝑏</ci></apply><apply id="algx1.l6.m1.1.2.3.3.cmml" xref="algx1.l6.m1.1.2.3.3"><sum id="algx1.l6.m1.1.2.3.3.1.cmml" xref="algx1.l6.m1.1.2.3.3.1"></sum><apply id="algx1.l6.m1.1.2.3.3.2.cmml" xref="algx1.l6.m1.1.2.3.3.2"><csymbol cd="ambiguous" id="algx1.l6.m1.1.2.3.3.2.1.cmml" xref="algx1.l6.m1.1.2.3.3.2">subscript</csymbol><ci id="algx1.l6.m1.1.2.3.3.2.2.cmml" xref="algx1.l6.m1.1.2.3.3.2.2">𝜓</ci><apply id="algx1.l6.m1.1.2.3.3.2.3.cmml" xref="algx1.l6.m1.1.2.3.3.2.3"><times id="algx1.l6.m1.1.2.3.3.2.3.1.cmml" xref="algx1.l6.m1.1.2.3.3.2.3.1"></times><ci id="algx1.l6.m1.1.2.3.3.2.3.2.cmml" xref="algx1.l6.m1.1.2.3.3.2.3.2">𝑖</ci><ci id="algx1.l6.m1.1.2.3.3.2.3.3.cmml" xref="algx1.l6.m1.1.2.3.3.2.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l6.m1.1c">\mu[i]\leftarrow\frac{1}{b}\sum\psi_{ij}</annotation></semantics></math> <span id="algx1.l6.1" class="ltx_text" style="float:right;"><math id="algx1.l6.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l6.1.m1.1a"><mo id="algx1.l6.1.m1.1.1" xref="algx1.l6.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l6.1.m1.1b"><ci id="algx1.l6.1.m1.1.1.cmml" xref="algx1.l6.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l6.1.m1.1c">\triangleright</annotation></semantics></math> Mean matrix
</span>
</div>
<div id="algx1.l7" class="ltx_listingline">              <math id="algx1.l7.m1.1" class="ltx_Math" alttext="\Sigma[i]\leftarrow" display="inline"><semantics id="algx1.l7.m1.1a"><mrow id="algx1.l7.m1.1.2" xref="algx1.l7.m1.1.2.cmml"><mrow id="algx1.l7.m1.1.2.2" xref="algx1.l7.m1.1.2.2.cmml"><mi mathvariant="normal" id="algx1.l7.m1.1.2.2.2" xref="algx1.l7.m1.1.2.2.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="algx1.l7.m1.1.2.2.1" xref="algx1.l7.m1.1.2.2.1.cmml">​</mo><mrow id="algx1.l7.m1.1.2.2.3.2" xref="algx1.l7.m1.1.2.2.3.1.cmml"><mo stretchy="false" id="algx1.l7.m1.1.2.2.3.2.1" xref="algx1.l7.m1.1.2.2.3.1.1.cmml">[</mo><mi id="algx1.l7.m1.1.1" xref="algx1.l7.m1.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l7.m1.1.2.2.3.2.2" xref="algx1.l7.m1.1.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="algx1.l7.m1.1.2.1" xref="algx1.l7.m1.1.2.1.cmml">←</mo><mi id="algx1.l7.m1.1.2.3" xref="algx1.l7.m1.1.2.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algx1.l7.m1.1b"><apply id="algx1.l7.m1.1.2.cmml" xref="algx1.l7.m1.1.2"><ci id="algx1.l7.m1.1.2.1.cmml" xref="algx1.l7.m1.1.2.1">←</ci><apply id="algx1.l7.m1.1.2.2.cmml" xref="algx1.l7.m1.1.2.2"><times id="algx1.l7.m1.1.2.2.1.cmml" xref="algx1.l7.m1.1.2.2.1"></times><ci id="algx1.l7.m1.1.2.2.2.cmml" xref="algx1.l7.m1.1.2.2.2">Σ</ci><apply id="algx1.l7.m1.1.2.2.3.1.cmml" xref="algx1.l7.m1.1.2.2.3.2"><csymbol cd="latexml" id="algx1.l7.m1.1.2.2.3.1.1.cmml" xref="algx1.l7.m1.1.2.2.3.2.1">delimited-[]</csymbol><ci id="algx1.l7.m1.1.1.cmml" xref="algx1.l7.m1.1.1">𝑖</ci></apply></apply><csymbol cd="latexml" id="algx1.l7.m1.1.2.3.cmml" xref="algx1.l7.m1.1.2.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l7.m1.1c">\Sigma[i]\leftarrow</annotation></semantics></math><span id="algx1.l7.1" class="ltx_text ltx_font_typewriter"> Covariance(<math id="algx1.l7.1.m1.1" class="ltx_Math" alttext="\psi_{ij}" display="inline"><semantics id="algx1.l7.1.m1.1a"><msub id="algx1.l7.1.m1.1.1" xref="algx1.l7.1.m1.1.1.cmml"><mi id="algx1.l7.1.m1.1.1.2" xref="algx1.l7.1.m1.1.1.2.cmml">ψ</mi><mrow id="algx1.l7.1.m1.1.1.3" xref="algx1.l7.1.m1.1.1.3.cmml"><mi id="algx1.l7.1.m1.1.1.3.2" xref="algx1.l7.1.m1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="algx1.l7.1.m1.1.1.3.1" xref="algx1.l7.1.m1.1.1.3.1.cmml">​</mo><mi id="algx1.l7.1.m1.1.1.3.3" xref="algx1.l7.1.m1.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="algx1.l7.1.m1.1b"><apply id="algx1.l7.1.m1.1.1.cmml" xref="algx1.l7.1.m1.1.1"><csymbol cd="ambiguous" id="algx1.l7.1.m1.1.1.1.cmml" xref="algx1.l7.1.m1.1.1">subscript</csymbol><ci id="algx1.l7.1.m1.1.1.2.cmml" xref="algx1.l7.1.m1.1.1.2">𝜓</ci><apply id="algx1.l7.1.m1.1.1.3.cmml" xref="algx1.l7.1.m1.1.1.3"><times id="algx1.l7.1.m1.1.1.3.1.cmml" xref="algx1.l7.1.m1.1.1.3.1"></times><ci id="algx1.l7.1.m1.1.1.3.2.cmml" xref="algx1.l7.1.m1.1.1.3.2">𝑖</ci><ci id="algx1.l7.1.m1.1.1.3.3.cmml" xref="algx1.l7.1.m1.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l7.1.m1.1c">\psi_{ij}</annotation></semantics></math>)</span> <span id="algx1.l7.2" class="ltx_text" style="float:right;"><math id="algx1.l7.2.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l7.2.m1.1a"><mo id="algx1.l7.2.m1.1.1" xref="algx1.l7.2.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l7.2.m1.1b"><ci id="algx1.l7.2.m1.1.1.cmml" xref="algx1.l7.2.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l7.2.m1.1c">\triangleright</annotation></semantics></math> Covariance matrix
</span>
</div>
<div id="algx1.l8" class="ltx_listingline">              <math id="algx1.l8.m1.1" class="ltx_Math" alttext="\Sigma[i]_{S}\leftarrow" display="inline"><semantics id="algx1.l8.m1.1a"><mrow id="algx1.l8.m1.1.2" xref="algx1.l8.m1.1.2.cmml"><mrow id="algx1.l8.m1.1.2.2" xref="algx1.l8.m1.1.2.2.cmml"><mi mathvariant="normal" id="algx1.l8.m1.1.2.2.2" xref="algx1.l8.m1.1.2.2.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="algx1.l8.m1.1.2.2.1" xref="algx1.l8.m1.1.2.2.1.cmml">​</mo><msub id="algx1.l8.m1.1.2.2.3" xref="algx1.l8.m1.1.2.2.3.cmml"><mrow id="algx1.l8.m1.1.2.2.3.2.2" xref="algx1.l8.m1.1.2.2.3.2.1.cmml"><mo stretchy="false" id="algx1.l8.m1.1.2.2.3.2.2.1" xref="algx1.l8.m1.1.2.2.3.2.1.1.cmml">[</mo><mi id="algx1.l8.m1.1.1" xref="algx1.l8.m1.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l8.m1.1.2.2.3.2.2.2" xref="algx1.l8.m1.1.2.2.3.2.1.1.cmml">]</mo></mrow><mi id="algx1.l8.m1.1.2.2.3.3" xref="algx1.l8.m1.1.2.2.3.3.cmml">S</mi></msub></mrow><mo stretchy="false" id="algx1.l8.m1.1.2.1" xref="algx1.l8.m1.1.2.1.cmml">←</mo><mi id="algx1.l8.m1.1.2.3" xref="algx1.l8.m1.1.2.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algx1.l8.m1.1b"><apply id="algx1.l8.m1.1.2.cmml" xref="algx1.l8.m1.1.2"><ci id="algx1.l8.m1.1.2.1.cmml" xref="algx1.l8.m1.1.2.1">←</ci><apply id="algx1.l8.m1.1.2.2.cmml" xref="algx1.l8.m1.1.2.2"><times id="algx1.l8.m1.1.2.2.1.cmml" xref="algx1.l8.m1.1.2.2.1"></times><ci id="algx1.l8.m1.1.2.2.2.cmml" xref="algx1.l8.m1.1.2.2.2">Σ</ci><apply id="algx1.l8.m1.1.2.2.3.cmml" xref="algx1.l8.m1.1.2.2.3"><csymbol cd="ambiguous" id="algx1.l8.m1.1.2.2.3.1.cmml" xref="algx1.l8.m1.1.2.2.3">subscript</csymbol><apply id="algx1.l8.m1.1.2.2.3.2.1.cmml" xref="algx1.l8.m1.1.2.2.3.2.2"><csymbol cd="latexml" id="algx1.l8.m1.1.2.2.3.2.1.1.cmml" xref="algx1.l8.m1.1.2.2.3.2.2.1">delimited-[]</csymbol><ci id="algx1.l8.m1.1.1.cmml" xref="algx1.l8.m1.1.1">𝑖</ci></apply><ci id="algx1.l8.m1.1.2.2.3.3.cmml" xref="algx1.l8.m1.1.2.2.3.3">𝑆</ci></apply></apply><csymbol cd="latexml" id="algx1.l8.m1.1.2.3.cmml" xref="algx1.l8.m1.1.2.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l8.m1.1c">\Sigma[i]_{S}\leftarrow</annotation></semantics></math><span id="algx1.l8.1" class="ltx_text ltx_font_typewriter"> Shrinkage(<math id="algx1.l8.1.m1.1" class="ltx_Math" alttext="\Sigma[i]" display="inline"><semantics id="algx1.l8.1.m1.1a"><mrow id="algx1.l8.1.m1.1.2" xref="algx1.l8.1.m1.1.2.cmml"><mi mathvariant="normal" id="algx1.l8.1.m1.1.2.2" xref="algx1.l8.1.m1.1.2.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="algx1.l8.1.m1.1.2.1" xref="algx1.l8.1.m1.1.2.1.cmml">​</mo><mrow id="algx1.l8.1.m1.1.2.3.2" xref="algx1.l8.1.m1.1.2.3.1.cmml"><mo stretchy="false" id="algx1.l8.1.m1.1.2.3.2.1" xref="algx1.l8.1.m1.1.2.3.1.1.cmml">[</mo><mi id="algx1.l8.1.m1.1.1" xref="algx1.l8.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l8.1.m1.1.2.3.2.2" xref="algx1.l8.1.m1.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l8.1.m1.1b"><apply id="algx1.l8.1.m1.1.2.cmml" xref="algx1.l8.1.m1.1.2"><times id="algx1.l8.1.m1.1.2.1.cmml" xref="algx1.l8.1.m1.1.2.1"></times><ci id="algx1.l8.1.m1.1.2.2.cmml" xref="algx1.l8.1.m1.1.2.2">Σ</ci><apply id="algx1.l8.1.m1.1.2.3.1.cmml" xref="algx1.l8.1.m1.1.2.3.2"><csymbol cd="latexml" id="algx1.l8.1.m1.1.2.3.1.1.cmml" xref="algx1.l8.1.m1.1.2.3.2.1">delimited-[]</csymbol><ci id="algx1.l8.1.m1.1.1.cmml" xref="algx1.l8.1.m1.1.1">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l8.1.m1.1c">\Sigma[i]</annotation></semantics></math>)</span>

</div>
<div id="algx1.l9" class="ltx_listingline">              <math id="algx1.l9.m1.1" class="ltx_Math" alttext="\Sigma[i]_{N}\leftarrow" display="inline"><semantics id="algx1.l9.m1.1a"><mrow id="algx1.l9.m1.1.2" xref="algx1.l9.m1.1.2.cmml"><mrow id="algx1.l9.m1.1.2.2" xref="algx1.l9.m1.1.2.2.cmml"><mi mathvariant="normal" id="algx1.l9.m1.1.2.2.2" xref="algx1.l9.m1.1.2.2.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="algx1.l9.m1.1.2.2.1" xref="algx1.l9.m1.1.2.2.1.cmml">​</mo><msub id="algx1.l9.m1.1.2.2.3" xref="algx1.l9.m1.1.2.2.3.cmml"><mrow id="algx1.l9.m1.1.2.2.3.2.2" xref="algx1.l9.m1.1.2.2.3.2.1.cmml"><mo stretchy="false" id="algx1.l9.m1.1.2.2.3.2.2.1" xref="algx1.l9.m1.1.2.2.3.2.1.1.cmml">[</mo><mi id="algx1.l9.m1.1.1" xref="algx1.l9.m1.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l9.m1.1.2.2.3.2.2.2" xref="algx1.l9.m1.1.2.2.3.2.1.1.cmml">]</mo></mrow><mi id="algx1.l9.m1.1.2.2.3.3" xref="algx1.l9.m1.1.2.2.3.3.cmml">N</mi></msub></mrow><mo stretchy="false" id="algx1.l9.m1.1.2.1" xref="algx1.l9.m1.1.2.1.cmml">←</mo><mi id="algx1.l9.m1.1.2.3" xref="algx1.l9.m1.1.2.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algx1.l9.m1.1b"><apply id="algx1.l9.m1.1.2.cmml" xref="algx1.l9.m1.1.2"><ci id="algx1.l9.m1.1.2.1.cmml" xref="algx1.l9.m1.1.2.1">←</ci><apply id="algx1.l9.m1.1.2.2.cmml" xref="algx1.l9.m1.1.2.2"><times id="algx1.l9.m1.1.2.2.1.cmml" xref="algx1.l9.m1.1.2.2.1"></times><ci id="algx1.l9.m1.1.2.2.2.cmml" xref="algx1.l9.m1.1.2.2.2">Σ</ci><apply id="algx1.l9.m1.1.2.2.3.cmml" xref="algx1.l9.m1.1.2.2.3"><csymbol cd="ambiguous" id="algx1.l9.m1.1.2.2.3.1.cmml" xref="algx1.l9.m1.1.2.2.3">subscript</csymbol><apply id="algx1.l9.m1.1.2.2.3.2.1.cmml" xref="algx1.l9.m1.1.2.2.3.2.2"><csymbol cd="latexml" id="algx1.l9.m1.1.2.2.3.2.1.1.cmml" xref="algx1.l9.m1.1.2.2.3.2.2.1">delimited-[]</csymbol><ci id="algx1.l9.m1.1.1.cmml" xref="algx1.l9.m1.1.1">𝑖</ci></apply><ci id="algx1.l9.m1.1.2.2.3.3.cmml" xref="algx1.l9.m1.1.2.2.3.3">𝑁</ci></apply></apply><csymbol cd="latexml" id="algx1.l9.m1.1.2.3.cmml" xref="algx1.l9.m1.1.2.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l9.m1.1c">\Sigma[i]_{N}\leftarrow</annotation></semantics></math><span id="algx1.l9.1" class="ltx_text ltx_font_typewriter"> Normalization(<math id="algx1.l9.1.m1.1" class="ltx_Math" alttext="\Sigma[i]_{S}" display="inline"><semantics id="algx1.l9.1.m1.1a"><mrow id="algx1.l9.1.m1.1.2" xref="algx1.l9.1.m1.1.2.cmml"><mi mathvariant="normal" id="algx1.l9.1.m1.1.2.2" xref="algx1.l9.1.m1.1.2.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="algx1.l9.1.m1.1.2.1" xref="algx1.l9.1.m1.1.2.1.cmml">​</mo><msub id="algx1.l9.1.m1.1.2.3" xref="algx1.l9.1.m1.1.2.3.cmml"><mrow id="algx1.l9.1.m1.1.2.3.2.2" xref="algx1.l9.1.m1.1.2.3.2.1.cmml"><mo stretchy="false" id="algx1.l9.1.m1.1.2.3.2.2.1" xref="algx1.l9.1.m1.1.2.3.2.1.1.cmml">[</mo><mi id="algx1.l9.1.m1.1.1" xref="algx1.l9.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l9.1.m1.1.2.3.2.2.2" xref="algx1.l9.1.m1.1.2.3.2.1.1.cmml">]</mo></mrow><mi id="algx1.l9.1.m1.1.2.3.3" xref="algx1.l9.1.m1.1.2.3.3.cmml">S</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="algx1.l9.1.m1.1b"><apply id="algx1.l9.1.m1.1.2.cmml" xref="algx1.l9.1.m1.1.2"><times id="algx1.l9.1.m1.1.2.1.cmml" xref="algx1.l9.1.m1.1.2.1"></times><ci id="algx1.l9.1.m1.1.2.2.cmml" xref="algx1.l9.1.m1.1.2.2">Σ</ci><apply id="algx1.l9.1.m1.1.2.3.cmml" xref="algx1.l9.1.m1.1.2.3"><csymbol cd="ambiguous" id="algx1.l9.1.m1.1.2.3.1.cmml" xref="algx1.l9.1.m1.1.2.3">subscript</csymbol><apply id="algx1.l9.1.m1.1.2.3.2.1.cmml" xref="algx1.l9.1.m1.1.2.3.2.2"><csymbol cd="latexml" id="algx1.l9.1.m1.1.2.3.2.1.1.cmml" xref="algx1.l9.1.m1.1.2.3.2.2.1">delimited-[]</csymbol><ci id="algx1.l9.1.m1.1.1.cmml" xref="algx1.l9.1.m1.1.1">𝑖</ci></apply><ci id="algx1.l9.1.m1.1.2.3.3.cmml" xref="algx1.l9.1.m1.1.2.3.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l9.1.m1.1c">\Sigma[i]_{S}</annotation></semantics></math>)</span>

</div>
<div id="algx1.l10" class="ltx_listingline">              <span id="algx1.l10.1" class="ltx_text ltx_font_bold">if</span> <math id="algx1.l10.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="algx1.l10.m1.1a"><mi id="algx1.l10.m1.1.1" xref="algx1.l10.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="algx1.l10.m1.1b"><ci id="algx1.l10.m1.1.1.cmml" xref="algx1.l10.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l10.m1.1c">\epsilon</annotation></semantics></math> is not empty <span id="algx1.l10.2" class="ltx_text ltx_font_bold">then</span>

</div>
<div id="algx1.l11" class="ltx_listingline">                  <span id="algx1.l11.2" class="ltx_text ltx_font_typewriter">similarity <math id="algx1.l11.1.m1.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="algx1.l11.1.m1.1a"><mo stretchy="false" id="algx1.l11.1.m1.1.1" xref="algx1.l11.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algx1.l11.1.m1.1b"><ci id="algx1.l11.1.m1.1.1.cmml" xref="algx1.l11.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l11.1.m1.1c">\leftarrow</annotation></semantics></math> cosine similarity(features <math id="algx1.l11.2.m2.2" class="ltx_Math" alttext="\in\epsilon,x_{i}^{{}^{\prime}}" display="inline"><semantics id="algx1.l11.2.m2.2a"><mrow id="algx1.l11.2.m2.2.2" xref="algx1.l11.2.m2.2.2.cmml"><mi id="algx1.l11.2.m2.2.2.3" xref="algx1.l11.2.m2.2.2.3.cmml"></mi><mo id="algx1.l11.2.m2.2.2.2" xref="algx1.l11.2.m2.2.2.2.cmml">∈</mo><mrow id="algx1.l11.2.m2.2.2.1.1" xref="algx1.l11.2.m2.2.2.1.2.cmml"><mi id="algx1.l11.2.m2.1.1" xref="algx1.l11.2.m2.1.1.cmml">ϵ</mi><mo id="algx1.l11.2.m2.2.2.1.1.2" xref="algx1.l11.2.m2.2.2.1.2.cmml">,</mo><msubsup id="algx1.l11.2.m2.2.2.1.1.1" xref="algx1.l11.2.m2.2.2.1.1.1.cmml"><mi id="algx1.l11.2.m2.2.2.1.1.1.2.2" xref="algx1.l11.2.m2.2.2.1.1.1.2.2.cmml">x</mi><mi id="algx1.l11.2.m2.2.2.1.1.1.2.3" xref="algx1.l11.2.m2.2.2.1.1.1.2.3.cmml">i</mi><msup id="algx1.l11.2.m2.2.2.1.1.1.3" xref="algx1.l11.2.m2.2.2.1.1.1.3.cmml"><mi id="algx1.l11.2.m2.2.2.1.1.1.3a" xref="algx1.l11.2.m2.2.2.1.1.1.3.cmml"></mi><mo id="algx1.l11.2.m2.2.2.1.1.1.3.1" xref="algx1.l11.2.m2.2.2.1.1.1.3.1.cmml">′</mo></msup></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l11.2.m2.2b"><apply id="algx1.l11.2.m2.2.2.cmml" xref="algx1.l11.2.m2.2.2"><in id="algx1.l11.2.m2.2.2.2.cmml" xref="algx1.l11.2.m2.2.2.2"></in><csymbol cd="latexml" id="algx1.l11.2.m2.2.2.3.cmml" xref="algx1.l11.2.m2.2.2.3">absent</csymbol><list id="algx1.l11.2.m2.2.2.1.2.cmml" xref="algx1.l11.2.m2.2.2.1.1"><ci id="algx1.l11.2.m2.1.1.cmml" xref="algx1.l11.2.m2.1.1">italic-ϵ</ci><apply id="algx1.l11.2.m2.2.2.1.1.1.cmml" xref="algx1.l11.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="algx1.l11.2.m2.2.2.1.1.1.1.cmml" xref="algx1.l11.2.m2.2.2.1.1.1">superscript</csymbol><apply id="algx1.l11.2.m2.2.2.1.1.1.2.cmml" xref="algx1.l11.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="algx1.l11.2.m2.2.2.1.1.1.2.1.cmml" xref="algx1.l11.2.m2.2.2.1.1.1">subscript</csymbol><ci id="algx1.l11.2.m2.2.2.1.1.1.2.2.cmml" xref="algx1.l11.2.m2.2.2.1.1.1.2.2">𝑥</ci><ci id="algx1.l11.2.m2.2.2.1.1.1.2.3.cmml" xref="algx1.l11.2.m2.2.2.1.1.1.2.3">𝑖</ci></apply><apply id="algx1.l11.2.m2.2.2.1.1.1.3.cmml" xref="algx1.l11.2.m2.2.2.1.1.1.3"><ci id="algx1.l11.2.m2.2.2.1.1.1.3.1.cmml" xref="algx1.l11.2.m2.2.2.1.1.1.3.1">′</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l11.2.m2.2c">\in\epsilon,x_{i}^{{}^{\prime}}</annotation></semantics></math>)</span> <span id="algx1.l11.3" class="ltx_text" style="float:right;"><math id="algx1.l11.3.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l11.3.m1.1a"><mo id="algx1.l11.3.m1.1.1" xref="algx1.l11.3.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l11.3.m1.1b"><ci id="algx1.l11.3.m1.1.1.cmml" xref="algx1.l11.3.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l11.3.m1.1c">\triangleright</annotation></semantics></math> Compute cosine similarity
</span>
</div>
<div id="algx1.l12" class="ltx_listingline">                  <span id="algx1.l12.1" class="ltx_text ltx_font_bold">if</span> similarity <math id="algx1.l12.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="algx1.l12.m1.1a"><mo id="algx1.l12.m1.1.1" xref="algx1.l12.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="algx1.l12.m1.1b"><geq id="algx1.l12.m1.1.1.cmml" xref="algx1.l12.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="algx1.l12.m1.1c">\geq</annotation></semantics></math> threshold  <span id="algx1.l12.2" class="ltx_text ltx_font_bold">then</span>

</div>
<div id="algx1.l13" class="ltx_listingline">                       Update <math id="algx1.l13.m1.1" class="ltx_Math" alttext="\mu[i]" display="inline"><semantics id="algx1.l13.m1.1a"><mrow id="algx1.l13.m1.1.2" xref="algx1.l13.m1.1.2.cmml"><mi id="algx1.l13.m1.1.2.2" xref="algx1.l13.m1.1.2.2.cmml">μ</mi><mo lspace="0em" rspace="0em" id="algx1.l13.m1.1.2.1" xref="algx1.l13.m1.1.2.1.cmml">​</mo><mrow id="algx1.l13.m1.1.2.3.2" xref="algx1.l13.m1.1.2.3.1.cmml"><mo stretchy="false" id="algx1.l13.m1.1.2.3.2.1" xref="algx1.l13.m1.1.2.3.1.1.cmml">[</mo><mi id="algx1.l13.m1.1.1" xref="algx1.l13.m1.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l13.m1.1.2.3.2.2" xref="algx1.l13.m1.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l13.m1.1b"><apply id="algx1.l13.m1.1.2.cmml" xref="algx1.l13.m1.1.2"><times id="algx1.l13.m1.1.2.1.cmml" xref="algx1.l13.m1.1.2.1"></times><ci id="algx1.l13.m1.1.2.2.cmml" xref="algx1.l13.m1.1.2.2">𝜇</ci><apply id="algx1.l13.m1.1.2.3.1.cmml" xref="algx1.l13.m1.1.2.3.2"><csymbol cd="latexml" id="algx1.l13.m1.1.2.3.1.1.cmml" xref="algx1.l13.m1.1.2.3.2.1">delimited-[]</csymbol><ci id="algx1.l13.m1.1.1.cmml" xref="algx1.l13.m1.1.1">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l13.m1.1c">\mu[i]</annotation></semantics></math>, <math id="algx1.l13.m2.1" class="ltx_Math" alttext="\Sigma[i]_{N}" display="inline"><semantics id="algx1.l13.m2.1a"><mrow id="algx1.l13.m2.1.2" xref="algx1.l13.m2.1.2.cmml"><mi mathvariant="normal" id="algx1.l13.m2.1.2.2" xref="algx1.l13.m2.1.2.2.cmml">Σ</mi><mo lspace="0em" rspace="0em" id="algx1.l13.m2.1.2.1" xref="algx1.l13.m2.1.2.1.cmml">​</mo><msub id="algx1.l13.m2.1.2.3" xref="algx1.l13.m2.1.2.3.cmml"><mrow id="algx1.l13.m2.1.2.3.2.2" xref="algx1.l13.m2.1.2.3.2.1.cmml"><mo stretchy="false" id="algx1.l13.m2.1.2.3.2.2.1" xref="algx1.l13.m2.1.2.3.2.1.1.cmml">[</mo><mi id="algx1.l13.m2.1.1" xref="algx1.l13.m2.1.1.cmml">i</mi><mo stretchy="false" id="algx1.l13.m2.1.2.3.2.2.2" xref="algx1.l13.m2.1.2.3.2.1.1.cmml">]</mo></mrow><mi id="algx1.l13.m2.1.2.3.3" xref="algx1.l13.m2.1.2.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="algx1.l13.m2.1b"><apply id="algx1.l13.m2.1.2.cmml" xref="algx1.l13.m2.1.2"><times id="algx1.l13.m2.1.2.1.cmml" xref="algx1.l13.m2.1.2.1"></times><ci id="algx1.l13.m2.1.2.2.cmml" xref="algx1.l13.m2.1.2.2">Σ</ci><apply id="algx1.l13.m2.1.2.3.cmml" xref="algx1.l13.m2.1.2.3"><csymbol cd="ambiguous" id="algx1.l13.m2.1.2.3.1.cmml" xref="algx1.l13.m2.1.2.3">subscript</csymbol><apply id="algx1.l13.m2.1.2.3.2.1.cmml" xref="algx1.l13.m2.1.2.3.2.2"><csymbol cd="latexml" id="algx1.l13.m2.1.2.3.2.1.1.cmml" xref="algx1.l13.m2.1.2.3.2.2.1">delimited-[]</csymbol><ci id="algx1.l13.m2.1.1.cmml" xref="algx1.l13.m2.1.1">𝑖</ci></apply><ci id="algx1.l13.m2.1.2.3.3.cmml" xref="algx1.l13.m2.1.2.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l13.m2.1c">\Sigma[i]_{N}</annotation></semantics></math> <span id="algx1.l13.1" class="ltx_text" style="float:right;"><math id="algx1.l13.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx1.l13.1.m1.1a"><mo id="algx1.l13.1.m1.1.1" xref="algx1.l13.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l13.1.m1.1b"><ci id="algx1.l13.1.m1.1.1.cmml" xref="algx1.l13.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l13.1.m1.1c">\triangleright</annotation></semantics></math> Update the mean and cov matrix for each class
</span>
</div>
<div id="algx1.l14" class="ltx_listingline">                  <span id="algx1.l14.1" class="ltx_text ltx_font_bold">end</span> <span id="algx1.l14.2" class="ltx_text ltx_font_bold">if</span>
</div>
<div id="algx1.l15" class="ltx_listingline">              <span id="algx1.l15.1" class="ltx_text ltx_font_bold">end</span> <span id="algx1.l15.2" class="ltx_text ltx_font_bold">if</span>
</div>
<div id="algx1.l16" class="ltx_listingline">         <span id="algx1.l16.1" class="ltx_text ltx_font_bold">end</span> <span id="algx1.l16.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="algx1.l17" class="ltx_listingline">     <span id="algx1.l17.1" class="ltx_text ltx_font_bold">end</span> <span id="algx1.l17.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="algx1.l18" class="ltx_listingline">
<span id="algx1.l18.1" class="ltx_text ltx_font_bold">end</span> <span id="algx1.l18.2" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.24" class="ltx_p ltx_figure_panel"><span id="alg1.24.1" class="ltx_text ltx_font_bold ltx_font_italic">Test Phase</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.25" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="algx2.l1" class="ltx_listingline">
<span id="algx2.l1.1" class="ltx_text ltx_font_bold">for</span> <math id="algx2.l1.m1.1" class="ltx_Math" alttext="x_{i}^{{}^{\prime\prime}}\in D_{test}" display="inline"><semantics id="algx2.l1.m1.1a"><mrow id="algx2.l1.m1.1.1" xref="algx2.l1.m1.1.1.cmml"><msubsup id="algx2.l1.m1.1.1.2" xref="algx2.l1.m1.1.1.2.cmml"><mi id="algx2.l1.m1.1.1.2.2.2" xref="algx2.l1.m1.1.1.2.2.2.cmml">x</mi><mi id="algx2.l1.m1.1.1.2.2.3" xref="algx2.l1.m1.1.1.2.2.3.cmml">i</mi><msup id="algx2.l1.m1.1.1.2.3" xref="algx2.l1.m1.1.1.2.3.cmml"><mi id="algx2.l1.m1.1.1.2.3a" xref="algx2.l1.m1.1.1.2.3.cmml"></mi><mo id="algx2.l1.m1.1.1.2.3.1" xref="algx2.l1.m1.1.1.2.3.1.cmml">′′</mo></msup></msubsup><mo id="algx2.l1.m1.1.1.1" xref="algx2.l1.m1.1.1.1.cmml">∈</mo><msub id="algx2.l1.m1.1.1.3" xref="algx2.l1.m1.1.1.3.cmml"><mi id="algx2.l1.m1.1.1.3.2" xref="algx2.l1.m1.1.1.3.2.cmml">D</mi><mrow id="algx2.l1.m1.1.1.3.3" xref="algx2.l1.m1.1.1.3.3.cmml"><mi id="algx2.l1.m1.1.1.3.3.2" xref="algx2.l1.m1.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="algx2.l1.m1.1.1.3.3.1" xref="algx2.l1.m1.1.1.3.3.1.cmml">​</mo><mi id="algx2.l1.m1.1.1.3.3.3" xref="algx2.l1.m1.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="algx2.l1.m1.1.1.3.3.1a" xref="algx2.l1.m1.1.1.3.3.1.cmml">​</mo><mi id="algx2.l1.m1.1.1.3.3.4" xref="algx2.l1.m1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="algx2.l1.m1.1.1.3.3.1b" xref="algx2.l1.m1.1.1.3.3.1.cmml">​</mo><mi id="algx2.l1.m1.1.1.3.3.5" xref="algx2.l1.m1.1.1.3.3.5.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="algx2.l1.m1.1b"><apply id="algx2.l1.m1.1.1.cmml" xref="algx2.l1.m1.1.1"><in id="algx2.l1.m1.1.1.1.cmml" xref="algx2.l1.m1.1.1.1"></in><apply id="algx2.l1.m1.1.1.2.cmml" xref="algx2.l1.m1.1.1.2"><csymbol cd="ambiguous" id="algx2.l1.m1.1.1.2.1.cmml" xref="algx2.l1.m1.1.1.2">superscript</csymbol><apply id="algx2.l1.m1.1.1.2.2.cmml" xref="algx2.l1.m1.1.1.2"><csymbol cd="ambiguous" id="algx2.l1.m1.1.1.2.2.1.cmml" xref="algx2.l1.m1.1.1.2">subscript</csymbol><ci id="algx2.l1.m1.1.1.2.2.2.cmml" xref="algx2.l1.m1.1.1.2.2.2">𝑥</ci><ci id="algx2.l1.m1.1.1.2.2.3.cmml" xref="algx2.l1.m1.1.1.2.2.3">𝑖</ci></apply><apply id="algx2.l1.m1.1.1.2.3.cmml" xref="algx2.l1.m1.1.1.2.3"><ci id="algx2.l1.m1.1.1.2.3.1.cmml" xref="algx2.l1.m1.1.1.2.3.1">′′</ci></apply></apply><apply id="algx2.l1.m1.1.1.3.cmml" xref="algx2.l1.m1.1.1.3"><csymbol cd="ambiguous" id="algx2.l1.m1.1.1.3.1.cmml" xref="algx2.l1.m1.1.1.3">subscript</csymbol><ci id="algx2.l1.m1.1.1.3.2.cmml" xref="algx2.l1.m1.1.1.3.2">𝐷</ci><apply id="algx2.l1.m1.1.1.3.3.cmml" xref="algx2.l1.m1.1.1.3.3"><times id="algx2.l1.m1.1.1.3.3.1.cmml" xref="algx2.l1.m1.1.1.3.3.1"></times><ci id="algx2.l1.m1.1.1.3.3.2.cmml" xref="algx2.l1.m1.1.1.3.3.2">𝑡</ci><ci id="algx2.l1.m1.1.1.3.3.3.cmml" xref="algx2.l1.m1.1.1.3.3.3">𝑒</ci><ci id="algx2.l1.m1.1.1.3.3.4.cmml" xref="algx2.l1.m1.1.1.3.3.4">𝑠</ci><ci id="algx2.l1.m1.1.1.3.3.5.cmml" xref="algx2.l1.m1.1.1.3.3.5">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx2.l1.m1.1c">x_{i}^{{}^{\prime\prime}}\in D_{test}</annotation></semantics></math> <span id="algx2.l1.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="algx2.l2" class="ltx_listingline">     <math id="algx2.l2.m1.5" class="ltx_Math" alttext="\phi(f_{e}(x_{i}^{{}^{\prime\prime}});\mu,\Sigma)\leftarrow(f_{e}(x)-\mu_{i})^{T}" display="inline"><semantics id="algx2.l2.m1.5a"><mrow id="algx2.l2.m1.5.5" xref="algx2.l2.m1.5.5.cmml"><mrow id="algx2.l2.m1.4.4.1" xref="algx2.l2.m1.4.4.1.cmml"><mi id="algx2.l2.m1.4.4.1.3" xref="algx2.l2.m1.4.4.1.3.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="algx2.l2.m1.4.4.1.2" xref="algx2.l2.m1.4.4.1.2.cmml">​</mo><mrow id="algx2.l2.m1.4.4.1.1.1" xref="algx2.l2.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="algx2.l2.m1.4.4.1.1.1.2" xref="algx2.l2.m1.4.4.1.1.2.cmml">(</mo><mrow id="algx2.l2.m1.4.4.1.1.1.1" xref="algx2.l2.m1.4.4.1.1.1.1.cmml"><msub id="algx2.l2.m1.4.4.1.1.1.1.3" xref="algx2.l2.m1.4.4.1.1.1.1.3.cmml"><mi id="algx2.l2.m1.4.4.1.1.1.1.3.2" xref="algx2.l2.m1.4.4.1.1.1.1.3.2.cmml">f</mi><mi id="algx2.l2.m1.4.4.1.1.1.1.3.3" xref="algx2.l2.m1.4.4.1.1.1.1.3.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="algx2.l2.m1.4.4.1.1.1.1.2" xref="algx2.l2.m1.4.4.1.1.1.1.2.cmml">​</mo><mrow id="algx2.l2.m1.4.4.1.1.1.1.1.1" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algx2.l2.m1.4.4.1.1.1.1.1.1.2" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="algx2.l2.m1.4.4.1.1.1.1.1.1.1" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.cmml"><mi id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.2" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.3" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.3.cmml">i</mi><msup id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mi id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3a" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3.cmml"></mi><mo id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3.1" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3.1.cmml">′′</mo></msup></msubsup><mo stretchy="false" id="algx2.l2.m1.4.4.1.1.1.1.1.1.3" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="algx2.l2.m1.4.4.1.1.1.3" xref="algx2.l2.m1.4.4.1.1.2.cmml">;</mo><mi id="algx2.l2.m1.1.1" xref="algx2.l2.m1.1.1.cmml">μ</mi><mo id="algx2.l2.m1.4.4.1.1.1.4" xref="algx2.l2.m1.4.4.1.1.2.cmml">,</mo><mi mathvariant="normal" id="algx2.l2.m1.2.2" xref="algx2.l2.m1.2.2.cmml">Σ</mi><mo stretchy="false" id="algx2.l2.m1.4.4.1.1.1.5" xref="algx2.l2.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="algx2.l2.m1.5.5.3" xref="algx2.l2.m1.5.5.3.cmml">←</mo><msup id="algx2.l2.m1.5.5.2" xref="algx2.l2.m1.5.5.2.cmml"><mrow id="algx2.l2.m1.5.5.2.1.1" xref="algx2.l2.m1.5.5.2.1.1.1.cmml"><mo stretchy="false" id="algx2.l2.m1.5.5.2.1.1.2" xref="algx2.l2.m1.5.5.2.1.1.1.cmml">(</mo><mrow id="algx2.l2.m1.5.5.2.1.1.1" xref="algx2.l2.m1.5.5.2.1.1.1.cmml"><mrow id="algx2.l2.m1.5.5.2.1.1.1.2" xref="algx2.l2.m1.5.5.2.1.1.1.2.cmml"><msub id="algx2.l2.m1.5.5.2.1.1.1.2.2" xref="algx2.l2.m1.5.5.2.1.1.1.2.2.cmml"><mi id="algx2.l2.m1.5.5.2.1.1.1.2.2.2" xref="algx2.l2.m1.5.5.2.1.1.1.2.2.2.cmml">f</mi><mi id="algx2.l2.m1.5.5.2.1.1.1.2.2.3" xref="algx2.l2.m1.5.5.2.1.1.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="algx2.l2.m1.5.5.2.1.1.1.2.1" xref="algx2.l2.m1.5.5.2.1.1.1.2.1.cmml">​</mo><mrow id="algx2.l2.m1.5.5.2.1.1.1.2.3.2" xref="algx2.l2.m1.5.5.2.1.1.1.2.cmml"><mo stretchy="false" id="algx2.l2.m1.5.5.2.1.1.1.2.3.2.1" xref="algx2.l2.m1.5.5.2.1.1.1.2.cmml">(</mo><mi id="algx2.l2.m1.3.3" xref="algx2.l2.m1.3.3.cmml">x</mi><mo stretchy="false" id="algx2.l2.m1.5.5.2.1.1.1.2.3.2.2" xref="algx2.l2.m1.5.5.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="algx2.l2.m1.5.5.2.1.1.1.1" xref="algx2.l2.m1.5.5.2.1.1.1.1.cmml">−</mo><msub id="algx2.l2.m1.5.5.2.1.1.1.3" xref="algx2.l2.m1.5.5.2.1.1.1.3.cmml"><mi id="algx2.l2.m1.5.5.2.1.1.1.3.2" xref="algx2.l2.m1.5.5.2.1.1.1.3.2.cmml">μ</mi><mi id="algx2.l2.m1.5.5.2.1.1.1.3.3" xref="algx2.l2.m1.5.5.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="algx2.l2.m1.5.5.2.1.1.3" xref="algx2.l2.m1.5.5.2.1.1.1.cmml">)</mo></mrow><mi id="algx2.l2.m1.5.5.2.3" xref="algx2.l2.m1.5.5.2.3.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="algx2.l2.m1.5b"><apply id="algx2.l2.m1.5.5.cmml" xref="algx2.l2.m1.5.5"><ci id="algx2.l2.m1.5.5.3.cmml" xref="algx2.l2.m1.5.5.3">←</ci><apply id="algx2.l2.m1.4.4.1.cmml" xref="algx2.l2.m1.4.4.1"><times id="algx2.l2.m1.4.4.1.2.cmml" xref="algx2.l2.m1.4.4.1.2"></times><ci id="algx2.l2.m1.4.4.1.3.cmml" xref="algx2.l2.m1.4.4.1.3">italic-ϕ</ci><list id="algx2.l2.m1.4.4.1.1.2.cmml" xref="algx2.l2.m1.4.4.1.1.1"><apply id="algx2.l2.m1.4.4.1.1.1.1.cmml" xref="algx2.l2.m1.4.4.1.1.1.1"><times id="algx2.l2.m1.4.4.1.1.1.1.2.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.2"></times><apply id="algx2.l2.m1.4.4.1.1.1.1.3.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.3"><csymbol cd="ambiguous" id="algx2.l2.m1.4.4.1.1.1.1.3.1.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.3">subscript</csymbol><ci id="algx2.l2.m1.4.4.1.1.1.1.3.2.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.3.2">𝑓</ci><ci id="algx2.l2.m1.4.4.1.1.1.1.3.3.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.3.3">𝑒</ci></apply><apply id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1">superscript</csymbol><apply id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.3.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3"><ci id="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3.1.cmml" xref="algx2.l2.m1.4.4.1.1.1.1.1.1.1.3.1">′′</ci></apply></apply></apply><ci id="algx2.l2.m1.1.1.cmml" xref="algx2.l2.m1.1.1">𝜇</ci><ci id="algx2.l2.m1.2.2.cmml" xref="algx2.l2.m1.2.2">Σ</ci></list></apply><apply id="algx2.l2.m1.5.5.2.cmml" xref="algx2.l2.m1.5.5.2"><csymbol cd="ambiguous" id="algx2.l2.m1.5.5.2.2.cmml" xref="algx2.l2.m1.5.5.2">superscript</csymbol><apply id="algx2.l2.m1.5.5.2.1.1.1.cmml" xref="algx2.l2.m1.5.5.2.1.1"><minus id="algx2.l2.m1.5.5.2.1.1.1.1.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.1"></minus><apply id="algx2.l2.m1.5.5.2.1.1.1.2.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.2"><times id="algx2.l2.m1.5.5.2.1.1.1.2.1.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.2.1"></times><apply id="algx2.l2.m1.5.5.2.1.1.1.2.2.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.2.2"><csymbol cd="ambiguous" id="algx2.l2.m1.5.5.2.1.1.1.2.2.1.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.2.2">subscript</csymbol><ci id="algx2.l2.m1.5.5.2.1.1.1.2.2.2.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.2.2.2">𝑓</ci><ci id="algx2.l2.m1.5.5.2.1.1.1.2.2.3.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.2.2.3">𝑒</ci></apply><ci id="algx2.l2.m1.3.3.cmml" xref="algx2.l2.m1.3.3">𝑥</ci></apply><apply id="algx2.l2.m1.5.5.2.1.1.1.3.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.3"><csymbol cd="ambiguous" id="algx2.l2.m1.5.5.2.1.1.1.3.1.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.3">subscript</csymbol><ci id="algx2.l2.m1.5.5.2.1.1.1.3.2.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.3.2">𝜇</ci><ci id="algx2.l2.m1.5.5.2.1.1.1.3.3.cmml" xref="algx2.l2.m1.5.5.2.1.1.1.3.3">𝑖</ci></apply></apply><ci id="algx2.l2.m1.5.5.2.3.cmml" xref="algx2.l2.m1.5.5.2.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx2.l2.m1.5c">\phi(f_{e}(x_{i}^{{}^{\prime\prime}});\mu,\Sigma)\leftarrow(f_{e}(x)-\mu_{i})^{T}</annotation></semantics></math> <math id="algx2.l2.m2.1" class="ltx_Math" alttext="(\Sigma_{i})_{N}^{-1}" display="inline"><semantics id="algx2.l2.m2.1a"><msubsup id="algx2.l2.m2.1.1" xref="algx2.l2.m2.1.1.cmml"><mrow id="algx2.l2.m2.1.1.1.1.1" xref="algx2.l2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algx2.l2.m2.1.1.1.1.1.2" xref="algx2.l2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="algx2.l2.m2.1.1.1.1.1.1" xref="algx2.l2.m2.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="algx2.l2.m2.1.1.1.1.1.1.2" xref="algx2.l2.m2.1.1.1.1.1.1.2.cmml">Σ</mi><mi id="algx2.l2.m2.1.1.1.1.1.1.3" xref="algx2.l2.m2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="algx2.l2.m2.1.1.1.1.1.3" xref="algx2.l2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="algx2.l2.m2.1.1.1.3" xref="algx2.l2.m2.1.1.1.3.cmml">N</mi><mrow id="algx2.l2.m2.1.1.3" xref="algx2.l2.m2.1.1.3.cmml"><mo id="algx2.l2.m2.1.1.3a" xref="algx2.l2.m2.1.1.3.cmml">−</mo><mn id="algx2.l2.m2.1.1.3.2" xref="algx2.l2.m2.1.1.3.2.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="algx2.l2.m2.1b"><apply id="algx2.l2.m2.1.1.cmml" xref="algx2.l2.m2.1.1"><csymbol cd="ambiguous" id="algx2.l2.m2.1.1.2.cmml" xref="algx2.l2.m2.1.1">superscript</csymbol><apply id="algx2.l2.m2.1.1.1.cmml" xref="algx2.l2.m2.1.1"><csymbol cd="ambiguous" id="algx2.l2.m2.1.1.1.2.cmml" xref="algx2.l2.m2.1.1">subscript</csymbol><apply id="algx2.l2.m2.1.1.1.1.1.1.cmml" xref="algx2.l2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="algx2.l2.m2.1.1.1.1.1.1.1.cmml" xref="algx2.l2.m2.1.1.1.1.1">subscript</csymbol><ci id="algx2.l2.m2.1.1.1.1.1.1.2.cmml" xref="algx2.l2.m2.1.1.1.1.1.1.2">Σ</ci><ci id="algx2.l2.m2.1.1.1.1.1.1.3.cmml" xref="algx2.l2.m2.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="algx2.l2.m2.1.1.1.3.cmml" xref="algx2.l2.m2.1.1.1.3">𝑁</ci></apply><apply id="algx2.l2.m2.1.1.3.cmml" xref="algx2.l2.m2.1.1.3"><minus id="algx2.l2.m2.1.1.3.1.cmml" xref="algx2.l2.m2.1.1.3"></minus><cn type="integer" id="algx2.l2.m2.1.1.3.2.cmml" xref="algx2.l2.m2.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx2.l2.m2.1c">(\Sigma_{i})_{N}^{-1}</annotation></semantics></math> <math id="algx2.l2.m3.2" class="ltx_Math" alttext="(f_{e}(x)-\mu_{i})" display="inline"><semantics id="algx2.l2.m3.2a"><mrow id="algx2.l2.m3.2.2.1" xref="algx2.l2.m3.2.2.1.1.cmml"><mo stretchy="false" id="algx2.l2.m3.2.2.1.2" xref="algx2.l2.m3.2.2.1.1.cmml">(</mo><mrow id="algx2.l2.m3.2.2.1.1" xref="algx2.l2.m3.2.2.1.1.cmml"><mrow id="algx2.l2.m3.2.2.1.1.2" xref="algx2.l2.m3.2.2.1.1.2.cmml"><msub id="algx2.l2.m3.2.2.1.1.2.2" xref="algx2.l2.m3.2.2.1.1.2.2.cmml"><mi id="algx2.l2.m3.2.2.1.1.2.2.2" xref="algx2.l2.m3.2.2.1.1.2.2.2.cmml">f</mi><mi id="algx2.l2.m3.2.2.1.1.2.2.3" xref="algx2.l2.m3.2.2.1.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="algx2.l2.m3.2.2.1.1.2.1" xref="algx2.l2.m3.2.2.1.1.2.1.cmml">​</mo><mrow id="algx2.l2.m3.2.2.1.1.2.3.2" xref="algx2.l2.m3.2.2.1.1.2.cmml"><mo stretchy="false" id="algx2.l2.m3.2.2.1.1.2.3.2.1" xref="algx2.l2.m3.2.2.1.1.2.cmml">(</mo><mi id="algx2.l2.m3.1.1" xref="algx2.l2.m3.1.1.cmml">x</mi><mo stretchy="false" id="algx2.l2.m3.2.2.1.1.2.3.2.2" xref="algx2.l2.m3.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="algx2.l2.m3.2.2.1.1.1" xref="algx2.l2.m3.2.2.1.1.1.cmml">−</mo><msub id="algx2.l2.m3.2.2.1.1.3" xref="algx2.l2.m3.2.2.1.1.3.cmml"><mi id="algx2.l2.m3.2.2.1.1.3.2" xref="algx2.l2.m3.2.2.1.1.3.2.cmml">μ</mi><mi id="algx2.l2.m3.2.2.1.1.3.3" xref="algx2.l2.m3.2.2.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="algx2.l2.m3.2.2.1.3" xref="algx2.l2.m3.2.2.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="algx2.l2.m3.2b"><apply id="algx2.l2.m3.2.2.1.1.cmml" xref="algx2.l2.m3.2.2.1"><minus id="algx2.l2.m3.2.2.1.1.1.cmml" xref="algx2.l2.m3.2.2.1.1.1"></minus><apply id="algx2.l2.m3.2.2.1.1.2.cmml" xref="algx2.l2.m3.2.2.1.1.2"><times id="algx2.l2.m3.2.2.1.1.2.1.cmml" xref="algx2.l2.m3.2.2.1.1.2.1"></times><apply id="algx2.l2.m3.2.2.1.1.2.2.cmml" xref="algx2.l2.m3.2.2.1.1.2.2"><csymbol cd="ambiguous" id="algx2.l2.m3.2.2.1.1.2.2.1.cmml" xref="algx2.l2.m3.2.2.1.1.2.2">subscript</csymbol><ci id="algx2.l2.m3.2.2.1.1.2.2.2.cmml" xref="algx2.l2.m3.2.2.1.1.2.2.2">𝑓</ci><ci id="algx2.l2.m3.2.2.1.1.2.2.3.cmml" xref="algx2.l2.m3.2.2.1.1.2.2.3">𝑒</ci></apply><ci id="algx2.l2.m3.1.1.cmml" xref="algx2.l2.m3.1.1">𝑥</ci></apply><apply id="algx2.l2.m3.2.2.1.1.3.cmml" xref="algx2.l2.m3.2.2.1.1.3"><csymbol cd="ambiguous" id="algx2.l2.m3.2.2.1.1.3.1.cmml" xref="algx2.l2.m3.2.2.1.1.3">subscript</csymbol><ci id="algx2.l2.m3.2.2.1.1.3.2.cmml" xref="algx2.l2.m3.2.2.1.1.3.2">𝜇</ci><ci id="algx2.l2.m3.2.2.1.1.3.3.cmml" xref="algx2.l2.m3.2.2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx2.l2.m3.2c">(f_{e}(x)-\mu_{i})</annotation></semantics></math> <span id="algx2.l2.1" class="ltx_text" style="float:right;"><math id="algx2.l2.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx2.l2.1.m1.1a"><mo id="algx2.l2.1.m1.1.1" xref="algx2.l2.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx2.l2.1.m1.1b"><ci id="algx2.l2.1.m1.1.1.cmml" xref="algx2.l2.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx2.l2.1.m1.1c">\triangleright</annotation></semantics></math> Calculate the Mahalanobis distance
</span>
</div>
<div id="algx2.l3" class="ltx_listingline">     <math id="algx2.l3.m1.1" class="ltx_Math" alttext="y_{pred}\leftarrow" display="inline"><semantics id="algx2.l3.m1.1a"><mrow id="algx2.l3.m1.1.1" xref="algx2.l3.m1.1.1.cmml"><msub id="algx2.l3.m1.1.1.2" xref="algx2.l3.m1.1.1.2.cmml"><mi id="algx2.l3.m1.1.1.2.2" xref="algx2.l3.m1.1.1.2.2.cmml">y</mi><mrow id="algx2.l3.m1.1.1.2.3" xref="algx2.l3.m1.1.1.2.3.cmml"><mi id="algx2.l3.m1.1.1.2.3.2" xref="algx2.l3.m1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="algx2.l3.m1.1.1.2.3.1" xref="algx2.l3.m1.1.1.2.3.1.cmml">​</mo><mi id="algx2.l3.m1.1.1.2.3.3" xref="algx2.l3.m1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="algx2.l3.m1.1.1.2.3.1a" xref="algx2.l3.m1.1.1.2.3.1.cmml">​</mo><mi id="algx2.l3.m1.1.1.2.3.4" xref="algx2.l3.m1.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="algx2.l3.m1.1.1.2.3.1b" xref="algx2.l3.m1.1.1.2.3.1.cmml">​</mo><mi id="algx2.l3.m1.1.1.2.3.5" xref="algx2.l3.m1.1.1.2.3.5.cmml">d</mi></mrow></msub><mo stretchy="false" id="algx2.l3.m1.1.1.1" xref="algx2.l3.m1.1.1.1.cmml">←</mo><mi id="algx2.l3.m1.1.1.3" xref="algx2.l3.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algx2.l3.m1.1b"><apply id="algx2.l3.m1.1.1.cmml" xref="algx2.l3.m1.1.1"><ci id="algx2.l3.m1.1.1.1.cmml" xref="algx2.l3.m1.1.1.1">←</ci><apply id="algx2.l3.m1.1.1.2.cmml" xref="algx2.l3.m1.1.1.2"><csymbol cd="ambiguous" id="algx2.l3.m1.1.1.2.1.cmml" xref="algx2.l3.m1.1.1.2">subscript</csymbol><ci id="algx2.l3.m1.1.1.2.2.cmml" xref="algx2.l3.m1.1.1.2.2">𝑦</ci><apply id="algx2.l3.m1.1.1.2.3.cmml" xref="algx2.l3.m1.1.1.2.3"><times id="algx2.l3.m1.1.1.2.3.1.cmml" xref="algx2.l3.m1.1.1.2.3.1"></times><ci id="algx2.l3.m1.1.1.2.3.2.cmml" xref="algx2.l3.m1.1.1.2.3.2">𝑝</ci><ci id="algx2.l3.m1.1.1.2.3.3.cmml" xref="algx2.l3.m1.1.1.2.3.3">𝑟</ci><ci id="algx2.l3.m1.1.1.2.3.4.cmml" xref="algx2.l3.m1.1.1.2.3.4">𝑒</ci><ci id="algx2.l3.m1.1.1.2.3.5.cmml" xref="algx2.l3.m1.1.1.2.3.5">𝑑</ci></apply></apply><csymbol cd="latexml" id="algx2.l3.m1.1.1.3.cmml" xref="algx2.l3.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algx2.l3.m1.1c">y_{pred}\leftarrow</annotation></semantics></math> argmin <math id="algx2.l3.m2.3" class="ltx_Math" alttext="\phi(f_{e}(x_{i}^{{}^{\prime\prime}});\mu,\Sigma)" display="inline"><semantics id="algx2.l3.m2.3a"><mrow id="algx2.l3.m2.3.3" xref="algx2.l3.m2.3.3.cmml"><mi id="algx2.l3.m2.3.3.3" xref="algx2.l3.m2.3.3.3.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="algx2.l3.m2.3.3.2" xref="algx2.l3.m2.3.3.2.cmml">​</mo><mrow id="algx2.l3.m2.3.3.1.1" xref="algx2.l3.m2.3.3.1.2.cmml"><mo stretchy="false" id="algx2.l3.m2.3.3.1.1.2" xref="algx2.l3.m2.3.3.1.2.cmml">(</mo><mrow id="algx2.l3.m2.3.3.1.1.1" xref="algx2.l3.m2.3.3.1.1.1.cmml"><msub id="algx2.l3.m2.3.3.1.1.1.3" xref="algx2.l3.m2.3.3.1.1.1.3.cmml"><mi id="algx2.l3.m2.3.3.1.1.1.3.2" xref="algx2.l3.m2.3.3.1.1.1.3.2.cmml">f</mi><mi id="algx2.l3.m2.3.3.1.1.1.3.3" xref="algx2.l3.m2.3.3.1.1.1.3.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="algx2.l3.m2.3.3.1.1.1.2" xref="algx2.l3.m2.3.3.1.1.1.2.cmml">​</mo><mrow id="algx2.l3.m2.3.3.1.1.1.1.1" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algx2.l3.m2.3.3.1.1.1.1.1.2" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.cmml">(</mo><msubsup id="algx2.l3.m2.3.3.1.1.1.1.1.1" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.cmml"><mi id="algx2.l3.m2.3.3.1.1.1.1.1.1.2.2" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="algx2.l3.m2.3.3.1.1.1.1.1.1.2.3" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.2.3.cmml">i</mi><msup id="algx2.l3.m2.3.3.1.1.1.1.1.1.3" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.3.cmml"><mi id="algx2.l3.m2.3.3.1.1.1.1.1.1.3a" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.3.cmml"></mi><mo id="algx2.l3.m2.3.3.1.1.1.1.1.1.3.1" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.3.1.cmml">′′</mo></msup></msubsup><mo stretchy="false" id="algx2.l3.m2.3.3.1.1.1.1.1.3" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="algx2.l3.m2.3.3.1.1.3" xref="algx2.l3.m2.3.3.1.2.cmml">;</mo><mi id="algx2.l3.m2.1.1" xref="algx2.l3.m2.1.1.cmml">μ</mi><mo id="algx2.l3.m2.3.3.1.1.4" xref="algx2.l3.m2.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="algx2.l3.m2.2.2" xref="algx2.l3.m2.2.2.cmml">Σ</mi><mo stretchy="false" id="algx2.l3.m2.3.3.1.1.5" xref="algx2.l3.m2.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx2.l3.m2.3b"><apply id="algx2.l3.m2.3.3.cmml" xref="algx2.l3.m2.3.3"><times id="algx2.l3.m2.3.3.2.cmml" xref="algx2.l3.m2.3.3.2"></times><ci id="algx2.l3.m2.3.3.3.cmml" xref="algx2.l3.m2.3.3.3">italic-ϕ</ci><list id="algx2.l3.m2.3.3.1.2.cmml" xref="algx2.l3.m2.3.3.1.1"><apply id="algx2.l3.m2.3.3.1.1.1.cmml" xref="algx2.l3.m2.3.3.1.1.1"><times id="algx2.l3.m2.3.3.1.1.1.2.cmml" xref="algx2.l3.m2.3.3.1.1.1.2"></times><apply id="algx2.l3.m2.3.3.1.1.1.3.cmml" xref="algx2.l3.m2.3.3.1.1.1.3"><csymbol cd="ambiguous" id="algx2.l3.m2.3.3.1.1.1.3.1.cmml" xref="algx2.l3.m2.3.3.1.1.1.3">subscript</csymbol><ci id="algx2.l3.m2.3.3.1.1.1.3.2.cmml" xref="algx2.l3.m2.3.3.1.1.1.3.2">𝑓</ci><ci id="algx2.l3.m2.3.3.1.1.1.3.3.cmml" xref="algx2.l3.m2.3.3.1.1.1.3.3">𝑒</ci></apply><apply id="algx2.l3.m2.3.3.1.1.1.1.1.1.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="algx2.l3.m2.3.3.1.1.1.1.1.1.1.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1">superscript</csymbol><apply id="algx2.l3.m2.3.3.1.1.1.1.1.1.2.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="algx2.l3.m2.3.3.1.1.1.1.1.1.2.1.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1">subscript</csymbol><ci id="algx2.l3.m2.3.3.1.1.1.1.1.1.2.2.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.2.2">𝑥</ci><ci id="algx2.l3.m2.3.3.1.1.1.1.1.1.2.3.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="algx2.l3.m2.3.3.1.1.1.1.1.1.3.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.3"><ci id="algx2.l3.m2.3.3.1.1.1.1.1.1.3.1.cmml" xref="algx2.l3.m2.3.3.1.1.1.1.1.1.3.1">′′</ci></apply></apply></apply><ci id="algx2.l3.m2.1.1.cmml" xref="algx2.l3.m2.1.1">𝜇</ci><ci id="algx2.l3.m2.2.2.cmml" xref="algx2.l3.m2.2.2">Σ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="algx2.l3.m2.3c">\phi(f_{e}(x_{i}^{{}^{\prime\prime}});\mu,\Sigma)</annotation></semantics></math> <math id="algx2.l3.m3.1" class="ltx_Math" alttext="\forall" display="inline"><semantics id="algx2.l3.m3.1a"><mo id="algx2.l3.m3.1.1" xref="algx2.l3.m3.1.1.cmml">∀</mo><annotation-xml encoding="MathML-Content" id="algx2.l3.m3.1b"><csymbol cd="latexml" id="algx2.l3.m3.1.1.cmml" xref="algx2.l3.m3.1.1">for-all</csymbol></annotation-xml><annotation encoding="application/x-tex" id="algx2.l3.m3.1c">\forall</annotation></semantics></math> <math id="algx2.l3.m4.3" class="ltx_Math" alttext="y_{i}=0,1,...T" display="inline"><semantics id="algx2.l3.m4.3a"><mrow id="algx2.l3.m4.3.3" xref="algx2.l3.m4.3.3.cmml"><msub id="algx2.l3.m4.3.3.3" xref="algx2.l3.m4.3.3.3.cmml"><mi id="algx2.l3.m4.3.3.3.2" xref="algx2.l3.m4.3.3.3.2.cmml">y</mi><mi id="algx2.l3.m4.3.3.3.3" xref="algx2.l3.m4.3.3.3.3.cmml">i</mi></msub><mo id="algx2.l3.m4.3.3.2" xref="algx2.l3.m4.3.3.2.cmml">=</mo><mrow id="algx2.l3.m4.3.3.1.1" xref="algx2.l3.m4.3.3.1.2.cmml"><mn id="algx2.l3.m4.1.1" xref="algx2.l3.m4.1.1.cmml">0</mn><mo id="algx2.l3.m4.3.3.1.1.2" xref="algx2.l3.m4.3.3.1.2.cmml">,</mo><mn id="algx2.l3.m4.2.2" xref="algx2.l3.m4.2.2.cmml">1</mn><mo id="algx2.l3.m4.3.3.1.1.3" xref="algx2.l3.m4.3.3.1.2.cmml">,</mo><mrow id="algx2.l3.m4.3.3.1.1.1" xref="algx2.l3.m4.3.3.1.1.1.cmml"><mi mathvariant="normal" id="algx2.l3.m4.3.3.1.1.1.2" xref="algx2.l3.m4.3.3.1.1.1.2.cmml">…</mi><mo lspace="0em" rspace="0em" id="algx2.l3.m4.3.3.1.1.1.1" xref="algx2.l3.m4.3.3.1.1.1.1.cmml">​</mo><mi id="algx2.l3.m4.3.3.1.1.1.3" xref="algx2.l3.m4.3.3.1.1.1.3.cmml">T</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx2.l3.m4.3b"><apply id="algx2.l3.m4.3.3.cmml" xref="algx2.l3.m4.3.3"><eq id="algx2.l3.m4.3.3.2.cmml" xref="algx2.l3.m4.3.3.2"></eq><apply id="algx2.l3.m4.3.3.3.cmml" xref="algx2.l3.m4.3.3.3"><csymbol cd="ambiguous" id="algx2.l3.m4.3.3.3.1.cmml" xref="algx2.l3.m4.3.3.3">subscript</csymbol><ci id="algx2.l3.m4.3.3.3.2.cmml" xref="algx2.l3.m4.3.3.3.2">𝑦</ci><ci id="algx2.l3.m4.3.3.3.3.cmml" xref="algx2.l3.m4.3.3.3.3">𝑖</ci></apply><list id="algx2.l3.m4.3.3.1.2.cmml" xref="algx2.l3.m4.3.3.1.1"><cn type="integer" id="algx2.l3.m4.1.1.cmml" xref="algx2.l3.m4.1.1">0</cn><cn type="integer" id="algx2.l3.m4.2.2.cmml" xref="algx2.l3.m4.2.2">1</cn><apply id="algx2.l3.m4.3.3.1.1.1.cmml" xref="algx2.l3.m4.3.3.1.1.1"><times id="algx2.l3.m4.3.3.1.1.1.1.cmml" xref="algx2.l3.m4.3.3.1.1.1.1"></times><ci id="algx2.l3.m4.3.3.1.1.1.2.cmml" xref="algx2.l3.m4.3.3.1.1.1.2">…</ci><ci id="algx2.l3.m4.3.3.1.1.1.3.cmml" xref="algx2.l3.m4.3.3.1.1.1.3">𝑇</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="algx2.l3.m4.3c">y_{i}=0,1,...T</annotation></semantics></math> <span id="algx2.l3.1" class="ltx_text" style="float:right;"><math id="algx2.l3.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="algx2.l3.1.m1.1a"><mo id="algx2.l3.1.m1.1.1" xref="algx2.l3.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx2.l3.1.m1.1b"><ci id="algx2.l3.1.m1.1.1.cmml" xref="algx2.l3.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx2.l3.1.m1.1c">\triangleright</annotation></semantics></math> Assign the class with minimum Mahalanobis distance
</span>
</div>
<div id="algx2.l4" class="ltx_listingline">
<span id="algx2.l4.1" class="ltx_text ltx_font_bold">end</span> <span id="algx2.l4.2" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</div>
</div>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Intra Layer Feature Representation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Intra-layer feature representation (ILFR) leverages the power of intermediate layers that encodes the low and mid-level feature information present in the data extracted using a pre-trained model. Instead of relying solely on the final output layer of the feature extractor, the presence of multiple activation maps generalizes the learned knowledge and further improves the performance of the algorithm. We argue that enriching the last layer representations with hierarchical intra-layer features increases robustness to domain shifts and thus improves generalizability to downstream continual tasks. These extracted features can be the class embeddings of a transformer encoder <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib81" title="" class="ltx_ref">Vaswani et al.</a></cite> or flattened feature maps of a ResNet encoder <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib82" title="" class="ltx_ref">He et al.</a></cite>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">There are two intuitive ways to promote intra-layer feature representations into the model: averaging the representations from the last "k" layers of the network or concatenating the representations from the last k layers. The first approach requires the output dimensions of all layers to be identical to facilitate summation. In our use case, we opt for concatenation, as the outputs from different layers have varying dimensions. Concatenation also preserves the rich, multi-scale features, unlike summation, which can result in information loss due to the merging of complementary features captured by different layers, potentially reducing the richness of the learned representations.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">For the multimodal experiment, we pre-train the domain 1 feature extractor on gripper data of objects not present in the training dataset, while the domain 2 feature extractor is trained on the Core50 dataset. More details about the pre-trained model architecture are provided in Table <a href="#S3.T1" title="Table 1 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Setup ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For the Core50 experiment, we use the ResNet18 architecture as the feature extractor, pre-trained on the ImageNet1k dataset <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib83" title="" class="ltx_ref">Russakovsky et al.</a></cite>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Semi-Supervised Learning</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.4" class="ltx_p">Semi-supervised learning (SSL) denotes the capability of an algorithm to learn from supervised data and then improve the performance of the model by training it on the unsupervised part. It is very useful in a situation where we have limited supervised data but we can collect huge amounts of unsupervised data from the environment. This is an active area of research given that large, labeled datasets are expensive, but most applications have access to plentiful, cheap unlabeled data. In this paper, we use the concept of pseudo-labeling to organize the unsupervised data and provide them with dummy labels for further training. To perform pseudo labeling we randomly store the feature maps of each class for every task in a temporary memory buffer and then perform cosine similarity between the reference feature maps and the feature maps generated from the complete unsupervised dataset as defined in equation <a href="#S4.E2" title="In 4.3 Semi-Supervised Learning ‣ 4 Methodology ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E2.m1.4" class="ltx_Math" alttext="similarity=\frac{x_{1}.x_{2}}{||x_{1}||_{2}||x_{2}||_{2}}" display="block"><semantics id="S4.E2.m1.4a"><mrow id="S4.E2.m1.4.5" xref="S4.E2.m1.4.5.cmml"><mrow id="S4.E2.m1.4.5.2" xref="S4.E2.m1.4.5.2.cmml"><mi id="S4.E2.m1.4.5.2.2" xref="S4.E2.m1.4.5.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.3" xref="S4.E2.m1.4.5.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1a" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.4" xref="S4.E2.m1.4.5.2.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1b" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.5" xref="S4.E2.m1.4.5.2.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1c" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.6" xref="S4.E2.m1.4.5.2.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1d" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.7" xref="S4.E2.m1.4.5.2.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1e" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.8" xref="S4.E2.m1.4.5.2.8.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1f" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.9" xref="S4.E2.m1.4.5.2.9.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1g" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.10" xref="S4.E2.m1.4.5.2.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.5.2.1h" xref="S4.E2.m1.4.5.2.1.cmml">​</mo><mi id="S4.E2.m1.4.5.2.11" xref="S4.E2.m1.4.5.2.11.cmml">y</mi></mrow><mo id="S4.E2.m1.4.5.1" xref="S4.E2.m1.4.5.1.cmml">=</mo><mfrac id="S4.E2.m1.4.4" xref="S4.E2.m1.4.4.cmml"><mrow id="S4.E2.m1.2.2.2.2" xref="S4.E2.m1.2.2.2.3.cmml"><msub id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.2.cmml">x</mi><mn id="S4.E2.m1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo lspace="0em" rspace="0.167em" id="S4.E2.m1.2.2.2.2.3" xref="S4.E2.m1.2.2.2.3a.cmml">.</mo><msub id="S4.E2.m1.2.2.2.2.2" xref="S4.E2.m1.2.2.2.2.2.cmml"><mi id="S4.E2.m1.2.2.2.2.2.2" xref="S4.E2.m1.2.2.2.2.2.2.cmml">x</mi><mn id="S4.E2.m1.2.2.2.2.2.3" xref="S4.E2.m1.2.2.2.2.2.3.cmml">2</mn></msub></mrow><mrow id="S4.E2.m1.4.4.4" xref="S4.E2.m1.4.4.4.cmml"><msub id="S4.E2.m1.3.3.3.1" xref="S4.E2.m1.3.3.3.1.cmml"><mrow id="S4.E2.m1.3.3.3.1.1.1" xref="S4.E2.m1.3.3.3.1.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.3.1.1.1.2" xref="S4.E2.m1.3.3.3.1.1.2.1.cmml">‖</mo><msub id="S4.E2.m1.3.3.3.1.1.1.1" xref="S4.E2.m1.3.3.3.1.1.1.1.cmml"><mi id="S4.E2.m1.3.3.3.1.1.1.1.2" xref="S4.E2.m1.3.3.3.1.1.1.1.2.cmml">x</mi><mn id="S4.E2.m1.3.3.3.1.1.1.1.3" xref="S4.E2.m1.3.3.3.1.1.1.1.3.cmml">1</mn></msub><mo stretchy="false" id="S4.E2.m1.3.3.3.1.1.1.3" xref="S4.E2.m1.3.3.3.1.1.2.1.cmml">‖</mo></mrow><mn id="S4.E2.m1.3.3.3.1.3" xref="S4.E2.m1.3.3.3.1.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S4.E2.m1.4.4.4.3" xref="S4.E2.m1.4.4.4.3.cmml">​</mo><msub id="S4.E2.m1.4.4.4.2" xref="S4.E2.m1.4.4.4.2.cmml"><mrow id="S4.E2.m1.4.4.4.2.1.1" xref="S4.E2.m1.4.4.4.2.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.4.4.4.2.1.1.2" xref="S4.E2.m1.4.4.4.2.1.2.1.cmml">‖</mo><msub id="S4.E2.m1.4.4.4.2.1.1.1" xref="S4.E2.m1.4.4.4.2.1.1.1.cmml"><mi id="S4.E2.m1.4.4.4.2.1.1.1.2" xref="S4.E2.m1.4.4.4.2.1.1.1.2.cmml">x</mi><mn id="S4.E2.m1.4.4.4.2.1.1.1.3" xref="S4.E2.m1.4.4.4.2.1.1.1.3.cmml">2</mn></msub><mo stretchy="false" id="S4.E2.m1.4.4.4.2.1.1.3" xref="S4.E2.m1.4.4.4.2.1.2.1.cmml">‖</mo></mrow><mn id="S4.E2.m1.4.4.4.2.3" xref="S4.E2.m1.4.4.4.2.3.cmml">2</mn></msub></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.4b"><apply id="S4.E2.m1.4.5.cmml" xref="S4.E2.m1.4.5"><eq id="S4.E2.m1.4.5.1.cmml" xref="S4.E2.m1.4.5.1"></eq><apply id="S4.E2.m1.4.5.2.cmml" xref="S4.E2.m1.4.5.2"><times id="S4.E2.m1.4.5.2.1.cmml" xref="S4.E2.m1.4.5.2.1"></times><ci id="S4.E2.m1.4.5.2.2.cmml" xref="S4.E2.m1.4.5.2.2">𝑠</ci><ci id="S4.E2.m1.4.5.2.3.cmml" xref="S4.E2.m1.4.5.2.3">𝑖</ci><ci id="S4.E2.m1.4.5.2.4.cmml" xref="S4.E2.m1.4.5.2.4">𝑚</ci><ci id="S4.E2.m1.4.5.2.5.cmml" xref="S4.E2.m1.4.5.2.5">𝑖</ci><ci id="S4.E2.m1.4.5.2.6.cmml" xref="S4.E2.m1.4.5.2.6">𝑙</ci><ci id="S4.E2.m1.4.5.2.7.cmml" xref="S4.E2.m1.4.5.2.7">𝑎</ci><ci id="S4.E2.m1.4.5.2.8.cmml" xref="S4.E2.m1.4.5.2.8">𝑟</ci><ci id="S4.E2.m1.4.5.2.9.cmml" xref="S4.E2.m1.4.5.2.9">𝑖</ci><ci id="S4.E2.m1.4.5.2.10.cmml" xref="S4.E2.m1.4.5.2.10">𝑡</ci><ci id="S4.E2.m1.4.5.2.11.cmml" xref="S4.E2.m1.4.5.2.11">𝑦</ci></apply><apply id="S4.E2.m1.4.4.cmml" xref="S4.E2.m1.4.4"><divide id="S4.E2.m1.4.4.5.cmml" xref="S4.E2.m1.4.4"></divide><apply id="S4.E2.m1.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.2.3a.cmml" xref="S4.E2.m1.2.2.2.2.3">formulae-sequence</csymbol><apply id="S4.E2.m1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3">1</cn></apply><apply id="S4.E2.m1.2.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.2.2.2.1.cmml" xref="S4.E2.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.E2.m1.2.2.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2.2.2">𝑥</ci><cn type="integer" id="S4.E2.m1.2.2.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.2.2.3">2</cn></apply></apply><apply id="S4.E2.m1.4.4.4.cmml" xref="S4.E2.m1.4.4.4"><times id="S4.E2.m1.4.4.4.3.cmml" xref="S4.E2.m1.4.4.4.3"></times><apply id="S4.E2.m1.3.3.3.1.cmml" xref="S4.E2.m1.3.3.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.3.1.2.cmml" xref="S4.E2.m1.3.3.3.1">subscript</csymbol><apply id="S4.E2.m1.3.3.3.1.1.2.cmml" xref="S4.E2.m1.3.3.3.1.1.1"><csymbol cd="latexml" id="S4.E2.m1.3.3.3.1.1.2.1.cmml" xref="S4.E2.m1.3.3.3.1.1.1.2">norm</csymbol><apply id="S4.E2.m1.3.3.3.1.1.1.1.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.3.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.3.3.3.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1.2">𝑥</ci><cn type="integer" id="S4.E2.m1.3.3.3.1.1.1.1.3.cmml" xref="S4.E2.m1.3.3.3.1.1.1.1.3">1</cn></apply></apply><cn type="integer" id="S4.E2.m1.3.3.3.1.3.cmml" xref="S4.E2.m1.3.3.3.1.3">2</cn></apply><apply id="S4.E2.m1.4.4.4.2.cmml" xref="S4.E2.m1.4.4.4.2"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.4.2.2.cmml" xref="S4.E2.m1.4.4.4.2">subscript</csymbol><apply id="S4.E2.m1.4.4.4.2.1.2.cmml" xref="S4.E2.m1.4.4.4.2.1.1"><csymbol cd="latexml" id="S4.E2.m1.4.4.4.2.1.2.1.cmml" xref="S4.E2.m1.4.4.4.2.1.1.2">norm</csymbol><apply id="S4.E2.m1.4.4.4.2.1.1.1.cmml" xref="S4.E2.m1.4.4.4.2.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.4.2.1.1.1.1.cmml" xref="S4.E2.m1.4.4.4.2.1.1.1">subscript</csymbol><ci id="S4.E2.m1.4.4.4.2.1.1.1.2.cmml" xref="S4.E2.m1.4.4.4.2.1.1.1.2">𝑥</ci><cn type="integer" id="S4.E2.m1.4.4.4.2.1.1.1.3.cmml" xref="S4.E2.m1.4.4.4.2.1.1.1.3">2</cn></apply></apply><cn type="integer" id="S4.E2.m1.4.4.4.2.3.cmml" xref="S4.E2.m1.4.4.4.2.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.4c">similarity=\frac{x_{1}.x_{2}}{||x_{1}||_{2}||x_{2}||_{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS3.p1.3" class="ltx_p">where <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="x_{1}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><msub id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">x</mi><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">𝑥</ci><cn type="integer" id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">x_{1}</annotation></semantics></math> and <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="x_{2}" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><msub id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">x</mi><mn id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">𝑥</ci><cn type="integer" id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">x_{2}</annotation></semantics></math> refers to the reference feature map present in the temporary memory and the feature maps from the unsupervised dataset, <math id="S4.SS3.p1.3.m3.1" class="ltx_math_unparsed" alttext="||.||_{2}" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mrow id="S4.SS3.p1.3.m3.1b"><mo fence="false" rspace="0.167em" stretchy="false" id="S4.SS3.p1.3.m3.1.1">|</mo><mo fence="false" stretchy="false" id="S4.SS3.p1.3.m3.1.2">|</mo><mo lspace="0.167em" rspace="0.167em" id="S4.SS3.p1.3.m3.1.3">.</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S4.SS3.p1.3.m3.1.4">|</mo><msub id="S4.SS3.p1.3.m3.1.5"><mo fence="false" stretchy="false" id="S4.SS3.p1.3.m3.1.5.2">|</mo><mn id="S4.SS3.p1.3.m3.1.5.3">2</mn></msub></mrow><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">||.||_{2}</annotation></semantics></math> refers to the l2 norm of the two tensors. If the value of the cosine similarity is greater than a certain threshold, we then train the exFeCAM algorithm on the respective feature maps and its associated pseudo labels.
These pseudo-labels are derived from the class labels used for feature matching. The prototype values for that class are subsequently updated using the averaging rule described in the previous section. To determine the threshold value, we employ the Optuna framework <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib84" title="" class="ltx_ref">Akiba et al.</a></cite>, which uses bayesian optimization to explore the hyperparameter space efficiently.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2409.13792/assets/figs/fecam_algorithm.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="425" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Modified FeCAM algorithm with intra layer feature representation, online batchwise learning, and semi-supervised learning capabilities for multimodal training. During training on multiple domains, the algorithm stores the mean and covariance matrices of the classes in a dictionary. In the testing phase, the algorithm uses these stored prototypes and employs the Mahalanobis distance to determine the prediction class. Supervised training is depicted with solid black lines, while unsupervised training is illustrated with dashed black lines.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Multimodal Training</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.5" class="ltx_p">We extend the class-incremental continual learning to a more realistic semi-supervised continual learning (SSCL) setting, where data distributions reflect existing object class correlations between, and among, the labeled and unlabeled data distributions. For our experiment we use 70% labeled data and 30% unlabeled data for the two protocols (random and unseen) discussed above. At task n, we denote batches of labeled data as <math id="S4.SS4.p1.1.m1.5" class="ltx_Math" alttext="X_{n}={(x_{b},y_{b}):b_{i}\in(1,...,b)|y_{b}\in\tau_{n}}" display="inline"><semantics id="S4.SS4.p1.1.m1.5a"><mrow id="S4.SS4.p1.1.m1.5.5" xref="S4.SS4.p1.1.m1.5.5.cmml"><mrow id="S4.SS4.p1.1.m1.5.5.2" xref="S4.SS4.p1.1.m1.5.5.2.cmml"><msub id="S4.SS4.p1.1.m1.5.5.2.4" xref="S4.SS4.p1.1.m1.5.5.2.4.cmml"><mi id="S4.SS4.p1.1.m1.5.5.2.4.2" xref="S4.SS4.p1.1.m1.5.5.2.4.2.cmml">X</mi><mi id="S4.SS4.p1.1.m1.5.5.2.4.3" xref="S4.SS4.p1.1.m1.5.5.2.4.3.cmml">n</mi></msub><mo id="S4.SS4.p1.1.m1.5.5.2.3" xref="S4.SS4.p1.1.m1.5.5.2.3.cmml">=</mo><mrow id="S4.SS4.p1.1.m1.5.5.2.2.2" xref="S4.SS4.p1.1.m1.5.5.2.2.3.cmml"><mo stretchy="false" id="S4.SS4.p1.1.m1.5.5.2.2.2.3" xref="S4.SS4.p1.1.m1.5.5.2.2.3.cmml">(</mo><msub id="S4.SS4.p1.1.m1.4.4.1.1.1.1" xref="S4.SS4.p1.1.m1.4.4.1.1.1.1.cmml"><mi id="S4.SS4.p1.1.m1.4.4.1.1.1.1.2" xref="S4.SS4.p1.1.m1.4.4.1.1.1.1.2.cmml">x</mi><mi id="S4.SS4.p1.1.m1.4.4.1.1.1.1.3" xref="S4.SS4.p1.1.m1.4.4.1.1.1.1.3.cmml">b</mi></msub><mo id="S4.SS4.p1.1.m1.5.5.2.2.2.4" xref="S4.SS4.p1.1.m1.5.5.2.2.3.cmml">,</mo><msub id="S4.SS4.p1.1.m1.5.5.2.2.2.2" xref="S4.SS4.p1.1.m1.5.5.2.2.2.2.cmml"><mi id="S4.SS4.p1.1.m1.5.5.2.2.2.2.2" xref="S4.SS4.p1.1.m1.5.5.2.2.2.2.2.cmml">y</mi><mi id="S4.SS4.p1.1.m1.5.5.2.2.2.2.3" xref="S4.SS4.p1.1.m1.5.5.2.2.2.2.3.cmml">b</mi></msub><mo rspace="0.278em" stretchy="false" id="S4.SS4.p1.1.m1.5.5.2.2.2.5" xref="S4.SS4.p1.1.m1.5.5.2.2.3.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S4.SS4.p1.1.m1.5.5.3" xref="S4.SS4.p1.1.m1.5.5.3.cmml">:</mo><mrow id="S4.SS4.p1.1.m1.5.5.4" xref="S4.SS4.p1.1.m1.5.5.4.cmml"><msub id="S4.SS4.p1.1.m1.5.5.4.2" xref="S4.SS4.p1.1.m1.5.5.4.2.cmml"><mi id="S4.SS4.p1.1.m1.5.5.4.2.2" xref="S4.SS4.p1.1.m1.5.5.4.2.2.cmml">b</mi><mi id="S4.SS4.p1.1.m1.5.5.4.2.3" xref="S4.SS4.p1.1.m1.5.5.4.2.3.cmml">i</mi></msub><mo id="S4.SS4.p1.1.m1.5.5.4.3" xref="S4.SS4.p1.1.m1.5.5.4.3.cmml">∈</mo><mrow id="S4.SS4.p1.1.m1.5.5.4.4" xref="S4.SS4.p1.1.m1.5.5.4.4.cmml"><mrow id="S4.SS4.p1.1.m1.5.5.4.4.2.2" xref="S4.SS4.p1.1.m1.5.5.4.4.2.1.cmml"><mo stretchy="false" id="S4.SS4.p1.1.m1.5.5.4.4.2.2.1" xref="S4.SS4.p1.1.m1.5.5.4.4.2.1.cmml">(</mo><mn id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">1</mn><mo id="S4.SS4.p1.1.m1.5.5.4.4.2.2.2" xref="S4.SS4.p1.1.m1.5.5.4.4.2.1.cmml">,</mo><mi mathvariant="normal" id="S4.SS4.p1.1.m1.2.2" xref="S4.SS4.p1.1.m1.2.2.cmml">…</mi><mo id="S4.SS4.p1.1.m1.5.5.4.4.2.2.3" xref="S4.SS4.p1.1.m1.5.5.4.4.2.1.cmml">,</mo><mi id="S4.SS4.p1.1.m1.3.3" xref="S4.SS4.p1.1.m1.3.3.cmml">b</mi><mo stretchy="false" id="S4.SS4.p1.1.m1.5.5.4.4.2.2.4" xref="S4.SS4.p1.1.m1.5.5.4.4.2.1.cmml">)</mo></mrow><mo fence="false" id="S4.SS4.p1.1.m1.5.5.4.4.1" xref="S4.SS4.p1.1.m1.5.5.4.4.1.cmml">|</mo><msub id="S4.SS4.p1.1.m1.5.5.4.4.3" xref="S4.SS4.p1.1.m1.5.5.4.4.3.cmml"><mi id="S4.SS4.p1.1.m1.5.5.4.4.3.2" xref="S4.SS4.p1.1.m1.5.5.4.4.3.2.cmml">y</mi><mi id="S4.SS4.p1.1.m1.5.5.4.4.3.3" xref="S4.SS4.p1.1.m1.5.5.4.4.3.3.cmml">b</mi></msub></mrow><mo id="S4.SS4.p1.1.m1.5.5.4.5" xref="S4.SS4.p1.1.m1.5.5.4.5.cmml">∈</mo><msub id="S4.SS4.p1.1.m1.5.5.4.6" xref="S4.SS4.p1.1.m1.5.5.4.6.cmml"><mi id="S4.SS4.p1.1.m1.5.5.4.6.2" xref="S4.SS4.p1.1.m1.5.5.4.6.2.cmml">τ</mi><mi id="S4.SS4.p1.1.m1.5.5.4.6.3" xref="S4.SS4.p1.1.m1.5.5.4.6.3.cmml">n</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.5b"><apply id="S4.SS4.p1.1.m1.5.5.cmml" xref="S4.SS4.p1.1.m1.5.5"><ci id="S4.SS4.p1.1.m1.5.5.3.cmml" xref="S4.SS4.p1.1.m1.5.5.3">:</ci><apply id="S4.SS4.p1.1.m1.5.5.2.cmml" xref="S4.SS4.p1.1.m1.5.5.2"><eq id="S4.SS4.p1.1.m1.5.5.2.3.cmml" xref="S4.SS4.p1.1.m1.5.5.2.3"></eq><apply id="S4.SS4.p1.1.m1.5.5.2.4.cmml" xref="S4.SS4.p1.1.m1.5.5.2.4"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.5.5.2.4.1.cmml" xref="S4.SS4.p1.1.m1.5.5.2.4">subscript</csymbol><ci id="S4.SS4.p1.1.m1.5.5.2.4.2.cmml" xref="S4.SS4.p1.1.m1.5.5.2.4.2">𝑋</ci><ci id="S4.SS4.p1.1.m1.5.5.2.4.3.cmml" xref="S4.SS4.p1.1.m1.5.5.2.4.3">𝑛</ci></apply><interval closure="open" id="S4.SS4.p1.1.m1.5.5.2.2.3.cmml" xref="S4.SS4.p1.1.m1.5.5.2.2.2"><apply id="S4.SS4.p1.1.m1.4.4.1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.4.4.1.1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S4.SS4.p1.1.m1.4.4.1.1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.4.4.1.1.1.1.2">𝑥</ci><ci id="S4.SS4.p1.1.m1.4.4.1.1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.4.4.1.1.1.1.3">𝑏</ci></apply><apply id="S4.SS4.p1.1.m1.5.5.2.2.2.2.cmml" xref="S4.SS4.p1.1.m1.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.5.5.2.2.2.2.1.cmml" xref="S4.SS4.p1.1.m1.5.5.2.2.2.2">subscript</csymbol><ci id="S4.SS4.p1.1.m1.5.5.2.2.2.2.2.cmml" xref="S4.SS4.p1.1.m1.5.5.2.2.2.2.2">𝑦</ci><ci id="S4.SS4.p1.1.m1.5.5.2.2.2.2.3.cmml" xref="S4.SS4.p1.1.m1.5.5.2.2.2.2.3">𝑏</ci></apply></interval></apply><apply id="S4.SS4.p1.1.m1.5.5.4.cmml" xref="S4.SS4.p1.1.m1.5.5.4"><and id="S4.SS4.p1.1.m1.5.5.4a.cmml" xref="S4.SS4.p1.1.m1.5.5.4"></and><apply id="S4.SS4.p1.1.m1.5.5.4b.cmml" xref="S4.SS4.p1.1.m1.5.5.4"><in id="S4.SS4.p1.1.m1.5.5.4.3.cmml" xref="S4.SS4.p1.1.m1.5.5.4.3"></in><apply id="S4.SS4.p1.1.m1.5.5.4.2.cmml" xref="S4.SS4.p1.1.m1.5.5.4.2"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.5.5.4.2.1.cmml" xref="S4.SS4.p1.1.m1.5.5.4.2">subscript</csymbol><ci id="S4.SS4.p1.1.m1.5.5.4.2.2.cmml" xref="S4.SS4.p1.1.m1.5.5.4.2.2">𝑏</ci><ci id="S4.SS4.p1.1.m1.5.5.4.2.3.cmml" xref="S4.SS4.p1.1.m1.5.5.4.2.3">𝑖</ci></apply><apply id="S4.SS4.p1.1.m1.5.5.4.4.cmml" xref="S4.SS4.p1.1.m1.5.5.4.4"><csymbol cd="latexml" id="S4.SS4.p1.1.m1.5.5.4.4.1.cmml" xref="S4.SS4.p1.1.m1.5.5.4.4.1">conditional</csymbol><vector id="S4.SS4.p1.1.m1.5.5.4.4.2.1.cmml" xref="S4.SS4.p1.1.m1.5.5.4.4.2.2"><cn type="integer" id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">1</cn><ci id="S4.SS4.p1.1.m1.2.2.cmml" xref="S4.SS4.p1.1.m1.2.2">…</ci><ci id="S4.SS4.p1.1.m1.3.3.cmml" xref="S4.SS4.p1.1.m1.3.3">𝑏</ci></vector><apply id="S4.SS4.p1.1.m1.5.5.4.4.3.cmml" xref="S4.SS4.p1.1.m1.5.5.4.4.3"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.5.5.4.4.3.1.cmml" xref="S4.SS4.p1.1.m1.5.5.4.4.3">subscript</csymbol><ci id="S4.SS4.p1.1.m1.5.5.4.4.3.2.cmml" xref="S4.SS4.p1.1.m1.5.5.4.4.3.2">𝑦</ci><ci id="S4.SS4.p1.1.m1.5.5.4.4.3.3.cmml" xref="S4.SS4.p1.1.m1.5.5.4.4.3.3">𝑏</ci></apply></apply></apply><apply id="S4.SS4.p1.1.m1.5.5.4c.cmml" xref="S4.SS4.p1.1.m1.5.5.4"><in id="S4.SS4.p1.1.m1.5.5.4.5.cmml" xref="S4.SS4.p1.1.m1.5.5.4.5"></in><share href="#S4.SS4.p1.1.m1.5.5.4.4.cmml" id="S4.SS4.p1.1.m1.5.5.4d.cmml" xref="S4.SS4.p1.1.m1.5.5.4"></share><apply id="S4.SS4.p1.1.m1.5.5.4.6.cmml" xref="S4.SS4.p1.1.m1.5.5.4.6"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.5.5.4.6.1.cmml" xref="S4.SS4.p1.1.m1.5.5.4.6">subscript</csymbol><ci id="S4.SS4.p1.1.m1.5.5.4.6.2.cmml" xref="S4.SS4.p1.1.m1.5.5.4.6.2">𝜏</ci><ci id="S4.SS4.p1.1.m1.5.5.4.6.3.cmml" xref="S4.SS4.p1.1.m1.5.5.4.6.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.5c">X_{n}={(x_{b},y_{b}):b_{i}\in(1,...,b)|y_{b}\in\tau_{n}}</annotation></semantics></math> and batches of unlabeled data as <math id="S4.SS4.p1.2.m2.4" class="ltx_Math" alttext="X_{n}^{{}^{\prime}}={(x_{b}^{{}^{\prime}}):b_{i}\in(1,...,b)}" display="inline"><semantics id="S4.SS4.p1.2.m2.4a"><mrow id="S4.SS4.p1.2.m2.4.4" xref="S4.SS4.p1.2.m2.4.4.cmml"><mrow id="S4.SS4.p1.2.m2.4.4.1" xref="S4.SS4.p1.2.m2.4.4.1.cmml"><msubsup id="S4.SS4.p1.2.m2.4.4.1.3" xref="S4.SS4.p1.2.m2.4.4.1.3.cmml"><mi id="S4.SS4.p1.2.m2.4.4.1.3.2.2" xref="S4.SS4.p1.2.m2.4.4.1.3.2.2.cmml">X</mi><mi id="S4.SS4.p1.2.m2.4.4.1.3.2.3" xref="S4.SS4.p1.2.m2.4.4.1.3.2.3.cmml">n</mi><msup id="S4.SS4.p1.2.m2.4.4.1.3.3" xref="S4.SS4.p1.2.m2.4.4.1.3.3.cmml"><mi id="S4.SS4.p1.2.m2.4.4.1.3.3a" xref="S4.SS4.p1.2.m2.4.4.1.3.3.cmml"></mi><mo id="S4.SS4.p1.2.m2.4.4.1.3.3.1" xref="S4.SS4.p1.2.m2.4.4.1.3.3.1.cmml">′</mo></msup></msubsup><mo id="S4.SS4.p1.2.m2.4.4.1.2" xref="S4.SS4.p1.2.m2.4.4.1.2.cmml">=</mo><mrow id="S4.SS4.p1.2.m2.4.4.1.1.1" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS4.p1.2.m2.4.4.1.1.1.2" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.cmml">(</mo><msubsup id="S4.SS4.p1.2.m2.4.4.1.1.1.1" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.cmml"><mi id="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.2" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.2.cmml">x</mi><mi id="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.3" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.3.cmml">b</mi><msup id="S4.SS4.p1.2.m2.4.4.1.1.1.1.3" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.3.cmml"><mi id="S4.SS4.p1.2.m2.4.4.1.1.1.1.3a" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.3.cmml"></mi><mo id="S4.SS4.p1.2.m2.4.4.1.1.1.1.3.1" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.3.1.cmml">′</mo></msup></msubsup><mo rspace="0.278em" stretchy="false" id="S4.SS4.p1.2.m2.4.4.1.1.1.3" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S4.SS4.p1.2.m2.4.4.2" xref="S4.SS4.p1.2.m2.4.4.2.cmml">:</mo><mrow id="S4.SS4.p1.2.m2.4.4.3" xref="S4.SS4.p1.2.m2.4.4.3.cmml"><msub id="S4.SS4.p1.2.m2.4.4.3.2" xref="S4.SS4.p1.2.m2.4.4.3.2.cmml"><mi id="S4.SS4.p1.2.m2.4.4.3.2.2" xref="S4.SS4.p1.2.m2.4.4.3.2.2.cmml">b</mi><mi id="S4.SS4.p1.2.m2.4.4.3.2.3" xref="S4.SS4.p1.2.m2.4.4.3.2.3.cmml">i</mi></msub><mo id="S4.SS4.p1.2.m2.4.4.3.1" xref="S4.SS4.p1.2.m2.4.4.3.1.cmml">∈</mo><mrow id="S4.SS4.p1.2.m2.4.4.3.3.2" xref="S4.SS4.p1.2.m2.4.4.3.3.1.cmml"><mo stretchy="false" id="S4.SS4.p1.2.m2.4.4.3.3.2.1" xref="S4.SS4.p1.2.m2.4.4.3.3.1.cmml">(</mo><mn id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">1</mn><mo id="S4.SS4.p1.2.m2.4.4.3.3.2.2" xref="S4.SS4.p1.2.m2.4.4.3.3.1.cmml">,</mo><mi mathvariant="normal" id="S4.SS4.p1.2.m2.2.2" xref="S4.SS4.p1.2.m2.2.2.cmml">…</mi><mo id="S4.SS4.p1.2.m2.4.4.3.3.2.3" xref="S4.SS4.p1.2.m2.4.4.3.3.1.cmml">,</mo><mi id="S4.SS4.p1.2.m2.3.3" xref="S4.SS4.p1.2.m2.3.3.cmml">b</mi><mo stretchy="false" id="S4.SS4.p1.2.m2.4.4.3.3.2.4" xref="S4.SS4.p1.2.m2.4.4.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.4b"><apply id="S4.SS4.p1.2.m2.4.4.cmml" xref="S4.SS4.p1.2.m2.4.4"><ci id="S4.SS4.p1.2.m2.4.4.2.cmml" xref="S4.SS4.p1.2.m2.4.4.2">:</ci><apply id="S4.SS4.p1.2.m2.4.4.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1"><eq id="S4.SS4.p1.2.m2.4.4.1.2.cmml" xref="S4.SS4.p1.2.m2.4.4.1.2"></eq><apply id="S4.SS4.p1.2.m2.4.4.1.3.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3"><csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.1.3.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3">superscript</csymbol><apply id="S4.SS4.p1.2.m2.4.4.1.3.2.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3"><csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.1.3.2.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3">subscript</csymbol><ci id="S4.SS4.p1.2.m2.4.4.1.3.2.2.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3.2.2">𝑋</ci><ci id="S4.SS4.p1.2.m2.4.4.1.3.2.3.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3.2.3">𝑛</ci></apply><apply id="S4.SS4.p1.2.m2.4.4.1.3.3.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3.3"><ci id="S4.SS4.p1.2.m2.4.4.1.3.3.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1.3.3.1">′</ci></apply></apply><apply id="S4.SS4.p1.2.m2.4.4.1.1.1.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.1.1.1.1.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1">superscript</csymbol><apply id="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1">subscript</csymbol><ci id="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.2.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.2">𝑥</ci><ci id="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.3.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.2.3">𝑏</ci></apply><apply id="S4.SS4.p1.2.m2.4.4.1.1.1.1.3.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.3"><ci id="S4.SS4.p1.2.m2.4.4.1.1.1.1.3.1.cmml" xref="S4.SS4.p1.2.m2.4.4.1.1.1.1.3.1">′</ci></apply></apply></apply><apply id="S4.SS4.p1.2.m2.4.4.3.cmml" xref="S4.SS4.p1.2.m2.4.4.3"><in id="S4.SS4.p1.2.m2.4.4.3.1.cmml" xref="S4.SS4.p1.2.m2.4.4.3.1"></in><apply id="S4.SS4.p1.2.m2.4.4.3.2.cmml" xref="S4.SS4.p1.2.m2.4.4.3.2"><csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.4.4.3.2.1.cmml" xref="S4.SS4.p1.2.m2.4.4.3.2">subscript</csymbol><ci id="S4.SS4.p1.2.m2.4.4.3.2.2.cmml" xref="S4.SS4.p1.2.m2.4.4.3.2.2">𝑏</ci><ci id="S4.SS4.p1.2.m2.4.4.3.2.3.cmml" xref="S4.SS4.p1.2.m2.4.4.3.2.3">𝑖</ci></apply><vector id="S4.SS4.p1.2.m2.4.4.3.3.1.cmml" xref="S4.SS4.p1.2.m2.4.4.3.3.2"><cn type="integer" id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">1</cn><ci id="S4.SS4.p1.2.m2.2.2.cmml" xref="S4.SS4.p1.2.m2.2.2">…</ci><ci id="S4.SS4.p1.2.m2.3.3.cmml" xref="S4.SS4.p1.2.m2.3.3">𝑏</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.4c">X_{n}^{{}^{\prime}}={(x_{b}^{{}^{\prime}}):b_{i}\in(1,...,b)}</annotation></semantics></math>, where <math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><mi id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">b</annotation></semantics></math> refers to the batch size. The goal in task <math id="S4.SS4.p1.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS4.p1.4.m4.1a"><mi id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><ci id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">n</annotation></semantics></math> is to learn a model which predicts object class labels for any query input over all classes seen in the current and previous tasks (<math id="S4.SS4.p1.5.m5.1" class="ltx_Math" alttext="\tau_{0}\cup\tau_{1}\cup...\cup\tau_{n}" display="inline"><semantics id="S4.SS4.p1.5.m5.1a"><mrow id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml"><msub id="S4.SS4.p1.5.m5.1.1.2" xref="S4.SS4.p1.5.m5.1.1.2.cmml"><mi id="S4.SS4.p1.5.m5.1.1.2.2" xref="S4.SS4.p1.5.m5.1.1.2.2.cmml">τ</mi><mn id="S4.SS4.p1.5.m5.1.1.2.3" xref="S4.SS4.p1.5.m5.1.1.2.3.cmml">0</mn></msub><mo id="S4.SS4.p1.5.m5.1.1.1" xref="S4.SS4.p1.5.m5.1.1.1.cmml">∪</mo><msub id="S4.SS4.p1.5.m5.1.1.3" xref="S4.SS4.p1.5.m5.1.1.3.cmml"><mi id="S4.SS4.p1.5.m5.1.1.3.2" xref="S4.SS4.p1.5.m5.1.1.3.2.cmml">τ</mi><mn id="S4.SS4.p1.5.m5.1.1.3.3" xref="S4.SS4.p1.5.m5.1.1.3.3.cmml">1</mn></msub><mo id="S4.SS4.p1.5.m5.1.1.1a" xref="S4.SS4.p1.5.m5.1.1.1.cmml">∪</mo><mi mathvariant="normal" id="S4.SS4.p1.5.m5.1.1.4" xref="S4.SS4.p1.5.m5.1.1.4.cmml">…</mi><mo id="S4.SS4.p1.5.m5.1.1.1b" xref="S4.SS4.p1.5.m5.1.1.1.cmml">∪</mo><msub id="S4.SS4.p1.5.m5.1.1.5" xref="S4.SS4.p1.5.m5.1.1.5.cmml"><mi id="S4.SS4.p1.5.m5.1.1.5.2" xref="S4.SS4.p1.5.m5.1.1.5.2.cmml">τ</mi><mi id="S4.SS4.p1.5.m5.1.1.5.3" xref="S4.SS4.p1.5.m5.1.1.5.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><apply id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1"><union id="S4.SS4.p1.5.m5.1.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1.1"></union><apply id="S4.SS4.p1.5.m5.1.1.2.cmml" xref="S4.SS4.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.p1.5.m5.1.1.2.1.cmml" xref="S4.SS4.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS4.p1.5.m5.1.1.2.2.cmml" xref="S4.SS4.p1.5.m5.1.1.2.2">𝜏</ci><cn type="integer" id="S4.SS4.p1.5.m5.1.1.2.3.cmml" xref="S4.SS4.p1.5.m5.1.1.2.3">0</cn></apply><apply id="S4.SS4.p1.5.m5.1.1.3.cmml" xref="S4.SS4.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.p1.5.m5.1.1.3.1.cmml" xref="S4.SS4.p1.5.m5.1.1.3">subscript</csymbol><ci id="S4.SS4.p1.5.m5.1.1.3.2.cmml" xref="S4.SS4.p1.5.m5.1.1.3.2">𝜏</ci><cn type="integer" id="S4.SS4.p1.5.m5.1.1.3.3.cmml" xref="S4.SS4.p1.5.m5.1.1.3.3">1</cn></apply><ci id="S4.SS4.p1.5.m5.1.1.4.cmml" xref="S4.SS4.p1.5.m5.1.1.4">…</ci><apply id="S4.SS4.p1.5.m5.1.1.5.cmml" xref="S4.SS4.p1.5.m5.1.1.5"><csymbol cd="ambiguous" id="S4.SS4.p1.5.m5.1.1.5.1.cmml" xref="S4.SS4.p1.5.m5.1.1.5">subscript</csymbol><ci id="S4.SS4.p1.5.m5.1.1.5.2.cmml" xref="S4.SS4.p1.5.m5.1.1.5.2">𝜏</ci><ci id="S4.SS4.p1.5.m5.1.1.5.3.cmml" xref="S4.SS4.p1.5.m5.1.1.5.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">\tau_{0}\cup\tau_{1}\cup...\cup\tau_{n}</annotation></semantics></math>). During each training step the model receives different classes incrementally over all the experiences for each domain as shown in Figure <a href="#S2.F1" title="Figure 1 ‣ 2.3 Multimodality ‣ 2 Related Work ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The two domains contain data from different modalities specifically domain 1 contains the sensor data whereas domain 2 contains the vision data. The data for each task goes through a feature extractor to derive the feature maps from the different layers of the network. The feature maps for both domains are standardized to a fixed dimension of 384 and normalized to fall within the 0-1 range before being fed into the subsequent stages of the algorithm. These feature maps are then used to incrementally train the exFecam algorithm. During training for each task in the second domain, a small subset of the feature maps of the object is stored in a temporary memory buffer to facilitate pseudo-labeling for semi-supervised learning, as previously discussed.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">The feature maps are used to compute the mean and covariance matrix for each batch during training. The model performs covariance matrix approximation, shrinkage, and normalization to stabilize the training process <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib7" title="" class="ltx_ref">Goswami et al.</a></cite>. During the test phase, the extracted feature maps from the test dataset are used to calculate the Mahalanobis distance for all seen classes, and the class with the minimum distance value is selected as the output class. More details about the implementation of the algorithm is provided in the pseudo code. Additionally, we also perform a real-time test for object classification based on the multimodal data using the ROS framework as discussed in section <a href="#S6" title="6 Real-Time Evaluation With ROS ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> of the paper.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2409.13792/assets/figs/ilfr_plot_small.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="283" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Intra layer feature representation for the custom dataset and the Core50 dataset, we compare the improvement in the accuracy of the FeCAM algorithm on addition of knowledge from the last as well the penultimate layers of the pre-trained feature extractors. The improvement in case of Core50 dataset is considerably more than the custom dataset due to the presence of more diverse information in case of image data.</figcaption>
</figure>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">We further analyzed the intra-layer feature representation for both the custom dataset and the Core50 dataset by comparing the accuracy improvement of the exFeCAM algorithm when incorporating knowledge from the last and penultimate layers of pre-trained feature extractors. The Core50 dataset showed a significantly greater improvement in accuracy compared to the custom dataset. The difference is attributed to the more diverse information contained in the image data of the Core50 dataset.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2409.13792/assets/figs/spider_plot.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>On the left: radar plot shows the accuracy of the two domains after incremental training on different tasks. The FeCAM algorithm learns the first domain in a class-incremental approach, while it learns the second domain in a combined domain-incremental and class-incremental manner. On the right: the plot shows domain 1 accuracy (in orange) with random gaussian noise added to it, the solid line in grey shows the percentage improvement in the overall accuracy of the experiences after addition of the second domain. The black lines show the error bars for the two cases.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To assess the performance of our algorithm and the effectiveness of the proposed modifications, we evaluate the exFeCAM algorithm on a custom multimodal dataset and the standard Core50 dataset used in the literature. The Core50 dataset was chosen for its non-iid nature and its compatibility for self-supervised learning. We do not explicitly compare our algorithm with other state-of-the-art (SOTA) benchmarks because the focus of this paper is not to establish a new level of accuracy for object classification, but rather to demonstrate the effectiveness of CL in a real world multimodal training setting. Nevertheless, our results are based on improvements to the original FeCAM algorithm, indirectly providing a comparison. All experiments are repeated three times, and we plot the mean and standard deviation of the respective metrics.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2409.13792/assets/figs/core50_custom_combined.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="469" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Accuracy of the FeCAM algorithm on SSL tasks, the blue and green plot shows the SSL condition for unseen object from the same parent class, with blue indicating SSL enabled and green indicating SSL disabled case. The maroon and red plots represent the SSL condition for randomly selected images of the object, with maroon indicating SSL enabled and red indicating SSL disabled case. Top plot shows the accuracy for the custom multimodal dataset and the botton plot shows the accuracy for the Core50 dataset. The black dotted lines denotes the average accuarcy over all the experiences for different SSL cases.</figcaption>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.5" class="ltx_p">Figure <a href="#S4.F4" title="Figure 4 ‣ 4.4 Multimodal Training ‣ 4 Methodology ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates the improvements in our algorithm’s prediction accuracy with the inclusion of intra-layer feature representation. For the custom dataset (plotted in green), the first five experiences illustrate the percentage improvement in domain 2 data, while the next five experiences indicate the accuracy improvement in domain 1. Each experience comprises two different classes for both the domains. The improvement magnitude for domain 2 is slightly greater than domain 1. The overall improvement for the custom dataset experiment is approximately 3.21 <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.p2.1.m1.1a"><mo id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><csymbol cd="latexml" id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\pm</annotation></semantics></math> 1.43 <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p2.2.m2.1a"><mo id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><csymbol cd="latexml" id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">\%</annotation></semantics></math>, with domain 2 contributing about 1.71 <math id="S5.p2.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p2.3.m3.1a"><mo id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><csymbol cd="latexml" id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">\%</annotation></semantics></math> more than domain 1. This can be attributed to the presence of image data in domain 2, which offers more diverse information across different network layers compared to sensor signal data. This trend is further validated by the core50 experiment (shown in blue), where all 10 experiences involve images, each containing five random classes. In this case, the overall improvement is around 12.39 <math id="S5.p2.4.m4.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.p2.4.m4.1a"><mo id="S5.p2.4.m4.1.1" xref="S5.p2.4.m4.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.p2.4.m4.1b"><csymbol cd="latexml" id="S5.p2.4.m4.1.1.cmml" xref="S5.p2.4.m4.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.m4.1c">\pm</annotation></semantics></math> 0.0 <math id="S5.p2.5.m5.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p2.5.m5.1a"><mo id="S5.p2.5.m5.1.1" xref="S5.p2.5.m5.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p2.5.m5.1b"><csymbol cd="latexml" id="S5.p2.5.m5.1.1.cmml" xref="S5.p2.5.m5.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.5.m5.1c">\%</annotation></semantics></math> compared to the original FeCAM algorithm without intra-layer feature representation.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.4" class="ltx_p">The CL capability of the exFeCAM algorithm is depicted in Figure <a href="#S4.F5" title="Figure 5 ‣ 4.4 Multimodal Training ‣ 4 Methodology ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> (left). The spider plot displays both class incremental and domain incremental accuracy for the two modalities. The class incremental accuracy for the sensor data is represented in orange, while the violet plot corresponds to the combined domain incremental and class incremental scenario for the image data. The results demonstrate that the model can learn new modalities while preserving information from previous ones. The per task accuracy for each domain is clearly visible in the spider plot, and the mean accuracy after completion of all the tasks for domain 1 is 60.63 <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.p3.1.m1.1a"><mo id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><csymbol cd="latexml" id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">\pm</annotation></semantics></math> 6.15<math id="S5.p3.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p3.2.m2.1a"><mo id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><csymbol cd="latexml" id="S5.p3.2.m2.1.1.cmml" xref="S5.p3.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">\%</annotation></semantics></math> whereas for domain 2 is 65.36 <math id="S5.p3.3.m3.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.p3.3.m3.1a"><mo id="S5.p3.3.m3.1.1" xref="S5.p3.3.m3.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.p3.3.m3.1b"><csymbol cd="latexml" id="S5.p3.3.m3.1.1.cmml" xref="S5.p3.3.m3.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.3.m3.1c">\pm</annotation></semantics></math> 0.0 <math id="S5.p3.4.m4.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p3.4.m4.1a"><mo id="S5.p3.4.m4.1.1" xref="S5.p3.4.m4.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p3.4.m4.1b"><csymbol cd="latexml" id="S5.p3.4.m4.1.1.cmml" xref="S5.p3.4.m4.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.4.m4.1c">\%</annotation></semantics></math>. One of the reasons for higher variability in domain 1 can be due to the presence of relatively small sample sizes for training and testing. However, this experiment does not take into consideration the SSL capability of the algorithm and is trained on the complete data in a supervised manner. Figure <a href="#S4.F5" title="Figure 5 ‣ 4.4 Multimodal Training ‣ 4 Methodology ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> (right) demonstrates the advantage of training on a new domain when the information from the first domain (sensors signal) is noisy. To simulate this scenario, gaussian noise was added to the sensor signal data. The solid orange line indicates the accuracy across different experiences for domain 1 with noisy sensor data, while the dashed orange line shows the original accuracy without noise. The solid grey line represents the percentage improvement in accuracy across different experiences when the second domain is added to compensate for the accuracy loss due to the noisy data in domain 1.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.2" class="ltx_p">To demostrate the SSL capabilities, we conducted two distinct types of experiments in the SSL setting, as discussed in Section <a href="#S3.SS3" title="3.3 Evaluation Metrics ‣ 3 Experimental Setup ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>. Figure 4 (top) illustrates the accuracy of the custom dataset within the SSL framework. It is important to note that the SSL technique is applied exclusively to the image data due to the presence of multiple objects for each class. The blue plot depicts the accuracy of the exFeCAM algorithm for the <span id="S5.p4.2.1" class="ltx_text ltx_font_italic">unseen object</span> scenario with SSL enabled, while the green plot shows the accuracy for the same scenario but with SSL disabled. The plots clearly demonstrate that incorporating information about new unseen objects enhances the accuracy over each experience. Similarly, for the <span id="S5.p4.2.2" class="ltx_text ltx_font_italic">random object</span> scenario, the model’s accuracy with SSL, shown in brown, surpasses that of the benchmark case without SSL capabilities, indicated in red. The box plots provide detailed information about the highest and lowest accuracy, the median value (represented by a solid black line), the mean value (represented by a dotted black line), and the Q1 and Q3 quartiles, which encompass approximately 25 <math id="S5.p4.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p4.1.m1.1a"><mo id="S5.p4.1.m1.1.1" xref="S5.p4.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p4.1.m1.1b"><csymbol cd="latexml" id="S5.p4.1.m1.1.1.cmml" xref="S5.p4.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.1.m1.1c">\%</annotation></semantics></math> to 75 <math id="S5.p4.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p4.2.m2.1a"><mo id="S5.p4.2.m2.1.1" xref="S5.p4.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p4.2.m2.1b"><csymbol cd="latexml" id="S5.p4.2.m2.1.1.cmml" xref="S5.p4.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.2.m2.1c">\%</annotation></semantics></math> of the overall accuracy.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2409.13792/assets/figs/ros_flowchart_plot.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="217" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The real-time multimodal experiment using ROS involves three publishers and one subscriber node. The publishers (P1, P2, P3) are depicted in blue, while the subscriber is shown in yellow. P1 operates at a frequency of 20 Hz, P2 operates at 10 Hz, and P3 operates at 0.2 Hz. The output from P3 is used to actuate a soft finger equipped with sensors. The outputs from P1 and P2 are fed to the subscriber, where they undergo pre-processing, feature extraction using a pre-trained network, and finally to the FeCAM algorithm to make the predictions using the saved mean and co-variance matrices.</figcaption>
</figure>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">Figure 4 (bottom) presents similar information for the Core50 dataset, where we employed the same experimental protocols. The key difference lies in the pre-trained model and the pre-training dataset used in this experiment. However, the improvement in accuracy for the Core50 dataset is minimal compared to the custom dataset. This could be attributed to the significant variations in the objects within each class, making the simple cosine similarity method less effective in this context. A more complex SSL method might be more beneficial for this scenario, which we plan to explore in future experiments.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Real-Time Evaluation With ROS</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Robot Operating System (ROS) is a comprehensive framework that comprises a suite of tools, libraries, and protocols aimed at facilitating the development of various robotic systems. The system manages the creation and control of communication between a robot’s peripheral modules, such as sensors, cameras, and actuators, thereby enabling the seamless integration of these components with parallization capabilties.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2409.13792/assets/figs/stapler_signal_train_small.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Real-time images of the object from the camera’s perspective, along with the sensor data from four sensors attached to the soft finger, upon its actuation. These images and sensor readings are directly fed into the FeCAM model after resizing them to the desired dimension. For a single 15-second run, there are a total of 150 sensor signals and 300 images, representing the number of raw data points and corresponding images of the object.</figcaption>
</figure>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>ROS Setup</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">ROS is primarily designed to function optimally on Ubuntu, while only partially compatible with other operating systems, such as Windows and Mac. For our case we use ROS on Ubuntu 20.04 on a Intel Core i7 7th gen CPU <math id="S6.SS1.p1.1.m1.1" class="ltx_Math" alttext="@" display="inline"><semantics id="S6.SS1.p1.1.m1.1a"><mi mathvariant="normal" id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">@</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><ci id="S6.SS1.p1.1.m1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1">@</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">@</annotation></semantics></math> 2.80 GHz equipped with Nvidia GTX 1080 GPU. We use the Noetic Ninjemys distribution of ROS 1 <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib9" title="" class="ltx_ref">Koubaa et al.</a></cite> in our experiment. A detailed explanation about the workflow of the project is provided in the flowchart in Figure <a href="#S5.F7" title="Figure 7 ‣ 5 Results ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="S6.F9" class="ltx_figure"><img src="/html/2409.13792/assets/figs/pressure_plot.png" id="S6.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1030" height="800" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Square wave sent to the control box to actuate the soft pneumatic finger. We pressurise the finger for 3 seconds with a maximum pressure of 1.3 bars and then depressurise it for 2 seconds, the cycle is repeated "N" times till we reach the 15 seconds threshold for each run.</figcaption>
</figure>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">The first publisher (P1) publishes the sensor signals coming from the four sensors attached to the soft finger, the second publisher (P2) publishes the video coming from the camera and the third publisher (P3) publishes the command pressure to the control box which inturn actuates the finger. The control frequency of P1 and P2 are 10hz and 20hz, whereas the actuation frequency of P3 is 0.2hz. We further observed that actuating the finger at a more higher frequency constrained it from properly holding the object and thus effected the quality of the generated data from the sensors. The data from P1 and P2 goes to the subscriber which then pre-process the data, extracts the frames from the video in case of P2 and sends it to the respective feature extractors. The output of the feature extractor is a 384-dimensional feature map (in case the intra-layer feature representation is turned on) which goes as an input to the exFecam model for further processing.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Real-Time Experiment</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">To assess the performance of our algorithm, we conduct a quasi real-time experiment using a soft pneumatic gripper equipped with two flex sensors and two force sensors. During the evaluation phase, data from the sensors and the camera are collected in real-time for approximately 15 seconds. These data are treated as two distinct domains and are sent through the pipeline in parallel for further processing and subsequently to the exFecam model for predictions. To generate the predictions we utilize the stored mean and the co-variance matrix from a prior offline incremental experiment conducted for the two domains. Impressively, the mean and covariance matrix occupy only 22.5 MB of memory, making it quite efficient compared to other continual learning strategies</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">However, since the model was initially trained on images of the objects in a different frame of reference, where the operator extends his arm and smoothly rotates the object in front of the camera. In contrast, during the real-time experiment, the objects are positioned near the soft finger, and a camera captures images from a top-down view. This difference sometimes leads to incorrect predictions by the model. To address this issue, for some objects, we occasionally need to refine the model’s knowledge by conducting a brief training session (lasting around 82 seconds) specifically for that object. Figure <a href="#S6.F8" title="Figure 8 ‣ 6 Real-Time Evaluation With ROS ‣ Continual Learning for Multimodal Data Fusion of a Soft Gripper" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows a snapshot of the real-time data collection from both the sensors and the camera’s perspective. The image shows the progression of the sensor signal and the camera image upon actuating the finger. For each cycle the sensors collect 150 raw values, which are transformed into a single 600-dimensional vector, whereas the camera collects around 300 images of the object from various orientations within the 15-seconds interval.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">As discussed above one of the major advantages of this domain incremental training is for autonomous agents in situations where the field of view of one of the sensors gets restricted due to the presence of some obstacle from the environment, in that case the presence of other sensor can compensate for the missing knowledge.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Real World Application</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">A real world application for such a technique can be in companion robots <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib85" title="" class="ltx_ref">Broadbent et al.</a></cite>, where the robot learns new tasks incrementally by interacting with its environment and recognizing different objects using information from multiple sensors available to it. The use of multiple sensors is particularly advantageous in scenarios where a single sensor cannot provide complete information about an object. For instance, a vision camera might struggle to differentiate between two objects with similar structures but with different textures or materials, with one being much softer than the other. In such cases, information from a tactile sensor can be extremely beneficial. Our proposed framework simplifies the addition of new sensors by treating each as a new domain, eliminating the need to retrain the entire algorithm from scratch each time. All the sensors and the algorithm can be synchronized using a mobile version of ROS for embedded systems <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib86" title="" class="ltx_ref">Min et al.</a></cite>, providing a comprehensive solution.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Discussion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we present a novel continual learning method that combines the informations from different sensors in a domain incremental fashion while also learning new classes or objects in a class incremental manner. We enhanced the original FeCAM algorithm by incorporating online batch-wise training, intra-layer feature representation, and SSL capabilities thereby making the algorithm suitable for our scenario. The exFeCAM algorithm employs cosine similarity based feature matching to perform pseudo labeling when encountering unlabeled data. We validated the algorithm on two different modalities of data namely sensor signal based data and image based data, and demonstrated the ability of the algorithm to learn the two modalities incrementally. We also conducted an ablation study to show the contribution of different parts of the algorithm. Additionally, we performed a real-time experiment on a soft pneumatic gripper equipped with four sensors and an external camera system, all synchronised using the ROS framework. As part of our future work, we aim to enhance the exFeCAM algorithm further by adding forward and backward knowledge capabilities, either through interactions between class prototypes or by training a simple multilayer perceptron (MLP) network to learn these interactions. Moreover, currently we need to manually select the prediction domain modality in the presence of noise; in the future, we aim to enable the algorithm to automatically determine this by calculating the confidence of each prediction from the network.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">CRediT authorship contribution statement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Nilay Kushawaha:</span> Writing - original draft, Methodology, Investigation, Experimentation, Formal Analysis, Conceptualization. <span id="Sx1.p1.1.2" class="ltx_text ltx_font_bold">Egidio Falotico:</span> Supervision, Funding acquisition, Project administration.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Declaration of competing interest</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Data availability</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">Data will be made available on request. The code is available on the github repo : <a target="_blank" href="https://github.com/nilay121/Multimodal-Fusion-using-CL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/nilay121/Multimodal-Fusion-using-CL</a></p>
</div>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">We acknowledge the contribution from the Italian National Recovery and Resilience Plan (NRRP), M4C2, funded by the European Union–NextGenerationEU (Project IR0000011, CUP B51E22000150006, "EBRAINS-Italy")</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmad et al. [2021]</span>
<span class="ltx_bibblock">
M. Ahmad, S. Shabbir, S. K. Roy, D. Hong, X. Wu, J. Yao, A. M. Khan, M. Mazzara, S. Distefano, J. Chanussot,

</span>
<span class="ltx_bibblock">Hyperspectral image classification—traditional to deep models: A survey for future prospects,

</span>
<span class="ltx_bibblock">IEEE journal of selected topics in applied earth observations and remote sensing 15 (2021) 968–999.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et al. [2023]</span>
<span class="ltx_bibblock">
Z. Zou, K. Chen, Z. Shi, Y. Guo, J. Ye,

</span>
<span class="ltx_bibblock">Object detection in 20 years: A survey,

</span>
<span class="ltx_bibblock">Proceedings of the IEEE 111 (2023) 257–276.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Otter et al. [2020]</span>
<span class="ltx_bibblock">
D. W. Otter, J. R. Medina, J. K. Kalita,

</span>
<span class="ltx_bibblock">A survey of the usages of deep learning for natural language processing,

</span>
<span class="ltx_bibblock">IEEE transactions on neural networks and learning systems 32 (2020) 604–624.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2024]</span>
<span class="ltx_bibblock">
L. Wang, X. Zhang, H. Su, J. Zhu,

</span>
<span class="ltx_bibblock">A comprehensive survey of continual learning: theory, method and application,

</span>
<span class="ltx_bibblock">IEEE Transactions on Pattern Analysis and Machine Intelligence (2024).

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lesort et al. [2020]</span>
<span class="ltx_bibblock">
T. Lesort, V. Lomonaco, A. Stoian, D. Maltoni, D. Filliat, N. Díaz-Rodríguez,

</span>
<span class="ltx_bibblock">Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges,

</span>
<span class="ltx_bibblock">Information fusion 58 (2020) 52–68.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Engelen and Hoos [2020]</span>
<span class="ltx_bibblock">
J. E. Van Engelen, H. H. Hoos,

</span>
<span class="ltx_bibblock">A survey on semi-supervised learning,

</span>
<span class="ltx_bibblock">Machine learning 109 (2020) 373–440.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goswami et al. [2024]</span>
<span class="ltx_bibblock">
D. Goswami, Y. Liu, B. Twardowski, J. van de Weijer,

</span>
<span class="ltx_bibblock">Fecam: Exploiting the heterogeneity of class distributions in exemplar-free continual learning,

</span>
<span class="ltx_bibblock">Advances in Neural Information Processing Systems 36 (2024).

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lomonaco and Maltoni [2017]</span>
<span class="ltx_bibblock">
V. Lomonaco, D. Maltoni,

</span>
<span class="ltx_bibblock">Core50: a new dataset and benchmark for continuous object recognition,

</span>
<span class="ltx_bibblock">in: Conference on robot learning, PMLR, 2017, pp. 17–26.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koubaa et al. [2017]</span>
<span class="ltx_bibblock">
A. Koubaa, et al., Robot Operating System (ROS)., volume 1, Springer, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rusu et al. [2016]</span>
<span class="ltx_bibblock">
A. A. Rusu, N. C. Rabinowitz, G. Desjardins, H. Soyer, J. Kirkpatrick, K. Kavukcuoglu, R. Pascanu, R. Hadsell,

</span>
<span class="ltx_bibblock">Progressive neural networks,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1606.04671 (2016).

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernando et al. [2017]</span>
<span class="ltx_bibblock">
C. Fernando, D. Banarse, C. Blundell, Y. Zwols, D. Ha, A. A. Rusu, A. Pritzel, D. Wierstra,

</span>
<span class="ltx_bibblock">Pathnet: Evolution channels gradient descent in super neural networks,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1701.08734 (2017).

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajasegaran et al. [2019]</span>
<span class="ltx_bibblock">
J. Rajasegaran, M. Hayat, S. H. Khan, F. S. Khan, L. Shao,

</span>
<span class="ltx_bibblock">Random path selection for continual learning,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 32 (2019).

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aljundi et al. [2017]</span>
<span class="ltx_bibblock">
R. Aljundi, P. Chakravarty, T. Tuytelaars,

</span>
<span class="ltx_bibblock">Expert gate: Lifelong learning with a network of experts,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 3366–3375.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallya et al. [2018]</span>
<span class="ltx_bibblock">
A. Mallya, D. Davis, S. Lazebnik,

</span>
<span class="ltx_bibblock">Piggyback: Adapting a single network to multiple tasks by learning to mask weights,

</span>
<span class="ltx_bibblock">in: Proceedings of the European conference on computer vision (ECCV), 2018, pp. 67–82.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Serra et al. [2018]</span>
<span class="ltx_bibblock">
J. Serra, D. Suris, M. Miron, A. Karatzoglou,

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting with hard attention to the task,

</span>
<span class="ltx_bibblock">in: International conference on machine learning, PMLR, 2018, pp. 4548–4557.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallya and Lazebnik [2018]</span>
<span class="ltx_bibblock">
A. Mallya, S. Lazebnik,

</span>
<span class="ltx_bibblock">Packnet: Adding multiple tasks to a single network by iterative pruning,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2018, pp. 7765–7773.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahn et al. [2019]</span>
<span class="ltx_bibblock">
H. Ahn, S. Cha, D. Lee, T. Moon,

</span>
<span class="ltx_bibblock">Uncertainty-based continual learning with adaptive regularization,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 32 (2019).

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et al. [2017]</span>
<span class="ltx_bibblock">
J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, et al.,

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks,

</span>
<span class="ltx_bibblock">Proceedings of the national academy of sciences 114 (2017) 3521–3526.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zenke et al. [2017]</span>
<span class="ltx_bibblock">
F. Zenke, B. Poole, S. Ganguli,

</span>
<span class="ltx_bibblock">Continual learning through synaptic intelligence,

</span>
<span class="ltx_bibblock">in: International conference on machine learning, PMLR, 2017, pp. 3987–3995.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhry et al. [2018]</span>
<span class="ltx_bibblock">
A. Chaudhry, P. K. Dokania, T. Ajanthan, P. H. Torr,

</span>
<span class="ltx_bibblock">Riemannian walk for incremental learning: Understanding forgetting and intransigence,

</span>
<span class="ltx_bibblock">in: Proceedings of the European conference on computer vision (ECCV), 2018, pp. 532–547.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aljundi et al. [2018]</span>
<span class="ltx_bibblock">
R. Aljundi, F. Babiloni, M. Elhoseiny, M. Rohrbach, T. Tuytelaars,

</span>
<span class="ltx_bibblock">Memory aware synapses: Learning what (not) to forget,

</span>
<span class="ltx_bibblock">in: Proceedings of the European conference on computer vision (ECCV), 2018, pp. 139–154.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al. [2015]</span>
<span class="ltx_bibblock">
G. Hinton, O. Vinyals, J. Dean,

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1503.02531 (2015).

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Hoiem [2017]</span>
<span class="ltx_bibblock">
Z. Li, D. Hoiem,

</span>
<span class="ltx_bibblock">Learning without forgetting,

</span>
<span class="ltx_bibblock">IEEE transactions on pattern analysis and machine intelligence 40 (2017) 2935–2947.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rebuffi et al. [2017]</span>
<span class="ltx_bibblock">
S.-A. Rebuffi, A. Kolesnikov, G. Sperl, C. H. Lampert,

</span>
<span class="ltx_bibblock">icarl: Incremental classifier and representation learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2017, pp. 2001–2010.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhar et al. [2019]</span>
<span class="ltx_bibblock">
P. Dhar, R. V. Singh, K.-C. Peng, Z. Wu, R. Chellappa,

</span>
<span class="ltx_bibblock">Learning without memorizing,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 5138–5146.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. [2019]</span>
<span class="ltx_bibblock">
K. Lee, K. Lee, J. Shin, H. Lee,

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting with unlabeled data in the wild,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, pp. 312–321.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lopez-Paz and Ranzato [2017]</span>
<span class="ltx_bibblock">
D. Lopez-Paz, M. Ranzato,

</span>
<span class="ltx_bibblock">Gradient episodic memory for continual learning,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 30 (2017).

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bang et al. [2021]</span>
<span class="ltx_bibblock">
J. Bang, H. Kim, Y. Yoo, J.-W. Ha, J. Choi,

</span>
<span class="ltx_bibblock">Rainbow memory: Continual learning with a memory of diverse samples,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 8218–8227.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumari et al. [2022]</span>
<span class="ltx_bibblock">
L. Kumari, S. Wang, T. Zhou, J. A. Bilmes,

</span>
<span class="ltx_bibblock">Retrospective adversarial replay for continual learning,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 35 (2022) 28530–28544.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ebrahimi et al. [2021]</span>
<span class="ltx_bibblock">
S. Ebrahimi, S. Petryk, A. Gokul, W. Gan, J. E. Gonzalez, M. Rohrbach, T. Darrell,

</span>
<span class="ltx_bibblock">Remembering for the right reasons: Explanations reduce catastrophic forgetting,

</span>
<span class="ltx_bibblock">Applied AI letters 2 (2021) e44.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saha and Roy [2023]</span>
<span class="ltx_bibblock">
G. Saha, K. Roy,

</span>
<span class="ltx_bibblock">Saliency guided experience packing for replay in continual learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2023, pp. 5273–5283.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shin et al. [2017]</span>
<span class="ltx_bibblock">
H. Shin, J. K. Lee, J. Kim, J. Kim,

</span>
<span class="ltx_bibblock">Continual learning with deep generative replay,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 30 (2017).

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2018]</span>
<span class="ltx_bibblock">
C. Wu, L. Herranz, X. Liu, J. Van De Weijer, B. Raducanu, et al.,

</span>
<span class="ltx_bibblock">Memory replay gans: Learning to generate new categories without forgetting,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 31 (2018).

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ayub and Wagner [2021]</span>
<span class="ltx_bibblock">
A. Ayub, A. R. Wagner,

</span>
<span class="ltx_bibblock">Eec: Learning to encode and regenerate images for continual learning,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2101.04904 (2021).

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfülb and Gepperth [2021]</span>
<span class="ltx_bibblock">
B. Pfülb, A. Gepperth,

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting with gaussian mixture replay,

</span>
<span class="ltx_bibblock">in: 2021 International Joint Conference on Neural Networks (IJCNN), IEEE, 2021, pp. 1–9.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2022]</span>
<span class="ltx_bibblock">
Z. Wang, L. Liu, Y. Duan, D. Tao,

</span>
<span class="ltx_bibblock">Continual learning through retrieval and imagination,

</span>
<span class="ltx_bibblock">in: Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, 2022, pp. 8594–8602.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van de Ven et al. [2020]</span>
<span class="ltx_bibblock">
G. M. Van de Ven, H. T. Siegelmann, A. S. Tolias,

</span>
<span class="ltx_bibblock">Brain-inspired replay for continual learning with artificial neural networks,

</span>
<span class="ltx_bibblock">Nature communications 11 (2020) 4069.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2020]</span>
<span class="ltx_bibblock">
X. Liu, C. Wu, M. Menta, L. Herranz, B. Raducanu, A. D. Bagdanov, S. Jui, J. v. de Weijer,

</span>
<span class="ltx_bibblock">Generative feature replay for class-incremental learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2020, pp. 226–227.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye and Bors [2020]</span>
<span class="ltx_bibblock">
F. Ye, A. G. Bors,

</span>
<span class="ltx_bibblock">Learning latent representations across multiple data domains using lifelong vaegan,

</span>
<span class="ltx_bibblock">in: Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XX 16, Springer, 2020, pp. 777–795.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kushawaha et al. [2024]</span>
<span class="ltx_bibblock">
N. Kushawaha, L. Fruzzetti, E. Donato, E. Falotico,

</span>
<span class="ltx_bibblock">Synapnet: A complementary learning system inspired algorithm with real-time application in multimodal perception,

</span>
<span class="ltx_bibblock">IEEE Transactions on Neural Networks and Learning Systems (2024).

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pham et al. [2021]</span>
<span class="ltx_bibblock">
Q. Pham, C. Liu, S. Hoi,

</span>
<span class="ltx_bibblock">Dualnet: Continual learning, fast and slow,

</span>
<span class="ltx_bibblock">Advances in Neural Information Processing Systems 34 (2021) 16131–16144.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petit et al. [2023]</span>
<span class="ltx_bibblock">
G. Petit, A. Popescu, H. Schindler, D. Picard, B. Delezoide,

</span>
<span class="ltx_bibblock">Fetril: Feature translation for exemplar-free class-incremental learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF winter conference on applications of computer vision, 2023, pp. 3911–3920.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al. [2021]</span>
<span class="ltx_bibblock">
J. Smith, Y.-C. Hsu, J. Balloch, Y. Shen, H. Jin, Z. Kira,

</span>
<span class="ltx_bibblock">Always be dreaming: A new approach for data-free class-incremental learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF international conference on computer vision, 2021, pp. 9374–9384.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hayes et al. [2020]</span>
<span class="ltx_bibblock">
T. L. Hayes, K. Kafle, R. Shrestha, M. Acharya, C. Kanan,

</span>
<span class="ltx_bibblock">Remind your neural network to prevent catastrophic forgetting,

</span>
<span class="ltx_bibblock">in: European conference on computer vision, Springer, 2020, pp. 466–483.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. [2023]</span>
<span class="ltx_bibblock">
M. Yan, S. C. Hui, N. Li,

</span>
<span class="ltx_bibblock">Dml-pl: Deep metric learning based pseudo-labeling framework for class imbalanced semi-supervised learning,

</span>
<span class="ltx_bibblock">Information Sciences 626 (2023) 641–657.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mawuli et al. [2023]</span>
<span class="ltx_bibblock">
C. B. Mawuli, J. Kumar, E. Nanor, S. Fu, L. Pan, Q. Yang, W. Zhang, J. Shao,

</span>
<span class="ltx_bibblock">Semi-supervised federated learning on evolving data streams,

</span>
<span class="ltx_bibblock">Information Sciences 643 (2023) 119235.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasmus et al. [2015]</span>
<span class="ltx_bibblock">
A. Rasmus, M. Berglund, M. Honkala, H. Valpola, T. Raiko,

</span>
<span class="ltx_bibblock">Semi-supervised learning with ladder networks,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 28 (2015).

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma et al. [2014]</span>
<span class="ltx_bibblock">
D. P. Kingma, S. Mohamed, D. Jimenez Rezende, M. Welling,

</span>
<span class="ltx_bibblock">Semi-supervised learning with deep generative models,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 27 (2014).

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Odena [2016]</span>
<span class="ltx_bibblock">
A. Odena,

</span>
<span class="ltx_bibblock">Semi-supervised learning with generative adversarial networks,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1606.01583 (2016).

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oliver et al. [2018]</span>
<span class="ltx_bibblock">
A. Oliver, A. Odena, C. A. Raffel, E. D. Cubuk, I. Goodfellow,

</span>
<span class="ltx_bibblock">Realistic evaluation of deep semi-supervised learning algorithms,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 31 (2018).

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berthelot et al. [2019]</span>
<span class="ltx_bibblock">
D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, C. A. Raffel,

</span>
<span class="ltx_bibblock">Mixmatch: A holistic approach to semi-supervised learning,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 32 (2019).

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. [2013]</span>
<span class="ltx_bibblock">
D.-H. Lee, et al.,

</span>
<span class="ltx_bibblock">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks,

</span>
<span class="ltx_bibblock">in: Workshop on challenges in representation learning, ICML, volume 3, Atlanta, 2013, p. 896.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuo et al. [2019]</span>
<span class="ltx_bibblock">
C.-W. Kuo, C.-Y. Ma, J.-B. Huang, Z. Kira,

</span>
<span class="ltx_bibblock">Manifold graph with learned prototypes for semi-supervised image classification,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1906.05202 (2019).

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laine and Aila [2016]</span>
<span class="ltx_bibblock">
S. Laine, T. Aila,

</span>
<span class="ltx_bibblock">Temporal ensembling for semi-supervised learning,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1610.02242 (2016).

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tarvainen and Valpola [2017]</span>
<span class="ltx_bibblock">
A. Tarvainen, H. Valpola,

</span>
<span class="ltx_bibblock">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 30 (2017).

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Athiwaratkun et al. [2018]</span>
<span class="ltx_bibblock">
B. Athiwaratkun, M. Finzi, P. Izmailov, A. G. Wilson,

</span>
<span class="ltx_bibblock">There are many consistent explanations of unlabeled data: Why you should average,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1806.05594 (2018).

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2020]</span>
<span class="ltx_bibblock">
Q. Xie, M.-T. Luong, E. Hovy, Q. V. Le,

</span>
<span class="ltx_bibblock">Self-training with noisy student improves imagenet classification,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2020, pp. 10687–10698.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grandvalet and Bengio [2004]</span>
<span class="ltx_bibblock">
Y. Grandvalet, Y. Bengio,

</span>
<span class="ltx_bibblock">Semi-supervised learning by entropy minimization,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 17 (2004).

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Donato et al. [2024]</span>
<span class="ltx_bibblock">
E. Donato, E. Falotico, T. G. Thuruthel,

</span>
<span class="ltx_bibblock">Multi-modal perception for soft robotic interactions using generative models,

</span>
<span class="ltx_bibblock">in: 2024 IEEE 7th International Conference on Soft Robotics (RoboSoft), IEEE, 2024, pp. 311–318.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Babadian et al. [2023]</span>
<span class="ltx_bibblock">
R. P. Babadian, K. Faez, M. Amiri, E. Falotico,

</span>
<span class="ltx_bibblock">Fusion of tactile and visual information in deep learning models for object recognition,

</span>
<span class="ltx_bibblock">Information Fusion 92 (2023) 313–325.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baltrušaitis et al. [2018]</span>
<span class="ltx_bibblock">
T. Baltrušaitis, C. Ahuja, L.-P. Morency,

</span>
<span class="ltx_bibblock">Multimodal machine learning: A survey and taxonomy,

</span>
<span class="ltx_bibblock">IEEE transactions on pattern analysis and machine intelligence 41 (2018) 423–443.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ngiam et al. [2011]</span>
<span class="ltx_bibblock">
J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, A. Y. Ng,

</span>
<span class="ltx_bibblock">Multimodal deep learning,

</span>
<span class="ltx_bibblock">in: Proceedings of the 28th international conference on machine learning (ICML-11), 2011, pp. 689–696.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silberer and Lapata [2014]</span>
<span class="ltx_bibblock">
C. Silberer, M. Lapata,

</span>
<span class="ltx_bibblock">Learning grounded meaning representations with autoencoders,

</span>
<span class="ltx_bibblock">in: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2014, pp. 721–732.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava and Salakhutdinov [2012a]</span>
<span class="ltx_bibblock">
N. Srivastava, R. Salakhutdinov,

</span>
<span class="ltx_bibblock">Learning representations for multimodal data with deep belief nets,

</span>
<span class="ltx_bibblock">in: International conference on machine learning workshop, volume 79, 2012a, pp. 978–1.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava and Salakhutdinov [2012b]</span>
<span class="ltx_bibblock">
N. Srivastava, R. R. Salakhutdinov,

</span>
<span class="ltx_bibblock">Multimodal learning with deep boltzmann machines,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 25 (2012b).

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. [2013]</span>
<span class="ltx_bibblock">
Y. Kim, H. Lee, E. M. Provost,

</span>
<span class="ltx_bibblock">Deep learning for robust feature generation in audiovisual emotion recognition,

</span>
<span class="ltx_bibblock">in: 2013 IEEE international conference on acoustics, speech and signal processing, IEEE, 2013, pp. 3687–3691.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang and Kingsbury [2013]</span>
<span class="ltx_bibblock">
J. Huang, B. Kingsbury,

</span>
<span class="ltx_bibblock">Audio-visual deep learning for noise robust speech recognition,

</span>
<span class="ltx_bibblock">in: 2013 IEEE international conference on acoustics, speech and signal processing, IEEE, 2013, pp. 7596–7599.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and Shao [2014]</span>
<span class="ltx_bibblock">
D. Wu, L. Shao,

</span>
<span class="ltx_bibblock">Multimodal dynamic networks for gesture recognition,

</span>
<span class="ltx_bibblock">in: Proceedings of the 22nd ACM international conference on Multimedia, 2014, pp. 945–948.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. [2014]</span>
<span class="ltx_bibblock">
W. Ouyang, X. Chu, X. Wang,

</span>
<span class="ltx_bibblock">Multi-source deep learning for human pose estimation,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2014, pp. 2329–2336.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frome et al. [2013]</span>
<span class="ltx_bibblock">
A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, T. Mikolov,

</span>
<span class="ltx_bibblock">Devise: A deep visual-semantic embedding model,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 26 (2013).

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarfraz et al. [2024]</span>
<span class="ltx_bibblock">
F. Sarfraz, B. Zonooz, E. Arani,

</span>
<span class="ltx_bibblock">Beyond unimodal learning: The importance of integrating multiple modalities for lifelong learning,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2405.02766 (2024).

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2023]</span>
<span class="ltx_bibblock">
L. Xu, Q. Wu, L. Pan, F. Meng, H. Li, C. He, H. Wang, S. Cheng, Y. Dai,

</span>
<span class="ltx_bibblock">Towards continual egocentric activity recognition: A multi-modal egocentric activity dataset for continual learning,

</span>
<span class="ltx_bibblock">IEEE Transactions on Multimedia (2023).

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kazakos et al. [2019]</span>
<span class="ltx_bibblock">
E. Kazakos, A. Nagrani, A. Zisserman, D. Damen,

</span>
<span class="ltx_bibblock">Epic-fusion: Audio-visual temporal binding for egocentric action recognition,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE/CVF international conference on computer vision, 2019, pp. 5492–5501.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. [2023]</span>
<span class="ltx_bibblock">
J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al.,

</span>
<span class="ltx_bibblock">Gpt-4 technical report,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2303.08774 (2023).

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van de Ven et al. [2022]</span>
<span class="ltx_bibblock">
G. M. Van de Ven, T. Tuytelaars, A. S. Tolias,

</span>
<span class="ltx_bibblock">Three types of incremental learning,

</span>
<span class="ltx_bibblock">Nature Machine Intelligence 4 (2022) 1185–1197.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al. [2016]</span>
<span class="ltx_bibblock">
Y. Hao, Z. Gong, Z. Xie, S. Guan, X. Yang, Z. Ren, T. Wang, L. Wen,

</span>
<span class="ltx_bibblock">Universal soft pneumatic robotic gripper with variable effective length (2016) 6109–6114.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saggio et al. [2015]</span>
<span class="ltx_bibblock">
G. Saggio, F. Riillo, L. Sbernini, L. R. Quitadamo,

</span>
<span class="ltx_bibblock">Resistive flex sensors: a survey,

</span>
<span class="ltx_bibblock">Smart Materials and Structures 25 (2015) 013001.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et al. [2021]</span>
<span class="ltx_bibblock">
R. B. Mishra, N. El-Atab, A. M. Hussain, M. M. Hussain,

</span>
<span class="ltx_bibblock">Recent progress on flexible capacitive pressure sensors: From design and materials to applications,

</span>
<span class="ltx_bibblock">Advanced materials technologies 6 (2021) 2001023.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hollinger and Wanderley [2006]</span>
<span class="ltx_bibblock">
A. Hollinger, M. M. Wanderley,

</span>
<span class="ltx_bibblock">Evaluation of commercial force-sensing resistors,

</span>
<span class="ltx_bibblock">in: Proceedings of the International Conference on New Interfaces for Musical Expression, Paris, France, Citeseer, 2006, pp. 4–8.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al. [2021]</span>
<span class="ltx_bibblock">
J. Smith, J. Balloch, Y.-C. Hsu, Z. Kira,

</span>
<span class="ltx_bibblock">Memory-efficient semi-supervised continual learning: The world is its own replay buffer,

</span>
<span class="ltx_bibblock">in: 2021 International Joint Conference on Neural Networks (IJCNN), IEEE, 2021, pp. 1–8.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. [2017]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, I. Polosukhin,

</span>
<span class="ltx_bibblock">Attention is all you need,

</span>
<span class="ltx_bibblock">Advances in neural information processing systems 30 (2017).

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2016]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, J. Sun,

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition,

</span>
<span class="ltx_bibblock">in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Russakovsky et al. [2015]</span>
<span class="ltx_bibblock">
O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al.,

</span>
<span class="ltx_bibblock">Imagenet large scale visual recognition challenge,

</span>
<span class="ltx_bibblock">International journal of computer vision 115 (2015) 211–252.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akiba et al. [2019]</span>
<span class="ltx_bibblock">
T. Akiba, S. Sano, T. Yanase, T. Ohta, M. Koyama,

</span>
<span class="ltx_bibblock">Optuna: A next-generation hyperparameter optimization framework,

</span>
<span class="ltx_bibblock">in: Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining, 2019, pp. 2623–2631.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Broadbent et al. [2023]</span>
<span class="ltx_bibblock">
E. Broadbent, M. Billinghurst, S. G. Boardman, P. M. Doraiswamy,

</span>
<span class="ltx_bibblock">Enhancing social connectedness with companion robots using ai,

</span>
<span class="ltx_bibblock">Science robotics 8 (2023) eadi6347.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et al. [2018]</span>
<span class="ltx_bibblock">
S. K. Min, R. Delgado, W. C. Byoung,

</span>
<span class="ltx_bibblock">Comparative study of ros on embedded system for a mobile robot,

</span>
<span class="ltx_bibblock">Journal of Automation, Mobile Robotics and Intelligent Systems (2018) 61–67.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.13790" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.13792" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.13792">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.13792" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.13793" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 01:56:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
