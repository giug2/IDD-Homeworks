<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2109.14593] Federated Learning over Next-Generation Ethernet Passive Optical Networks</title><meta property="og:description" content="Federated Learning (FL) is a distributed machine learning (ML) type of processing that preserves the privacy of user data, sharing only the parameters of ML models with a common server.
The processing of FL requires sp…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning over Next-Generation Ethernet Passive Optical Networks">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning over Next-Generation Ethernet Passive Optical Networks">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2109.14593">

<!--Generated on Wed Mar  6 22:03:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Dynamic Wavelength and Bandwidth Allocation, 
Federated Learning, 
Ethernet Passive Optical Networks, 
Quality of Service, 
Multi-services, 
Future Access Networks.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning over Next-Generation Ethernet Passive Optical Networks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Oscar J. Ciceri, Carlos A. Astudillo, Zuqing Zhu, and Nelson L. S. da Fonseca
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Institute of Computing - University of Campinas 
<br class="ltx_break">Campinas 13089-971, SP, Brazil 
<br class="ltx_break">Email: oscar@lrc.ic.unicamp.br, castudillo@lrc.ic.unicamp.br,
zqzhu@ieee.org,
nfonseca@ic.unicamp.br
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Oscar J. Ciceri, Carlos A. Astudillo, Zuqing Zhu, and Nelson L. S. da Fonseca 
</span><span class="ltx_author_notes">O. J. Ciceri, C. A. Astudillo and N. L. S da Fonseca are with the Institute of Computing, University of Campinas 13083-852, Brazil (emails: oscar@lrc.ic.unicamp.br,castudillo@lrc.ic.unicamp.br, nfonseca@ic.unicamp.br).Z. Zhu is with the School of Information Science and
Technology, University of Science and Technology of China, Hefei, Anhui 230027, P. R. China (email: zqzhu@ieee.org).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated Learning (FL) is a distributed machine learning (ML) type of processing that preserves the privacy of user data, sharing only the parameters of ML models with a common server.
The processing of FL requires specific latency and bandwidth demands that need to be fulfilled by the operation of the communication network.
This paper introduces a Dynamic Wavelength and Bandwidth Allocation algorithm for Quality of Service (QoS) provisioning for FL traffic over 50 Gb/s Ethernet Passive Optical Networks. The proposed algorithm prioritizes FL traffic and reduces the delay of FL and delay-critical applications supported on the same infrastructure.
</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Dynamic Wavelength and Bandwidth Allocation,
Federated Learning,
Ethernet Passive Optical Networks,
Quality of Service,
Multi-services,
Future Access Networks.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span title="Artificial Intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Artificial Intelligence</span></span> (<abbr title="Artificial Intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr>) applications are widely employed in various different sectors of our daily life, such
as in smart cities, smart homes, smart transportation, smart health, and finance.
Moreover, the upcoming  <span title="6th Generation mobile networks" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">6th Generation mobile networks</span></span> (<abbr title="6th Generation mobile networks" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">6G</span></abbr>) will support an even wider range of applications based on <abbr title="Artificial Intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr>, such as holographic communications, super-smart homes, and cooperative autonomous robots. The <abbr title="6th Generation mobile networks" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">6G</span></abbr> system will change the network vision from ”connected things” to ”connected intelligence” <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, in which advanced and ubiquitous <abbr title="Artificial Intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr> will empower numerous applications.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Traditional use of  <span title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Machine Learning</span></span> (<abbr title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ML</span></abbr>) models relies on batch processing in a central server and the employment of datasets containing user data. With the worldwide adoption of data protection and privacy legislation, the creation of datasets and applications based on ML has been considerably limited. One way of coping with such restrictions is the adoption of  <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> (<abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>), which is a distributed way of processing machine learning algorithms that does not disclose private data. In FL, clients train a local ML model using a private dataset, and the parameters of these local models are then sent to a central server. The server produces a global model on the basis of the numerous parameter values received and distributes this global model to the clients for further training. This round of processing is repeated until the global model produces results with an acceptable level of accuracy. In this way, user privacy is preserved. The most common approaches for the consolidation of the parameters sent by the clients to produce the global model (FedAvg) rely on the assumption that clients are synchronized and that local datasets are independent and identically distributed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Such FL can be used for the training of large ML models involving thousands or even millions of parameters.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The processing of <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> models has brought challenges to communication networks.
<abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> clients may produce highly bursty traffic when uploading their model parameters to the server.
For example, clients training a <span title="Convolutional Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long-plural">Convolutional Neural Networks</span></span> model with few convolution layers and thousands of parameters may need to send hundreds of megabytes. When millions of parameters are involved, the amount of bytes sent can be of the order of gigabytes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Moreover, <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> may impose stringent communication delays for the uploading of client parameters to enhance fast convergence to the global model, especially when the federation involves numerous clients. To cope with diverse communication delays, the server may either wait the arrival of the local parameters from all clients, increasing convergence time, or exclude the late arriving data from the parameter consolidation step, which reduces the accuracy of the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
In addition, <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> may also require a very large number of training rounds to produce accurate global models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. These challenges calls for efficient resource allocation mechanisms to meet the FL requirements.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Passive Optical Network</span></span> (<abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr>) is a cost-efficient access network technology for delivering broadband services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Operators have already deployed 10 Gb/s  <span title="Time Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Time Division Multiplexing</span></span> (<abbr title="Time Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TDM</span></abbr>) PONs during the past two decades. In recent years, the ITU and IEEE standardization groups have proposed next-generation <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">PONs</span></abbr> based on  <span title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Time and Wavelength Division Multiplexing</span></span> (<abbr title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDM</span></abbr>) to increase the network capacity for supporting demanding applications and services. TWDM allows allocation in various wavelength channels of 25 Gb/s (50G-EPON) and 10 Gb/s (40G-XPON) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span title="Infrastructure service Provider" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long-plural">Infrastructure service Providers</span></span> owning a <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> can increase network utilization, as well as their profits, by offering a diverse variety of services to a variety of different customers, such as residential users, enterprises, and mobile network operators (MNO). The capacity to support the Quality of Service (QoS) requirements of emerging 5G/6G applications, such as
distributed <span title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Machine Learning</span></span>, Tactile Internet, or  <span title="Mobile Fronthauling" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Mobile Fronthauling</span></span> (<abbr title="Mobile Fronthauling" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MFH</span></abbr>) calls for efficient use of network resources.
Nonetheless, the aforementioned challenges of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications make QoS provisioning challenging.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">A few approaches have been proposed to deal with FL processing
over PONs (<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>).
One of these is the  <span title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Bandwidth Slicing</span></span> (<abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr>) approach for TDM-PONs, that reserves portions of the PON capacity for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The bandwidth for each of the slices granted per cycle is orders of magnitude less than that required for transmitting a model update, which implies that several scheduling cycles will be required to fully upload the parameters of the client models.
An architecture for scalable federated learning involving two-step of aggregation over <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">PONs</span></abbr> was introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
In this proposal, the parameters of local models are first aggregated at clients connected to  <span title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Optical Network Unit</span></span> (<abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr>) and then aggregated on a server connected to the  <span title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Optical Line Terminator</span></span> (<abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr>).
As a consequence, the amount of upstream traffic remains relatively constant regardless of the number of clients in the federation.
However, the high volume of traffic generated by the FL clients can create network bottlenecks, which impacts on the time to upload of the local parameters.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">This paper discusses the main issues for supporting FL applications over PONs and introduces a  <span title="Dynamic Wavelength and Bandwidth Allocation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Dynamic Wavelength and Bandwidth Allocation</span></span> (<abbr title="Dynamic Wavelength and Bandwidth Allocation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DWBA</span></abbr>) algorithm for 50G-EPONs that dynamically prioritizes <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic while maintaining the traditional guaranteed bandwidth scheme for <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> customers.
Two prioritization policies have been proposed to reduce the delay of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic and delay-critical applications. In the first, the intra-ONU scheduler strictly prioritizes the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic over that from other types of applications (<span id="S1.p7.1.1" class="ltx_text ltx_font_italic">FL-first policy</span>).
In the second, the delay-critical traffic is prioritized over the FL traffic (<span id="S1.p7.1.2" class="ltx_text ltx_font_italic">DC-first policy</span>).
The <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> algorithm introduced by Li <span id="S1.p7.1.3" class="ltx_text ltx_font_italic">et. al</span> (2020) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> was adapted to employ multiple wavelengths, as well as an adaptive polling cycle as required in 50G-EPON networks with dynamic resource allocation for comparison purpose.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Results show that the <span id="S1.p8.1.1" class="ltx_text ltx_font_italic">DC-first policy</span> increases the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> model accuracy and reduces the delay of federated learning and delay-critical applications when compared to the <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> approach and the <span id="S1.p8.1.2" class="ltx_text ltx_font_italic">FL-first policy</span>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Resource Allocation in Passive Optical Networks</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.5" class="ltx_p"><abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> is a network access technology that offers larger capacity, greater cost-efficiency, and more energy savings than do other network access technologies.
There are two main <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> standards:  <span title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Ethernet PON</span></span> (<abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">EPON</span></abbr>) and  <span title="Gigabit Capable " class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Gigabit Capable <abbr title="" class="ltx_glossaryref"></abbr></span></span> (<abbr title="Gigabit Capable " class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GPON</span></abbr>), with <abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">EPON</span></abbr> being less expensive.
<abbr title="Gigabit Capable " class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GPON</span></abbr> transmission system ofemploys synchronous frames issued at every 125 <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S2.p1.1.m1.1a"><mi class="ltx_unit" id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\mu</annotation></semantics></math>s, while those of <abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">EPON</span></abbr> use Ethernet frames asynchronously for transmissions based on granted cycles of variable duration.
While traditional <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> standards allow bit rates of 1 <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="\nicefrac{{Gb}}{{s}}" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mpadded class="ltx_unit" voffset="0.3em" id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml"><mi class="ltx_unit" mathsize="70%" id="S2.p1.2.m2.1.1.2a" xref="S2.p1.2.m2.1.1.2.cmml">Gb</mi></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="S2.p1.2.m2.1.1.1a" xref="S2.p1.2.m2.1.1.1.cmml">/</mo></mpadded><mi class="ltx_unit" mathsize="70%" mathvariant="normal" id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><divide id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"></divide><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">Gb</ci><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">s</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\nicefrac{{Gb}}{{s}}</annotation></semantics></math> and 10 <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="\nicefrac{{Gb}}{{s}}" display="inline"><semantics id="S2.p1.3.m3.1a"><mrow id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mpadded class="ltx_unit" voffset="0.3em" id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml"><mi class="ltx_unit" mathsize="70%" id="S2.p1.3.m3.1.1.2a" xref="S2.p1.3.m3.1.1.2.cmml">Gb</mi></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S2.p1.3.m3.1.1.1" xref="S2.p1.3.m3.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="S2.p1.3.m3.1.1.1a" xref="S2.p1.3.m3.1.1.1.cmml">/</mo></mpadded><mi class="ltx_unit" mathsize="70%" mathvariant="normal" id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><divide id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1.1"></divide><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">Gb</ci><ci id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3">s</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">\nicefrac{{Gb}}{{s}}</annotation></semantics></math>,
the next-generation <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> standards allow those of 40 <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="\nicefrac{{Gb}}{{s}}" display="inline"><semantics id="S2.p1.4.m4.1a"><mrow id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mpadded class="ltx_unit" voffset="0.3em" id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml"><mi class="ltx_unit" mathsize="70%" id="S2.p1.4.m4.1.1.2a" xref="S2.p1.4.m4.1.1.2.cmml">Gb</mi></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S2.p1.4.m4.1.1.1" xref="S2.p1.4.m4.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="S2.p1.4.m4.1.1.1a" xref="S2.p1.4.m4.1.1.1.cmml">/</mo></mpadded><mi class="ltx_unit" mathsize="70%" mathvariant="normal" id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><divide id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1"></divide><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">Gb</ci><ci id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">s</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">\nicefrac{{Gb}}{{s}}</annotation></semantics></math> to 100 <math id="S2.p1.5.m5.1" class="ltx_Math" alttext="\nicefrac{{Gb}}{{s}}" display="inline"><semantics id="S2.p1.5.m5.1a"><mrow id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><mpadded class="ltx_unit" voffset="0.3em" id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml"><mi class="ltx_unit" mathsize="70%" id="S2.p1.5.m5.1.1.2a" xref="S2.p1.5.m5.1.1.2.cmml">Gb</mi></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S2.p1.5.m5.1.1.1" xref="S2.p1.5.m5.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="S2.p1.5.m5.1.1.1a" xref="S2.p1.5.m5.1.1.1.cmml">/</mo></mpadded><mi class="ltx_unit" mathsize="70%" mathvariant="normal" id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><divide id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1"></divide><ci id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2">Gb</ci><ci id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3">s</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">\nicefrac{{Gb}}{{s}}</annotation></semantics></math>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The 50 Gb/s optical access network standardized in <abbr title="Institute of Electrical and Electronics Engineers" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IEEE</span></abbr> 50G-EPON 802.3ca-2020 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> is a promising technology for adoption by <abbr title="Infrastructure service Provider" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">InP</span></abbr> to support emerging services with strigent latency and bandwidth requirements.
This 50G-EPON technology employs the  <span title="Time and Wavelength Division Multiple Access" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Time and Wavelength Division Multiple Access</span></span> (<abbr title="Time and Wavelength Division Multiple Access" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDMA</span></abbr>) technique for controlling uplink transmissions between the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> and the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr>.
There are three main <abbr title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDM</span></abbr>-<abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr>-based access architectures for the connectivity between the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> and <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr>:  <span title="Multiple-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Multiple-Scheduling Domain</span></span> (<abbr title="Multiple-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSD</span></abbr>),  <span title="Single-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Single-Scheduling Domain</span></span> (<abbr title="Single-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SSD</span></abbr>), and  <span title="Wavelength Agile" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Wavelength Agile</span></span> (<abbr title="Wavelength Agile" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">WA</span></abbr>). In the first, ONUs transmit on a single wavelength at a time. In the second, ONUs can transmit simultaneously on all wavelengths, and in the third, more than one wavelength can be granted to a single <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">In this technology, the signaling protocol  <span title="Multipoint Control Protocol" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Multipoint Control Protocol</span></span> (<abbr title="Multipoint Control Protocol" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPCP</span></abbr>) is employed for resource allocation.
This protocol uses Report and Gate messages for this allocation.
Report messages are sent on the upstream to the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> by the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> to request bandwidth, while
Gate messages are sent on the downstream by the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> to the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> to inform the grated wavelength(s) and transmission windows, as well as the starting time of the next transmission window.
Resource allocation is carried out in two steps, one for wavelength allocation and the other for bandwidth allocation. The use of different schemes for transmission on multiple wavelengths can be defined on the basis of
conventional  <span title="Dynamic Bandwidth Allocation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Dynamic Bandwidth Allocation</span></span> (<abbr title="Dynamic Bandwidth Allocation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DBA</span></abbr>) algorithms for TDM-PONs.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">For dynamic bandwidth allocation over EPONs, the  <span title="Interleaved Polling with Adaptive Cycle Time" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Interleaved Polling with Adaptive Cycle Time</span></span> (<abbr title="Interleaved Polling with Adaptive Cycle Time" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IPACT</span></abbr>) algorithm has been adopted to complement the <abbr title="Multipoint Control Protocol" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPCP</span></abbr> protocol.
The <abbr title="Interleaved Polling with Adaptive Cycle Time" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IPACT</span></abbr> algorithm employs an interleaved polling and statistical multiplexing technique that leads to efficient upstream channel usage.
The limited policy has been used to assure bandwidth to <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> according to pre-defined Service Level Agreements.
Moreover, the original <abbr title="Interleaved Polling with Adaptive Cycle Time" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IPACT</span></abbr> algorithm employs a single wavelength channel for scheduling. It has been modified to operate with multiple wavelengths in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
The modified <abbr title="Interleaved Polling with Adaptive Cycle Time" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IPACT</span></abbr> algorithm was proposed for the <abbr title="Single-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SSD</span></abbr> and <abbr title="Multiple-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSD</span></abbr> architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
Additional algorithms have been proposed: the  <span title="Water-Fill" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Water-Fill</span></span> (<abbr title="Water-Fill" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">WF</span></abbr>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to promote fairness in the wavelength utilization and  <span title="First-Fit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">First-Fit</span></span> (<abbr title="First-Fit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FF</span></abbr>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> to provide less delay.
Moreover, when there is no scheduler for  <span title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Quality of Service</span></span> (<abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr>) provisioning in the <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr>, the First-Come-First-Served (FCFS) queuing policy is employed. However, this strategy does not consider the priority or required bandwidth/delay of the applications.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2109.14593/assets/img/arqx.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="261" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of federated learning over passive optical networks.</figcaption>
</figure>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">The performance of diverse applications in a <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> is ensured by the adopted <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> mechanism, it controls the way frames are queued, prioritized, and scheduled.
Such assurance of <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> can be provided by either the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr> or <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr>.
In the single-level architecture, the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> reports individual queue sizes, while the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> distributes the bandwidth for each type of traffic.
In the hierarchical architecture, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> allocates bandwidth for each <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr>, and the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> manage the amount of bandwidth to be allocated for each traffic.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">The most straightforward method of facilitating <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> provisioning is the Differentiated Service approach. It classifies network traffic and delivers different services to different applications.
The simplest way to implement Differentiated Services is to employ strict priority scheduling. The ONUs categorize the incoming traffic and put it in the buffer, imposing the prioritization of different traffic classes.
With the employment of Differentiated Services, however, the <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> can support packetized voice and video with strict bandwidth and latency constraints, as well as best-effort traffic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
However, none of the exiting mechanisms have been specially designed to support the <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> requirements of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Resource Allocation for Federated Learning </span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Fig. <a href="#S2.F1" title="Figure 1 ‣ II Resource Allocation in Passive Optical Networks ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the scenario of FL processing over a PON; where clients are connected to the ONUs and the server is attached to the OLT.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The FL training process can be either asynchronous or synchronous.
In the former, the global model parameters are computed as soon as the server receives updates of the parameters of the local models from a certain number of clients. In the latter, the server aggregates the local parameters that arrive in a period of constant duration
excluding the parameters from the late arriving stragglers. This exclusion, however, reduces the accuracy of the model as well as increases the time required for convergence to a final global model.
</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">The synchronization time per round includes the downstream, computing, network, propagation, and aggregation delays, as shown in Fig. <a href="#S3.F2.sf1" title="In Figure 2 ‣ III Resource Allocation for Federated Learning ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2a</span></a>.
The downstream delay includes the propagation and transmission delays of the parameters of the global model from the server to the clients.
The computing time is the time taken to train the local model at the client in each round.
The network delay is the time spent in communication the local model parameters from the clients to the server.
The propagation delay is the time taken by the bits transmitted to travel from the client to the server on the network medium.
The aggregation delay is the processing time of the aggregation algorithm.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">The network delay depends on the network load and the resource allocation mechanism employed for the <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> for allocating bandwidth and wavelength(s) to the ONUs. The computing time depends on the capacity of the client and the size of the training dataset, while the propagation delay depends on the distances between the server and the clients.
Moreover, long network delays may increase the number of straggler clients, decreasing the model accuracy and increasing the convergence time.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">The time taken to transmit the local model parameters to the server depends on the bandwidth allocated to the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic.
In general, <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> customers receive a portion of the total available bandwidth in the <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> due to the shared nature of the upstream channel.
Residential and business customers usually have guaranteed bandwidth from tens to hundreds of Mbps, and other PON customers can require on demand up to tens of Gbps.
However, the large size of the local model parameters, which can be in the order of gigabytes, may demand several seconds to be fully transmitted, even with guaranteed bandwidths on the order of Gbps, as shown in Figure <a href="#S3.F2.sf2" title="In Figure 2 ‣ III Resource Allocation for Federated Learning ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2b</span></a>.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">The unique characteristics of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications introduce challenges for the management of the available bandwidth in scenarios with limited bandwidth and diversity of customers, services and applications.
The recently proposed <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> algorithm to the support of <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications assures a slice of bandwidth for the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic. This is then allocated according to the ascending order of downstream client delay and computing time.
However, the approach is not efficient for <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> scenarios when loads are high and traffic is bursty.
The large bandwidth slice required to serve <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic properly
reduces the available bandwidth for other <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> customers. It also reduces the statistical multiplexing gain due to the static allocation of the network resources.
On the other hand, if the slice is much smaller than the total available bandwidth, the granted bandwidth is likely to be insufficient to serve timely the FL processing due to the large size of the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> packets.
As a consequence, clients send a small portion of the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> frames per cycle, requiring numerous scheduling cycles to be fully served.
If two or more clients have <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> frames in the queue at a given time, then only one client can use the slice, while the others will have to wait for that slice to become available, as shown in Figure <a href="#S3.F2.sf3" title="In Figure 2 ‣ III Resource Allocation for Federated Learning ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2c</span></a>.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p">Furthermore, the <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> approach is not compatible with traditional <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> business models, in which customers rent portions of the <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> capacity from the <abbr title="Infrastructure service Provider" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">InP</span></abbr> to support their applications and services.
Moreover, it is unclear who pays for a shared bandwidth slice.</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p">In summary, even though the <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> approach reduces the latency for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications in relation to the traditional First Come First Served approach, the static bandwidth allocation and the incompatibility of the approach with traditional business models may lead to issue of <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> support and deployment.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2109.14593/assets/img/delays.png" id="S3.F2.sf1.g1" class="ltx_graphics ltx_img_square" width="239" height="230" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span><span id="S3.F2.sf1.2.1" class="ltx_ERROR undefined">\titlecap</span>Delays of Federated Learning</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2109.14593/assets/img/delay.png" id="S3.F2.sf2.g1" class="ltx_graphics ltx_img_square" width="250" height="230" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span><span id="S3.F2.sf2.2.1" class="ltx_ERROR undefined">\titlecap</span>Large FL Packet Size</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2109.14593/assets/img/bs.png" id="S3.F2.sf3.g1" class="ltx_graphics ltx_img_landscape" width="327" height="230" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span><span id="S3.F2.sf3.2.1" class="ltx_ERROR undefined">\titlecap</span>Bandwidth Slice for FL</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Resource allocation issues for <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> over PONs</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><abbr title="Dynamic Wavelength and Bandwidth Allocation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DWBA</span></abbr><span id="S4.1.1" class="ltx_text ltx_font_smallcaps"> Schemes for Supporting <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic over 50G-<abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">EPON</span></abbr> networks</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section introduces the proposed scheme for providing <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications
over 50G-EPON networks.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Adaptation of the Bandwidth Slicing Approach to <span id="S4.SS1.6.2.1" class="ltx_text">TWDM-EPON</span></span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> serves FL traffic by dynamically allocating bandwidth on a single wavelength for FL clients. It calculates the number of cycles an FL client requires to be completely served based on the required bandwidth and the fixed polling cycle length of 125 <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mu s" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_unit" id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">μ</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">​</mo><mi class="ltx_unit" id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝜇</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\mu s</annotation></semantics></math> employed in the GPON technology. However, next-generation PONs employ multiple wavelengths and the cycle duration is unknown a priori when an adaptive polling cycle mechanism is employed, such as in the EPON technology.
Therefore, the proposed <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> algorithm cannot be directly employed in TWDM-EPON networks.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">We proposed an adaptation of the <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> approach for TWDM-EPONs called multi-wavelength BS algorithm (<span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">MW-BS</span>). It deals with multiple wavelengths and employs an adaptive polling cycle for dynamic resource allocation.
A portion of the PON capacity (bandwidth slice) is still reserved for the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic in each scheduling cycle, but
instead of using the polling cycle information to grant the transmission windows for FL traffic and then share the remaining slice capacity with other traffic types, <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">MW-BS</span> reserves the total slice to the FL traffic as long as a bandwidth request from any FL client exists. The use of a dynamic polling cycle reduces the FL traffic delays and avoids the need for information about the duration of the unknown upcoming cycles.
Three variations of the MW-BS algorithm were proposed for different <abbr title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDM</span></abbr> wavelength allocation policies,
namely <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_italic">MW-BS</span>-<span id="S4.SS1.p2.1.4" class="ltx_text ltx_font_italic">SSD</span>,
<span id="S4.SS1.p2.1.5" class="ltx_text ltx_font_italic">MW-BS</span>-<span id="S4.SS1.p2.1.6" class="ltx_text ltx_font_italic">MSD</span>, and
<span id="S4.SS1.p2.1.7" class="ltx_text ltx_font_italic">MW-BS</span>-<span id="S4.SS1.p2.1.8" class="ltx_text ltx_font_italic">FF</span>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2109.14593/assets/img/alg.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="419" height="399" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Flow chart of the bandwidth slicing algorithm adapted for TWDM-EPONs.</figcaption>
</figure>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">The flow diagram in Figure <a href="#S4.F3" title="Figure 3 ‣ IV-A Adaptation of the Bandwidth Slicing Approach to TWDM-EPON ‣ IV Schemes for Supporting traffic over 50G- networks ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes the proposed DWBA scheme residing on the OLT.
The <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> sends the Report message requesting bandwidth for <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> as well as conventional applications.
When a Report message arrives from a <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr>
containing a bandwidth request for FL traffic, the OLT first grants the bandwidth from the reserved slice, if available (Block 1);
otherwise, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> allocates bandwidth for the conventional traffic (Block 2).</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">For allocation of bandwidth for the slice,
The <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> also reserves bandwidth for the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr> for upcoming cycles.
It selects the wavelength(s) as a function of the
<abbr title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDM</span></abbr> wavelength allocation policy,
and calculates the next starting time for the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> transmission.
For the SSD policy, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> grants all wavelengths.
For the MSD policy, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> grants a predetermined-fixed wavelength.
For the FF policy, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> grants the first available wavelength,
and then calculates the granted transmission window for each allocated wavelength, depending on the number of wavelengths and the portion of the <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> capacity designed for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> use.
If the granted window is equal to the requested windows, the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic will be fully served, and the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> will make the bandwidth slice available for the next cycle.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">The <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> also calculates the granted bandwidth for the convectional applications.
If the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> has previously allocated the bandwidth for the slice, it selects these wavelength(s) for the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic.
Otherwise, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> selects the wavelength(s) for the FL traffic and calculates the next starting time for that <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> transmission as a function of the <abbr title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDM</span></abbr> wavelength allocation policies involved. The transmission window for the conventional applications is calculated according to the limited policy.
Finally, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> issues and send a Gate message with the granted bandwidths for both <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> and conventional applications.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">DWBA for Federated Learning</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To address the issues of resource allocation raised here, we introduce a DWBA algorithm that supports <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> provisioning for <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> applications while meeting the requirements of delay-critical applications in TWDM-<abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">EPON</span></abbr> networks. The algorithm is called DWBA for Federated Learning (DWBA-FL).</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The idea behind our proposal is to allow <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> customers to employ their guaranteed bandwidth for the scheduling of the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> application, without jeopardizing the QoS provisioning of other delay-critical applications. To achieve this, the proposed mechanism adopts the widely-used Differentiated Service approach to tackle the <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> provisioning problem of <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> applications over Ethernet <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr>. The prioritization of FL traffic is used to comply with the traditional business model, as well as to improve statistical multiplexing gain.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">The proposal employs an intra-<abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr> scheduler with a strict priority queuing policy to serve the ONU queues.
The <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> arbitrates the transmission demands of the different applications.
Upon the arrival of a Report message, the <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> calculates the transmission window according to the conventional limited policy and selects the wavelength(s) on the basis of the
<abbr title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDM</span></abbr> wavelength allocation policies.
The <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> then sends a Gate message containing the resource allocation decision.
Upon the receipt of that Gate message, the intra-ONU scheduler distributes the received bandwidth among the queues in the ONU.
In our model, traffic is classified as <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span>, delay-critical, delay-sensitive, or best-effort.
The <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> mantains four different queues for buffering frames for these types of traffic.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.5" class="ltx_p">We propose two prioritization policies.
The <span id="S4.SS2.p4.5.1" class="ltx_text ltx_font_italic">FL-first policy</span> defines the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic as that of the <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="highest" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mrow id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.1" xref="S4.SS2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.1a" xref="S4.SS2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.1.m1.1.1.4" xref="S4.SS2.p4.1.m1.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.1b" xref="S4.SS2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.1.m1.1.1.5" xref="S4.SS2.p4.1.m1.1.1.5.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.1c" xref="S4.SS2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.1.m1.1.1.6" xref="S4.SS2.p4.1.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.1d" xref="S4.SS2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.1.m1.1.1.7" xref="S4.SS2.p4.1.m1.1.1.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.1e" xref="S4.SS2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.1.m1.1.1.8" xref="S4.SS2.p4.1.m1.1.1.8.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><times id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1.1"></times><ci id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2">ℎ</ci><ci id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3">𝑖</ci><ci id="S4.SS2.p4.1.m1.1.1.4.cmml" xref="S4.SS2.p4.1.m1.1.1.4">𝑔</ci><ci id="S4.SS2.p4.1.m1.1.1.5.cmml" xref="S4.SS2.p4.1.m1.1.1.5">ℎ</ci><ci id="S4.SS2.p4.1.m1.1.1.6.cmml" xref="S4.SS2.p4.1.m1.1.1.6">𝑒</ci><ci id="S4.SS2.p4.1.m1.1.1.7.cmml" xref="S4.SS2.p4.1.m1.1.1.7">𝑠</ci><ci id="S4.SS2.p4.1.m1.1.1.8.cmml" xref="S4.SS2.p4.1.m1.1.1.8">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">highest</annotation></semantics></math> priority and the delay-critical, delay-sensitive, and best-effort being of <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="high" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mrow id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.1.1.1" xref="S4.SS2.p4.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.1.1.1a" xref="S4.SS2.p4.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.2.m2.1.1.4" xref="S4.SS2.p4.2.m2.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.1.1.1b" xref="S4.SS2.p4.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.2.m2.1.1.5" xref="S4.SS2.p4.2.m2.1.1.5.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><times id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1.1"></times><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">ℎ</ci><ci id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3">𝑖</ci><ci id="S4.SS2.p4.2.m2.1.1.4.cmml" xref="S4.SS2.p4.2.m2.1.1.4">𝑔</ci><ci id="S4.SS2.p4.2.m2.1.1.5.cmml" xref="S4.SS2.p4.2.m2.1.1.5">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">high</annotation></semantics></math>, <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="medium" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mrow id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml"><mi id="S4.SS2.p4.3.m3.1.1.2" xref="S4.SS2.p4.3.m3.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1" xref="S4.SS2.p4.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.3.m3.1.1.3" xref="S4.SS2.p4.3.m3.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1a" xref="S4.SS2.p4.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.3.m3.1.1.4" xref="S4.SS2.p4.3.m3.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1b" xref="S4.SS2.p4.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.3.m3.1.1.5" xref="S4.SS2.p4.3.m3.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1c" xref="S4.SS2.p4.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.3.m3.1.1.6" xref="S4.SS2.p4.3.m3.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1d" xref="S4.SS2.p4.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.3.m3.1.1.7" xref="S4.SS2.p4.3.m3.1.1.7.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><apply id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1"><times id="S4.SS2.p4.3.m3.1.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1.1"></times><ci id="S4.SS2.p4.3.m3.1.1.2.cmml" xref="S4.SS2.p4.3.m3.1.1.2">𝑚</ci><ci id="S4.SS2.p4.3.m3.1.1.3.cmml" xref="S4.SS2.p4.3.m3.1.1.3">𝑒</ci><ci id="S4.SS2.p4.3.m3.1.1.4.cmml" xref="S4.SS2.p4.3.m3.1.1.4">𝑑</ci><ci id="S4.SS2.p4.3.m3.1.1.5.cmml" xref="S4.SS2.p4.3.m3.1.1.5">𝑖</ci><ci id="S4.SS2.p4.3.m3.1.1.6.cmml" xref="S4.SS2.p4.3.m3.1.1.6">𝑢</ci><ci id="S4.SS2.p4.3.m3.1.1.7.cmml" xref="S4.SS2.p4.3.m3.1.1.7">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">medium</annotation></semantics></math> and <math id="S4.SS2.p4.4.m4.1" class="ltx_Math" alttext="low" display="inline"><semantics id="S4.SS2.p4.4.m4.1a"><mrow id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml"><mi id="S4.SS2.p4.4.m4.1.1.2" xref="S4.SS2.p4.4.m4.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.1.1.1" xref="S4.SS2.p4.4.m4.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.4.m4.1.1.3" xref="S4.SS2.p4.4.m4.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.1.1.1a" xref="S4.SS2.p4.4.m4.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.4.m4.1.1.4" xref="S4.SS2.p4.4.m4.1.1.4.cmml">w</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.1b"><apply id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1"><times id="S4.SS2.p4.4.m4.1.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1.1"></times><ci id="S4.SS2.p4.4.m4.1.1.2.cmml" xref="S4.SS2.p4.4.m4.1.1.2">𝑙</ci><ci id="S4.SS2.p4.4.m4.1.1.3.cmml" xref="S4.SS2.p4.4.m4.1.1.3">𝑜</ci><ci id="S4.SS2.p4.4.m4.1.1.4.cmml" xref="S4.SS2.p4.4.m4.1.1.4">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.1c">low</annotation></semantics></math> priority, respectively.
On the one hand, this strict prioritization of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> frames can reduce synchronization time for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> processing.
It can also increase the delay of delay-critical application because the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic requires a large bandwidth per cycle.
To help alleviate this problem, we propose the <span id="S4.SS2.p4.5.2" class="ltx_text ltx_font_italic">DC-first policy</span>, in which delay-critical traffic also has the highest priority and <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> traffic the <math id="S4.SS2.p4.5.m5.1" class="ltx_Math" alttext="high" display="inline"><semantics id="S4.SS2.p4.5.m5.1a"><mrow id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml"><mi id="S4.SS2.p4.5.m5.1.1.2" xref="S4.SS2.p4.5.m5.1.1.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.5.m5.1.1.1" xref="S4.SS2.p4.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.5.m5.1.1.3" xref="S4.SS2.p4.5.m5.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.5.m5.1.1.1a" xref="S4.SS2.p4.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.5.m5.1.1.4" xref="S4.SS2.p4.5.m5.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.5.m5.1.1.1b" xref="S4.SS2.p4.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS2.p4.5.m5.1.1.5" xref="S4.SS2.p4.5.m5.1.1.5.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><apply id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1"><times id="S4.SS2.p4.5.m5.1.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1.1"></times><ci id="S4.SS2.p4.5.m5.1.1.2.cmml" xref="S4.SS2.p4.5.m5.1.1.2">ℎ</ci><ci id="S4.SS2.p4.5.m5.1.1.3.cmml" xref="S4.SS2.p4.5.m5.1.1.3">𝑖</ci><ci id="S4.SS2.p4.5.m5.1.1.4.cmml" xref="S4.SS2.p4.5.m5.1.1.4">𝑔</ci><ci id="S4.SS2.p4.5.m5.1.1.5.cmml" xref="S4.SS2.p4.5.m5.1.1.5">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">high</annotation></semantics></math> priority.
Moreover, the proposal was defined for all <abbr title="Time and Wavelength Division Multiplexing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TWDM</span></abbr> architectures.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Performance Evaluation</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The performance of the proposed <abbr title="Dynamic Wavelength and Bandwidth Allocation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DWBA</span></abbr> scheme was evaluated using an <abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">EPON</span></abbr> simulator (EPON-Sim), previously validated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
This extension was extended to support the three architectures, <abbr title="Single-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SSD</span></abbr>, <abbr title="Multiple-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSD</span></abbr> and <abbr title="Wavelength Agile" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">WA</span></abbr>, proposed for 50G-EPON networks.
Moreover, our proposal and the <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> approach were introduced in the simulator.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Simulation Model and Setup</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.7" class="ltx_p">The simulation scenarios include a 50G-<abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">EPON</span></abbr> network with <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">1</annotation></semantics></math> <abbr title="Optical Line Terminator" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">OLT</span></abbr> serving 32 <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> on an optical distribution network with a tree topology.
Two wavelength channels of 25 Gbit/s were employed for upstream transmission, giving a total capacity of 50 Gbit/s.
The total available bandwidth in the <abbr title="Passive Optical Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PON</span></abbr> was equally distributed among the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr>,
so that each <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr> has the same guaranteed bandwidth <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="b_{i}" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><msub id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mi id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">b</mi><mi id="S5.SS1.p1.2.m2.1.1.3" xref="S5.SS1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p1.2.m2.1.1.2.cmml" xref="S5.SS1.p1.2.m2.1.1.2">𝑏</ci><ci id="S5.SS1.p1.2.m2.1.1.3.cmml" xref="S5.SS1.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">b_{i}</annotation></semantics></math>, while the aggregated offered load per <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr> <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="l_{i}" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><msub id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml"><mi id="S5.SS1.p1.3.m3.1.1.2" xref="S5.SS1.p1.3.m3.1.1.2.cmml">l</mi><mi id="S5.SS1.p1.3.m3.1.1.3" xref="S5.SS1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><apply id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p1.3.m3.1.1.2.cmml" xref="S5.SS1.p1.3.m3.1.1.2">𝑙</ci><ci id="S5.SS1.p1.3.m3.1.1.3.cmml" xref="S5.SS1.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">l_{i}</annotation></semantics></math> varied from <math id="S5.SS1.p1.4.m4.1" class="ltx_Math" alttext="0.6\cdot b_{i}" display="inline"><semantics id="S5.SS1.p1.4.m4.1a"><mrow id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml"><mn id="S5.SS1.p1.4.m4.1.1.2" xref="S5.SS1.p1.4.m4.1.1.2.cmml">0.6</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p1.4.m4.1.1.1" xref="S5.SS1.p1.4.m4.1.1.1.cmml">⋅</mo><msub id="S5.SS1.p1.4.m4.1.1.3" xref="S5.SS1.p1.4.m4.1.1.3.cmml"><mi id="S5.SS1.p1.4.m4.1.1.3.2" xref="S5.SS1.p1.4.m4.1.1.3.2.cmml">b</mi><mi id="S5.SS1.p1.4.m4.1.1.3.3" xref="S5.SS1.p1.4.m4.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><apply id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1"><ci id="S5.SS1.p1.4.m4.1.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1.1">⋅</ci><cn type="float" id="S5.SS1.p1.4.m4.1.1.2.cmml" xref="S5.SS1.p1.4.m4.1.1.2">0.6</cn><apply id="S5.SS1.p1.4.m4.1.1.3.cmml" xref="S5.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m4.1.1.3.1.cmml" xref="S5.SS1.p1.4.m4.1.1.3">subscript</csymbol><ci id="S5.SS1.p1.4.m4.1.1.3.2.cmml" xref="S5.SS1.p1.4.m4.1.1.3.2">𝑏</ci><ci id="S5.SS1.p1.4.m4.1.1.3.3.cmml" xref="S5.SS1.p1.4.m4.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">0.6\cdot b_{i}</annotation></semantics></math> to <math id="S5.SS1.p1.5.m5.1" class="ltx_Math" alttext="1.0\cdot b_{i}" display="inline"><semantics id="S5.SS1.p1.5.m5.1a"><mrow id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml"><mn id="S5.SS1.p1.5.m5.1.1.2" xref="S5.SS1.p1.5.m5.1.1.2.cmml">1.0</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p1.5.m5.1.1.1" xref="S5.SS1.p1.5.m5.1.1.1.cmml">⋅</mo><msub id="S5.SS1.p1.5.m5.1.1.3" xref="S5.SS1.p1.5.m5.1.1.3.cmml"><mi id="S5.SS1.p1.5.m5.1.1.3.2" xref="S5.SS1.p1.5.m5.1.1.3.2.cmml">b</mi><mi id="S5.SS1.p1.5.m5.1.1.3.3" xref="S5.SS1.p1.5.m5.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><apply id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1"><ci id="S5.SS1.p1.5.m5.1.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1.1">⋅</ci><cn type="float" id="S5.SS1.p1.5.m5.1.1.2.cmml" xref="S5.SS1.p1.5.m5.1.1.2">1.0</cn><apply id="S5.SS1.p1.5.m5.1.1.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p1.5.m5.1.1.3.1.cmml" xref="S5.SS1.p1.5.m5.1.1.3">subscript</csymbol><ci id="S5.SS1.p1.5.m5.1.1.3.2.cmml" xref="S5.SS1.p1.5.m5.1.1.3.2">𝑏</ci><ci id="S5.SS1.p1.5.m5.1.1.3.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">1.0\cdot b_{i}</annotation></semantics></math> (for the sake of clearness and brevity, herein after, <math id="S5.SS1.p1.6.m6.1" class="ltx_Math" alttext="b_{i}" display="inline"><semantics id="S5.SS1.p1.6.m6.1a"><msub id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml"><mi id="S5.SS1.p1.6.m6.1.1.2" xref="S5.SS1.p1.6.m6.1.1.2.cmml">b</mi><mi id="S5.SS1.p1.6.m6.1.1.3" xref="S5.SS1.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.1b"><apply id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.6.m6.1.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS1.p1.6.m6.1.1.2.cmml" xref="S5.SS1.p1.6.m6.1.1.2">𝑏</ci><ci id="S5.SS1.p1.6.m6.1.1.3.cmml" xref="S5.SS1.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.1c">b_{i}</annotation></semantics></math> is omitted from the offered load values of ONU <math id="S5.SS1.p1.7.m7.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS1.p1.7.m7.1a"><mi id="S5.SS1.p1.7.m7.1.1" xref="S5.SS1.p1.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.7.m7.1b"><ci id="S5.SS1.p1.7.m7.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.7.m7.1c">i</annotation></semantics></math>).</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The aggregated load included the traffic of the four different types of application: <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span>, delay-critical, delay-sensitive, and <span title="Best Effort" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Best Effort</span></span>.
The benchmarking framework for learning in federated settings LEAF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> was used to generate the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic.
The FEMNIST dataset and <abbr title="Convolutional Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CNN</span></abbr> with two 5×5 convolution layers were used for model training, while the FedAvg algorithm was employed to aggregate the local parameters in the server.
Other configurations for the learning process, such as learning rate and batch size, followed the settings defined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
<abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> clients generated 26.4 MBytes of data in each round of training.
Moreover, the <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">ONUs</span></abbr> put the local parameters into frames according to the Ethernet protocol, which has a Maximum Transmission Unit of 1500 bytes and a header field for signaling (preamble) of 20 bytes.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.4" class="ltx_p">The delay-critical applications were modeled employing a  <span title="Constant Bit Rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Constant Bit Rate</span></span> (<abbr title="Constant Bit Rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CBR</span></abbr>) flow. It was coded with a fixed-size packet of 70 bytes and an inter-arrival time of 12.5 <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mi id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><ci id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">\mu</annotation></semantics></math>s, which produces an offered load of 44.8 Mbps.
The rest of the offered load <math id="S5.SS1.p3.2.m2.1" class="ltx_Math" alttext="l_{i}" display="inline"><semantics id="S5.SS1.p3.2.m2.1a"><msub id="S5.SS1.p3.2.m2.1.1" xref="S5.SS1.p3.2.m2.1.1.cmml"><mi id="S5.SS1.p3.2.m2.1.1.2" xref="S5.SS1.p3.2.m2.1.1.2.cmml">l</mi><mi id="S5.SS1.p3.2.m2.1.1.3" xref="S5.SS1.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.2.m2.1b"><apply id="S5.SS1.p3.2.m2.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p3.2.m2.1.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p3.2.m2.1.1.2.cmml" xref="S5.SS1.p3.2.m2.1.1.2">𝑙</ci><ci id="S5.SS1.p3.2.m2.1.1.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.2.m2.1c">l_{i}</annotation></semantics></math> was evenly distributed between delay-sensitive and <span title="Best Effort" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Best Effort</span></span> traffic.
The traffic streams were generated employing Pareto ON-OFF sources.
The ON period time and packet-burst size followed a Pareto and Bounded Pareto distributions, respectively. The aggregated traffic at the ONU had a Hurst parameter of 0.8.
Moreover, the packet lengths are uniformly distributed between <math id="S5.SS1.p3.3.m3.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S5.SS1.p3.3.m3.1a"><mn id="S5.SS1.p3.3.m3.1.1" xref="S5.SS1.p3.3.m3.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.3.m3.1b"><cn type="integer" id="S5.SS1.p3.3.m3.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.3.m3.1c">64</annotation></semantics></math> and <math id="S5.SS1.p3.4.m4.1" class="ltx_Math" alttext="1518" display="inline"><semantics id="S5.SS1.p3.4.m4.1a"><mn id="S5.SS1.p3.4.m4.1.1" xref="S5.SS1.p3.4.m4.1.1.cmml">1518</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.4.m4.1b"><cn type="integer" id="S5.SS1.p3.4.m4.1.1.cmml" xref="S5.SS1.p3.4.m4.1.1">1518</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.4.m4.1c">1518</annotation></semantics></math> bytes.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.3" class="ltx_p">A threshold value of <math id="S5.SS1.p4.1.m1.1" class="ltx_Math" alttext="\theta=0.015" display="inline"><semantics id="S5.SS1.p4.1.m1.1a"><mrow id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml"><mi class="ltx_unit" id="S5.SS1.p4.1.m1.1.1.2" xref="S5.SS1.p4.1.m1.1.1.2.cmml">θ</mi><mo id="S5.SS1.p4.1.m1.1.1.1" xref="S5.SS1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.p4.1.m1.1.1.3" xref="S5.SS1.p4.1.m1.1.1.3.cmml">0.015</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><apply id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1"><eq id="S5.SS1.p4.1.m1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1.1"></eq><ci id="S5.SS1.p4.1.m1.1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.1.2">𝜃</ci><cn type="float" id="S5.SS1.p4.1.m1.1.1.3.cmml" xref="S5.SS1.p4.1.m1.1.1.3">0.015</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">\theta=0.015</annotation></semantics></math> was employed in the <span id="S5.SS1.p4.3.1" class="ltx_text ltx_font_italic">MW-BS</span> algorithm, as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
This algorithm reduces the bandwidth for each <abbr title="Optical Network Unit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ONU</span></abbr> since it reserves bandwidth for the slice.
Moreover, we employ the same aggregated offered load in the simulated algorithms to make a fair comparison.
The duration of the guard period was set to 0.624 <math id="S5.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mu s" display="inline"><semantics id="S5.SS1.p4.2.m2.1a"><mrow id="S5.SS1.p4.2.m2.1.1" xref="S5.SS1.p4.2.m2.1.1.cmml"><mi class="ltx_unit" id="S5.SS1.p4.2.m2.1.1.2" xref="S5.SS1.p4.2.m2.1.1.2.cmml">μ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p4.2.m2.1.1.1" xref="S5.SS1.p4.2.m2.1.1.1.cmml">​</mo><mi class="ltx_unit" id="S5.SS1.p4.2.m2.1.1.3" xref="S5.SS1.p4.2.m2.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.1b"><apply id="S5.SS1.p4.2.m2.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1"><times id="S5.SS1.p4.2.m2.1.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1.1"></times><ci id="S5.SS1.p4.2.m2.1.1.2.cmml" xref="S5.SS1.p4.2.m2.1.1.2">𝜇</ci><ci id="S5.SS1.p4.2.m2.1.1.3.cmml" xref="S5.SS1.p4.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.1c">\mu s</annotation></semantics></math> with a maximum cycle length of 1 ms.
Each simulation scenario lasted 100 s and was replicated <math id="S5.SS1.p4.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS1.p4.3.m3.1a"><mn id="S5.SS1.p4.3.m3.1.1" xref="S5.SS1.p4.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.3.m3.1b"><cn type="integer" id="S5.SS1.p4.3.m3.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.3.m3.1c">10</annotation></semantics></math> times.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2109.14593/assets/img/DELAY_EF_.png" id="S5.F4.sf1.g1" class="ltx_graphics ltx_img_square" width="319" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Delay-critical application</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2109.14593/assets/img/DELAY_FL_.png" id="S5.F4.sf2.g1" class="ltx_graphics ltx_img_square" width="313" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span><span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> application</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Average delay produced by the delay-critical and <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications. <math id="S5.F4.3.m1.1" class="ltx_Math" alttext="P1" display="inline"><semantics id="S5.F4.3.m1.1b"><mrow id="S5.F4.3.m1.1.1" xref="S5.F4.3.m1.1.1.cmml"><mi id="S5.F4.3.m1.1.1.2" xref="S5.F4.3.m1.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.F4.3.m1.1.1.1" xref="S5.F4.3.m1.1.1.1.cmml">​</mo><mn id="S5.F4.3.m1.1.1.3" xref="S5.F4.3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.3.m1.1c"><apply id="S5.F4.3.m1.1.1.cmml" xref="S5.F4.3.m1.1.1"><times id="S5.F4.3.m1.1.1.1.cmml" xref="S5.F4.3.m1.1.1.1"></times><ci id="S5.F4.3.m1.1.1.2.cmml" xref="S5.F4.3.m1.1.1.2">𝑃</ci><cn type="integer" id="S5.F4.3.m1.1.1.3.cmml" xref="S5.F4.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.3.m1.1d">P1</annotation></semantics></math> and <math id="S5.F4.4.m2.1" class="ltx_Math" alttext="P2" display="inline"><semantics id="S5.F4.4.m2.1b"><mrow id="S5.F4.4.m2.1.1" xref="S5.F4.4.m2.1.1.cmml"><mi id="S5.F4.4.m2.1.1.2" xref="S5.F4.4.m2.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.F4.4.m2.1.1.1" xref="S5.F4.4.m2.1.1.1.cmml">​</mo><mn id="S5.F4.4.m2.1.1.3" xref="S5.F4.4.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F4.4.m2.1c"><apply id="S5.F4.4.m2.1.1.cmml" xref="S5.F4.4.m2.1.1"><times id="S5.F4.4.m2.1.1.1.cmml" xref="S5.F4.4.m2.1.1.1"></times><ci id="S5.F4.4.m2.1.1.2.cmml" xref="S5.F4.4.m2.1.1.2">𝑃</ci><cn type="integer" id="S5.F4.4.m2.1.1.3.cmml" xref="S5.F4.4.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.4.m2.1d">P2</annotation></semantics></math> mean, respectively, <span id="S5.F4.8.1" class="ltx_text ltx_font_italic">DWBA-FL</span> algorithm with <span id="S5.F4.9.2" class="ltx_text ltx_font_italic">FL-first policy</span> and <span id="S5.F4.10.3" class="ltx_text ltx_font_italic">DC-first policy</span>.</figcaption>
</figure>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2109.14593/assets/img/cdf_both.png" id="S5.F5.sf1.g1" class="ltx_graphics ltx_img_landscape" width="290" height="230" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Involved clients vs. synchronization time</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2109.14593/assets/img/accuracy.png" id="S5.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="307" height="230" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Learning accuracy (with 2000 rounds) vs. synchronization time</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Percentage of the learning accuracy and involved clients depending on the synchronization time. <math id="S5.F5.2.m1.1" class="ltx_Math" alttext="P2" display="inline"><semantics id="S5.F5.2.m1.1b"><mrow id="S5.F5.2.m1.1.1" xref="S5.F5.2.m1.1.1.cmml"><mi id="S5.F5.2.m1.1.1.2" xref="S5.F5.2.m1.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.F5.2.m1.1.1.1" xref="S5.F5.2.m1.1.1.1.cmml">​</mo><mn id="S5.F5.2.m1.1.1.3" xref="S5.F5.2.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.2.m1.1c"><apply id="S5.F5.2.m1.1.1.cmml" xref="S5.F5.2.m1.1.1"><times id="S5.F5.2.m1.1.1.1.cmml" xref="S5.F5.2.m1.1.1.1"></times><ci id="S5.F5.2.m1.1.1.2.cmml" xref="S5.F5.2.m1.1.1.2">𝑃</ci><cn type="integer" id="S5.F5.2.m1.1.1.3.cmml" xref="S5.F5.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.2.m1.1d">P2</annotation></semantics></math> means <span id="S5.F5.5.1" class="ltx_text ltx_font_italic">DWBA-FL</span> algorithm with <span id="S5.F5.6.2" class="ltx_text ltx_font_italic">DC-first policy</span>.</figcaption>
</figure>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2109.14593/assets/img/_boxplot_.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="665" height="200" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Network delay performance for the <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> application. Each boxplot shows 10th, 30th, 50th, 80th, and 100th percentile of network delay for FL clients; <math id="S5.F6.2.m1.1" class="ltx_Math" alttext="P2" display="inline"><semantics id="S5.F6.2.m1.1b"><mrow id="S5.F6.2.m1.1.1" xref="S5.F6.2.m1.1.1.cmml"><mi id="S5.F6.2.m1.1.1.2" xref="S5.F6.2.m1.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.F6.2.m1.1.1.1" xref="S5.F6.2.m1.1.1.1.cmml">​</mo><mn id="S5.F6.2.m1.1.1.3" xref="S5.F6.2.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.2.m1.1c"><apply id="S5.F6.2.m1.1.1.cmml" xref="S5.F6.2.m1.1.1"><times id="S5.F6.2.m1.1.1.1.cmml" xref="S5.F6.2.m1.1.1.1"></times><ci id="S5.F6.2.m1.1.1.2.cmml" xref="S5.F6.2.m1.1.1.2">𝑃</ci><cn type="integer" id="S5.F6.2.m1.1.1.3.cmml" xref="S5.F6.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.2.m1.1d">P2</annotation></semantics></math> means <span id="S5.F6.5.1" class="ltx_text ltx_font_italic">DWBA-FL</span> algorithm with <span id="S5.F6.6.2" class="ltx_text ltx_font_italic">DC-first policy</span>..</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Simulation Results and Discussion</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Mean delay values obtained by DWBA-FL were lower than 80 ms and 150 ms for the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic in both underloaded and overloaded conditions, respectively.
The delay values given by <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> were at least twice as high as those given by our proposal (Fig. <a href="#S5.F4.sf2" title="In Figure 4 ‣ V-A Simulation Model and Setup ‣ V Performance Evaluation ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4b</span></a>).
This improvement is a consequence of the large windows allocated for transmissions of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic when our proposal is employed.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Moreover, the use of the <span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_italic">DC-first policy</span> produced lower delay values for the delay-critical traffic lower than those given by both the <span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_italic">FL-first policy</span> and the <span id="S5.SS2.p2.1.3" class="ltx_text ltx_font_italic">BS</span> algorithm (Fig. <a href="#S5.F4.sf1" title="In Figure 4 ‣ V-A Simulation Model and Setup ‣ V Performance Evaluation ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4a</span></a>).
This result occurs because the bandwidth slice is statically allocated for the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic. Furthermore, the strict prioritization of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffic employing the <span id="S5.SS2.p2.1.4" class="ltx_text ltx_font_italic">FL-first policy</span> and the huge amount of traffic produced by the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> application leads to delay-critical application to bandwidth starvation.
The mean delay of the delay-critical traffic produced by the <span id="S5.SS2.p2.1.5" class="ltx_text ltx_font_italic">FL-first policy</span> was from 200 us to 1000 us and is more than that produced by <span id="S5.SS2.p2.1.6" class="ltx_text ltx_font_italic">FL-first policy</span>.
Thus, the DWBA-FL with <span id="S5.SS2.p2.1.7" class="ltx_text ltx_font_italic">DC-first policy</span> produce mean delay values for the <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> and delay-critical application lower than the other algorithms.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Furthermore, the <abbr title="First-Fit" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FF</span></abbr> policy produces a slight decrease in delay values for both traffics than the other wavelength allocation policies (<span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_italic">i.e., </span> SSD and MSD).
This results are a consequence of the wastage of bandwidth due to the excessive uses of guard periods and poor multiplexing gain when employing the <abbr title="Single-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SSD</span></abbr> and <abbr title="Multiple-Scheduling Domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSD</span></abbr>, respectively.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">In Fig. <a href="#S5.F5.sf1" title="In Figure 5 ‣ V-A Simulation Model and Setup ‣ V Performance Evaluation ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5a</span></a>, the blue curve shows the proportion of clients involved as a function of the computing time. It shows the minimal synchronization time per round without any communication delay.
The <span id="S5.SS2.p4.1.1" class="ltx_text ltx_font_italic">MW-BS</span> algorithm requires a longer synchronization time per round to produce the same percentage of the involved clients than that required by the proposed scheme with <span id="S5.SS2.p4.1.2" class="ltx_text ltx_font_italic">DC-first policy</span>. For example, it is required a synchronization time of 1.9 s and 2.1 s to produce a percentage of involved clients of 50 % with our proposal and the <span id="S5.SS2.p4.1.3" class="ltx_text ltx_font_italic">MW-BS</span> algorithm, respectively.
To achieve a training accuracy of 76% (Fig. <a href="#S5.F5.sf2" title="In Figure 5 ‣ V-A Simulation Model and Setup ‣ V Performance Evaluation ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5b</span></a>), the proposed scheme can reduce 9.5% of the training time compared to the <abbr title="Bandwidth Slicing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BS</span></abbr> algorithm (<span id="S5.SS2.p4.1.4" class="ltx_text ltx_font_italic">i.e., </span> 0.2 s less for a synchronization time of 2.1 s), when the total traffic load is 0.8.</p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">Fig. <a href="#S5.F6" title="Figure 6 ‣ V-A Simulation Model and Setup ‣ V Performance Evaluation ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the network delay as a function of the ONU offered load.
The <span id="S5.SS2.p5.1.1" class="ltx_text ltx_font_italic">MW-BS</span> produce delay values greater than 300 ms, whereas, with the DWBA-FA algorithm, these values are reduced to less than 150 ms.
Moreover, for 80 % of the clients, which is the typical percentage of clients that produce accuracy greater than 75 % (see Fig. <a href="#S5.F5" title="Figure 5 ‣ V-A Simulation Model and Setup ‣ V Performance Evaluation ‣ Federated Learning over Next-Generation Ethernet Passive Optical Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), the <span id="S5.SS2.p5.1.2" class="ltx_text ltx_font_italic">MW-BS</span> scheme imposes a network delay greater than 200 ms, while the DWBA-FA imposes delay values lower than 100 ms, under underloaded conditions (<span id="S5.SS2.p5.1.3" class="ltx_text ltx_font_italic">i.e., </span> load ¡ 0.85).
In summary, DWBA-FL reduces the network delay when compared to the <span id="S5.SS2.p5.1.4" class="ltx_text ltx_font_italic">MW-BS</span> scheme.
This reduction in delay may decrease the number of stragglers, which in the end leads to a faster convergence and greater model accuracy.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This paper has introduced a resource allocation (RA) scheme for supporting <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> applications in TWDM-<abbr title="Ethernet PON" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural">EPONs</span></abbr> networks.
Our proposal includes a strict prioritization for federated learning and delay-critical traffic, which maximizes the allocated bandwidth and reduce the delay for both types of application.
Our proposal reduces the synchronization time without compromising the number of involved clients. It also reduces the delay of time-critical and federated learning applications.
Future research directions are envisioned as follows.
Various <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications coexisting on a given network infrastructure, which have different size of the local model parameters, number of clients and synchronization time.
Mechanisms are needed to appropriately address the <abbr title="Quality of Service" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">QoS</span></abbr> provisioning for the diversity of FL applications.
These schemes may schedule the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> traffics based on required bandwidth but also considering the number of straggler clients, the diverse <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> packet sizes, and synchronization time.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was partially sponsored by grant #15/24494-8, São Paulo Research Foundation (FAPESP), and CNPq.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. B. Letaief, W. Chen, Y. Shi, J. Zhang, and Y.-J. A. Zhang, “The roadmap to
6g: Ai empowered wireless networks,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>,
vol. 57, no. 8, pp. 84–90, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2016, pp. 770–778.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. Li, X. Shen, L. Chen, and J. Chen, “Bandwidth slicing to boost federated
learning over passive optical networks,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>,
vol. 24, no. 7, pp. 1492–1495, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan,
V. Smith, and A. Talwalkar, “Leaf: A benchmark for federated settings,”
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
F. de Melo Pereira, N. L. S. da Fonseca, and D. S. Arantes, “A fair scheduling
discipline for ethernet passive optical networks,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Comput. Networks</em>,
vol. 53, no. 11, pp. 1859–1878, 2009.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. S. Wey, “The outlook for pon standardization: a tutorial,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Journal
of Lightwave Technology</em>, vol. 38, no. 1, pp. 31–42, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Li, L. Chen, and J. Chen, “Scalable federated learning over passive optical
networks,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.15454</em>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
“Ieee standard for ethernet amendment 9: Physical layer specifications and
management parameters for 25 gb/s and 50 gb/s passive optical networks,”
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Std 802.3ca-2020 (Amendment to IEEE Std 802.3-2018 as amended by
IEEE 802.3cb-2018, IEEE 802.3bt-2018, IEEE 802.3cd-2018, IEEE 802.3cn-2019,
IEEE 802.3cg-2019, IEEE 802.3cq-2020, IEEE 802.3cm-2020, and IEEE
802.3ch-2020)</em>, pp. 1–267, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
M. P. McGarry, M. Reisslein, and M. Maier, “Wdm ethernet passive optical
networks,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>, vol. 44, no. 2, pp. 15–22,
2006.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
L. Wang, X. Wang, M. Tornatore, H. S. Chung, H. H. Lee, S. Park, and
B. Mukherjee, “Dynamic bandwidth and wavelength allocation scheme for
next-generation wavelength-agile epon,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Journal of Optical
Communications and Networking</em>, vol. 9, no. 3, pp. B33–B42, 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S. B. Hussain, W. Hu, H. Xin, and A. M. Mikaeil, “Low-latency dynamic
wavelength and bandwidth allocation algorithm for ng-epon,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Journal of
Optical Communications and Networking</em>, vol. 9, no. 12, pp. 1108–1115, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. P. McGarry, M. Reisslein, and M. Maier, “Ethernet passive optical network
architectures and dynamic bandwidth allocation algorithms,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE
Communications Surveys &amp; Tutorials</em>, vol. 10, no. 3, pp. 46–60, 2008.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
O. J. Ciceri, C. A. Astudillo, G. B. Figueiredo, Z. Zhu, and N. L. S.
da Fonseca, “Passive optical networking for 5g and beyond 5g low-latency
mobile fronthauling services,” 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Li, L. Chen, and J. Chen, “Scalable federated learning over passive optical
networks,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.15454</em>, 2020.

</span>
</li>
</ul>
</section>
<figure id="tab1" class="ltx_float biography">
<table id="tab1.1" class="ltx_tabular">
<tr id="tab1.1.1" class="ltx_tr">
<td id="tab1.1.1.1" class="ltx_td">
<span id="tab1.1.1.1.1" class="ltx_inline-block">
<span id="tab1.1.1.1.1.1" class="ltx_p"><span id="tab1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Oscar Ciceri</span>  (oscar@lrc.ic.unicamp.br) completed his five-year degree in Electronics and Telecommunications Engineering at Universidad del Cauca (UNICAUCA), Colombia, in 2015, and his M.S. degree in Computer Science at the University of Campinas (UNICAMP), Brazil, in 2019. He is a Ph.D. student and researcher in the Network Computing Laboratory (LRC) at that university. His research interests include Passive Optical Networks (PONs), 5G and 5G beyond networks, Machine Learning, and virtualization. His current work is on the low-latency PON technologies for 5G and 5G beyond mobile optical access systems.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab2" class="ltx_float biography">
<table id="tab2.1" class="ltx_tabular">
<tr id="tab2.1.1" class="ltx_tr">
<td id="tab2.1.1.1" class="ltx_td">
<span id="tab2.1.1.1.1" class="ltx_inline-block">
<span id="tab2.1.1.1.1.1" class="ltx_p"><span id="tab2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Carlos Astudillo</span>  (castudillo@lrc.ic.unicamp.br) received his bachelor’s degree in Electronics and Telecommunications Engineering from the University of Cauca, Colombia in 2009, and his MSc degree in Computer Science from the University of Campinas (UNICAMP), Brazil, in 2015. Currently, he is a PhD candidate in Computer Science at the Institute of Computing (IC), UNICAMP. His master’s thesis received 1st place at the 29th Theses and Dissertations Contest (CTD) of the Brazilian Computer Society (SBC), and the 2016 Best Master’s Thesis Award from IC/UNICAMP. His research interests include radio resource allocation and quality of service provisioning for machine to machine communications and the Internet of Things, backhauling/fronthauling in 5G &amp; B5G cellular networks, and machine learning for networking.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab3" class="ltx_float biography">
<table id="tab3.1" class="ltx_tabular">
<tr id="tab3.1.1" class="ltx_tr">
<td id="tab3.1.1.1" class="ltx_td">
<span id="tab3.1.1.1.1" class="ltx_inline-block">
<span id="tab3.1.1.1.1.1" class="ltx_p"><span id="tab3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Zuqing Zhu</span>  [M’07, SM’12] (zqzhu@ieee.org) received his Ph.D. degree from the Department of Electrical and Computer Engineering, University of California, Davis, in 2007. He is currently a full professor at USTC. He has published more than 200 papers in referreed journals and conferences. He was an IEEE Communications Society Distinguished Lecturer (2018–2019) and a Senior Member of OSA.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab4" class="ltx_float biography">
<table id="tab4.1" class="ltx_tabular">
<tr id="tab4.1.1" class="ltx_tr">
<td id="tab4.1.1.1" class="ltx_td">
<span id="tab4.1.1.1.1" class="ltx_inline-block">
<span id="tab4.1.1.1.1.1" class="ltx_p"><span id="tab4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Nelson L. S. da Fonseca</span>  [M’88, SM’01] (nfonseca@ic.unicamp.br) obtained his Ph.D. degree from the University of Southern California in 1994. He is Full Professor at the Institute of Computing, State University of Campinas (UNICAMP). He published 400+ papers and supervised 70+ graduate students. He is Senior Editor for the IEEE Communications Magazine and the IEEE Systems Journal. He is also an Associate Editor for Peer-to-Peer Networking and Applications and Computer Networks. He is past EiC of the IEEE Communications Surveys and Tutorials. He served as the IEEE ComSoc VP Publications, VP Technical and Educational Activities, and VP Member Relations.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2109.14592" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2109.14593" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2109.14593">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2109.14593" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2109.14594" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar  6 22:03:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
