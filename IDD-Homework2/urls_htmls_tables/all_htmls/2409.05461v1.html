<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets</title>
<!--Generated on Mon Sep  9 09:33:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Algorithm Selection,  Automated Recommender Systems,  AutoRecSys,  Ranking Prediction,  Collaborative Filtering" lang="en" name="keywords"/>
<base href="/html/2409.05461v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S1" title="In Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S2" title="In Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S3" title="In Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S3.SS1" title="In 3. Method ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset Processing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S3.SS2" title="In 3. Method ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Meta-Features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S3.SS3" title="In 3. Method ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Algorithms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S3.SS4" title="In 3. Method ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Meta-Learner</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S4" title="In Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S5" title="In Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Recommender Systems Algorithm Selection for
<br class="ltx_break"/>Ranking Prediction on Implicit Feedback Datasets</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lukas Wegmeth
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:lukas.wegmeth@uni-siegen.de">lukas.wegmeth@uni-siegen.de</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-8848-9434" title="ORCID identifier">0000-0001-8848-9434</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Intelligent Systems Group
<br class="ltx_break"/>University of Siegen</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id3.3.id3">Germany</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tobias Vente
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:tobias.vente@uni-siegen.de">tobias.vente@uni-siegen.de</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0003-8881-2379" title="ORCID identifier">0009-0003-8881-2379</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">Intelligent Systems Group
<br class="ltx_break"/>University of Siegen</span><span class="ltx_text ltx_affiliation_city" id="id5.2.id2">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id6.3.id3">Germany</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joeran Beel
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:joeran.beel@uni-siegen.de">joeran.beel@uni-siegen.de</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-4537-5573" title="ORCID identifier">0000-0002-4537-5573</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Intelligent Systems Group
<br class="ltx_break"/>University of Siegen</span><span class="ltx_text ltx_affiliation_city" id="id8.2.id2">Siegen</span><span class="ltx_text ltx_affiliation_country" id="id9.3.id3">Germany</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id10.id1">The recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets is under-explored.
Traditional approaches in recommender systems algorithm selection focus predominantly on rating prediction on explicit feedback datasets, leaving a research gap for ranking prediction on implicit feedback datasets.
Algorithm selection is a critical challenge for nearly every practitioner in recommender systems.
In this work, we take the first steps toward addressing this research gap.</p>
<p class="ltx_p" id="id11.id2">We evaluate the NDCG@10 of 24 recommender systems algorithms, each with two hyperparameter configurations, on 72 recommender systems datasets.
We train four optimized machine-learning meta-models and one automated machine-learning meta-model with three different settings on the resulting meta-dataset.</p>
<p class="ltx_p" id="id12.id3">Our results show that the predictions of all tested meta-models exhibit a median Spearman correlation ranging from 0.857 to 0.918 with the ground truth.
We show that the median Spearman correlation between meta-model predictions and the ground truth increases by an average of 0.124 when the meta-model is optimized to predict the ranking of algorithms instead of their performance.
Furthermore, in terms of predicting the best algorithm for an unknown dataset, we demonstrate that the best optimized traditional meta-model, e.g., XGBoost, achieves a recall of 48.6%, outperforming the best tested automated machine learning meta-model, e.g., AutoGluon, which achieves a recall of 47.2%.</p>
</div>
<div class="ltx_keywords">Algorithm Selection, Automated Recommender Systems, AutoRecSys, Ranking Prediction, Collaborative Filtering
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>18th ACM Conference on Recommender Systems; October 14–18, 2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>18th ACM Conference on Recommender Systems (RecSys ’24), October 14–18, 2024, Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3640457.3691718</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0505-2/24/10</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets remains unsolved, and research on this topic is scarce.
Previous works on recommender systems algorithm selection focus on rating prediction and ranking prediction of explicit feedback datasets <cite class="ltx_cite ltx_citemacro_citep">(Beel, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib3" title="">2017</a>; Collins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib8" title="">2018</a>; Tkaczyk et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib34" title="">2018</a>; Collins and Beel, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib7" title="">2019</a>; Beel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib5" title="">2020</a>; Collins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib9" title="">2020</a>; Cunha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib13" title="">2016</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib11" title="">2017a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib14" title="">2017b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib15" title="">2018b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib17" title="">2018d</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib16" title="">2018c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib12" title="">2018a</a>)</cite>.
However, the recommender systems community has recently shifted its focus to solving ranking prediction on implicit feedback datasets.
Algorithm selection is a critical challenge for nearly every practitioner in recommender systems, underscoring its significant impact.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The algorithm selection problem is commonly defined as (automatically) finding the best algorithm for a given task and is a prominent problem in the machine-learning community <cite class="ltx_cite ltx_citemacro_citep">(Khan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib26" title="">2020</a>; Kerschke et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib25" title="">2019</a>)</cite>.
Algorithm selection in machine learning and recommender systems is often solved with meta-learning techniques <cite class="ltx_cite ltx_citemacro_citep">(Cunha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib12" title="">2018a</a>)</cite>.
Meta-learning here means to learn the relationship between dataset meta-features, also called dataset characteristics, and algorithm performance.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The machine-learning community boosted the performance of algorithm selection solutions with the introduction and development of automated machine-learning techniques <cite class="ltx_cite ltx_citemacro_citep">(Erickson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib20" title="">2020</a>)</cite>.
However, to our knowledge, no works exist that explore the performance of automated machine-learning techniques on the recommender systems algorithm selection problem.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Recently, recommender systems research has shifted its focus toward solving ranking prediction tasks rather than rating prediction tasks.
That is, predicting the most relevant items to the user instead of predicting the rating a user would likely give an item.
The ranking prediction task was proposed over a decade ago <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib23" title="">2008</a>)</cite> and tackled in influential works already at least eight years ago <cite class="ltx_cite ltx_citemacro_citep">(Covington et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib10" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Similarly, the choice of recommender systems datasets has also changed over the years.
Traditionally, rating prediction was performed on explicit feedback datasets.
The predicted ratings were sometimes sorted and evaluated like a ranking prediction task.
However, with the shift to implicit feedback datasets in recommender systems practice, ranking prediction became the research focus.
Despite this, to our knowledge, there has been no research on the recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets so far.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In explicit feedback datasets, the users provided an explicit weight of the interaction with an item to convey the strength of a like or dislike of the item.
In contrast, a weight is commonly absent in implicit feedback datasets, further constraining meta-features.
Steck <cite class="ltx_cite ltx_citemacro_citep">(Steck, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib33" title="">2013</a>)</cite> has addressed the contrast between the two tasks.
We think this warrants a study of whether the available evidence of recommender systems algorithm selection for rating and ranking prediction on explicit feedback applies to ranking prediction on implicit feedback datasets.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Given the introduced research gaps, we tackle the following research questions on the recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets.</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix1.1.1.1">RQ1:</span></span>
<div class="ltx_para" id="S1.I1.ix1.p1">
<p class="ltx_p" id="S1.I1.ix1.p1.1">How effective are the established meta-features commonly used for solving the recommender systems algorithm selection problem for rating and ranking prediction on explicit feedback datasets when applied to ranking prediction for implicit feedback datasets?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix2.1.1.1">RQ2:</span></span>
<div class="ltx_para" id="S1.I1.ix2.p1">
<p class="ltx_p" id="S1.I1.ix2.p1.1">How does the performance of automated machine-learning algorithms compare to traditional meta-learning algorithms in recommender systems algorithm selection for ranking prediction on implicit feedback datasets?</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">To tackle the research questions, we develop a meta-dataset that includes the performance scores of 24 recommender systems algorithms, each with two hyperparameter configurations, on 72 recommender systems datasets.
For <span class="ltx_text ltx_font_bold" id="S1.p8.1.1">RQ1</span>, we perform a literature review to find meta-features commonly extracted from explicit feedback datasets and understand whether they can be extracted from implicit feedback datasets.
We then train traditional meta-learning algorithms on our meta-dataset, evaluate their algorithm selection performance, and discuss the implications of the results.
For <span class="ltx_text ltx_font_bold" id="S1.p8.1.2">RQ2</span>, we compare the algorithm selection performance of optimized traditional meta-learning algorithms versus automated machine-learning algorithms on our meta-dataset.
The results indicate whether automated machine-learning algorithms may be superior for solving the algorithm selection problem.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">Our main contribution is the first analysis of the recommender systems algorithm selection performance for ranking prediction on implicit feedback datasets.
We compare traditional and automated machine learning meta-models using established meta-features for ranking prediction on implicit feedback datasets in recommender systems.
Furthermore, we are making our meta-dataset publicly available, which includes performance scores for 24 algorithms, each with two hyperparameter configurations, across 72 datasets, evaluated using three ranking metrics at five thresholds.
The source code for reproducing all our results is available on GitHub<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://code.isg.beel.org/RecSys-Algorithm-Selection-Ranking-Implicit-LBR" title="">https://code.isg.beel.org/RecSys-Algorithm-Selection-Ranking-Implicit-LBR</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Already over a decade ago, recommender systems researchers published works that correlate data characteristics, e.g., meta-features in the context of meta-learning algorithm selection, to algorithm performance <cite class="ltx_cite ltx_citemacro_citep">(Huang and Zeng, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib24" title="">2011</a>; Griffith et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib21" title="">2012</a>; Adomavicius and Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib2" title="">2012</a>; Ekstrand and Riedl, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib18" title="">2012</a>; Matuszyk and Spiliopoulou, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib27" title="">2014</a>)</cite>.
Though having different objectives, they focus on understanding which data characteristics may predict the performance of a recommender systems algorithm for rating prediction.
All these works identify the common problem that no recommender systems algorithm is best for all datasets.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Following up on these works, roughly eight years ago, two groups of researchers, namely Beel &amp; Collins et al. and Cunha &amp; Soares et al., first analyzed the recommender systems algorithm selection problem as a meta-learning problem in a series of developing works (Beel &amp; Collins et al. <cite class="ltx_cite ltx_citemacro_citep">(Beel, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib3" title="">2017</a>; Collins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib8" title="">2018</a>; Tkaczyk et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib34" title="">2018</a>; Collins and Beel, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib7" title="">2019</a>; Beel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib5" title="">2020</a>; Collins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib9" title="">2020</a>; Wegmeth and Beel, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib37" title="">2022</a>)</cite>, Cunha &amp; Soares et al. <cite class="ltx_cite ltx_citemacro_citep">(Cunha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib13" title="">2016</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib11" title="">2017a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib14" title="">2017b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib15" title="">2018b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib17" title="">2018d</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib16" title="">2018c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib12" title="">2018a</a>)</cite>).
They provide concrete evidence of the performance of engineered meta-features and meta-learning algorithms on recommender systems algorithm selection in various domains.
In recent years other groups of researchers added new insights into the recommender systems algorithm selection problem <cite class="ltx_cite ltx_citemacro_citep">(Polatidis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib32" title="">2021</a>; Varela et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib35" title="">2022</a>)</cite>.
Additionally, the Beel &amp; Kotthoff organized the AMIR workshop that focused on the topic <cite class="ltx_cite ltx_citemacro_citep">(Beel and Kotthoff, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib4" title="">2019</a>)</cite>.
The shared focus of these works is understanding how to predict the best algorithm for rating or ranking prediction on explicit feedback datasets in recommender systems.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">A few works have addressed recommender systems algorithm selection for ranking prediction tasks <cite class="ltx_cite ltx_citemacro_citep">(McElfresh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib28" title="">2024</a>; Cunha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib12" title="">2018a</a>; Vente et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib36" title="">2023</a>)</cite>.
McElfresh et al. <cite class="ltx_cite ltx_citemacro_citep">(McElfresh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib28" title="">2024</a>)</cite> use meta-features that are only available in explicit feedback datasets.
They retrieve datasets that contain ratings, which they convert to weightless interactions for training recommender systems algorithms.
However, they extract meta-features that contain information about the interaction based on its rating before conversion.
Cunha et al. <cite class="ltx_cite ltx_citemacro_citep">(Cunha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib12" title="">2018a</a>)</cite>, on the other hand, perform ranking prediction after predicting ratings by sorting the ratings.
Vente et al. <cite class="ltx_cite ltx_citemacro_citep">(Vente et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib36" title="">2023</a>)</cite> do not employ meta-learning but use the validation score during optimization.
Our work differs from the others because we strictly focus on meta-learning with the constraints of implicit feedback datasets, where no rating information is available.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section details our design decisions for the evaluation pipeline, specifically, which datasets and algorithms we choose for our meta-dataset, which meta-features we extract from the datasets, and which meta-learners we compare.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Dataset Processing</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We retrieve 72 datasets<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The interested reader may refer to our GitHub repository for a list of datasets.</span></span></span> from varying sources, shapes, and domains.
They include contain many popular recommendation datasets, e.g., variations of the MovieLens <cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib22" title="">2015</a>)</cite> and Amazon <cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib30" title="">2019</a>)</cite> datasets, and also less popular ones.
All datasets are designed explicitly for recommender systems applications.
For this first analysis, we constrain ourselves to datasets that contain up to one million interactions.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Since we focus on the algorithm selection problem for ranking prediction on implicit feedback datasets, we must convert explicit feedback datasets, e.g., ratings, to implicit feedback datasets, e.g., interactions.
We specifically address the problem of algorithm selection for implicit feedback datasets that are constrained by not having this type of weighting for interactions.
Therefore, we treat any rating as an interaction, as is commonly done.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We process every dataset using five-core pruning, which involves recursively removing users and items with fewer than five interactions. This helps to reduce noise and mitigates the impact of cold-start scenarios, as collaborative filtering algorithms struggle to learn from users and items without sufficient joint interactions.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">Because an accurate estimation of algorithm performance is of utmost importance to the underlying algorithm selection problem, we employ five-fold cross-validation throughout the evaluation pipeline.
For example, we randomly split interactions per user into train and test sets at a ratio of 80% to 20%, ensuring that every interaction is tested once.
Our goal is to encompass the broadest range of data-constrained recommendation tasks.
Therefore, we choose not to apply a time-based split because datasets often do not contain timestamps.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Meta-Features</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Literature on recommender systems meta-feature extraction primarily considers distribution meta-features <cite class="ltx_cite ltx_citemacro_citep">(McElfresh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib28" title="">2024</a>; Cunha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib12" title="">2018a</a>)</cite>.
In particular, counting the number of instances, features, labels, categories, etc., is straightforward.
For example, the number of users, items, and interactions, related information like data sparsity, and the minimum and maximum number of interactions of any user or on any item.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Extracting meta-features from the weightless interactions of implicit feedback datasets is more challenging than from explicit feedback datasets.
For example, when ratings are available, many meta-features use the rating of interactions, such as the mean rating, the histogram of ratings, and user and item bias.
We cannot use rating-based meta-features since we do not have ratings in implicit feedback datasets.
Interaction timestamps are also helpful for meta-feature extraction, e.g., the interaction time frequency, interaction history length, and the average time per user and item interaction.
However, we do not use time-based meta-features, as this would limit our algorithm selection findings to datasets with timestamps, which are sometimes absent in recommender systems datasets.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Therefore, we use the following meta-features in this paper: the number of users, the number of items, the number of interactions, the density of the user-item matrix, the ratio of users to items, the ratio of items to users, the highest number of ratings by a single user, the lowest number of ratings by a single user, the highest number of ratings on a single item, the lowest number of ratings on a single item, the mean number of ratings by each user, the mean number of ratings on each item.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Algorithms</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We use 24 recommender systems algorithms<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The interested reader may refer to our GitHub repository for a list of algorithms.</span></span></span> to present results for as many relevant algorithms as possible.
The algorithms are in various categories, e.g., neighborhood-based (User-based KNN, Item-based KNN), factorization-based (SVD, Implicit MF), deep learning (VAE, LightGCN), and popularity.
We further evaluate two hyperparameter configurations for each algorithm<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Except Popularity and Random because they do not have hyperparameters.</span></span></span> to consider possible variations of algorithm performance due to hyperparameters.
This results in 46 different algorithm-hyperparameter combinations.
We use the algorithm implementations from RecBole <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib38" title="">2023</a>)</cite>, LensKit <cite class="ltx_cite ltx_citemacro_citep">(Ekstrand, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib19" title="">2020</a>)</cite>, and RecPack <cite class="ltx_cite ltx_citemacro_citep">(Michiels et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib29" title="">2022</a>)</cite> to compare different libraries.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">We calculate the number of recommender systems algorithm training procedures by multiplying the number of datasets by the number of data splits and algorithms-hyperparameter combinations.
In total, we train 16,560 recommender systems algorithms.
Due to this immense requirement, we constrain the training procedure to guarantee results after a particular time.
First, we limit ourselves to 8,280 GPU<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>On the OMNI cluster of the University of Siegen (AMD EPYC 7452, Tesla V100).</span></span></span> hours for training.
This results in precisely thirty minutes of training per algorithm, after which training is stopped, and the model at that time is used.
We acknowledge that half an hour of training may be limiting for specific algorithms.
However, we guarantee that every algorithm produces a model in this time frame.
Finally, we choose three commonly used ranking metrics for recommender systems: <em class="ltx_emph ltx_font_italic" id="S3.SS3.p2.1.1">nDCG</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS3.p2.1.2">Recall</em>, and <em class="ltx_emph ltx_font_italic" id="S3.SS3.p2.1.3">Hit Rate</em>, and evaluate these metrics at multiple thresholds, e.g., 1, 3, 5, 10, and 20.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Meta-Learner</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">We use dataset meta-features as the input features for the meta-learning problem.
The performance scores of recommender system algorithms on these datasets serve as the labels.
We aim to learn how dataset meta-features relate to algorithm performance to predict the best algorithm for a new dataset based solely on its meta-features.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">Training the meta-learner is a machine learning problem, though under heavy constraints.
In this paper, we explore two different objectives for the meta-learning process: algorithm performance prediction and algorithm ranking prediction.
In algorithm performance prediction, we predict the performance of algorithms and then rank them.
In algorithm ranking prediction, we predict the ranking of algorithms directly.
The labels, e.g. the algorithm performance scores, are real numbers in performance prediction or integers in ranking prediction.
Therefore, for both objectives, we define the meta-learning problem as a regression problem.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">We train one meta-learner per algorithm-hyperparameter combination, e.g., we pose the meta-learning problem as a single label-regression problem, where the label is the performance of an algorithm given a specific metric.
In this paper, we focus on NDCG@10.
This process is computationally expensive, but we expect more robust and fine-tuned models than posing the meta-learning problem, for example, as a multi-label regression problem.
Regardless, inference is fast because the meta-models are tiny.</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">For traditional meta-learning algorithms we employ the scikit-learn <cite class="ltx_cite ltx_citemacro_citep">(Pedregosa et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib31" title="">2011</a>)</cite> implementation of Linear Regression, K Nearest Neighbors, and Random Forest, as well as XGBoost by DMLC <cite class="ltx_cite ltx_citemacro_citep">(Chen and Guestrin, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib6" title="">2016</a>)</cite>.
All meta-learning algorithms are optimized with a grid search on a hyperparameter grid with more than 500 combinations.
To compare the traditional meta-learning algorithms with automated machine learning algorithms, we run AutoGluon <cite class="ltx_cite ltx_citemacro_citep">(Erickson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#bib.bib20" title="">2020</a>)</cite> with three settings: medium quality, best quality without bagging, and best quality with bagging, for up to twenty minutes each.</p>
</div>
<div class="ltx_para" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1">We perform a leave-one-out split for the evaluation of the meta-learning algorithms.
This means we train a model on all but one dataset and test it on the remaining dataset, repeating this for each dataset.
A leave-one-out split helps us to understand per dataset, whether the meta-learning is successful.
For most machine-learning tasks, a leave-one-out split would explode the training effort, as one model must be trained per instance.
However, due to the inherently small size of the meta-dataset, this is relatively inexpensive.
Multiplying the number of models, optimization objectives, and data splits yields 46,368 meta-models we train for this paper.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We present the comparison of the performance of traditional and automated machine-learning meta-models in the recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets.
We focus on meta-models trained to predict the ranking or performance of recommender systems algorithms evaluated with the NDCG@10.</p>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="830" id="S4.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>The Spearman correlation between meta-model predictions and ground truth (NDCG@10) per dataset. Each data point represents the correlation between predicted rankings (first plot) or performance (second plot) and the ground truth for a test dataset in a leave-one-out evaluation.</figcaption>
</figure>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We begin by examining the Spearman correlation (<math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mrow id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">p</mi><mo id="S4.p2.1.m1.1.1.1" xref="S4.p2.1.m1.1.1.1.cmml">&lt;</mo><mn id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><lt id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1"></lt><ci id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2">𝑝</ci><cn id="S4.p2.1.m1.1.1.3.cmml" type="float" xref="S4.p2.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_p &lt; 0.05</annotation></semantics></math>) between the meta-model predictions and the ground-truth algorithm performances for each dataset, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S4.F1" title="Figure 1 ‣ 4. Results ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_tag">1</span></a>.
Our analysis reveals a consistently high Spearman correlation across all meta-models.
Notably, meta-models optimized for predicting algorithm rankings exhibit an average median Spearman correlation 0.124 points higher than those optimized for performance prediction.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Among the automated machine learning meta-models, AutoGluon Best (Bagging) achieves the highest Spearman correlation of 0.809.
This is lower than the median Spearman correlation of 0.843 for the best traditional algorithm, Linear Regression, in performance prediction (see the second plot in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S4.F1" title="Figure 1 ‣ 4. Results ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_tag">1</span></a>).
However, AutoGluon Best (No Bagging) outperforms the best traditional model, Random Forest, with a median Spearman correlation of 0.918 compared to 0.904 for ranking prediction (see the first plot in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S4.F1" title="Figure 1 ‣ 4. Results ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">We also observe some outliers, where the meta-models struggle to learn effectively.
Given that the ranking prediction objective consistently outperforms the performance prediction objective, we will focus on the ranking prediction objective moving forward.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="830" id="S4.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>The Recall@1 and Recall@3 for the ranking objective meta-model predictions show the frequency of achieving the specified recall per dataset in a leave-one-out evaluation. For example, a Recall@1 score of 1 means the meta-model correctly identified the top algorithm. Each meta-model is evaluated on 72 datasets.</figcaption>
</figure>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">Most meta-models predict the best algorithm for nearly half of the datasets.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.05461v1#S4.F2" title="Figure 2 ‣ 4. Results ‣ Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates this by showing the Recall of meta-models for the ranking prediction objective.
The best meta-model for Recall@1 is the optimized XGBoost, with a score of 0.486, e.g., it predicts the best algorithm for 48.6% of datasets.
For Recall@3, all meta-models identify two of the top three algorithms in most cases.
The best meta-model here is optimized Random Forest, with a Recall@3 of 0.669, predicting two of the top three algorithms for each dataset.
Additionally, Random Forest predicts the top 3 algorithms for 34.7% (25 of 72) of datasets.
Traditional meta-models slightly outperform AutoGluon Best (No Bagging), which has a Recall@1 of 0.472 and a Recall@3 of 0.658.
However, AutoGluon shows a higher Spearman correlation with the ground truth.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Answering <span class="ltx_text ltx_font_bold" id="S5.p1.1.1">RQ1</span>, based on the presented results, we find that traditionally used meta-features are effective for predicting algorithm ranking.
Although we are unable to use many meta-features that consider ratings in original works on recommender systems algorithm selection, we show that even a limited set of meta-features leads to a high correlation between meta-model predictions and the ground truth.
We further demonstrate how we considerably improve the performance of the meta-models by optimizing them for predicting the ranking of algorithms instead of their performance.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Answering <span class="ltx_text ltx_font_bold" id="S5.p2.1.1">RQ2</span>, based on the presented results, we find that the automated machine-learning meta-model AutuGluon has a higher correlation between the predicted algorithm ranking and ground truth than traditional optimized meta-models.
However, optimized traditional meta-models beat AutoGluon at predicting the best and the top three algorithms.
The performance difference between traditional models and AutoGluon is marginal but the training time for AutoGluon is higher.
Still, AutoGluon is easier to set up, requiring no parameter grid.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">We are able to predict the best algorithm for 48.6% of all datasets, regardless of size, domain, or algorithm category.
However, there is still much room for improvement, e.g., by extracting more complex meta-features, extending the meta-dataset, and improving meta-models.
In conclusion, we think that our results offer a positive outlook for the solution of the recommender systems algorithm selection problem for ranking prediction of implicit feedback datasets.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adomavicius and Zhang (2012)</span>
<span class="ltx_bibblock">
Gediminas Adomavicius and Jingjing Zhang. 2012.

</span>
<span class="ltx_bibblock">Impact of data characteristics on recommender systems performance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">ACM Trans. Manage. Inf. Syst.</em> 3, 1, Article 3 (apr 2012), 17 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2151163.2151166" title="">https://doi.org/10.1145/2151163.2151166</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beel (2017)</span>
<span class="ltx_bibblock">
Joeran Beel. 2017.

</span>
<span class="ltx_bibblock">A macro/micro recommender system for recommendation algorithms [proposal].

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beel and Kotthoff (2019)</span>
<span class="ltx_bibblock">
Joeran Beel and Lars Kotthoff. 2019.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proposal for the 1st Interdisciplinary Workshop on Algorithm Selection and Meta-Learning in Information Retrieval (AMIR)</em>.

</span>
<span class="ltx_bibblock">Springer International Publishing, 383–388.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-030-15719-7_53" title="">https://doi.org/10.1007/978-3-030-15719-7_53</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beel et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Joeran Beel, Bryan Tyrell, Edward Bergman, Andrew Collins, and Shahad Nagoor. 2020.

</span>
<span class="ltx_bibblock">Siamese Meta-Learning and Algorithm Selection with ’Algorithm-Performance Personas’ [Proposal].

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">CoRR</em> abs/2006.12328 (2020).

</span>
<span class="ltx_bibblock">arXiv:2006.12328

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2006.12328" title="">https://arxiv.org/abs/2006.12328</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Guestrin (2016)</span>
<span class="ltx_bibblock">
Tianqi Chen and Carlos Guestrin. 2016.

</span>
<span class="ltx_bibblock">XGBoost: A Scalable Tree Boosting System. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (San Francisco, California, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2">(KDD ’16)</em>. ACM, New York, NY, USA, 785–794.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2939672.2939785" title="">https://doi.org/10.1145/2939672.2939785</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins and Beel (2019)</span>
<span class="ltx_bibblock">
Andrew Collins and Joeran Beel. 2019.

</span>
<span class="ltx_bibblock">A first analysis of meta-learned per-instance algorithm selection in scholarly recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Workshop on Recommendation in Complex Scenarios, 13th ACM Conference on Recommender Systems (RecSys)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrew Collins, Jöran Beel, and Dominika Tkaczyk. 2018.

</span>
<span class="ltx_bibblock">One-at-a-time: A Meta-Learning Recommender-System for Recommendation-Algorithm Selection on Micro Level.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">CoRR</em> abs/1805.12118 (2018).

</span>
<span class="ltx_bibblock">arXiv:1805.12118

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1805.12118" title="">http://arxiv.org/abs/1805.12118</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Andrew Collins, Laura Tierney, and Joeran Beel. 2020.

</span>
<span class="ltx_bibblock">Per-Instance Algorithm Selection for Recommender Systems via Instance Clustering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">CoRR</em> abs/2012.15151 (2020).

</span>
<span class="ltx_bibblock">arXiv:2012.15151

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2012.15151" title="">https://arxiv.org/abs/2012.15151</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Covington et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Paul Covington, Jay Adams, and Emre Sargin. 2016.

</span>
<span class="ltx_bibblock">Deep Neural Networks for YouTube Recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Proceedings of the 10th ACM Conference on Recommender Systems</em> (Boston, Massachusetts, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib10.4.2">(RecSys ’16)</em>. Association for Computing Machinery, New York, NY, USA, 191–198.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2959100.2959190" title="">https://doi.org/10.1145/2959100.2959190</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2017a)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C.P.L.F. Carvalho. 2017a.

</span>
<span class="ltx_bibblock">Metalearning for Context-aware Filtering: Selection of Tensor Factorization Algorithms. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Proceedings of the Eleventh ACM Conference on Recommender Systems</em> (Como, Italy) <em class="ltx_emph ltx_font_italic" id="bib.bib11.4.2">(RecSys ’17)</em>. Association for Computing Machinery, New York, NY, USA, 14–22.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3109859.3109899" title="">https://doi.org/10.1145/3109859.3109899</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2018a)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C.P.L.F. de Carvalho. 2018a.

</span>
<span class="ltx_bibblock">Metalearning and Recommender Systems: A literature review and empirical study on the algorithm selection problem for Collaborative Filtering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Information Sciences</em> 423 (2018), 128–144.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.ins.2017.09.050" title="">https://doi.org/10.1016/j.ins.2017.09.050</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C. P. L. F. de Carvalho. 2016.

</span>
<span class="ltx_bibblock">Selecting Collaborative Filtering Algorithms Using Metalearning. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Machine Learning and Knowledge Discovery in Databases</em>, Paolo Frasconi, Niels Landwehr, Giuseppe Manco, and Jilles Vreeken (Eds.). Springer International Publishing, Cham, 393–409.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2017b)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C. P. L. F. de Carvalho. 2017b.

</span>
<span class="ltx_bibblock">Recommending Collaborative Filtering Algorithms Using Subsampling Landmarkers. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Discovery Science</em>, Akihiro Yamamoto, Takuya Kida, Takeaki Uno, and Tetsuji Kuboyama (Eds.). Springer International Publishing, Cham, 189–203.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2018b)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C. P. L. F. de Carvalho. 2018b.

</span>
<span class="ltx_bibblock">Algorithm Selection for Collaborative Filtering: the influence of graph metafeatures and multicriteria metatargets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">CoRR</em> abs/1807.09097 (2018).

</span>
<span class="ltx_bibblock">arXiv:1807.09097

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1807.09097" title="">http://arxiv.org/abs/1807.09097</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2018c)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C. P. L. F. de Carvalho. 2018c.

</span>
<span class="ltx_bibblock">cf2vec: Collaborative Filtering algorithm selection using graph distributed representations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">CoRR</em> abs/1809.06120 (2018).

</span>
<span class="ltx_bibblock">arXiv:1809.06120

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1809.06120" title="">http://arxiv.org/abs/1809.06120</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cunha et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2018d)</span>
<span class="ltx_bibblock">
Tiago Cunha, Carlos Soares, and André C. P. L. F. de Carvalho. 2018d.

</span>
<span class="ltx_bibblock">CF4CF: recommending collaborative filtering algorithms using collaborative filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of the 12th ACM Conference on Recommender Systems</em> (Vancouver, British Columbia, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib17.4.2">(RecSys ’18)</em>. Association for Computing Machinery, New York, NY, USA, 357–361.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3240323.3240378" title="">https://doi.org/10.1145/3240323.3240378</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekstrand and Riedl (2012)</span>
<span class="ltx_bibblock">
Michael Ekstrand and John Riedl. 2012.

</span>
<span class="ltx_bibblock">When recommenders fail: predicting recommender failure for algorithm selection and combination. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the Sixth ACM Conference on Recommender Systems</em> (Dublin, Ireland) <em class="ltx_emph ltx_font_italic" id="bib.bib18.2.2">(RecSys ’12)</em>. Association for Computing Machinery, New York, NY, USA, 233–236.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2365952.2366002" title="">https://doi.org/10.1145/2365952.2366002</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekstrand (2020)</span>
<span class="ltx_bibblock">
Michael D. Ekstrand. 2020.

</span>
<span class="ltx_bibblock">LensKit for Python: Next-Generation Software for Recommender Systems Experiments. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em> (Virtual Event, Ireland) <em class="ltx_emph ltx_font_italic" id="bib.bib19.2.2">(CIKM ’20)</em>. Association for Computing Machinery, New York, NY, USA, 2999–3006.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3340531.3412778" title="">https://doi.org/10.1145/3340531.3412778</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Erickson et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola. 2020.

</span>
<span class="ltx_bibblock">AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2003.06505 [stat.ML]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2003.06505" title="">https://arxiv.org/abs/2003.06505</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Griffith et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Josephine Griffith, Colm O’Riordan, and Humphrey Sorensen. 2012.

</span>
<span class="ltx_bibblock">Investigations into user rating information and predictive accuracy in a collaborative filtering domain. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the 27th Annual ACM Symposium on Applied Computing</em> (Trento, Italy) <em class="ltx_emph ltx_font_italic" id="bib.bib21.4.2">(SAC ’12)</em>. Association for Computing Machinery, New York, NY, USA, 937–942.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2245276.2245458" title="">https://doi.org/10.1145/2245276.2245458</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harper and Konstan (2015)</span>
<span class="ltx_bibblock">
F. Maxwell Harper and Joseph A. Konstan. 2015.

</span>
<span class="ltx_bibblock">The MovieLens Datasets: History and Context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">ACM Trans. Interact. Intell. Syst.</em> 5, 4, Article 19 (dec 2015), 19 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2827872" title="">https://doi.org/10.1145/2827872</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2008)</span>
<span class="ltx_bibblock">
Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008.

</span>
<span class="ltx_bibblock">Collaborative Filtering for Implicit Feedback Datasets. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">2008 Eighth IEEE International Conference on Data Mining</em>. 263–272.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICDM.2008.22" title="">https://doi.org/10.1109/ICDM.2008.22</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang and Zeng (2011)</span>
<span class="ltx_bibblock">
Zan Huang and Daniel Dajun Zeng. 2011.

</span>
<span class="ltx_bibblock">Why Does Collaborative Filtering Work? Transaction-Based Recommendation Model Validation and Selection by Analyzing Bipartite Random Graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">INFORMS J. on Computing</em> 23, 1 (jan 2011), 138–152.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1287/ijoc.1100.0385" title="">https://doi.org/10.1287/ijoc.1100.0385</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kerschke et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Pascal Kerschke, Holger H. Hoos, Frank Neumann, and Heike Trautmann. 2019.

</span>
<span class="ltx_bibblock">Automated Algorithm Selection: Survey and Perspectives.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Evolutionary Computation</em> 27, 1 (2019), 3–45.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1162/evco_a_00242" title="">https://doi.org/10.1162/evco_a_00242</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Irfan Khan, Xianchao Zhang, Mobashar Rehman, and Rahman Ali. 2020.

</span>
<span class="ltx_bibblock">A Literature Survey and Empirical Study of Meta-Learning for Classifier Selection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">IEEE Access</em> 8 (2020), 10262–10281.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2020.2964726" title="">https://doi.org/10.1109/ACCESS.2020.2964726</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Matuszyk and Spiliopoulou (2014)</span>
<span class="ltx_bibblock">
Pawel Matuszyk and Myra Spiliopoulou. 2014.

</span>
<span class="ltx_bibblock">Predicting the Performance of Collaborative Filtering Algorithms. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 4th International Conference on Web Intelligence, Mining and Semantics (WIMS14)</em> (Thessaloniki, Greece) <em class="ltx_emph ltx_font_italic" id="bib.bib27.2.2">(WIMS ’14)</em>. Association for Computing Machinery, New York, NY, USA, Article 38, 6 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2611040.2611054" title="">https://doi.org/10.1145/2611040.2611054</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McElfresh et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Duncan McElfresh, Sujay Khandagale, Jonathan Valverde, John P. Dickerson, and Colin White. 2024.

</span>
<span class="ltx_bibblock">On the generalizability and predictability of recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">Proceedings of the 36th International Conference on Neural Information Processing Systems</em> (New Orleans, LA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib28.4.2">(NIPS ’22)</em>. Curran Associates Inc., Red Hook, NY, USA, Article 319, 17 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Michiels et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Lien Michiels, Robin Verachtert, and Bart Goethals. 2022.

</span>
<span class="ltx_bibblock">RecPack: An(other) Experimentation Toolkit for Top-N Recommendation using Implicit Feedback Data. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Proceedings of the 16th ACM Conference on Recommender Systems</em> (Seattle, WA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib29.4.2">(RecSys ’22)</em>. Association for Computing Machinery, New York, NY, USA, 648–651.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3551472" title="">https://doi.org/10.1145/3523227.3551472</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019.

</span>
<span class="ltx_bibblock">Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects. In <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (Eds.). Association for Computational Linguistics, Hong Kong, China, 188–197.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/D19-1018" title="">https://doi.org/10.18653/v1/D19-1018</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedregosa et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine Learning in Python.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Journal of Machine Learning Research</em> 12 (2011), 2825–2830.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Polatidis et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Nikolaos Polatidis, Stelios Kapetanakis, and Elias Pimenidis. 2021.

</span>
<span class="ltx_bibblock">Recommender Systems Algorithm Selection Using Machine Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proceedings of the 22nd Engineering Applications of Neural Networks Conference</em>, Lazaros Iliadis, John Macintyre, Chrisina Jayne, and Elias Pimenidis (Eds.). Springer International Publishing, Cham, 477–487.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steck (2013)</span>
<span class="ltx_bibblock">
Harald Steck. 2013.

</span>
<span class="ltx_bibblock">Evaluation of recommendations: rating-prediction and ranking. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 7th ACM Conference on Recommender Systems</em> (Hong Kong, China) <em class="ltx_emph ltx_font_italic" id="bib.bib33.2.2">(RecSys ’13)</em>. Association for Computing Machinery, New York, NY, USA, 213–220.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2507157.2507160" title="">https://doi.org/10.1145/2507157.2507160</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tkaczyk et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Dominika Tkaczyk, Rohit Gupta, Riccardo Cinti, and Jöran Beel. 2018.

</span>
<span class="ltx_bibblock">ParsRec: A Novel Meta-Learning Approach to Recommending Bibliographic Reference Parsers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">CoRR</em> abs/1811.10369 (2018).

</span>
<span class="ltx_bibblock">arXiv:1811.10369

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1811.10369" title="">http://arxiv.org/abs/1811.10369</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Varela et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Daniela Varela, Jose Aguilar, Julián Monsalve-Pulido, and Edwin Montoya. 2022.

</span>
<span class="ltx_bibblock">Analysis of Meta-Features in the Context of Adaptive Hybrid Recommendation Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">2022 XVLIII Latin American Computer Conference (CLEI)</em>. 1–10.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/CLEI56649.2022.9959945" title="">https://doi.org/10.1109/CLEI56649.2022.9959945</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vente et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tobias Vente, Michael Ekstrand, and Joeran Beel. 2023.

</span>
<span class="ltx_bibblock">Introducing LensKit-Auto, an Experimental Automated Recommender System (AutoRecSys) Toolkit. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib36.4.2">(RecSys ’23)</em>. Association for Computing Machinery, New York, NY, USA, 1212–1216.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3610656" title="">https://doi.org/10.1145/3604915.3610656</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wegmeth and Beel (2022)</span>
<span class="ltx_bibblock">
Lukas Wegmeth and Joeran Beel. 2022.

</span>
<span class="ltx_bibblock">CaMeLS: Cooperative meta-learning service for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the Perspectives on the Evaluation of Recommender Systems Workshop 2022</em>. CEUR-WS.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ceur-ws.org/Vol-3228/paper2.pdf" title="">https://ceur-ws.org/Vol-3228/paper2.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Lanling Xu, Zhen Tian, Gaowei Zhang, Junjie Zhang, Lei Wang, Bowen Zheng, Yifan Li, Jiakai Tang, Zeyu Zhang, Yupeng Hou, Xingyu Pan, Wayne Xin Zhao, Xu Chen, and Ji-Rong Wen. 2023.

</span>
<span class="ltx_bibblock">Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">SIGIR</em>. ACM, 2837–2847.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep  9 09:33:20 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
