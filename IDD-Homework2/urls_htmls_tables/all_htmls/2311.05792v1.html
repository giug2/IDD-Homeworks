<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.05792] Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education</title><meta property="og:description" content="Despite the promises of ML in education, its adoption in the classroom has surfaced numerous issues regarding fairness, accountability, and transparency, as well as concerns about data privacy and student consent. A ro…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.05792">

<!--Generated on Tue Feb 27 19:19:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="datasets,  neural networks,  gaze detection,  text tagging">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mei Tan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mxtan@stanford.edu">mxtan@stanford.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Stanford University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hansol Lee
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_affiliation_institution">Stanford University</span><span id="id4.2.id2" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dakuo Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_affiliation_institution">Northeastern University</span><span id="id6.2.id2" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hariharan Subramonyam
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Stanford University</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id9.id1" class="ltx_p">Despite the promises of ML in education, its adoption in the classroom has surfaced numerous issues regarding fairness, accountability, and transparency, as well as concerns about data privacy and student consent. A root cause of these issues is the lack of understanding of the complex dynamics of education, including teacher-student interactions, collaborative learning, and classroom environment. To overcome these challenges and fully utilize the potential of ML in education, software practitioners need to work closely with educators and students to fully understand the context of the data (the backbone of ML applications) and collaboratively define the ML data specifications. To gain a deeper understanding of such a collaborative process, we conduct ten co-design sessions with ML software practitioners, educators, and students. In the sessions, teachers and students work with ML engineers, UX designers, and legal practitioners to define dataset characteristics for a given ML application. We find that stakeholders contextualize data based on their domain and procedural knowledge, proactively design data requirements to mitigate downstream harms and data reliability concerns, and exhibit role-based collaborative strategies and contribution patterns. Further, we find that beyond a seat at the table, meaningful stakeholder participation in ML requires structured supports: defined processes for continuous iteration and co-evaluation, shared contextual data quality standards, and information scaffolds for both technical and non-technical stakeholders to traverse expertise boundaries.</p>
</div>
<div class="ltx_keywords">datasets, neural networks, gaze detection, text tagging
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>; ; </span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer systems organization Embedded systems</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer systems organization Redundancy</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer systems organization Robotics</span></span></span><span id="id10" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Networks Network reliability</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Education is a complex and dynamic system <cite class="ltx_cite ltx_citemacro_citep">(Koopmans, <a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite>. Yet, applications of machine learning (ML) in education rely on generalized approaches with narrow conceptualizations of educational knowledge to analyze learner behavior, interactions, and performance <cite class="ltx_cite ltx_citemacro_citep">(Perrotta and Selwyn, <a href="#bib.bib63" title="" class="ltx_ref">2020</a>)</cite>. Consequently, the adoption of ML applications in school administration, instruction, and learning has led to issues of fairness, accountability, transparency, and utility in their implications for practitioners and vulnerable student populations <cite class="ltx_cite ltx_citemacro_citep">(Baker and Hawn, <a href="#bib.bib6" title="" class="ltx_ref">2022a</a>; Perrotta and Selwyn, <a href="#bib.bib63" title="" class="ltx_ref">2020</a>; Pedro et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019</a>; Holmes et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2022</a>; Reich and Ito, <a href="#bib.bib71" title="" class="ltx_ref">2017</a>)</cite>. Harms include systematic inequalities in recommender systems <cite class="ltx_cite ltx_citemacro_citep">(Marras et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite> and high-stakes automated decision-making <cite class="ltx_cite ltx_citemacro_citep">(Kizilcec and Lee, <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>, surveillance and civil rights concerns in facial recognition systems <cite class="ltx_cite ltx_citemacro_citep">(Whittaker et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2018</a>)</cite>, data privacy concerns <cite class="ltx_cite ltx_citemacro_citep">(Potgieter, <a href="#bib.bib68" title="" class="ltx_ref">2020</a>; Feathers, <a href="#bib.bib23" title="" class="ltx_ref">2022b</a>, <a href="#bib.bib24" title="" class="ltx_ref">a</a>)</cite>, and disparities in student propensities to consent <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">These issues are rooted in the underlying challenge facing ML design and development, which include undefined policy-level guidelines <cite class="ltx_cite ltx_citemacro_citep">(Schiff, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>)</cite>, insufficient teacher education and involvement in ML development <cite class="ltx_cite ltx_citemacro_citep">(Bogina et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2022</a>; Schiff, <a href="#bib.bib79" title="" class="ltx_ref">2021</a>; Roll and Wylie, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite>, the underdevelopment of inclusive and high-quality data systems <cite class="ltx_cite ltx_citemacro_citep">(Ocumpaugh et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2014</a>; Gardner et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>, and the lack of ethical regulation and transparency in data collection, use, and dissemination <cite class="ltx_cite ltx_citemacro_citep">(Pedro et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019</a>)</cite>. Traditional ML development processes undervalue the critical role of trustworthy training data and dataset accountability and largely assume data as given <cite class="ltx_cite ltx_citemacro_citep">(Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Further, current engineering processes limit engagement with domain experts and end-users such as educators and students and miss important contextual features of real-world data <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2022a</a>)</cite>. When included, domain experts only converge in ML development after crucial data-related decisions have been made <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib87" title="" class="ltx_ref">2022b</a>)</cite>. While researchers have created guidelines for downstream data evaluation and documentation (e.g., Datasheets for Datasets <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite>), standard practices remain undefined in upstream data specification <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite>. Resolving these issues requires addressing the tensions between ML innovations, engineering priorities, and teacher and student needs. Concretely, to create ethical and human-centered ML experiences for education scenarios, we need early collaboration between educators, students, and ML practitioners.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The recent methodological shift in ML practice to re-prioritize the design and quality of training data (i.e., data-centric AI) presents an opportunity to involve teachers and students early in the design of the ML data pipeline <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2021b</a>)</cite>. However, mere participation is <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">not enough</span> <cite class="ltx_cite ltx_citemacro_citep">(Sloane et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2020</a>)</cite>. To truly involve teachers and students, we argue they must be provided with the necessary training and resources to understand and contribute to the design process. This includes ensuring that their input and feedback are considered, working with them to resolve knowledge gaps, contextualizing data needs within domain needs, and negotiating trade-offs around scope and generalizability. Further ML software practitioners should revise their work practices to prioritize domain knowledge and collaboration with domain experts.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this work, we investigate whether and how teachers and students can work with ML practitioners to define data requirements (the backbone of machine learning models) from the ground up. While prior research has focused on co-designing ML applications with teachers (e.g., <cite class="ltx_cite ltx_citemacro_citep">(Holstein et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019a</a>)</cite>), our work looks at the collaborative specification of dataset attributes, labels, and data collection pipeline (i.e., items in the Datasheets for Datasets <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite>). We ask the following research questions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">RQ1:</span> What do diverse stakeholders bring to the table when co-designing data specifications?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">RQ2:</span> How can we systematically support and amplify diverse stakeholder voices in the ML data specification process?</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To investigate these research questions, we conducted a series of co-design sessions engaging experts and stakeholders across domains in collaborative data specification for ML applications in education. Forty participants took part in our study, representing ML engineers, teachers, students, UX designers, and legal experts roles. During these sessions, stakeholders defined dataset characteristics, discussed representativeness and validation criteria, developed labels, and planned ethical data collection strategies for several common application scenarios <cite class="ltx_cite ltx_citemacro_citep">(Niemi et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2023</a>)</cite> (e.g., student drop-out risk prediction, automated essay grading, student engagement image classification). We find that teachers and students play a crucial role in contextualizing upstream data-related decisions in downstream use and support the identification of potential biases and reliability threats during data collection and labeling. Further, we identify challenges and needs to deepen stakeholder collaboration to ensure productive participation.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In summary, our work contributes to the emerging practice of data-centric AI, collaborative processes in human-centered AI, and the growing literature on practitioner needs regarding ML applications in education. Through our co-design sessions, we highlight the affordances and limitations of having a seat at the table and discuss directions for future research designing collaborative processes for engaging stakeholders in the education domain. We also discuss the implications of our findings, including developing shared standards, information scaffolds, and supportive tooling to support multi-stakeholder contribution to ML data specification and evaluation.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The potential for ML systems to create or exacerbate biases, unfairness, and downstream ethical harms has received academic attention across disciplines. The focus of this work investigates the engineering processes in the research and industry environments that build these ML systems. Prior work has highlighted an urgent need for the organizational adoption of tooling and internal processes that support the responsible development and maintenance of fairer systems <cite class="ltx_cite ltx_citemacro_citep">(Latonero et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2017</a>; Sculley et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2015</a>)</cite>. These calls to action emphasize two high-level practices: focusing on data work and involving context in the design and development of ML applications <cite class="ltx_cite ltx_citemacro_citep">(Leslie et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite>. Here we first synthesize existing literature on data practices in ML and then situate our work in current approaches to data documentation and stakeholder collaboration.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>ML Data Pipeline and Current Practices</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Compared to software application development, machine learning applications require the complexities of discovering and managing data <cite class="ltx_cite ltx_citemacro_citep">(Amershi et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>. The machine learning lifecycle begins with data management, underpinned by a set of system-level requirements, which produces the training dataset used to drive the model learning, model verification, and model deployment stages of the ML workflow <cite class="ltx_cite ltx_citemacro_citep">(Ashmore et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2021</a>; Guo, <a href="#bib.bib29" title="" class="ltx_ref">2013</a>)</cite>. Data management consists of multiple steps, including data acquisition, data annotation, data pre-processing, data augmentation, and data validation <cite class="ltx_cite ltx_citemacro_citep">(Akkiraju et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>. During data acquisition, collecting examples may take the form of searching and indexing existing datasets, distorting and deriving synthetic examples from existing datasets, or creating datasets through data generation techniques <cite class="ltx_cite ltx_citemacro_citep">(Whang et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2023</a>)</cite>. During data annotation, labeling examples may involve the utilization of existing labels, or manually or automatically generating new labels <cite class="ltx_cite ltx_citemacro_citep">(Whang et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2023</a>)</cite>. The data pipeline additionally encompasses the devices and processes involved in storing and moving data <cite class="ltx_cite ltx_citemacro_citep">(Munappy et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite>. The creation of data used to develop ML systems often requires costly manual work but this work critically affects the trustworthiness of the resulting model <cite class="ltx_cite ltx_citemacro_citep">(Liang et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Despite the complexity and significance of data management, current industry practices rely on model-centric development, in which engineering resources are dedicated primarily to iterating the model architecture or training procedure to improve the benchmark performance <cite class="ltx_cite ltx_citemacro_citep">(Liang et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite>. Prior work has found ‘discretionary’ practices in system design <cite class="ltx_cite ltx_citemacro_citep">(Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>; Passi and Sengers, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>, ambiguous roles and responsibilities within teams <cite class="ltx_cite ltx_citemacro_citep">(Saltz and Grady, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>)</cite>, and reliance on individual engineers to identify issues and address ethical concerns <cite class="ltx_cite ltx_citemacro_citep">(Rakova et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2021</a>)</cite>. Furthermore, traditional engineering processes limit engagement with domain experts and end-users, separating the work of technical development and understanding end-user requirements <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2022a</a>)</cite>, and prioritizing technical affordances over the problems of practitioners and real-world contexts <cite class="ltx_cite ltx_citemacro_citep">(Kerner, <a href="#bib.bib39" title="" class="ltx_ref">2020</a>; Birhane et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. These ad hoc and technology-focused engineering practices have resulted in haphazard data management, in which decisions regarding the definitions of data are forgotten beneath a series of additional decisions, opportunities, improvisations, and assumptions <cite class="ltx_cite ltx_citemacro_citep">(Muller and Strohmayer, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite>. Practitioners developing ML systems currently face challenges across multiple steps of the data pipeline, including finding, understanding, preparing, and validating data <cite class="ltx_cite ltx_citemacro_citep">(Polyzotis et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2018</a>, <a href="#bib.bib66" title="" class="ltx_ref">2017</a>)</cite>. Audits of dataset development work have found practices that value efficiency over care <cite class="ltx_cite ltx_citemacro_citep">(Paullada et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2021</a>)</cite>, resulting in an overwhelming majority of datasets that do not meet quality standards <cite class="ltx_cite ltx_citemacro_citep">(Nagle et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite>. Data-centric practices are undervalued in conventional ML development, resulting in compounding downstream negative effects  <cite class="ltx_cite ltx_citemacro_citep">(Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>; Richardson et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Data-Centric AI and Data Documentation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To address the limitations of model-centric AI practices, recent work has started to focus on data-centric practices, producing supportive tooling for maintaining data repositories and facilitating data annotation and validation <cite class="ltx_cite ltx_citemacro_citep">(Liang et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite>. Research in data-centric AI has primarily addressed the downstream harms of low-quality data through the creation of numerous frameworks for facilitating data accountability and transparency through clear documentation practices <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Díaz et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>; Richards et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2021</a>; Arnold et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2019</a>; Bender and Friedman, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>; Chmielinski et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022</a>; Pushkarna et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2022</a>)</cite>. The dataset documentation literature introduces standardized processes for datasets to be accompanied by information identifying their motivation, context, composition, features, collection process, biases, recommended uses, and so on (e.g., DataSheets) <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite>. Documentation frameworks help engineers understand ethical issues in training data <cite class="ltx_cite ltx_citemacro_citep">(Boyd, <a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite> and provide important guidelines supporting accountability in data quality standards.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">However, prioritizing data work also necessitates supporting the collection and curation of high-quality data sets in the first place <cite class="ltx_cite ltx_citemacro_citep">(Holstein et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2019c</a>)</cite> and addressing the upstream work of defining dataset requirements <cite class="ltx_cite ltx_citemacro_citep">(Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite>. Ideal data-centric practices begin with specification and defining data requirements according to application needs, but ML systems commonly suffer from incomplete or misinterpreted requirements <cite class="ltx_cite ltx_citemacro_citep">(Challa et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; D’Amour et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>; Hullman et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2022</a>; Akkiraju et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>. Practices that support the specification of dataset requirements early in the data pipeline are understudied in the data-centric ML literature. In education settings, appropriate data specification design in the early stages of ML development is key to mitigating ethical harms in a high-stakes domain <cite class="ltx_cite ltx_citemacro_citep">(Baker and Hawn, <a href="#bib.bib7" title="" class="ltx_ref">2022b</a>; Kizilcec and Lee, <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>. Prior work evaluating AI fairness in education has encouraged research to interrogate the definition of ML problems and data collection procedures and evaluate the quality of training data <cite class="ltx_cite ltx_citemacro_citep">(Kizilcec and Lee, <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>. Our research investigates the proactive process of data specification, anticipating the evaluative components of documentation frameworks.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Domain Context and Stakeholder Collaboration</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Data is inextricably bound to place and community <cite class="ltx_cite ltx_citemacro_citep">(Taylor et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2015</a>)</cite>. The context encoded in data and the context of data production is critical to understanding datasets and their downstream applications <cite class="ltx_cite ltx_citemacro_citep">(Vertesi and Dourish, <a href="#bib.bib93" title="" class="ltx_ref">2011</a>)</cite>. Placing data in their temporal, geographic, and social context, disciplinary norms, and worldly representativeness is a key component of making sense of data <cite class="ltx_cite ltx_citemacro_citep">(Koesten et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite>. Prior work has called for incorporating more domain knowledge <cite class="ltx_cite ltx_citemacro_citep">(Veale et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2018</a>)</cite>, developing domain-specific performance metrics <cite class="ltx_cite ltx_citemacro_citep">(Holstein et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2019c</a>; Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2020</a>)</cite>, and creating frameworks for documenting context-specific intended use cases <cite class="ltx_cite ltx_citemacro_citep">(Chmielinski et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">A growing body of research has addressed the elevation of domain context through the study of collaboration and stakeholder participation. AI and HCI communities have increasingly called for more stakeholder participation in the design, development, and maintenance of ML systems <cite class="ltx_cite ltx_citemacro_citep">(Delgado et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>; Leslie et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>; Weber et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2022</a>; Boyarskaya et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>; Tomašev et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2020</a>; Muller et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2019</a>; Kross and Guo, <a href="#bib.bib44" title="" class="ltx_ref">2021</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2020</a>)</cite>. However, meaningful collaborative practice is complicated by the language boundaries of domains and the power dynamics at the intersection of communities of practice.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Firstly, collaboration in social applications of ML involves the complexities of cross-discipline communication. Development practices rooted in silos of expertise limit communication between disciplines. Subramonyam et al. <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib87" title="" class="ltx_ref">2022b</a>)</cite> investigated co-creation processes between engineers and user-experience designers and found a separation of concerns between engineers and domain practitioners. Technical experts explore machine learning capabilities independently while making erroneous assumptions about human behavior and contextual needs. Passi and Jackson <cite class="ltx_cite ltx_citemacro_citep">(Passi and Jackson, <a href="#bib.bib59" title="" class="ltx_ref">2018</a>)</cite> similarly found a separation of concerns among data science and business analyst experts dividing system accountability tasks. Mao et al. <cite class="ltx_cite ltx_citemacro_citep">(Mao et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite> studied the collaborative practices between data scientists and bio-medical scientists and found that these distinct roles often struggle to establish common ground regarding research projects. Work in stakeholder collaboration has additionally emphasized the importance of translation between different forms of knowledge  <cite class="ltx_cite ltx_citemacro_citep">(Williams and Begg, <a href="#bib.bib98" title="" class="ltx_ref">1993</a>)</cite>. Hou et al. <cite class="ltx_cite ltx_citemacro_citep">(Hou and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite> studied collaborative roles between technical and non-technical workers in a civic data hackathon, noting that the different stakeholders spoke different languages. Collaboration required organizers to understand both data science and context to serve as brokers and translate needs across disciplines. Domain stakeholder involvement requires transparent and interpretable technical explanations <cite class="ltx_cite ltx_citemacro_citep">(Estivill-Castro et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite>, but materials for educating stakeholders on ML are scarce <cite class="ltx_cite ltx_citemacro_citep">(Bogina et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>. Domain experts face barriers to participation in ML development and decision-making due to persistent knowledge gaps <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2022a</a>)</cite>.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">Secondly, the creative cooperation between stakeholders and technology designers requires the negotiation of values across communities of practice. The involvement of stakeholders in collaborative design efforts evolves from a tradition of participatory design, which highlights an agenda of democratizing innovation by shifting existing power structures and creating a hybrid space between the domains of technology designers and impacted users <span id="S2.SS3.p4.1.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">(Steen, <a href="#bib.bib84" title="" class="ltx_ref">2013</a>; Sanders and Stappers, <a href="#bib.bib78" title="" class="ltx_ref">2008</a>)</cite></span>. Equitable and community-based participatory design emphasize methods that are sensitive to the needs and practices of communities <span id="S2.SS3.p4.1.2" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">(Rosner et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2016</a>)</cite></span>. They aim to foster creativity, learning, and cultural production <cite class="ltx_cite ltx_citemacro_citep">(DiSalvo et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2012</a>)</cite> to design solutions that are considered successful by community metrics <span id="S2.SS3.p4.1.3" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">(Harrington et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite></span>.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p">In the education domain, participatory design methods are rarely deployed in the development of AI tools. Though stakeholder involvement is critical for the creation of useful and socially responsible products <cite class="ltx_cite ltx_citemacro_citep">(Buddemeyer et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>, teachers are often marginalized in technology discussions and engaged only as accessories during the implementation of ML systems <cite class="ltx_cite ltx_citemacro_citep">(Roll and Wylie, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite>. Michos et al. <cite class="ltx_cite ltx_citemacro_citep">(Michos et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite> collaborated with educational practitioners to understand practical challenges and iteratively evaluate solutions through workshops and implementation settings, following the structure of design-based research. Holstein et al. <cite class="ltx_cite ltx_citemacro_citep">(Holstein et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2019b</a>)</cite> involved teachers and students in “participatory speed dating” in order to solicit design feedback regarding AI applications in education. Other studies in education involve end-users through need-finding interviews and product design feedback <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2022</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2021</a>)</cite>. While such consultations are valuable, teachers and students are often engaged in a limited capacity as end-users. By participating only in later stages of ML development, long after crucial data-related decisions have been made, opportunities for envisioning equitable design solutions are limited.</p>
</div>
<div id="S2.SS3.p6" class="ltx_para">
<p id="S2.SS3.p6.1" class="ltx_p">In the ML pipeline, data specification is a unique high-leverage stage of involvement for stakeholder participation. End users and domain experts may play a critical role in making transparent what is valued in the data <cite class="ltx_cite ltx_citemacro_citep">(Hutchinson et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>. When engaged early, multi-stakeholder involvement may contribute significant insights to the design of collection and labeling procedures, validation and evaluation measures, modeling choices, and downstream use and maintenance of the dataset and application. By involving diverse stakeholders in education, our work further investigates the expanded role and contribution of teachers, students, engineers, designers and legal professionals in the co-design of data specifications. We position our work at the understudied intersection of stakeholder collaboration in the design of ML data specifications, situated in the unique and high-stakes context of education.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To investigate collaborative interactions between stakeholders, we conducted structured co-design workshops with engineers, designers, legal professionals, domain experts, and data subjects (i.e., individuals whose data will be collected). In each workshop, we presented participants with a potential application of ML in the education domain and asked them to collaboratively generate the data specifications for the ML model. The workshop sessions were held virtually via Zoom, with one individual representing each stakeholder’s role (a total of 10 workshop sessions). Each workshop session lasted <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="120" display="inline"><semantics id="S3.p1.1.m1.1a"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">120</mn><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><cn type="integer" id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">120</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">120</annotation></semantics></math> minutes. Our institution’s IRB approved the study. Participation was voluntary, and all participants were compensated with $50 for their involvement.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Participants</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We aimed to recruit one participant from each of the five roles for each session. Because our study is anchored in the education domain, we involved educators in the domain expert role and students in the data subject role. Aside from the student role, all other roles required participants to have at least one year of relevant professional experience. We recruited participants through direct email, mailing lists at university departments and technology companies, and social media posts shared by groups involved in the intersection of AI, ethics, and design. As shown in Table <a href="#S3.T1" title="Table 1 ‣ 3.1. Participants ‣ 3. Methodology ‣ Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, all but one session had participants from four of the five roles. Participants with expertise in the legal and ethical AI domains were challenging to recruit as it is an emerging role in practice. However, in developing the study protocol, we consulted with a legal AI scholar to provide adequate guidance for the group in thinking about legal and ethical requirements and constraints. Further, in cases where two or more scheduled participants were absent, we rescheduled the session and compensated those who were present with an additional $20 for their time (a total of 3 sessions). For session 10, we decided to proceed with the session with three participants as legal professionals were challenging to recruit and schedule. In total, we conducted workshop sessions with <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="40" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">40</annotation></semantics></math> participants.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S3.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Session</span></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r"><span id="S3.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Design Scenario</span></th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column"><span id="S3.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Participants (Years of Experience)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<th id="S3.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">1</th>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Student Engagement Image Classification</td>
<td id="S3.T1.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">E (25 yrs), T (18 yrs), S, D (2 yrs)</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<th id="S3.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">2</th>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r">Student Engagement Image Classification</td>
<td id="S3.T1.1.3.2.3" class="ltx_td ltx_align_left">E (3 yrs), T (30 yrs), S, D (2 yrs)</td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<th id="S3.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">3</th>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r">Student Engagement Image Classification</td>
<td id="S3.T1.1.4.3.3" class="ltx_td ltx_align_left">E (15 yrs), T (2 yrs), S, L (7 yrs)</td>
</tr>
<tr id="S3.T1.1.5.4" class="ltx_tr">
<th id="S3.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">4</th>
<td id="S3.T1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r">Resume-based Career Recommendation</td>
<td id="S3.T1.1.5.4.3" class="ltx_td ltx_align_left">E (5 yrs), T (9 yrs), S, D (1 yrs)</td>
</tr>
<tr id="S3.T1.1.6.5" class="ltx_tr">
<th id="S3.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">5</th>
<td id="S3.T1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r">Student Drop-out Risk Prediction</td>
<td id="S3.T1.1.6.5.3" class="ltx_td ltx_align_left">E (3 yrs), T (3 yrs), S, D (5 yrs)</td>
</tr>
<tr id="S3.T1.1.7.6" class="ltx_tr">
<th id="S3.T1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">6</th>
<td id="S3.T1.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r">Student Drop-out Risk Prediction</td>
<td id="S3.T1.1.7.6.3" class="ltx_td ltx_align_left">E (3 yrs), T (3 yrs), S, D (1 yrs)</td>
</tr>
<tr id="S3.T1.1.8.7" class="ltx_tr">
<th id="S3.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">7</th>
<td id="S3.T1.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r">Student Drop-out Risk Prediction</td>
<td id="S3.T1.1.8.7.3" class="ltx_td ltx_align_left">E (3 yrs), T (8 yrs), S, D (2 yrs), L (5 yrs)</td>
</tr>
<tr id="S3.T1.1.9.8" class="ltx_tr">
<th id="S3.T1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">8</th>
<td id="S3.T1.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r">Automated Essay Grading</td>
<td id="S3.T1.1.9.8.3" class="ltx_td ltx_align_left">E (2 yrs), T (5 yrs), S, D (1 yrs)</td>
</tr>
<tr id="S3.T1.1.10.9" class="ltx_tr">
<th id="S3.T1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">9</th>
<td id="S3.T1.1.10.9.2" class="ltx_td ltx_align_left ltx_border_r">Automated Essay Grading</td>
<td id="S3.T1.1.10.9.3" class="ltx_td ltx_align_left">E (7 yrs), T (7 yrs), S, D (2 yrs)</td>
</tr>
<tr id="S3.T1.1.11.10" class="ltx_tr">
<th id="S3.T1.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">10</th>
<td id="S3.T1.1.11.10.2" class="ltx_td ltx_align_left ltx_border_r">Automated Essay Grading</td>
<td id="S3.T1.1.11.10.3" class="ltx_td ltx_align_left">E (1 yrs), T (3 yrs), L (2 yrs)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Each workshop session is listed with participants by role (E = machine learning engineer, T = teacher, S = student, D = designer, L = legal/ethics professional) and the associated design scenario. Years of experience in their fields of expertise are indicated parenthetically for each professional stakeholder.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Workshop Protocol</h3>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2311.05792/assets/workshopdesign.png" id="S3.F1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Overview of our study protocol, including a design brief and high-level objectives for each of the data co-design sections.</figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Motivated by prior research studying collaborative AI design <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2021a</a>)</cite>, we opted to anchor our workshops on concrete applications of AI in education. Further, we used current <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">guidelines</span> on human-centered data specifications and desiderata about <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">data documentation</span> as a starting point to develop our workshop protocol. Concretely, the first and second authors analyzed the topics and questions in Datasheets for Datasets <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite> to identify those questions that could benefit from multi-stakeholder inputs and can be <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">proactively</span> specified before actual data collection. For instance, questions about attributes of each data instance, the meaning of representativeness for the dataset, and collection procedures can all be described upfront. In contrast, questions about sample size and data split between training and test sets are better defined in the later stages of the ML pipeline. As shown in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.2. Workshop Protocol ‣ 3. Methodology ‣ Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the questions correspond to five main topics for our workshop protocol, including (1) Motivation, (2) Composition, (3) Collection, (4) Evaluation, and (5) Continued Use. Further, to support discussions around each set of questions, we developed guiding prompts and examples based on human-centered data guidelines <cite class="ltx_cite ltx_citemacro_citep">(Google, <a href="#bib.bib28" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">To establish goals and a common language, workshops began with the presentation of a machine learning design scenario in education and a high-level explanation of the role of data in the intended application. Next, we provided participants with a data specification document with questions detailing considerations in each stage of the data pipeline. While the group collectively brainstormed ideas verbally, a research coordinator facilitated the session and recorded points of consensus in the data specification document screen-shared on Zoom. Our goal was to encourage discussions regarding priorities, trade-offs, and ethical concerns across diverse stakeholders to define data requirements. After each workshop, we asked participants a series of reflection questions to understand challenges in the co-design process and for additional tools or support to improve collaboration. We recorded each workshop session and collected generated data specification artifacts. Below, we detail the main steps in our protocol.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Design Brief</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">We prepared four ML application design scenarios for anchoring the workshop data specification activity. The scenarios were inspired by recent popular applications of machine learning in education, and our selection favored scenarios using different forms of input data. We aimed to understand whether and how different data types supported and challenged collaboration. The scenarios included a student engagement classification system using <span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">image</span> data, a student dropout early warning system using <span id="S3.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_italic">tabular</span> academic record data, and an automatic essay grading system using <span id="S3.SS2.SSS1.p1.1.3" class="ltx_text ltx_font_italic">text</span> input data. Initially, we intended to use resume-based career recommendations as an application of text data in ML. However, based on feedback from session 4, we observed that K-12 educators were less familiar with the application use case. Hence, for the remaining sessions, we opted for AI-based essay grading, which is more familiar to K-12 teachers. In each scenario presentation, workshop participants were shown examples of inputs and outputs to the model, as well as a visual mock-up of the use case and application interface. We broadly described the training data expected through an illustration of the data pipeline with sample features and labels, while noting the many uncertainties in the data specifications left for participants to consider <cite class="ltx_cite ltx_citemacro_citep">(Piet, <a href="#bib.bib64" title="" class="ltx_ref">2019</a>)</cite>. Workshop participants were then presented with a data specification document and the co-design task. We explained the data specification document as a guidebook for software teams to collect and evaluate the training data used to build the ML application specified in the design scenario. We additionally emphasized to participants that they should work collaboratively, seek the perspectives and expertise of one another, and lean into their unique stakeholder roles to make design decisions. Our study materials are included as a supplement to the paper.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Motivation</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">In the first stage of the protocol, participants were asked to define the details of the use case and application context for the ML application described in the design brief. Questions in this stage asked stakeholders to identify the people who will directly interact with the system, be directly impacted by the system’s operation, or could have a stake in how the system is created, used, or managed. We provided guidance in defining direct and indirect stakeholders and prompted participants to specify the characteristics of the relevant users and environments. Finally, we invited participants to brainstorm and elaborate concrete scenarios to situate the design task and build common ground to support subsequent steps in the protocol.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Composition</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">In the composition stage of the protocol, participants were first asked to consider the attributes, characteristics, and example instances that the training dataset should contain. We prompted groups that the dataset could contain multiple types or mediums of examples (e.g., documents, photos, people, countries, etc.), and we suggested that groups engage in a generative process with an eye to features that would be predictive of the target ML scenario outcomes (e.g., <span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">”which factors do you think could contribute to whether a student might be at risk of dropping out?”</span>). Next, participants were tasked with designing the categories and labels that are most appropriately associated with each example. We reminded groups that their chosen labeling schema would define the structure of outputs from the ML model, and we prompted participants to consider the specific context they had chosen in the previous stage. Importantly, participants were asked to define conditions under which the dataset is representative of the scenario users, including the representation and distribution of subgroups. By the conclusion of this stage, stakeholders converge on the specifications for the examples, features, labeling schema, and relative quantities of data representing important traits in the composition of the training dataset.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4. </span>Collection</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">In the collection stage of the protocol, participants were asked to design procedures for collecting data based on specifications defined in the previous step. We prompted that approaches could involve the collection of new raw data from relevant communities or accessing and re-purposing existing data sources. We explained that data collection mechanisms could additionally include direct reports by subjects (e.g., survey responses) or inference and derivation from other data (e.g., part-of-speech tags). We additionally asked participants to consider the details of the data collection timeframe and people involved in the collection process, as well as how consent should be requested and provided by individuals represented in the dataset. Participants were then asked to design procedures for labeling the examples in the dataset, specifying the people involved (e.g., domain experts, crowd workers, students), compensation, and timeline. Finally, we invited participants to brainstorm precautions that should be taken to avoid biases introduced by the data collection process and revise the collection procedure to address these risks. At the conclusion of this stage, stakeholders converge on a set of specifications for data collection and labeling and develop an expectation for the shape of the data in preparation for the next step.</p>
</div>
</section>
<section id="S3.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.5. </span>Evaluation of Data Quality and Data Cleaning</h4>

<div id="S3.SS2.SSS5.p1" class="ltx_para">
<p id="S3.SS2.SSS5.p1.1" class="ltx_p">In the evaluation stage of the protocol, participants were asked to assess the quality of the data collected. To scaffold understanding of data evaluation, we asked participants to first consider how they might measure the quality of a model, noting the desirable and undesirable behaviors in the downstream system. Using the discussion of model quality as common ground, we invited participants to design metrics and validation processes to test for data quality. We prompted groups to consider the potential errors, biases, and ethical concerns in collected data, as well as the characteristics of high-quality data that would inspire confidence in training a high-quality model. Next, we asked participants to design high-level data cleaning procedures, including the removal of low-quality or erroneous examples, the handling of sensitive or confidential data, methods for addressing the under-representation of various subgroups, and the processing of missing data.</p>
</div>
</section>
<section id="S3.SS2.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.6. </span>Continued Use</h4>

<div id="S3.SS2.SSS6.p1" class="ltx_para">
<p id="S3.SS2.SSS6.p1.1" class="ltx_p">In the final specification stage, participants were asked to address privacy, security, distribution, and copyright concerns for dataset use beyond the scope of the presented application. We invited participants to discuss whether the dataset should be distributed for use in future applications and to consider the mechanisms and procedures for data access. We prompted groups to consider the qualities of responsible data stewardship and to brainstorm continued implications of having specified and created the dataset.</p>
</div>
</section>
<section id="S3.SS2.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.7. </span>Debriefing</h4>

<div id="S3.SS2.SSS7.p1" class="ltx_para">
<p id="S3.SS2.SSS7.p1.1" class="ltx_p">At the conclusion of each workshop, participants were invited to reflect upon their co-design experience and discuss the opportunities and challenges of creating data specifications. We asked participants to share the highlights and lowlights of their collaborative co-design experience, recall moments in which they encountered or overcame knowledge gaps, and make suggestions for process improvements in engaging diverse stakeholders in the design of machine learning applications. We explained that the guiding questions used in the data specification design task are an active area of investigation, and we solicited feedback on the order, clarity, and completeness of the protocol.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Data Analysis</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The first author transcribed all workshop sessions first using a Python script with speaker diarization and then, in a second pass, manually verified the transcribed text and speaker roles against the video recordings. Next, we conducted inductive qualitative coding in Atlas.ti <cite class="ltx_cite ltx_citemacro_citep">(GmbH, <a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> using a grounded theory approach <cite class="ltx_cite ltx_citemacro_citep">(Strauss and Corbin, <a href="#bib.bib85" title="" class="ltx_ref">1990</a>)</cite> beginning with in-vivo analysis. Two authors independently open-coded the same two transcripts and collaboratively developed an initial code book, resolving disagreements by consensus. The resulting codebook consists of <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="53" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mn id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">53</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><cn type="integer" id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">53</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">53</annotation></semantics></math> codes. The coding scheme included references to procedural data needs (consent, labeling, cleaning, validation, etc.), contextual data needs (representation, bias mitigation, trade-offs, etc.), and collaborative processes (translation, sharing domain expertise, making assumptions, misconceptions, etc.). Using this codebook, we coded the remaining transcripts. The first author applied the code book to analyze the remaining transcripts <cite class="ltx_cite ltx_citemacro_citep">(Denzin et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>. Throughout the coding process, the authors wrote reflective memos describing insights and emerging themes and making connections across workshop sessions <cite class="ltx_cite ltx_citemacro_citep">(Birks et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2008</a>)</cite>. Once coding was complete, the research team engaged in multiple discussion sessions. In these sessions, we grouped codes and discussed memos through an iterative sense-making process to identify higher-level themes and synthesize findings across transcripts. Analyses and discussion of themes were informed by the authors’ experiences conducting the workshops, as well as by artifacts and notes produced in each session. Our analyses offer insights into the collaborative process for human-centered data specification across stakeholder domains of expertise.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Positionality</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We acknowledge that our research perspectives and approaches are shaped by our own experiences and positionality. Specifically, we are researchers living and working in the U.S., with teaching experience and experiences working with school teachers and district personnel on technology integration, researching the fairness of AI in education, and working with AI practitioners on projects related to human-centered design. In addition, we come from a mix of disciplinary backgrounds, including Computer Science, Learning Sciences and Technology, Education, and HCI, which we have drawn on to conduct prior research into sociotechnical approaches to human-centered AI design practices.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Findings</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In each workshop session, we provided a diverse group of stakeholders with a specific application of ML in the education domain. We asked them to co-design specifications for each stage of the ML data pipeline. Teams engaged in rich discussions to define dataset composition, collection and labeling procedures, and evaluation metrics. By engaging in generative design thinking, participants shared domain expertise and personal (experiential) perspectives to anticipate challenges and navigate ethical considerations for data subjects and end-users. Across all sessions, knowledge sharing and constant co-evaluation facilitated the conceptualization of a human-centered ML data pipeline from the ground up. We summarize our study findings in terms of (1) contextualizing upstream tasks with downstream use, (2) collaboration strategies across expertise boundaries, and (3) shifting roles, identities, and support needs.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Contextualizing Upstream ML Tasks within Downstream Use</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Typical ML data pipelines are linear and comprised of distinct data and modeling tasks. Our protocol based on current data documentation templates also followed a linear organization. However, participants tended to approach specifications for each component by considering its <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">interactions</span> with other stages in the data lifecycle. While current stages in the ML data pipeline are meaningful to engineering tasks, cross-discipline negotiation of concerns transcended discrete steps in the ML data pipeline. As summarized in Table  <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:downstream_context</span>, domain experts across all sessions contextualized upstream ML data tasks by considering downstream application context and hypothesized the consequences of collection and modeling decisions in downstream usage. In engaging diverse stakeholders in designing data needs in each stage of the pipeline, we find that collaborative practices can disrupt the backward-looking engineering process of retroactively improving models when performance, utility, or ethical issues surface. Here we present observations about how stakeholders <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">proactively</span> anticipate challenges, consider trade-offs, recognize data unknowns, and address bias and reliability threats.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<span id="S4.SS1.p2.1" class="ltx_ERROR undefined">\NewTblrTheme</span>
<p id="S4.SS1.p2.2" class="ltx_p">fancy
<span id="S4.SS1.p2.2.1" class="ltx_ERROR undefined">\SetTblrStyle</span>caption

<span id="S4.SS1.p2.2.2" class="ltx_ERROR undefined">{longtblr}</span><span id="S4.SS1.p2.2.3" class="ltx_text" style="font-size:70%;">[
theme = fancy,
caption=Summary of stakeholders’ downstream considerations in the education domain associated with upstream data specification tasks and challenges faced by teachers and students in our design workshops.,
label=tab:downstream_context
]
width=colspec= Q[1.2] Q[3.5,l,h] Q[3.5,l,h] Q[3,l,h] ,
row1 =  font=,
rowhead = 1,

<span id="S4.SS1.p2.2.3.1" class="ltx_text ltx_font_bold">Upstream Data Task</span> &amp;
<span id="S4.SS1.p2.2.3.2" class="ltx_text ltx_font_bold">Domain Contexts</span> 
<span id="S4.SS1.p2.2.3.3" class="ltx_text ltx_font_bold">Concerns</span> 
<span id="S4.SS1.p2.2.3.4" class="ltx_text ltx_font_bold">Unmet Support Needs
<br class="ltx_break"></span><span id="S4.SS1.p2.2.3.5" class="ltx_text ltx_font_italic">Composition</span> 
<br class="ltx_break">
<br class="ltx_break">
<span id="S4.SS1.p2.2.3.6" class="ltx_inline-block ltx_transformed_outer" style="width:6.2pt;height:88.5pt;vertical-align:-42.5pt;"><span class="ltx_transformed_inner" style="width:88.6pt;transform:translate(-41.16pt,2.04pt) rotate(-90deg) ;">
<span id="S4.SS1.p2.2.3.6.1" class="ltx_p">Identifying relevant variables</span>
</span></span> 
Training data should account for differences across <span id="S4.SS1.p2.2.3.7" class="ltx_text ltx_font_bold">diverse educational environments</span> (e.g., public and private institutions, geographic location, grade level, subject of study, and mode of instruction). Representation of subgroups is required along demographic dimensions (e.g., race, gender, socio-economic status) as well as <span id="S4.SS1.p2.2.3.8" class="ltx_text ltx_font_bold">individual learning needs</span> (e.g., language proficiencies, neurodiversity, disabilities). 
Teachers and students are unsure about the feasibility and ethics of obtaining <span id="S4.SS1.p2.2.3.9" class="ltx_text ltx_font_bold">sensitive information</span> (e.g., student perceptions on their relationships with their teachers). Both domain stakeholders express concern about the <span id="S4.SS1.p2.2.3.10" class="ltx_text ltx_font_bold">fairness and utility</span> of the model given the numerous critical <span id="S4.SS1.p2.2.3.11" class="ltx_text ltx_font_bold">factors that data cannot capture</span> about the student experience (e.g., administrative data does not indicate whether a student is experiencing homelessness or traumas outside of school). 
Non-technical stakeholders lack technical knowledge about <span id="S4.SS1.p2.2.3.12" class="ltx_text ltx_font_bold">data use across the ML pipeline</span>, including the relationship between training data, application data, and data used for validation (e.g., specifying variables for training data that may be infeasible to collect continuously in application data, hesitating to collect demographic variables under the assumption that they must be model inputs).

<br class="ltx_break">
Nuanced <span id="S4.SS1.p2.2.3.13" class="ltx_text ltx_font_bold">contextual interpretations</span> of administrative variables (e.g., separating general absences from excused absences that involve medical leave, student self-perceptions of aptitude detectable from course selection), <span id="S4.SS1.p2.2.3.14" class="ltx_text ltx_font_bold">student out-of-school factors</span> (e.g., family and community support, extracurriculars, social network), and <span id="S4.SS1.p2.2.3.15" class="ltx_text ltx_font_bold">self-reported perceptions</span> (e.g., writing confidence, classroom trust and safety, boredom) are impactful predictors. 
Teachers worry about <span id="S4.SS1.p2.2.3.16" class="ltx_text ltx_font_bold">misinterpretation of causation</span> as users attempt to make sense of model inputs and outputs and take subsequent <span id="S4.SS1.p2.2.3.17" class="ltx_text ltx_font_bold">misinformed action</span> (e.g., administration blaming student drop-out on teaching quality despite imperfect measures, students learning to insert complex vocabulary rather than improving writing holistically). 
Non-technical stakeholders struggle to conceptualize <span id="S4.SS1.p2.2.3.18" class="ltx_text ltx_font_bold">how variables influence prediction</span>. This knowledge gap is further complicated by technical handling of different types of data and modeling choices that influence <span id="S4.SS1.p2.2.3.19" class="ltx_text ltx_font_bold">explainability</span>.

<br class="ltx_break">
<br class="ltx_break">
<br class="ltx_break">
<span id="S4.SS1.p2.2.3.20" class="ltx_inline-block ltx_transformed_outer" style="width:6.2pt;height:84.3pt;vertical-align:-40.4pt;"><span class="ltx_transformed_inner" style="width:84.3pt;transform:translate(-39.05pt,2.04pt) rotate(-90deg) ;">
<span id="S4.SS1.p2.2.3.20.1" class="ltx_p">Developing labeling schema</span>
</span></span> 
Labels and attributes should align to <span id="S4.SS1.p2.2.3.21" class="ltx_text ltx_font_bold">pedagogical goals</span> (e.g., standards-aligned rubric for essay evaluation along multiple dimensions rather than holistic scoring) and signal actions toward <span id="S4.SS1.p2.2.3.22" class="ltx_text ltx_font_bold">improving teaching practices</span> (e.g., identifying lesson activities with low-engagement rather than students who seem bored, identifying specific supports required by students rather than risk of drop-out). 
Teachers raise concerns about the complexity of administrative and professional development efforts required to specify <span id="S4.SS1.p2.2.3.23" class="ltx_text ltx_font_bold">followup action</span> and <span id="S4.SS1.p2.2.3.24" class="ltx_text ltx_font_bold">accountability</span> in response to predictions. 
Stakeholders lack <span id="S4.SS1.p2.2.3.25" class="ltx_text ltx_font_bold">common ground</span>, leaving domain stakeholders to advocate for and explain pedagogical goals, instructional practices, organization of school systems, and sensitive issues in education.

<br class="ltx_break">

Teachers caution against labels that cast assumptions about students and limit <span id="S4.SS1.p2.2.3.26" class="ltx_text ltx_font_bold">student agency</span> (e.g., administrative repercussions from classifying students as ”drop-outs”, behavior management implications from predicting student emotions). Labels impact the design of the final application and how users are trained to interact with it. 

<br class="ltx_break">
Labeling schema should account for <span id="S4.SS1.p2.2.3.27" class="ltx_text ltx_font_bold">multiple standards</span> across the education system and inherent inconsistencies (e.g., teacher discretion in grading, varying academic standards, varying state requirements for graduation). 
Teachers worry about <span id="S4.SS1.p2.2.3.28" class="ltx_text ltx_font_bold">academic biases</span> in attributes associated with quality labels in strict evaluative environments (e.g., valuing Standard American English over language familiar to students in their communities) 

<br class="ltx_break">
<br class="ltx_break"><span id="S4.SS1.p2.2.3.29" class="ltx_text ltx_font_italic">Collection</span> 
<br class="ltx_break">
<br class="ltx_break">
<span id="S4.SS1.p2.2.3.30" class="ltx_inline-block ltx_transformed_outer" style="width:6.2pt;height:73.3pt;vertical-align:-34.9pt;"><span class="ltx_transformed_inner" style="width:73.2pt;transform:translate(-33.49pt,2.04pt) rotate(-90deg) ;">
<span id="S4.SS1.p2.2.3.30.1" class="ltx_p">Identifying data sources</span>
</span></span> 
School systems maintain <span id="S4.SS1.p2.2.3.31" class="ltx_text ltx_font_bold">administrative data</span> and <span id="S4.SS1.p2.2.3.32" class="ltx_text ltx_font_bold">historical records</span> consisting of basic academic and demographic variables. Teachers may also be able to assist with data collection or submit data directly. 

Domain-stakeholders struggle with unknown <span id="S4.SS1.p2.2.3.33" class="ltx_text ltx_font_bold">data ownership</span> and unknown data management (e.g., deferring to administration without nowing roles responsible for data management or available variables in administrative data, uncertainty about <span id="S4.SS1.p2.2.3.34" class="ltx_text ltx_font_bold">privacy laws</span> or what teachers can legally share).

<br class="ltx_break">
Educational systems include <span id="S4.SS1.p2.2.3.35" class="ltx_text ltx_font_bold">third-party partnerships</span> and interactions with technology, testing, and consulting companies that privately manage data (e.g., College Board, learning management systems, national board for professional teaching). 

Stakeholders lack clarity about data collection, management, and privacy <span id="S4.SS1.p2.2.3.36" class="ltx_text ltx_font_bold">terms from third-party systems</span>.

<br class="ltx_break">
<br class="ltx_break">
<span id="S4.SS1.p2.2.3.37" class="ltx_inline-block ltx_transformed_outer" style="width:6.2pt;height:92.1pt;vertical-align:-44.3pt;"><span class="ltx_transformed_inner" style="width:92.1pt;transform:translate(-42.96pt,2.04pt) rotate(-90deg) ;">
<span id="S4.SS1.p2.2.3.37.1" class="ltx_p">Defining collection procedures</span>
</span></span> 
Procedures must account for <span id="S4.SS1.p2.2.3.38" class="ltx_text ltx_font_bold">legal regulations</span> that govern data collection in protected school-aged populations (e.g., COPPA). Collection may require multiple forms of <span id="S4.SS1.p2.2.3.39" class="ltx_text ltx_font_bold">data use agreements</span> (e.g., <span id="S4.SS1.p2.2.3.40" class="ltx_text ltx_font_bold">informed consent</span> from parents and legal guardians, informed consent from data subjects, data contracts with administrative data owners and organizations). 
Opt-in consent policies may result in <span id="S4.SS1.p2.2.3.41" class="ltx_text ltx_font_bold">sampling biases</span> (e.g., overhead of parental consent may deter schools or individual students from participating, volunteered essays may skew toward positive examples). 
Teachers and students lack a frame of reference for what they can expect to in terms of <span id="S4.SS1.p2.2.3.42" class="ltx_text ltx_font_bold">rights and disclosures</span> detailed in consent forms. Without knowing the highest standards for data privacy and security practices, they cannot evaluate the language of data agreements.

<br class="ltx_break">
Consent forms should build trust with <span id="S4.SS1.p2.2.3.43" class="ltx_text ltx_font_bold">transparency</span> of purpose and assurances for data management, storage, sharing, and deletion. 
Stakeholders worry about the <span id="S4.SS1.p2.2.3.44" class="ltx_text ltx_font_bold">data privacy</span> implications of maintaining student identifiers and sensitive information.


<br class="ltx_break">
Procedures should account for contextual factors that may impact data quality such as <span id="S4.SS1.p2.2.3.45" class="ltx_text ltx_font_bold">temporal variation</span> (e.g., differing standards and experiences at the start and end of a school year, differing activities at the start and end of a class period), <span id="S4.SS1.p2.2.3.46" class="ltx_text ltx_font_bold">uncooperative data subjects</span> (e.g., unreliable or falsified student-submitted data), and <span id="S4.SS1.p2.2.3.47" class="ltx_text ltx_font_bold">invasive collection methods</span> (e.g., inauthentic writing tasks, students being aware of being filmed).



<br class="ltx_break">
<br class="ltx_break">
<br class="ltx_break">
<span id="S4.SS1.p2.2.3.48" class="ltx_inline-block ltx_transformed_outer" style="width:6.2pt;height:87.3pt;vertical-align:-41.9pt;"><span class="ltx_transformed_inner" style="width:87.3pt;transform:translate(-40.53pt,2.04pt) rotate(-90deg) ;">
<span id="S4.SS1.p2.2.3.48.1" class="ltx_p">Defining labeling procedures</span>
</span></span> 
Labeling should emphasize student agency and fairness through incorporating <span id="S4.SS1.p2.2.3.49" class="ltx_text ltx_font_bold">student perspectives</span> (e.g., allowing students to self-identify engagement). 


<br class="ltx_break">
Labelers should have <span id="S4.SS1.p2.2.3.50" class="ltx_text ltx_font_bold">domain expertise</span> (e.g., experienced teachers, mental health professionals with knowledge of the age group). The <span id="S4.SS1.p2.2.3.51" class="ltx_text ltx_font_bold">diversity</span> and representativeness of labelers should match that of the data subjects. 
Teachers and students express concern about the <span id="S4.SS1.p2.2.3.52" class="ltx_text ltx_font_bold">subjective evaluations</span> and biases that are unavoidable in the education domain (e.g., teacher biases in perceiving student behavior, inconsistent grading standards between teachers). 

<br class="ltx_break">
<br class="ltx_break"><span id="S4.SS1.p2.2.3.53" class="ltx_text ltx_font_italic">Evaluation</span> 
<br class="ltx_break">
<br class="ltx_break">
<span id="S4.SS1.p2.2.3.54" class="ltx_inline-block ltx_transformed_outer" style="width:30.0pt;height:71.1pt;vertical-align:-33.1pt;"><span class="ltx_transformed_inner" style="width:71.1pt;transform:translate(-20.55pt,18.85pt) rotate(-90deg) ;">
<span id="S4.SS1.p2.2.3.54.1" class="ltx_block ltx_parbox ltx_align_middle" style="width:71.1pt;">
<span id="S4.SS1.p2.2.3.54.1.1" class="ltx_p">Identifying cleaning</span>
<span id="S4.SS1.p2.2.3.54.1.2" class="ltx_p">and validation</span>
<span id="S4.SS1.p2.2.3.54.1.3" class="ltx_p">requirements</span>
</span>
</span></span> 
Data may be subject to <span id="S4.SS1.p2.2.3.55" class="ltx_text ltx_font_bold">missingness</span> or collection limitations, including biased samples of included schools (e.g., participation from only urban charter schools) and data fields that cannot be collected (e.g., student health details). 
Teachers worry about the <span id="S4.SS1.p2.2.3.56" class="ltx_text ltx_font_bold">transparency of flaws</span> in the dataset and implications for interpreting model outputs. They note the lack of protocols for documentation and training to name the biases in the data.</span></p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Domain Context Shapes Dataset Specifications</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">In the composition stage of the protocol, participants initially approached dataset characteristics with broadly defined education contexts. However, in all sessions, teachers and students played a critical role in refining initial specifications in ways that captured the nuances of realistic downstream needs. The first section of Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:downstream_context</span> summarizes how teachers’ and students’ downstream domain considerations influences their contributions to identifying relevant variables and developing labeling schema. For example, student perspectives provide insights that help to contextualize and re-interpret academic and administrative data. Though models in education commonly predict student outcomes based on an evaluation of academic achievement, student S6 explained that a feeling of academic success and well-being depends on a meaningful combination of variables:</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<blockquote id="S4.SS1.SSS1.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS1.SSS1.p2.1.1" class="ltx_p"><span id="S4.SS1.SSS1.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">S6 (Student Drop-out Risk Prediction): “I think it’s not just what their grades are. If somebody is failing out of like AP classes versus like acing like non-AP classes, I feel like, you know, the combination of those things says different stories.” (1)</span></p>
</blockquote>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<p id="S4.SS1.SSS1.p3.1" class="ltx_p">Teachers similarly identified domain-relevant data features. While normative data practices associate diversity and demographics with a limited set of attributes, teachers highlighted the richness of what diversity means in education. For example, teachers noted the effect <span id="S4.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_bold">environmental context</span> such as educational institution type, teacher experience level, urbanicity, teaching quality and subject matter, and community socioeconomic status may have on predicted outcomes. For instance, when specifying student attentional data, teacher T2 explained:</p>
</div>
<div id="S4.SS1.SSS1.p4" class="ltx_para">
<blockquote id="S4.SS1.SSS1.p4.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS1.SSS1.p4.1.1" class="ltx_p"><span id="S4.SS1.SSS1.p4.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T2 (Student Engagement Image Classification): “Diversity can mean so many different things beyond just physical attributes. It’s like diversity of environment, what they’re working on, because focusing on math might look different than focusing on reading or art…or if they’re working with other people…because those are things that could play into a student’s engagement level.” (2)</span></p>
</blockquote>
</div>
<div id="S4.SS1.SSS1.p5" class="ltx_para">
<p id="S4.SS1.SSS1.p5.1" class="ltx_p">Further, when defining subgroup representation, teachers advocated for <span id="S4.SS1.SSS1.p5.1.1" class="ltx_text ltx_font_bold">student-specific context</span> variables known to significantly differentiate learning experiences and outcomes including student age, language learner status, and first-generation or immigrant status. One contextual variable commonly raised by teachers involves the presence of learning differences or disabilities that would require an individualized education program (IEP). Teacher T1 described:</p>
</div>
<div id="S4.SS1.SSS1.p6" class="ltx_para">
<blockquote id="S4.SS1.SSS1.p6.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS1.SSS1.p6.1.1" class="ltx_p"><span id="S4.SS1.SSS1.p6.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T1 (Student Engagement Image Classification): “The other thing is maybe having data knowing whether a student has an IEP…if a student is diagnosed with ADHD they are not going to be as focused as the student without. There are also emotional learning disabilities…students who are having particular traumas at home, and these are actually pretty relevant in terms of motivation and engagement.” (3)</span></p>
</blockquote>
</div>
<div id="S4.SS1.SSS1.p7" class="ltx_para">
<p id="S4.SS1.SSS1.p7.1" class="ltx_p">Across sessions, the range of encoded information contextualizing diversity stands in contrast to common engineering interpretations of representation standards. By sharing rich anecdotal insights and examples, teachers introduced contextual factors that prompted the group to rethink the <span id="S4.SS1.SSS1.p7.1.1" class="ltx_text ltx_font_bold">scope and generalizability</span> of dataset composition. Consequently, participants considered tradeoffs between the size of the dataset (i.e., large-scale collection of contextual variables representing diverse learners and environments ) and the scope of the application scenario. Participants expressed concerns about both the amount of data required to ensure equitable distribution of subgroups represented in the dataset and the prediction accuracy for underrepresented subgroups. Subsequently, participants considered whether the model should be designed to apply only to a specific age group, learner status, or type of school. In these discussions, engineers contextualized downstream modeling options and machine learning processes to support data composition and target application decisions. For example, engineer E6 explained the practice of comparing multiple models, in response to a disagreement between non-technical stakeholders regarding semantic differences in public and private school data:</p>
</div>
<div id="S4.SS1.SSS1.p8" class="ltx_para">
<blockquote id="S4.SS1.SSS1.p8.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS1.SSS1.p8.1.1" class="ltx_p"><span id="S4.SS1.SSS1.p8.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E6 (Student Drop-out Risk Prediction): “In machine learning, it’s pretty common to have multiple models and it’s called ensembling where you just put them all together. You then choose the best results…but then you have different understandings of the same data, and that can be pretty useful, especially if we want to compare…” (4)</span></p>
</blockquote>
</div>
<div id="S4.SS1.SSS1.p9" class="ltx_para">
<p id="S4.SS1.SSS1.p9.1" class="ltx_p">In most sessions, engineers shared expertise highlighting the affordances of machine learning, downstream opportunities to test multiple design choices, and trade-offs in the accuracy and interpretability of technical methods. These technical contributions situate the design of dataset composition in downstream processing and modeling applications, adding methodological context to the real-world factors shared by domain practitioners.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Context Enables Identifying Bias and Reliability Threats in Data Collection</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Based on contextual knowledge introduced by teachers, all teams identified threats to data quality in the design of data collection and labeling specifications. The second section of Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:downstream_context</span> summarizes how participants’ domain contexts informed their concerns and considerations when identifying data sources, defining collection procedures, and defining labeling procedures. For example, when designing <span id="S4.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_bold">data collection procedures</span>, stakeholders leaned on student perspectives as data subjects to anticipate concerns with false, malformed, and missing data. Students shared their personal experiences with survey fatigue, inadequate incentive structures, and creating fake signals. In helping the group to maximize response rates for collecting student resumes, student S4 explained their reactions to various collection strategies:</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<blockquote id="S4.SS1.SSS2.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS1.SSS2.p2.1.1" class="ltx_p"><span id="S4.SS1.SSS2.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">S4 (Resume-based Career Recommendation): “As a student I’m probably not going to bother sending off my resume for no compensation, but compensate me and I might try and game it. However, if you do ask me for the resume with compensation and a survey, I feel like answering the survey questions is maybe going to invest me more than if I was just firing off PDFs.” (5)</span></p>
</blockquote>
</div>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<p id="S4.SS1.SSS2.p3.1" class="ltx_p">Student S2 cautioned that observable signals from students may not align with their needs or experiences. They explained: <span id="S4.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_italic">“Students always have a way of masking. Even like on Zoom it could look like I’m looking at the screen but I’d be on my phone.”</span> In several sessions, stakeholders grappled with the possible impacts of uncooperative data subjects and adjusted collection procedures to prevent unwanted outcomes. Their hypothesized solutions include information campaigns to improve data subject buy-in, designing non-invasive collection methods to avoid disrupting authentic student behaviors, and enforcing the completion of data fields in the survey instrument to avoid downstream handling of missing data.</p>
</div>
<div id="S4.SS1.SSS2.p4" class="ltx_para">
<p id="S4.SS1.SSS2.p4.1" class="ltx_p">Further, data quality threats motivated stakeholders to design <span id="S4.SS1.SSS2.p4.1.1" class="ltx_text ltx_font_bold">data cleaning procedures</span> that detect and remove malformed or false data and standardize data fields. Regarding variability in the interpretation of grade labels in collected district writing samples, engineer E10 (Automated Essay Grading) explained: <span id="S4.SS1.SSS2.p4.1.2" class="ltx_text ltx_font_italic">“Some of the schools are strict on grading, and some of them are not, so maybe we also need to align those…maybe we need to do the data engineering to make all of these standardized.”</span> In another session, a student experience with variable grading encouraged the group to consider labeling schema derived from state standards. Student S8 explained: <span id="S4.SS1.SSS2.p4.1.3" class="ltx_text ltx_font_italic">“To me, teachers are not always consistent with grading. They all have different perspectives on what A and B are.”</span> Data representativeness and appropriate distributions of diverse subgroups emerged as a recurrent theme regarding data quality in the evaluation stage. Participants designed processes to pursue this standard by returning to the design of collection procedures and augmenting data from underrepresented groups via additional collection processes, extrapolation, or borrowing data from other contexts.</p>
</div>
<div id="S4.SS1.SSS2.p5" class="ltx_para">
<p id="S4.SS1.SSS2.p5.1" class="ltx_p">Third, teams brainstormed ways to account for errors in data collection during specification of <span id="S4.SS1.SSS2.p5.1.1" class="ltx_text ltx_font_bold">data labeling procedures.</span> Participants committed to hiring multiple labelers and calculating agreement scores, auditing labels in second-hand datasets, and specifying requirements for the qualifications and diversity of labelers as a precaution for obtaining reliable labels. While labeling procedures are discussed in the collection stage of the workshop protocol, participants often discussed data quality standards and data evaluation concepts to anchor their design decisions. Considering the authenticity of labelers, and drawing upon their previous experience as a special-education teacher, designer D2 suggested engaging data subjects in self-identifying labels:</p>
</div>
<div id="S4.SS1.SSS2.p6" class="ltx_para">
<blockquote id="S4.SS1.SSS2.p6.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS1.SSS2.p6.1.1" class="ltx_p"><span id="S4.SS1.SSS2.p6.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">D2 (Student Engagement Image Classification): “I think it would be really important actually to have students self identify. The people who are interpreting that facial expression are going to have a different interpretation than the person that made it. But like having the comparison between the students’ self reflection and the teachers’ perception and measuring that gap in between.” (6)</span></p>
</blockquote>
</div>
<div id="S4.SS1.SSS2.p7" class="ltx_para">
<p id="S4.SS1.SSS2.p7.1" class="ltx_p">For sessions in which groups decided to re-purpose an existing dataset rather than collecting raw data, participants expressed skepticism over potentially biased labels and concern for the downstream effects of mislabeled examples.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Validating Specifications by Mapping to Context</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">Building on the newly acquired contextual knowledge, all teams referenced context as a way of assessing evolving specifications and collection procedures. The third section of Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:downstream_context</span> summarizes how domain context shaped participants’ considerations when identifying data cleaning and validation requirements. Few groups noted the importance of transparency of data processes to mitigate applied bias in downstream use cases. As an example, in the automatic essay grading scenario, one of the groups considered reusing second-hand data from a standardized testing service, while observing that work samples from students <span id="S4.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_italic">financially able</span> to access the service were over-represented. Specifying the communication of the biases that cannot be mitigated, teacher T8 described:</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<blockquote id="S4.SS1.SSS3.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS1.SSS3.p2.1.1" class="ltx_p"><span id="S4.SS1.SSS3.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T8 (Automated Essay Grading): “I think also just naming the biases that you cannot reduce, or that you cannot address, so if you’re using a certain set of criteria that’s constructed by the AP, the emphasis on language conventions is…biased towards standardized academic English. Okay, if we can’t eliminate this bias, we can at least name it in our process.” (7)</span></p>
</blockquote>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p id="S4.SS1.SSS3.p3.1" class="ltx_p">Further, rather than leaning on technical language and conventional engineering metrics for model performance in the evaluation stage of the protocol, domain experts encouraged groups to prioritize the evaluation of the application as a whole. Across all sessions, groups acknowledged the tradition of standardized quantitative metrics and their inability to capture the real-world effects of a machine learning application. Adding to the conversation about testing procedures validating the accuracy of the model, teacher T9 (Automated Essay Grading) advocated for the most relevant domain-specific performance metric in education: <span id="S4.SS1.SSS3.p3.1.1" class="ltx_text ltx_font_italic">“The quality should be measured by the learning outcomes of the students…like how they’re responding to the feedback that they get from the tool. I know that’s really hard.”</span> The challenge of designing evaluation specifications prompted stakeholders to revisit decisions in earlier stages of the data pipeline. This often involved returning to design decisions in the data composition stage and selecting different labels that would better support end-user goals. Despite recognizing the incompleteness of existing metrics, participants faced difficulties creating new ones that better serve contextual needs.</p>
</div>
<div id="S4.SS1.SSS3.p4" class="ltx_para">
<p id="S4.SS1.SSS3.p4.1" class="ltx_p">To summarize the section, by moving freely along the data pipeline, participants situated data needs and machine learning processes in domain-aware contexts. They anticipated end-user experiences and proactively mitigated threats to data quality. The separation of concerns between data, modeling, and application work represents an engineering-centric framework. We find that multi-stakeholder groups engage in decision-making holistically, contextualizing data specification with use case elicitation and trade-offs in every stage of application development.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Collaboration Strategies Across Expertise Boundaries</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">While role-based knowledge boundaries have traditionally limited opportunities for collaboration between machine learning engineers and domain experts, we observed multi-stakeholder groups engaged in boundary-spanning collaborative practices. Participants employed expertise-specific strategies to overcome knowledge gaps and build cross-discipline understanding. Through practices of translation and advocacy, groups amplified diverse perspectives, built common ground, and navigated ambiguity.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Translation</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Non-technical stakeholders often perceive barriers to participation in technical decision-making due to knowledge gaps in machine learning capabilities and processes. Acknowledging the lack of familiarity with ML in the education domain, teacher T9 explained:</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<blockquote id="S4.SS2.SSS1.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS1.p2.1.1" class="ltx_p"><span id="S4.SS2.SSS1.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T9 (Automated Essay Grading): “If you were to go into a classroom, I think the majority of high school teachers in the United States…if you say machine learning and natural language processing and algorithms, they have no idea what you’re talking about. That’s not because they’re stupid, it’s just because it’s a very niche topic that you don’t really hear much about when you’re in the classroom. There needs to be some sort of middle ground…some kind of translation to lay folks that don’t live in this world of zero and ones.” (8)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p">While jointly negotiating data needs, engineers across all sessions facilitated collaboration through translation. Concretely, technical experts went beyond merely re-framing practitioner priorities into machine learning terms in data specifications. Engineers in the most successful co-design sessions actively shared technical knowledge to establish common ground and scaffold practical understanding for domain expert participation. One mode of translating contextual data needs into technical specifications involves <span id="S4.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">evaluating the feasibility</span> of teacher requests. In the data composition stage, when teacher T5 advocated for augmenting standardized exam scores with local classroom performance metrics, engineer E5 considered the feature in terms of its technical representation:</p>
</div>
<div id="S4.SS2.SSS1.p4" class="ltx_para">
<blockquote id="S4.SS2.SSS1.p4.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS1.p4.1.1" class="ltx_p"><span id="S4.SS2.SSS1.p4.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T5 (Student Drop-out Risk Prediction): “Would it be much harder to add in that layer? It’s just whether they have passed a class with a certain letter, in this case it’s a C or higher.”
<br class="ltx_break">E5 (Student Drop-out Risk Prediction): “I wouldn’t say it’s a hard feature to add, it sounds like a binary feature. It’s a yes or no, right? You add a column, and the value is yes or no. Yeah, I think that’s feasible.” (9)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS1.p5" class="ltx_para">
<p id="S4.SS2.SSS1.p5.1" class="ltx_p">Engineers across all sessions applied their technical knowledge to support feature requests from teachers whenever feasible. Translation occurred in the encoding of teacher-raised relevant data fields, as well as the planning of technical processes in the data collection and evaluation stages to accommodate use case concerns. Engineers engaged in translation by <span id="S4.SS2.SSS1.p5.1.1" class="ltx_text ltx_font_bold">clarifying machine learning processes</span> to support broader practitioner concerns and values. For example, given the publicity surrounding privacy violations and biases along demographic dimensions in machine learning, nontechnical stakeholders displayed a sensitivity to collecting race, age, and gender variables. Addressing confusion and unease about the collection and use of demographic data, engineer E2 explained:</p>
</div>
<div id="S4.SS2.SSS1.p6" class="ltx_para">
<blockquote id="S4.SS2.SSS1.p6.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS1.p6.1.1" class="ltx_p"><span id="S4.SS2.SSS1.p6.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E2 (Student Engagement Image Classification): “You can decide to use [demographic variables] to understand your data, and then you already know the data is potentially biased. So when you build your model, you keep that in mind, and you refine your model to cope with that bias.” (10)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS1.p7" class="ltx_para">
<p id="S4.SS2.SSS1.p7.1" class="ltx_p">By translating domain priorities into evaluative specifications, the engineer reached across knowledge boundaries and deepened a collective understanding of the use of demographic data in machine learning processes. As a practice, translating allowed engineers to use their technical expertise to amplify the voices of practitioners, enabling non-technical stakeholders to contribute to the construction of human-centered data needs. Using the shared scenario context, engineers <span id="S4.SS2.SSS1.p7.1.1" class="ltx_text ltx_font_bold">explained trade-offs</span> in data and modeling choices, building the technical foundation to support domain expert participation. While considering the representation of diverse school settings in the data composition stage, engineer E6 described their considerations in specifying the scope of a model:</p>
</div>
<div id="S4.SS2.SSS1.p8" class="ltx_para">
<blockquote id="S4.SS2.SSS1.p8.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS1.p8.1.1" class="ltx_p"><span id="S4.SS2.SSS1.p8.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E6 (Student Drop-out Risk Prediction): “If you train this model for just this one school, then you would be looking at all of the previous data that you have from that school…with the downside being that you might not have enough data for the model to learn from, or it might draw the wrong conclusions. One of the benefits of training a model on all the schools in the district is that you have a lot more data points. But the downside of that is like maybe you’re at a really poor school, and all the other schools in your district are really rich, so the drop-out patterns might be different.”
<br class="ltx_break">T6 (Student Drop-out Risk Prediction): “They both seem to have downsides, but maybe per-district is better, because if it’s generalized for everyone, then the inaccuracy is higher, but there’s a lot more data, so it’s better to be more accurate.” (11)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS1.p9" class="ltx_para">
<p id="S4.SS2.SSS1.p9.1" class="ltx_p">By leaning on the design scenario, the engineer contextualized the effects of technical decisions in domain-relevant terms, enabling the teacher to engage in the evaluation of the trade-off. While technical terms such as “accuracy” and “generalization” had been used previously in the workshop, they had not been taken up by the teacher. By translating the contextual costs and benefits of modeling choices, the engineer empowered the teacher to then take up technical language and contribute to decision-making.</p>
</div>
<div id="S4.SS2.SSS1.p10" class="ltx_para">
<p id="S4.SS2.SSS1.p10.1" class="ltx_p">In many sessions, the technical stakeholders took additional care to educate non-technical stakeholders regarding technical details through extended dialogue, actively scaffolding their uptake of technical language in the design process. In a few sessions, engineers employed metaphors and likened ML to familiar analog processes, tailoring technical knowledge in their explanations to serve as a broker between domains. Translation was practiced predominantly by technical experts. Due to the social nature of the education domain, technical experts may more easily make assumptions about educational contexts without requiring translation from domain experts, while the infusion of technology in education is a recent and disruptive change foreign to many domain practitioners.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Advocacy</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The high-stakes nature of the educational field necessitates developing machine
learning applications prioritizing practitioner experiences. In the collaborative context, domain experts engaged in advocacy, leaning into <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">extended discourse and emotion-driven language</span>, urging out-of-domain stakeholders to confront the complexities of education systems and hidden implications of data decisions. As student S4 described, <span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">“you have to try and be an advocate, and if you’re going to deploy a system like this you’re going to have to come up against people who do advocate for other interests.”</span> Indeed, teachers and students across sessions characterized their collaborative participation as advocacy. They advocated for fairness and utility priorities motivated by their domain contexts and lived experiences while negotiating cross-cutting requirements.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">By surfacing critical downstream implications of data labels, feature encoding, and modeling choices, teachers and students voiced values and sensitivities central to the education space. Student S5 advocated for data subjects by explaining that privacy violations and data misuse put students at risk of negatively impacting future educational opportunities.</p>
</div>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<blockquote id="S4.SS2.SSS2.p3.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS2.p3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.p3.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">S5 (Student Drop-Out Risk Prediction): “I would be concerned about teachers or administrators or a committee…overseeing the results…the degree of embarrassment if I did show up as someone likely to drop out…that would imply that you know you’re not performing well and something’s wrong.” (12)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS2.p4" class="ltx_para">
<p id="S4.SS2.SSS2.p4.1" class="ltx_p">Teacher T6 similarly expressed concern about downstream harms for students due to the severity of language characterizing labels (e.g., ”dropped out” and ”did not drop out”) in the student drop-out prediction scenario. They warned: <span id="S4.SS2.SSS2.p4.1.1" class="ltx_text ltx_font_italic">“Then these students will be labeled like dropouts, and then it gives administrators a reason to push students like this out of school.”</span> Teacher T6 instead advocated for student-centric labels and reframed the application scenario to predict whether a student was <span id="S4.SS2.SSS2.p4.1.2" class="ltx_text ltx_font_italic">“on track to graduate”</span>. The complex structure of educational systems produces role-based differences in interests, priorities, and interpretations of model results. While school and district administrators value drop-out metrics, teachers prefer a reversed framing featuring student progress towards positive goals, aware of the real-world implications for how students flagged by the system may be treated. By explaining their experience-motivated understanding of mentalities and practices in the downstream application context, teachers in several sessions advocated for data specifications that avoid the perpetuation of system inequalities.</p>
</div>
<div id="S4.SS2.SSS2.p5" class="ltx_para">
<p id="S4.SS2.SSS2.p5.1" class="ltx_p">In many cases, groups ultimately adopted the teacher-recommended labels, indicating an openness to identify with practitioner values of supporting student autonomy and avoiding punitive administrative repercussions. However, teachers occasionally received extensive push-back from technical stakeholders. Such back-and-forth patterns between teachers and machine learning engineers are illustrated in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.2.3. Ambiguity ‣ 4.2. Collaboration Strategies Across Expertise Boundaries ‣ 4. Findings ‣ Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In these cases, teachers persisted in their advocacy until groups understood the intent and gravitas behind their concerns. In one session working with the engagement classification scenario, the teacher and engineer engaged in an extended heated exchange regarding the ethics of classifying students with emotion-based labels. Teacher T3 explained the racialized underpinnings of assuming the emotional states of students in classroom practice:</p>
</div>
<div id="S4.SS2.SSS2.p6" class="ltx_para">
<blockquote id="S4.SS2.SSS2.p6.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS2.p6.1.1" class="ltx_p"><span id="S4.SS2.SSS2.p6.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T3 (Student Engagement Image Classification): “I would personally feel like that’s something I can decide based on myself and my rapport with the students. If a student was frustrated or confused, to use those labels, I would be concerned about stereotyping. It’s a really big problem in education, how black students versus white students, how their behaviors read to a lot of white teachers as different, even though it can just be their specific cultural background.” (13)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS2.p7" class="ltx_para">
<p id="S4.SS2.SSS2.p7.1" class="ltx_p">While advocating against using labels that make assumptions about the emotional states of students, teacher T3 alludes to two other sensitive themes in the education domain: the historical context of racially biased perceptions of student behavior, as well as ML’s infringement on the teacher’s role of human judgment in the classroom. The exchange emphasized the weight of these critical tensions in education and the prominence of racial and cultural considerations in the domain. A similarly heated discussion in another session involved the collection of teaching quality evaluation data for predicting student drop-out risk. Teacher T5 argued that the use of teacher evaluation data by administrators would impact teacher unions and staffing policies, further complicating an existing district struggle with protections for teachers. By contextualizing the social and political constructs connected to technically objective variables, teacher advocacy enabled groups to collectively situate data decisions in a complex ecosystem and approach designs with respect and sensitivity toward the worldviews encapsulated.</p>
</div>
<div id="S4.SS2.SSS2.p8" class="ltx_para">
<p id="S4.SS2.SSS2.p8.1" class="ltx_p">Across many sessions, advocacy operated through the sharing of personal lived experiences. While designing dataset composition in the automated essay grading scenario, teacher T9 argued against relying on quantified rule-based grammatical features to evaluate student writing:</p>
</div>
<div id="S4.SS2.SSS2.p9" class="ltx_para">
<blockquote id="S4.SS2.SSS2.p9.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS2.p9.1.1" class="ltx_p"><span id="S4.SS2.SSS2.p9.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T9 (Automated Essay Grading): “When I taught English on the west side of Chicago, ninety-nine percent of my students were African American. I understood what they were saying, but it was not written sort of like traditional academic American English. You don’t want to penalize the student for the culture that they live in, and the language that they speak.” (14)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS2.p10" class="ltx_para">
<p id="S4.SS2.SSS2.p10.1" class="ltx_p">Teacher T9 reflected on their personal struggle to both respect individual student backgrounds and prepare students for future strict evaluative environments, and admitted that they still feel uncertain about the balance. The problem-solving nature of the co-design sessions invited sensitive practitioner stories involving difficulties faced in the classroom. Despite the relative vulnerability required of teachers and students compared to other roles, they met the task and eagerly advocated for the complex realities in the domain.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>Ambiguity</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">During time-limited co-design sessions, participants navigated the balance between big-picture discussions and specifying design details. Engaging in high-level discussions required stakeholders to develop a sense of <span id="S4.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_bold">comfort with ambiguity</span>, accepting data unknowns and unfinished design decisions. Though participants expressed uneasiness about ambiguity in the design task, engineer E5 noted how the process stands in contrast to designing with a false sense of certainty:</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<blockquote id="S4.SS2.SSS3.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS2.SSS3.p2.1.1" class="ltx_p"><span id="S4.SS2.SSS3.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E5 (Student Drop-out Risk Prediction): “When we’re talking about designing a system everybody wants to pretend they know more than they think. When we talk about making a decision everybody feels like they already know the answer, like they should know the answer. In this kind of setup…I feel that it’s okay for me to not know the answer…and I rely on other roles.” (15)</span></p>
</blockquote>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p id="S4.SS2.SSS3.p3.1" class="ltx_p">The presence of diverse stakeholders facilitates a collective acceptance of ambiguity while choosing proactive big-picture data planning. Engineers in other sessions echoed their ultimate appreciation of the open-ended nature of design decisions, given the relative infrequency of higher-level conversations in typical machine learning practice.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2311.05792/assets/quotes_viz.png" id="S4.F2.g1" class="ltx_graphics ltx_img_square" width="598" height="524" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Visualization of role-based contributions in workshop discussions across stages of data specification. Each horizontal line represents one sentence of speech. Selected quotes are marked by number.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Shifting Roles, Identities, and Support Needs</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Our study surfaces role-based collaborative dynamics and persistent knowledge gaps and boundaries that <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">complicate</span> contribution in multi-stakeholder settings. Although participants engaged productively in the co-design process, we observed groups making assumptions, building on misconceptions, and getting stumped by shared unknowns. Stakeholders struggled with role-based identities and contributions. We identify challenges and support needs for engaging diverse stakeholders in collaborative data specification and summarize these in the final column of Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:downstream_context</span>.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>Rigid responsibility boundaries</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">While co-design sessions encouraged many boundary-spanning practices between engineers and domain experts, some role-based boundaries persisted and hindered collaboration. Several engineers maintained a bounded view of responsibilities and liability in data decisions. Especially for evaluations of ethical decisions, fairness for demographic subgroups, and consent practices, engineers were quick to <span id="S4.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_bold">delegate to specialized entities</span>. Regarding the representation of subgroups in the composition stage of the protocol, engineer E1 explained:</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<blockquote id="S4.SS3.SSS1.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS3.SSS1.p2.1.1" class="ltx_p"><span id="S4.SS3.SSS1.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E1 (Student Engagement Image Classification): “This is usually something that you shouldn’t be asking just anybody. I’d leave this question up to the ethics review panel professionals.” (16)</span></p>
</blockquote>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p">In an industry made efficient through role-based specialization, engineering <span id="S4.SS3.SSS1.p3.1.1" class="ltx_text ltx_font_bold">responsibilities may be narrowly defined</span>. Ethical standards are often handled by designated professionals in teams separate from engineering processes. Beyond preferring a separation of concerns, engineers indicated being accustomed to a standard industry practice removed from dataset design choices. In the automated essay grading scenario, engineer E10 explained their unease in the data collection stage of the protocol, while deciding between several ideas for labeling schemes:</p>
</div>
<div id="S4.SS3.SSS1.p4" class="ltx_para">
<blockquote id="S4.SS3.SSS1.p4.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS3.SSS1.p4.1.1" class="ltx_p"><span id="S4.SS3.SSS1.p4.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E10 (Automated Essay Grading): “We don’t usually have that many options. You don’t have a choice, we really work with what we have. I don’t design how people give their data.” (17)</span></p>
</blockquote>
</div>
<div id="S4.SS3.SSS1.p5" class="ltx_para">
<p id="S4.SS3.SSS1.p5.1" class="ltx_p">While engineers engaged in knowledge-sharing and translating practices, some did so to varying degrees of effectiveness. Despite an engineering effort to break down technical barriers, some teachers continued to feel intimidated by technology blindness. Others further struggled to contribute when additionally perceiving a misalignment between the student age group they had experience teaching and the target student age group for the machine learning application. Teacher T4 explained:</p>
</div>
<div id="S4.SS3.SSS1.p6" class="ltx_para">
<blockquote id="S4.SS3.SSS1.p6.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS3.SSS1.p6.1.1" class="ltx_p"><span id="S4.SS3.SSS1.p6.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T4 (Resume-base Career Recommendation): “I didn’t think I had as much to add from an education perspective because my background is with a lot younger students.” (18)</span></p>
</blockquote>
</div>
<div id="S4.SS3.SSS1.p7" class="ltx_para">
<p id="S4.SS3.SSS1.p7.1" class="ltx_p">Despite differences in the age group or subject matter in which teachers are more experienced, teachers nonetheless contribute domain expertise. By underselling their understanding of the context from working in the education system as an educator more generally, some teachers viewed their own stakeholder role as a direct end-user rather than co-designer. In several sessions, teachers fell more silent to self-imposed boundaries and misconceptions of qualifications for participation.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Persistent knowledge gaps</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Groups face knowledge gaps regarding the identification of data owners. Despite the collection of educational data from academic records, classroom observations, and student work, teachers were unsure of data ownership regulations. Referring to collecting student essay data, teacher T8 explained:</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<blockquote id="S4.SS3.SSS2.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS3.SSS2.p2.1.1" class="ltx_p"><span id="S4.SS3.SSS2.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">T8 (Automated Essay Grading): “They probably live in the teachers’ district or school Google Drive, or whatever they’re using…and so I’m not really sure who owns the rights to those.” (19)</span></p>
</blockquote>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p id="S4.SS3.SSS2.p3.1" class="ltx_p">Data ownership is further complicated by the storage of data through ed-tech systems with opaque data privacy terms negotiated with school administration. Even for data assumed to be maintained directly by school administration, teachers could not identify ownership and access processes. With regard to obtaining student academic records, multiple teachers expressed the need for school administrators to be present. Circumstances in education systems introduce variance in roles and responsibilities across districts, complicating the task of bringing stakeholder voices to the table. For domain experts, this knowledge gap may point to an unknown stakeholder and data owner in school administration who should be engaged in designing data specifications.
Engineers similarly make assumptions about data availability. Regarding a variety of student academic and financial records, engineer E6 assumed:</p>
</div>
<div id="S4.SS3.SSS2.p4" class="ltx_para">
<blockquote id="S4.SS3.SSS2.p4.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS3.SSS2.p4.1.1" class="ltx_p"><span id="S4.SS3.SSS2.p4.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E6 (Student Drop-out Risk Prediction): “A lot of this data can be directly collected through the College Application, right? Sounds like a safe bet to say the university has all of them, I mean they keep a record of everything. It’s probably already marked in their system.” (20)</span></p>
</blockquote>
</div>
<div id="S4.SS3.SSS2.p5" class="ltx_para">
<p id="S4.SS3.SSS2.p5.1" class="ltx_p">For engineers, these assumptions may be reflective of their training, in which datasets are given rather than constructed. Despite unknowns regarding data use agreements, shape and composition of data, and the right data owner to contact, engineers maintained confidence that data exists.</p>
</div>
<div id="S4.SS3.SSS2.p6" class="ltx_para">
<p id="S4.SS3.SSS2.p6.1" class="ltx_p">Despite involving stakeholders advocating for the legality of data privacy issues, knowledge gaps persist in data security and access. Engineer E1 used an assumption of security to justify haphazard consent practices:</p>
</div>
<div id="S4.SS3.SSS2.p7" class="ltx_para">
<blockquote id="S4.SS3.SSS2.p7.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS3.SSS2.p7.1.1" class="ltx_p"><span id="S4.SS3.SSS2.p7.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">E1: “For educational applications where there’s going to be very little chance of any kind of deleterious impact or data leak, … you can ask the children to check a box saying my parents approve.” (21)</span></p>
</blockquote>
</div>
<div id="S4.SS3.SSS2.p8" class="ltx_para">
<p id="S4.SS3.SSS2.p8.1" class="ltx_p">Both technical and non-technical participants expressed relaxed attitudes toward data security, citing a lack of incentive for malicious data breaches. Teacher T2 explained, <span id="S4.SS3.SSS2.p8.1.1" class="ltx_text ltx_font_italic">“I don’t see why anybody would even want to hack into something that the schools were using.”</span></p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3. </span>Shifting stakeholder identities</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">While the teacher, engineer, and legal professional held clear participatory roles with established expectations for contribution, the collaborative identities of the student and UX professional roles were less defined. The distinct participation patterns across participants is illustrated in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.2.3. Ambiguity ‣ 4.2. Collaboration Strategies Across Expertise Boundaries ‣ 4. Findings ‣ Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, indicating the consistent interactions between teachers and engineers in contrast to the variance in the contributions of students and UX professionals. Student S4 explained, <span id="S4.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_italic">“consistently occupying the student perspective…is difficult because the students are not going to be involved in every stage.”</span> In several sessions, students expressed discomfort being the youngest in a group of professionals and lacking a defined structure of contribution. As a result, they often removed themselves from their primary role of end-user and contributed to the collective task in a general co-designer capacity. Students eagerly participated in technical co-design, offering data collection and modeling ideas unrelated to the student perspective. For example, while the group discussed potential features to include in the dataset composition stage of the protocol for the student drop-out prediction scenario, student S5 explained their ideas for unconventional survey methods:</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<blockquote id="S4.SS3.SSS3.p2.1" class="ltx_quote ltx_displayquote">
<p id="S4.SS3.SSS3.p2.1.1" class="ltx_p"><span id="S4.SS3.SSS3.p2.1.1.1" class="ltx_text ltx_inline-quote ltx_font_italic">S5 (Student Drop-out Risk Prediction): “it might be interesting to have students survey each other almost, and…this feels kind of creepy, but assigning one person in each of your classes and then say ‘does this person seem okay or do they seem like they’re gonna fail out of school’, I think that that could be interesting.”
<br class="ltx_break">E5 (Student Drop-out Risk Prediction): “I could see the potential bullying material for that.” (22)</span></p>
</blockquote>
</div>
<div id="S4.SS3.SSS3.p3" class="ltx_para">
<p id="S4.SS3.SSS3.p3.1" class="ltx_p">In an effort to contribute to the design task, the student had <span id="S4.SS3.SSS3.p3.1.1" class="ltx_text ltx_font_bold">lost empathy with data subjects</span>, requiring the engineer to point out the potential downstream harms. Several students in the student drop-out prediction scenario additionally advocated for collecting mental health and other sensitive information from students. Across all sessions, students often referred to data subjects as “they” and separate from themselves.</p>
</div>
<div id="S4.SS3.SSS3.p4" class="ltx_para">
<p id="S4.SS3.SSS3.p4.1" class="ltx_p">We find that, across all sessions, stakeholders lean on prior roles and experiences, often demonstrating multiple competencies, and shifting between these identities throughout the collaborative co-design process. Several legal professionals additionally had technical experience such that they could contribute ML best practices and participate in translation practices. Several designers and engineers had prior experience in various positions in the education sector such that they could contribute ideas motivated by domain expertise to contextualize data. Every stakeholder either remembers the experience of having been a student or is closely connected with a student through their social relationships, such that they could speak on behalf of student interests. Meanwhile, students struggled to always contribute through the role of a data subject and end-user. They instead often opted to participate through the role of a co-designer of data specifications.</p>
</div>
<div id="S4.SS3.SSS3.p5" class="ltx_para">
<p id="S4.SS3.SSS3.p5.1" class="ltx_p">UX professionals similarly lacked definition in their participatory roles. In the debriefing of the workshop, engineer E7 reflected, <span id="S4.SS3.SSS3.p5.1.1" class="ltx_text ltx_font_italic">“this problem didn’t have too much to do with the UX perspective, so the collaborators have unequal representation in the discussion.”</span> By organizing co-design workshops that engage diverse stakeholders, the setting of the research study performed some of the traditional roles of designers, confusing the group’s understanding of their expected contribution. Across sessions, several designers additionally maintained a role-based separation of concerns, limiting their contribution to technical topics. Removed from technical contribution and lacking the personal domain experiences of teachers and students, designers often faded into the background.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our findings demonstrate the vital role that multi-stakeholder collaborations play in the design of dataset specifications. Through conducting workshops anchored in the co-design of ML datasets in the high-stakes field of education, we highlight practitioner efforts to contextualize domain and procedural knowledge, establish common ground, and mitigate downstream harms. Participants engaged in a generative process of negotiating data requirements and quality in each stage of the data pipeline, placing due emphasis on the proactive design of human-centered systems. We emphasize the value of engaging domain experts and discuss the challenges facing the scalable implementation of the collaborative processes explored in this study. We characterize our contributions in terms of implications for the work of data specification and support needs for future integration of multi-stakeholder collaborative processes in responsible data use in education.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Is a Seat at the Table Enough?</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Critical scholarship has explored the tension between developing machine learning systems for scalable production and involving end users in the design of these systems <cite class="ltx_cite ltx_citemacro_citep">(Sloane et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2020</a>)</cite>. By establishing a structured co-design environment in which diverse stakeholders were given a seat at the table, many of our participants engaged in organic negotiations to overcome knowledge boundaries to establish common ground through collaborative strategies. We found that participants both made significant contributions to the specification of data requirements and faced challenges in the co-design process. In this section, we discuss the affordances and limitations of stakeholder involvement in our workshop sessions through two participation frameworks and the application context of the education domain.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Delgado et al. describe an analytical framework for the dimensions of participation, designed for practitioners to assess the extent to which a process for participation meaningfully empowers diverse stakeholders in the design of ML applications <cite class="ltx_cite ltx_citemacro_citep">(Delgado et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>. Consultation, involvement, collaboration, and empowerment are scaled degrees of participation, assessed at five decision points addressing the motivation, stakes, attendance, form, and power distribution in participation processes. Sloane et al. caution against “participation washing,” in which the narrative of participation obscures power dynamics and the extractive nature of collaboration <cite class="ltx_cite ltx_citemacro_citep">(Sloane et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2020</a>)</cite>. By critically framing participatory design practices as work, consultation, and justice forms, practitioners may assess the authenticity of collaborative processes. Here we reflect on the nature of participation in our co-design sessions.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>Affordances of co-design</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">Our findings effectively demonstrate the crucial role of collaboration in data specifications, contributing to prior literature by identifying and confirming a critical site of participation in the development of ML applications. Across multiple decision points in Delgado et al.’s framework <cite class="ltx_cite ltx_citemacro_citep">(Delgado et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, the participatory structure of our workshops improves upon current practices, which limit teachers to lower degrees of participation, such as engaging in design feedback to improve the user experience of AI systems <cite class="ltx_cite ltx_citemacro_citep">(Holstein et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2019b</a>; Roll and Wylie, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite>. In contrast, the co-design of data specification is a participatory structure with stakes that empower stakeholders to contribute to the scope and purpose of ML applications. Data is the backbone of ML models and specifying data requirements is a systematic way to influence system behavior and hold AI accountable to stakeholders. By engaging stakeholders in this high-leverage high-impact stage of the ML pipeline, the design of data attributes and evaluation of data quality can systematically amplify the impact of stakeholder voices.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para">
<p id="S5.SS1.SSS1.p2.1" class="ltx_p">Teachers shared domain expertise impacting critical features in dataset design and model performance. Out-of-domain experts commonly expressed surprise while recognizing their own knowledge gaps and disrupted assumptions regarding contextual variables relevant to the education domain. When reflecting on their collaborative experiences, engineers across all sessions discussed the narrow technical focus of traditional ML development processes, admitting frequent misplaced efforts and overlooked practitioner priorities. In most sessions, engineers expressed appreciation for the value of collaboration in the early stages of projects and eagerness to incorporate the process into practice. Teachers similarly expressed enthusiasm about contributing to data work. Stakeholders agreed unanimously across sessions that early stakeholder participation in designing data specifications uncovers domain-relevant priorities and potential downstream harms.</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para">
<p id="S5.SS1.SSS1.p3.1" class="ltx_p">Groups additionally realized the value of “big picture” conversations to anticipate future harms by incorporating a contextual understanding of how data choices affect end-users and their environments. Rather than converging on design decisions, groups engaged in a process of ideation and filtration that often resulted in the recognition of multiple possibilities for further exploration. In line with collaborative approaches emphasizing the importance of friction and disagreement <cite class="ltx_cite ltx_citemacro_citep">(Keshavarz and Maze, <a href="#bib.bib40" title="" class="ltx_ref">2013</a>)</cite>, diverging perspectives encouraged participants to develop an appreciation for ambiguity. The construction of a jointly negotiated framing, in a participatory process in which diverse stakeholder expertise is valued equally, promotes a plurality of designs in the resulting specifications. In the process, participants admit unknowns and rely on the collective knowledge of those at the table.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>Unequal burdens</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">To engage in effective co-design, participants traversed expertise boundaries by practicing collaborative strategies unique to their roles. We observed domain experts striving to establish common ground by sharing vulnerable personal experiences and advocating for practitioner needs in a complicated historical and socio-cultural context. Out-of-domain stakeholders frequently and confidently made assumptions about the education system. Teachers and students are left with the emotional burden of advocating for their classroom experiences and navigating technology-centric pushback. In contrast, a heavy communicative burden is placed on the role of technical experts as boundary spanners.
This finding extends the existing understanding of ML team collaboration where technical members lack domain contexts, in which parties assume a diverse but equal contribution <cite class="ltx_cite ltx_citemacro_citep">(Piorkowski et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2021</a>; Muller et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2019</a>; Park et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>)</cite>.
Because domain practitioners in education feel significant barriers to contributing to the design of highly technical applications, engineers must support the central role of translation in collaborative practice. In the most positive collaborative sessions, engineers exhibited a willingness to teach foundational concepts and processes, patiently explaining technical tradeoffs. By translating domain-specific requirements to data and modeling requirements, engineers were able to address the needs advocated by non-technical domain experts. However, despite the productive ends of these collaborative strategies, they place extensive capacity demands in unique ways on both technical and non-technical participants. Without structured support, multi-stakeholder collaboration is a high-lift endeavor. Across our sessions, groups recurrently fell back on engineer-led linear decision-making when any stakeholder lacked the skill, knowledge, or energy capacity to meet these collaborative requirements.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p">In Sloane et al.’s framing of the forms of participation, the co-design workshops in this study align most closely with “participation as consultation,” in which diverse stakeholders are engaged in various stages of episodic, short-term projects. Consultative forms of participation often take a one-size-fits-all approach, creating a single process and expecting the same form of contribution from all stakeholders. However, diverse stakeholders contribute differently and require different support. Collaborative processes can better engage stakeholder perspectives by designing participation to be context and stakeholder-specific, revisiting processes to ensure the appropriate information is given to and gathered from the appropriate stakeholders.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3. </span>Unfilled seats</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">Our co-design workshops represent a lower degree of participation along the dimension of stakeholder selection, as the included community members were chosen by the research team. According to Delgado et al.’s framework, a participation process that truly empowers stakeholders involves engaging community members designated by the community itself. While valuable and necessary, this standard is difficult to achieve in the education context.</p>
</div>
<div id="S5.SS1.SSS3.p2" class="ltx_para">
<p id="S5.SS1.SSS3.p2.1" class="ltx_p">The education domain involves complex dynamic systems affected by the attributes of institutions, practitioners, communities, and policy. While teachers contributed eagerly to the co-design of data specifications, participants across sessions grappled with the unknown perspectives of diverse domain-relevant stakeholders not represented in our workshops. Beyond students and teachers, groups named parents, district administrators, school counselors, instructional coaches, support staff and district personnel, community organizations, and policymakers as significant stakeholders in the design scenarios presented. Participants consistently demonstrated knowledge gaps regarding organizational structures in schools and school systems, struggling to identify data owners and match position titles to role-based responsibilities. While participants often referenced “administration” as an agentic entity and critical stakeholder, the specific practitioner role to call upon remains undefined. Further, teachers shared experiences in which they were required to perform the responsibilities of administration and support staff when those roles were unavailable. The complexity of education systems is exacerbated by constant organizational change, situational differences across individual institutions, and overlapping roles due to personnel turnover and resource strain. In the education domain, the non-trivial task of identifying the full set of appropriate stakeholders to bring to the table is a necessary precondition to multi-stakeholder collaboration.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Supporting Collaborative Data Specification</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Prior work assessing engineering processes has noted the lack of defined practices for engaging domain experts and diverse stakeholders, as well as the implications for the fairness and utility of the resulting systems <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2021a</a>)</cite>. In response, we formulated our workshop protocol as a preliminary approach to multi-stakeholder co-design of data specifications. Our findings demonstrate that, in order for collaborative data specification to realize its potential of systematically supporting and amplifying diverse stakeholder voices, structural supports are required. We further contribute to the participatory design literature by identifying process needs that facilitate participation by establishing common ground and continuous collaboration practices.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Information Scaffolds</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Prior to the co-design workshops, participants were only informed about the research motivations. The design scenario and background about data use in ML development were presented during the session. As a result, participation in our workshops took the form of facilitated group discussions initiated by researchers. While this research design enabled us to observe practitioners navigating knowledge gaps, the introduction of initial groundwork may enable a higher degree of participation. Intentionally designed information scaffolds can establish common ground, overcome technical knowledge gaps, and accelerate proactive contributions across participants.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">While the lack of appropriate materials for educating domain experts on foundational ML knowledge is known <cite class="ltx_cite ltx_citemacro_citep">(Bogina et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>, materials for educating ML practitioners on domain context are equally scarce. Despite a common assumption in collaborative ML work that non-technical experts require scaffolding of technical information, the same assumptions, and requirements and rarely ascribed to technical experts. Pre-reading regarding the social and political context of the design scenario may seed a foundational understanding of domain needs, practices, and motivations. Further, participants reported feeling unsure about the quality of their contributions and uncertain about the expectations of their role. Establishing common ground and defining stakeholder roles prior to engaging in co-design may better prepare participants for richer collaborative discussions.</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para">
<p id="S5.SS2.SSS1.p3.1" class="ltx_p">Information scaffolds may additionally define the collaborative context more effectively. Participants struggled with decision-making due to a lack of clarity regarding the constraints of the design scenario. While the open-ended scenario invited high-level negotiations of priorities and requirements, groups reflected on the potential value of bounding ideation with real-world conditions, factoring financial, labor, and time resources into the initial formulation of the task. Finally, the inclusion of initial groundwork may enhance the generative design process, giving participants time to ideate independently before joint discussion and decision-making.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Shared standards</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">Across sessions, groups struggled the most with designing specifications for the evaluation of data quality. Participants found this task challenging due to the lack of shared language and metrics for data and system evaluation across disciplines. Non-technical stakeholders were unfamiliar with standard machine learning metrics, such as accuracy, prediction, and recall, and lacked context regarding their applied meanings for the given design scenario. Correspondingly, technical stakeholders were unable to translate practitioner calls for evaluations based on student learning outcomes into actionable data specifications. Despite recognizing the incompleteness of any existing metric, participants faced difficulties creating new ones that better serve contextual needs. We echo the call from prior work that fairness in ML requires the development of domain-specific metrics of quality <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3. </span>Continuous iteration</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">Applying Delgado et al.’s framework, participation in our workshops is a one-time collaboration needed to better align ML applications with stakeholder needs. While this motivation is representative of a high degree of collaborative participation, the design falls short of empowering stakeholders due to a lack of accountability processes. Without accountability for the quality of implementation of stakeholder contributions, participation in workshops can become performative, failing to actualize the recommendations of diverse stakeholders. According to Sloan et al.’s framework, the most meaningful form of stakeholder involvement (i.e., “participation as justice”) requires long-term partnerships with diverse stakeholders, building trust through mutual benefit, reciprocity, equity, and tightly coupled relationships with frequent communication. To establish processes for cross-domain collaboration, prior work has highlighted the importance of design iteration with constant evaluation <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2021a</a>)</cite>.</p>
</div>
<div id="S5.SS2.SSS3.p2" class="ltx_para">
<p id="S5.SS2.SSS3.p2.1" class="ltx_p">Indeed, participants in every workshop session echoed this collaborative requirement, calling for stakeholder involvement at each step in the execution of the data specification. While domain practitioners appreciated the proactive data planning exercise, they expressed concerns about implementation fidelity and the potential for harmful assumptions to re-enter the development process in their absence. Involving multi-stakeholders in continuous collaboration requires the construction of a framework that defines and scaffolds participant roles in iterative data specification in downstream stages of the ML pipeline. Some groups suggested the collaborative creation of a governing set of utility and ethical standards to be used in interval quality evaluations as new data decisions and trade-offs emerge. Support for sustained participation may also involve the development of software platforms to engage stakeholders in the downstream processes of data cleaning and model evaluation. Industry applications of ML development may benefit from the creation of new roles, hiring teachers and boundary-spanners in permanent or semi-permanent positions. The emerging field of education data science may train individuals with expertise at the intersection of technology and education, who are able to translate across domains. Future work should explore these and other processes necessary to sustain iterative and long-term end-user and domain expert participation in data and machine learning development, in each stage of the data lifecycle and beyond.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Limitations</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We present our data specification workshop procedure as a proof of concept with the acknowledgment that our sessions are subject to several limitations. A 2-hour workshop represents an oversimplified data specification process in which time constraints affect the nature of participation. The narrative surrounding the involvement of diverse stakeholders focuses on the prevention of harm by engaging domain context and impacted communities (e.g., <cite class="ltx_cite ltx_citemacro_citep">(Boyarskaya et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite>). Such framing of priority, combined with time constraints and latent structural inequality between stakeholder roles, limit the contribution of teachers to advocacy around well-recognized challenges in the education domain. When knowledge gaps are large enough, collaborative time is dedicated to establishing baseline domain understanding, leaving the full potential of stakeholder contribution unexplored. We chose to conduct design workshops despite literature acknowledging their limitations in participatory design <cite class="ltx_cite ltx_citemacro_citep">(Rosner et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2016</a>; Harrington et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> because they allow us to imagine the research methods that may be adapted to authentic contexts. The demonstration presented here cannot assess the efficiency, feasibility, or affordability of collaborative data specification procedures. However, we identify their promise in addressing downstream issues of model-centric development and invite future work to explore the integration of this practice in industry settings.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Furthermore, our sampling methods may have introduced selection bias, favoring stakeholders who felt fewer barriers to participation and displayed an eagerness to seek collaborative work. Our participants additionally comprised an incomplete representation of stakeholders’ communities. Due to convenience and ethical regulations regarding participation in research, the student role was represented by undergraduate students, rather than younger students more accurately impacted by the largely K-12 design scenarios. We recruited ML engineers from a variety of research and industry backgrounds, and teachers specializing in various age groups and subject disciplines, and we do not account for the role of this heterogeneity in the participatory results.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">Finally, the four design scenarios produced heterogeneity across sessions and introduced different challenges and design discussions due to the nature of the datasets involved (e.g., tabular, text, and image data). Some scenarios were more emotionally charged, while others were more challenging technically to stakeholders. For example, the undertone of surveillance in scenarios involving student images prompted richer discourse about racial biases, representation, and fairness than in scenarios involving text data. While tabular data was easier to conceptualize, stakeholders were less familiar with image and text processing for data cleaning procedures, and these sessions relied heavily on technical experts to explain processing.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The emerging fairness, accountability, transparency, and utility concerns surrounding the development of ML applications in education are rooted in the limitations of conventional ML engineering processes. Developing ethical and human-centered ML experiences for education scenarios requires the prioritization of high-quality data contextualized through early collaboration with teachers and students. By engaging diverse stakeholders in a series of co-design sessions, we observed meaningful contributions to dataset specification. Participants shared domain and technical expertise to contextualize data needs, advocate for stakeholder values, anticipate downstream implications, overcome knowledge boundaries, and establish common ground. However, despite the many affordances of our collaborative process, a seat at the table is not enough. Empowering stakeholder perspectives in ML dataset specification requires systematic support, including accountable processes for the continuous involvement of teachers and students in iteration and co-evaluation, shared contextual data quality standards, and information scaffolds for both technical and non-technical stakeholders to traverse expertise boundaries.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We are grateful to the reviewers and our study participants for their time and helpful feedback. This work was funded through a grant from the McCoy Family Center for Ethics in Society at Stanford University. Dakuo Wang was supported by IBM Research as a visiting researcher at Stanford’s Human-Centered AI Institute.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akkiraju et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Rama Akkiraju, Vibha
Sinha, Anbang Xu, Jalal Mahmud,
Pritam Gundecha, Zhe Liu,
Xiaotong Liu, and John Schumacher.
2020.

</span>
<span class="ltx_bibblock">Characterizing machine learning processes: A
maturity framework. In <em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">International Conference on
Business Process Management</em>. Springer, 17–31.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amershi et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Saleema Amershi, Andrew
Begel, Christian Bird, Robert DeLine,
Harald Gall, Ece Kamar,
Nachiappan Nagappan, Besmira Nushi, and
Thomas Zimmermann. 2019.

</span>
<span class="ltx_bibblock">Software engineering for machine learning: A case
study. In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">2019 IEEE/ACM 41st International
Conference on Software Engineering: Software Engineering in Practice
(ICSE-SEIP)</em>. IEEE, 291–300.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arnold et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Matthew Arnold, Rachel KE
Bellamy, Michael Hind, Stephanie Houde,
Sameep Mehta, Aleksandra Mojsilović,
Ravi Nair, K Natesan Ramamurthy,
Alexandra Olteanu, David Piorkowski,
et al<span id="bib.bib4.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">FactSheets: Increasing trust in AI services through
supplier’s declarations of conformity.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.4.1" class="ltx_emph ltx_font_italic">IBM Journal of Research and Development</em>
63, 4/5 (2019),
6–1.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ashmore et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Rob Ashmore, Radu
Calinescu, and Colin Paterson.
2021.

</span>
<span class="ltx_bibblock">Assuring the machine learning lifecycle:
Desiderata, methods, and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>
54, 5 (2021),
1–39.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baker and Hawn (2022a)</span>
<span class="ltx_bibblock">
Ryan S Baker and Aaron
Hawn. 2022a.

</span>
<span class="ltx_bibblock">Algorithmic bias in education.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 32, 4
(2022), 1052–1092.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baker and Hawn (2022b)</span>
<span class="ltx_bibblock">
Ryan S. Baker and Aaron
Hawn. 2022b.

</span>
<span class="ltx_bibblock">Algorithmic Bias in Education.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 32, 4
(Dec. 2022), 1052–1092.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/s40593-021-00285-9" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s40593-021-00285-9</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender and Friedman (2018)</span>
<span class="ltx_bibblock">
Emily M Bender and Batya
Friedman. 2018.

</span>
<span class="ltx_bibblock">Data statements for natural language processing:
Toward mitigating system bias and enabling better science.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for
Computational Linguistics</em> 6 (2018),
587–604.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Birhane et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Abeba Birhane, Pratyusha
Kalluri, Dallas Card, William Agnew,
Ravit Dotan, and Michelle Bao.
2021.

</span>
<span class="ltx_bibblock">The values encoded in machine learning research.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.15590</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Birks et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2008)</span>
<span class="ltx_bibblock">
Melanie Birks, Ysanne
Chapman, and Karen Francis.
2008.

</span>
<span class="ltx_bibblock">Memoing in qualitative research: Probing data and
processes.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Journal of research in nursing</em>
13, 1 (2008),
68–75.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bogina et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Veronika Bogina, Alan
Hartman, Tsvi Kuflik, and Avital
Shulner-Tal. 2022.

</span>
<span class="ltx_bibblock">Educating software and AI stakeholders about
algorithmic fairness, accountability, transparency and ethics.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 32, 3
(2022), 808–833.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boyarskaya et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Margarita Boyarskaya,
Alexandra Olteanu, and Kate Crawford.
2020.

</span>
<span class="ltx_bibblock">Overcoming failures of imagination in AI infused
system development and deployment.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.13416</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boyd (2021)</span>
<span class="ltx_bibblock">
Karen L Boyd.
2021.

</span>
<span class="ltx_bibblock">Datasheets for Datasets help ML Engineers Notice
and Understand Ethical Issues in Training Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 5, CSCW2
(2021), 1–27.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buddemeyer et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Amanda Buddemeyer, Erin
Walker, and Malihe Alikhani.
2021.

</span>
<span class="ltx_bibblock">Words of Wisdom: Representational Harms in Learning
From AI Communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.08581</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Challa et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Harshitha Challa, Nan
Niu, and Reese Johnson.
2020.

</span>
<span class="ltx_bibblock">Faulty requirements made valuable: On the role of
data quality in deep learning. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">2020 IEEE
Seventh International Workshop on Artificial Intelligence for Requirements
Engineering (AIRE)</em>. IEEE, 61–69.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chmielinski et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Kasia S Chmielinski, Sarah
Newman, Matt Taylor, Josh Joseph,
Kemi Thomas, Jessica Yurkofsky, and
Yue Chelsea Qiu. 2022.

</span>
<span class="ltx_bibblock">The dataset nutrition label (2nd Gen): Leveraging
context to mitigate harms in artificial intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.03954</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Delgado et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Fernando Delgado, Stephen
Yang, Michael Madaio, and Qian Yang.
2021.

</span>
<span class="ltx_bibblock">Stakeholder Participation in AI: Beyond” Add
Diverse Stakeholders and Stir”.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.01122</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Denzin et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Norman K Denzin, Yvonna S
Lincoln, Michael D Giardina, and
Gaile S Cannella. 2023.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">The Sage handbook of qualitative
research</em>.

</span>
<span class="ltx_bibblock">Sage publications.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Díaz et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mark Díaz, Ian
Kivlichan, Rachel Rosen, Dylan Baker,
Razvan Amironesei, Vinodkumar
Prabhakaran, and Emily Denton.
2022.

</span>
<span class="ltx_bibblock">Crowdworksheets: Accounting for individual and
collective identities underlying crowdsourced dataset annotation. In
<em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on Fairness, Accountability,
and Transparency</em>. 2342–2351.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DiSalvo et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Carl DiSalvo, Andrew
Clement, and Volkmar Pipek.
2012.

</span>
<span class="ltx_bibblock">Participatory design for, with, and by
communities.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">International handbook of participatory
design</em> (2012), 182–209.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">D’Amour et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Alexander D’Amour,
Katherine Heller, Dan Moldovan,
Ben Adlam, Babak Alipanahi,
Alex Beutel, Christina Chen,
Jonathan Deaton, Jacob Eisenstein,
Matthew D Hoffman, et al<span id="bib.bib21.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">Underspecification presents challenges for
credibility in modern machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.4.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Estivill-Castro et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Vladimir Estivill-Castro,
Eugene Gilmore, and René Hexel.
2022.

</span>
<span class="ltx_bibblock">Constructing Explainable Classifiers from the
Start—Enabling Human-in-the Loop Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Information</em> 13,
10 (2022), 464.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feathers (2022b)</span>
<span class="ltx_bibblock">
Todd Feathers. Jan 11,
2022b.

</span>
<span class="ltx_bibblock">This Private Equity Firm Is Amassing Companies That
Collect Data on America’s Children.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">The Markup</em> (Jan 11, 2022).

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">https://themarkup.org/machine-learning/2022/01/11/this-private-equity-firm-is-amassing-companies-that-collect-data-on-americas-children.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feathers (2022a)</span>
<span class="ltx_bibblock">
Todd Feathers. Jan 13,
2022a.

</span>
<span class="ltx_bibblock">College Prep Software Naviance Is Selling
Advertising Access to Millions of Students.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">The Markup</em> (Jan 13, 2022).

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">https://themarkup.org/machine-learning/2022/01/13/college-prep-software-naviance-is-selling-advertising-access-to-millions-of-students.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gardner et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Josh Gardner, Christopher
Brooks, and Ryan Baker.
2019.

</span>
<span class="ltx_bibblock">Evaluating the fairness of predictive student
models through slicing analysis. In <em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 9th international conference on learning analytics &amp; knowledge</em>.
225–234.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Timnit Gebru, Jamie
Morgenstern, Briana Vecchione,
Jennifer Wortman Vaughan, Hanna Wallach,
Hal Daumé Iii, and Kate Crawford.
2021.

</span>
<span class="ltx_bibblock">Datasheets for datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 64,
12 (2021), 86–92.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GmbH (2023)</span>
<span class="ltx_bibblock">
ATLAS.ti Scientific Software Development
GmbH. 2023.

</span>
<span class="ltx_bibblock">ATLAS.ti: The Qualitative Data Analysis &amp; Research
Software.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://atlasti.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://atlasti.com/</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google (2019)</span>
<span class="ltx_bibblock">
Google. 2019.

</span>
<span class="ltx_bibblock">People + AI Guidebook.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://pair.withgoogle.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://pair.withgoogle.com/</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo (2013)</span>
<span class="ltx_bibblock">
Philip Guo.
2013.

</span>
<span class="ltx_bibblock">Data science workflow: Overview and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> (2013).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harrington et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Christina Harrington,
Sheena Erete, and Anne Marie Piper.
2019.

</span>
<span class="ltx_bibblock">Deconstructing community-based collaborative
design: Towards more equitable participatory design engagements.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 3, CSCW
(2019), 1–25.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heger et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Amy K Heger, Liz B
Marquis, Mihaela Vorvoreanu, Hanna
Wallach, and Jennifer Wortman Vaughan.
2022.

</span>
<span class="ltx_bibblock">Understanding Machine Learning Practitioners’ Data
Documentation Perceptions, Needs, Challenges, and Desiderata.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 6, CSCW2
(2022), 1–29.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holmes et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Wayne Holmes, Kaska
Porayska-Pomsta, Ken Holstein, Emma
Sutherland, Toby Baker, Simon Buckingham
Shum, Olga C Santos, Mercedes T Rodrigo,
Mutlu Cukurova, Ig Ibert Bittencourt,
et al<span id="bib.bib32.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Ethics of AI in education: Towards a community-wide
framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.4.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 32, 3
(2022), 504–526.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holstein et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Kenneth Holstein, Bruce M
McLaren, and Vincent Aleven.
2019a.

</span>
<span class="ltx_bibblock">Co-designing a real-time classroom orchestration
tool to support teacher–AI complementarity.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Journal of Learning Analytics</em>
6, 2 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holstein et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Kenneth Holstein, Bruce M
McLaren, and Vincent Aleven.
2019b.

</span>
<span class="ltx_bibblock">Designing for complementarity: Teacher and student
needs for orchestration support in AI-enhanced classrooms. In
<em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">International conference on artificial intelligence
in education</em>. Springer, 157–171.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holstein et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2019c)</span>
<span class="ltx_bibblock">
Kenneth Holstein, Jennifer
Wortman Vaughan, Hal Daumé III, Miro
Dudik, and Hanna Wallach.
2019c.

</span>
<span class="ltx_bibblock">Improving fairness in machine learning systems:
What do industry practitioners need?. In
<em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI conference on human
factors in computing systems</em>. 1–16.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou and Wang (2017)</span>
<span class="ltx_bibblock">
Youyang Hou and Dakuo
Wang. 2017.

</span>
<span class="ltx_bibblock">Hacking with NPOs: collaborative analytics and
broker roles in civic data hackathons.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 1, CSCW
(2017), 1–16.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hullman et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jessica Hullman, Sayash
Kapoor, Priyanka Nanayakkara, Andrew
Gelman, and Arvind Narayanan.
2022.

</span>
<span class="ltx_bibblock">The worst of both worlds: A comparative analysis of
errors in learning from data in psychology and machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.06498</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hutchinson et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ben Hutchinson, Andrew
Smart, Alex Hanna, Emily Denton,
Christina Greer, Oddur Kjartansson,
Parker Barnes, and Margaret Mitchell.
2021.

</span>
<span class="ltx_bibblock">Towards Accountability for Machine Learning
Datasets: Practices from Software Engineering and Infrastructure. In
<em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 ACM Conference on Fairness,
Accountability, and Transparency</em> (Virtual Event, Canada)
<em id="bib.bib38.4.2" class="ltx_emph ltx_font_italic">(FAccT ’21)</em>. Association for
Computing Machinery, New York, NY, USA,
560–575.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3442188.3445918" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3442188.3445918</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kerner (2020)</span>
<span class="ltx_bibblock">
Hannah Kerner.
2020.

</span>
<span class="ltx_bibblock">Too many AI researchers think real-world problems
are not relevant.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Opinion. MIT Technology Review</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Keshavarz and Maze (2013)</span>
<span class="ltx_bibblock">
Mahmoud Keshavarz and
Ramia Maze. 2013.

</span>
<span class="ltx_bibblock">Design and dissensus: framing and staging
participation in design research.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Design Philosophy Papers</em>
11, 1 (2013),
7–29.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kizilcec and Lee (2022)</span>
<span class="ltx_bibblock">
René F. Kizilcec and
Hansol Lee. 2022.

</span>
<span class="ltx_bibblock">Algorithmic Fairness in Education.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">The Ethics of Artificial Intelligence in
Education</em>, W. Holmes &amp; K.
Porayska-Pomsta (Ed.). Routledge, Chapter 7.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koesten et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Laura Koesten, Kathleen
Gregory, Paul Groth, and Elena
Simperl. 2021.

</span>
<span class="ltx_bibblock">Talking datasets–understanding data sensemaking
behaviours.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">International journal of human-computer
studies</em> 146 (2021),
102562.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koopmans (2020)</span>
<span class="ltx_bibblock">
Matthijs Koopmans.
2020.

</span>
<span class="ltx_bibblock">Education is a complex dynamical system: Challenges
for research.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">The Journal of Experimental Education</em>
88, 3 (2020),
358–374.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kross and Guo (2021)</span>
<span class="ltx_bibblock">
Sean Kross and Philip
Guo. 2021.

</span>
<span class="ltx_bibblock">Orienting, framing, bridging, magic, and
counseling: How data scientists navigate the outer loop of client
collaborations in industry and academia.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 5, CSCW2
(2021), 1–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Latonero et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
M Latonero, M Kleinman,
and K Hiatt. 2017.

</span>
<span class="ltx_bibblock">Tech Folk:‘Move Fast and Break Things’
Doesn’t Work When Lives Are at Stake.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">The Guardian, February</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leslie et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
David Leslie, Michael
Katell, Mhairi Aitken, Jatinder Singh,
Morgan Briggs, Rosamund Powell,
Cami Rincón, Antonella Perini,
Smera Jayadeva, and Christopher Burr.
2022.

</span>
<span class="ltx_bibblock">Data Justice in Practice: A Guide for Developers.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.01037</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Warren Li, Kaiwen Sun,
Florian Schaub, and Christopher
Brooks. 2022.

</span>
<span class="ltx_bibblock">Disparities in students’ propensity to consent to
learning analytics.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 32, 3
(2022), 564–608.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Weixin Liang, Girmaw Abebe
Tadesse, Daniel Ho, L Fei-Fei,
Matei Zaharia, Ce Zhang, and
James Zou. 2022.

</span>
<span class="ltx_bibblock">Advances, challenges and opportunities in creating
data for trustworthy AI.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>
4, 8 (2022),
669–677.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mao et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Yaoli Mao, Dakuo Wang,
Michael Muller, Kush R Varshney,
Ioana Baldini, Casey Dugan, and
Aleksandra Mojsilović.
2019.

</span>
<span class="ltx_bibblock">How data scientistswork together with domain
experts in scientific collaborations: To find the right answer or to ask the
right question?

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 3, GROUP
(2019), 1–23.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marras et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mirko Marras, Ludovico
Boratto, Guilherme Ramos, and Gianni
Fenu. 2022.

</span>
<span class="ltx_bibblock">Equality of learning opportunity via individual
fairness in personalized recommendations.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 32, 3
(2022), 636–684.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Michos et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Konstantinos Michos,
Charles Lang, Davinia Hernández-Leo,
and Detra Price-Dennis. 2020.

</span>
<span class="ltx_bibblock">Involving teachers in learning analytics design:
Lessons learned from two case studies. In
<em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Tenth international conference
on learning analytics &amp; knowledge</em>. 94–99.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muller et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Michael Muller, Ingrid
Lange, Dakuo Wang, David Piorkowski,
Jason Tsay, Q Vera Liao,
Casey Dugan, and Thomas Erickson.
2019.

</span>
<span class="ltx_bibblock">How data science workers work with data: Discovery,
capture, curation, design, creation. In
<em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI conference on human
factors in computing systems</em>. 1–15.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muller and Strohmayer (2022)</span>
<span class="ltx_bibblock">
Michael Muller and
Angelika Strohmayer. 2022.

</span>
<span class="ltx_bibblock">Forgetting Practices in the Data Sciences. In
<em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">CHI Conference on Human Factors in Computing
Systems</em>. 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Munappy et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Aiswarya Raj Munappy, Jan
Bosch, and Helena Homström Olsson.
2020.

</span>
<span class="ltx_bibblock">Data pipeline management in practice: Challenges
and opportunities. In <em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">International Conference on
Product-Focused Software Process Improvement</em>. Springer,
168–184.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nagle et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Tadhg Nagle, Thomas C
Redman, and David Sammon.
2017.

</span>
<span class="ltx_bibblock">Only 3% of companies’ data meets basic quality
standards.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Harvard Business Review</em>
95, 5 (2017),
2–5.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niemi et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hannele Niemi, Roy D Pea,
and Yu Lu. 2023.

</span>
<span class="ltx_bibblock">AI in Learning: Designing the Future.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ocumpaugh et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Jaclyn Ocumpaugh, Ryan
Baker, Sujith Gowda, Neil Heffernan,
and Cristina Heffernan. 2014.

</span>
<span class="ltx_bibblock">Population validity for educational data mining
models: A case study in affect detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">British Journal of Educational Technology</em>
45 (05 2014).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1111/bjet.12156" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1111/bjet.12156</a>

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Soya Park, April Yi Wang,
Ban Kawas, Q Vera Liao,
David Piorkowski, and Marina
Danilevsky. 2021.

</span>
<span class="ltx_bibblock">Facilitating knowledge sharing from domain experts
to data scientists for building nlp models. In
<em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">26th International Conference on Intelligent User
Interfaces</em>. 585–596.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Passi and Jackson (2018)</span>
<span class="ltx_bibblock">
Samir Passi and Steven J
Jackson. 2018.

</span>
<span class="ltx_bibblock">Trust in data science: Collaboration, translation,
and accountability in corporate data science projects.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 2, CSCW
(2018), 1–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Passi and Sengers (2020)</span>
<span class="ltx_bibblock">
Samir Passi and Phoebe
Sengers. 2020.

</span>
<span class="ltx_bibblock">Making data science systems work.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Big Data &amp; Society</em> 7,
2 (2020),
2053951720939605.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paullada et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Amandalynne Paullada,
Inioluwa Deborah Raji, Emily M Bender,
Emily Denton, and Alex Hanna.
2021.

</span>
<span class="ltx_bibblock">Data and its (dis) contents: A survey of dataset
development and use in machine learning research.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">Patterns</em> 2,
11 (2021), 100336.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedro et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Francesc Pedro, Miguel
Subosa, Axel Rivas, and Paula
Valverde. 2019.

</span>
<span class="ltx_bibblock">Artificial intelligence in education: Challenges
and opportunities for sustainable development.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perrotta and Selwyn (2020)</span>
<span class="ltx_bibblock">
Carlo Perrotta and Neil
Selwyn. 2020.

</span>
<span class="ltx_bibblock">Deep learning goes to school: Toward a relational
understanding of AI in education.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Learning, Media and Technology</em>
45, 3 (2020),
251–269.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Piet (2019)</span>
<span class="ltx_bibblock">
Nadia Piet.
2019.

</span>
<span class="ltx_bibblock">AI Meets Design.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://aimeets.design/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://aimeets.design/</a>

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Piorkowski et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
David Piorkowski, Soya
Park, April Yi Wang, Dakuo Wang,
Michael Muller, and Felix Portnoy.
2021.

</span>
<span class="ltx_bibblock">How ai developers overcome communication challenges
in a multidisciplinary team: A case study.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 5, CSCW1
(2021), 1–25.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Polyzotis et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Neoklis Polyzotis, Sudip
Roy, Steven Euijong Whang, and Martin
Zinkevich. 2017.

</span>
<span class="ltx_bibblock">Data management challenges in production machine
learning. In <em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM
International Conference on Management of Data</em>.
1723–1726.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Polyzotis et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Neoklis Polyzotis, Sudip
Roy, Steven Euijong Whang, and Martin
Zinkevich. 2018.

</span>
<span class="ltx_bibblock">Data lifecycle challenges in production machine
learning: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">ACM SIGMOD Record</em> 47,
2 (2018), 17–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Potgieter (2020)</span>
<span class="ltx_bibblock">
Isak Potgieter.
2020.

</span>
<span class="ltx_bibblock">Privacy concerns in educational data mining and
learning analytics.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">The International Review of Information
Ethics</em> 28 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pushkarna et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mahima Pushkarna, Andrew
Zaldivar, and Oddur Kjartansson.
2022.

</span>
<span class="ltx_bibblock">Data Cards: Purposeful and Transparent Dataset
Documentation for Responsible AI.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.01075</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rakova et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Bogdana Rakova, Jingying
Yang, Henriette Cramer, and Rumman
Chowdhury. 2021.

</span>
<span class="ltx_bibblock">Where responsible AI meets reality: Practitioner
perspectives on enablers for shifting organizational practices.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 5, CSCW1
(2021), 1–23.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reich and Ito (2017)</span>
<span class="ltx_bibblock">
Justin Reich and Mizuko
Ito. 2017.

</span>
<span class="ltx_bibblock">From good intentions to real outcomes: Equity by
design in learning technologies.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Digital Media and Learning Research Hub</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Richards et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
John T Richards, David
Piorkowski, Michael Hind, Stephanie
Houde, Aleksandra Mojsilovic, and
Kush R Varshney. 2021.

</span>
<span class="ltx_bibblock">A Human-Centered Methodology for Creating AI
FactSheets.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">IEEE Data Eng. Bull.</em> 44,
4 (2021), 47–58.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Richardson et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Rashida Richardson,
Jason M Schultz, and Kate Crawford.
2019.

</span>
<span class="ltx_bibblock">Dirty data, bad predictions: How civil rights
violations impact police data, predictive policing systems, and justice.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">NYUL Rev. Online</em> 94
(2019), 15.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roll and Wylie (2016)</span>
<span class="ltx_bibblock">
Ido Roll and Ruth
Wylie. 2016.

</span>
<span class="ltx_bibblock">Evolution and revolution in artificial intelligence
in education.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 26, 2
(2016), 582–599.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rosner et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Daniela K Rosner, Saba
Kawas, Wenqi Li, Nicole Tilly, and
Yi-Chen Sung. 2016.

</span>
<span class="ltx_bibblock">Out of time, out of place: Reflections on design
workshops as a research method. In <em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social
Computing</em>. 1131–1141.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saltz and Grady (2017)</span>
<span class="ltx_bibblock">
Jeffrey S Saltz and
Nancy W Grady. 2017.

</span>
<span class="ltx_bibblock">The ambiguity of data science team roles and the
need for a data science workforce framework. In
<em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">2017 IEEE international conference on big data (Big
Data)</em>. IEEE, 2355–2361.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sambasivan et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Nithya Sambasivan, Shivani
Kapania, Hannah Highfill, Diana Akrong,
Praveen Paritosh, and Lora M Aroyo.
2021.

</span>
<span class="ltx_bibblock">“Everyone Wants to Do the Model Work, Not the
Data Work”: Data Cascades in High-Stakes AI. In
<em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 CHI Conference on Human
Factors in Computing Systems</em> (Yokohama, Japan) <em id="bib.bib77.4.2" class="ltx_emph ltx_font_italic">(CHI
’21)</em>. Association for Computing Machinery,
New York, NY, USA, Article 39,
15 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3411764.3445518" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3411764.3445518</a>

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanders and Stappers (2008)</span>
<span class="ltx_bibblock">
Elizabeth B.-N. Sanders and
Pieter Jan Stappers. 2008.

</span>
<span class="ltx_bibblock">Co-creation and the new landscapes of design.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">CoDesign</em> 4,
1 (2008), 5–18.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1080/15710880701875068" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1080/15710880701875068</a>
arXiv:https://doi.org/10.1080/15710880701875068

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schiff (2021)</span>
<span class="ltx_bibblock">
Daniel Schiff.
2021.

</span>
<span class="ltx_bibblock">Out of the laboratory and into the classroom: the
future of artificial intelligence in education.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">AI &amp; society</em> 36,
1 (2021), 331–348.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schiff (2022)</span>
<span class="ltx_bibblock">
Daniel Schiff.
2022.

</span>
<span class="ltx_bibblock">Education for AI, not AI for Education: the role of
education and ethics in national AI policy strategies.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">International Journal of Artificial
Intelligence in Education</em> 32, 3
(2022), 527–563.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sculley et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
David Sculley, Gary Holt,
Daniel Golovin, Eugene Davydov,
Todd Phillips, Dietmar Ebner,
Vinay Chaudhary, Michael Young,
Jean-Francois Crespo, and Dan
Dennison. 2015.

</span>
<span class="ltx_bibblock">Hidden technical debt in machine learning systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 28 (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zheyuan Ryan Shi, Claire
Wang, and Fei Fang. 2020.

</span>
<span class="ltx_bibblock">Artificial intelligence for social good: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.01818</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sloane et al<span id="bib.bib83.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mona Sloane, Emanuel
Moss, Olaitan Awomolo, and Laura
Forlano. 2020.

</span>
<span class="ltx_bibblock">Participation is not a design fix for machine
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.02423</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steen (2013)</span>
<span class="ltx_bibblock">
Marc Steen.
2013.

</span>
<span class="ltx_bibblock">Co-Design as a Process of Joint Inquiry and
Imagination.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">Design Issues</em> 29,
2 (04 2013),
16–28.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1162/DESI_a_00207" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1162/DESI_a_00207</a>
arXiv:https://direct.mit.edu/desi/article-pdf/29/2/16/1715163/desi_a_00207.pdf

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strauss and Corbin (1990)</span>
<span class="ltx_bibblock">
Anselm Strauss and
Juliet Corbin. 1990.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">Basics of qualitative research</em>.

</span>
<span class="ltx_bibblock">Sage publications.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramonyam et al<span id="bib.bib86.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Hariharan Subramonyam,
Jane Im, Colleen Seifert, and
Eytan Adar. 2022a.

</span>
<span class="ltx_bibblock">Solving Separation-of-Concerns Problems in
Collaborative Design of Human-AI Systems through Leaky Abstractions. In
<em id="bib.bib86.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 CHI Conference on Human
Factors in Computing Systems</em> (New Orleans, LA, USA)
<em id="bib.bib86.4.2" class="ltx_emph ltx_font_italic">(CHI ’22)</em>. Association for
Computing Machinery, New York, NY, USA, Article
481, 21 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3491102.3517537" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3491102.3517537</a>

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramonyam et al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Hariharan Subramonyam,
Jane Im, Colleen Seifert, and
Eytan Adar. 2022b.

</span>
<span class="ltx_bibblock">Solving Separation-of-Concerns Problems in
Collaborative Design of Human-AI Systems through Leaky Abstractions. In
<em id="bib.bib87.3.1" class="ltx_emph ltx_font_italic">CHI Conference on Human Factors in Computing
Systems</em>. 1–21.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramonyam et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Hariharan Subramonyam,
Colleen Seifert, and Eytan Adar.
2021a.

</span>
<span class="ltx_bibblock">Towards a process model for co-creating AI
experiences. In <em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">Designing Interactive Systems
Conference 2021</em>. 1529–1543.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramonyam et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Hariharan Subramonyam,
Colleen Seifert, and MI Eytan Adar.
2021b.

</span>
<span class="ltx_bibblock">How Can Human-Centered Design Shape Data-Centric
AI?. In <em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">NeurIPS Data-Centric AI Workshop.
Retrieved from https://haridecoded. com/resources/AIX_NeurIPS_2021. pdf</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taylor et al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Alex S Taylor, Siân
Lindley, Tim Regan, David Sweeney,
Vasillis Vlachokyriakos, Lillie Grainger,
and Jessica Lingel. 2015.

</span>
<span class="ltx_bibblock">Data-in-place: Thinking through the relations
between data and community. In <em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
33rd Annual ACM Conference on Human Factors in Computing Systems</em>.
2863–2872.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tomašev et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Nenad Tomašev,
Julien Cornebise, Frank Hutter,
Shakir Mohamed, Angela Picciariello,
Bec Connelly, Danielle Belgrave,
Daphne Ezer, Fanny Cachat van der Haert,
Frank Mugisha, et al<span id="bib.bib91.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">AI for social good: unlocking the opportunity for
positive impact.

</span>
<span class="ltx_bibblock"><em id="bib.bib91.4.1" class="ltx_emph ltx_font_italic">Nature Communications</em> 11,
1 (2020), 1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veale et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Michael Veale, Max
Van Kleek, and Reuben Binns.
2018.

</span>
<span class="ltx_bibblock">Fairness and accountability design needs for
algorithmic support in high-stakes public sector decision-making. In
<em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 chi conference on human
factors in computing systems</em>. 1–14.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vertesi and Dourish (2011)</span>
<span class="ltx_bibblock">
Janet Vertesi and Paul
Dourish. 2011.

</span>
<span class="ltx_bibblock">The value of data: considering the context of
production in data economies. In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the ACM 2011 conference on Computer supported cooperative work</em>.
533–542.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
April Yi Wang, Dakuo
Wang, Jaimie Drozdal, Michael Muller,
Soya Park, Justin D Weisz,
Xuye Liu, Lingfei Wu, and
Casey Dugan. 2022.

</span>
<span class="ltx_bibblock">Documentation Matters: Human-Centered AI System to
Assist Data Science Code Documentation in Computational Notebooks.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Computer-Human
Interaction</em> 29, 2
(2022), 1–33.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weber et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Michael Weber, Martin
Engert, Norman Schaffer, Jörg
Weking, and Helmut Krcmar.
2022.

</span>
<span class="ltx_bibblock">Organizational capabilities for ai
implementation—coping with inscrutability and data dependency in ai.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">Information Systems Frontiers</em>
(2022), 1–21.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Whang et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Steven Euijong Whang, Yuji
Roh, Hwanjun Song, and Jae-Gil Lee.
2023.

</span>
<span class="ltx_bibblock">Data collection and quality challenges in deep
learning: A data-centric ai perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">The VLDB Journal</em> (2023),
1–23.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Whittaker et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Meredith Whittaker, Kate
Crawford, Roel Dobbe, Genevieve Fried,
Elizabeth Kaziunas, Varoon Mathur,
Sarah Mysers West, Rashida Richardson,
Jason Schultz, and Oscar Schwartz.
2018.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">AI now report 2018</em>.

</span>
<span class="ltx_bibblock">AI Now Institute at New York University New
York.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams and Begg (1993)</span>
<span class="ltx_bibblock">
Marian G Williams and
Vivienne Begg. 1993.

</span>
<span class="ltx_bibblock">Translation between software designers and users.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 36,
6 (1993), 102–103.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Amy X Zhang, Michael
Muller, and Dakuo Wang.
2020.

</span>
<span class="ltx_bibblock">How do data science workers collaborate? roles,
workflows, and tools.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 4, CSCW1
(2020), 1–23.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zheng Zhang, Ying Xu,
Yanhao Wang, Bingsheng Yao,
Daniel Ritchie, Tongshuang Wu,
Mo Yu, Dakuo Wang, and
Toby Jia-Jun Li. 2022.

</span>
<span class="ltx_bibblock">StoryBuddy: A Human-AI Collaborative Chatbot for
Parent-Child Interactive Storytelling with Flexible Parental Involvement. In
<em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">CHI Conference on Human Factors in Computing
Systems</em>. 1–21.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Qi Zhou, Wannapon
Suraworachet, Stanislav Pozdniakov,
Roberto Martinez-Maldonado, Tom
Bartindale, Peter Chen, Dan Richardson,
and Mutlu Cukurova. 2021.

</span>
<span class="ltx_bibblock">Investigating students’ experiences with
collaboration analytics for remote group meetings. In
<em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence
in Education</em>. Springer, 472–485.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.05790" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.05792" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.05792">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.05792" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.05793" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 19:19:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
