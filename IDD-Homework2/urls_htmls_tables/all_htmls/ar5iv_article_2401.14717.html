<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document" style="font-size:90%;">
  Turn-taking and Backchannel Prediction with
  <br class="ltx_break"/>
  Acoustic and Large Language Model Fusion
 </h1>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id1.id1">
   <span class="ltx_text" id="id1.id1.1" style="font-size:90%;">
    We propose an approach for continuous prediction of turn-taking and backchanneling locations in spoken dialogue by fusing a neural acoustic model with a large language model (LLM). Experiments on the Switchboard human-human conversation dataset demonstrate that our approach consistently outperforms the baseline models with single modality. We also develop a novel multi-task instruction fine-tuning strategy to further benefit from LLM-encoded knowledge for understanding the tasks and conversational contexts, leading to additional improvements. Our approach demonstrates the potential of combined LLMs and acoustic models for a more natural and conversational interaction between humans and speech-enabled AI agents.
   </span>
  </p>
 </div>
 <div class="ltx_para" id="p1">
  <p class="ltx_p" id="p1.1">
   <span class="ltx_text ltx_font_bold ltx_font_italic" id="p1.1.1" style="font-size:90%;">
    Index Terms
    <span class="ltx_text ltx_font_upright" id="p1.1.1.1">
     —
    </span>
   </span>
   <span class="ltx_text" id="p1.1.2" style="font-size:90%;">
    turn-taking, backchannel, large language model, model fusion, instruction tuning.
   </span>
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section" style="font-size:90%;">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    <span class="ltx_text" id="S1.p1.1.1" style="font-size:90%;">
     AI voice assistants are becoming increasingly multi-functional and important in people’s daily lives
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p1.1.2.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib3" title="">
      3
     </a>
     <span class="ltx_text" id="S1.p1.1.3.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p1.1.4" style="font-size:90%;">
     . However, conventional voice assistant systems are mostly designed for query-based use cases. Towards the goal of more effective and effortless interaction between humans and AI, voice assistants that can solve tasks in a more natural manner and human-human-like conversational experience would be very desirable
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p1.1.5.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib4" title="">
      4
     </a>
     <span class="ltx_text" id="S1.p1.1.6.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p1.1.7" style="font-size:90%;">
     . As one of its most basic capabilities, the system should be able to determine when to take turns naturally and with minimal latency in a dialogue with the user, and without the need for push-to-talk or wakewords. One common solution for turn-taking is to trigger the system’s response after a period of silence based on a predefined threshold
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p1.1.8.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib5" title="">
      5
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     <span class="ltx_text" id="S1.p1.1.9.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p1.1.10" style="font-size:90%;">
     . However, this threshold-based method may result in a suboptimal user experience due to lack of naturalness
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p1.1.11.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib10" title="">
      10
     </a>
     <span class="ltx_text" id="S1.p1.1.12.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p1.1.13" style="font-size:90%;">
     . Another behavior that is important for managing human-human conversations that are a challenge for present-day conversational systems is backchanneling
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p1.1.14.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      12
     </a>
     <span class="ltx_text" id="S1.p1.1.15.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p1.1.16" style="font-size:90%;">
     . Backchannels are defined as short utterances expressing acknowledgment or reactions on the part of the listener, without signaling an intent to take a turn, such as “
    </span>
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.17" style="font-size:90%;">
     uh-huh
    </span>
    <span class="ltx_text" id="S1.p1.1.18" style="font-size:90%;">
     ”, “
    </span>
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.19" style="font-size:90%;">
     oh no
    </span>
    <span class="ltx_text" id="S1.p1.1.20" style="font-size:90%;">
     ” and “
    </span>
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.21" style="font-size:90%;">
     right
    </span>
    <span class="ltx_text" id="S1.p1.1.22" style="font-size:90%;">
     ”. They typically occur during the current speaker’s turn and do not necessarily trigger turn-taking
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p1.1.23.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib13" title="">
      13
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib14" title="">
      14
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     <span class="ltx_text" id="S1.p1.1.24.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p1.1.25" style="font-size:90%;">
     .
    </span>
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    <span class="ltx_text" id="S1.p2.1.1" style="font-size:90%;">
     Going back to conversation analysis in linguistic pragmatics
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p2.1.2.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib15" title="">
      15
     </a>
     <span class="ltx_text" id="S1.p2.1.3.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p2.1.4" style="font-size:90%;">
     , there is a long history of descriptive and computational research trying to capture turn-taking and backchanneling cues in multiple modalities. In the acoustic domain, prosodic features such as duration, pitch, voice quality and intensity have been shown to have high correlation with turn-taking and backchannel locations
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p2.1.5.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib16" title="">
      16
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     <span class="ltx_text" id="S1.p2.1.6.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p2.1.7" style="font-size:90%;">
     . In
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p2.1.8.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     <span class="ltx_text" id="S1.p2.1.9.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p2.1.10" style="font-size:90%;">
     , turn-taking prediction has been embedded as an auxiliary task in automatic speech recognition (ASR), based on acoustic encoder features. Aside from acoustic features, linguistic features have also been investigated. Given context or predicted transcription from an ASR system, word embeddings like Word2Vec
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p2.1.11.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib5" title="">
      5
     </a>
     <span class="ltx_text" id="S1.p2.1.12.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p2.1.13" style="font-size:90%;">
     and encoded hidden states from transformer networks
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p2.1.14.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib18" title="">
      18
     </a>
     <span class="ltx_text" id="S1.p2.1.15.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p2.1.16" style="font-size:90%;">
     or recurrent neural networks (RNNs)
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p2.1.17.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib19" title="">
      19
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib20" title="">
      20
     </a>
     <span class="ltx_text" id="S1.p2.1.18.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p2.1.19" style="font-size:90%;">
     have been used as linguistic representations for prediction. Furthermore, multi-modal fusion or joint modeling have been explored in earlier work, using RNN-based text and acoustic encoders
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p2.1.20.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib21" title="">
      21
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     <span class="ltx_text" id="S1.p2.1.21.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p2.1.22" style="font-size:90%;">
     .
    </span>
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    <span class="ltx_text" id="S1.p3.1.1" style="font-size:90%;">
     However, in these earlier works that use linguistic modeling, features and representations are relatively simple and only approximate the full range of linguistic cues used by humans in daily conversation
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p3.1.2.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib22" title="">
      22
     </a>
     <span class="ltx_text" id="S1.p3.1.3.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p3.1.4" style="font-size:90%;">
     . Large language models (LLMs) promise to better capture the formal dependencies and meaning relations in language
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p3.1.5.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib23" title="">
      23
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib24" title="">
      24
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib25" title="">
      25
     </a>
     <span class="ltx_text" id="S1.p3.1.6.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p3.1.7" style="font-size:90%;">
     . Ekstedt et al.
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p3.1.8.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib22" title="">
      22
     </a>
     <span class="ltx_text" id="S1.p3.1.9.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p3.1.10" style="font-size:90%;">
     proposed TurnGPT to leverage LLMs (in the form of GPT2
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p3.1.11.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib26" title="">
      26
     </a>
     <span class="ltx_text" id="S1.p3.1.12.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p3.1.13" style="font-size:90%;">
     ) for turn-taking prediction, showing superior performance compared to conventional modeling techniques. However, that work is still limited to turn-taking prediction and uses only lexical (text) information.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    <span class="ltx_text" id="S1.p4.1.1" style="font-size:90%;">
     In this work, we propose a novel approach for turn-taking and backchannel location prediction in spoken dialogue, with a fusion of LLM and acoustic models. We adopt two LLMs, GPT2
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p4.1.2.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib26" title="">
      26
     </a>
     <span class="ltx_text" id="S1.p4.1.3.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p4.1.4" style="font-size:90%;">
     and RedPajama
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p4.1.5.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib27" title="">
      27
     </a>
     <span class="ltx_text" id="S1.p4.1.6.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p4.1.7" style="font-size:90%;">
     for modeling linguistic cues, and we use HuBERT
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p4.1.8.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib28" title="">
      28
     </a>
     <span class="ltx_text" id="S1.p4.1.9.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p4.1.10" style="font-size:90%;">
     for modeling acoustic cues, to leverage both representations and prior knowledge learned during pretraining. Two fusion methods are explored by manipulating the LLM branch to better understand the role of the different modalities in joint modeling. Furthermore, inspired by the success of instruction fine-tuning of LLMs for other tasks
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="S1.p4.1.11.1" style="font-size:90%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib29" title="">
      29
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib30" title="">
      30
     </a>
     <span class="ltx_text" id="S1.p4.1.12.2" style="font-size:90%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="S1.p4.1.13" style="font-size:90%;">
     , a novel multi-task instruction fine-tuning is proposed to further utilize the ability of LLMs to understand task descriptions and dialogue history, and direct the joint model to focus on different tasks with task-specific submodules triggered by corresponding instructions.
Our main contributions are thus (1) extending the turn-taking model to include backchanneling, (2) use of LLMs with acoustic fusion for these tasks, and (3) exploration of LLMs for instruction-tuning rather than simple token encoding and prediction.
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section" style="font-size:90%;">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Proposed Method
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Problem setup
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.4">
     <span class="ltx_text" id="S2.SS1.p1.4.1" style="font-size:90%;">
      For a more natural human-agent interaction, the task of interest here is to predict the proper turn-related behavior with respect to the user’s input to a voice assistant system during conversation. Three distinct behaviors are considered: 1)
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.4.2" style="font-size:90%;">
      Continuing Speech
     </span>
     <span class="ltx_text" id="S2.SS1.p1.4.3" style="font-size:90%;">
      : the currently active speaker is predicted to continue speaking (the other party keeps listening); 2)
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.4.4" style="font-size:90%;">
      Backchannel
     </span>
     <span class="ltx_text" id="S2.SS1.p1.4.5" style="font-size:90%;">
      : the listening party (system or user) should generate a brief utterance as a sign of acknowledgment, understanding or assessment without an intention to take the turn
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S2.SS1.p1.4.6.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      <span class="ltx_text" id="S2.SS1.p1.4.7.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S2.SS1.p1.4.8" style="font-size:90%;">
      ; 3)
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.4.9" style="font-size:90%;">
      Turn-taking
     </span>
     <span class="ltx_text" id="S2.SS1.p1.4.10" style="font-size:90%;">
      : the current speaker is predicted to be done talking and the nonspeaking party should take over the conversation and provide a response. More formally, given a (partial) utterance with acoustic features
     </span>
     <math alttext="X^{A}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1">
      <semantics id="S2.SS1.p1.1.m1.1a">
       <msup id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">
        <mi id="S2.SS1.p1.1.m1.1.1.2" mathsize="90%" xref="S2.SS1.p1.1.m1.1.1.2.cmml">
         X
        </mi>
        <mi id="S2.SS1.p1.1.m1.1.1.3" mathsize="90%" xref="S2.SS1.p1.1.m1.1.1.3.cmml">
         A
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b">
        <apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">
          𝑋
         </ci>
         <ci id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3">
          𝐴
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">
        X^{A}
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS1.p1.4.11" style="font-size:90%;">
      and text features
     </span>
     <math alttext="X^{L}" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1">
      <semantics id="S2.SS1.p1.2.m2.1a">
       <msup id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">
        <mi id="S2.SS1.p1.2.m2.1.1.2" mathsize="90%" xref="S2.SS1.p1.2.m2.1.1.2.cmml">
         X
        </mi>
        <mi id="S2.SS1.p1.2.m2.1.1.3" mathsize="90%" xref="S2.SS1.p1.2.m2.1.1.3.cmml">
         L
        </mi>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b">
        <apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">
         <csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">
          superscript
         </csymbol>
         <ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">
          𝑋
         </ci>
         <ci id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">
          𝐿
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">
        X^{L}
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS1.p1.4.12" style="font-size:90%;">
      , the goal is to predict the class/behavior posteriors
     </span>
     <math alttext="P(Y|X^{A},X^{L})" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1">
      <semantics id="S2.SS1.p1.3.m3.1a">
       <mrow id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">
        <mi id="S2.SS1.p1.3.m3.1.1.3" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.3.cmml">
         P
        </mi>
        <mo id="S2.SS1.p1.3.m3.1.1.2" lspace="0em" rspace="0em" xref="S2.SS1.p1.3.m3.1.1.2.cmml">
         ​
        </mo>
        <mrow id="S2.SS1.p1.3.m3.1.1.1.1" xref="S2.SS1.p1.3.m3.1.1.1.1.1.cmml">
         <mo id="S2.SS1.p1.3.m3.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="S2.SS1.p1.3.m3.1.1.1.1.1" xref="S2.SS1.p1.3.m3.1.1.1.1.1.cmml">
          <mi id="S2.SS1.p1.3.m3.1.1.1.1.1.4" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.4.cmml">
           Y
          </mi>
          <mo fence="false" id="S2.SS1.p1.3.m3.1.1.1.1.1.3" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.3.cmml">
           |
          </mo>
          <mrow id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.3.cmml">
           <msup id="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1" xref="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.cmml">
            <mi id="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.2.cmml">
             X
            </mi>
            <mi id="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.3" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.3.cmml">
             A
            </mi>
           </msup>
           <mo id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.3" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.3.cmml">
            ,
           </mo>
           <msup id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.cmml">
            <mi id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.2" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.2.cmml">
             X
            </mi>
            <mi id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.3" mathsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.3.cmml">
             L
            </mi>
           </msup>
          </mrow>
         </mrow>
         <mo id="S2.SS1.p1.3.m3.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S2.SS1.p1.3.m3.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b">
        <apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">
         <times id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">
         </times>
         <ci id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3">
          𝑃
         </ci>
         <apply id="S2.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1">
          <csymbol cd="latexml" id="S2.SS1.p1.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.3">
           conditional
          </csymbol>
          <ci id="S2.SS1.p1.3.m3.1.1.1.1.1.4.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.4">
           𝑌
          </ci>
          <list id="S2.SS1.p1.3.m3.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2">
           <apply id="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1">
             superscript
            </csymbol>
            <ci id="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.2">
             𝑋
            </ci>
            <ci id="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.1.1.1.3">
             𝐴
            </ci>
           </apply>
           <apply id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2">
            <csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.1.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2">
             superscript
            </csymbol>
            <ci id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.2.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.2">
             𝑋
            </ci>
            <ci id="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.3.cmml" xref="S2.SS1.p1.3.m3.1.1.1.1.1.2.2.2.3">
             𝐿
            </ci>
           </apply>
          </list>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">
        P(Y|X^{A},X^{L})
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS1.p1.4.13" style="font-size:90%;">
      , where
     </span>
     <math alttext="Y" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1">
      <semantics id="S2.SS1.p1.4.m4.1a">
       <mi id="S2.SS1.p1.4.m4.1.1" mathsize="90%" xref="S2.SS1.p1.4.m4.1.1.cmml">
        Y
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b">
        <ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">
         𝑌
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">
        Y
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS1.p1.4.14" style="font-size:90%;">
      is from the label set consisting of “Continuing Speech”, “Backchannel” and “Turn-taking”. The framework is depicted in Figure
     </span>
     <a class="ltx_ref" href="#S2.F1" style="font-size:90%;" title="Figure 1 ‣ 2.3 Fusion or joint training ‣ 2 Proposed Method ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S2.SS1.p1.4.15" style="font-size:90%;">
      .
     </span>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Acoustic and language modeling
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     <span class="ltx_text" id="S2.SS2.p1.1.1" style="font-size:90%;">
      The acoustic model is shown as the bottom left module in Figure
     </span>
     <a class="ltx_ref" href="#S2.F1" style="font-size:90%;" title="Figure 1 ‣ 2.3 Fusion or joint training ‣ 2 Proposed Method ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S2.SS2.p1.1.2" style="font-size:90%;">
      . In this work, HuBERT
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S2.SS2.p1.1.3.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib28" title="">
       28
      </a>
      <span class="ltx_text" id="S2.SS2.p1.1.4.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S2.SS2.p1.1.5" style="font-size:90%;">
      is used to encode speech signals of the (partial) utterances, as well as to serve as the base acoustic model (AM) for prediction with single modality. To manipulate the architecture for classification, the average-pooled 768-dimensional HuBERT embedding across all time steps emitted from the base model is fed into a projection layer to obtain a 256-dimensional vector. Then a linear classifier maps the projection to three classes. During model training, the acoustic base model is frozen.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     <span class="ltx_text" id="S2.SS2.p2.1.1" style="font-size:90%;">
      The linguistic modeling is done by LLM fine-tuning as shown at the bottom right in Figure
     </span>
     <a class="ltx_ref" href="#S2.F1" style="font-size:90%;" title="Figure 1 ‣ 2.3 Fusion or joint training ‣ 2 Proposed Method ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S2.SS2.p2.1.2" style="font-size:90%;">
      . Here, either GPT2 or RedPajama are used to encode the text of the (partial) utterances, producing embeddings of 768 and 2560 dimensions, respectively.
Unlike in acoustic modeling, LLM fine-tuning uses the embedding of the last token. Then, the embedding is fed into a linear layer of dimension 3 for classification. Depending on the base LLM being used, different fine-tuning strategies are applied, as discussed further in
Section
     </span>
     <a class="ltx_ref" href="#S3.SS3" style="font-size:90%;" title="3.3 Experimental details ‣ 3 Experiments ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       3.3
      </span>
     </a>
     <span class="ltx_text" id="S2.SS2.p2.1.3" style="font-size:90%;">
      .
     </span>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Fusion or joint training
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     <span class="ltx_text" id="S2.SS3.p1.1.1" style="font-size:90%;">
      A late fusion mechanism is used where the final embeddings emitted from the AM and LLM are concatenated and fed into a single linear classification layer with dimension 3 to predict
     </span>
     <math alttext="P(Y|X^{A},X^{L})" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1">
      <semantics id="S2.SS3.p1.1.m1.1a">
       <mrow id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">
        <mi id="S2.SS3.p1.1.m1.1.1.3" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.3.cmml">
         P
        </mi>
        <mo id="S2.SS3.p1.1.m1.1.1.2" lspace="0em" rspace="0em" xref="S2.SS3.p1.1.m1.1.1.2.cmml">
         ​
        </mo>
        <mrow id="S2.SS3.p1.1.m1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.1.1.1.cmml">
         <mo id="S2.SS3.p1.1.m1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="S2.SS3.p1.1.m1.1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.1.1.1.cmml">
          <mi id="S2.SS3.p1.1.m1.1.1.1.1.1.4" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.4.cmml">
           Y
          </mi>
          <mo fence="false" id="S2.SS3.p1.1.m1.1.1.1.1.1.3" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.3.cmml">
           |
          </mo>
          <mrow id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.3.cmml">
           <msup id="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.cmml">
            <mi id="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2.cmml">
             X
            </mi>
            <mi id="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3.cmml">
             A
            </mi>
           </msup>
           <mo id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.3" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.3.cmml">
            ,
           </mo>
           <msup id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.cmml">
            <mi id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.2" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.2.cmml">
             X
            </mi>
            <mi id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.3" mathsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.3.cmml">
             L
            </mi>
           </msup>
          </mrow>
         </mrow>
         <mo id="S2.SS3.p1.1.m1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S2.SS3.p1.1.m1.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b">
        <apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">
         <times id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">
         </times>
         <ci id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3">
          𝑃
         </ci>
         <apply id="S2.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1">
          <csymbol cd="latexml" id="S2.SS3.p1.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.3">
           conditional
          </csymbol>
          <ci id="S2.SS3.p1.1.m1.1.1.1.1.1.4.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.4">
           𝑌
          </ci>
          <list id="S2.SS3.p1.1.m1.1.1.1.1.1.2.3.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2">
           <apply id="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1">
             superscript
            </csymbol>
            <ci id="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2">
             𝑋
            </ci>
            <ci id="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3">
             𝐴
            </ci>
           </apply>
           <apply id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2">
            <csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2">
             superscript
            </csymbol>
            <ci id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.2">
             𝑋
            </ci>
            <ci id="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1.2.2.2.3">
             𝐿
            </ci>
           </apply>
          </list>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">
        P(Y|X^{A},X^{L})
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS3.p1.1.2" style="font-size:90%;">
      , as shown in the top module of Figure
     </span>
     <a class="ltx_ref" href="#S2.F1" style="font-size:90%;" title="Figure 1 ‣ 2.3 Fusion or joint training ‣ 2 Proposed Method ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S2.SS3.p1.1.3" style="font-size:90%;">
      . Two different fusion setups are investigated. In Option 1 (
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p1.1.4" style="font-size:90%;">
      Opt1
     </span>
     <span class="ltx_text" id="S2.SS3.p1.1.5" style="font-size:90%;">
      ) both AM and LLM are loaded from the pretrained library
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S2.SS3.p1.1.6.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib31" title="">
       31
      </a>
      <span class="ltx_text" id="S2.SS3.p1.1.7.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S2.SS3.p1.1.8" style="font-size:90%;">
      without fine-tuning. Then, both the fusion layer and the LLM base model undergo domain adaptation and downstream task training. In Option 2 (
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p1.1.9" style="font-size:90%;">
      Opt2
     </span>
     <span class="ltx_text" id="S2.SS3.p1.1.10" style="font-size:90%;">
      ), aside from loading the pretrained AM as in Opt1, the LLM is loaded after stand-alone fine-tuning as described in Section
     </span>
     <a class="ltx_ref" href="#S2.SS2" style="font-size:90%;" title="2.2 Acoustic and language modeling ‣ 2 Proposed Method ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       2.2
      </span>
     </a>
     <span class="ltx_text" id="S2.SS3.p1.1.11" style="font-size:90%;">
      . Then the LLM branch is also frozen and only the fusion layer is trained. The key difference between
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p1.1.12" style="font-size:90%;">
      Opt1
     </span>
     <span class="ltx_text" id="S2.SS3.p1.1.13" style="font-size:90%;">
      and
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p1.1.14" style="font-size:90%;">
      Opt2
     </span>
     <span class="ltx_text" id="S2.SS3.p1.1.15" style="font-size:90%;">
      is whether LLM has been fine-tuned for the downstream task and frozen. Though more sophisticated architectures could be helpful, we will demonstrate the effectiveness of combining AM and LLM for turn-taking and backchannel prediction tasks even with the two simple fusion options considered here.
     </span>
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F1">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="205" id="S2.F1.g1" src="/html/2401.14717/assets/Figure/Diagram.eps.png" width="350"/>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text ltx_font_bold" id="S2.F1.4.1.1">
       Fig. 1
      </span>
      :
     </span>
     Schematic of combined acoustic and LLM modeling for turn-taking, backchannel and continuing speech prediction.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S2.SS4">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     2.4
    </span>
    Multi-task instruction fine-tuning
   </h3>
   <div class="ltx_para" id="S2.SS4.p1">
    <p class="ltx_p" id="S2.SS4.p1.1">
     <span class="ltx_text" id="S2.SS4.p1.1.1" style="font-size:90%;">
      Besides serving as an advanced text encoder, LLMs have also demonstrated the ability to understand narrative instructions in natural language. Instruction fine-tuning
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S2.SS4.p1.1.2.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib29" title="">
       29
      </a>
      <span class="ltx_text" id="S2.SS4.p1.1.3.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S2.SS4.p1.1.4" style="font-size:90%;">
      has been used to teach LLMs this behavior. Thus, we reformulate our framework as a multi-task training scenario with instructions specific to our tasks. Rather than setting up a three-way classification, each class is handled as a separate binary classification task. This will later allows us to evaluate performance as three separate detection tasks. Figure
     </span>
     <a class="ltx_ref" href="#S2.F2" style="font-size:90%;" title="Figure 2 ‣ 2.4 Multi-task instruction fine-tuning ‣ 2 Proposed Method ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     <span class="ltx_text" id="S2.SS4.p1.1.5" style="font-size:90%;">
      shows the diagram of this multi-task instruction fine-tuning process, where Sample 0, 1 and 2 are considered as the samples with corresponding ground-truth labels of “Continuing Speech”, “Backchannel” and “Turn-taking”, respectively. During training, each sample will be augmented three times, with the following respective instructions: 1)
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS4.p1.1.6" style="font-size:90%;">
      Inst 0
     </span>
     <span class="ltx_text" id="S2.SS4.p1.1.7" style="font-size:90%;">
      : “Identify if the current speaker will continue to speak at the end of the sentence.”; 2)
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS4.p1.1.8" style="font-size:90%;">
      Inst 1
     </span>
     <span class="ltx_text" id="S2.SS4.p1.1.9" style="font-size:90%;">
      : “Identify if another speaker will backchannel at the end of the sentence.”; 3)
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.SS4.p1.1.10" style="font-size:90%;">
      Inst 2
     </span>
     <span class="ltx_text" id="S2.SS4.p1.1.11" style="font-size:90%;">
      : “Identify if another speaker will take the turn at the end of the sentence.”
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S2.SS4.p2">
    <p class="ltx_p" id="S2.SS4.p2.4">
     <span class="ltx_text" id="S2.SS4.p2.4.1" style="font-size:90%;">
      For each generated sample, if the prepended instruction corresponds to the ground-truth label, i.e. {
     </span>
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p2.4.2" style="font-size:90%;">
      inst0, sample0
     </span>
     <span class="ltx_text" id="S2.SS4.p2.4.3" style="font-size:90%;">
      }, {
     </span>
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p2.4.4" style="font-size:90%;">
      inst1, sample1
     </span>
     <span class="ltx_text" id="S2.SS4.p2.4.5" style="font-size:90%;">
      } and {
     </span>
     <span class="ltx_text ltx_font_italic" id="S2.SS4.p2.4.6" style="font-size:90%;">
      inst2, sample2
     </span>
     <span class="ltx_text" id="S2.SS4.p2.4.7" style="font-size:90%;">
      }, then the corresponding binary label will be assigned as 1, otherwise 0. Each classifier is only in charge of one corresponding instruction and updates only its parameters, without being affected by samples augmented by the other two instructions. Let
     </span>
     <math alttext="X" class="ltx_Math" display="inline" id="S2.SS4.p2.1.m1.1">
      <semantics id="S2.SS4.p2.1.m1.1a">
       <mi id="S2.SS4.p2.1.m1.1.1" mathsize="90%" xref="S2.SS4.p2.1.m1.1.1.cmml">
        X
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p2.1.m1.1b">
        <ci id="S2.SS4.p2.1.m1.1.1.cmml" xref="S2.SS4.p2.1.m1.1.1">
         𝑋
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p2.1.m1.1c">
        X
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p2.4.8" style="font-size:90%;">
      denote a batch of samples
     </span>
     <math alttext="X=[x_{1},x_{2},...,x_{n}]" class="ltx_Math" display="inline" id="S2.SS4.p2.2.m2.4">
      <semantics id="S2.SS4.p2.2.m2.4a">
       <mrow id="S2.SS4.p2.2.m2.4.4" xref="S2.SS4.p2.2.m2.4.4.cmml">
        <mi id="S2.SS4.p2.2.m2.4.4.5" mathsize="90%" xref="S2.SS4.p2.2.m2.4.4.5.cmml">
         X
        </mi>
        <mo id="S2.SS4.p2.2.m2.4.4.4" mathsize="90%" xref="S2.SS4.p2.2.m2.4.4.4.cmml">
         =
        </mo>
        <mrow id="S2.SS4.p2.2.m2.4.4.3.3" xref="S2.SS4.p2.2.m2.4.4.3.4.cmml">
         <mo id="S2.SS4.p2.2.m2.4.4.3.3.4" maxsize="90%" minsize="90%" xref="S2.SS4.p2.2.m2.4.4.3.4.cmml">
          [
         </mo>
         <msub id="S2.SS4.p2.2.m2.2.2.1.1.1" xref="S2.SS4.p2.2.m2.2.2.1.1.1.cmml">
          <mi id="S2.SS4.p2.2.m2.2.2.1.1.1.2" mathsize="90%" xref="S2.SS4.p2.2.m2.2.2.1.1.1.2.cmml">
           x
          </mi>
          <mn id="S2.SS4.p2.2.m2.2.2.1.1.1.3" mathsize="90%" xref="S2.SS4.p2.2.m2.2.2.1.1.1.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S2.SS4.p2.2.m2.4.4.3.3.5" mathsize="90%" xref="S2.SS4.p2.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S2.SS4.p2.2.m2.3.3.2.2.2" xref="S2.SS4.p2.2.m2.3.3.2.2.2.cmml">
          <mi id="S2.SS4.p2.2.m2.3.3.2.2.2.2" mathsize="90%" xref="S2.SS4.p2.2.m2.3.3.2.2.2.2.cmml">
           x
          </mi>
          <mn id="S2.SS4.p2.2.m2.3.3.2.2.2.3" mathsize="90%" xref="S2.SS4.p2.2.m2.3.3.2.2.2.3.cmml">
           2
          </mn>
         </msub>
         <mo id="S2.SS4.p2.2.m2.4.4.3.3.6" mathsize="90%" xref="S2.SS4.p2.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S2.SS4.p2.2.m2.1.1" mathsize="90%" mathvariant="normal" xref="S2.SS4.p2.2.m2.1.1.cmml">
          …
         </mi>
         <mo id="S2.SS4.p2.2.m2.4.4.3.3.7" mathsize="90%" xref="S2.SS4.p2.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S2.SS4.p2.2.m2.4.4.3.3.3" xref="S2.SS4.p2.2.m2.4.4.3.3.3.cmml">
          <mi id="S2.SS4.p2.2.m2.4.4.3.3.3.2" mathsize="90%" xref="S2.SS4.p2.2.m2.4.4.3.3.3.2.cmml">
           x
          </mi>
          <mi id="S2.SS4.p2.2.m2.4.4.3.3.3.3" mathsize="90%" xref="S2.SS4.p2.2.m2.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S2.SS4.p2.2.m2.4.4.3.3.8" maxsize="90%" minsize="90%" xref="S2.SS4.p2.2.m2.4.4.3.4.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p2.2.m2.4b">
        <apply id="S2.SS4.p2.2.m2.4.4.cmml" xref="S2.SS4.p2.2.m2.4.4">
         <eq id="S2.SS4.p2.2.m2.4.4.4.cmml" xref="S2.SS4.p2.2.m2.4.4.4">
         </eq>
         <ci id="S2.SS4.p2.2.m2.4.4.5.cmml" xref="S2.SS4.p2.2.m2.4.4.5">
          𝑋
         </ci>
         <list id="S2.SS4.p2.2.m2.4.4.3.4.cmml" xref="S2.SS4.p2.2.m2.4.4.3.3">
          <apply id="S2.SS4.p2.2.m2.2.2.1.1.1.cmml" xref="S2.SS4.p2.2.m2.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S2.SS4.p2.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS4.p2.2.m2.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S2.SS4.p2.2.m2.2.2.1.1.1.2.cmml" xref="S2.SS4.p2.2.m2.2.2.1.1.1.2">
            𝑥
           </ci>
           <cn id="S2.SS4.p2.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS4.p2.2.m2.2.2.1.1.1.3">
            1
           </cn>
          </apply>
          <apply id="S2.SS4.p2.2.m2.3.3.2.2.2.cmml" xref="S2.SS4.p2.2.m2.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S2.SS4.p2.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS4.p2.2.m2.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S2.SS4.p2.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS4.p2.2.m2.3.3.2.2.2.2">
            𝑥
           </ci>
           <cn id="S2.SS4.p2.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS4.p2.2.m2.3.3.2.2.2.3">
            2
           </cn>
          </apply>
          <ci id="S2.SS4.p2.2.m2.1.1.cmml" xref="S2.SS4.p2.2.m2.1.1">
           …
          </ci>
          <apply id="S2.SS4.p2.2.m2.4.4.3.3.3.cmml" xref="S2.SS4.p2.2.m2.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S2.SS4.p2.2.m2.4.4.3.3.3.1.cmml" xref="S2.SS4.p2.2.m2.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S2.SS4.p2.2.m2.4.4.3.3.3.2.cmml" xref="S2.SS4.p2.2.m2.4.4.3.3.3.2">
            𝑥
           </ci>
           <ci id="S2.SS4.p2.2.m2.4.4.3.3.3.3.cmml" xref="S2.SS4.p2.2.m2.4.4.3.3.3.3">
            𝑛
           </ci>
          </apply>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p2.2.m2.4c">
        X=[x_{1},x_{2},...,x_{n}]
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p2.4.9" style="font-size:90%;">
      , with corresponding ground-truth labels
     </span>
     <math alttext="Y=[y_{1},y_{2},...,y_{n}]" class="ltx_Math" display="inline" id="S2.SS4.p2.3.m3.4">
      <semantics id="S2.SS4.p2.3.m3.4a">
       <mrow id="S2.SS4.p2.3.m3.4.4" xref="S2.SS4.p2.3.m3.4.4.cmml">
        <mi id="S2.SS4.p2.3.m3.4.4.5" mathsize="90%" xref="S2.SS4.p2.3.m3.4.4.5.cmml">
         Y
        </mi>
        <mo id="S2.SS4.p2.3.m3.4.4.4" mathsize="90%" xref="S2.SS4.p2.3.m3.4.4.4.cmml">
         =
        </mo>
        <mrow id="S2.SS4.p2.3.m3.4.4.3.3" xref="S2.SS4.p2.3.m3.4.4.3.4.cmml">
         <mo id="S2.SS4.p2.3.m3.4.4.3.3.4" maxsize="90%" minsize="90%" xref="S2.SS4.p2.3.m3.4.4.3.4.cmml">
          [
         </mo>
         <msub id="S2.SS4.p2.3.m3.2.2.1.1.1" xref="S2.SS4.p2.3.m3.2.2.1.1.1.cmml">
          <mi id="S2.SS4.p2.3.m3.2.2.1.1.1.2" mathsize="90%" xref="S2.SS4.p2.3.m3.2.2.1.1.1.2.cmml">
           y
          </mi>
          <mn id="S2.SS4.p2.3.m3.2.2.1.1.1.3" mathsize="90%" xref="S2.SS4.p2.3.m3.2.2.1.1.1.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S2.SS4.p2.3.m3.4.4.3.3.5" mathsize="90%" xref="S2.SS4.p2.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S2.SS4.p2.3.m3.3.3.2.2.2" xref="S2.SS4.p2.3.m3.3.3.2.2.2.cmml">
          <mi id="S2.SS4.p2.3.m3.3.3.2.2.2.2" mathsize="90%" xref="S2.SS4.p2.3.m3.3.3.2.2.2.2.cmml">
           y
          </mi>
          <mn id="S2.SS4.p2.3.m3.3.3.2.2.2.3" mathsize="90%" xref="S2.SS4.p2.3.m3.3.3.2.2.2.3.cmml">
           2
          </mn>
         </msub>
         <mo id="S2.SS4.p2.3.m3.4.4.3.3.6" mathsize="90%" xref="S2.SS4.p2.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S2.SS4.p2.3.m3.1.1" mathsize="90%" mathvariant="normal" xref="S2.SS4.p2.3.m3.1.1.cmml">
          …
         </mi>
         <mo id="S2.SS4.p2.3.m3.4.4.3.3.7" mathsize="90%" xref="S2.SS4.p2.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S2.SS4.p2.3.m3.4.4.3.3.3" xref="S2.SS4.p2.3.m3.4.4.3.3.3.cmml">
          <mi id="S2.SS4.p2.3.m3.4.4.3.3.3.2" mathsize="90%" xref="S2.SS4.p2.3.m3.4.4.3.3.3.2.cmml">
           y
          </mi>
          <mi id="S2.SS4.p2.3.m3.4.4.3.3.3.3" mathsize="90%" xref="S2.SS4.p2.3.m3.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S2.SS4.p2.3.m3.4.4.3.3.8" maxsize="90%" minsize="90%" xref="S2.SS4.p2.3.m3.4.4.3.4.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p2.3.m3.4b">
        <apply id="S2.SS4.p2.3.m3.4.4.cmml" xref="S2.SS4.p2.3.m3.4.4">
         <eq id="S2.SS4.p2.3.m3.4.4.4.cmml" xref="S2.SS4.p2.3.m3.4.4.4">
         </eq>
         <ci id="S2.SS4.p2.3.m3.4.4.5.cmml" xref="S2.SS4.p2.3.m3.4.4.5">
          𝑌
         </ci>
         <list id="S2.SS4.p2.3.m3.4.4.3.4.cmml" xref="S2.SS4.p2.3.m3.4.4.3.3">
          <apply id="S2.SS4.p2.3.m3.2.2.1.1.1.cmml" xref="S2.SS4.p2.3.m3.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S2.SS4.p2.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS4.p2.3.m3.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S2.SS4.p2.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS4.p2.3.m3.2.2.1.1.1.2">
            𝑦
           </ci>
           <cn id="S2.SS4.p2.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS4.p2.3.m3.2.2.1.1.1.3">
            1
           </cn>
          </apply>
          <apply id="S2.SS4.p2.3.m3.3.3.2.2.2.cmml" xref="S2.SS4.p2.3.m3.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S2.SS4.p2.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS4.p2.3.m3.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S2.SS4.p2.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS4.p2.3.m3.3.3.2.2.2.2">
            𝑦
           </ci>
           <cn id="S2.SS4.p2.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS4.p2.3.m3.3.3.2.2.2.3">
            2
           </cn>
          </apply>
          <ci id="S2.SS4.p2.3.m3.1.1.cmml" xref="S2.SS4.p2.3.m3.1.1">
           …
          </ci>
          <apply id="S2.SS4.p2.3.m3.4.4.3.3.3.cmml" xref="S2.SS4.p2.3.m3.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S2.SS4.p2.3.m3.4.4.3.3.3.1.cmml" xref="S2.SS4.p2.3.m3.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S2.SS4.p2.3.m3.4.4.3.3.3.2.cmml" xref="S2.SS4.p2.3.m3.4.4.3.3.3.2">
            𝑦
           </ci>
           <ci id="S2.SS4.p2.3.m3.4.4.3.3.3.3.cmml" xref="S2.SS4.p2.3.m3.4.4.3.3.3.3">
            𝑛
           </ci>
          </apply>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p2.3.m3.4c">
        Y=[y_{1},y_{2},...,y_{n}]
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p2.4.10" style="font-size:90%;">
      , and denote by
     </span>
     <math alttext="s" class="ltx_Math" display="inline" id="S2.SS4.p2.4.m4.1">
      <semantics id="S2.SS4.p2.4.m4.1a">
       <mi id="S2.SS4.p2.4.m4.1.1" mathsize="90%" xref="S2.SS4.p2.4.m4.1.1.cmml">
        s
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p2.4.m4.1b">
        <ci id="S2.SS4.p2.4.m4.1.1.cmml" xref="S2.SS4.p2.4.m4.1.1">
         𝑠
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p2.4.m4.1c">
        s
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p2.4.11" style="font-size:90%;">
      the instruction index. The workflow can be written as follows:
     </span>
    </p>
    <table class="ltx_equationgroup ltx_eqn_table" id="S2.E1">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E1X">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle{X_{s}}" class="ltx_Math" display="inline" id="S2.E1X.2.1.1.m1.1">
         <semantics id="S2.E1X.2.1.1.m1.1a">
          <msub id="S2.E1X.2.1.1.m1.1.1" xref="S2.E1X.2.1.1.m1.1.1.cmml">
           <mi id="S2.E1X.2.1.1.m1.1.1.2" mathsize="90%" xref="S2.E1X.2.1.1.m1.1.1.2.cmml">
            X
           </mi>
           <mi id="S2.E1X.2.1.1.m1.1.1.3" mathsize="90%" xref="S2.E1X.2.1.1.m1.1.1.3.cmml">
            s
           </mi>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S2.E1X.2.1.1.m1.1b">
           <apply id="S2.E1X.2.1.1.m1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">
             subscript
            </csymbol>
            <ci id="S2.E1X.2.1.1.m1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.1.1.2">
             𝑋
            </ci>
            <ci id="S2.E1X.2.1.1.m1.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.3">
             𝑠
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.1c">
           \displaystyle{X_{s}}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_left ltx_eqn_cell">
        <math alttext="\displaystyle=\{inst_{s},X\}" class="ltx_Math" display="inline" id="S2.E1X.3.2.2.m1.2">
         <semantics id="S2.E1X.3.2.2.m1.2a">
          <mrow id="S2.E1X.3.2.2.m1.2.2" xref="S2.E1X.3.2.2.m1.2.2.cmml">
           <mi id="S2.E1X.3.2.2.m1.2.2.3" xref="S2.E1X.3.2.2.m1.2.2.3.cmml">
           </mi>
           <mo id="S2.E1X.3.2.2.m1.2.2.2" mathsize="90%" xref="S2.E1X.3.2.2.m1.2.2.2.cmml">
            =
           </mo>
           <mrow id="S2.E1X.3.2.2.m1.2.2.1.1" xref="S2.E1X.3.2.2.m1.2.2.1.2.cmml">
            <mo id="S2.E1X.3.2.2.m1.2.2.1.1.2" maxsize="90%" minsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.2.cmml">
             {
            </mo>
            <mrow id="S2.E1X.3.2.2.m1.2.2.1.1.1" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.cmml">
             <mi id="S2.E1X.3.2.2.m1.2.2.1.1.1.2" mathsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.2.cmml">
              i
             </mi>
             <mo id="S2.E1X.3.2.2.m1.2.2.1.1.1.1" lspace="0em" rspace="0em" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.1.cmml">
              ​
             </mo>
             <mi id="S2.E1X.3.2.2.m1.2.2.1.1.1.3" mathsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.3.cmml">
              n
             </mi>
             <mo id="S2.E1X.3.2.2.m1.2.2.1.1.1.1a" lspace="0em" rspace="0em" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.1.cmml">
              ​
             </mo>
             <mi id="S2.E1X.3.2.2.m1.2.2.1.1.1.4" mathsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.4.cmml">
              s
             </mi>
             <mo id="S2.E1X.3.2.2.m1.2.2.1.1.1.1b" lspace="0em" rspace="0em" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.1.cmml">
              ​
             </mo>
             <msub id="S2.E1X.3.2.2.m1.2.2.1.1.1.5" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.5.cmml">
              <mi id="S2.E1X.3.2.2.m1.2.2.1.1.1.5.2" mathsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.5.2.cmml">
               t
              </mi>
              <mi id="S2.E1X.3.2.2.m1.2.2.1.1.1.5.3" mathsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.5.3.cmml">
               s
              </mi>
             </msub>
            </mrow>
            <mo id="S2.E1X.3.2.2.m1.2.2.1.1.3" mathsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.2.cmml">
             ,
            </mo>
            <mi id="S2.E1X.3.2.2.m1.1.1" mathsize="90%" xref="S2.E1X.3.2.2.m1.1.1.cmml">
             X
            </mi>
            <mo id="S2.E1X.3.2.2.m1.2.2.1.1.4" maxsize="90%" minsize="90%" xref="S2.E1X.3.2.2.m1.2.2.1.2.cmml">
             }
            </mo>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S2.E1X.3.2.2.m1.2b">
           <apply id="S2.E1X.3.2.2.m1.2.2.cmml" xref="S2.E1X.3.2.2.m1.2.2">
            <eq id="S2.E1X.3.2.2.m1.2.2.2.cmml" xref="S2.E1X.3.2.2.m1.2.2.2">
            </eq>
            <csymbol cd="latexml" id="S2.E1X.3.2.2.m1.2.2.3.cmml" xref="S2.E1X.3.2.2.m1.2.2.3">
             absent
            </csymbol>
            <set id="S2.E1X.3.2.2.m1.2.2.1.2.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1">
             <apply id="S2.E1X.3.2.2.m1.2.2.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1">
              <times id="S2.E1X.3.2.2.m1.2.2.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.1">
              </times>
              <ci id="S2.E1X.3.2.2.m1.2.2.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.2">
               𝑖
              </ci>
              <ci id="S2.E1X.3.2.2.m1.2.2.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.3">
               𝑛
              </ci>
              <ci id="S2.E1X.3.2.2.m1.2.2.1.1.1.4.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.4">
               𝑠
              </ci>
              <apply id="S2.E1X.3.2.2.m1.2.2.1.1.1.5.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.5">
               <csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.2.2.1.1.1.5.1.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.5">
                subscript
               </csymbol>
               <ci id="S2.E1X.3.2.2.m1.2.2.1.1.1.5.2.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.5.2">
                𝑡
               </ci>
               <ci id="S2.E1X.3.2.2.m1.2.2.1.1.1.5.3.cmml" xref="S2.E1X.3.2.2.m1.2.2.1.1.1.5.3">
                𝑠
               </ci>
              </apply>
             </apply>
             <ci id="S2.E1X.3.2.2.m1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1">
              𝑋
             </ci>
            </set>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S2.E1X.3.2.2.m1.2c">
           \displaystyle=\{inst_{s},X\}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="2">
        <span class="ltx_tag ltx_tag_equationgroup ltx_align_right">
         (1)
        </span>
       </td>
      </tr>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E1Xa">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_eqn_cell">
       </td>
       <td class="ltx_td ltx_align_left ltx_eqn_cell">
        <math alttext="\displaystyle=(inst_{s},x_{1}),(inst_{s},x_{2})...(inst_{s},x_{n})\;s=0,1,2" class="ltx_Math" display="inline" id="S2.E1Xa.2.1.1.m1.5">
         <semantics id="S2.E1Xa.2.1.1.m1.5a">
          <mrow id="S2.E1Xa.2.1.1.m1.5.5.2" xref="S2.E1Xa.2.1.1.m1.5.5.3.cmml">
           <mrow id="S2.E1Xa.2.1.1.m1.4.4.1.1" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.cmml">
            <mi id="S2.E1Xa.2.1.1.m1.4.4.1.1.4" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.4.cmml">
            </mi>
            <mo id="S2.E1Xa.2.1.1.m1.4.4.1.1.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.3.cmml">
             =
            </mo>
            <mrow id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.3.cmml">
             <mo id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.3" maxsize="90%" minsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.3.cmml">
              (
             </mo>
             <mrow id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.cmml">
              <mi id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.2.cmml">
               i
              </mi>
              <mo id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1.cmml">
               ​
              </mo>
              <mi id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.3.cmml">
               n
              </mi>
              <mo id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1.cmml">
               ​
              </mo>
              <mi id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.4" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.4.cmml">
               s
              </mi>
              <mo id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1.cmml">
               ​
              </mo>
              <msub id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.cmml">
               <mi id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.2.cmml">
                t
               </mi>
               <mi id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.3.cmml">
                s
               </mi>
              </msub>
             </mrow>
             <mo id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.4" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.3.cmml">
              ,
             </mo>
             <msub id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.cmml">
              <mi id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.2.cmml">
               x
              </mi>
              <mn id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.3.cmml">
               1
              </mn>
             </msub>
             <mo id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.5" maxsize="90%" minsize="90%" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.3.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="S2.E1Xa.2.1.1.m1.5.5.2.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.3a.cmml">
            ,
           </mo>
           <mrow id="S2.E1Xa.2.1.1.m1.5.5.2.2" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.cmml">
            <mrow id="S2.E1Xa.2.1.1.m1.5.5.2.2.4" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.cmml">
             <mrow id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.3.cmml">
              <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.3" maxsize="90%" minsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.3.cmml">
               (
              </mo>
              <mrow id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.cmml">
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2.cmml">
                i
               </mi>
               <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.cmml">
                n
               </mi>
               <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.cmml">
                ​
               </mo>
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.cmml">
                s
               </mi>
               <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1b" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.cmml">
                ​
               </mo>
               <msub id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.cmml">
                <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.2.cmml">
                 t
                </mi>
                <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.3.cmml">
                 s
                </mi>
               </msub>
              </mrow>
              <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.4" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.3.cmml">
               ,
              </mo>
              <msub id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.cmml">
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.2.cmml">
                x
               </mi>
               <mn id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.3.cmml">
                2
               </mn>
              </msub>
              <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.5" maxsize="90%" minsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.3.cmml">
               )
              </mo>
             </mrow>
             <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5.cmml">
              ​
             </mo>
             <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.6" mathsize="90%" mathvariant="normal" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.6.cmml">
              …
             </mi>
             <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5a" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5.cmml">
              ​
             </mo>
             <mrow id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.3.cmml">
              <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.3" maxsize="90%" minsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.3.cmml">
               (
              </mo>
              <mrow id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.cmml">
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.2.cmml">
                i
               </mi>
               <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1.cmml">
                ​
               </mo>
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.3.cmml">
                n
               </mi>
               <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1a" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1.cmml">
                ​
               </mo>
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.4" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.4.cmml">
                s
               </mi>
               <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1b" lspace="0em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1.cmml">
                ​
               </mo>
               <msub id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.cmml">
                <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.2.cmml">
                 t
                </mi>
                <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.3.cmml">
                 s
                </mi>
               </msub>
              </mrow>
              <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.4" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.3.cmml">
               ,
              </mo>
              <msub id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.cmml">
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.2.cmml">
                x
               </mi>
               <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.3.cmml">
                n
               </mi>
              </msub>
              <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.5" maxsize="90%" minsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.3.cmml">
               )
              </mo>
             </mrow>
             <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5b" lspace="0.280em" rspace="0em" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5.cmml">
              ​
             </mo>
             <mi id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.7" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.7.cmml">
              s
             </mi>
            </mrow>
            <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.5" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.5.cmml">
             =
            </mo>
            <mrow id="S2.E1Xa.2.1.1.m1.5.5.2.2.6.2" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.6.1.cmml">
             <mn id="S2.E1Xa.2.1.1.m1.1.1" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.1.1.cmml">
              0
             </mn>
             <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.6.2.1" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.6.1.cmml">
              ,
             </mo>
             <mn id="S2.E1Xa.2.1.1.m1.2.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.2.2.cmml">
              1
             </mn>
             <mo id="S2.E1Xa.2.1.1.m1.5.5.2.2.6.2.2" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.6.1.cmml">
              ,
             </mo>
             <mn id="S2.E1Xa.2.1.1.m1.3.3" mathsize="90%" xref="S2.E1Xa.2.1.1.m1.3.3.cmml">
              2
             </mn>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S2.E1Xa.2.1.1.m1.5b">
           <apply id="S2.E1Xa.2.1.1.m1.5.5.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2">
            <csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.5.5.3a.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.3">
             formulae-sequence
            </csymbol>
            <apply id="S2.E1Xa.2.1.1.m1.4.4.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1">
             <eq id="S2.E1Xa.2.1.1.m1.4.4.1.1.3.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.3">
             </eq>
             <csymbol cd="latexml" id="S2.E1Xa.2.1.1.m1.4.4.1.1.4.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.4">
              absent
             </csymbol>
             <interval closure="open" id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.3.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2">
              <apply id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1">
               <times id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.1">
               </times>
               <ci id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.2">
                𝑖
               </ci>
               <ci id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.3.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.3">
                𝑛
               </ci>
               <ci id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.4.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.4">
                𝑠
               </ci>
               <apply id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5">
                <csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.1.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5">
                 subscript
                </csymbol>
                <ci id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.2.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.2">
                 𝑡
                </ci>
                <ci id="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.3.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.1.1.1.5.3">
                 𝑠
                </ci>
               </apply>
              </apply>
              <apply id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2">
               <csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.1.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2">
                subscript
               </csymbol>
               <ci id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.2">
                𝑥
               </ci>
               <cn id="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.3.cmml" type="integer" xref="S2.E1Xa.2.1.1.m1.4.4.1.1.2.2.2.3">
                1
               </cn>
              </apply>
             </interval>
            </apply>
            <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2">
             <eq id="S2.E1Xa.2.1.1.m1.5.5.2.2.5.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.5">
             </eq>
             <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4">
              <times id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.5">
              </times>
              <interval closure="open" id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2">
               <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1">
                <times id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1">
                </times>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2">
                 𝑖
                </ci>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3">
                 𝑛
                </ci>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4">
                 𝑠
                </ci>
                <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5">
                 <csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5">
                  subscript
                 </csymbol>
                 <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.2">
                  𝑡
                 </ci>
                 <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.1.1.1.1.5.3">
                  𝑠
                 </ci>
                </apply>
               </apply>
               <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2">
                <csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2">
                 subscript
                </csymbol>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.2">
                 𝑥
                </ci>
                <cn id="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.3.cmml" type="integer" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.2.2.2.2.3">
                 2
                </cn>
               </apply>
              </interval>
              <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.6.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.6">
               …
              </ci>
              <interval closure="open" id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2">
               <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1">
                <times id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.1">
                </times>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.2">
                 𝑖
                </ci>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.3">
                 𝑛
                </ci>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.4.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.4">
                 𝑠
                </ci>
                <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5">
                 <csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5">
                  subscript
                 </csymbol>
                 <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.2">
                  𝑡
                 </ci>
                 <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.3.3.1.1.5.3">
                  𝑠
                 </ci>
                </apply>
               </apply>
               <apply id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2">
                <csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2">
                 subscript
                </csymbol>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.2">
                 𝑥
                </ci>
                <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.3.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.4.2.2.3">
                 𝑛
                </ci>
               </apply>
              </interval>
              <ci id="S2.E1Xa.2.1.1.m1.5.5.2.2.4.7.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.4.7">
               𝑠
              </ci>
             </apply>
             <list id="S2.E1Xa.2.1.1.m1.5.5.2.2.6.1.cmml" xref="S2.E1Xa.2.1.1.m1.5.5.2.2.6.2">
              <cn id="S2.E1Xa.2.1.1.m1.1.1.cmml" type="integer" xref="S2.E1Xa.2.1.1.m1.1.1">
               0
              </cn>
              <cn id="S2.E1Xa.2.1.1.m1.2.2.cmml" type="integer" xref="S2.E1Xa.2.1.1.m1.2.2">
               1
              </cn>
              <cn id="S2.E1Xa.2.1.1.m1.3.3.cmml" type="integer" xref="S2.E1Xa.2.1.1.m1.3.3">
               2
              </cn>
             </list>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S2.E1Xa.2.1.1.m1.5c">
           \displaystyle=(inst_{s},x_{1}),(inst_{s},x_{2})...(inst_{s},x_{n})\;s=0,1,2
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
      </tr>
     </tbody>
    </table>
    <table class="ltx_equationgroup ltx_eqn_table" id="S2.E2">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E2X">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle Y_{s}=[y_{s,1},y_{s,2},...,y_{s,n}],\;\;\;y_{s,i}=" class="ltx_math_unparsed" display="inline" id="S2.E2X.2.1.1.m1.9">
         <semantics id="S2.E2X.2.1.1.m1.9a">
          <mrow id="S2.E2X.2.1.1.m1.9b">
           <msub id="S2.E2X.2.1.1.m1.9.10">
            <mi id="S2.E2X.2.1.1.m1.9.10.2" mathsize="90%">
             Y
            </mi>
            <mi id="S2.E2X.2.1.1.m1.9.10.3" mathsize="90%">
             s
            </mi>
           </msub>
           <mo id="S2.E2X.2.1.1.m1.9.11" mathsize="90%">
            =
           </mo>
           <mrow id="S2.E2X.2.1.1.m1.9.12">
            <mo id="S2.E2X.2.1.1.m1.9.12.1" maxsize="90%" minsize="90%">
             [
            </mo>
            <msub id="S2.E2X.2.1.1.m1.9.12.2">
             <mi id="S2.E2X.2.1.1.m1.9.12.2.2" mathsize="90%">
              y
             </mi>
             <mrow id="S2.E2X.2.1.1.m1.2.2.2.4">
              <mi id="S2.E2X.2.1.1.m1.1.1.1.1" mathsize="90%">
               s
              </mi>
              <mo id="S2.E2X.2.1.1.m1.2.2.2.4.1" mathsize="90%">
               ,
              </mo>
              <mn id="S2.E2X.2.1.1.m1.2.2.2.2" mathsize="90%">
               1
              </mn>
             </mrow>
            </msub>
            <mo id="S2.E2X.2.1.1.m1.9.12.3" mathsize="90%">
             ,
            </mo>
            <msub id="S2.E2X.2.1.1.m1.9.12.4">
             <mi id="S2.E2X.2.1.1.m1.9.12.4.2" mathsize="90%">
              y
             </mi>
             <mrow id="S2.E2X.2.1.1.m1.4.4.2.4">
              <mi id="S2.E2X.2.1.1.m1.3.3.1.1" mathsize="90%">
               s
              </mi>
              <mo id="S2.E2X.2.1.1.m1.4.4.2.4.1" mathsize="90%">
               ,
              </mo>
              <mn id="S2.E2X.2.1.1.m1.4.4.2.2" mathsize="90%">
               2
              </mn>
             </mrow>
            </msub>
            <mo id="S2.E2X.2.1.1.m1.9.12.5" mathsize="90%">
             ,
            </mo>
            <mi id="S2.E2X.2.1.1.m1.9.9" mathsize="90%" mathvariant="normal">
             …
            </mi>
            <mo id="S2.E2X.2.1.1.m1.9.12.6" mathsize="90%">
             ,
            </mo>
            <msub id="S2.E2X.2.1.1.m1.9.12.7">
             <mi id="S2.E2X.2.1.1.m1.9.12.7.2" mathsize="90%">
              y
             </mi>
             <mrow id="S2.E2X.2.1.1.m1.6.6.2.4">
              <mi id="S2.E2X.2.1.1.m1.5.5.1.1" mathsize="90%">
               s
              </mi>
              <mo id="S2.E2X.2.1.1.m1.6.6.2.4.1" mathsize="90%">
               ,
              </mo>
              <mi id="S2.E2X.2.1.1.m1.6.6.2.2" mathsize="90%">
               n
              </mi>
             </mrow>
            </msub>
            <mo id="S2.E2X.2.1.1.m1.9.12.8" maxsize="90%" minsize="90%">
             ]
            </mo>
           </mrow>
           <mo id="S2.E2X.2.1.1.m1.9.13" mathsize="90%" rspace="0.997em">
            ,
           </mo>
           <msub id="S2.E2X.2.1.1.m1.9.14">
            <mi id="S2.E2X.2.1.1.m1.9.14.2" mathsize="90%">
             y
            </mi>
            <mrow id="S2.E2X.2.1.1.m1.8.8.2.4">
             <mi id="S2.E2X.2.1.1.m1.7.7.1.1" mathsize="90%">
              s
             </mi>
             <mo id="S2.E2X.2.1.1.m1.8.8.2.4.1" mathsize="90%">
              ,
             </mo>
             <mi id="S2.E2X.2.1.1.m1.8.8.2.2" mathsize="90%">
              i
             </mi>
            </mrow>
           </msub>
           <mo id="S2.E2X.2.1.1.m1.9.15" mathsize="90%">
            =
           </mo>
          </mrow>
          <annotation encoding="application/x-tex" id="S2.E2X.2.1.1.m1.9c">
           \displaystyle Y_{s}=[y_{s,1},y_{s,2},...,y_{s,n}],\;\;\;y_{s,i}=
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_left ltx_eqn_cell">
        <math alttext="\displaystyle\begin{cases}1&amp;s=y_{i}\\
0&amp;s\neq y_{i}\end{cases}" class="ltx_Math" display="inline" id="S2.E2X.3.2.2.m1.1">
         <semantics id="S2.E2X.3.2.2.m1.1a">
          <mrow id="S2.E2.m1.4.4.4.4.4.4a" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
           <mo id="S2.E2.m1.4.4.4.4.4.4a.5" xref="S2.E2X.3.2.2.m1.1.1.1.1.cmml">
            {
           </mo>
           <mtable columnspacing="5pt" id="S2.E2.m1.4.4.4.4.4.4.4a" rowspacing="0pt" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
            <mtr id="S2.E2.m1.4.4.4.4.4.4.4aa" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
             <mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4.4.4.4.4ab" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
              <mn id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.mf" mathsize="90%" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.mf.cmml">
               1
              </mn>
             </mtd>
             <mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4.4.4.4.4ac" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
              <mrow id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.cmml">
               <mi id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.2" mathsize="90%" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.2.cmml">
                s
               </mi>
               <mo id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.1" mathsize="90%" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.1.cmml">
                =
               </mo>
               <msub id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.cmml">
                <mi id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.2" mathsize="90%" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.2.cmml">
                 y
                </mi>
                <mi id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.3" mathsize="90%" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.3.cmml">
                 i
                </mi>
               </msub>
              </mrow>
             </mtd>
            </mtr>
            <mtr id="S2.E2.m1.4.4.4.4.4.4.4ad" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
             <mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4.4.4.4.4ae" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
              <mn id="S2.E2.m1.3.3.3.3.3.3.3.3.1.1.mf" mathsize="90%" xref="S2.E2.m1.3.3.3.3.3.3.3.3.1.1.mf.cmml">
               0
              </mn>
             </mtd>
             <mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4.4.4.4.4af" xref="S2.E2X.3.2.2.m1.1.1.1.cmml">
              <mrow id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.cmml">
               <mi id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.2" mathsize="90%" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.2.cmml">
                s
               </mi>
               <mo id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.1" mathsize="90%" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.1.cmml">
                ≠
               </mo>
               <msub id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.cmml">
                <mi id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.2" mathsize="90%" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.2.cmml">
                 y
                </mi>
                <mi id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.3" mathsize="90%" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.3.cmml">
                 i
                </mi>
               </msub>
              </mrow>
             </mtd>
            </mtr>
           </mtable>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S2.E2X.3.2.2.m1.1b">
           <apply id="S2.E2X.3.2.2.m1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4a">
            <csymbol cd="latexml" id="S2.E2X.3.2.2.m1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4a.5">
             cases
            </csymbol>
            <cn id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.mf.cmml" type="integer" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.mf">
             1
            </cn>
            <apply id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf">
             <eq id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.1">
             </eq>
             <ci id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.2">
              𝑠
             </ci>
             <apply id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3">
              <csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3">
               subscript
              </csymbol>
              <ci id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.2">
               𝑦
              </ci>
              <ci id="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2.2.2.1.mf.3.3">
               𝑖
              </ci>
             </apply>
            </apply>
            <cn id="S2.E2.m1.3.3.3.3.3.3.3.3.1.1.mf.cmml" type="integer" xref="S2.E2.m1.3.3.3.3.3.3.3.3.1.1.mf">
             0
            </cn>
            <apply id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.cmml" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf">
             <neq id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.1">
             </neq>
             <ci id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.2">
              𝑠
             </ci>
             <apply id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.cmml" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3">
              <csymbol cd="ambiguous" id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3">
               subscript
              </csymbol>
              <ci id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.2">
               𝑦
              </ci>
              <ci id="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.3.cmml" xref="S2.E2.m1.4.4.4.4.4.4.4.4.2.1.mf.3.3">
               𝑖
              </ci>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S2.E2X.3.2.2.m1.1c">
           \displaystyle\begin{cases}1&amp;s=y_{i}\\
0&amp;s\neq y_{i}\end{cases}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equationgroup ltx_align_right">
         (2)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <table class="ltx_equationgroup ltx_eqn_table" id="S2.E3">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E3X">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle\hat{Y_{s}}=\mathit{Classifier_{s}}(\mathit{Model}(X_{s}))" class="ltx_Math" display="inline" id="S2.E3X.2.1.1.m1.1">
         <semantics id="S2.E3X.2.1.1.m1.1a">
          <mrow id="S2.E3X.2.1.1.m1.1.1" xref="S2.E3X.2.1.1.m1.1.1.cmml">
           <mover accent="true" id="S2.E3X.2.1.1.m1.1.1.3" xref="S2.E3X.2.1.1.m1.1.1.3.cmml">
            <msub id="S2.E3X.2.1.1.m1.1.1.3.2" xref="S2.E3X.2.1.1.m1.1.1.3.2.cmml">
             <mi id="S2.E3X.2.1.1.m1.1.1.3.2.2" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.3.2.2.cmml">
              Y
             </mi>
             <mi id="S2.E3X.2.1.1.m1.1.1.3.2.3" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.3.2.3.cmml">
              s
             </mi>
            </msub>
            <mo id="S2.E3X.2.1.1.m1.1.1.3.1" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.3.1.cmml">
             ^
            </mo>
           </mover>
           <mo id="S2.E3X.2.1.1.m1.1.1.2" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.2.cmml">
            =
           </mo>
           <mrow id="S2.E3X.2.1.1.m1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.cmml">
            <msub id="S2.E3X.2.1.1.m1.1.1.1.3" xref="S2.E3X.2.1.1.m1.1.1.1.3.cmml">
             <mi id="S2.E3X.2.1.1.m1.1.1.1.3.2" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.3.2.cmml">
              𝐶𝑙𝑎𝑠𝑠𝑖𝑓𝑖𝑒𝑟
             </mi>
             <mi id="S2.E3X.2.1.1.m1.1.1.1.3.3" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.3.3.cmml">
              s
             </mi>
            </msub>
            <mo id="S2.E3X.2.1.1.m1.1.1.1.2" lspace="0em" rspace="0em" xref="S2.E3X.2.1.1.m1.1.1.1.2.cmml">
             ​
            </mo>
            <mrow id="S2.E3X.2.1.1.m1.1.1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.cmml">
             <mo id="S2.E3X.2.1.1.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.cmml">
              (
             </mo>
             <mrow id="S2.E3X.2.1.1.m1.1.1.1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.cmml">
              <mi id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.3" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.3.cmml">
               𝑀𝑜𝑑𝑒𝑙
              </mi>
              <mo id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.2.cmml">
               ​
              </mo>
              <mrow id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
               <mo id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
                (
               </mo>
               <msub id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
                <mi id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">
                 X
                </mi>
                <mi id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3" mathsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">
                 s
                </mi>
               </msub>
               <mo id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
                )
               </mo>
              </mrow>
             </mrow>
             <mo id="S2.E3X.2.1.1.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S2.E3X.2.1.1.m1.1b">
           <apply id="S2.E3X.2.1.1.m1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1">
            <eq id="S2.E3X.2.1.1.m1.1.1.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.2">
            </eq>
            <apply id="S2.E3X.2.1.1.m1.1.1.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.3">
             <ci id="S2.E3X.2.1.1.m1.1.1.3.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.3.1">
              ^
             </ci>
             <apply id="S2.E3X.2.1.1.m1.1.1.3.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.3.2">
              <csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.1.1.3.2.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.3.2">
               subscript
              </csymbol>
              <ci id="S2.E3X.2.1.1.m1.1.1.3.2.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.3.2.2">
               𝑌
              </ci>
              <ci id="S2.E3X.2.1.1.m1.1.1.3.2.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.3.2.3">
               𝑠
              </ci>
             </apply>
            </apply>
            <apply id="S2.E3X.2.1.1.m1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1">
             <times id="S2.E3X.2.1.1.m1.1.1.1.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.2">
             </times>
             <apply id="S2.E3X.2.1.1.m1.1.1.1.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.3">
              <csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.1.1.1.3.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.3">
               subscript
              </csymbol>
              <ci id="S2.E3X.2.1.1.m1.1.1.1.3.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.3.2">
               𝐶𝑙𝑎𝑠𝑠𝑖𝑓𝑖𝑒𝑟
              </ci>
              <ci id="S2.E3X.2.1.1.m1.1.1.1.3.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.3.3">
               𝑠
              </ci>
             </apply>
             <apply id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1">
              <times id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.2">
              </times>
              <ci id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.3">
               𝑀𝑜𝑑𝑒𝑙
              </ci>
              <apply id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1">
               <csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1">
                subscript
               </csymbol>
               <ci id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2">
                𝑋
               </ci>
               <ci id="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">
                𝑠
               </ci>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S2.E3X.2.1.1.m1.1c">
           \displaystyle\hat{Y_{s}}=\mathit{Classifier_{s}}(\mathit{Model}(X_{s}))
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equationgroup ltx_align_right">
         (3)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <table class="ltx_equationgroup ltx_eqn_table" id="S2.E4">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E4X">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle L_{s}=\mathit{BCELoss}(\hat{Y_{s}},Y_{s}),\;\;\;L=\sum_{s=0}^{2}L_{s}" class="ltx_Math" display="inline" id="S2.E4X.2.1.1.m1.3">
         <semantics id="S2.E4X.2.1.1.m1.3a">
          <mrow id="S2.E4X.2.1.1.m1.3.3.2" xref="S2.E4X.2.1.1.m1.3.3.3.cmml">
           <mrow id="S2.E4X.2.1.1.m1.2.2.1.1" xref="S2.E4X.2.1.1.m1.2.2.1.1.cmml">
            <msub id="S2.E4X.2.1.1.m1.2.2.1.1.3" xref="S2.E4X.2.1.1.m1.2.2.1.1.3.cmml">
             <mi id="S2.E4X.2.1.1.m1.2.2.1.1.3.2" mathsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.3.2.cmml">
              L
             </mi>
             <mi id="S2.E4X.2.1.1.m1.2.2.1.1.3.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.3.3.cmml">
              s
             </mi>
            </msub>
            <mo id="S2.E4X.2.1.1.m1.2.2.1.1.2" mathsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.2.cmml">
             =
            </mo>
            <mrow id="S2.E4X.2.1.1.m1.2.2.1.1.1" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.cmml">
             <mi id="S2.E4X.2.1.1.m1.2.2.1.1.1.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.3.cmml">
              𝐵𝐶𝐸𝐿𝑜𝑠𝑠
             </mi>
             <mo id="S2.E4X.2.1.1.m1.2.2.1.1.1.2" lspace="0em" rspace="0em" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.2.cmml">
              ​
             </mo>
             <mrow id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.2.cmml">
              <mo id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.2.cmml">
               (
              </mo>
              <mover accent="true" id="S2.E4X.2.1.1.m1.1.1" xref="S2.E4X.2.1.1.m1.1.1.cmml">
               <msub id="S2.E4X.2.1.1.m1.1.1.2" xref="S2.E4X.2.1.1.m1.1.1.2.cmml">
                <mi id="S2.E4X.2.1.1.m1.1.1.2.2" mathsize="90%" xref="S2.E4X.2.1.1.m1.1.1.2.2.cmml">
                 Y
                </mi>
                <mi id="S2.E4X.2.1.1.m1.1.1.2.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.1.1.2.3.cmml">
                 s
                </mi>
               </msub>
               <mo id="S2.E4X.2.1.1.m1.1.1.1" mathsize="90%" xref="S2.E4X.2.1.1.m1.1.1.1.cmml">
                ^
               </mo>
              </mover>
              <mo id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.2.cmml">
               ,
              </mo>
              <msub id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.cmml">
               <mi id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.2" mathsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.2.cmml">
                Y
               </mi>
               <mi id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml">
                s
               </mi>
              </msub>
              <mo id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.4" maxsize="90%" minsize="90%" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.2.cmml">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
           <mo id="S2.E4X.2.1.1.m1.3.3.2.3" mathsize="90%" rspace="0.997em" xref="S2.E4X.2.1.1.m1.3.3.3a.cmml">
            ,
           </mo>
           <mrow id="S2.E4X.2.1.1.m1.3.3.2.2" xref="S2.E4X.2.1.1.m1.3.3.2.2.cmml">
            <mi id="S2.E4X.2.1.1.m1.3.3.2.2.2" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.2.cmml">
             L
            </mi>
            <mo id="S2.E4X.2.1.1.m1.3.3.2.2.1" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.1.cmml">
             =
            </mo>
            <mrow id="S2.E4X.2.1.1.m1.3.3.2.2.3" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.cmml">
             <mstyle displaystyle="true" id="S2.E4X.2.1.1.m1.3.3.2.2.3.1" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.cmml">
              <munderover id="S2.E4X.2.1.1.m1.3.3.2.2.3.1a" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.cmml">
               <mo id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.2.cmml">
                ∑
               </mo>
               <mrow id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.cmml">
                <mi id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.2" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.2.cmml">
                 s
                </mi>
                <mo id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.1" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.1.cmml">
                 =
                </mo>
                <mn id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.3.cmml">
                 0
                </mn>
               </mrow>
               <mn id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.3.cmml">
                2
               </mn>
              </munderover>
             </mstyle>
             <msub id="S2.E4X.2.1.1.m1.3.3.2.2.3.2" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.2.cmml">
              <mi id="S2.E4X.2.1.1.m1.3.3.2.2.3.2.2" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.2.2.cmml">
               L
              </mi>
              <mi id="S2.E4X.2.1.1.m1.3.3.2.2.3.2.3" mathsize="90%" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.2.3.cmml">
               s
              </mi>
             </msub>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S2.E4X.2.1.1.m1.3b">
           <apply id="S2.E4X.2.1.1.m1.3.3.3.cmml" xref="S2.E4X.2.1.1.m1.3.3.2">
            <csymbol cd="ambiguous" id="S2.E4X.2.1.1.m1.3.3.3a.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.3">
             formulae-sequence
            </csymbol>
            <apply id="S2.E4X.2.1.1.m1.2.2.1.1.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1">
             <eq id="S2.E4X.2.1.1.m1.2.2.1.1.2.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.2">
             </eq>
             <apply id="S2.E4X.2.1.1.m1.2.2.1.1.3.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.3">
              <csymbol cd="ambiguous" id="S2.E4X.2.1.1.m1.2.2.1.1.3.1.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.3">
               subscript
              </csymbol>
              <ci id="S2.E4X.2.1.1.m1.2.2.1.1.3.2.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.3.2">
               𝐿
              </ci>
              <ci id="S2.E4X.2.1.1.m1.2.2.1.1.3.3.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.3.3">
               𝑠
              </ci>
             </apply>
             <apply id="S2.E4X.2.1.1.m1.2.2.1.1.1.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1">
              <times id="S2.E4X.2.1.1.m1.2.2.1.1.1.2.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.2">
              </times>
              <ci id="S2.E4X.2.1.1.m1.2.2.1.1.1.3.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.3">
               𝐵𝐶𝐸𝐿𝑜𝑠𝑠
              </ci>
              <interval closure="open" id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.2.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1">
               <apply id="S2.E4X.2.1.1.m1.1.1.cmml" xref="S2.E4X.2.1.1.m1.1.1">
                <ci id="S2.E4X.2.1.1.m1.1.1.1.cmml" xref="S2.E4X.2.1.1.m1.1.1.1">
                 ^
                </ci>
                <apply id="S2.E4X.2.1.1.m1.1.1.2.cmml" xref="S2.E4X.2.1.1.m1.1.1.2">
                 <csymbol cd="ambiguous" id="S2.E4X.2.1.1.m1.1.1.2.1.cmml" xref="S2.E4X.2.1.1.m1.1.1.2">
                  subscript
                 </csymbol>
                 <ci id="S2.E4X.2.1.1.m1.1.1.2.2.cmml" xref="S2.E4X.2.1.1.m1.1.1.2.2">
                  𝑌
                 </ci>
                 <ci id="S2.E4X.2.1.1.m1.1.1.2.3.cmml" xref="S2.E4X.2.1.1.m1.1.1.2.3">
                  𝑠
                 </ci>
                </apply>
               </apply>
               <apply id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1">
                <csymbol cd="ambiguous" id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1">
                 subscript
                </csymbol>
                <ci id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.2">
                 𝑌
                </ci>
                <ci id="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E4X.2.1.1.m1.2.2.1.1.1.1.1.1.3">
                 𝑠
                </ci>
               </apply>
              </interval>
             </apply>
            </apply>
            <apply id="S2.E4X.2.1.1.m1.3.3.2.2.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2">
             <eq id="S2.E4X.2.1.1.m1.3.3.2.2.1.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.1">
             </eq>
             <ci id="S2.E4X.2.1.1.m1.3.3.2.2.2.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.2">
              𝐿
             </ci>
             <apply id="S2.E4X.2.1.1.m1.3.3.2.2.3.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3">
              <apply id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1">
               <csymbol cd="ambiguous" id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.1.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1">
                superscript
               </csymbol>
               <apply id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1">
                <csymbol cd="ambiguous" id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.1.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1">
                 subscript
                </csymbol>
                <sum id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.2.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.2">
                </sum>
                <apply id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3">
                 <eq id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.1.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.1">
                 </eq>
                 <ci id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.2.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.2">
                  𝑠
                 </ci>
                 <cn id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.3.cmml" type="integer" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.2.3.3">
                  0
                 </cn>
                </apply>
               </apply>
               <cn id="S2.E4X.2.1.1.m1.3.3.2.2.3.1.3.cmml" type="integer" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.1.3">
                2
               </cn>
              </apply>
              <apply id="S2.E4X.2.1.1.m1.3.3.2.2.3.2.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.2">
               <csymbol cd="ambiguous" id="S2.E4X.2.1.1.m1.3.3.2.2.3.2.1.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.2">
                subscript
               </csymbol>
               <ci id="S2.E4X.2.1.1.m1.3.3.2.2.3.2.2.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.2.2">
                𝐿
               </ci>
               <ci id="S2.E4X.2.1.1.m1.3.3.2.2.3.2.3.cmml" xref="S2.E4X.2.1.1.m1.3.3.2.2.3.2.3">
                𝑠
               </ci>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S2.E4X.2.1.1.m1.3c">
           \displaystyle L_{s}=\mathit{BCELoss}(\hat{Y_{s}},Y_{s}),\;\;\;L=\sum_{s=0}^{2}L_{s}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equationgroup ltx_align_right">
         (4)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="S2.SS4.p3">
    <p class="ltx_p" id="S2.SS4.p3.1">
     <span class="ltx_text" id="S2.SS4.p3.1.1" style="font-size:90%;">
      Compared to Section
     </span>
     <a class="ltx_ref" href="#S2.SS2" style="font-size:90%;" title="2.2 Acoustic and language modeling ‣ 2 Proposed Method ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       2.2
      </span>
     </a>
     <span class="ltx_text" id="S2.SS4.p3.1.2" style="font-size:90%;">
      , the LLM is used not only as a text encoder, but also for instruction understanding, leveraging pretrained knowledge about the tasks. Furthermore, having independent task-specific binary classifiers enables scaling to additional speaker activity classes or multi-label tasks. The training setup fully utilizes all original samples for each task to update the corresponding classifier by prepending the appropriate instruction.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S2.SS4.p4">
    <p class="ltx_p" id="S2.SS4.p4.6">
     <span class="ltx_text" id="S2.SS4.p4.6.1" style="font-size:90%;">
      We also explore a variant of instruction fine-tuning with added dialogue history to contextualize the model’s interpretation. Here, two sentences preceding the target partial utterance, with speaker changes marked, are appended to the task-specific instruction, using the following format: “Identify
     </span>
     <math alttext="&lt;" class="ltx_Math" display="inline" id="S2.SS4.p4.1.m1.1">
      <semantics id="S2.SS4.p4.1.m1.1a">
       <mo id="S2.SS4.p4.1.m1.1.1" mathsize="90%" xref="S2.SS4.p4.1.m1.1.1.cmml">
        &lt;
       </mo>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p4.1.m1.1b">
        <lt id="S2.SS4.p4.1.m1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1">
        </lt>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p4.1.m1.1c">
        &lt;
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p4.6.2" style="font-size:90%;">
      instruction text
     </span>
     <math alttext="&gt;" class="ltx_Math" display="inline" id="S2.SS4.p4.2.m2.1">
      <semantics id="S2.SS4.p4.2.m2.1a">
       <mo id="S2.SS4.p4.2.m2.1.1" mathsize="90%" xref="S2.SS4.p4.2.m2.1.1.cmml">
        &gt;
       </mo>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p4.2.m2.1b">
        <gt id="S2.SS4.p4.2.m2.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1">
        </gt>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p4.2.m2.1c">
        &gt;
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p4.6.3" style="font-size:90%;">
      :
     </span>
     <math alttext="&lt;" class="ltx_Math" display="inline" id="S2.SS4.p4.3.m3.1">
      <semantics id="S2.SS4.p4.3.m3.1a">
       <mo id="S2.SS4.p4.3.m3.1.1" mathsize="90%" xref="S2.SS4.p4.3.m3.1.1.cmml">
        &lt;
       </mo>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p4.3.m3.1b">
        <lt id="S2.SS4.p4.3.m3.1.1.cmml" xref="S2.SS4.p4.3.m3.1.1">
        </lt>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p4.3.m3.1c">
        &lt;
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p4.6.4" style="font-size:90%;">
      history with speaker token
     </span>
     <math alttext="&gt;" class="ltx_Math" display="inline" id="S2.SS4.p4.4.m4.1">
      <semantics id="S2.SS4.p4.4.m4.1a">
       <mo id="S2.SS4.p4.4.m4.1.1" mathsize="90%" xref="S2.SS4.p4.4.m4.1.1.cmml">
        &gt;
       </mo>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p4.4.m4.1b">
        <gt id="S2.SS4.p4.4.m4.1.1.cmml" xref="S2.SS4.p4.4.m4.1.1">
        </gt>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p4.4.m4.1c">
        &gt;
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p4.6.5" style="font-size:90%;">
      .
     </span>
     <math alttext="&lt;" class="ltx_Math" display="inline" id="S2.SS4.p4.5.m5.1">
      <semantics id="S2.SS4.p4.5.m5.1a">
       <mo id="S2.SS4.p4.5.m5.1.1" mathsize="90%" xref="S2.SS4.p4.5.m5.1.1.cmml">
        &lt;
       </mo>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p4.5.m5.1b">
        <lt id="S2.SS4.p4.5.m5.1.1.cmml" xref="S2.SS4.p4.5.m5.1.1">
        </lt>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p4.5.m5.1c">
        &lt;
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p4.6.6" style="font-size:90%;">
      target sample with speaker token
     </span>
     <math alttext="&gt;" class="ltx_Math" display="inline" id="S2.SS4.p4.6.m6.1">
      <semantics id="S2.SS4.p4.6.m6.1a">
       <mo id="S2.SS4.p4.6.m6.1.1" mathsize="90%" xref="S2.SS4.p4.6.m6.1.1.cmml">
        &gt;
       </mo>
       <annotation-xml encoding="MathML-Content" id="S2.SS4.p4.6.m6.1b">
        <gt id="S2.SS4.p4.6.m6.1.1.cmml" xref="S2.SS4.p4.6.m6.1.1">
        </gt>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS4.p4.6.m6.1c">
        &gt;
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S2.SS4.p4.6.7" style="font-size:90%;">
      .”
     </span>
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="169" id="S2.F2.g1" src="/html/2401.14717/assets/Figure/Instruct.eps.png" width="350"/>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text ltx_font_bold" id="S2.F2.4.1.1">
       Fig. 2
      </span>
      :
     </span>
     LLM-based multi-task instruction fine-tuning for turn-taking, backchannel, and continuing speech prediction.
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section" style="font-size:90%;">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Experiments
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Dataset
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     <span class="ltx_text" id="S3.SS1.p1.1.1" style="font-size:90%;">
      We use the Switchboard corpus
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS1.p1.1.2.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib32" title="">
       32
      </a>
      <span class="ltx_text" id="S3.SS1.p1.1.3.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS1.p1.1.4" style="font-size:90%;">
      (
     </span>
     <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.5" style="font-size:90%;">
      Switchboard-1 Telephone Speech Corpus: Release 2
     </span>
     <span class="ltx_text" id="S3.SS1.p1.1.6" style="font-size:90%;">
      ). It is comprised of 2438 dyadic conversational dialogues involving 543 male and female speakers, who were connected by phone to converse about one of around 70 topics. The dataset consists of around 260 hours of audio with ground-truth transcripts comprising around 3 million words; word-level time alignments are also available. We use these symmetrical human-human dialogues to model appropriate system behavior for a conversational voice assistant when receiving user input. Though all data consists of human-human dialogue, we treat the currently active user’s speech as if input to a dialogue system, and the other (listening) speaker’s behavior as a model for how the system should behave. As discussed, the possible behaviors are “let current speaker continue”, “produce backchannel”, or “take a turn”. To utilize the data fully, user and system identities are swapped at each speaker change, i.e., when speaker A is active, A is the user and the system will try to behave as speaker B, and then vice versa for the next turn.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     <span class="ltx_text" id="S3.SS1.p2.1.1" style="font-size:90%;">
      Given ground-truth speaker-wise dialog transcripts and word alignments, we prepare the data in each session as follows: 1) Extract dialog sentences from each speaker, while simultaneously normalizing special annotations, including [silence]/[noise] removal, partial word completion, and mispronunciation correction, as in
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS1.p2.1.2.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      <span class="ltx_text" id="S3.SS1.p2.1.3.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS1.p2.1.4" style="font-size:90%;">
      . 2) Mark isolated one-word or two-word phrases as backchannel candidates. Backchannels are considered to be the 20 most frequent one and two-word phrases, such as “yeah”, “mmhmm” and “oh okay”, as summarized in
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS1.p2.1.5.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      <span class="ltx_text" id="S3.SS1.p2.1.6.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS1.p2.1.7" style="font-size:90%;">
      . 3) Combine the two speakers’ dialog sentences in start-time ascending order and break sentences into words, for the purpose of word-level labeling in the following steps. 4) Remove words marked as backchannels and save them in a candidate list along with their speaker, start-time and end-time attributes. 5) Mark all speaker changes as “Turn-taking” at last word spoken by a speaker. 6) Insert backchannel candidates back into the original dialogue according to their start-times and mark the word spoken by the other speaker where backchanneling occurs as “Backchannel”. If a word is marked by none of these two labels, the default label of “Continuing Speech“ is assigned.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p3">
    <p class="ltx_p" id="S3.SS1.p3.1">
     <span class="ltx_text" id="S3.SS1.p3.1.1" style="font-size:90%;">
      Note that overlapping speech is only recorded for backchannel utterances, but not for regular turns, which are serialized, in a way compatible with TurnGPT processing
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS1.p3.1.2.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      <span class="ltx_text" id="S3.SS1.p3.1.3.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS1.p3.1.4" style="font-size:90%;">
      . We leave the prediction of turn-taking with overlap
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS1.p3.1.5.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib33" title="">
       33
      </a>
      <span class="ltx_text" id="S3.SS1.p3.1.6.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS1.p3.1.7" style="font-size:90%;">
      for future work. (While overlapping turns are not uncommon for human-human dialog, a polite AI agent might refrain from producing them.)
After this preparation, each sample is a (partial) utterance (audio, text, or both) spoken by a single speaker, with the class label given by the last word’s label within the utterance. The data is split by session with train:validation:test ratio of 2000:300:138
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS1.p3.1.8.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      <span class="ltx_text" id="S3.SS1.p3.1.9.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS1.p3.1.10" style="font-size:90%;">
      .
     </span>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Training and evaluation scenarios
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     <span class="ltx_text" id="S3.SS2.p1.1.1" style="font-size:90%;">
      During training, since “Continuing Speech” is by far the majority class, a downsampling procedure is applied to samples of that class, such that that the label frequency equals the average number of “Backchannel” and “Turn-taking” samples. The resulting subset has “Continuing Speech”, “Backchannel”, and “Turn-Taking” occurring with counts 71k vs. 56k vs. 86k in training, and 6k vs. 5k vs. 7k for validation, respectively. During evaluation, all samples are used without downsampling, i.e., samples of each class in the test session will be decoded regardless of the class imbalance. The test set has samples with “Continuing Speech”, “Backchannel”, and “Turn-taking” with counts 123k, 2.3k and 3.2k, respectively.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     <span class="ltx_text" id="S3.SS2.p2.1.1" style="font-size:90%;">
      In TurnGPT
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS2.p2.1.2.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      <span class="ltx_text" id="S3.SS2.p2.1.3.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS2.p2.1.4" style="font-size:90%;">
      , the balanced accuracy (bAcc) over true and false turn-shifts is used as the evaluation metric. Here, since we have formulated three binary detection tasks, we prefer performance metrics that are independent of class priors and operating points (thresholds), namely, area-under-the-curve (AUC) and equal error rate (EER), evaluated for each class separately and in average.
The metrics are based on decision scores that are given by the logits for the targeted class, after softmax normalization.
     </span>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Experimental details
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.2">
     <span class="ltx_text" id="S3.SS3.p1.2.1" style="font-size:90%;">
      All frameworks are implemented using the Huggingface Transformers Library
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS3.p1.2.2.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib31" title="">
       31
      </a>
      <span class="ltx_text" id="S3.SS3.p1.2.3.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS3.p1.2.4" style="font-size:90%;">
      on 8 NVIDIA V100 GPUs. To validate the generalization of the proposed methods, two pretrained LLMs of different sizes are investigated, namely GPT2 (124M parameters)
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS3.p1.2.5.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib26" title="">
       26
      </a>
      <span class="ltx_text" id="S3.SS3.p1.2.6.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS3.p1.2.7" style="font-size:90%;">
      and RedPajama (3B parameters)
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS3.p1.2.8.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib27" title="">
       27
      </a>
      <span class="ltx_text" id="S3.SS3.p1.2.9.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS3.p1.2.10" style="font-size:90%;">
      . For GPT2, the entire model is unfrozen for LLM fine-tuning and fusion Option 1. For RedPajama, a parameter-efficient fine-tuning approach, LoRA
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS3.p1.2.11.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib34" title="">
       34
      </a>
      <span class="ltx_text" id="S3.SS3.p1.2.12.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS3.p1.2.13" style="font-size:90%;">
      with a rank of 32, is applied in LLM fine-tuning and fusion Option 1, resulting in around 0.4% (
     </span>
     <math alttext="\approx" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1">
      <semantics id="S3.SS3.p1.1.m1.1a">
       <mo id="S3.SS3.p1.1.m1.1.1" mathsize="90%" xref="S3.SS3.p1.1.m1.1.1.cmml">
        ≈
       </mo>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b">
        <approx id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">
        </approx>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">
        \approx
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S3.SS3.p1.2.14" style="font-size:90%;">
      10M) trainable parameters. All models are trained with learning rate
     </span>
     <math alttext="5\times 10^{-5}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1">
      <semantics id="S3.SS3.p1.2.m2.1a">
       <mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">
        <mn id="S3.SS3.p1.2.m2.1.1.2" mathsize="90%" xref="S3.SS3.p1.2.m2.1.1.2.cmml">
         5
        </mn>
        <mo id="S3.SS3.p1.2.m2.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.SS3.p1.2.m2.1.1.1.cmml">
         ×
        </mo>
        <msup id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">
         <mn id="S3.SS3.p1.2.m2.1.1.3.2" mathsize="90%" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">
          10
         </mn>
         <mrow id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">
          <mo id="S3.SS3.p1.2.m2.1.1.3.3a" mathsize="90%" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">
           −
          </mo>
          <mn id="S3.SS3.p1.2.m2.1.1.3.3.2" mathsize="90%" xref="S3.SS3.p1.2.m2.1.1.3.3.2.cmml">
           5
          </mn>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b">
        <apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">
         <times id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1">
         </times>
         <cn id="S3.SS3.p1.2.m2.1.1.2.cmml" type="integer" xref="S3.SS3.p1.2.m2.1.1.2">
          5
         </cn>
         <apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3">
           superscript
          </csymbol>
          <cn id="S3.SS3.p1.2.m2.1.1.3.2.cmml" type="integer" xref="S3.SS3.p1.2.m2.1.1.3.2">
           10
          </cn>
          <apply id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">
           <minus id="S3.SS3.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">
           </minus>
           <cn id="S3.SS3.p1.2.m2.1.1.3.3.2.cmml" type="integer" xref="S3.SS3.p1.2.m2.1.1.3.3.2">
            5
           </cn>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">
        5\times 10^{-5}
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text" id="S3.SS3.p1.2.15" style="font-size:90%;">
      , number of epochs 5, and batch size 4. All other hyperparameters are set to the default values provided by the Transformer library
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S3.SS3.p1.2.16.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib31" title="">
       31
      </a>
      <span class="ltx_text" id="S3.SS3.p1.2.17.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S3.SS3.p1.2.18" style="font-size:90%;">
      .
     </span>
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section" style="font-size:90%;">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Results
  </h2>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Single modality versus fusion
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     <span class="ltx_text" id="S4.SS1.p1.1.1" style="font-size:90%;">
      Experimental results for single modalities and the two fusion approaches are reported in Table
     </span>
     <a class="ltx_ref" href="#S4.T1" style="font-size:90%;" title="Table 1 ‣ 4.1 Single modality versus fusion ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S4.SS1.p1.1.2" style="font-size:90%;">
      . First, with single modalities, language models yield much better performances than acoustic models. Second, by comparing the text-only models based on LLMs, it turns out that even though fine-tuning RedPajama results in significantly fewer trainable parameter than fully fine-tuning GPT2, RedPajama still achieves comparable performance, with an average AUC of 0.8351, as compared to 0.8292 for GPT2. This result indicates that RedPajama, as a larger LLM, has higher efficiency and greater potential for modeling conversational dialogue, and benefits more from approaches that exploit the model’s language understanding capabilities, such as the proposed instruction fine-tuning.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     <span class="ltx_text" id="S4.SS1.p2.1.1" style="font-size:90%;">
      Under the same LLM setup, both fusion approaches achieve significant improvements over models with single modality, as shown in Table
     </span>
     <a class="ltx_ref" href="#S4.T1" style="font-size:90%;" title="Table 1 ‣ 4.1 Single modality versus fusion ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S4.SS1.p2.1.2" style="font-size:90%;">
      . For instance, the fusion model with RedPajama + HuBERT + Opt1 achieves the best performance for all three classes with an average AUC of 0.8657, leading to relative improvements of 22.6% and 3.67% over the best acoustic and text single modality models, respectively. Moreover, by comparing the three classes, predicting “Continuing Speech” and “Turn-taking” benefits most from the fusion, while “Backchannel” only shows a small improvement. This result aligns with known properties of these turn-management events, where “Turn-taking” and “Continuing speech” are strongly cued by intonation and duration features, whereas “Backchannel” is possibly more related to syntactic and semantic information. In addition, the difference between Opt1 and Opt2 does not share the same pattern for GPT2 and RedPajama. RedPajama works better with Opt1. We suspect that GPT2 has relatively limited modeling capacity. Unfreezing the larger RedPajama model will learn information that better complements the acoustic information.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p3">
    <p class="ltx_p" id="S4.SS1.p3.1">
     <span class="ltx_text" id="S4.SS1.p3.1.1" style="font-size:90%;">
      We aimed to compare our model with TurnGPT
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" id="S4.SS1.p3.1.2.1" style="font-size:90%;">
       [
      </span>
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      <span class="ltx_text" id="S4.SS1.p3.1.3.2" style="font-size:90%;">
       ]
      </span>
     </cite>
     <span class="ltx_text" id="S4.SS1.p3.1.4" style="font-size:90%;">
      , where bAcc of 0.789 and 0.823 were reported for the “Spoken” dataset (of which Switchboard makes up the majority) with training on ”Assistant” and ”Full” datasets, respectively. We obtained a similar bAcc of 0.8002 for the GPT2-only model when focusing only on “Turn-taking” and “Continuing Speech” samples. Though this is not an apples-to-apples comparison, as the evaluation samples could be different, it shows that our LLM is comparable to TurnGPT when we leave out backchanneling. In this focused two-class evaluation, we obtain an improved bAcc of 0.8578 for the RedPajama + HuBERT + Opt1 fusion model, confirming the benefit of complementing lexical with acoustic information.
     </span>
    </p>
   </div>
   <figure class="ltx_table" id="S4.T1">
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text ltx_font_bold" id="S4.T1.4.1.1">
       Table 1
      </span>
      :
     </span>
     Results for single modality and fusion models.
    </figcaption>
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.5" style="width:433.6pt;height:153.3pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(13.2pt,-4.7pt) scale(1.06488048174532,1.06488048174532) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.5.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="S4.T1.5.1.1.1">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.1">
          <span class="ltx_text" id="S4.T1.5.1.1.1.1.1" style="font-size:90%;">
           Method
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.2">
          <span class="ltx_text" id="S4.T1.5.1.1.1.2.1" style="font-size:90%;">
           AUC(Cont)
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.3">
          <span class="ltx_text" id="S4.T1.5.1.1.1.3.1" style="font-size:90%;">
           AUC(Back)
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.4">
          <span class="ltx_text" id="S4.T1.5.1.1.1.4.1" style="font-size:90%;">
           AUC(Turn)
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.5">
          <span class="ltx_text" id="S4.T1.5.1.1.1.5.1" style="font-size:90%;">
           AUC(avg)
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.1.1.6">
          <span class="ltx_text" id="S4.T1.5.1.1.1.6.1" style="font-size:90%;">
           EER(avg)
          </span>
         </th>
        </tr>
        <tr class="ltx_tr" id="S4.T1.5.1.2.2">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.1">
          <span class="ltx_text" id="S4.T1.5.1.2.2.1.1" style="font-size:90%;">
           HuBERT
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.2">
          <span class="ltx_text" id="S4.T1.5.1.2.2.2.1" style="font-size:90%;">
           0.7323
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.3">
          <span class="ltx_text" id="S4.T1.5.1.2.2.3.1" style="font-size:90%;">
           0.6455
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.4">
          <span class="ltx_text" id="S4.T1.5.1.2.2.4.1" style="font-size:90%;">
           0.7401
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.5">
          <span class="ltx_text" id="S4.T1.5.1.2.2.5.1" style="font-size:90%;">
           0.7060
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.6">
          <span class="ltx_text" id="S4.T1.5.1.2.2.6.1" style="font-size:90%;">
           34.87
          </span>
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S4.T1.5.1.3.1">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.1">
          <span class="ltx_text" id="S4.T1.5.1.3.1.1.1" style="font-size:90%;">
           GPT2
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.2">
          <span class="ltx_text" id="S4.T1.5.1.3.1.2.1" style="font-size:90%;">
           0.8510
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.3">
          <span class="ltx_text" id="S4.T1.5.1.3.1.3.1" style="font-size:90%;">
           0.7744
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.4">
          <span class="ltx_text" id="S4.T1.5.1.3.1.4.1" style="font-size:90%;">
           0.8623
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.5">
          <span class="ltx_text" id="S4.T1.5.1.3.1.5.1" style="font-size:90%;">
           0.8292
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.6">
          <span class="ltx_text" id="S4.T1.5.1.3.1.6.1" style="font-size:90%;">
           24.47
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T1.5.1.4.2">
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.1">
          <span class="ltx_text" id="S4.T1.5.1.4.2.1.1" style="font-size:90%;">
           + HuBERT Opt1
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.2">
          <span class="ltx_text" id="S4.T1.5.1.4.2.2.1" style="font-size:90%;">
           0.8783
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.3">
          <span class="ltx_text" id="S4.T1.5.1.4.2.3.1" style="font-size:90%;">
           0.7798
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.4">
          <span class="ltx_text" id="S4.T1.5.1.4.2.4.1" style="font-size:90%;">
           0.884
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.5">
          <span class="ltx_text" id="S4.T1.5.1.4.2.5.1" style="font-size:90%;">
           0.8474
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.6">
          <span class="ltx_text" id="S4.T1.5.1.4.2.6.1" style="font-size:90%;">
           22.63
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T1.5.1.5.3">
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.1">
          <span class="ltx_text" id="S4.T1.5.1.5.3.1.1" style="font-size:90%;">
           + HuBERT Opt2
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.2">
          <span class="ltx_text" id="S4.T1.5.1.5.3.2.1" style="font-size:90%;">
           0.8778
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.3">
          <span class="ltx_text ltx_font_bold" id="S4.T1.5.1.5.3.3.1" style="font-size:90%;">
           0.7862
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.4">
          <span class="ltx_text" id="S4.T1.5.1.5.3.4.1" style="font-size:90%;">
           0.8859
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.5">
          <span class="ltx_text" id="S4.T1.5.1.5.3.5.1" style="font-size:90%;">
           0.8500
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.6">
          <span class="ltx_text" id="S4.T1.5.1.5.3.6.1" style="font-size:90%;">
           22.77
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T1.5.1.6.4">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.1">
          <span class="ltx_text" id="S4.T1.5.1.6.4.1.1" style="font-size:90%;">
           RedPajama
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.2">
          <span class="ltx_text" id="S4.T1.5.1.6.4.2.1" style="font-size:90%;">
           0.8629
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.3">
          <span class="ltx_text" id="S4.T1.5.1.6.4.3.1" style="font-size:90%;">
           0.7739
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.4">
          <span class="ltx_text" id="S4.T1.5.1.6.4.4.1" style="font-size:90%;">
           0.8685
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.5">
          <span class="ltx_text" id="S4.T1.5.1.6.4.5.1" style="font-size:90%;">
           0.8351
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.6">
          <span class="ltx_text" id="S4.T1.5.1.6.4.6.1" style="font-size:90%;">
           23.60
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T1.5.1.7.5">
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.1">
          <span class="ltx_text" id="S4.T1.5.1.7.5.1.1" style="font-size:90%;">
           + HuBERT Opt1
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.2">
          <span class="ltx_text ltx_font_bold" id="S4.T1.5.1.7.5.2.1" style="font-size:90%;">
           0.8992
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.3">
          <span class="ltx_text ltx_font_bold" id="S4.T1.5.1.7.5.3.1" style="font-size:90%;">
           0.7862
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.4">
          <span class="ltx_text ltx_font_bold" id="S4.T1.5.1.7.5.4.1" style="font-size:90%;">
           0.9116
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.5">
          <span class="ltx_text ltx_font_bold" id="S4.T1.5.1.7.5.5.1" style="font-size:90%;">
           0.8657
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.6">
          <span class="ltx_text ltx_font_bold" id="S4.T1.5.1.7.5.6.1" style="font-size:90%;">
           20.33
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T1.5.1.8.6">
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.8.6.1">
          <span class="ltx_text" id="S4.T1.5.1.8.6.1.1" style="font-size:90%;">
           + HuBERT Opt2
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.8.6.2">
          <span class="ltx_text" id="S4.T1.5.1.8.6.2.1" style="font-size:90%;">
           0.8982
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.8.6.3">
          <span class="ltx_text" id="S4.T1.5.1.8.6.3.1" style="font-size:90%;">
           0.7743
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.8.6.4">
          <span class="ltx_text" id="S4.T1.5.1.8.6.4.1" style="font-size:90%;">
           0.9006
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.8.6.5">
          <span class="ltx_text" id="S4.T1.5.1.8.6.5.1" style="font-size:90%;">
           0.8577
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.8.6.6">
          <span class="ltx_text" id="S4.T1.5.1.8.6.6.1" style="font-size:90%;">
           21.57
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Multi-task instruction fine-tuning
   </h3>
   <figure class="ltx_table" id="S4.T2">
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1">
       Table 2
      </span>
      :
     </span>
     Results with multi-task instruction fine-tuning.
    </figcaption>
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.5" style="width:433.6pt;height:168.6pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(8.5pt,-3.3pt) scale(1.04072810814655,1.04072810814655) ;">
      <table class="ltx_tabular ltx_align_middle" id="S4.T2.5.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S4.T2.5.1.1.1">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.1.1.1">
          <span class="ltx_text" id="S4.T2.5.1.1.1.1.1" style="font-size:90%;">
           Method
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.1.1.2">
          <span class="ltx_text" id="S4.T2.5.1.1.1.2.1" style="font-size:90%;">
           AUC(Cont)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.1.1.3">
          <span class="ltx_text" id="S4.T2.5.1.1.1.3.1" style="font-size:90%;">
           AUC(Back)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.1.1.4">
          <span class="ltx_text" id="S4.T2.5.1.1.1.4.1" style="font-size:90%;">
           AUC(Turn)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.1.1.5">
          <span class="ltx_text" id="S4.T2.5.1.1.1.5.1" style="font-size:90%;">
           AUC(avg)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.1.1.6">
          <span class="ltx_text" id="S4.T2.5.1.1.1.6.1" style="font-size:90%;">
           EER(avg)
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.2.2">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.2.1">
          <span class="ltx_text" id="S4.T2.5.1.2.2.1.1" style="font-size:90%;">
           GPT2
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.2.2">
          <span class="ltx_text" id="S4.T2.5.1.2.2.2.1" style="font-size:90%;">
           0.8416
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.2.3">
          <span class="ltx_text" id="S4.T2.5.1.2.2.3.1" style="font-size:90%;">
           0.7863
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.2.4">
          <span class="ltx_text" id="S4.T2.5.1.2.2.4.1" style="font-size:90%;">
           0.8582
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.2.5">
          <span class="ltx_text" id="S4.T2.5.1.2.2.5.1" style="font-size:90%;">
           0.8287
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.2.2.6">
          <span class="ltx_text" id="S4.T2.5.1.2.2.6.1" style="font-size:90%;">
           24.13
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.3.3">
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.3.1">
          <span class="ltx_text" id="S4.T2.5.1.3.3.1.1" style="font-size:90%;">
           + HuBERT Opt1
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.3.2">
          <span class="ltx_text" id="S4.T2.5.1.3.3.2.1" style="font-size:90%;">
           0.8726
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.3.3">
          <span class="ltx_text" id="S4.T2.5.1.3.3.3.1" style="font-size:90%;">
           0.7901
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.3.4">
          <span class="ltx_text" id="S4.T2.5.1.3.3.4.1" style="font-size:90%;">
           0.8766
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.3.5">
          <span class="ltx_text" id="S4.T2.5.1.3.3.5.1" style="font-size:90%;">
           0.8464
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.3.3.6">
          <span class="ltx_text" id="S4.T2.5.1.3.3.6.1" style="font-size:90%;">
           22.50
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.4.4">
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.4.1">
          <span class="ltx_text" id="S4.T2.5.1.4.4.1.1" style="font-size:90%;">
           + HuBERT Opt2
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.4.2">
          <span class="ltx_text" id="S4.T2.5.1.4.4.2.1" style="font-size:90%;">
           0.8806
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.4.3">
          <span class="ltx_text" id="S4.T2.5.1.4.4.3.1" style="font-size:90%;">
           0.7838
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.4.4">
          <span class="ltx_text" id="S4.T2.5.1.4.4.4.1" style="font-size:90%;">
           0.8890
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.4.5">
          <span class="ltx_text" id="S4.T2.5.1.4.4.5.1" style="font-size:90%;">
           0.8511
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.4.6">
          <span class="ltx_text" id="S4.T2.5.1.4.4.6.1" style="font-size:90%;">
           22.23
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.5.5">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.5.5.1">
          <span class="ltx_text" id="S4.T2.5.1.5.5.1.1" style="font-size:90%;">
           RedPajama
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.5.5.2">
          <span class="ltx_text" id="S4.T2.5.1.5.5.2.1" style="font-size:90%;">
           0.8668
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.5.5.3">
          <span class="ltx_text" id="S4.T2.5.1.5.5.3.1" style="font-size:90%;">
           0.8097
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.5.5.4">
          <span class="ltx_text" id="S4.T2.5.1.5.5.4.1" style="font-size:90%;">
           0.8796
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.5.5.5">
          <span class="ltx_text" id="S4.T2.5.1.5.5.5.1" style="font-size:90%;">
           0.8520
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.5.5.6">
          <span class="ltx_text" id="S4.T2.5.1.5.5.6.1" style="font-size:90%;">
           21.80
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.6.6">
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.6.6.1">
          <span class="ltx_text" id="S4.T2.5.1.6.6.1.1" style="font-size:90%;">
           + HuBERT Opt1
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.6.6.2">
          <span class="ltx_text" id="S4.T2.5.1.6.6.2.1" style="font-size:90%;">
           0.9000
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.6.6.3">
          <span class="ltx_text ltx_font_bold" id="S4.T2.5.1.6.6.3.1" style="font-size:90%;">
           0.8229
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.6.6.4">
          <span class="ltx_text" id="S4.T2.5.1.6.6.4.1" style="font-size:90%;">
           0.9127
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.6.6.5">
          <span class="ltx_text" id="S4.T2.5.1.6.6.5.1" style="font-size:90%;">
           0.8785
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.6.6.6">
          <span class="ltx_text" id="S4.T2.5.1.6.6.6.1" style="font-size:90%;">
           19.50
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.7.7">
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.7.1">
          <span class="ltx_text" id="S4.T2.5.1.7.7.1.1" style="font-size:90%;">
           + HuBERT Opt2
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.7.2">
          <span class="ltx_text" id="S4.T2.5.1.7.7.2.1" style="font-size:90%;">
           0.8980
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.7.3">
          <span class="ltx_text" id="S4.T2.5.1.7.7.3.1" style="font-size:90%;">
           0.8182
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.7.4">
          <span class="ltx_text" id="S4.T2.5.1.7.7.4.1" style="font-size:90%;">
           0.9129
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.7.5">
          <span class="ltx_text" id="S4.T2.5.1.7.7.5.1" style="font-size:90%;">
           0.8764
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.7.6">
          <span class="ltx_text" id="S4.T2.5.1.7.7.6.1" style="font-size:90%;">
           19.60
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.8.8">
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.8.8.1">
          <span class="ltx_text" id="S4.T2.5.1.8.8.1.1" style="font-size:90%;">
           RedPajama + History
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.8.8.2">
          <span class="ltx_text" id="S4.T2.5.1.8.8.2.1" style="font-size:90%;">
           0.8747
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.8.8.3">
          <span class="ltx_text" id="S4.T2.5.1.8.8.3.1" style="font-size:90%;">
           0.8074
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.8.8.4">
          <span class="ltx_text" id="S4.T2.5.1.8.8.4.1" style="font-size:90%;">
           0.8912
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.8.8.5">
          <span class="ltx_text" id="S4.T2.5.1.8.8.5.1" style="font-size:90%;">
           0.8578
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.8.8.6">
          <span class="ltx_text" id="S4.T2.5.1.8.8.6.1" style="font-size:90%;">
           21.63
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.5.1.9.9">
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.9.9.1">
          <span class="ltx_text" id="S4.T2.5.1.9.9.1.1" style="font-size:90%;">
           + HuBERT Opt1
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.9.9.2">
          <span class="ltx_text ltx_font_bold" id="S4.T2.5.1.9.9.2.1" style="font-size:90%;">
           0.9029
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.9.9.3">
          <span class="ltx_text" id="S4.T2.5.1.9.9.3.1" style="font-size:90%;">
           0.8184
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.9.9.4">
          <span class="ltx_text ltx_font_bold" id="S4.T2.5.1.9.9.4.1" style="font-size:90%;">
           0.9197
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.9.9.5">
          <span class="ltx_text ltx_font_bold" id="S4.T2.5.1.9.9.5.1" style="font-size:90%;">
           0.8803
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.9.9.6">
          <span class="ltx_text ltx_font_bold" id="S4.T2.5.1.9.9.6.1" style="font-size:90%;">
           19.30
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
   </figure>
   <figure class="ltx_figure" id="S4.F3">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S4.F3.1">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="429" id="S4.F3.1.g1" src="/html/2401.14717/assets/Figure/ROC_turn_new.png" width="592"/>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S4.F3.2">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="429" id="S4.F3.2.g1" src="/html/2401.14717/assets/Figure/ROC_back_new.png" width="592"/>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text ltx_font_bold" id="S4.F3.6.1.1">
       Fig. 3
      </span>
      :
     </span>
     ROC plots for turn-taking (left) and backchannel (right).
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S4.F4">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S4.F4.1">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="414" id="S4.F4.1.g1" src="/html/2401.14717/assets/Figure/Score_distribution_back.png" width="592"/>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S4.F4.2">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="523" id="S4.F4.2.g1" src="/html/2401.14717/assets/Figure/Example1_new.png" width="592"/>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text ltx_font_bold" id="S4.F4.6.1.1">
       Fig. 4
      </span>
      :
     </span>
     Left: backchannel score distribution for the positive and negative samples. Right: a sentence example with token-level backchannel score. The markers represent the ground-truth token labels.
    </figcaption>
   </figure>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     <span class="ltx_text" id="S4.SS2.p1.1.1" style="font-size:90%;">
      Results for multi-task instruction fine-tuning are reported in Table
     </span>
     <a class="ltx_ref" href="#S4.T2" style="font-size:90%;" title="Table 2 ‣ 4.2 Multi-task instruction fine-tuning ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     <span class="ltx_text" id="S4.SS2.p1.1.2" style="font-size:90%;">
      . For GPT2, it shows that applying instruction fine-tuning only results in a very minor differences to Table
     </span>
     <a class="ltx_ref" href="#S4.T1" style="font-size:90%;" title="Table 1 ‣ 4.1 Single modality versus fusion ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S4.SS2.p1.1.3" style="font-size:90%;">
      . However, when replacing GPT2 with RedPajama, significant improvements on average AUC and EER are observed for all three modeling approaches, with relative improvements of 2.02%, 1.5% and 2.16% on average AUC for RedPajama, RedPajama + HuBERT Opt1 and Opt2, respectively. Moreover, RedPajama + HuBERT + Opt1 with multi-task instruction fine-tuning achieves the best performance for all the cases without the dialogue history, with an average AUC of 0.8785.
     </span>
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     <span class="ltx_text" id="S4.SS2.p2.1.1" style="font-size:90%;">
      More interestingly, comparing to the results without the instruction fine-tuning in Table
     </span>
     <a class="ltx_ref" href="#S4.T1" style="font-size:90%;" title="Table 1 ‣ 4.1 Single modality versus fusion ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     <span class="ltx_text" id="S4.SS2.p2.1.2" style="font-size:90%;">
      , “Backchannel” prediction sees the highest AUC gain from applying the multi-task instruction fine-tuning, compared to other classes. Figure
     </span>
     <a class="ltx_ref" href="#S4.F3" style="font-size:90%;" title="Figure 3 ‣ 4.2 Multi-task instruction fine-tuning ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     <span class="ltx_text" id="S4.SS2.p2.1.3" style="font-size:90%;">
      shows the ROC curves for Turn-taking and Backchannel. It is clear here that Turn-taking benefits remarkably from the fusion, but benefits minimally from the instruction fine-tuning, while Backchannel shows the opposite trend. We conducted a further analysis by calculating the Backchannel score distribution of the samples. As shown in the left plot in Figure
     </span>
     <a class="ltx_ref" href="#S4.F4" style="font-size:90%;" title="Figure 4 ‣ 4.2 Multi-task instruction fine-tuning ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     <span class="ltx_text" id="S4.SS2.p2.1.4" style="font-size:90%;">
      , applying instruction fine-tuning helps to push the score distribution of the backchannel (positive) samples and non-backchannel (negative) samples higher and lower, respectively. The right portion of Figure
     </span>
     <a class="ltx_ref" href="#S4.F4" style="font-size:90%;" title="Figure 4 ‣ 4.2 Multi-task instruction fine-tuning ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     <span class="ltx_text" id="S4.SS2.p2.1.5" style="font-size:90%;">
      shows an example, with a transcript of “It gets very uncomfortable on hills, most the teachers have taking
     </span>
     <span class="ltx_note ltx_role_footnote" id="footnote1">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         1
        </sup>
        <span class="ltx_tag ltx_tag_note">
         1
        </span>
        The provided corpus transcription. The actual word spoken is “taken”.
       </span>
      </span>
     </span>
     <span class="ltx_text" id="S4.SS2.p2.1.6" style="font-size:90%;">
      to wearing uh track shoes”, the model with instruction fine-tuning correctly predicts the backchannel behavior after “hills”, while the model without predicts a backchannel after “uncomfortable”. This observation also supports our earlier conjecture that backchanneling is a speech activity best predicted by syntactic/semantic context. These results demonstrate that RedPajama benefits from multi-task instruction fine-tuning for better task understanding and more accurate backchannel prediction.
     </span>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Instruction fine-tuning with dialogue history
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     <span class="ltx_text" id="S4.SS3.p1.1.1" style="font-size:90%;">
      The last section of Table
     </span>
     <a class="ltx_ref" href="#S4.T2" style="font-size:90%;" title="Table 2 ‣ 4.2 Multi-task instruction fine-tuning ‣ 4 Results ‣ Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     <span class="ltx_text" id="S4.SS3.p1.1.2" style="font-size:90%;">
      shows the results for multi-task instruction fine-tuning with added dialogue history. As described earlier, a dialogue history of two sentences is included in the instruction, prepended to each sample utterance. Compared to the instruction fine-tuning results without history, average AUC and EER improve with history. However, when looking at each class individually, both “Turn-taking” and “Continuing Speech” classes are predicted better with history information, while the “Backchannel” class sees a slight degradation. This could be because backchanneling is largely a locally-cued behavior and affected little by long-term context.
     </span>
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section" style="font-size:90%;">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Conclusions
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    <span class="ltx_text" id="S5.p1.1.1" style="font-size:90%;">
     We have proposed a fusion model for turn-taking and backchannel prediction in spoken dialogue, combining both LLM and acoustic modeling. We experimented with LLMs of various sizes (GPT2 and RedPajama) and used HuBERT for modeling acoustic cues, to leverage both representations and prior knowledge learned from pretraining. Experiments demonstrate that our fusion approach consistently outperforms the baseline models with single modality, which indicates that joint modeling is effective at exploiting the complementarity of the modalities. Moreover, the proposed multi-task instruction fine-tuning strategy leverages LLMs for better task understanding and further improvements. Our approach provides a solution for more accurate causal turn-taking and backchannel prediction, ultimately enabling more natural and conversational human-agent interactions. In future work, it will be worth investigating how the use of automatic instead of ground-truth transcriptions would affect results, as required for inference in real-time applications.
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib1.1.1" style="font-size:80%;">
      Matthew B. Hoy,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib1.2.1" style="font-size:80%;">
      “Alexa, Siri, Cortana, and more: an introduction to voice
assistants,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib1.3.1" style="font-size:80%;">
      Medical reference services quarterly
     </span>
     <span class="ltx_text" id="bib.bib1.4.2" style="font-size:80%;">
      , vol. 37, no. 1, pp.
81–88, 2018.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib2.1.1" style="font-size:80%;">
      Ramin Yaghoubzadeh, Marcel Kramer, Karola Pitsch, and Stefan Kopp,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib2.2.1" style="font-size:80%;">
      “Virtual agents as daily assistants for elderly or cognitively
impaired people: Studies on acceptance and interaction feasibility,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib2.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib2.4.2" style="font-size:80%;">
      Intelligent Virtual Agents
     </span>
     <span class="ltx_text" id="bib.bib2.5.3" style="font-size:80%;">
      , 2013, pp. 79–91.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib3.1.1" style="font-size:80%;">
      Pranav Rane, Varun Mhatre, and Lakshmi Kurup,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib3.2.1" style="font-size:80%;">
      “Study of a home robot: Jibo,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib3.3.1" style="font-size:80%;">
      International journal of engineering research and technology
     </span>
     <span class="ltx_text" id="bib.bib3.4.2" style="font-size:80%;">
      ,
vol. 3, no. 10, pp. 490–493, 2014.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.1.1" style="font-size:80%;">
      Nigel G. Ward and David DeVault,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.2.1" style="font-size:80%;">
      “Ten challenges in highly-interactive dialog system.,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib4.4.2" style="font-size:80%;">
      AAAI Spring Symposium
     </span>
     <span class="ltx_text" id="bib.bib4.5.3" style="font-size:80%;">
      , 2015.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib5.1.1" style="font-size:80%;">
      Divesh Lala, Koji Inoue, and Tatsuya Kawahara,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib5.2.1" style="font-size:80%;">
      “Evaluation of real-time deep learning turn-taking models for
multiple dialogue scenarios,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib5.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib5.4.2" style="font-size:80%;">
      Proc. ACM ICMI
     </span>
     <span class="ltx_text" id="bib.bib5.5.3" style="font-size:80%;">
      , 2018, pp. 78–86.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib6.1.1" style="font-size:80%;">
      Shuo-yiin Chang, Bo Li, Tara N Sainath, Chao Zhang, Trevor Strohman, Qiao
Liang, and Yanzhang He,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib6.2.1" style="font-size:80%;">
      “Turn-taking prediction for natural conversational speech,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib6.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib6.4.2" style="font-size:80%;">
      Proc. Interspeech
     </span>
     <span class="ltx_text" id="bib.bib6.5.3" style="font-size:80%;">
      , 2022, pp. 1821–1825.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib7.1.1" style="font-size:80%;">
      Gabriel Skantze, Anna Hjalmarsson, and Catharine Oertel,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib7.2.1" style="font-size:80%;">
      “Turn-taking, feedback and joint attention in situated human-robot
interaction,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib7.3.1" style="font-size:80%;">
      Speech Communication
     </span>
     <span class="ltx_text" id="bib.bib7.4.2" style="font-size:80%;">
      , vol. 65, pp. 50–66, 2014.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.1.1" style="font-size:80%;">
      Nigel G. Ward, Olac Fuentes, and Alejandro Vega,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.2.1" style="font-size:80%;">
      “Dialog prediction for a general model of turn-taking,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib8.4.2" style="font-size:80%;">
      Proc. Interspeech
     </span>
     <span class="ltx_text" id="bib.bib8.5.3" style="font-size:80%;">
      , 2010, pp. 2662–2665.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.1.1" style="font-size:80%;">
      Zakaria Aldeneh, Dimitrios Dimitriadis, and Emily Mower Provost,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.2.1" style="font-size:80%;">
      “Improving end-of-turn detection in spoken dialogues by detecting
speaker intentions as a secondary task,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib9.4.2" style="font-size:80%;">
      Proc. ICASSP
     </span>
     <span class="ltx_text" id="bib.bib9.5.3" style="font-size:80%;">
      , 2018, pp. 6159–6163.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.1.1" style="font-size:80%;">
      Erik Ekstedt and Gabriel Skantze,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.2.1" style="font-size:80%;">
      “Voice activity projection: Self-supervised learning of turn-taking
events,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib10.4.2" style="font-size:80%;">
      Proc. Interspeech
     </span>
     <span class="ltx_text" id="bib.bib10.5.3" style="font-size:80%;">
      , 2022, pp. 5190–5194.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib11.1.1" style="font-size:80%;">
      Gabriel Skantze,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib11.2.1" style="font-size:80%;">
      “Turn-taking in conversational systems and human-robot interaction:
a review,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib11.3.1" style="font-size:80%;">
      Computer Speech &amp; Language
     </span>
     <span class="ltx_text" id="bib.bib11.4.2" style="font-size:80%;">
      , vol. 67, pp. 101178, 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.1.1" style="font-size:80%;">
      Markus Mueller, David Leuschner, Lars Briem, Maria Schmidt, Kevin Kilgour,
Sebastian Stueker, and Alex Waibel,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.2.1" style="font-size:80%;">
      “Using neural networks for data-driven backchannel prediction: A
survey on input features and training techniques,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib12.4.2" style="font-size:80%;">
      Human-Computer Interaction: Interaction Technologies
     </span>
     <span class="ltx_text" id="bib.bib12.5.3" style="font-size:80%;">
      , 2015,
pp. 329–340.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib13.1.1" style="font-size:80%;">
      Daniel Ortega, Chia-Yu Li, and Ngoc Thang Vu,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib13.2.1" style="font-size:80%;">
      “Oh, jeez! or uh-huh? a listener-aware backchannel predictor on
ASR transcriptions,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib13.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib13.4.2" style="font-size:80%;">
      Proc. IEEE ICASSP
     </span>
     <span class="ltx_text" id="bib.bib13.5.3" style="font-size:80%;">
      , 2020, pp. 8064–8068.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib14.1.1" style="font-size:80%;">
      Tatsuya Kawahara, Takashi Yamaguchi, Koji Inoue, Katsuya Takanashi, and Nigel G
Ward,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib14.2.1" style="font-size:80%;">
      “Prediction and generation of backchannel form for attentive
listening systems.,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib14.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib14.4.2" style="font-size:80%;">
      Interspeech
     </span>
     <span class="ltx_text" id="bib.bib14.5.3" style="font-size:80%;">
      , 2016, pp. 2890–2894.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.1.1" style="font-size:80%;">
      Harvey Sacks, Emanuel A. Schegloff, and Gail Jefferson,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.2.1" style="font-size:80%;">
      “A simplest systematics for the organization of turn taking for
conversation,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib15.4.2" style="font-size:80%;">
      Studies in the organization of conversational interaction
     </span>
     <span class="ltx_text" id="bib.bib15.5.3" style="font-size:80%;">
      ,
pp. 7–55. Elsevier, 1978.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.1.1" style="font-size:80%;">
      Gabriel Skantze,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.2.1" style="font-size:80%;">
      “Towards a general, continuous model of turn-taking in spoken
dialogue using LSTM recurrent neural networks,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib16.4.2" style="font-size:80%;">
      Proceedings of the 18th Annual SIGdial Meeting on Discourse
and Dialogue
     </span>
     <span class="ltx_text" id="bib.bib16.5.3" style="font-size:80%;">
      , 2017, pp. 220–230.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.1.1" style="font-size:80%;">
      Chaoran Liu, Carlos Toshinori Ishi, and Hiroshi Ishiguro,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.2.1" style="font-size:80%;">
      “Turn-taking estimation model based on joint embedding of lexical
and prosodic contents.,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib17.4.2" style="font-size:80%;">
      Proc. Interspeech
     </span>
     <span class="ltx_text" id="bib.bib17.5.3" style="font-size:80%;">
      , 2017, pp. 1686–1690.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.1.1" style="font-size:80%;">
      Jiudong Yang, Peiying Wang, Yi Zhu, Mingchao Feng, Meng Chen, and Xiaodong He,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.2.1" style="font-size:80%;">
      “Gated multimodal fusion with contrastive learning for turn-taking
prediction in human-robot dialogue,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib18.4.2" style="font-size:80%;">
      Proc. ICASSP
     </span>
     <span class="ltx_text" id="bib.bib18.5.3" style="font-size:80%;">
      , 2022, pp. 7747–7751.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.1.1" style="font-size:80%;">
      Ryo Masumura, Tomohiro Tanaka, Atsushi Ando, Ryo Ishii, Ryuichiro Higashinaka,
and Yushi Aono,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.2.1" style="font-size:80%;">
      “Neural dialogue context online end-of-turn detection,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib19.4.2" style="font-size:80%;">
      Proceedings of the 19th Annual SIGdial Meeting on Discourse
and Dialogue
     </span>
     <span class="ltx_text" id="bib.bib19.5.3" style="font-size:80%;">
      , 2018, pp. 224–228.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.1.1" style="font-size:80%;">
      Ryo Masumura, Taichi Asami, Hirokazu Masataki, Ryo Ishii, and Ryuichiro
Higashinaka,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.2.1" style="font-size:80%;">
      “Online end-of-turn detection from speech based on stacked
time-asynchronous sequential networks.,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib20.4.2" style="font-size:80%;">
      Proc. Interspeech
     </span>
     <span class="ltx_text" id="bib.bib20.5.3" style="font-size:80%;">
      , 2017, pp. 1661–1665.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.1.1" style="font-size:80%;">
      Matthew Roddy, Gabriel Skantze, and Naomi Harte,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.2.1" style="font-size:80%;">
      “Multimodal continuous turn-taking prediction using multiscale
RNNs,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib21.4.2" style="font-size:80%;">
      Proc. ACM ICMI
     </span>
     <span class="ltx_text" id="bib.bib21.5.3" style="font-size:80%;">
      , 2018, pp. 186–190.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib22.1.1" style="font-size:80%;">
      Erik Ekstedt and Gabriel Skantze,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib22.2.1" style="font-size:80%;">
      “TurnGPT: a transformer-based language model for predicting
turn-taking in spoken dialog,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib22.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib22.4.2" style="font-size:80%;">
      Proc.  EMNLP
     </span>
     <span class="ltx_text" id="bib.bib22.5.3" style="font-size:80%;">
      , 2020, pp. 2981–2990.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib23.1.1" style="font-size:80%;">
      Luciano Floridi and Massimo Chiriatti,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib23.2.1" style="font-size:80%;">
      “GPT-3: Its nature, scope, limits, and consequences,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib23.3.1" style="font-size:80%;">
      Minds and Machines
     </span>
     <span class="ltx_text" id="bib.bib23.4.2" style="font-size:80%;">
      , vol. 30, pp. 681–694, 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.1.1" style="font-size:80%;">
      Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh
Parthasarathy, Sriram Rajamani, and Rahul Sharma,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.2.1" style="font-size:80%;">
      “Jigsaw: Large language models meet program synthesis,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib24.4.2" style="font-size:80%;">
      Proc. ACM ICSE
     </span>
     <span class="ltx_text" id="bib.bib24.5.3" style="font-size:80%;">
      , 2022, pp. 1219–1231.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.1.1" style="font-size:80%;">
      Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert,
Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan
Günnemann, Eyke Hüllermeier, et al.,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.2.1" style="font-size:80%;">
      “ChatGPT for good? On opportunities and challenges of large
language models for education,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib25.3.1" style="font-size:80%;">
      Learning and individual differences
     </span>
     <span class="ltx_text" id="bib.bib25.4.2" style="font-size:80%;">
      , vol. 103, pp. 102274,
2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib26.1.1" style="font-size:80%;">
      Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib26.2.1" style="font-size:80%;">
      “Language models are unsupervised multitask learners,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib26.3.1" style="font-size:80%;">
      OpenAI Blog
     </span>
     <span class="ltx_text" id="bib.bib26.4.2" style="font-size:80%;">
      , vol. 1, no. 8, 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.1.1" style="font-size:80%;">
      Together Computer,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.2.1" style="font-size:80%;">
      “RedPajama: An open source recipe to reproduce LLaMA training
dataset,” https://github.com/togethercomputer/RedPajama-Data, Apr. 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib28.1.1" style="font-size:80%;">
      Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan
Salakhutdinov, and Abdelrahman Mohamed,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib28.2.1" style="font-size:80%;">
      “HuBERT: Self-supervised speech representation learning by masked
prediction of hidden units,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib28.3.1" style="font-size:80%;">
      IEEE/ACM Transactions on Audio, Speech, and Language
Processing
     </span>
     <span class="ltx_text" id="bib.bib28.4.2" style="font-size:80%;">
      , vol. 29, pp. 3451–3460, 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.1.1" style="font-size:80%;">
      Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester,
Nan Du, Andrew M Dai, and Quoc V Le,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.2.1" style="font-size:80%;">
      “Finetuned language models are zero-shot learners,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib29.4.2" style="font-size:80%;">
      Proc. ICLR
     </span>
     <span class="ltx_text" id="bib.bib29.5.3" style="font-size:80%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib30.1.1" style="font-size:80%;">
      Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen,
Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib30.2.1" style="font-size:80%;">
      “Recent advances in natural language processing via large
pre-trained language models: A survey,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib30.3.1" style="font-size:80%;">
      ACM Computing Surveys
     </span>
     <span class="ltx_text" id="bib.bib30.4.2" style="font-size:80%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.1.1" style="font-size:80%;">
      Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander M. Rush,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.2.1" style="font-size:80%;">
      “Transformers: State-of-the-art natural language processing,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib31.4.2" style="font-size:80%;">
      Proc.  EMNLP
     </span>
     <span class="ltx_text" id="bib.bib31.5.3" style="font-size:80%;">
      , 2020, pp. 38–45.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.1.1" style="font-size:80%;">
      John J Godfrey, Edward C. Holliman, and Jane McDaniel,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.2.1" style="font-size:80%;">
      “Switchboard: Telephone speech corpus for research and
development,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib32.4.2" style="font-size:80%;">
      Proc. IEEE ICASSP
     </span>
     <span class="ltx_text" id="bib.bib32.5.3" style="font-size:80%;">
      , 1992, vol. 1, pp. 517–520.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.1.1" style="font-size:80%;">
      Elizabeth Shriberg, Andreas Stolcke, and Don Baron,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.2.1" style="font-size:80%;">
      “Observations on overlap: findings and implications for automatic
processing of multi-party conversation,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.3.1" style="font-size:80%;">
      in
     </span>
     <span class="ltx_text ltx_font_italic" id="bib.bib33.4.2" style="font-size:80%;">
      Proc. Interspeech
     </span>
     <span class="ltx_text" id="bib.bib33.5.3" style="font-size:80%;">
      , 2001, pp. 1359–1362.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib34.1.1" style="font-size:80%;">
      Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
Wang, Lu Wang, and Weizhu Chen,
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib34.2.1" style="font-size:80%;">
      “LoRA: Low-rank adaptation of large language models,”
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib34.3.1" style="font-size:80%;">
      arXiv preprint arXiv:2106.09685
     </span>
     <span class="ltx_text" id="bib.bib34.4.2" style="font-size:80%;">
      , 2021.
     </span>
    </span>
   </li>
  </ul>
 </section>
</article>
