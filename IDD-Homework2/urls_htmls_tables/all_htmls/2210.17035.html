<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2210.17035] Evaluation of large-scale synthetic data for Grammar Error Correction</title><meta property="og:description" content="Grammar Error Correction(GEC) mainly relies on the availability of high quality of large amount of synthetic parallel data of grammatically correct and erroneous sentence pairs. The quality of the synthetic data is eva…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Evaluation of large-scale synthetic data for Grammar Error Correction">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Evaluation of large-scale synthetic data for Grammar Error Correction">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2210.17035">

<!--Generated on Thu Mar 14 05:58:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Evaluation of large-scale synthetic data for Grammar Error Correction</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vanya Bannihatti Kumar 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">vanya.bk@bytedance.com
<br class="ltx_break"></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Grammar Error Correction(GEC) mainly relies on the availability of high quality of large amount of synthetic parallel data of grammatically correct and erroneous sentence pairs. The quality of the synthetic data is evaluated on how well the GEC system performs when pre-trained using it. But this does not provide much insight into what are the necessary factors which define the quality of these data. So this work aims to introduce 3 metrics - reliability, diversity and distribution match to provide more insight into the quality of large-scale synthetic data generated for the GEC task, as well as automatically evaluate them.
Evaluating these three metrics automatically can also help in providing feedback to the data generation systems and thereby improve the quality of the synthetic data generated dynamically</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Grammar error correction systems focus on detecting possible grammar errors like spelling errors, punctuation errors, verb errors etc and correcting them. Recent success in GEC systems depends largely on the availability of a large amount(in the scale of several millions) of parallel data consisting of grammatically correct and incorrect sentences. Some examples of this include:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Stahlberg and Kumar (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> use error type tags from ERRANT<cite class="ltx_cite ltx_citemacro_citep">(Bryant et al., <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite> to guide the synthetic data distribution so that the distribution of the synthetic data can be similar to that of the domain in which the GEC system is used. This synthetic dataset consists of 200 million parallel sentences and achieves near state-of-the-art results on the CoNLL-14<cite class="ltx_cite ltx_citemacro_citep">(Ng et al., <a href="#bib.bib8" title="" class="ltx_ref">2014</a>)</cite> dataset</p>
</div>
</li>
</ul>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Awasthi et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite> introduces the rule-based synthetic data generation method for GEC by using a list of common replacement errors, common insertion errors, common deletion errors and verb errors, and applying these errors randomly to any part of the grammatically correct sentence. Using this method, a very large synthetic dataset can be easily created for better GEC results</p>
</div>
</li>
</ul>
<ul id="S1.I3" class="ltx_itemize">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p id="S1.I3.i1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Koyama et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> compares the results of using the synthetic data generated using different backtranslation models such as Transformers, CNN and LSTM models. Here, a pseudo data of nearly 9 million samples are created using each of the above models and the quality of the synthetic data is compared by how well the GEC model trained using these synthetic datasets, perform on test sets like BEA-test<cite class="ltx_cite ltx_citemacro_citep">(Bryant et al., <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> etc.</p>
</div>
</li>
</ul>
<p id="S1.p1.2" class="ltx_p">As mentioned previously, all these synthetic datasets are evaluated based on how the GEC models perform when trained using them. However, this does not capture essential metrics which can be used to improve the synthetic data generation. This work aims to introduce these metrics in terms of :</p>
<ul id="S1.I4" class="ltx_itemize">
<li id="S1.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I4.i1.p1" class="ltx_para">
<p id="S1.I4.i1.p1.1" class="ltx_p">Reliability - This metric can help evaluate which part of the dataset truly resembles humans in terms of creating grammatical errors in a particular sentence</p>
</div>
</li>
</ul>
<ul id="S1.I5" class="ltx_itemize">
<li id="S1.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i1.p1" class="ltx_para">
<p id="S1.I5.i1.p1.1" class="ltx_p">Diversity - Many synthetic data generation techniques like <cite class="ltx_cite ltx_citemacro_citet">Stahlberg and Kumar (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zhou et al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> show that diverse synthetic data can help improve the GEC systems. But these works do not accurately measure the diversity of the datasets. So, this work aims to evaluate the diversity of any synthetic dataset more accurately.</p>
</div>
</li>
</ul>
<ul id="S1.I6" class="ltx_itemize">
<li id="S1.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I6.i1.p1" class="ltx_para">
<p id="S1.I6.i1.p1.1" class="ltx_p">Distribution match - This metric is useful in determining which synthetic dataset to be used to train the GEC model for a particular domain. In this work, the experiments are done using datasets across different domains like the open domain and the novel domain to determine the accuracy of the metric</p>
</div>
</li>
</ul>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">For the rest of the discussion, the experiments of the proposed metrics are conducted on the following synthetic datasets:</p>
<ul id="S1.I7" class="ltx_itemize">
<li id="S1.I7.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I7.i1.p1" class="ltx_para">
<p id="S1.I7.i1.p1.1" class="ltx_p">Tagged corruption model - <cite class="ltx_cite ltx_citemacro_citet">Stahlberg and Kumar (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite></p>
</div>
</li>
</ul>
<ul id="S1.I8" class="ltx_itemize">
<li id="S1.I8.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I8.i1.p1" class="ltx_para">
<p id="S1.I8.i1.p1.1" class="ltx_p">Backtranslation method - <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite></p>
</div>
</li>
</ul>
<ul id="S1.I9" class="ltx_itemize">
<li id="S1.I9.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I9.i1.p1" class="ltx_para">
<p id="S1.I9.i1.p1.1" class="ltx_p">Rule-based method - <cite class="ltx_cite ltx_citemacro_citet">Awasthi et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite></p>
</div>
</li>
</ul>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The backtranslation method is applied on the novel domain to verify if the metrics still holds for different domains other than the open domain.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Reliability</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">A large portion of the parallel data produced by synthetic methods like backtranslation, round-trip translation, tagged-corruption models, rule-based methods etc., consists of erroneous sentences which are not realistically generated by humans. For example, consider one of the sentences in the google c4 corpus:</p>
<blockquote id="S2.p1.2" class="ltx_quote">
<p id="S2.p1.2.1" class="ltx_p"><span id="S2.p1.2.1.1" class="ltx_text ltx_font_italic">19. Develop a calendar of local and regional events in your locale and make your company visible in the areas most related to your company and your potential clients’ interests . </span></p>
</blockquote>
<p id="S2.p1.3" class="ltx_p">It’s corrupted sentence from the tagged-corruption model is as follows:</p>
<blockquote id="S2.p1.4" class="ltx_quote">
<p id="S2.p1.4.1" class="ltx_p"><span id="S2.p1.4.1.1" class="ltx_text ltx_font_italic">19 develop development a calendar of local and regional events in your louce and make your company visible in the areas most relating to your company. (Environment + Agriculture) and potential interests .</span></p>
</blockquote>
<p id="S2.p1.5" class="ltx_p">The difference between the erroneous sentence and the original sentence is as follows:</p>
<blockquote id="S2.p1.6" class="ltx_quote">
<p id="S2.p1.6.1" class="ltx_p"><span id="S2.p1.6.1.1" class="ltx_text ltx_font_italic">[19. Develop -&gt; 19 develop development] a calendar of local and regional events in your [locale -&gt; louce] and make your company visible in the areas most [related -&gt; relating] to your company [and your potential clients’ -&gt; (Environment + Agriculture) and potential] interests . </span></p>
</blockquote>
<p id="S2.p1.7" class="ltx_p">From this example, it is quite clear that except [related-&gt;relating] and [locale-&gt;louce] edits, all the other edits are impractical and are most likely not made by humans. Since these examples do not mimic the annotated parallel data of erroneous sentences and the grammatically correct sentences, training a model with such a data do not give any improvements.

<br class="ltx_break">To this end, this work aims to formalise a metric which measures the number of reliable examples in the synthetic dataset automatically.

<br class="ltx_break"></p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Error type</span></th>
<th id="S2.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Original</span></th>
<th id="S2.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S2.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Reliable</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.1.2.1" class="ltx_tr">
<td id="S2.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">OTHER</td>
<td id="S2.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">23.45</td>
<td id="S2.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">23.55</td>
</tr>
<tr id="S2.T1.1.3.2" class="ltx_tr">
<td id="S2.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r">ADV</td>
<td id="S2.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r">1.79</td>
<td id="S2.T1.1.3.2.3" class="ltx_td ltx_align_center">1.79</td>
</tr>
<tr id="S2.T1.1.4.3" class="ltx_tr">
<td id="S2.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r">PREP</td>
<td id="S2.T1.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r">9.16</td>
<td id="S2.T1.1.4.3.3" class="ltx_td ltx_align_center">9.17</td>
</tr>
<tr id="S2.T1.1.5.4" class="ltx_tr">
<td id="S2.T1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_r">ORTH</td>
<td id="S2.T1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r">6.71</td>
<td id="S2.T1.1.5.4.3" class="ltx_td ltx_align_center">6.74</td>
</tr>
<tr id="S2.T1.1.6.5" class="ltx_tr">
<td id="S2.T1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_r">NOUN</td>
<td id="S2.T1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r">16.11</td>
<td id="S2.T1.1.6.5.3" class="ltx_td ltx_align_center">16.06</td>
</tr>
<tr id="S2.T1.1.7.6" class="ltx_tr">
<td id="S2.T1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_r">MORPH</td>
<td id="S2.T1.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r">2.74</td>
<td id="S2.T1.1.7.6.3" class="ltx_td ltx_align_center">2.74</td>
</tr>
<tr id="S2.T1.1.8.7" class="ltx_tr">
<td id="S2.T1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_r">DET</td>
<td id="S2.T1.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r">8.04</td>
<td id="S2.T1.1.8.7.3" class="ltx_td ltx_align_center">8</td>
</tr>
<tr id="S2.T1.1.9.8" class="ltx_tr">
<td id="S2.T1.1.9.8.1" class="ltx_td ltx_align_center ltx_border_r">PRON</td>
<td id="S2.T1.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r">1.72</td>
<td id="S2.T1.1.9.8.3" class="ltx_td ltx_align_center">1.71</td>
</tr>
<tr id="S2.T1.1.10.9" class="ltx_tr">
<td id="S2.T1.1.10.9.1" class="ltx_td ltx_align_center ltx_border_r">VERB:SVA</td>
<td id="S2.T1.1.10.9.2" class="ltx_td ltx_align_left ltx_border_r">1.28</td>
<td id="S2.T1.1.10.9.3" class="ltx_td ltx_align_center">1.27</td>
</tr>
<tr id="S2.T1.1.11.10" class="ltx_tr">
<td id="S2.T1.1.11.10.1" class="ltx_td ltx_align_center ltx_border_r">PART</td>
<td id="S2.T1.1.11.10.2" class="ltx_td ltx_align_left ltx_border_r">0.7</td>
<td id="S2.T1.1.11.10.3" class="ltx_td ltx_align_center">0.69</td>
</tr>
<tr id="S2.T1.1.12.11" class="ltx_tr">
<td id="S2.T1.1.12.11.1" class="ltx_td ltx_align_center ltx_border_r">VERB</td>
<td id="S2.T1.1.12.11.2" class="ltx_td ltx_align_left ltx_border_r">6.04</td>
<td id="S2.T1.1.12.11.3" class="ltx_td ltx_align_center">6.02</td>
</tr>
<tr id="S2.T1.1.13.12" class="ltx_tr">
<td id="S2.T1.1.13.12.1" class="ltx_td ltx_align_center ltx_border_r">VERB:TENSE</td>
<td id="S2.T1.1.13.12.2" class="ltx_td ltx_align_left ltx_border_r">3.62</td>
<td id="S2.T1.1.13.12.3" class="ltx_td ltx_align_center">3.56</td>
</tr>
<tr id="S2.T1.1.14.13" class="ltx_tr">
<td id="S2.T1.1.14.13.1" class="ltx_td ltx_align_center ltx_border_r">VERB:FORM</td>
<td id="S2.T1.1.14.13.2" class="ltx_td ltx_align_left ltx_border_r">2.4</td>
<td id="S2.T1.1.14.13.3" class="ltx_td ltx_align_center">2.4</td>
</tr>
<tr id="S2.T1.1.15.14" class="ltx_tr">
<td id="S2.T1.1.15.14.1" class="ltx_td ltx_align_center ltx_border_r">SPELL</td>
<td id="S2.T1.1.15.14.2" class="ltx_td ltx_align_left ltx_border_r">7.72</td>
<td id="S2.T1.1.15.14.3" class="ltx_td ltx_align_center">7.77</td>
</tr>
<tr id="S2.T1.1.16.15" class="ltx_tr">
<td id="S2.T1.1.16.15.1" class="ltx_td ltx_align_center ltx_border_r">CONJ</td>
<td id="S2.T1.1.16.15.2" class="ltx_td ltx_align_left ltx_border_r">0.9</td>
<td id="S2.T1.1.16.15.3" class="ltx_td ltx_align_center">0.93</td>
</tr>
<tr id="S2.T1.1.17.16" class="ltx_tr">
<td id="S2.T1.1.17.16.1" class="ltx_td ltx_align_center ltx_border_r">ADJ</td>
<td id="S2.T1.1.17.16.2" class="ltx_td ltx_align_left ltx_border_r">2.07</td>
<td id="S2.T1.1.17.16.3" class="ltx_td ltx_align_center">2.07</td>
</tr>
<tr id="S2.T1.1.18.17" class="ltx_tr">
<td id="S2.T1.1.18.17.1" class="ltx_td ltx_align_center ltx_border_r">WO</td>
<td id="S2.T1.1.18.17.2" class="ltx_td ltx_align_left ltx_border_r">0.81</td>
<td id="S2.T1.1.18.17.3" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="S2.T1.1.19.18" class="ltx_tr">
<td id="S2.T1.1.19.18.1" class="ltx_td ltx_align_center ltx_border_r">PUNCT</td>
<td id="S2.T1.1.19.18.2" class="ltx_td ltx_align_left ltx_border_r">1.63</td>
<td id="S2.T1.1.19.18.3" class="ltx_td ltx_align_center">1.64</td>
</tr>
<tr id="S2.T1.1.20.19" class="ltx_tr">
<td id="S2.T1.1.20.19.1" class="ltx_td ltx_align_center ltx_border_r">NOUN:NUM</td>
<td id="S2.T1.1.20.19.2" class="ltx_td ltx_align_left ltx_border_r">2.77</td>
<td id="S2.T1.1.20.19.3" class="ltx_td ltx_align_center">2.76</td>
</tr>
<tr id="S2.T1.1.21.20" class="ltx_tr">
<td id="S2.T1.1.21.20.1" class="ltx_td ltx_align_center ltx_border_r">ADJ:FORM</td>
<td id="S2.T1.1.21.20.2" class="ltx_td ltx_align_left ltx_border_r">0.08</td>
<td id="S2.T1.1.21.20.3" class="ltx_td ltx_align_center">0.09</td>
</tr>
<tr id="S2.T1.1.22.21" class="ltx_tr">
<td id="S2.T1.1.22.21.1" class="ltx_td ltx_align_center ltx_border_r">CONTR</td>
<td id="S2.T1.1.22.21.2" class="ltx_td ltx_align_left ltx_border_r">0.03</td>
<td id="S2.T1.1.22.21.3" class="ltx_td ltx_align_center">0.03</td>
</tr>
<tr id="S2.T1.1.23.22" class="ltx_tr">
<td id="S2.T1.1.23.22.1" class="ltx_td ltx_align_center ltx_border_r">NOUN:POS</td>
<td id="S2.T1.1.23.22.2" class="ltx_td ltx_align_left ltx_border_r">0.04</td>
<td id="S2.T1.1.23.22.3" class="ltx_td ltx_align_center">0.04</td>
</tr>
<tr id="S2.T1.1.24.23" class="ltx_tr">
<td id="S2.T1.1.24.23.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">NOUN:INFL</td>
<td id="S2.T1.1.24.23.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.09</td>
<td id="S2.T1.1.24.23.3" class="ltx_td ltx_align_center ltx_border_b">0.09</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Distribution from tagged corruption model using ERRANT</figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">To measure the reliability metric of any synthetic data, the pre-trained binary classification BERT model from huggingface<cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">hug </a></cite> was fine-tuned using the dataset created as follows:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">The unreliable sentence pairs were created using rule-based method where the following rules were applied:</p>
<ul id="S2.I1.i1.I1" class="ltx_itemize">
<li id="S2.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i1.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.I1.i1.p1.1" class="ltx_p">The verb error was introduced from the verb error list by replacing a verb with the verb errors of another completely different and random verb. For example, instead of replacing ’abandon’ with ’abandoning’(which creates a more realistic error), ’abandon’ was replaced with ’associating’, to create an improbable error sentence from the original sentence.</p>
</div>
</li>
<li id="S2.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i1.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i1.I1.i2.p1.1" class="ltx_p">Similarly for replacement error, the replacement list was used where instead of replacing the word in the replacement list with its commonly confused word, it was replaced with a commonly confused counterpart of a completely different and random word in the replacement list. For example, instead of replacing ’equipment’ with ’equipmet’, ’equipment’ was replaced with ’Therefofe’(commonly confused word of ’Therefore’), to create an impractical and unreliable sentence pair.</p>
</div>
</li>
<li id="S2.I1.i1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i1.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i1.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i1.I1.i3.p1.1" class="ltx_p">For deletion error, a word from the commonly inserted words list was deleted randomly. And for insertion error, a word from the commonly deleted words list was inserted randomly.

<br class="ltx_break">(The verb error, replacement, insertion and deletion error lists were obtained from <cite class="ltx_cite ltx_citemacro_citet">Awasthi et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite></p>
</div>
</li>
</ul>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">The reliable sentence pairs were obtained from human annotated GEC corpus such as Lang8, NUCLE, W&amp;I+LOCNESS and FCE datasets which are publicly available.</p>
</div>
</li>
</ul>
<p id="S2.p2.2" class="ltx_p">The unreliable and the reliable sentence pairs were used in the ratio of 1:1 to create a dataset of 500k sentence pairs, which was used to fine-tune the pre-trained binary classification BERT model.
This fine-tuned BERT classification model is used to get the reliability metric for a sample of 100k sentence pairs of few synthetic datasets as shown in Table <a href="#S2.T2" title="Table 2 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></p>
</div>
<figure id="S2.T2" class="ltx_table">
<table id="S2.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.1.1.1" class="ltx_tr">
<th id="S2.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S2.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S2.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S2.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Reliability metric</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.1.2.1" class="ltx_tr">
<th id="S2.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Tagged corruption model</th>
<td id="S2.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">17.63%</td>
</tr>
<tr id="S2.T2.1.3.2" class="ltx_tr">
<th id="S2.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Backtranslation method</th>
<td id="S2.T2.1.3.2.2" class="ltx_td ltx_align_center">26.22%</td>
</tr>
<tr id="S2.T2.1.4.3" class="ltx_tr">
<th id="S2.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b">Rule-based method</th>
<td id="S2.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b">9.61%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Reliability metric for sample of few synthetic datasets</figcaption>
</figure>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The authenticity of the reliability metric was measured by further using these classified datasets, one part containing unreliable sentence pairs and the other part containing reliable sentence pairs, to fine-tune a GEC model which was pre-trained using Lang-8(<cite class="ltx_cite ltx_citemacro_citet">Mizumoto et al. (<a href="#bib.bib7" title="" class="ltx_ref">2011</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib10" title="" class="ltx_ref">Tajiri et al.</a></cite>), W&amp;I+LOCNESS(<cite class="ltx_cite ltx_citemacro_citet">Bryant et al. (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Granger (<a href="#bib.bib5" title="" class="ltx_ref">2014</a>)</cite>) and FCE<cite class="ltx_cite ltx_citemacro_citep">(Yannakoudakis et al., <a href="#bib.bib12" title="" class="ltx_ref">2011</a>)</cite> datasets, and then verifying the F0.5 metrics on GEC test dataset as shown in the Tables <a href="#S2.T3" title="Table 3 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S2.T4" title="Table 4 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The reliable and the unreliable datasets used for fine-tuning were both made of 50k sentence pairs.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Table <a href="#S2.T3" title="Table 3 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results of fine-tuning reliable and unreliable datasets of synthetic data generated by tagged corruption model and rule-based methods on CoNLL-14 test set. While Table <a href="#S2.T4" title="Table 4 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the results of fine-tuning reliable and unreliable datasets of synthetic data generated by the backtranslation method in the novel domain on a test set made of 8k sentence pairs in the novel domain. From these tables we can see that for the same size of dataset used for fine-tuning and with the same origin i.e, generated using the same synthetic means, there is a vast difference in how the GEC models fine-tuned on these datasets perform as measured by the F0.5 metric. There is a difference of at least 1.7% in F0.5 between the GEC model trained on reliable dataset as compared to the unreliable one. This shows that the classification model is fairly accurate in distinguishing the reliable synthetic data from the unreliable ones. This is true not only in the open domain as shown in the Table <a href="#S2.T3" title="Table 3 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> but across other domains like the novel domain as shown in the Table <a href="#S2.T4" title="Table 4 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S2.T3" class="ltx_table">
<table id="S2.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T3.1.1.1" class="ltx_tr">
<th id="S2.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S2.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S2.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Reliable</span></th>
<th id="S2.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S2.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Unreliable</span></th>
</tr>
<tr id="S2.T3.1.2.2" class="ltx_tr">
<th id="S2.T3.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"></th>
<th id="S2.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">F0.5</th>
<th id="S2.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F0.5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T3.1.3.1" class="ltx_tr">
<th id="S2.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Tagged corruption</th>
<td id="S2.T3.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.64%</td>
<td id="S2.T3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">36.6%</td>
</tr>
<tr id="S2.T3.1.4.2" class="ltx_tr">
<th id="S2.T3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">Rule-based</th>
<td id="S2.T3.1.4.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">48.35%</td>
<td id="S2.T3.1.4.2.3" class="ltx_td ltx_align_center ltx_border_b">46.67%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance of reliable and unreliable datasets from tagged corruption model and rule-based methods on CoNLL-14</figcaption>
</figure>
<figure id="S2.T4" class="ltx_table">
<table id="S2.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T4.1.1.1" class="ltx_tr">
<th id="S2.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S2.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S2.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S2.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">Reliable</span></th>
<th id="S2.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S2.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">Unreliable</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T4.1.2.1" class="ltx_tr">
<th id="S2.T4.1.2.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<td id="S2.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">F0.5</td>
<td id="S2.T4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">F0.5</td>
</tr>
<tr id="S2.T4.1.3.2" class="ltx_tr">
<th id="S2.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Backtranslation</th>
<td id="S2.T4.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">15.10%</td>
<td id="S2.T4.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">10.25%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance of reliable and unreliable datasets from backtranslation model on test data in novel domain</figcaption>
</figure>
<figure id="S2.T5" class="ltx_table">
<table id="S2.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T5.1.1.1" class="ltx_tr">
<th id="S2.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S2.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">Error type</span></th>
<td id="S2.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T5.1.1.1.2.1" class="ltx_text ltx_font_bold">Original</span></td>
<td id="S2.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T5.1.1.1.3.1" class="ltx_text ltx_font_bold">Reliable</span></td>
</tr>
<tr id="S2.T5.1.2.2" class="ltx_tr">
<th id="S2.T5.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">OTHER</th>
<td id="S2.T5.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">18.17</td>
<td id="S2.T5.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">23.67</td>
</tr>
<tr id="S2.T5.1.3.3" class="ltx_tr">
<th id="S2.T5.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ADV</th>
<td id="S2.T5.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r">0.5</td>
<td id="S2.T5.1.3.3.3" class="ltx_td ltx_align_center">0.2</td>
</tr>
<tr id="S2.T5.1.4.4" class="ltx_tr">
<th id="S2.T5.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">PREP</th>
<td id="S2.T5.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">4.93</td>
<td id="S2.T5.1.4.4.3" class="ltx_td ltx_align_center">2.53</td>
</tr>
<tr id="S2.T5.1.5.5" class="ltx_tr">
<th id="S2.T5.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ORTH</th>
<td id="S2.T5.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">14.87</td>
<td id="S2.T5.1.5.5.3" class="ltx_td ltx_align_center">6.69</td>
</tr>
<tr id="S2.T5.1.6.6" class="ltx_tr">
<th id="S2.T5.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NOUN</th>
<td id="S2.T5.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">1.47</td>
<td id="S2.T5.1.6.6.3" class="ltx_td ltx_align_center">0.84</td>
</tr>
<tr id="S2.T5.1.7.7" class="ltx_tr">
<th id="S2.T5.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MORPH</th>
<td id="S2.T5.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r">3.07</td>
<td id="S2.T5.1.7.7.3" class="ltx_td ltx_align_center">0.89</td>
</tr>
<tr id="S2.T5.1.8.8" class="ltx_tr">
<th id="S2.T5.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DET</th>
<td id="S2.T5.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r">7.03</td>
<td id="S2.T5.1.8.8.3" class="ltx_td ltx_align_center">2.19</td>
</tr>
<tr id="S2.T5.1.9.9" class="ltx_tr">
<th id="S2.T5.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">PRON</th>
<td id="S2.T5.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r">2.29</td>
<td id="S2.T5.1.9.9.3" class="ltx_td ltx_align_center">0.99</td>
</tr>
<tr id="S2.T5.1.10.10" class="ltx_tr">
<th id="S2.T5.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VERB:SVA</th>
<td id="S2.T5.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r">0.14</td>
<td id="S2.T5.1.10.10.3" class="ltx_td ltx_align_center">0.16</td>
</tr>
<tr id="S2.T5.1.11.11" class="ltx_tr">
<th id="S2.T5.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">PART</th>
<td id="S2.T5.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r">0.13</td>
<td id="S2.T5.1.11.11.3" class="ltx_td ltx_align_center">0.07</td>
</tr>
<tr id="S2.T5.1.12.12" class="ltx_tr">
<th id="S2.T5.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VERB</th>
<td id="S2.T5.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r">3.09</td>
<td id="S2.T5.1.12.12.3" class="ltx_td ltx_align_center">1.51</td>
</tr>
<tr id="S2.T5.1.13.13" class="ltx_tr">
<th id="S2.T5.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VERB:TENSE</th>
<td id="S2.T5.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r">5.62</td>
<td id="S2.T5.1.13.13.3" class="ltx_td ltx_align_center">2.15</td>
</tr>
<tr id="S2.T5.1.14.14" class="ltx_tr">
<th id="S2.T5.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VERB:FORM</th>
<td id="S2.T5.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r">3.4</td>
<td id="S2.T5.1.14.14.3" class="ltx_td ltx_align_center">1.06</td>
</tr>
<tr id="S2.T5.1.15.15" class="ltx_tr">
<th id="S2.T5.1.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SPELL</th>
<td id="S2.T5.1.15.15.2" class="ltx_td ltx_align_center ltx_border_r">0.64</td>
<td id="S2.T5.1.15.15.3" class="ltx_td ltx_align_center">1.15</td>
</tr>
<tr id="S2.T5.1.16.16" class="ltx_tr">
<th id="S2.T5.1.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CONJ</th>
<td id="S2.T5.1.16.16.2" class="ltx_td ltx_align_center ltx_border_r">1.09</td>
<td id="S2.T5.1.16.16.3" class="ltx_td ltx_align_center">0.96</td>
</tr>
<tr id="S2.T5.1.17.17" class="ltx_tr">
<th id="S2.T5.1.17.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ADJ</th>
<td id="S2.T5.1.17.17.2" class="ltx_td ltx_align_center ltx_border_r">0.96</td>
<td id="S2.T5.1.17.17.3" class="ltx_td ltx_align_center">0.3</td>
</tr>
<tr id="S2.T5.1.18.18" class="ltx_tr">
<th id="S2.T5.1.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">WO</th>
<td id="S2.T5.1.18.18.2" class="ltx_td ltx_align_center ltx_border_r">0.49</td>
<td id="S2.T5.1.18.18.3" class="ltx_td ltx_align_center">0.2</td>
</tr>
<tr id="S2.T5.1.19.19" class="ltx_tr">
<th id="S2.T5.1.19.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">PUNCT</th>
<td id="S2.T5.1.19.19.2" class="ltx_td ltx_align_center ltx_border_r">29.92</td>
<td id="S2.T5.1.19.19.3" class="ltx_td ltx_align_center">52.48</td>
</tr>
<tr id="S2.T5.1.20.20" class="ltx_tr">
<th id="S2.T5.1.20.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NOUN:NUM</th>
<td id="S2.T5.1.20.20.2" class="ltx_td ltx_align_center ltx_border_r">1.6</td>
<td id="S2.T5.1.20.20.3" class="ltx_td ltx_align_center">0.53</td>
</tr>
<tr id="S2.T5.1.21.21" class="ltx_tr">
<th id="S2.T5.1.21.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ADJ:FORM</th>
<td id="S2.T5.1.21.21.2" class="ltx_td ltx_align_center ltx_border_r">0.43</td>
<td id="S2.T5.1.21.21.3" class="ltx_td ltx_align_center">0.14</td>
</tr>
<tr id="S2.T5.1.22.22" class="ltx_tr">
<th id="S2.T5.1.22.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CONTR</th>
<td id="S2.T5.1.22.22.2" class="ltx_td ltx_align_center ltx_border_r">0.05</td>
<td id="S2.T5.1.22.22.3" class="ltx_td ltx_align_center">0.18</td>
</tr>
<tr id="S2.T5.1.23.23" class="ltx_tr">
<th id="S2.T5.1.23.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NOUN:POS</th>
<td id="S2.T5.1.23.23.2" class="ltx_td ltx_align_center ltx_border_r">0.02</td>
<td id="S2.T5.1.23.23.3" class="ltx_td ltx_align_center">1.12</td>
</tr>
<tr id="S2.T5.1.24.24" class="ltx_tr">
<th id="S2.T5.1.24.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">NOUN:INFL</th>
<td id="S2.T5.1.24.24.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.01</td>
<td id="S2.T5.1.24.24.3" class="ltx_td ltx_align_center ltx_border_b">0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Distribution from backtranslation model</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Diversity</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Diversity is another key factor which determines the quality of the synthetic data. The ERRANT tool is used to measure the error types of the synthetic datasets in the English language. Previous works like <cite class="ltx_cite ltx_citemacro_citet">Zhou et al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> interpret that a dataset has more diversity in error types if the number of ’OTHER’ or ’Unknown’ error sentence pairs as annotated by ERRANT is more. This work aims to figure out how the percentage of these error types changes with dataset containing both reliable and unreliable data v/s when it contains only reliable sentence pairs. Since the authenticity of the reliability metric was established in the previous section <a href="#S2" title="2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the measure of diversity distribution with only reliable sentence pairs is far more accurate for any synthetic dataset, than that with both reliable and unreliable sentence pairs. Table <a href="#S2.T1" title="Table 1 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows that the diversity of the original dataset containing both reliable and unreliable sentence pairs, obtained using tagged corruption model and that of the filtered dataset containing only reliable sentence pairs remains almost constant. But it changes drastically for the synthetic dataset obtained using backtranslation method as shown in Table <a href="#S2.T5" title="Table 5 ‣ 2 Reliability ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(distribution annotated using ERRANT). This shows that the diversity distribution for different synthetic datasets sometimes vary when the unreliable sentence pairs are removed from the dataset.</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.17035/assets/Tagged_corr.png" id="S3.F1.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="513" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Tagged corruption model</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.17035/assets/backtrans.png" id="S3.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="598" height="513" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Backtranslation model</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.17035/assets/Novel_anot.png" id="S3.F1.sf3.g1" class="ltx_graphics ltx_img_square" width="598" height="518" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Novel annotated dataset</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Comparing distributions of different datasets against the test set in novel domain</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Distribution match</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Distribution match of the synthetic dataset used to fine-tune the GEC model with that of the real-world test dataset is the most important factor which measures the quality of the synthetic set. If there is a large shift in the distribution between these two sets, the model trained using this synthetic dataset will perform worse as indicated in several previous works like <cite class="ltx_cite ltx_citemacro_citet">Stahlberg and Kumar (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>.

<br class="ltx_break">Experiments were conducted by fine-tuning the GEC model(pre-trained on Lang-8, WI+LOCNESS and FCE datasets) on different datasets having varying distributions. As is evident from Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Diversity ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the distribution of the synthetic datasets from tagged corruption model and backtranslation vary vastly from that of the novel test data distribution and hence the performance of the GEC model fine-tuned with these datasets is worse compared to the novel annotated dataset which has distribution very similar to that of the test set, as shown in Table <a href="#S4.T6" title="Table 6 ‣ 4 Distribution match ‣ Evaluation of large-scale synthetic data for Grammar Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.

<br class="ltx_break">Even though the synthetic datasets from tagged corruption model and backtranslation model were filtered to only include reliable sentences to match the quality of the annotated novel training dataset, ultimately since the distribution was much different compare to the test set, the performance was also much worse.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T6.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S4.T6.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T6.1.1.1.2.1" class="ltx_text ltx_font_italic">Precision</span></th>
<th id="S4.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T6.1.1.1.3.1" class="ltx_text ltx_font_italic">Recall</span></th>
<th id="S4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T6.1.1.1.4.1" class="ltx_text ltx_font_italic">F0.5</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.2.1" class="ltx_tr">
<th id="S4.T6.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Tagged Corruption</th>
<th id="S4.T6.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">12.86</th>
<td id="S4.T6.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">21.74</td>
<td id="S4.T6.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">14.01</td>
</tr>
<tr id="S4.T6.1.3.2" class="ltx_tr">
<th id="S4.T6.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Backtranslation</th>
<th id="S4.T6.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">13.87</th>
<td id="S4.T6.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">23.38</td>
<td id="S4.T6.1.3.2.4" class="ltx_td ltx_align_center">15.10</td>
</tr>
<tr id="S4.T6.1.4.3" class="ltx_tr">
<th id="S4.T6.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Novel annotated</th>
<th id="S4.T6.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T6.1.4.3.2.1" class="ltx_text ltx_font_bold">50.66</span></th>
<td id="S4.T6.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.1.4.3.3.1" class="ltx_text ltx_font_bold">33.98</span></td>
<td id="S4.T6.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T6.1.4.3.4.1" class="ltx_text ltx_font_bold">46.13</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Results of GEC model fine-tuned on different datasets, evaluated against test set in novel domain</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This work formally introduces the three main parameters which are key to measuring the quality of a synthetic dataset. Several experiments were also conducted to measure the authenticity of these parameters and whether they are robust across domains. This ensures the universality of the parameters and can probably be extended to other similar tasks like machine translation. Since these parameters i.e, reliability, diversity and distribution match are measured automatically, they can be used as feedback to the system which generates synthetic data(much like in a Reinforcement Learning setting), thereby improving the overall quality of the synthetic dataset generated. With a very high quality of the synthetic data generated to either pre-train or fine-tune a GEC model, its performance would also improve drastically.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The limitations of this work is that since the reliability is measured automatically, large-scale annotated data for the classification task is required to obtain accurate classification results which may not be feasible. It would also require a lot of computing resources to evaluate on large scale synthetic datasets in the scale of millions.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">The datasets used for the experiments conducted in the paper are obtained from diverse sources like Lang-8, FCE, WI+LOCNESS etc, and different domains like novel, which includes data annotated by people whose first language is not English as well as from native English speakers, making it widely applicable in the society.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/docs/transformers/model_doc/bert" title="" class="ltx_ref ltx_href">Huggingface bert</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Awasthi et al. (2019)</span>
<span class="ltx_bibblock">
Abhijeet Awasthi, Sunita Sarawagi, Rasna Goyal, Sabyasachi Ghosh, and Vihari
Piratla. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1435" title="" class="ltx_ref ltx_href">Parallel iterative edit
models for local sequence transduction</a>.

</span>
<span class="ltx_bibblock">pages 4260–4270.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bryant et al. (2019)</span>
<span class="ltx_bibblock">
Christopher Bryant, Mariano Felice, Øistein E. Andersen, and Ted Briscoe.
2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W19-4406" title="" class="ltx_ref ltx_href">The BEA-2019 shared
task on grammatical error correction</a>.

</span>
<span class="ltx_bibblock">pages 52–75.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bryant et al. (2017)</span>
<span class="ltx_bibblock">
Christopher Bryant, Mariano Felice, and Ted Briscoe. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1074" title="" class="ltx_ref ltx_href">Automatic annotation
and evaluation of error types for grammatical error correction</a>.

</span>
<span class="ltx_bibblock">pages 793–805.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Granger (2014)</span>
<span class="ltx_bibblock">
Sylviane Granger. 2014.

</span>
<span class="ltx_bibblock">The computer learner corpus: a versatile new source of data for sla
research: Sylviane granger.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koyama et al. (2021)</span>
<span class="ltx_bibblock">
Aomi Koyama, Kengo Hotate, Masahiro Kaneko, and Mamoru Komachi. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-srw.16" title="" class="ltx_ref ltx_href">Comparison of
grammatical error correction using back-translation models</a>.

</span>
<span class="ltx_bibblock">pages 126–135.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mizumoto et al. (2011)</span>
<span class="ltx_bibblock">
Tomoya Mizumoto, Mamoru Komachi, Masaaki Nagata, and Yuji Matsumoto. 2011.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/I11-1017" title="" class="ltx_ref ltx_href">Mining revision log of
language learning SNS for automated Japanese error correction of second
language learners</a>.

</span>
<span class="ltx_bibblock">pages 147–155.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng et al. (2014)</span>
<span class="ltx_bibblock">
Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, Christian Hadiwinoto, Raymond Hendy
Susanto, and Christopher Bryant. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/W14-1701" title="" class="ltx_ref ltx_href">The CoNLL-2014
shared task on grammatical error correction</a>.

</span>
<span class="ltx_bibblock">pages 1–14.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stahlberg and Kumar (2021)</span>
<span class="ltx_bibblock">
Felix Stahlberg and Shankar Kumar. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.bea-1.4" title="" class="ltx_ref ltx_href">"synthetic data
generation for grammatical error correction with tagged corruption models"</a>.

</span>
<span class="ltx_bibblock">pages 37–47.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tajiri et al. (2012)</span>
<span class="ltx_bibblock">
Toshikazu Tajiri, Mamoru Komachi, and Yuji Matsumoto. 2012.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/P12-2039" title="" class="ltx_ref ltx_href">Tense and aspect error
correction for ESL learners using global context</a>.

</span>
<span class="ltx_bibblock">pages 198–202.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2018)</span>
<span class="ltx_bibblock">
Ziang Xie, Guillaume Genthial, Stanley Xie, Andrew Ng, and Dan Jurafsky. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N18-1057" title="" class="ltx_ref ltx_href">Noising and denoising
natural language: Diverse backtranslation for grammar correction</a>.

</span>
<span class="ltx_bibblock">pages 619–628.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yannakoudakis et al. (2011)</span>
<span class="ltx_bibblock">
Helen Yannakoudakis, Ted Briscoe, and Ben Medlock. 2011.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/P11-1019" title="" class="ltx_ref ltx_href">A new dataset and method
for automatically grading ESOL texts</a>.

</span>
<span class="ltx_bibblock">pages 180–189.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2020)</span>
<span class="ltx_bibblock">
Wangchunshu Zhou, Tao Ge, Chang Mu, Ke Xu, Furu Wei, and Ming Zhou. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.30" title="" class="ltx_ref ltx_href">Improving
grammatical error correction with machine translation pairs</a>.

</span>
<span class="ltx_bibblock">pages 318–328.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2210.17034" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2210.17035" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2210.17035">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2210.17035" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2210.17036" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 05:58:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
