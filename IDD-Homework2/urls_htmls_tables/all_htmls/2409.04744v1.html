<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.</title>
<!--Generated on Sat Sep  7 07:37:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.04744v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S1" title="In LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S2" title="In LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S2.SS1" title="In II Methodology ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Framework Structure</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S2.SS2" title="In II Methodology ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Prompt Design</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3" title="In LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Experiment</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS1" title="In III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Experimental Settings</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS2" title="In III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Comparison Experiments with Traditional Exploration-Exploitation Trade-off Methods</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS3" title="In III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS3.SSS1" title="In III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span>1 </span>Main experiment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS3.SSS2" title="In III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span>2 </span>Ablation study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS4" title="In III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Experiments in Industrial Recommendation Scenarios</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS4.SSS1" title="In III-D Experiments in Industrial Recommendation Scenarios ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span>1 </span>Simulation environment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS4.SSS2" title="In III-D Experiments in Industrial Recommendation Scenarios ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span>2 </span>Experimental results</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S4" title="In LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs*
<br class="ltx_break"/><sup class="ltx_sup" id="id4.id1"><span class="ltx_text" id="id4.id1.1" style="font-size:46%;">*</span></sup><span class="ltx_text" id="id5.id2" style="font-size:46%;">Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.</span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yongxin Deng<sup class="ltx_sup" id="id6.4.id1"><span class="ltx_text ltx_font_italic" id="id6.4.id1.1">∗</span></sup>, Xihe Qiu<sup class="ltx_sup" id="id7.5.id2"><span class="ltx_text ltx_font_italic" id="id7.5.id2.1">∗,†</span></sup>, Xiaoyu Tan<sup class="ltx_sup" id="id8.6.id3"><span class="ltx_text ltx_font_italic" id="id8.6.id3.1">∗</span></sup>, Wei Chu and Yinghui Xu
</span><span class="ltx_author_notes">* This is to indicate the equal contribution.† This is to indicate the corresponding author.Yongxin Deng, Xihe Qiu<span class="ltx_text ltx_font_typewriter" id="id9.7.id1" style="font-size:90%;">(email:qiuxihe@sues.edu.cn)</span> are with the School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, ChinaXiaoyu Tan, Wei Chu are with the INF Technology (Shanghai) Co., Ltd. Shanghai, China Yinghui Xu<span class="ltx_text ltx_font_typewriter" id="id10.8.id1" style="font-size:90%;">(email:xuyinghui@fudan.edu.cn)</span> is with the Artificial Intelligence Innovation and Incubation Institute, Fudan University, Shanghai, China</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id11.id1">The uncertainty inherent in the environmental transition model of Reinforcement Learning (RL) necessitates a careful balance between exploration and exploitation to optimize the use of computational resources for accurately estimating an agent’s expected reward. Achieving balance in control systems is particularly challenging in scenarios with sparse rewards. However, given the extensive prior knowledge available for many environments, it is redundant to begin learning from scratch in such settings. To address this, we introduce <span class="ltx_text ltx_font_bold" id="id11.id1.1">L</span>anguage <span class="ltx_text ltx_font_bold" id="id11.id1.2">M</span>odel <span class="ltx_text ltx_font_bold" id="id11.id1.3">G</span>uided <span class="ltx_text ltx_font_bold" id="id11.id1.4">T</span>rade-offs (i.e., <span class="ltx_text ltx_font_bold" id="id11.id1.5">LMGT</span>), a novel, sample-efficient framework that leverages the comprehensive prior knowledge embedded in Large Language Models (LLMs) and their adeptness at processing non-standard data forms, such as wiki tutorials. LMGT proficiently manages the exploration-exploitation trade-off by employing reward shifts guided by LLMs, which direct agents’ exploration endeavors, thereby improving sample efficiency. We have thoroughly tested LMGT across various RL tasks and deployed it in industrial-grade RL recommendation systems, where it consistently outperforms baseline methods. The results indicate that our framework can significantly reduce the time cost required during the training phase in RL.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.3">Reinforcement Learning (RL) encounters a fundamental challenge in finding a balance between exploration and exploitation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib1" title="">1</a>]</cite>. This equilibrium is crucial for ensuring the robustness of RL algorithms when applied in real-world scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib2" title="">2</a>]</cite>. Agents operating in such settings often face the exploration-exploitation dilemma due to the unknown and stochastic nature of their environments, making it impossible to deduce the exact environmental model. The interactions between the agent and the environment provide estimates of expected rewards, denoted as <math alttext="\hat{E}(R)" class="ltx_Math" display="inline" id="S1.p1.1.m1.1"><semantics id="S1.p1.1.m1.1a"><mrow id="S1.p1.1.m1.1.2" xref="S1.p1.1.m1.1.2.cmml"><mover accent="true" id="S1.p1.1.m1.1.2.2" xref="S1.p1.1.m1.1.2.2.cmml"><mi id="S1.p1.1.m1.1.2.2.2" xref="S1.p1.1.m1.1.2.2.2.cmml">E</mi><mo id="S1.p1.1.m1.1.2.2.1" xref="S1.p1.1.m1.1.2.2.1.cmml">^</mo></mover><mo id="S1.p1.1.m1.1.2.1" xref="S1.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S1.p1.1.m1.1.2.3.2" xref="S1.p1.1.m1.1.2.cmml"><mo id="S1.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S1.p1.1.m1.1.2.cmml">(</mo><mi id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">R</mi><mo id="S1.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><apply id="S1.p1.1.m1.1.2.cmml" xref="S1.p1.1.m1.1.2"><times id="S1.p1.1.m1.1.2.1.cmml" xref="S1.p1.1.m1.1.2.1"></times><apply id="S1.p1.1.m1.1.2.2.cmml" xref="S1.p1.1.m1.1.2.2"><ci id="S1.p1.1.m1.1.2.2.1.cmml" xref="S1.p1.1.m1.1.2.2.1">^</ci><ci id="S1.p1.1.m1.1.2.2.2.cmml" xref="S1.p1.1.m1.1.2.2.2">𝐸</ci></apply><ci id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">\hat{E}(R)</annotation><annotation encoding="application/x-llamapun" id="S1.p1.1.m1.1d">over^ start_ARG italic_E end_ARG ( italic_R )</annotation></semantics></math>, for different actions. However, estimating the mean of rewards using sample means introduces inherent error, which prevents us from being certain that the action with the highest <math alttext="\hat{E}(R)" class="ltx_Math" display="inline" id="S1.p1.2.m2.1"><semantics id="S1.p1.2.m2.1a"><mrow id="S1.p1.2.m2.1.2" xref="S1.p1.2.m2.1.2.cmml"><mover accent="true" id="S1.p1.2.m2.1.2.2" xref="S1.p1.2.m2.1.2.2.cmml"><mi id="S1.p1.2.m2.1.2.2.2" xref="S1.p1.2.m2.1.2.2.2.cmml">E</mi><mo id="S1.p1.2.m2.1.2.2.1" xref="S1.p1.2.m2.1.2.2.1.cmml">^</mo></mover><mo id="S1.p1.2.m2.1.2.1" xref="S1.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S1.p1.2.m2.1.2.3.2" xref="S1.p1.2.m2.1.2.cmml"><mo id="S1.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S1.p1.2.m2.1.2.cmml">(</mo><mi id="S1.p1.2.m2.1.1" xref="S1.p1.2.m2.1.1.cmml">R</mi><mo id="S1.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S1.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p1.2.m2.1b"><apply id="S1.p1.2.m2.1.2.cmml" xref="S1.p1.2.m2.1.2"><times id="S1.p1.2.m2.1.2.1.cmml" xref="S1.p1.2.m2.1.2.1"></times><apply id="S1.p1.2.m2.1.2.2.cmml" xref="S1.p1.2.m2.1.2.2"><ci id="S1.p1.2.m2.1.2.2.1.cmml" xref="S1.p1.2.m2.1.2.2.1">^</ci><ci id="S1.p1.2.m2.1.2.2.2.cmml" xref="S1.p1.2.m2.1.2.2.2">𝐸</ci></apply><ci id="S1.p1.2.m2.1.1.cmml" xref="S1.p1.2.m2.1.1">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.2.m2.1c">\hat{E}(R)</annotation><annotation encoding="application/x-llamapun" id="S1.p1.2.m2.1d">over^ start_ARG italic_E end_ARG ( italic_R )</annotation></semantics></math> is truly optimal. Consequently, exploration is necessary to reduce the discrepancy between the sample mean and the true mean. However, in situations where resources are limited, it is likely that the action with the highest <math alttext="\hat{E}(R)" class="ltx_Math" display="inline" id="S1.p1.3.m3.1"><semantics id="S1.p1.3.m3.1a"><mrow id="S1.p1.3.m3.1.2" xref="S1.p1.3.m3.1.2.cmml"><mover accent="true" id="S1.p1.3.m3.1.2.2" xref="S1.p1.3.m3.1.2.2.cmml"><mi id="S1.p1.3.m3.1.2.2.2" xref="S1.p1.3.m3.1.2.2.2.cmml">E</mi><mo id="S1.p1.3.m3.1.2.2.1" xref="S1.p1.3.m3.1.2.2.1.cmml">^</mo></mover><mo id="S1.p1.3.m3.1.2.1" xref="S1.p1.3.m3.1.2.1.cmml">⁢</mo><mrow id="S1.p1.3.m3.1.2.3.2" xref="S1.p1.3.m3.1.2.cmml"><mo id="S1.p1.3.m3.1.2.3.2.1" stretchy="false" xref="S1.p1.3.m3.1.2.cmml">(</mo><mi id="S1.p1.3.m3.1.1" xref="S1.p1.3.m3.1.1.cmml">R</mi><mo id="S1.p1.3.m3.1.2.3.2.2" stretchy="false" xref="S1.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p1.3.m3.1b"><apply id="S1.p1.3.m3.1.2.cmml" xref="S1.p1.3.m3.1.2"><times id="S1.p1.3.m3.1.2.1.cmml" xref="S1.p1.3.m3.1.2.1"></times><apply id="S1.p1.3.m3.1.2.2.cmml" xref="S1.p1.3.m3.1.2.2"><ci id="S1.p1.3.m3.1.2.2.1.cmml" xref="S1.p1.3.m3.1.2.2.1">^</ci><ci id="S1.p1.3.m3.1.2.2.2.cmml" xref="S1.p1.3.m3.1.2.2.2">𝐸</ci></apply><ci id="S1.p1.3.m3.1.1.cmml" xref="S1.p1.3.m3.1.1">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.3.m3.1c">\hat{E}(R)</annotation><annotation encoding="application/x-llamapun" id="S1.p1.3.m3.1d">over^ start_ARG italic_E end_ARG ( italic_R )</annotation></semantics></math> is indeed the best choice. Accurately estimating the optimal action is a fundamental aspect of RL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib4" title="">4</a>]</cite>, whereas suboptimal actions require less computational evaluation, reflecting the concept of “exploitation” in RL. The conflict between exploration and exploitation therefore necessitates the selection of actions that are both “close to the current estimate of the best action” while also being “different from it”.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Numerous studies have attempted to address this challenge. Common strategies include <math alttext="\epsilon" class="ltx_Math" display="inline" id="S1.p2.1.m1.1"><semantics id="S1.p2.1.m1.1a"><mi id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S1.p2.1.m1.1d">italic_ϵ</annotation></semantics></math>-greedy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib5" title="">5</a>]</cite>, Softmax <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib5" title="">5</a>]</cite>, upper confidence bound <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib6" title="">6</a>]</cite>, thompson sampling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib7" title="">7</a>]</cite>. The choice of an appropriate exploration-exploitation strategy depends on the specific application context and problem requirements, as different RL problems may require different strategies. Nevertheless, given the broadening scope of RL applications, manually selecting different exploration-exploitation strategies for each distinct environment is impractical. One major difficulty arises from multimodal and long-tailed data distributions. Some adaptive algorithms adjust the exploration-exploitation balance based on the agent’s experiences <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib8" title="">8</a>]</cite>, but these algorithms still have constraints that can significantly impact model performance and robustness when applied beyond their scope. Additionally, previous exploration-exploitation balance strategies either rely solely on adjusting the ratio based on the data distribution, without utilizing prior knowledge or require the design and adjustment of strategies based on domain expertise and a deep understanding of the task. The latter approach requires substantial manual effort and can potentially reduce learning performance if not properly designed.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address the limitations of traditional exploration-exploitation strategies, we propose a novel framework called <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">L</span>anguage <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">M</span>odel <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">G</span>uided <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">T</span>rade-offs (i.e., <span class="ltx_text ltx_font_bold" id="S1.p3.1.5">LMGT</span>), that leverages prior knowledge from various sources to guide agents’ inefficient learning with limited resources. Jake <span class="ltx_text ltx_font_italic" id="S1.p3.1.6">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib9" title="">9</a>]</cite> discovered that valuable insights can be derived from effective offline demonstration data, enabling agents to align themselves correctly. By capturing the patterns of a sound policy in a model and using this model for intrinsic motivation, the RL agent can effectively map itself to a skillful demonstration-defined subspace. In this subspace, even undirected exploration can significantly enhance the agent’s understanding of the environment if the deviations align with rational pathways. Our LMGT leverages the text comprehension and generation capabilities of Large Language Models (LLMs) to incorporate prior knowledge, thereby enhancing the agent’s environmental understanding and achieving a balance between exploration and exploitation. <span class="ltx_text ltx_font_bold" id="S1.p3.1.7">Leveraging the powerful language processing capabilities of LLMs, our framework obviates the need for highly structured prior knowledge, thereby enabling extensive use of existing human knowledge bases. This distinct advantage sets our approach apart from other methods.</span> Moreover, the text generated by LLMs often reflects the structural patterns of the real world, embedding common-sense knowledge about various aspects of human reasoning and intuition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib11" title="">11</a>]</cite>. <span class="ltx_text ltx_font_bold" id="S1.p3.1.8">Compared to some recent methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib14" title="">14</a>]</cite> that directly use LLMs as agents within the RL process, the advantage of our approach lies in the fact that LLMs are only required during the training phase to assist the agent in learning. This fundamentally mitigates the risks associated with LLM hallucinations by confining such risks to the training stage, thereby enhancing the security of the strategy implemented by the agent.</span> Once the training is complete, our agent can be deployed independently without LLMs. In contrast to agents utilizing LLMs kernels, conventional RL agents founded upon multilayer perceptrons or convolutional neural networks exhibit a comparative advantage regarding computational resource utilization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib15" title="">15</a>]</cite>. The potential advantages of our architecture become apparent in large-scale application scenarios and latency-sensitive environments. Our interactive process between LLMs and agents involves LLMs processing environmental information and scoring agent behavior to guide exploration and exploitation through reward-shifting mechanisms. Additionally, our method aligns with a key principle: reward shifting is equivalent to modifying the initialization of the Q-function, effectively balancing the exploration and exploitation aspects of RL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib16" title="">16</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We conducted experiments in various settings and environments, demonstrating that our approach effectively utilizes prior knowledge, leading to a reduction in model training costs compared to baseline methods. We also evaluated the performance of different LLMs within our framework, providing a partial assessment of their inferential capabilities. Furthermore, we applied our framework to Google’s industrial-grade recommendation algorithm, SlateQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib17" title="">17</a>]</cite>. Our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p5">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a novel framework that leverages LLMs to balance exploration and exploitation within RL. This framework effectively resolves the exploration-exploitation dilemma and provides precise guidance for the agent’s actions. <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Featuring a distinctive architecture that decouples the LLM from the agent, our approach significantly reduces the risk of LLM hallucinations impacting RL strategies.</span></p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We validated our proposed framework in various automatic control environments and RL algorithms. Experimental results demonstrate that our method significantly reduces the training costs of RL models while maintaining both generality and ease of use.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We demonstrate the effectiveness of our method in an industrial application context, providing a practical and straightforward solution to reduce the training cost of RL models for industry practitioners.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Methodology</span>
</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="424" id="S2.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S2.F1.2.1">The structure of our LMGT framework.</span> The LLM can observe the environment’s state and the actions selected by the agent. It will evaluate the agent’s behavior using prior knowledge, adjusting the final reward accordingly (via reward shifting). Thus, the agent’s stored experience inherently includes a component of prior knowledge.</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we present the overall structure and provide an in-depth exploration of the aspects relevant to prompts within our framework.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.4.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.5.2">Framework Structure</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">RL methods are categorized into “on-policy” and “off-policy” based on how data is generated and processed. On-policy and off-policy methods are often viewed as distinct due to significant differences in their policy frameworks and algorithmic implementations in practice. These differences influence algorithm selection and optimization techniques. For instance, off-policy methods must address the importance of sampling issues associated with using data from non-target policies—a challenge not faced by on-policy methods. Broadly, however, on-policy methods can be seen as a subset of off-policy methods, where the behavior policy (which generates the data) aligns with the target policy (the policy under optimization). <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">Thus, off-policy definitions are inherently broader, encompassing all scenarios, even those where the learning and behavior policies coincide. All descriptions related to RL mentioned below refer to off-policy methods.</span> A common RL training process is as follows:</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<ol class="ltx_enumerate" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">Initialization of the evaluation policy and the behavioral policy. The evaluation policy may be initialized as a stochastic policy, such as a random policy, while the behavioral policy may take the form of an <math alttext="\epsilon" class="ltx_Math" display="inline" id="S2.I1.i1.p1.1.m1.1"><semantics id="S2.I1.i1.p1.1.m1.1a"><mi id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.1.m1.1d">italic_ϵ</annotation></semantics></math>-greedy policy, incorporating a probability of random exploration.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">The agent engages with the environment based on the behavioral policy, yielding training data in the form of state-action-reward-next state tuples. These data are then archived within an experience replay buffer.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">Training data is sampled from the experience replay buffer, and the agent’s parameters are updated based on the evaluation policy and the sampled data, employing techniques such as Temporal Difference (TD) learning or Monte Carlo methods.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1">Periodic evaluation of the evaluation policy’s performance within the environment, with training termination contingent on the attainment of a predefined performance threshold.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.2">The process iterates by returning to step 2, with periodic adjustments to the behavioral policy, such as the gradual reduction of <math alttext="\epsilon" class="ltx_Math" display="inline" id="S2.I1.i5.p1.1.m1.1"><semantics id="S2.I1.i5.p1.1.m1.1a"><mi id="S2.I1.i5.p1.1.m1.1.1" xref="S2.I1.i5.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i5.p1.1.m1.1b"><ci id="S2.I1.i5.p1.1.m1.1.1.cmml" xref="S2.I1.i5.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i5.p1.1.m1.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i5.p1.1.m1.1d">italic_ϵ</annotation></semantics></math> in the case of an <math alttext="\epsilon" class="ltx_Math" display="inline" id="S2.I1.i5.p1.2.m2.1"><semantics id="S2.I1.i5.p1.2.m2.1a"><mi id="S2.I1.i5.p1.2.m2.1.1" xref="S2.I1.i5.p1.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i5.p1.2.m2.1b"><ci id="S2.I1.i5.p1.2.m2.1.1.cmml" xref="S2.I1.i5.p1.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i5.p1.2.m2.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i5.p1.2.m2.1d">italic_ϵ</annotation></semantics></math>-greedy policy.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">To ensure the wide-ranging applicability of our improvements, we aim to preserve the fundamental principles of the original RL training process with minimal intervention. LMGT introduces a specific modification to the second step, which involves adjusting the acquired experiences of the agent. We consider the LLM as the “evaluator”. When the agent observes the environmental state, it selects an action based on the prevailing behavioral policy and communicates this action to the environment. We replicate and transmit both the observable state of the environment and the chosen action to the LLM. The LLM assesses the agent’s actions and assigns a score, taking into account the prior knowledge that is embedded in its weights or introduced through the prompt (such as game rules). This score serves as a reward shift, which is incorporated into the reward generated by the environment itself. In contrast to the conventional RL process, LMGT involves the agent recording adjusted rewards instead of relying on the inherent rewards provided by the environment. The agent then learns from these adapted rewards to gain guidance from the LLMs.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">In situations with sparse rewards, the agent faces challenges in accumulating information through trial and error. Hence, we employ the LLM to guide the agent, to avoid the pursuit of directions that have been previously determined as “valueless” based on prior knowledge, as indicated by a negative reward shift. The LLM assigns a positive reward shift for actions identified as “valuable” according to prior knowledge, encouraging the agent to focus on exploitation. While maintaining the traditional exploration-exploitation strategy from classical RL, the agent intensifies its exploration of actions neighboring those deemed “valuable” in the prior knowledge, increasing the likelihood of discovering the “optimal” action. Additionally, for actions not referenced in prior knowledge, the LLM assigns a “0” reward shift, allowing the agent to explore based on the original exploration policy.</p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1">The framework of LMGT is presented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S2.F1" title="Figure 1 ‣ II Methodology ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">1</span></a>. For different tasks, the LLM provides various forms of reward shifts, guided by the principle that intricate tasks require more nuanced reward shifts, while simpler tasks require simpler reward shifts, using “+1,” “0,” and “-1” to represent “approval”, “neutral”, and “disapproval”, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.4.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.5.2">Prompt Design</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In this section, we will discuss the engineering methodology applied to optimize the performance of LLMs. The primary emphasis is placed on the performance attributes of LLMs, specifically concerning the magnitude of embedded prior knowledge in their weight configurations, as well as their capacity to comprehend and harness pre-existing knowledge about textual genres. The efficacy of the reward-shifting mechanism, generated by LLMs, fundamentally dictates the success of our approach and the extent of enhancement in comparison to the baseline.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T3" title="TABLE III ‣ III-C1 Main experiment ‣ III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">III</span></a> catalogs a detailed inventory of immediate enhancements utilized in our experimental design. It is important to note that the primary distinction between Zero-shot <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib18" title="">18</a>]</cite> and Baseline involves Zero-shot’s integration of specific, task-related information into the prompt, which guides the LLM regarding the appropriate information to produce. The Name method could be perceived as perplexing. It involves attributing a name to an LLM in the prompt with the expectation that this modification could enhance its performance. Nonetheless, our experimental results indicate that this technique does not yield any improvements. For additional details on the experiments, please see Section <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS3" title="III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>. It is commonplace to deploy multiple prompt enhancements concurrently.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Furthermore, our prompt design is further categorized into two distinct classes: “prior-knowledge-inclusive prompt statements” and “prior-knowledge-exclusive prompt statements”. The former class provides an all-encompassing evaluation of the LLMs’ ability to harness their embedded prior knowledge, including their proficiency in leveraging prior knowledge presented in non-standard linguistic forms, such as natural language text. The latter class, on the other hand, exclusively investigates the LLMs’ aptitude for exploiting implicit prior knowledge embedded within their model weights.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Section <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3" title="III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">III</span></a> presents an elucidation of the effects of various prompt methods, along with a rationale for our methodological choices.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Experiment</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The experiment is structured into three distinct parts. <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">In the initial phase, we scrutinize the benefits of our proposed framework over conventional approaches for addressing sparse reward challenges.</span> Specifically, we compare LMGT with Return Decomposition for Delayed Rewards (RUDDER) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib19" title="">19</a>]</cite>, which is a novel RL approach for delayed rewards in finite MDPs. RUDDER’s objective is to neutralize expected future rewards, thereby simplifying Q-value estimations to the average of immediate rewards. Despite RUDDER’s expedited processing in scenarios with delayed rewards compared to traditional RL methods, it fails to incorporate prior knowledge—an area where LMGT particularly excels. Consequently, we anticipate LMGT to facilitate the expedited development of effective behavioral strategies by agents. <span class="ltx_text ltx_font_bold" id="S3.p1.1.2">The second segment of the experiment evaluates our framework’s versatility by applying it across diverse RL algorithms and environments to ascertain its efficacy.</span> This was accomplished by benchmarking across various standard environments provided by Gymnasium <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib20" title="">20</a>]</cite>, an API platform that supports single-agent RL environments such as cartpole, pendulum, mountain-car, mujoco, and atari. Herein, we also examine the enhancement in performance attributable to our framework across various RL algorithms, compared to the baseline algorithms presented in Stable Baselines3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib21" title="">21</a>]</cite>—a collection of robust RL algorithm implementations in PyTorch. This phase further includes an assessment of the impact of different prompting techniques on our framework’s performance and an exploratory evaluation of the reasoning capabilities of LLMs within our framework. <span class="ltx_text ltx_font_bold" id="S3.p1.1.3">To ensure that the evaluation conclusions of our framework extend beyond synthetic settings, the final section investigates its practical applications and improvements.</span> Specifically, we explore its integration with Google’s SlateQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib17" title="">17</a>]</cite>, a sophisticated recommendation algorithm that employs slate decomposition. This approach effectively manages the complexity of recommending multiple items simultaneously, addressing the challenge of large action spaces found in previous RL recommendation algorithms. This implementation was tested within a simulated environment on RecSim <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib22" title="">22</a>]</cite>, a versatile platform for developing simulation environments for recommender systems (RSs), facilitating sequential user interactions.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Experimental Settings</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For both LLM inference and agent training, we utilize a single NVIDIA A800-80G GPU. We adhere to the recommended settings by Llama for precise inference, which encompass a temperature of 0.7, top_p of 0.1, a repetition penalty of 1.18, and top_k of 40.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Comparison Experiments with Traditional Exploration-Exploitation Trade-off Methods</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2">We conducted a comparative study of LMGT and RUDDER using a classic pocket watch repair task as a case study. This task involves repairing and selling a pocket watch, where the decision to repair, contingent on the brand, hinges on cost-benefit analysis given a known selling price versus unknown repair and delivery expenses leading to negative rewards. The challenge lies in delayed rewards, where the profitability of repairing a specific brand becomes apparent only after total costs are established. The objective was to equip the agent with a strategy that consistently achieves a “break-even decision” ratio exceeding <math alttext="90\%" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">90</mn><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1">percent</csymbol><cn id="S3.SS2.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">90\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">90 %</annotation></semantics></math>. “The number of episodes to learn a qualified strategy” (expressed as <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.2.1">Episode</span>) and “the time to learn a qualified strategy” (expressed as <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.2.2">Time</span>) served as our evaluation metrics, acknowledging that training time is influenced by hardware performance and hence, primarily offers qualitative insights. In this part of the experiment, to align with the baseline chosen by RUDDER in the example, we applied LMGT to temporal difference (TD). To mitigate random seed effects on outcomes, experiments were conducted using seeds <math alttext="\{42,43,44,45,46\}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.5"><semantics id="S3.SS2.p1.2.m2.5a"><mrow id="S3.SS2.p1.2.m2.5.6.2" xref="S3.SS2.p1.2.m2.5.6.1.cmml"><mo id="S3.SS2.p1.2.m2.5.6.2.1" stretchy="false" xref="S3.SS2.p1.2.m2.5.6.1.cmml">{</mo><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">42</mn><mo id="S3.SS2.p1.2.m2.5.6.2.2" xref="S3.SS2.p1.2.m2.5.6.1.cmml">,</mo><mn id="S3.SS2.p1.2.m2.2.2" xref="S3.SS2.p1.2.m2.2.2.cmml">43</mn><mo id="S3.SS2.p1.2.m2.5.6.2.3" xref="S3.SS2.p1.2.m2.5.6.1.cmml">,</mo><mn id="S3.SS2.p1.2.m2.3.3" xref="S3.SS2.p1.2.m2.3.3.cmml">44</mn><mo id="S3.SS2.p1.2.m2.5.6.2.4" xref="S3.SS2.p1.2.m2.5.6.1.cmml">,</mo><mn id="S3.SS2.p1.2.m2.4.4" xref="S3.SS2.p1.2.m2.4.4.cmml">45</mn><mo id="S3.SS2.p1.2.m2.5.6.2.5" xref="S3.SS2.p1.2.m2.5.6.1.cmml">,</mo><mn id="S3.SS2.p1.2.m2.5.5" xref="S3.SS2.p1.2.m2.5.5.cmml">46</mn><mo id="S3.SS2.p1.2.m2.5.6.2.6" stretchy="false" xref="S3.SS2.p1.2.m2.5.6.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.5b"><set id="S3.SS2.p1.2.m2.5.6.1.cmml" xref="S3.SS2.p1.2.m2.5.6.2"><cn id="S3.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS2.p1.2.m2.1.1">42</cn><cn id="S3.SS2.p1.2.m2.2.2.cmml" type="integer" xref="S3.SS2.p1.2.m2.2.2">43</cn><cn id="S3.SS2.p1.2.m2.3.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.3.3">44</cn><cn id="S3.SS2.p1.2.m2.4.4.cmml" type="integer" xref="S3.SS2.p1.2.m2.4.4">45</cn><cn id="S3.SS2.p1.2.m2.5.5.cmml" type="integer" xref="S3.SS2.p1.2.m2.5.5">46</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.5c">\{42,43,44,45,46\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.5d">{ 42 , 43 , 44 , 45 , 46 }</annotation></semantics></math>, with results averaged. As evidenced in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T1" title="TABLE I ‣ III-B Comparison Experiments with Traditional Exploration-Exploitation Trade-off Methods ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">I</span></a>, LMGT outperformed RUDDER, requiring fewer episodes for strategy acquisition and demonstrating reduced training time. However, the reduced time advantage of LMGT over episodes suggests a potential threshold beyond which the efficiencies derived from LLM guidance might be counterbalanced by computational overheads. This threshold presents a future research direction for us.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Performance of LMGT and RUDDER in watch repair task.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">Metric</span></th>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.2.2.1">Episode</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.2">Time(sec)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.3.1.1">TD</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.3.1.2">71823</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.3.1.3">427</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.4.2.1">MC</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.4.2.2">221770</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.4.2.3">530</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.5.3.1">RUDDER</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.5.3.2">2029</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.5.3.3">171</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.4.1">LMGT(ours)+TD</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.4.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.6.4.2.1">417</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S3.T1.1.6.4.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.6.4.3.1">114</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.4.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments</span>
</h3>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS3.SSS1.4.1.1">III-C</span>1 </span>Main experiment</h4>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">This section undertakes a comprehensive evaluation of the efficacy of our LMGT framework across various RL environments, employing diverse RL algorithms. Detailed experimental findings are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T2" title="TABLE II ‣ III-C1 Main experiment ‣ III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">II</span></a>, in the “metric” column, “AR” is an abbreviation for average reward, and “BR” is an abbreviation for boosted reward, red numbers indicate that our method is inferior to the baseline in this scenario. <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS1.p1.1.1">Please be advised that all rewards presented in the results correspond to the environments’ intrinsic rewards and have not been modified.</span> The environments are identified with their observable states furnished to the LLMs in two distinct formats: a standardized numerical representation, denoted as “box” (e.g., a tuple encapsulating information on object positions), and a more intuitively comprehensible visual format referred to as “human” (such as a screenshot of the current frame). Our metric for assessing our approach against baseline methods is the “average reward of the model after a fixed number of training time steps”. Specifically, agents are trained separately using our method and baseline techniques within the same environment, and the trained weights are preserved after a predefined number of time steps. Subsequently, we evaluate the performance of models trained using different methods, employing an equivalent number of training time steps in the same environment, while comparing their average rewards.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p2">
<p class="ltx_p" id="S3.SS3.SSS1.p2.1">Throughout these experiments, we maintained a consistent choice of LLM and prompt techniques. Specifically, two prompt methods were employed: CoT and Zero-shot prompt, to formulate our prompts. The 4-bit quantized version of the Vicuna-30B model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib23" title="">23</a>]</cite>, with GPTQ quantization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib24" title="">24</a>]</cite>, was utilized as our guiding LLM within our framework. This model is utilized to assess the quality of agent behavior in distinct environmental states. We contend that this configuration optimizes the performance of our framework, and we will delve into the influence of different prompt techniques and LLMs on the framework’s performance in other parts of this section.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Experimental results under different settings.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.1.1.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.1.1.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.1.1.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.1.1.4"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S3.T2.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.5.1">Observable Environmental State Format</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2.2">
<td class="ltx_td ltx_border_r" id="S3.T2.1.2.2.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.2.2.2"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.2.2.3"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.2.2.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S3.T2.1.2.2.5">box</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S3.T2.1.2.2.6">human</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.3">
<td class="ltx_td ltx_border_r" id="S3.T2.1.3.3.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.3.3.2"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.3.3.3"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.3.3.4"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S3.T2.1.3.3.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.3.5.1">Time steps</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.4.4.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.4.1.1">Environment</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.4.4.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.4.2.1">Algorithm</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.4.4.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.4.3.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.4.4.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.4.4.1">Metric</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.5">n=100</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.6">n=1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.7">n=10000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.8">n=100</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.9">n=1000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.4.4.10">n=10000</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5.5">
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.5.5.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.5.5.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.5.5.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.5">10.15</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.6">9.40</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.7">9.30</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.8">10.15</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.9">9.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.5.5.10">9.30</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6.6">
<td class="ltx_td ltx_border_r" id="S3.T2.1.6.6.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.6.6.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.6.6.4"><span class="ltx_text" id="S3.T2.1.6.6.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.6.5.1">11.20</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.6.6.1">11.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.6.7.1">11.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.6.8.1">10.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.6.9.1">10.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.6.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.6.10.1">11.00</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.7.7">
<td class="ltx_td ltx_border_r" id="S3.T2.1.7.7.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.7.7.2"><span class="ltx_text" id="S3.T2.1.7.7.2.1">DQN<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib25" title="">25</a>]</cite></span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.7.7.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.5">1.05</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.6">1.90</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.7">2.60</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.8">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.9">0.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.7.7.10">1.70</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.8.8">
<td class="ltx_td ltx_border_r" id="S3.T2.1.8.8.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.8.8.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.8.8.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.5">113.45</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.6">368.90</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.7">418.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.8">113.45</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.9">368.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.8.8.10">418.00</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.9.9">
<td class="ltx_td ltx_border_r" id="S3.T2.1.9.9.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.9.9.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.9.9.4"><span class="ltx_text" id="S3.T2.1.9.9.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.9.9.5.1">245.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.9.9.6.1">380.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.9.9.7.1">435.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.9.9.8.1">115.50</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.9"><span class="ltx_text" id="S3.T2.1.9.9.9.1" style="color:#FE0000;">360.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.9.9.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.9.9.10.1">421.30</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.10.10">
<td class="ltx_td ltx_border_r" id="S3.T2.1.10.10.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.10.10.2"><span class="ltx_text" id="S3.T2.1.10.10.2.1">PPO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib26" title="">26</a>]</cite></span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.10.10.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.5">132.45</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.6">11.85</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.7">17.90</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.8">2.05</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.9">-8.50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.10.10.10">3.30</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.11.11">
<td class="ltx_td ltx_border_r" id="S3.T2.1.11.11.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.11.11.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.11.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.11.11.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.11.5">36.70</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.11.6">40.70</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.11.7">127.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.11.8">36.70</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.11.9">40.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.11.10">127.00</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.12.12">
<td class="ltx_td ltx_border_r" id="S3.T2.1.12.12.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.12.12.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.12.12.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.12.12.4"><span class="ltx_text" id="S3.T2.1.12.12.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.12.12.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.12.12.5.1">42.50</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.12.12.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.12.12.6.1">78.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.12.12.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.12.12.7.1">127.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.12.12.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.12.12.8.1">37.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.12.12.9"><span class="ltx_text" id="S3.T2.1.12.12.9.1" style="color:#FE0000;">39.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.12.12.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.12.12.10.1">131.20</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.13.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.13.13.1"><span class="ltx_text" id="S3.T2.1.13.13.1.1">Cart Pole</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.13.13.2"><span class="ltx_text" id="S3.T2.1.13.13.2.1">A2C<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib27" title="">27</a>]</cite></span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.13.13.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.13.13.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.13.13.5">5.80</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.13.13.6">38.20</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.13.13.7">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.13.13.8">0.30</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.13.13.9">-1.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.13.13.10">4.20</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.14.14">
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.14.14.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.14.14.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.14.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.14.14.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.14.5">-1430.32</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.14.6">-1747.89</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.14.7">-107.41</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.14.8">-1430.32</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.14.9">-1747.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.14.10">-107.41</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.15.15">
<td class="ltx_td ltx_border_r" id="S3.T2.1.15.15.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.15.15.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.15.15.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.15.15.4"><span class="ltx_text" id="S3.T2.1.15.15.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.15.15.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.15.5.1">-1071.59</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.15.15.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.15.6.1">-409.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.15.15.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.15.7.1">-100.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.15.15.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.15.8.1">-1396.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.15.15.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.15.9.1">-1421.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.15.15.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.15.10.1">-105.74</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.16.16">
<td class="ltx_td ltx_border_r" id="S3.T2.1.16.16.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.16.16.2"><span class="ltx_text" id="S3.T2.1.16.16.2.1">SAC<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib28" title="">28</a>]</cite></span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.16.16.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.16.16.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.16.16.5">358.73</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.16.16.6">1338.20</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.16.16.7">6.51</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.16.16.8">33.48</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.16.16.9">326.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.16.16.10">1.67</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.17.17">
<td class="ltx_td ltx_border_r" id="S3.T2.1.17.17.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.17.17.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.17.17.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.17.17.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.17.17.5">-1487.59</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.17.17.6">-1482.55</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.17.17.7">-152.24</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.17.17.8">-1487.59</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.17.17.9">-1482.55</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.17.17.10">-152.24</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.18.18">
<td class="ltx_td ltx_border_r" id="S3.T2.1.18.18.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.18.18.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.18.18.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.18.18.4"><span class="ltx_text" id="S3.T2.1.18.18.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.18.18.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.18.5.1">-1450.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.18.18.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.18.6.1">-305.20</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.18.18.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.18.7.1">-139.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.18.18.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.18.8.1">-1385.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.18.18.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.18.9.1">-912.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.18.18.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.18.10.1">-149.51</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.19.19">
<td class="ltx_td ltx_border_r" id="S3.T2.1.19.19.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.19.19.2"><span class="ltx_text" id="S3.T2.1.19.19.2.1">TD3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib29" title="">29</a>]</cite></span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.19.19.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.19.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.19.5">36.88</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.19.6">1177.35</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.19.7">12.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.19.8">102.17</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.19.9">569.88</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.19.10">2.73</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.20.20">
<td class="ltx_td ltx_border_r" id="S3.T2.1.20.20.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.20.20.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.20.20.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.20.20.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.20.20.5">-1324.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.20.20.6">-1067.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.20.20.7">-1012.46</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.20.20.8">-1324.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.20.20.9">-1067.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.20.20.10">-1012.46</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.21.21">
<td class="ltx_td ltx_border_r" id="S3.T2.1.21.21.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.21.21.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.21.21.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.21.21.4"><span class="ltx_text" id="S3.T2.1.21.21.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.21.21.5">-1021.50</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.21.21.6">-1019.97</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.21.21.7">-803.31</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.21.21.8">-1321.41</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.21.21.9">-1052.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.21.21.10">-1000.30</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.22.22">
<td class="ltx_td ltx_border_r" id="S3.T2.1.22.22.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.22.22.2"><span class="ltx_text" id="S3.T2.1.22.22.2.1">PPO</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.22.22.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.22.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.22.5">302.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.22.6">47.03</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.22.7">209.15</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.22.8">2.84</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.22.9">14.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.22.10">12.16</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.23.23">
<td class="ltx_td ltx_border_r" id="S3.T2.1.23.23.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.23.23.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.23.23.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.23.23.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.23.23.5">-1454.98</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.23.23.6">-1251.78</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.23.23.7">-1219.39</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.23.23.8">-1454.98</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.23.23.9">-1251.78</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.23.23.10">-1219.39</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.24.24">
<td class="ltx_td ltx_border_r" id="S3.T2.1.24.24.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T2.1.24.24.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.24.24.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.24.24.4"><span class="ltx_text" id="S3.T2.1.24.24.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.24.24.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.24.24.5.1">-1232.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.24.24.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.24.24.6.1">-1239.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.24.24.7"><span class="ltx_text" id="S3.T2.1.24.24.7.1" style="color:#FE0000;">-1220.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.24.24.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.24.24.8.1">-1421.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.24.24.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.24.24.9.1">-1248.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.24.24.10"><span class="ltx_text" id="S3.T2.1.24.24.10.1" style="color:#FE0000;">-1231.71</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.25.25">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T2.1.25.25.1"><span class="ltx_text" id="S3.T2.1.25.25.1.1">Pendulum</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T2.1.25.25.2"><span class="ltx_text" id="S3.T2.1.25.25.2.1">A2C</span></td>
<td class="ltx_td ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.25.25.3"></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.25.25.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.25.25.5">222.41</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.25.25.6">11.86</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.25.25.7">-1.35</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.25.25.8">33.73</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.25.25.9">3.12</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T2.1.25.25.10">-12.32</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS3.SSS1.p3">
<p class="ltx_p" id="S3.SS3.SSS1.p3.1">RL environments are seldom conveyed through purely textual descriptions; thus, LLMs necessitate multimodal capabilities to process such information. Common LLMs such as Llama, Llama2, and Vicuna do not inherently support multimodal functionality. <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS1.p3.1.1">To address this limitation, we adopted a pipeline model approach, where multiple single-modal models work synergistically, with each model responsible for processing specific data types and passing results to the next model to accomplish tasks.</span> In our experiments, we integrated LLaVA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib30" title="">30</a>]</cite> as the image processing model preceding the LLM. Therefore, in the aforementioned experiments, LLaVA was integrated with the Vicuna-30B model and operated collaboratively, equipping our “scorer” with image processing capabilities.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p4">
<p class="ltx_p" id="S3.SS3.SSS1.p4.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T2" title="TABLE II ‣ III-C1 Main experiment ‣ III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">II</span></a> illustrates that our framework consistently outperforms baseline methods across a majority of environments and various RL algorithms. It effectively achieves a trade-off between exploration and exploitation in RL methods, enabling agents to acquire skills more rapidly, thus leading to cost savings during training. Moreover, we observed that our framework’s performance is relatively inferior in tasks necessitating the utilization of pipeline models to process visual information compared to tasks that exclusively involve text information processing. In essence, if Vicuna-30B is required to handle additional image information from LLaVA, its performance tends to deteriorate. An intriguing observation proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib31" title="">31</a>]</cite> suggests that
attempting to enforce strict adherence of the LLM to response templates results in reduced performance across all scenarios.
We hypothesize that both these scenarios signify a degradation in LLM performance in multitask settings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib32" title="">32</a>]</cite>. Within our framework, “understanding extracted image information” and “assigning scores to agent behavior based on a combination of different information” represent distinct tasks, while the phenomenon mentioned in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib31" title="">31</a>]</cite> pertains to “providing responses based on prompts” and “formatting responses as required” as two separate tasks.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p5">
<p class="ltx_p" id="S3.SS3.SSS1.p5.1">We also investigated the influence of different prompt methods on the performance of our framework. Similar to the previous experiments, while keeping other variables constant, we continued to employ the 4-bit quantized version of the Vicuna-30B model as our LLM and the A2C algorithm as our RL technique. We conducted tests on two representative environments, and the experimental results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T3" title="TABLE III ‣ III-C1 Main experiment ‣ III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">III</span></a>. It is assumed that prompts in the table all inherently contain prior knowledge. For both simple (Cart Pole) and complex (Blackjack) environments, the most effective prompt method was found to be CoT. CoT particularly excelled in enhancing performance for complex tasks. We discovered that the model often overlooked the provided information and resulted in a uniform outcome unless explicitly instructed to employ hierarchical thinking in challenging tasks. Furthermore, we observed that merely assigning a simple name to the model scarcely enhanced its performance.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p6">
<p class="ltx_p" id="S3.SS3.SSS1.p6.1">An intriguing observation emerged when comparing prompt methods on our task: the “Zero-shot prompt” method outperformed the “Few-shot prompt” method. Few-shot prompts often led the Vicuna-30B model to generate results with a sense of “illusion”. Vicuna-30B frequently produced arbitrary extensions based on the provided examples. Furthermore, we observed that incorporating prior knowledge into the prompts can lead to an improvement in the performance of our framework, despite the fact that the weights within the Vicuna-30B model already encompass the requisite prior knowledge for addressing the challenges presented by the environment.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>The impact of employing various prompt strategies.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.1" style="width:337.5pt;height:244.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-29.8pt,21.6pt) scale(0.85,0.85) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S3.T3.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" colspan="3" id="S3.T3.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.2.1">Time steps</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.2.1.1.1">Prompt</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.2.1.2.1">Environment</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.2.1.3">n=100</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.2.1.4">n=1000</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.2.1.5">n=10000</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.3.2.1" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.3.2.1.1">Baseline</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.3.2.2">Cart Pole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.3.2.3">37.70</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.3.2.4">42.70</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.3.2.5">125.90</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.4.3.1">Blackjack</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.4.3.2">-0.20</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.4.3.3">0.20</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.4.3.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.5.4.1" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.5.4.1.1">CoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib33" title="">33</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.5.4.2">Cart Pole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.5.4.3">42.10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.5.4.4">74.00</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.5.4.5">126.00</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.6.5.1">Blackjack</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.6.5.2">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.6.5.3">0.28</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.6.5.4">0.45</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.7.6.1" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.7.6.1.1">Zero-shot prompt<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib18" title="">18</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.7.6.2">Cart Pole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.7.6.3">38.70</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.7.6.4">68.90</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.7.6.5">126.00</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.8.7.1">Blackjack</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.8.7.2">0.10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.8.7.3">0.28</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.8.7.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.9.8">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.9.8.1" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.9.8.1.1">Few-shot prompt<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib34" title="">34</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.9.8.2">Cart Pole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.9.8.3">38.10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.9.8.4">65.00</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.9.8.5">125.10</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.10.9">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.10.9.1">Blackjack</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.10.9.2">-0.20</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.10.9.3">0.20</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.10.9.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.11.10">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.11.10.1" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.11.10.1.1">Name<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib31" title="">31</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.11.10.2">Cart Pole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.11.10.3">37.10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.11.10.4">42.90</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.11.10.5">125.90</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.12.11">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.12.11.1">Blackjack</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.12.11.2">-0.20</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.12.11.3">0.20</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.12.11.4">0.33</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.13.12">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.13.12.1">CoT+Zero-shot prompt</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.13.12.2">Cart Pole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.13.12.3">42.00</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.13.12.4">77.10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.13.12.5">126.10</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.14.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T3.1.1.14.13.1">(excluded priori knowledge)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.14.13.2">Blackjack</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.14.13.3">0.00</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.14.13.4">0.25</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.14.13.5">0.40</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.15.14">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.15.14.1">CoT+Zero-shot prompt</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.15.14.2">Cart Pole</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.15.14.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.15.14.3.1">42.50</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.1.1.15.14.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.15.14.4.1">78.90</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.15.14.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.15.14.5.1">127.00</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.16.15">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S3.T3.1.1.16.15.1">(included prior knowledge)</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.1.16.15.2">Blackjack</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.1.16.15.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.16.15.3.1">0.12</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.1.16.15.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.16.15.4.1">0.30</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S3.T3.1.1.16.15.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.16.15.5.1">0.45</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS3.SSS1.p7">
<p class="ltx_p" id="S3.SS3.SSS1.p7.1">We also conducted experiments to assess the performance of different LLMs serving as the “evaluators” within our framework, thereby partially evaluating their inferential capabilities, we opted for the Blackjack environment for testing. The experimental results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T5" title="TABLE V ‣ III-D1 Simulation environment ‣ III-D Experiments in Industrial Recommendation Scenarios ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">V</span></a>. “Vicuna-30B-4bit-GPTQ” indicates the use of the Vicuna model, with a size of 30 billion parameters, employing GPTQ quantization with 4-bit precision. “Llama2-13B-8bit” signifies the use of the Llama2 model with a size of 13 billion parameters, without any quantization, running in 8-bit floating-point precision. We kept the prompt statements constant by using CoT and Zero-shot prompt, with the inclusion of prior knowledge, and fixed the RL algorithm (A2C).</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p8">
<p class="ltx_p" id="S3.SS3.SSS1.p8.1">From Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T5" title="TABLE V ‣ III-D1 Simulation environment ‣ III-D Experiments in Industrial Recommendation Scenarios ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">V</span></a>, we observe that the precision of quantization has a limited impact on inferential capabilities in the same model. A well-considered quantization method can effectively mitigate the performance loss resulting from quantization. Model size, on the other hand, has a more significant influence on a model’s inferential capabilities, a minimally sized language model fails to yield any significant improvement. Additionally, models of identical scale exhibit variations in their inferential capabilities, confined solely within the scope of our framework.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS3.SSS2.4.1.1">III-C</span>2 </span>Ablation study</h4>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">In Section <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.SS3.SSS1" title="III-C1 Main experiment ‣ III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span>1</span></a>, we noted that requiring a LLM to perform multiple tasks simultaneously within a single query might compromise its capability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib31" title="">31</a>]</cite>. Based on this principle, we designed an ablation experiment to test the performance of LMGT in both the ‘box’ and ‘human’ formats within a more visually complex Blackjack environment. For the latter, recognizing card information and converting it into numerical data constitutes a highly specialized task. When the LLM must first process complex visual data, its reasoning ability diminishes. The experimental results, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T4" title="TABLE IV ‣ III-C2 Ablation study ‣ III-C Evaluation of LMGT among Various Reinforcement Learning Algorithms and Environments ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">IV</span></a>, reveal that LMGT’s performance in the ‘human’ format fluctuates around the baseline, indicating performance deterioration in this context. This finding demonstrates that our LMGT effectively leverages the LLM’s capabilities to guide the agent’s learning: when the LLM’s capability is insufficient to provide guidance, the agent’s performance reverts to the baseline.</p>
</div>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Ablation Studies in Blackjack environment.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T4.1.1.1">
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.1.1.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.1.1.2"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.1.1.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.1.1.4"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S3.T4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T4.1.1.1.5.1">Observable Environmental State Format</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.2.2">
<td class="ltx_td ltx_border_r" id="S3.T4.1.2.2.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.2.2.2"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.2.2.3"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.2.2.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S3.T4.1.2.2.5">box</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S3.T4.1.2.2.6">human</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.3.3">
<td class="ltx_td ltx_border_r" id="S3.T4.1.3.3.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.3.3.2"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.3.3.3"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.3.3.4"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S3.T4.1.3.3.5"><span class="ltx_text ltx_font_bold" id="S3.T4.1.3.3.5.1">Time steps</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.4.1"><span class="ltx_text ltx_font_bold" id="S3.T4.1.4.4.1.1">Environment</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.4.2"><span class="ltx_text ltx_font_bold" id="S3.T4.1.4.4.2.1">Algorithm</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.4.3"><span class="ltx_text ltx_font_bold" id="S3.T4.1.4.4.3.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.4.4.4"><span class="ltx_text ltx_font_bold" id="S3.T4.1.4.4.4.1">Metric</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.4.4.5">n=100</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.4.4.6">n=1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.4.4.7">n=10000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.4.4.8">n=100</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.4.4.9">n=1000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.4.4.10">n=10000</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.5.5">
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.5.5.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.5.5.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.5.5.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.5.5.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.5.5.5">-0.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.5.5.6">-0.08</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.5.5.7">-0.08</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.5.5.8">-0.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.5.5.9">-0.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.5.5.10">-0.08</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.6.6">
<td class="ltx_td ltx_border_r" id="S3.T4.1.6.6.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.6.6.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.6.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.6.6.4"><span class="ltx_text" id="S3.T4.1.6.6.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S3.T4.1.6.6.5.1">-0.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S3.T4.1.6.6.6.1">-0.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.6.7"><span class="ltx_text ltx_font_bold" id="S3.T4.1.6.6.7.1">0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.6.8"><span class="ltx_text ltx_font_bold" id="S3.T4.1.6.6.8.1">-0.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.6.6.9"><span class="ltx_text ltx_font_bold" id="S3.T4.1.6.6.9.1">-0.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.6.6.10"><span class="ltx_text" id="S3.T4.1.6.6.10.1" style="color:#FE0000;">-0.09</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.7.7">
<td class="ltx_td ltx_border_r" id="S3.T4.1.7.7.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.7.7.2"><span class="ltx_text" id="S3.T4.1.7.7.2.1">DQN</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.7.7.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.7.7.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.7.7.5">0.08</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.7.7.6">0.03</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.7.7.7">0.18</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.7.7.8">0.01</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.7.7.9">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.7.7.10">-0.01</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.8.8">
<td class="ltx_td ltx_border_r" id="S3.T4.1.8.8.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.8.8.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.8.8.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.8.8.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.8.8.5">-0.10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.8.8.6">-0.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.8.8.7">-0.04</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.8.8.8">-0.10</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.8.8.9">-0.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.8.8.10">-0.04</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.9.9">
<td class="ltx_td ltx_border_r" id="S3.T4.1.9.9.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.9.9.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.9.9.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.9.9.4"><span class="ltx_text" id="S3.T4.1.9.9.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.9.9.5"><span class="ltx_text ltx_font_bold" id="S3.T4.1.9.9.5.1">-0.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.9.9.6"><span class="ltx_text ltx_font_bold" id="S3.T4.1.9.9.6.1">0.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.9.9.7"><span class="ltx_text ltx_font_bold" id="S3.T4.1.9.9.7.1">0.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.9.9.8"><span class="ltx_text" id="S3.T4.1.9.9.8.1" style="color:#FE0000;">-0.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.9.9.9"><span class="ltx_text ltx_font_bold" id="S3.T4.1.9.9.9.1">0.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.9.9.10"><span class="ltx_text" id="S3.T4.1.9.9.10.1" style="color:#FE0000;">-0.14</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.10.10">
<td class="ltx_td ltx_border_r" id="S3.T4.1.10.10.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.10.10.2"><span class="ltx_text" id="S3.T4.1.10.10.2.1">PPO</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.10.10.3"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.10.10.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.10.10.5">0.05</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.10.10.6">0.20</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.10.10.7">0.15</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.10.10.8">-0.01</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.10.10.9">0.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.10.10.10">-0.1</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.11.11">
<td class="ltx_td ltx_border_r" id="S3.T4.1.11.11.1"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.11.11.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.11.11.3">Baseline</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T4.1.11.11.4"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.11.11.5">-0.20</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.11.11.6">0.18</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.11.11.7">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.11.11.8">-0.20</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.11.11.9">0.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.11.11.10">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.12.12">
<td class="ltx_td ltx_border_r" id="S3.T4.1.12.12.1"></td>
<td class="ltx_td ltx_border_r" id="S3.T4.1.12.12.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.12.3">LMGT(ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T4.1.12.12.4"><span class="ltx_text" id="S3.T4.1.12.12.4.1">AR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.12.5"><span class="ltx_text ltx_font_bold" id="S3.T4.1.12.12.5.1">0.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.12.6"><span class="ltx_text ltx_font_bold" id="S3.T4.1.12.12.6.1">0.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.12.7"><span class="ltx_text ltx_font_bold" id="S3.T4.1.12.12.7.1">0.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.12.8"><span class="ltx_text ltx_font_bold" id="S3.T4.1.12.12.8.1">-0.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T4.1.12.12.9"><span class="ltx_text" id="S3.T4.1.12.12.9.1" style="color:#FE0000;">0.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.12.12.10"><span class="ltx_text" id="S3.T4.1.12.12.10.1" style="color:#FE0000;">0.31</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.13.13">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T4.1.13.13.1"><span class="ltx_text" id="S3.T4.1.13.13.1.1">Blackjack</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T4.1.13.13.2"><span class="ltx_text" id="S3.T4.1.13.13.2.1">A2C</span></td>
<td class="ltx_td ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.1.13.13.3"></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.1.13.13.4">BR</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.1.13.13.5">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.1.13.13.6">0.12</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.1.13.13.7">0.13</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.1.13.13.8">0.01</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T4.1.13.13.9">-0.03</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T4.1.13.13.10">-0.01</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.4.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.5.2">Experiments in Industrial Recommendation Scenarios</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In this section, we further apply our framework to Google’s RL recommendation algorithm, SlateQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib17" title="">17</a>]</cite>, to elucidate its potential in industrial applications.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS4.SSS1.4.1.1">III-D</span>1 </span>Simulation environment</h4>
<div class="ltx_para" id="S3.SS4.SSS1.p1">
<p class="ltx_p" id="S3.SS4.SSS1.p1.1">RecSim<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#bib.bib22" title="">22</a>]</cite> is a simulation platform for constructing and evaluating recommendation systems that naturally support sequential interactions with users. Developed by Google, it simulates users and environments to assess the effectiveness and performance of recommendation algorithms. We employ RecSim to create an environment that reflects user behavior and item structure to evaluate our LMGT framework.</p>
</div>
<figure class="ltx_table" id="S3.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE V: </span>The influence of employing various LLMs on the performance of our framework.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T5.1" style="width:234.9pt;height:307.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-13.0pt,17.1pt) scale(0.9,0.9) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T5.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T5.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T5.1.1.1.1.1"></th>
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="S3.T5.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.1.1.2.1">Time steps</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T5.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.2.2.1.1">Model</span></th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.2.2.2">n=100</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.2.2.3">n=1000</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.2.2.4">n=10000</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T5.1.1.3.3.1">Vicuna-7B-4bit</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.3.3.2">-0.20</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.3.3.3">0.18</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.3.3.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.4.4.1">Vicuna-7B-8bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.4.4.2">-0.20</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.4.4.3">0.18</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.4.4.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.5.5.1">Vicuna-7B-16bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.5.5.2">-0.20</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.5.5.3">0.18</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.5.5.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.6.6.1">Vicuna-7B-4bit-GPTQ</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.6.6.2">-0.20</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.6.6.3">0.18</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.6.6.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.7.7.1">Vicuna-13B-4bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.7.7.2">-0.20</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.7.7.3">0.18</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.7.7.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.8.8.1">Vicuna-13B-8bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.8.8.2">0.10</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.8.8.3">0.18</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.8.8.4">0.34</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.9.9.1">Vicuna-13B-16bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.9.9.2">0.10</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.9.9.3">0.18</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.9.9.4">0.36</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.10.10.1">Vicuna-13B-4bit-GPTQ</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.10.10.2">0.10</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.10.10.3">0.18</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.10.10.4">0.34</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.11.11.1">Vicuna-30B-4bit-GPTQ</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.11.11.2"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.11.11.2.1">0.12</span></td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.11.11.3"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.11.11.3.1">0.30</span></td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.11.11.4"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.11.11.4.1">0.45</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T5.1.1.12.12.1">Llama2-7B-4bit</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.12.12.2">-0.30</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.12.12.3">0.16</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T5.1.1.12.12.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.13.13.1">Llama2-7B-8bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.13.13.2">-0.30</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.13.13.3">0.16</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.13.13.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.14.14.1">Llama2-7B-16bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.14.14.2">-0.30</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.14.14.3">0.16</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.14.14.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.15.15.1">Llama-7B-4bit-GPTQ</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.15.15.2">-0.30</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.15.15.3">0.16</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.15.15.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.16.16.1">Llama2-13B-4bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.16.16.2">0.10</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.16.16.3">0.16</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.16.16.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.17.17.1">Llama2-13B-8bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.17.17.2">0.10</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.17.17.3">0.16</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.17.17.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.18.18.1">Llama2-13B-16bit</th>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.18.18.2">0.12</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.18.18.3">0.16</td>
<td class="ltx_td ltx_align_left" id="S3.T5.1.1.18.18.4">0.34</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S3.T5.1.1.19.19.1">Llama2-13B-4bit-GPTQ</th>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T5.1.1.19.19.2">0.12</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T5.1.1.19.19.3">0.16</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T5.1.1.19.19.4">0.34</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS4.SSS1.p2">
<p class="ltx_p" id="S3.SS4.SSS1.p2.1">We construct a “Choc vs. Kale” recommendation scenario, where the goal is to maximize user satisfaction and engagement over the long term by recommending a certain proportion of “chocolate” and “kale” elements. In this scenario, the “chocolate” element represents content that is interesting but not conducive to long-term satisfaction, while the “kale” element represents relatively less exciting but beneficial content for long-term satisfaction. The recommendation algorithm needs to balance these two elements to achieve maximized long-term user satisfaction.</p>
</div>
<figure class="ltx_table" id="S3.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>The performance of our framework when applied to the SlateQ recommendation algorithm.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T6.1" style="width:273.2pt;height:81pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.2pt,4.5pt) scale(0.9,0.9) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T6.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T6.1.1.1.1.1"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T6.1.1.1.1.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" colspan="3" id="S3.T6.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.3.1">Episode</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T6.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.2.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.2.1.2.1">Metric</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.2.1.3">n=10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.2.1.4">n=50</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T6.1.1.2.1.5">n=5000</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.3.2.1">SlateQ</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.3.2.2" rowspan="2"><span class="ltx_text" id="S3.T6.1.1.3.2.2.1">Average Reward</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.3.2.3">831.082</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.3.2.4">913.528</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T6.1.1.3.2.5">1127.136</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.4.3.1">LMGT(ours)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.4.3.2.1">933.624</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T6.1.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.4.3.3.1">1125.171</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T6.1.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.4.3.4.1">1150.251</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.5.4">
<td class="ltx_td ltx_border_b ltx_border_r ltx_border_t" id="S3.T6.1.1.5.4.1"></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T6.1.1.5.4.2">Boosted reward</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T6.1.1.5.4.3">102.542</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T6.1.1.5.4.4">211.643</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S3.T6.1.1.5.4.5">23.115</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS4.SSS1.p3">
<p class="ltx_p" id="S3.SS4.SSS1.p3.1">In our scenario, the entire simulation environment consists primarily of document models and user models. The document model serves as the main interface for interaction between users and the recommendation system (agent) and is responsible for selecting a subset of documents from a database containing a large number of documents to deliver to the recommendation system. The user model simulates user behavior and reacts to the slates provided by the recommendation system.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p4">
<p class="ltx_p" id="S3.SS4.SSS1.p4.2">The database in the document model essentially serves as a container for observable and unobservable features of underlying documents. In this scenario, document attributes are modeled as continuous features with values in the range of <math alttext="[0,1]" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p4.1.m1.2"><semantics id="S3.SS4.SSS1.p4.1.m1.2a"><mrow id="S3.SS4.SSS1.p4.1.m1.2.3.2" xref="S3.SS4.SSS1.p4.1.m1.2.3.1.cmml"><mo id="S3.SS4.SSS1.p4.1.m1.2.3.2.1" stretchy="false" xref="S3.SS4.SSS1.p4.1.m1.2.3.1.cmml">[</mo><mn id="S3.SS4.SSS1.p4.1.m1.1.1" xref="S3.SS4.SSS1.p4.1.m1.1.1.cmml">0</mn><mo id="S3.SS4.SSS1.p4.1.m1.2.3.2.2" xref="S3.SS4.SSS1.p4.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS4.SSS1.p4.1.m1.2.2" xref="S3.SS4.SSS1.p4.1.m1.2.2.cmml">1</mn><mo id="S3.SS4.SSS1.p4.1.m1.2.3.2.3" stretchy="false" xref="S3.SS4.SSS1.p4.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p4.1.m1.2b"><interval closure="closed" id="S3.SS4.SSS1.p4.1.m1.2.3.1.cmml" xref="S3.SS4.SSS1.p4.1.m1.2.3.2"><cn id="S3.SS4.SSS1.p4.1.m1.1.1.cmml" type="integer" xref="S3.SS4.SSS1.p4.1.m1.1.1">0</cn><cn id="S3.SS4.SSS1.p4.1.m1.2.2.cmml" type="integer" xref="S3.SS4.SSS1.p4.1.m1.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p4.1.m1.2c">[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p4.1.m1.2d">[ 0 , 1 ]</annotation></semantics></math>, referred to as the Kaleness scale. A document assigned a score of 0 represents pure “chocolate”, which is intriguing but regrettable, whereas a document with a score of 1 represents pure“kale”, which is less exciting but nutritious. Additionally, each document has a unique integer ID, and the document model selects <math alttext="N" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p4.2.m2.1"><semantics id="S3.SS4.SSS1.p4.2.m2.1a"><mi id="S3.SS4.SSS1.p4.2.m2.1.1" xref="S3.SS4.SSS1.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p4.2.m2.1b"><ci id="S3.SS4.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS4.SSS1.p4.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p4.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p4.2.m2.1d">italic_N</annotation></semantics></math> candidate documents in sequential order based on their IDs.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p5">
<p class="ltx_p" id="S3.SS4.SSS1.p5.4">The user model includes both observable and unobservable user features. Based on these features, the model responds to the received slate according to certain rules. Each user is characterized by the features of net kale exposure (<math alttext="nke_{t}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p5.1.m1.1"><semantics id="S3.SS4.SSS1.p5.1.m1.1a"><mrow id="S3.SS4.SSS1.p5.1.m1.1.1" xref="S3.SS4.SSS1.p5.1.m1.1.1.cmml"><mi id="S3.SS4.SSS1.p5.1.m1.1.1.2" xref="S3.SS4.SSS1.p5.1.m1.1.1.2.cmml">n</mi><mo id="S3.SS4.SSS1.p5.1.m1.1.1.1" xref="S3.SS4.SSS1.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p5.1.m1.1.1.3" xref="S3.SS4.SSS1.p5.1.m1.1.1.3.cmml">k</mi><mo id="S3.SS4.SSS1.p5.1.m1.1.1.1a" xref="S3.SS4.SSS1.p5.1.m1.1.1.1.cmml">⁢</mo><msub id="S3.SS4.SSS1.p5.1.m1.1.1.4" xref="S3.SS4.SSS1.p5.1.m1.1.1.4.cmml"><mi id="S3.SS4.SSS1.p5.1.m1.1.1.4.2" xref="S3.SS4.SSS1.p5.1.m1.1.1.4.2.cmml">e</mi><mi id="S3.SS4.SSS1.p5.1.m1.1.1.4.3" xref="S3.SS4.SSS1.p5.1.m1.1.1.4.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p5.1.m1.1b"><apply id="S3.SS4.SSS1.p5.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1"><times id="S3.SS4.SSS1.p5.1.m1.1.1.1.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1.1"></times><ci id="S3.SS4.SSS1.p5.1.m1.1.1.2.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1.2">𝑛</ci><ci id="S3.SS4.SSS1.p5.1.m1.1.1.3.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1.3">𝑘</ci><apply id="S3.SS4.SSS1.p5.1.m1.1.1.4.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1.4"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p5.1.m1.1.1.4.1.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1.4">subscript</csymbol><ci id="S3.SS4.SSS1.p5.1.m1.1.1.4.2.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1.4.2">𝑒</ci><ci id="S3.SS4.SSS1.p5.1.m1.1.1.4.3.cmml" xref="S3.SS4.SSS1.p5.1.m1.1.1.4.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p5.1.m1.1c">nke_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p5.1.m1.1d">italic_n italic_k italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>) and satisfaction (<math alttext="sat_{t}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p5.2.m2.1"><semantics id="S3.SS4.SSS1.p5.2.m2.1a"><mrow id="S3.SS4.SSS1.p5.2.m2.1.1" xref="S3.SS4.SSS1.p5.2.m2.1.1.cmml"><mi id="S3.SS4.SSS1.p5.2.m2.1.1.2" xref="S3.SS4.SSS1.p5.2.m2.1.1.2.cmml">s</mi><mo id="S3.SS4.SSS1.p5.2.m2.1.1.1" xref="S3.SS4.SSS1.p5.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p5.2.m2.1.1.3" xref="S3.SS4.SSS1.p5.2.m2.1.1.3.cmml">a</mi><mo id="S3.SS4.SSS1.p5.2.m2.1.1.1a" xref="S3.SS4.SSS1.p5.2.m2.1.1.1.cmml">⁢</mo><msub id="S3.SS4.SSS1.p5.2.m2.1.1.4" xref="S3.SS4.SSS1.p5.2.m2.1.1.4.cmml"><mi id="S3.SS4.SSS1.p5.2.m2.1.1.4.2" xref="S3.SS4.SSS1.p5.2.m2.1.1.4.2.cmml">t</mi><mi id="S3.SS4.SSS1.p5.2.m2.1.1.4.3" xref="S3.SS4.SSS1.p5.2.m2.1.1.4.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p5.2.m2.1b"><apply id="S3.SS4.SSS1.p5.2.m2.1.1.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1"><times id="S3.SS4.SSS1.p5.2.m2.1.1.1.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1.1"></times><ci id="S3.SS4.SSS1.p5.2.m2.1.1.2.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1.2">𝑠</ci><ci id="S3.SS4.SSS1.p5.2.m2.1.1.3.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1.3">𝑎</ci><apply id="S3.SS4.SSS1.p5.2.m2.1.1.4.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p5.2.m2.1.1.4.1.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1.4">subscript</csymbol><ci id="S3.SS4.SSS1.p5.2.m2.1.1.4.2.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1.4.2">𝑡</ci><ci id="S3.SS4.SSS1.p5.2.m2.1.1.4.3.cmml" xref="S3.SS4.SSS1.p5.2.m2.1.1.4.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p5.2.m2.1c">sat_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p5.2.m2.1d">italic_s italic_a italic_t start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>), which are associated through the sigmoid function <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p5.3.m3.1"><semantics id="S3.SS4.SSS1.p5.3.m3.1a"><mi id="S3.SS4.SSS1.p5.3.m3.1.1" xref="S3.SS4.SSS1.p5.3.m3.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p5.3.m3.1b"><ci id="S3.SS4.SSS1.p5.3.m3.1.1.cmml" xref="S3.SS4.SSS1.p5.3.m3.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p5.3.m3.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p5.3.m3.1d">italic_σ</annotation></semantics></math> to ensure that <math alttext="sat_{t}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p5.4.m4.1"><semantics id="S3.SS4.SSS1.p5.4.m4.1a"><mrow id="S3.SS4.SSS1.p5.4.m4.1.1" xref="S3.SS4.SSS1.p5.4.m4.1.1.cmml"><mi id="S3.SS4.SSS1.p5.4.m4.1.1.2" xref="S3.SS4.SSS1.p5.4.m4.1.1.2.cmml">s</mi><mo id="S3.SS4.SSS1.p5.4.m4.1.1.1" xref="S3.SS4.SSS1.p5.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p5.4.m4.1.1.3" xref="S3.SS4.SSS1.p5.4.m4.1.1.3.cmml">a</mi><mo id="S3.SS4.SSS1.p5.4.m4.1.1.1a" xref="S3.SS4.SSS1.p5.4.m4.1.1.1.cmml">⁢</mo><msub id="S3.SS4.SSS1.p5.4.m4.1.1.4" xref="S3.SS4.SSS1.p5.4.m4.1.1.4.cmml"><mi id="S3.SS4.SSS1.p5.4.m4.1.1.4.2" xref="S3.SS4.SSS1.p5.4.m4.1.1.4.2.cmml">t</mi><mi id="S3.SS4.SSS1.p5.4.m4.1.1.4.3" xref="S3.SS4.SSS1.p5.4.m4.1.1.4.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p5.4.m4.1b"><apply id="S3.SS4.SSS1.p5.4.m4.1.1.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1"><times id="S3.SS4.SSS1.p5.4.m4.1.1.1.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1.1"></times><ci id="S3.SS4.SSS1.p5.4.m4.1.1.2.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1.2">𝑠</ci><ci id="S3.SS4.SSS1.p5.4.m4.1.1.3.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1.3">𝑎</ci><apply id="S3.SS4.SSS1.p5.4.m4.1.1.4.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1.4"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p5.4.m4.1.1.4.1.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1.4">subscript</csymbol><ci id="S3.SS4.SSS1.p5.4.m4.1.1.4.2.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1.4.2">𝑡</ci><ci id="S3.SS4.SSS1.p5.4.m4.1.1.4.3.cmml" xref="S3.SS4.SSS1.p5.4.m4.1.1.4.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p5.4.m4.1c">sat_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p5.4.m4.1d">italic_s italic_a italic_t start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is constrained within a bounded range. Specifically, the satisfaction level is modeled as a sigmoid function of the net kale exposure, which determines the user’s satisfaction with the recommended slate:</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p6">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="sat_{t}=\sigma(\tau\cdot nke_{t})" class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml">s</mi><mo id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml">a</mi><mo id="S3.E1.m1.1.1.3.1a" xref="S3.E1.m1.1.1.3.1.cmml">⁢</mo><msub id="S3.E1.m1.1.1.3.4" xref="S3.E1.m1.1.1.3.4.cmml"><mi id="S3.E1.m1.1.1.3.4.2" xref="S3.E1.m1.1.1.3.4.2.cmml">t</mi><mi id="S3.E1.m1.1.1.3.4.3" xref="S3.E1.m1.1.1.3.4.3.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">σ</mi><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.cmml">τ</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.1.1.1.1.2.1.cmml">⋅</mo><mi id="S3.E1.m1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml">n</mi></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml">k</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1a" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">⁢</mo><msub id="S3.E1.m1.1.1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.4.2" xref="S3.E1.m1.1.1.1.1.1.1.4.2.cmml">e</mi><mi id="S3.E1.m1.1.1.1.1.1.1.4.3" xref="S3.E1.m1.1.1.1.1.1.1.4.3.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"></eq><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><times id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1"></times><ci id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2">𝑠</ci><ci id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3">𝑎</ci><apply id="S3.E1.m1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.4.1.cmml" xref="S3.E1.m1.1.1.3.4">subscript</csymbol><ci id="S3.E1.m1.1.1.3.4.2.cmml" xref="S3.E1.m1.1.1.3.4.2">𝑡</ci><ci id="S3.E1.m1.1.1.3.4.3.cmml" xref="S3.E1.m1.1.1.3.4.3">𝑡</ci></apply></apply><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">𝜎</ci><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></times><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><ci id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.1">⋅</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2">𝜏</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3">𝑛</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">𝑘</ci><apply id="S3.E1.m1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4.2">𝑒</ci><ci id="S3.E1.m1.1.1.1.1.1.1.4.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">sat_{t}=\sigma(\tau\cdot nke_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">italic_s italic_a italic_t start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_σ ( italic_τ ⋅ italic_n italic_k italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p7">
<p class="ltx_p" id="S3.SS4.SSS1.p7.3">Where <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p7.1.m1.1"><semantics id="S3.SS4.SSS1.p7.1.m1.1a"><mi id="S3.SS4.SSS1.p7.1.m1.1.1" xref="S3.SS4.SSS1.p7.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p7.1.m1.1b"><ci id="S3.SS4.SSS1.p7.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p7.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p7.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p7.1.m1.1d">italic_τ</annotation></semantics></math> is a user-specific sensitivity parameter. Upon receiving a Slate from the recommendation system, users select items to consume based on the Kaleness scale of the documents. Specifically, for item <math alttext="i" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p7.2.m2.1"><semantics id="S3.SS4.SSS1.p7.2.m2.1a"><mi id="S3.SS4.SSS1.p7.2.m2.1.1" xref="S3.SS4.SSS1.p7.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p7.2.m2.1b"><ci id="S3.SS4.SSS1.p7.2.m2.1.1.cmml" xref="S3.SS4.SSS1.p7.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p7.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p7.2.m2.1d">italic_i</annotation></semantics></math>, the probability of it being chosen is determined by <math alttext="p\sim e^{1-kaleness(i)}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p7.3.m3.1"><semantics id="S3.SS4.SSS1.p7.3.m3.1a"><mrow id="S3.SS4.SSS1.p7.3.m3.1.2" xref="S3.SS4.SSS1.p7.3.m3.1.2.cmml"><mi id="S3.SS4.SSS1.p7.3.m3.1.2.2" xref="S3.SS4.SSS1.p7.3.m3.1.2.2.cmml">p</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.2.1" xref="S3.SS4.SSS1.p7.3.m3.1.2.1.cmml">∼</mo><msup id="S3.SS4.SSS1.p7.3.m3.1.2.3" xref="S3.SS4.SSS1.p7.3.m3.1.2.3.cmml"><mi id="S3.SS4.SSS1.p7.3.m3.1.2.3.2" xref="S3.SS4.SSS1.p7.3.m3.1.2.3.2.cmml">e</mi><mrow id="S3.SS4.SSS1.p7.3.m3.1.1.1" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.cmml"><mn id="S3.SS4.SSS1.p7.3.m3.1.1.1.3" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.3.cmml">1</mn><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.2" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.2.cmml">−</mo><mrow id="S3.SS4.SSS1.p7.3.m3.1.1.1.4" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.cmml"><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.2" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.2.cmml">k</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.3" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.3.cmml">a</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1a" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.4" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.4.cmml">l</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1b" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.5" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.5.cmml">e</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1c" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.6" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.6.cmml">n</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1d" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.7" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.7.cmml">e</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1e" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.8" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.8.cmml">s</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1f" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.9" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.9.cmml">s</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1g" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml">⁢</mo><mrow id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.10.2" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.cmml"><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.10.2.1" stretchy="false" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.cmml">(</mo><mi id="S3.SS4.SSS1.p7.3.m3.1.1.1.1" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.1.cmml">i</mi><mo id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.10.2.2" stretchy="false" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p7.3.m3.1b"><apply id="S3.SS4.SSS1.p7.3.m3.1.2.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.2"><csymbol cd="latexml" id="S3.SS4.SSS1.p7.3.m3.1.2.1.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.2.1">similar-to</csymbol><ci id="S3.SS4.SSS1.p7.3.m3.1.2.2.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.2.2">𝑝</ci><apply id="S3.SS4.SSS1.p7.3.m3.1.2.3.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.2.3"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p7.3.m3.1.2.3.1.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.2.3">superscript</csymbol><ci id="S3.SS4.SSS1.p7.3.m3.1.2.3.2.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.2.3.2">𝑒</ci><apply id="S3.SS4.SSS1.p7.3.m3.1.1.1.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1"><minus id="S3.SS4.SSS1.p7.3.m3.1.1.1.2.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.2"></minus><cn id="S3.SS4.SSS1.p7.3.m3.1.1.1.3.cmml" type="integer" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.3">1</cn><apply id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4"><times id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.1"></times><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.2.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.2">𝑘</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.3.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.3">𝑎</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.4.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.4">𝑙</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.5.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.5">𝑒</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.6.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.6">𝑛</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.7.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.7">𝑒</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.8.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.8">𝑠</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.4.9.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.4.9">𝑠</ci><ci id="S3.SS4.SSS1.p7.3.m3.1.1.1.1.cmml" xref="S3.SS4.SSS1.p7.3.m3.1.1.1.1">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p7.3.m3.1c">p\sim e^{1-kaleness(i)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p7.3.m3.1d">italic_p ∼ italic_e start_POSTSUPERSCRIPT 1 - italic_k italic_a italic_l italic_e italic_n italic_e italic_s italic_s ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math>. After making their selections, the net kale exposure evolves as follows:</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p8">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="nke_{t+1}=\beta\cdot nke_{t}+2(k_{i}-1/2)+\mathcal{N}(0,\eta)" class="ltx_Math" display="block" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml"><mrow id="S3.E2.m1.3.3.3" xref="S3.E2.m1.3.3.3.cmml"><mi id="S3.E2.m1.3.3.3.2" xref="S3.E2.m1.3.3.3.2.cmml">n</mi><mo id="S3.E2.m1.3.3.3.1" xref="S3.E2.m1.3.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.3.3.3.3" xref="S3.E2.m1.3.3.3.3.cmml">k</mi><mo id="S3.E2.m1.3.3.3.1a" xref="S3.E2.m1.3.3.3.1.cmml">⁢</mo><msub id="S3.E2.m1.3.3.3.4" xref="S3.E2.m1.3.3.3.4.cmml"><mi id="S3.E2.m1.3.3.3.4.2" xref="S3.E2.m1.3.3.3.4.2.cmml">e</mi><mrow id="S3.E2.m1.3.3.3.4.3" xref="S3.E2.m1.3.3.3.4.3.cmml"><mi id="S3.E2.m1.3.3.3.4.3.2" xref="S3.E2.m1.3.3.3.4.3.2.cmml">t</mi><mo id="S3.E2.m1.3.3.3.4.3.1" xref="S3.E2.m1.3.3.3.4.3.1.cmml">+</mo><mn id="S3.E2.m1.3.3.3.4.3.3" xref="S3.E2.m1.3.3.3.4.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S3.E2.m1.3.3.2" xref="S3.E2.m1.3.3.2.cmml">=</mo><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.cmml"><mrow id="S3.E2.m1.3.3.1.3" xref="S3.E2.m1.3.3.1.3.cmml"><mrow id="S3.E2.m1.3.3.1.3.2" xref="S3.E2.m1.3.3.1.3.2.cmml"><mi id="S3.E2.m1.3.3.1.3.2.2" xref="S3.E2.m1.3.3.1.3.2.2.cmml">β</mi><mo id="S3.E2.m1.3.3.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.3.3.1.3.2.1.cmml">⋅</mo><mi id="S3.E2.m1.3.3.1.3.2.3" xref="S3.E2.m1.3.3.1.3.2.3.cmml">n</mi></mrow><mo id="S3.E2.m1.3.3.1.3.1" xref="S3.E2.m1.3.3.1.3.1.cmml">⁢</mo><mi id="S3.E2.m1.3.3.1.3.3" xref="S3.E2.m1.3.3.1.3.3.cmml">k</mi><mo id="S3.E2.m1.3.3.1.3.1a" xref="S3.E2.m1.3.3.1.3.1.cmml">⁢</mo><msub id="S3.E2.m1.3.3.1.3.4" xref="S3.E2.m1.3.3.1.3.4.cmml"><mi id="S3.E2.m1.3.3.1.3.4.2" xref="S3.E2.m1.3.3.1.3.4.2.cmml">e</mi><mi id="S3.E2.m1.3.3.1.3.4.3" xref="S3.E2.m1.3.3.1.3.4.3.cmml">t</mi></msub></mrow><mo id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.2.cmml">+</mo><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><mn id="S3.E2.m1.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.3.cmml">2</mn><mo id="S3.E2.m1.3.3.1.1.2" xref="S3.E2.m1.3.3.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.2.2.cmml">k</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.cmml"><mn id="S3.E2.m1.3.3.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.cmml">1</mn><mo id="S3.E2.m1.3.3.1.1.1.1.1.3.1" xref="S3.E2.m1.3.3.1.1.1.1.1.3.1.cmml">/</mo><mn id="S3.E2.m1.3.3.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.3.cmml">2</mn></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.2a" xref="S3.E2.m1.3.3.1.2.cmml">+</mo><mrow id="S3.E2.m1.3.3.1.4" xref="S3.E2.m1.3.3.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.4.2" xref="S3.E2.m1.3.3.1.4.2.cmml">𝒩</mi><mo id="S3.E2.m1.3.3.1.4.1" xref="S3.E2.m1.3.3.1.4.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.4.3.2" xref="S3.E2.m1.3.3.1.4.3.1.cmml"><mo id="S3.E2.m1.3.3.1.4.3.2.1" stretchy="false" xref="S3.E2.m1.3.3.1.4.3.1.cmml">(</mo><mn id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">0</mn><mo id="S3.E2.m1.3.3.1.4.3.2.2" xref="S3.E2.m1.3.3.1.4.3.1.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">η</mi><mo id="S3.E2.m1.3.3.1.4.3.2.3" stretchy="false" xref="S3.E2.m1.3.3.1.4.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"><eq id="S3.E2.m1.3.3.2.cmml" xref="S3.E2.m1.3.3.2"></eq><apply id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.3"><times id="S3.E2.m1.3.3.3.1.cmml" xref="S3.E2.m1.3.3.3.1"></times><ci id="S3.E2.m1.3.3.3.2.cmml" xref="S3.E2.m1.3.3.3.2">𝑛</ci><ci id="S3.E2.m1.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3">𝑘</ci><apply id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.4.1.cmml" xref="S3.E2.m1.3.3.3.4">subscript</csymbol><ci id="S3.E2.m1.3.3.3.4.2.cmml" xref="S3.E2.m1.3.3.3.4.2">𝑒</ci><apply id="S3.E2.m1.3.3.3.4.3.cmml" xref="S3.E2.m1.3.3.3.4.3"><plus id="S3.E2.m1.3.3.3.4.3.1.cmml" xref="S3.E2.m1.3.3.3.4.3.1"></plus><ci id="S3.E2.m1.3.3.3.4.3.2.cmml" xref="S3.E2.m1.3.3.3.4.3.2">𝑡</ci><cn id="S3.E2.m1.3.3.3.4.3.3.cmml" type="integer" xref="S3.E2.m1.3.3.3.4.3.3">1</cn></apply></apply></apply><apply id="S3.E2.m1.3.3.1.cmml" xref="S3.E2.m1.3.3.1"><plus id="S3.E2.m1.3.3.1.2.cmml" xref="S3.E2.m1.3.3.1.2"></plus><apply id="S3.E2.m1.3.3.1.3.cmml" xref="S3.E2.m1.3.3.1.3"><times id="S3.E2.m1.3.3.1.3.1.cmml" xref="S3.E2.m1.3.3.1.3.1"></times><apply id="S3.E2.m1.3.3.1.3.2.cmml" xref="S3.E2.m1.3.3.1.3.2"><ci id="S3.E2.m1.3.3.1.3.2.1.cmml" xref="S3.E2.m1.3.3.1.3.2.1">⋅</ci><ci id="S3.E2.m1.3.3.1.3.2.2.cmml" xref="S3.E2.m1.3.3.1.3.2.2">𝛽</ci><ci id="S3.E2.m1.3.3.1.3.2.3.cmml" xref="S3.E2.m1.3.3.1.3.2.3">𝑛</ci></apply><ci id="S3.E2.m1.3.3.1.3.3.cmml" xref="S3.E2.m1.3.3.1.3.3">𝑘</ci><apply id="S3.E2.m1.3.3.1.3.4.cmml" xref="S3.E2.m1.3.3.1.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.3.4.1.cmml" xref="S3.E2.m1.3.3.1.3.4">subscript</csymbol><ci id="S3.E2.m1.3.3.1.3.4.2.cmml" xref="S3.E2.m1.3.3.1.3.4.2">𝑒</ci><ci id="S3.E2.m1.3.3.1.3.4.3.cmml" xref="S3.E2.m1.3.3.1.3.4.3">𝑡</ci></apply></apply><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1.1"><times id="S3.E2.m1.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2"></times><cn id="S3.E2.m1.3.3.1.1.3.cmml" type="integer" xref="S3.E2.m1.3.3.1.1.3">2</cn><apply id="S3.E2.m1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1"><minus id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1"></minus><apply id="S3.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2.2">𝑘</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3"><divide id="S3.E2.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.1"></divide><cn id="S3.E2.m1.3.3.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2">1</cn><cn id="S3.E2.m1.3.3.1.1.1.1.1.3.3.cmml" type="integer" xref="S3.E2.m1.3.3.1.1.1.1.1.3.3">2</cn></apply></apply></apply><apply id="S3.E2.m1.3.3.1.4.cmml" xref="S3.E2.m1.3.3.1.4"><times id="S3.E2.m1.3.3.1.4.1.cmml" xref="S3.E2.m1.3.3.1.4.1"></times><ci id="S3.E2.m1.3.3.1.4.2.cmml" xref="S3.E2.m1.3.3.1.4.2">𝒩</ci><interval closure="open" id="S3.E2.m1.3.3.1.4.3.1.cmml" xref="S3.E2.m1.3.3.1.4.3.2"><cn id="S3.E2.m1.1.1.cmml" type="integer" xref="S3.E2.m1.1.1">0</cn><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝜂</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">nke_{t+1}=\beta\cdot nke_{t}+2(k_{i}-1/2)+\mathcal{N}(0,\eta)</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">italic_n italic_k italic_e start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT = italic_β ⋅ italic_n italic_k italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + 2 ( italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - 1 / 2 ) + caligraphic_N ( 0 , italic_η )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p9">
<p class="ltx_p" id="S3.SS4.SSS1.p9.6">Where <math alttext="\beta" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p9.1.m1.1"><semantics id="S3.SS4.SSS1.p9.1.m1.1a"><mi id="S3.SS4.SSS1.p9.1.m1.1.1" xref="S3.SS4.SSS1.p9.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p9.1.m1.1b"><ci id="S3.SS4.SSS1.p9.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p9.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p9.1.m1.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p9.1.m1.1d">italic_β</annotation></semantics></math> represents a user-specific memory discount, <math alttext="k_{i}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p9.2.m2.1"><semantics id="S3.SS4.SSS1.p9.2.m2.1a"><msub id="S3.SS4.SSS1.p9.2.m2.1.1" xref="S3.SS4.SSS1.p9.2.m2.1.1.cmml"><mi id="S3.SS4.SSS1.p9.2.m2.1.1.2" xref="S3.SS4.SSS1.p9.2.m2.1.1.2.cmml">k</mi><mi id="S3.SS4.SSS1.p9.2.m2.1.1.3" xref="S3.SS4.SSS1.p9.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p9.2.m2.1b"><apply id="S3.SS4.SSS1.p9.2.m2.1.1.cmml" xref="S3.SS4.SSS1.p9.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p9.2.m2.1.1.1.cmml" xref="S3.SS4.SSS1.p9.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p9.2.m2.1.1.2.cmml" xref="S3.SS4.SSS1.p9.2.m2.1.1.2">𝑘</ci><ci id="S3.SS4.SSS1.p9.2.m2.1.1.3.cmml" xref="S3.SS4.SSS1.p9.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p9.2.m2.1c">k_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p9.2.m2.1d">italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> corresponds to the kaleness of the selected item, and <math alttext="\eta" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p9.3.m3.1"><semantics id="S3.SS4.SSS1.p9.3.m3.1a"><mi id="S3.SS4.SSS1.p9.3.m3.1.1" xref="S3.SS4.SSS1.p9.3.m3.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p9.3.m3.1b"><ci id="S3.SS4.SSS1.p9.3.m3.1.1.cmml" xref="S3.SS4.SSS1.p9.3.m3.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p9.3.m3.1c">\eta</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p9.3.m3.1d">italic_η</annotation></semantics></math> denotes some noise standard deviation. Lastly, our focus will be on the user’s engagement <math alttext="s_{i}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p9.4.m4.1"><semantics id="S3.SS4.SSS1.p9.4.m4.1a"><msub id="S3.SS4.SSS1.p9.4.m4.1.1" xref="S3.SS4.SSS1.p9.4.m4.1.1.cmml"><mi id="S3.SS4.SSS1.p9.4.m4.1.1.2" xref="S3.SS4.SSS1.p9.4.m4.1.1.2.cmml">s</mi><mi id="S3.SS4.SSS1.p9.4.m4.1.1.3" xref="S3.SS4.SSS1.p9.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p9.4.m4.1b"><apply id="S3.SS4.SSS1.p9.4.m4.1.1.cmml" xref="S3.SS4.SSS1.p9.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p9.4.m4.1.1.1.cmml" xref="S3.SS4.SSS1.p9.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p9.4.m4.1.1.2.cmml" xref="S3.SS4.SSS1.p9.4.m4.1.1.2">𝑠</ci><ci id="S3.SS4.SSS1.p9.4.m4.1.1.3.cmml" xref="S3.SS4.SSS1.p9.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p9.4.m4.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p9.4.m4.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, i.e. a log-normal distribution with parameters linearly interpolating between the pure kale response <math alttext="(\mu_{k},\sigma_{k})" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p9.5.m5.2"><semantics id="S3.SS4.SSS1.p9.5.m5.2a"><mrow id="S3.SS4.SSS1.p9.5.m5.2.2.2" xref="S3.SS4.SSS1.p9.5.m5.2.2.3.cmml"><mo id="S3.SS4.SSS1.p9.5.m5.2.2.2.3" stretchy="false" xref="S3.SS4.SSS1.p9.5.m5.2.2.3.cmml">(</mo><msub id="S3.SS4.SSS1.p9.5.m5.1.1.1.1" xref="S3.SS4.SSS1.p9.5.m5.1.1.1.1.cmml"><mi id="S3.SS4.SSS1.p9.5.m5.1.1.1.1.2" xref="S3.SS4.SSS1.p9.5.m5.1.1.1.1.2.cmml">μ</mi><mi id="S3.SS4.SSS1.p9.5.m5.1.1.1.1.3" xref="S3.SS4.SSS1.p9.5.m5.1.1.1.1.3.cmml">k</mi></msub><mo id="S3.SS4.SSS1.p9.5.m5.2.2.2.4" xref="S3.SS4.SSS1.p9.5.m5.2.2.3.cmml">,</mo><msub id="S3.SS4.SSS1.p9.5.m5.2.2.2.2" xref="S3.SS4.SSS1.p9.5.m5.2.2.2.2.cmml"><mi id="S3.SS4.SSS1.p9.5.m5.2.2.2.2.2" xref="S3.SS4.SSS1.p9.5.m5.2.2.2.2.2.cmml">σ</mi><mi id="S3.SS4.SSS1.p9.5.m5.2.2.2.2.3" xref="S3.SS4.SSS1.p9.5.m5.2.2.2.2.3.cmml">k</mi></msub><mo id="S3.SS4.SSS1.p9.5.m5.2.2.2.5" stretchy="false" xref="S3.SS4.SSS1.p9.5.m5.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p9.5.m5.2b"><interval closure="open" id="S3.SS4.SSS1.p9.5.m5.2.2.3.cmml" xref="S3.SS4.SSS1.p9.5.m5.2.2.2"><apply id="S3.SS4.SSS1.p9.5.m5.1.1.1.1.cmml" xref="S3.SS4.SSS1.p9.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p9.5.m5.1.1.1.1.1.cmml" xref="S3.SS4.SSS1.p9.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p9.5.m5.1.1.1.1.2.cmml" xref="S3.SS4.SSS1.p9.5.m5.1.1.1.1.2">𝜇</ci><ci id="S3.SS4.SSS1.p9.5.m5.1.1.1.1.3.cmml" xref="S3.SS4.SSS1.p9.5.m5.1.1.1.1.3">𝑘</ci></apply><apply id="S3.SS4.SSS1.p9.5.m5.2.2.2.2.cmml" xref="S3.SS4.SSS1.p9.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p9.5.m5.2.2.2.2.1.cmml" xref="S3.SS4.SSS1.p9.5.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS4.SSS1.p9.5.m5.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p9.5.m5.2.2.2.2.2">𝜎</ci><ci id="S3.SS4.SSS1.p9.5.m5.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p9.5.m5.2.2.2.2.3">𝑘</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p9.5.m5.2c">(\mu_{k},\sigma_{k})</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p9.5.m5.2d">( italic_μ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_σ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )</annotation></semantics></math> and the pure choc response <math alttext="(\mu_{c},\sigma_{c})" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p9.6.m6.2"><semantics id="S3.SS4.SSS1.p9.6.m6.2a"><mrow id="S3.SS4.SSS1.p9.6.m6.2.2.2" xref="S3.SS4.SSS1.p9.6.m6.2.2.3.cmml"><mo id="S3.SS4.SSS1.p9.6.m6.2.2.2.3" stretchy="false" xref="S3.SS4.SSS1.p9.6.m6.2.2.3.cmml">(</mo><msub id="S3.SS4.SSS1.p9.6.m6.1.1.1.1" xref="S3.SS4.SSS1.p9.6.m6.1.1.1.1.cmml"><mi id="S3.SS4.SSS1.p9.6.m6.1.1.1.1.2" xref="S3.SS4.SSS1.p9.6.m6.1.1.1.1.2.cmml">μ</mi><mi id="S3.SS4.SSS1.p9.6.m6.1.1.1.1.3" xref="S3.SS4.SSS1.p9.6.m6.1.1.1.1.3.cmml">c</mi></msub><mo id="S3.SS4.SSS1.p9.6.m6.2.2.2.4" xref="S3.SS4.SSS1.p9.6.m6.2.2.3.cmml">,</mo><msub id="S3.SS4.SSS1.p9.6.m6.2.2.2.2" xref="S3.SS4.SSS1.p9.6.m6.2.2.2.2.cmml"><mi id="S3.SS4.SSS1.p9.6.m6.2.2.2.2.2" xref="S3.SS4.SSS1.p9.6.m6.2.2.2.2.2.cmml">σ</mi><mi id="S3.SS4.SSS1.p9.6.m6.2.2.2.2.3" xref="S3.SS4.SSS1.p9.6.m6.2.2.2.2.3.cmml">c</mi></msub><mo id="S3.SS4.SSS1.p9.6.m6.2.2.2.5" stretchy="false" xref="S3.SS4.SSS1.p9.6.m6.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p9.6.m6.2b"><interval closure="open" id="S3.SS4.SSS1.p9.6.m6.2.2.3.cmml" xref="S3.SS4.SSS1.p9.6.m6.2.2.2"><apply id="S3.SS4.SSS1.p9.6.m6.1.1.1.1.cmml" xref="S3.SS4.SSS1.p9.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p9.6.m6.1.1.1.1.1.cmml" xref="S3.SS4.SSS1.p9.6.m6.1.1.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p9.6.m6.1.1.1.1.2.cmml" xref="S3.SS4.SSS1.p9.6.m6.1.1.1.1.2">𝜇</ci><ci id="S3.SS4.SSS1.p9.6.m6.1.1.1.1.3.cmml" xref="S3.SS4.SSS1.p9.6.m6.1.1.1.1.3">𝑐</ci></apply><apply id="S3.SS4.SSS1.p9.6.m6.2.2.2.2.cmml" xref="S3.SS4.SSS1.p9.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p9.6.m6.2.2.2.2.1.cmml" xref="S3.SS4.SSS1.p9.6.m6.2.2.2.2">subscript</csymbol><ci id="S3.SS4.SSS1.p9.6.m6.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p9.6.m6.2.2.2.2.2">𝜎</ci><ci id="S3.SS4.SSS1.p9.6.m6.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p9.6.m6.2.2.2.2.3">𝑐</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p9.6.m6.2c">(\mu_{c},\sigma_{c})</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p9.6.m6.2d">( italic_μ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_σ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT )</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p10">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="s_{i}\sim log\mathcal{N}(k_{i}\mu_{k}+(1-k_{i})\mu_{c},k_{i}\sigma_{k}+(1-k_{i%
})\sigma_{c})" class="ltx_Math" display="block" id="S3.E3.m1.2"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mi id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml">s</mi><mi id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">∼</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.4.cmml">l</mi><mo id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">⁢</mo><mi id="S3.E3.m1.2.2.2.5" xref="S3.E3.m1.2.2.2.5.cmml">o</mi><mo id="S3.E3.m1.2.2.2.3a" xref="S3.E3.m1.2.2.2.3.cmml">⁢</mo><mi id="S3.E3.m1.2.2.2.6" xref="S3.E3.m1.2.2.2.6.cmml">g</mi><mo id="S3.E3.m1.2.2.2.3b" xref="S3.E3.m1.2.2.2.3.cmml">⁢</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.2.7" xref="S3.E3.m1.2.2.2.7.cmml">𝒩</mi><mo id="S3.E3.m1.2.2.2.3c" xref="S3.E3.m1.2.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.3.cmml"><mo id="S3.E3.m1.2.2.2.2.2.3" stretchy="false" xref="S3.E3.m1.2.2.2.2.3.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.1.1.3.2.2.cmml">k</mi><mi id="S3.E3.m1.1.1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.1.3.1.cmml">⁢</mo><msub id="S3.E3.m1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.1.1.3.3.2.cmml">μ</mi><mi id="S3.E3.m1.1.1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.1.1.3.3.3.cmml">k</mi></msub></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">k</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.3.2.cmml">μ</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3.cmml">c</mi></msub></mrow></mrow><mo id="S3.E3.m1.2.2.2.2.2.4" xref="S3.E3.m1.2.2.2.2.3.cmml">,</mo><mrow id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml"><mrow id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.cmml"><msub id="S3.E3.m1.2.2.2.2.2.2.3.2" xref="S3.E3.m1.2.2.2.2.2.2.3.2.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.3.2.2" xref="S3.E3.m1.2.2.2.2.2.2.3.2.2.cmml">k</mi><mi id="S3.E3.m1.2.2.2.2.2.2.3.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.2.2.2.2.3.1" xref="S3.E3.m1.2.2.2.2.2.2.3.1.cmml">⁢</mo><msub id="S3.E3.m1.2.2.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.2.2.3.3.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.3.3.2" xref="S3.E3.m1.2.2.2.2.2.2.3.3.2.cmml">σ</mi><mi id="S3.E3.m1.2.2.2.2.2.2.3.3.3" xref="S3.E3.m1.2.2.2.2.2.2.3.3.3.cmml">k</mi></msub></mrow><mo id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml">+</mo><mrow id="S3.E3.m1.2.2.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml"><mrow id="S3.E3.m1.2.2.2.2.2.2.1.1.1" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.cmml"><mo id="S3.E3.m1.2.2.2.2.2.2.1.1.1.2" stretchy="false" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.cmml"><mn id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.1.cmml">−</mo><msub id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.2" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.2.cmml">k</mi><mi id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.3" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.E3.m1.2.2.2.2.2.2.1.1.1.3" stretchy="false" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E3.m1.2.2.2.2.2.2.1.2" xref="S3.E3.m1.2.2.2.2.2.2.1.2.cmml">⁢</mo><msub id="S3.E3.m1.2.2.2.2.2.2.1.3" xref="S3.E3.m1.2.2.2.2.2.2.1.3.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.1.3.2" xref="S3.E3.m1.2.2.2.2.2.2.1.3.2.cmml">σ</mi><mi id="S3.E3.m1.2.2.2.2.2.2.1.3.3" xref="S3.E3.m1.2.2.2.2.2.2.1.3.3.cmml">c</mi></msub></mrow></mrow><mo id="S3.E3.m1.2.2.2.2.2.5" stretchy="false" xref="S3.E3.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><csymbol cd="latexml" id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3">similar-to</csymbol><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2">𝑠</ci><ci id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3">𝑖</ci></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><times id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></times><ci id="S3.E3.m1.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.4">𝑙</ci><ci id="S3.E3.m1.2.2.2.5.cmml" xref="S3.E3.m1.2.2.2.5">𝑜</ci><ci id="S3.E3.m1.2.2.2.6.cmml" xref="S3.E3.m1.2.2.2.6">𝑔</ci><ci id="S3.E3.m1.2.2.2.7.cmml" xref="S3.E3.m1.2.2.2.7">𝒩</ci><interval closure="open" id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><plus id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"></plus><apply id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.1"></times><apply id="S3.E3.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.2.2">𝑘</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.3.2">𝜇</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.3.3">𝑘</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1"></minus><cn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2">1</cn><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑘</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.2">𝜇</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3">𝑐</ci></apply></apply></apply><apply id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><plus id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2"></plus><apply id="S3.E3.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3"><times id="S3.E3.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.1"></times><apply id="S3.E3.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.3.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.3.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2.2">𝑘</ci><ci id="S3.E3.m1.2.2.2.2.2.2.3.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3">𝑖</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.3.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.3.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.3.2">𝜎</ci><ci id="S3.E3.m1.2.2.2.2.2.2.3.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.3.3">𝑘</ci></apply></apply><apply id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1"><times id="S3.E3.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.2"></times><apply id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1"><minus id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.1"></minus><cn id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.2.cmml" type="integer" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.2">1</cn><apply id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.2">𝑘</ci><ci id="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.E3.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.1.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.1.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.3.2">𝜎</ci><ci id="S3.E3.m1.2.2.2.2.2.2.1.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.3.3">𝑐</ci></apply></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">s_{i}\sim log\mathcal{N}(k_{i}\mu_{k}+(1-k_{i})\mu_{c},k_{i}\sigma_{k}+(1-k_{i%
})\sigma_{c})</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.2d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∼ italic_l italic_o italic_g caligraphic_N ( italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_μ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT + ( 1 - italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) italic_μ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT + ( 1 - italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) italic_σ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.SSS1.p10.1">The satisfaction variable <math alttext="sat_{t}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p10.1.m1.1"><semantics id="S3.SS4.SSS1.p10.1.m1.1a"><mrow id="S3.SS4.SSS1.p10.1.m1.1.1" xref="S3.SS4.SSS1.p10.1.m1.1.1.cmml"><mi id="S3.SS4.SSS1.p10.1.m1.1.1.2" xref="S3.SS4.SSS1.p10.1.m1.1.1.2.cmml">s</mi><mo id="S3.SS4.SSS1.p10.1.m1.1.1.1" xref="S3.SS4.SSS1.p10.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS4.SSS1.p10.1.m1.1.1.3" xref="S3.SS4.SSS1.p10.1.m1.1.1.3.cmml">a</mi><mo id="S3.SS4.SSS1.p10.1.m1.1.1.1a" xref="S3.SS4.SSS1.p10.1.m1.1.1.1.cmml">⁢</mo><msub id="S3.SS4.SSS1.p10.1.m1.1.1.4" xref="S3.SS4.SSS1.p10.1.m1.1.1.4.cmml"><mi id="S3.SS4.SSS1.p10.1.m1.1.1.4.2" xref="S3.SS4.SSS1.p10.1.m1.1.1.4.2.cmml">t</mi><mi id="S3.SS4.SSS1.p10.1.m1.1.1.4.3" xref="S3.SS4.SSS1.p10.1.m1.1.1.4.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p10.1.m1.1b"><apply id="S3.SS4.SSS1.p10.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1"><times id="S3.SS4.SSS1.p10.1.m1.1.1.1.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1.1"></times><ci id="S3.SS4.SSS1.p10.1.m1.1.1.2.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1.2">𝑠</ci><ci id="S3.SS4.SSS1.p10.1.m1.1.1.3.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1.3">𝑎</ci><apply id="S3.SS4.SSS1.p10.1.m1.1.1.4.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1.4"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p10.1.m1.1.1.4.1.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1.4">subscript</csymbol><ci id="S3.SS4.SSS1.p10.1.m1.1.1.4.2.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1.4.2">𝑡</ci><ci id="S3.SS4.SSS1.p10.1.m1.1.1.4.3.cmml" xref="S3.SS4.SSS1.p10.1.m1.1.1.4.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p10.1.m1.1c">sat_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p10.1.m1.1d">italic_s italic_a italic_t start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> represents the sole dynamic component of the user’s state, and thus, we generate the user’s observable state based on it. In the simulation, user satisfaction is modeled and computed as a latent state. However, to simulate real-world scenarios, we map the latent state to an observable state by introducing noise to account for user uncertainty.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS4.SSS2.4.1.1">III-D</span>2 </span>Experimental results</h4>
<div class="ltx_para" id="S3.SS4.SSS2.p1">
<p class="ltx_p" id="S3.SS4.SSS2.p1.1">The experimental configurations for LMGT and the baseline SlateQ approach are identical. We independently trained agents using both our method and the baseline SlateQ, evaluating their performance over an equivalent number of episodes. In the “Choc vs. Kale” scenario, each episode consists of a set number of time steps. As illustrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04744v1#S3.T6" title="TABLE VI ‣ III-D1 Simulation environment ‣ III-D Experiments in Industrial Recommendation Scenarios ‣ III Experiment ‣ LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs* *Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."><span class="ltx_text ltx_ref_tag">VI</span></a>, our results conclusively show that our approach significantly accelerates skill acquisition in agents, enabling them to adeptly navigate the complex challenges of the environment. This rapid development of expertise leverages prior knowledge and skillfully balances the tension between exploration and exploitation. As a consequence, there is an efficient use of sample resources, leading to a marked decrease in the training costs associated with RL models. Nonetheless, our study has its limitations. A notable omission is the analysis of computational resources required for integrating LLMs into the training process. Future research will focus on optimizing the use of computational resources in RL training by applying prior knowledge while addressing the heightened resource demand that comes with incorporating LLMs. Additionally, we have not yet formulated a theoretical framework to explain how LLMs dynamically influence reward structures. Addressing this represents a promising avenue for future research.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To harness the extensive prior knowledge produced by human endeavors and achieve a balance between exploration and exploitation in RL, we introduce a framework named <span class="ltx_text ltx_font_bold" id="S4.p1.1.1">LMGT</span>. This framework ingeniously takes advantage of the inherent domain expertise contained in LLMs and their sophisticated information-processing abilities to navigate agent exploration and exploitation efforts without significantly disrupting existing RL workflows. Through experimental evaluations across different settings and using a variety of algorithms, the LMGT framework has demonstrated its effectiveness. It successfully manages the balance between the exploration and exploitation of agents while simultaneously reducing their training expenses. Further validating its practicality, we have applied LMGT to SlateQ, an industrial-grade recommendation algorithm, underscoring its potential for real-world industrial applications. Despite these advances, our study has not yet explored the impact on computational resources due to the integration of LLMs into the training process. Future research will be directed towards striking a balance between the augmented resource consumption caused by incorporating LLMs and optimizing the use and allocation of computational resources in RL training environments to mitigate it.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M. Yogeswaran and S. Ponnambalam, “Reinforcement learning: Exploration–exploitation dilemma in multi-agent foraging task,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Opsearch</em>, vol. 49, pp. 223–236, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L. Busoniu, R. Babuska, and B. De Schutter, “A comprehensive survey of multiagent reinforcement learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)</em>, vol. 38, no. 2, pp. 156–172, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
L. P. Kaelbling, M. L. Littman, and A. W. Moore, “Reinforcement learning: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Journal of artificial intelligence research</em>, vol. 4, pp. 237–285, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. Chen, X. Qiu, X. Tan, Z. Fang, and Y. Jin, “A model-based hybrid soft actor-critic deep reinforcement learning algorithm for optimal ventilator settings,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Information sciences</em>, vol. 611, pp. 47–64, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. S. Sutton and A. G. Barto, <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Reinforcement learning: An introduction</em>.   MIT press, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C. Jin, Z. Allen-Zhu, S. Bubeck, and M. I. Jordan, “Is q-learning provably efficient?” in <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada</em>, S. Bengio, H. M. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds., 2018, pp. 4868–4878.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
D. J. Russo, B. Van Roy, A. Kazerouni, I. Osband, Z. Wen, <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">et al.</em>, “A tutorial on thompson sampling,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.2.2">Foundations and Trends® in Machine Learning</em>, vol. 11, no. 1, pp. 1–96, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
T. Zhang, H. Xu, X. Wang, Y. Wu, K. Keutzer, J. E. Gonzalez, and Y. Tian, “Noveld: A simple yet effective exploration criterion,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual</em>, M. Ranzato, A. Beygelzimer, Y. N. Dauphin, P. Liang, and J. W. Vaughan, Eds., 2021, pp. 25 217–25 230.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Bruce, A. Anand, B. Mazoure, and R. Fergus, “Learning about progress from experts,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">The Eleventh International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
C. M. Rytting and D. Wingate, “Leveraging the inductive bias of large language models for abstract textual reasoning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual</em>, M. Ranzato, A. Beygelzimer, Y. N. Dauphin, P. Liang, and J. W. Vaughan, Eds., 2021, pp. 17 111–17 122.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
W. Gurnee and M. Tegmark, “Language models represent space and time,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
D. Yin, F. Brahman, A. Ravichander, K. Chandu, K.-W. Chang, Y. Choi, and B. Y. Lin, “Lumos: Learning agents with unified data, modular design, and open-source llms,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">ArXiv preprint</em>, vol. abs/2311.05657, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
W. Yao, S. Heinecke, J. C. Niebles, Z. Liu, Y. Feng, L. Xue, R. Murthy, Z. Chen, J. Zhang, D. Arpit, <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">et al.</em>, “Retroformer: Retrospective large language agents with policy gradient optimization,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.2.2">ArXiv preprint</em>, vol. abs/2308.02151, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
X. Zhu, Y. Chen, H. Tian, C. Tao, W. Su, C. Yang, G. Huang, B. Li, L. Lu, X. Wang, <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">et al.</em>, “Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2">ArXiv preprint</em>, vol. abs/2305.17144, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin, E. Zhou, <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">et al.</em>, “The rise and potential of large language model based agents: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.2.2">ArXiv preprint</em>, vol. abs/2309.07864, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
H. Sun, L. Han, R. Yang, X. Ma, J. Guo, and B. Zhou, “Exploit reward shifting in value-based deep-rl: Optimistic curiosity-based exploration and conservative exploitation via linear reward shaping,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 37 719–37 734, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
E. Ie, V. Jain, J. Wang, S. Narvekar, R. Agarwal, R. Wu, H. Cheng, T. Chandra, and C. Boutilier, “Slateq: A tractable decomposition for reinforcement learning with recommendation sets,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019</em>, S. Kraus, Ed.   ijcai.org, 2019, pp. 2592–2599.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large language models are zero-shot reasoners,” <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in neural information processing systems</em>, vol. 35, pp. 22 199–22 213, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J. A. Arjona-Medina, M. Gillhofer, M. Widrich, T. Unterthiner, J. Brandstetter, and S. Hochreiter, “RUDDER: return decomposition for delayed rewards,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada</em>, H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. B. Fox, and R. Garnett, Eds., 2019, pp. 13 544–13 555.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. Towers, J. K. Terry, A. Kwiatkowski, J. U. Balis, G. d. Cola, T. Deleu, M. Goulão, A. Kallinteris, A. KG, M. Krimmel, R. Perez-Vicente, A. Pierré, S. Schulhoff, J. J. Tai, A. T. J. Shen, and O. G. Younis, “Gymnasium,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
A. Raffin, A. Hill, A. Gleave, A. Kanervisto, M. Ernestus, and N. Dormann, “Stable-baselines3: Reliable reinforcement learning implementations,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">J. Mach. Learn. Res.</em>, vol. 22, pp. 268:1–268:8, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
E. Ie, C. wei Hsu, M. Mladenov, V. Jain, S. Narvekar, J. Wang, R. Wu, and C. Boutilier, “Recsim: A configurable simulation platform for recommender systems,” 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, and E. P. Xing, “Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
E. Frantar, S. Ashkboos, T. Hoefler, and D. Alistarh, “Gptq: Accurate post-training quantization for generative pre-trained transformers,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">ArXiv preprint</em>, vol. abs/2210.17323, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, and M. Riedmiller, “Playing atari with deep reinforcement learning,” 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, “Proximal policy optimization algorithms,” 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. P. Lillicrap, T. Harley, D. Silver, and K. Kavukcuoglu, “Asynchronous methods for deep reinforcement learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016</em>, ser. JMLR Workshop and Conference Proceedings, M. Balcan and K. Q. Weinberger, Eds., vol. 48.   JMLR.org, 2016, pp. 1928–1937.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
T. Haarnoja, A. Zhou, K. Hartikainen, G. Tucker, S. Ha, J. Tan, V. Kumar, H. Zhu, A. Gupta, P. Abbeel, and S. Levine, “Soft actor-critic algorithms and applications,” 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
S. Fujimoto, H. van Hoof, and D. Meger, “Addressing function approximation error in actor-critic methods,” in <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018</em>, ser. Proceedings of Machine Learning Research, J. G. Dy and A. Krause, Eds., vol. 80.   PMLR, 2018, pp. 1582–1591.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
H. Liu, C. Li, Q. Wu, and Y. J. Lee, “Visual instruction tuning,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
B. Clavié, A. Ciceu, F. Naylor, G. Soulié, and T. Brightwell, “Large language models in the workplace: A case study on prompt engineering for job type classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">International Conference on Applications of Natural Language to Information Systems</em>.   Springer, 2023, pp. 3–17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt, “Measuring massive multitask language understanding,” in <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>.   OpenReview.net, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">et al.</em>, “Chain-of-thought prompting elicits reasoning in large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.2.2">Advances in neural information processing systems</em>, vol. 35, pp. 24 824–24 837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample, “Llama: Open and efficient foundation language models,” 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Sep  7 07:37:49 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
