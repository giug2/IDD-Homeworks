<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2210.00472] VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization</title><meta property="og:description" content="As a decentralized training approach, federated learning enables multiple organizations to jointly train a model without exposing their private data. This work investigates vertical federated learning (VFL) to address …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2210.00472">

<!--Generated on Tue Feb 27 01:47:41 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated Learning,  Visual Analytics,  Feature Interpretation,  Sample Selection">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yun Tian
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">School of Information Science and Technology, ShanghaiTech University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Shanghai</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:tianyun@shanghaitech.edu.cn">tianyun@shanghaitech.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">He Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">School of Information Science and Technology, ShanghaiTech University</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Shanghai</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:wanghe1@shanghaitech.edu.cn">wanghe1@shanghaitech.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Laixin Xie
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">School of Information Science and Technology, ShanghaiTech University</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Shanghai</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:xielx@shanghaitech.edu.cn">xielx@shanghaitech.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaojuan Ma
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id10.1.id1" class="ltx_text ltx_affiliation_institution">Department of Computer Science and Engineering, The Hong Kong University of Science and Technology</span><span id="id11.2.id2" class="ltx_text ltx_affiliation_city">Hong Kong</span><span id="id12.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:mxj@cse.ust.hk">mxj@cse.ust.hk</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Quan Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id13.1.id1" class="ltx_text ltx_affiliation_institution">School of Information Science and Technology, ShanghaiTech University</span><span id="id14.2.id2" class="ltx_text ltx_affiliation_city">Shanghai</span><span id="id15.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:liquan@shanghaitech.edu.cn">liquan@shanghaitech.edu.cn</a>
</span></span></span>
</div>
<div class="ltx_dates">(2022)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id16.id1" class="ltx_p">As a decentralized training approach, federated learning enables multiple organizations to jointly train a model without exposing their private data. This work investigates vertical federated learning (VFL) to address scenarios where collaborating organizations have the same set of users but with different features, and only one party holds the labels. While VFL shows good performance, practitioners often face uncertainty when preparing non-transparent, internal/external features and samples for the VFL training phase. Moreover, to balance the prediction accuracy and the resource consumption of model inference, practitioners require to know which subset of prediction instances is genuinely needed to invoke the VFL model for inference. To this end, we co-design the VFL modeling process by proposing an interactive real-time visualization system, <span id="id16.id1.1" class="ltx_text ltx_font_italic">VFLens</span>, to help practitioners with feature engineering, sample selection, and inference. A usage scenario, a quantitative experiment, and expert feedback suggest that <span id="id16.id1.2" class="ltx_text ltx_font_italic">VFLens</span> helps practitioners boost VFL efficiency at a lower cost with sufficient confidence.</p>
</div>
<div class="ltx_keywords">Federated Learning, Visual Analytics, Feature Interpretation, Sample Selection
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2022</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>The Tenth International Symposium of Chinese CHI; October 22–23, 2022; Guangzhou, China and Online, China</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>The Tenth International Symposium of Chinese CHI (Chinese CHI 2022), October 22–23, 2022, Guangzhou, China and Online, China</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3565698.3565765</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-9869-5/22/10</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing Visualization</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing Human computer interaction (HCI)</span></span></span><span id="id10" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing Interaction design</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">There is hope that all industries will benefit from big data-driven artificial intelligence (AI), especially after the huge success of <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">AlphaGo</span>. However, with the exception of a few industries, most fields lack sufficient data or have data quality issues to support the construction of a reliable and robust machine learning (ML) model. At the same time, companies are reluctant to share or aggregate their valuable data in a centralized manner due to industry competition and privacy and security concerns, leaving the data often existing as a set of isolated data silos. As a viable decentralized solution that can potentially break down barriers between data sources while preserving privacy and security, federated learning (FL) enables users to collaboratively learn an ML model while keeping all data that may contain private information on their local device <cite class="ltx_cite ltx_citemacro_citep">(Brendan McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2019c</a>)</cite>. Depending on how the data is partitioned between parties and application scenarios, FL can be divided into two main categories, namely horizontal FL (HFL) and vertical FL (VFL) <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2019c</a>)</cite>. The focus of this study is VFL, also known as feature-based FL. VFL can be applied to situations where two datasets have considerable overlap in sample IDs but differ in feature space <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>. A typical example of VFL is a collaboration between an e-commerce retail company and a financial institution in the same city. Their customer set may contain the majority of residents in the area; therefore, the intersection of their customer spaces is huge. However, since the financial institution records its customers’ income, spending behavior, and credit rating, while the e-commerce retailer retains its customers’ browsing and purchasing history, their feature spaces are quite different. In this case, VFL allows both parties to train a joint ML model for product purchase prediction based on customer and product information under privacy-preserving security conditions (<a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>).</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2210.00472/assets/figures/VFL.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Suppose two parties, i.e., a local financial institution (a) and an e-commerce retail company (b) want to co-build a ML model for product purchase prediction. Only the financial institution has the label Y: loan or not and neither party wants to expose their features X. The two parties has an overlapping sample IDs, i.e., user id:<math id="S1.F1.3.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S1.F1.3.m1.1b"><mn id="S1.F1.3.m1.1.1" xref="S1.F1.3.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S1.F1.3.m1.1c"><cn type="integer" id="S1.F1.3.m1.1.1.cmml" xref="S1.F1.3.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.3.m1.1d">1</annotation></semantics></math> – <math id="S1.F1.4.m2.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S1.F1.4.m2.1b"><mn id="S1.F1.4.m2.1.1" xref="S1.F1.4.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S1.F1.4.m2.1c"><cn type="integer" id="S1.F1.4.m2.1.1.cmml" xref="S1.F1.4.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.4.m2.1d">4</annotation></semantics></math>. The target is to establish a joint model under the condition of protecting privacy and the effect of the joint model is better than that of unilateral data modeling.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Although VFL has shown good performance in scenarios such as financial risk management <cite class="ltx_cite ltx_citemacro_citep">(Fedai, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2019b</a>; Zheng et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2020</a>)</cite>, healthcare <cite class="ltx_cite ltx_citemacro_citep">(Vepakomma et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2018</a>)</cite>, and e-commerce ad recommendation <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite>, real world practitioners have encountered the following challenges when trying to use VFL for their application domains <cite class="ltx_cite ltx_citemacro_citep">(Kairouz et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>: <span id="S1.p2.1.1" class="ltx_text ltx_font_bold">1) Uncertainty in sample selection for training.</span> Traditional VFL practitioners mainly utilize two methods to prepare for the VFL training phase. First, when there is not much available data with labels, they may utilize all the overlapping samples with labels to train a joint VFL model for convenience. However, it is well known that the training speed of FL is much slower than that of the local model due to the design of data encryption and communication mechanisms. In some cases, utilizing all overlapping samples with labels for VFL model training can lead to much longer training time. Second, when the amount of data available for training is large, they may select some labeled data samples for training and evaluate the model based on general metrics such as <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">accuracy</span>, <span id="S1.p2.1.3" class="ltx_text ltx_font_italic">loss</span>, and <span id="S1.p2.1.4" class="ltx_text ltx_font_italic">mAP</span>. As a slang expression in classical ML terminology, <span id="S1.p2.1.5" class="ltx_text ltx_font_italic">‘</span>‘garbage in, garbage out” <cite class="ltx_cite ltx_citemacro_citep">(Hohman et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> indicates the samples used for prediction should have a high-quality match with their specific jointly trained VFL models. Although the role of interactive data iteration in ML is emphasized and domain experts acknowledge that “<span id="S1.p2.1.6" class="ltx_text ltx_font_italic">data samples need to have appropriate signals for the model to be useful</span>” <cite class="ltx_cite ltx_citemacro_citep">(Hohman et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>, there is little support for their fine-tuning of training data samples in VFL scenarios. Both practices rely heavily on feedback from VFL model performance for further evaluation, which is sometimes too time-consuming and expensive. In particular, things get worse when the communication of the VFL training process is not so stable, as domain experts have to repeatedly re-upgrade the model training phase by trial and error. Therefore, an intuitive sample data evolution interaction mechanism that allows domain experts to compare the data characteristics and performance of different sample training datasets in a VFL scenario is necessary. <span id="S1.p2.1.7" class="ltx_text ltx_font_bold">2) Non-transparent feature selection and assessment.</span> Successful ML applications require an iterative process to create models that provide the desired performance. One of the key processes involves feature engineering and in this study, we focus on feature selection and assessment. However, unlike traditional centralized ML modeling or HFL in which all data features are available and easy to assess, in VFL, participants update only their internal feature parameters during training, and external features from other parties are not visible to them due to the design of privacy-preserving mechanisms, which poses unique challenges for internal/external feature selection and assessment. That is, in addition to selecting the necessary internal features or transforming the original internal features into other powerful alternatives, practitioners are exploring how to assess external features from other parties <cite class="ltx_cite ltx_citemacro_citep">(Roschewitz et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2021</a>; Wang, <a href="#bib.bib46" title="" class="ltx_ref">2019</a>)</cite>. However, the lack of comprehensive consideration of the contribution of internal and external features while protecting privacy still undermines the use of VFL in production. <span id="S1.p2.1.8" class="ltx_text ltx_font_bold">3) Costly and time-consuming inference.</span> The inference phase of VFL modeling requires online coordination between two (or more) parties to accomplish the inference task, which inevitably poses a challenge to computational resources and raises costs. According to our collaborating domain experts, the cost and deployment efficiency of federated modeling are issues that require rational planning for practical applications, and the use of homomorphic encryption in VFL can lead to a significant reduction in the computational speed and information transfer speed of federated modeling compared to centralized ML modeling <cite class="ltx_cite ltx_citemacro_citep">(Jing et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>. To solve this problem, in addition to optimizing the computational modeling process, another intuitive approach is to reduce the overall data volume. That is, not all samples to be predicted need to be truly predicted with the help of external features from other parties. For example, those samples in which practitioners have relatively high confidence in their labels do not need to be predicted by invoking an online trained VFL model because, e.g., the sample features are poor, and these samples can be safely ignored. Thus, how to visually help domain experts distinguish samples with different confidence in their labels is a desirable capability for real-world VFL deployments.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this study, we co-design the modeling process to help VFL practitioners improve the efficiency of VFL modeling from the perspective of visualization. We first conduct an observational study of the current practices of collaborating domain experts to identify their main needs and concerns regarding VFL applications. Then, we streamline the analysis pipeline of feature and sample spaces and propose an interactive visualization system called <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">VFLens</span>. <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">VFLens</span> helps domain experts to interactively participate in feature selection, assessment, and sample data iteration processes before the VFL model training phase, in feature interpretation after the VFL model training phase, and in data sample selection during the VFL model inference phase. A case study and expert feedback confirm the efficacy of <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">VFLens</span>. Our main contributions are summarized below.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We describe the problem in the VFL context from the perspective of feature and sample space through an observational study and in-depth discussions of design requirements with VFL domain experts.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We co-design the VFL modeling process to support domain experts to interactively participate in the data iteration, feature selection and assessment, and sample prediction processes. To the best of our knowledge, <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span> is the first such effort in the VFL scenario.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We evaluate <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span> through a usage scenario, a quantitative experiment and expert interviews.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The literature that overlaps this work can be categorized into four groups, namely, <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">federated learning</span>, <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">visualizations for federated learning</span>, <span id="S2.p1.1.3" class="ltx_text ltx_font_italic">feature selection and assessment</span>, and <span id="S2.p1.1.4" class="ltx_text ltx_font_italic">sample selection in machine learning</span>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Federated learning was first proposed by Google, which prevents data from being transmitted by distributing model training to each mobile terminal <cite class="ltx_cite ltx_citemacro_citep">(Brendan McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite>. Later, they released the first commercial FL application, <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">GBoard</span> <cite class="ltx_cite ltx_citemacro_citep">(Hard et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>, which uses a recursive neural language model to predict the next word in a keyboard application. <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">GBoard</span> allows each local mobile device to train the model using local data from the same distributed ML model. The global model can be updated by averaging the model parameters collected over all local models. Along the same lines, many studies have reshaped different ML models into a federated framework, including decision trees <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2020</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2018b</a>)</cite>, linear/logistic regression <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2018b</a>; Mohri et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2019</a>)</cite>, and neural networks <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2020</a>; Yurochkin et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2019</a>)</cite>. These works are categorized as HFL because the clients share the same feature space but differ in the sample space. Unlike HFL, VFL is applicable to scenarios where we have many overlapping instances but few overlapping features <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2019b</a>)</cite>. For example, an insurance company and an online retailer in a local city have many overlapping users, but each has its own feature space. VFL “merges” features and uses homomorphic encryption to protect the data privacy of the participating parties, and requires a more sophisticated mechanism to decompose the loss function of each party. This study focuses on VFL, “virtually aggregation” of different features to compute training losses and gradients in a privacy-preserving manner, and jointly build an ML model <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite> with data from both parties.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Visualizations for Federated Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Researchers from academia and industry are using visualizations to demonstrate, explain, and monitor the process of federated learning. For example, in industry, Lenovo has simulated the industrial revolution in factories by demonstrating the process of horizontal federated learning to predict the internal pressure of hardware <cite class="ltx_cite ltx_citemacro_citep">(Rojek, <a href="#bib.bib39" title="" class="ltx_ref">2018</a>)</cite>. Similarly, Cloudera Fast Forward Labs released an interactive simulation prototype, <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">Turbofan Tycoon</span>, which takes advantage of visualization to examine the federated model and predict when a turbofan will fail <cite class="ltx_cite ltx_citemacro_citep">(Mike, <a href="#bib.bib36" title="" class="ltx_ref">2018</a>)</cite>. <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">FATEBoard<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnote1.1.1.1" class="ltx_text ltx_font_upright">1</span></span><span id="footnote1.5" class="ltx_text ltx_font_upright">https://fate.fedai.org/</span></span></span></span></span> utilizes dashboard visualizations to display modeling logs, metrics, and evaluation results, including information on data sets, job status, computational plots, and model output <cite class="ltx_cite ltx_citemacro_citep">(Fan, <a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite>. While <span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_italic">FATEBoard</span> can help domain experts understand the ranking of features and the performance of models, it does not support detailed and interactive inspection of the sample and feature spaces. On the other hand, in academia, Wei et al. <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2019</a>)</cite> developed a game to demonstrate the superiority of HFL and built a visualization prototype to help understand the operation of HFL. However, this work assumes that client-side data can be witnessed by the server-side. Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021b</a>)</cite> proposed <span id="S2.SS2.p1.1.4" class="ltx_text ltx_font_italic">HFLens</span>, which strictly follows a data privacy-preserving design and supports comparative visual interpretation at the overview, communication round, and client instance levels. <span id="S2.SS2.p1.1.5" class="ltx_text ltx_font_italic">HFLens</span> facilitates the investigation of the overall HFL process involving all clients, the correlation analysis of client information in one or different communication rounds, the identification of potential anomalies, and the evaluation of the contribution of each HFL client. However, the pain point for VFL is not the anomaly detection like <span id="S2.SS2.p1.1.6" class="ltx_text ltx_font_italic">HFLens</span>, because for VFL there are generally not as many data collaborators as for HFL, and the collaborators partnerships with common interests. In this work, we do not focus on the operational process of FL, but rather improve the efficiency of VFL modeling by involving domain experts in the sample and feature space.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Feature Selection and Assessment</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">There is a large amount of existing work related to feature selection <cite class="ltx_cite ltx_citemacro_citep">(Chandrashekar and Sahin, <a href="#bib.bib7" title="" class="ltx_ref">2014</a>; Blum and Langley, <a href="#bib.bib5" title="" class="ltx_ref">1997</a>)</cite>, which has two main difficulties. First, a large number of features are used in the process of building machine learning models; however, if several features are linearly correlated with each other, many of them will be redundant, which adds additional computational effort and leads to more complex parameters. Second, common feature analysis methods use feature correlation metrics, but correlation metrics cannot measure nonlinear relationships. Isabelle et al. <cite class="ltx_cite ltx_citemacro_citep">(Guyon and Elisseeff, <a href="#bib.bib16" title="" class="ltx_ref">2003</a>)</cite> performed a survey of automatic feature selection methods. The authors abstracted the core problem of feature selection, which is to find a minimal subset of features from a large number of features. The authors also argued that there are many options for feature selection and that there is no one universal and unique solution. There are other types of feature selection methods, such as wrappers <cite class="ltx_cite ltx_citemacro_citep">(Kohavi and John, <a href="#bib.bib26" title="" class="ltx_ref">1997</a>)</cite>, which iteratively eliminate features by regression or classification models to find the ideal subset of features. There are also metric-based methods <cite class="ltx_cite ltx_citemacro_citep">(Forman et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2003</a>; Aphinyanaphongs et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2014</a>)</cite>, where users pick the top <math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><mi id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">k</annotation></semantics></math> best features. However, they also suffer from the problems described earlier. As for feature assessment, it will be different in VFL modeling and traditional centralized machine learning modeling. In VFL, Host B does not have direct access to the features of Guest A, so in practice, the feature importance of Guest A is obtained by encrypting the IV values <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>, <a href="#bib.bib9" title="" class="ltx_ref">2018</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite> (Host B and Guest A will be introduced in <a href="#S4.SS1" title="4.1. VFL Architecture ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsection 4.1</span></a>). In traditional centralized machine learning modeling, there are many methods to calculate feature importance, such as impurity-based feature importance <cite class="ltx_cite ltx_citemacro_citep">(Scornet, <a href="#bib.bib42" title="" class="ltx_ref">2020</a>)</cite> and permutation feature importance <cite class="ltx_cite ltx_citemacro_citep">(Altmann et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2010</a>)</cite>. In this study, we implement several different types of alternative feature selection techniques for choosing the internal features of Host B. We allow the user to decide whether the feature ranking is desirable or whether to focus on one of the features, while for the external features of Guest A, we use the encrypted IV values <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>, <a href="#bib.bib9" title="" class="ltx_ref">2018</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite> to obtain the feature importance metrics.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Sample Selection in Machine Learning</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">As one of the most critical infrastructures for building AI systems <cite class="ltx_cite ltx_citemacro_citep">(Halevy et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2009</a>)</cite>, data has a significant impact on the performance, fairness, robustness, and scalability of AI systems. However, data is often the “<span id="S2.SS4.p1.1.1" class="ltx_text ltx_font_italic">the least motivated aspect, considered ‘operational’</span>” relative to the lionized work in building new models and algorithms <cite class="ltx_cite ltx_citemacro_citep">(Halevy et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2009</a>; Mehrabi et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2021</a>; Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite>. Akrong et al. <cite class="ltx_cite ltx_citemacro_citep">(Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite> reported on data practices of high-risk AI by interviewing AI practitioners around the world. They identified compound events of adverse and downstream effects caused by data problems named data cascades. Yee et al. <cite class="ltx_cite ltx_citemacro_citep">(Yee et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2003</a>)</cite> proposed Faceted browsing that allows users to use metadata to extract subsets of data that share desired attributes. The rank-by-feature framework allows users to examine low-dimensional projections of multidimensional data based on their statistics  <cite class="ltx_cite ltx_citemacro_citep">(Seo and Shneiderman, <a href="#bib.bib43" title="" class="ltx_ref">2005</a>)</cite>. Hohman et al. <cite class="ltx_cite ltx_citemacro_citep">(Hohman et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> proposed <span id="S2.SS4.p1.1.2" class="ltx_text ltx_font_italic">CHAMELEON</span>, which allows users to compare data features, training/test splits, and performance of multiple data versions. Facets<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://pair-code.github.io/facets/</span></span></span> helps developers examine ML datasets, including training/test segmentation, observe feature shapes, and explore individual observations. For data selection in FL, recent studies select relevant data distributively based on a benchmark model prior to training, regardless of other data quality factors or batch composition during training. Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021c</a>)</cite> provided a systematic analysis of the underlying data factors that affect FL model performance and propose an overall design to privately and efficiently select high quality data samples. However, the focus of these studies is on HFL. Inspired by their work, we emphasize the importance of training data in VFL and propose several interactive visualization schemes to facilitate sample selection prior to training of VFL models. In VFL inference, we separate the samples to be predicted based on the different confidence levels of their labels. To the best of our knowledge, <span id="S2.SS4.p1.1.3" class="ltx_text ltx_font_italic">VFLens</span> is the first attempt in this regard.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Observational Study</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Background</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.5" class="ltx_p">To understand the application of VFL in practice, we worked with a team of domain experts from a collaborating local financial and AI organization, including a FL project manager (E1, male, age: <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="31" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">31</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">31</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">31</annotation></semantics></math>), a VFL researcher (E2, male, age: <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="33" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">33</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><cn type="integer" id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">33</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">33</annotation></semantics></math>), two VFL engineers (E3, male, age: <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="27" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mn id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">27</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><cn type="integer" id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">27</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">27</annotation></semantics></math>, E4, male, age: <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="28" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mn id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">28</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><cn type="integer" id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">28</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">28</annotation></semantics></math>), and one business contact (E5, female, age: <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="29" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mn id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">29</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><cn type="integer" id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">29</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">29</annotation></semantics></math>). A large part of their work is to provide federated learning (both HFL and VFL) solutions to clients to meet their specific business needs. They shared with us a recent encounter in which they designed and developed a precision marketing strategy in a real estate scenario. Notably, the real estate company wanted to leverage the features of other parties through VFL to jointly train an ML model to predict whether a particular customer would come to visit the real estate sales office and understand the customer’s characteristics. By taking this jointly trained VFL model, the real estate company can find more suitable customers from a large pool of other customers who may visit the sales office. An illustrative pipeline for this case is shown in <a href="#S3.F2" title="Figure 2 ‣ 3.1. Background ‣ 3. Observational Study ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2210.00472/assets/figures/showcase.png" id="S3.F2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>A case the experts encountered: designing and developing a precision marketing strategy in a real estate scenario. (1) The real estate company provides training samples from one sales office and (2) the samples are divided into two parts: those who have visited the sales office and those who have no interest in visiting the sales office. (3) The real estate company (host) jointly trains a VFL model with the data from an external data provider (guest). (4) The real estate company predicts whether a particular customer will visit the sales office from its large customer pool. (5) The real estate company learns the characteristics of its potential buying customers to guide offline telemarketing.</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.2" class="ltx_p">In this case of the approval and start-up phases of VFL, the experts encountered several problems. First, the domain experts had to identify training samples from an overlapping set of users between the real estate (host) and the external data provider (guest, i.e., an online e-commercial and financial company). Although the total amount of available training samples has reached about <math id="S3.SS1.p2.1.m1.2" class="ltx_Math" alttext="25,000" display="inline"><semantics id="S3.SS1.p2.1.m1.2a"><mrow id="S3.SS1.p2.1.m1.2.3.2" xref="S3.SS1.p2.1.m1.2.3.1.cmml"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">25</mn><mo id="S3.SS1.p2.1.m1.2.3.2.1" xref="S3.SS1.p2.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS1.p2.1.m1.2.2" xref="S3.SS1.p2.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.2b"><list id="S3.SS1.p2.1.m1.2.3.1.cmml" xref="S3.SS1.p2.1.m1.2.3.2"><cn type="integer" id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">25</cn><cn type="integer" id="S3.SS1.p2.1.m1.2.2.cmml" xref="S3.SS1.p2.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.2c">25,000</annotation></semantics></math>, not all of the samples are good enough. Most records were collected from field sales representatives and describe a rough profile of customer characteristics such as <span id="S3.SS1.p2.2.1" class="ltx_text ltx_font_italic">‘</span>‘gender”, <span id="S3.SS1.p2.2.2" class="ltx_text ltx_font_italic">‘</span>‘age”, <span id="S3.SS1.p2.2.3" class="ltx_text ltx_font_italic">‘</span>‘career”, <span id="S3.SS1.p2.2.4" class="ltx_text ltx_font_italic">‘</span>‘income level”, <span id="S3.SS1.p2.2.5" class="ltx_text ltx_font_italic">‘</span>‘marital status”, and <span id="S3.SS1.p2.2.6" class="ltx_text ltx_font_italic">‘</span>‘family structure”. E1 commented that “<span id="S3.SS1.p2.2.7" class="ltx_text ltx_font_italic">there may be some outliers in the training samples because sometimes salepeople cannot guarantee the veracity of all characteristics.</span>” E3 said that “<span id="S3.SS1.p2.2.8" class="ltx_text ltx_font_italic">we are not experts in real estate,</span>” so he did not have a clear idea about how to identify the right sample of customers for model training. Besides the local feature aspect, the limited computational resources and communication bandwidth between the host and the guest is another issue in the modeling process. In other words, dumping all overlapping training samples to train the VFL model is unrealistic because it may consume a lot of communication resources. Considering the characteristics of training samples and resources, domain experts would like to get some intuitive tips on how to select suitable and sufficient training samples. Second, when discussing how model knowledge can be used to guide their offline marketing strategies when contacting potential customers, E1 and E5 said, “<span id="S3.SS1.p2.2.9" class="ltx_text ltx_font_italic">we should at least know what the model has learned so that we can understand the characteristics of customers who are likely to visit our real estate sales office.</span>” Third, when it comes to inference and prediction using the trained VFL model, the initial expectation of the business requirement was that predictions needed to be made for all contacts in the real estate pool to obtain the likelihood that they would visit the sales office. However, the reality is that the pool is quite large, i.e., about <math id="S3.SS1.p2.2.m2.2" class="ltx_Math" alttext="100,000" display="inline"><semantics id="S3.SS1.p2.2.m2.2a"><mrow id="S3.SS1.p2.2.m2.2.3.2" xref="S3.SS1.p2.2.m2.2.3.1.cmml"><mn id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">100</mn><mo id="S3.SS1.p2.2.m2.2.3.2.1" xref="S3.SS1.p2.2.m2.2.3.1.cmml">,</mo><mn id="S3.SS1.p2.2.m2.2.2" xref="S3.SS1.p2.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.2b"><list id="S3.SS1.p2.2.m2.2.3.1.cmml" xref="S3.SS1.p2.2.m2.2.3.2"><cn type="integer" id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">100</cn><cn type="integer" id="S3.SS1.p2.2.m2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.2c">100,000</annotation></semantics></math> and each prediction requires a paid call to the online VFL model. “<span id="S3.SS1.p2.2.10" class="ltx_text ltx_font_italic">If the model predicts all the customers in the pool, the budget may not cover this cost.</span>” said E4, “<span id="S3.SS1.p2.2.11" class="ltx_text ltx_font_italic">can we just predict those customers who need the help of the VFL model without running all of them?</span>”</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Requirement Analysis</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To ensure that our approach was in line with the tasks and requirements, we interviewed all experts (E1 – E5) to identify their main concerns about improving VFL modeling efficiency and have summarized their requirements below.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">R.1 Evaluate the quality of the training samples from the host.</span> The first pressing problem that experts encounter when building VFL models is to prepare sufficiently good training samples. While previous studies have proposed various methods to support data iteration for better model training <cite class="ltx_cite ltx_citemacro_citep">(Hohman et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>; Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2021</a>; Seo and Shneiderman, <a href="#bib.bib43" title="" class="ltx_ref">2005</a>; Yee et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2003</a>)</cite>, there is little support for this in VFL. E1 and E5 had little work experience in ML and, given the specific business requirements in the VFL scenario, they felt that their domain knowledge could be useful in selecting training samples. Therefore, both technologists (E3 and E4) and business personnel (E1 and E5) wanted to assess the quality of samples used by the host for model training in an intuitive and interactive way.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">R.2 Understand the internal/external features of hosts and guests.</span> Although the well-established automatic feature selection techniques allow analysts to confirm the contribution of each feature to the final prediction, especially in datasets with many features <cite class="ltx_cite ltx_citemacro_citep">(Chatzimparmpas et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>, these techniques may produce significantly inconsistent results. According to E2, in a typical VFL scenario, the feature space is distributed in two (or multiple) parties. Thus, understanding internal/external features consists of two stages: 1) comparing alternative feature selection techniques based on their ranking of all internal features of the host, and 2) simulating external features of different batches of guests. Notably, the experts indicated that they would like answers to the following questions: “<span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_italic">which internal features are consistently ranked high?</span>”; “<span id="S3.SS2.p3.1.3" class="ltx_text ltx_font_italic">How much does the technology vary in terms of feature ranking?</span>” Our approach should allow experts to respond to such queries.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">R.3 Compare performance between models.</span> Inspired by recent studies that use similarities between model representations to correct for local training of the parties, such as conducting contrastive learning in model-level <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2021a</a>)</cite> or comparing differences between the global HFL model and the local model <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021b</a>)</cite>, E3 and E4 wished to understand the differences between each locally trained model and the global VFL model. For example, using standard validation metrics such as <span id="S3.SS2.p4.1.2" class="ltx_text ltx_font_italic">accuracy,</span> <span id="S3.SS2.p4.1.3" class="ltx_text ltx_font_italic">loss</span>, <span id="S3.SS2.p4.1.4" class="ltx_text ltx_font_italic">Kolmogorov-Smirnov (KS)</span>, <span id="S3.SS2.p4.1.5" class="ltx_text ltx_font_italic">Area under the curve (AUC)</span>, and <span id="S3.SS2.p4.1.6" class="ltx_text ltx_font_italic">mean Average Precision (mAP)</span> to understand performance fluctuations. In addition, experts wanted to have an overview of the history of the operations they performed so that they could identify “<span id="S3.SS2.p4.1.7" class="ltx_text ltx_font_italic">critical points that might correspond to model performance improvements</span>” <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2021a</a>)</cite>. Therefore, it is desirable to have an intuitive representation of the model performance per attempt and the performance differences between models.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p"><span id="S3.SS2.p5.1.1" class="ltx_text ltx_font_bold">R.4 Obtain VFL forecasts at low cost.</span> The most critical business requirement raised by E1 and E5 is the conflict between the large number of forecasting requirements and the limited monetary budget and computational/communication resources. They commented, “<span id="S3.SS2.p5.1.2" class="ltx_text ltx_font_italic">usually, the pool has a large number of samples to forecast, but blindly feeding all of them into the joint model will inevitably result in a waste of time and money.</span>” Therefore, given the limited resources, experts need a strategy to balance the prediction sample size with a good enough prediction accuracy.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p"><span id="S3.SS2.p6.1.1" class="ltx_text ltx_font_bold">R.5 Checking the prediction results.</span> As mentioned earlier, since our method makes a trade-off between the size of the VFL prediction sample and the prediction accuracy, experts are curious about the effectiveness of our strategy. Therefore, we should perform a comparative evaluation of the prediction results of our strategy. This evaluation will allow domain experts, especially E5, to understand the efficacy of our method and the reasons why those samples with relatively high confidence in the labels do not need to call the online trained VFL model for prediction.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Co-design the Modeling Process of VFL</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Inspired by the observational study, we propose a co-design process for VFL modeling, as shown in <a href="#S4.F3" title="Figure 3 ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>. Our approach, named <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span>, consists of an LR-based back-end VFL configuration module and a front-end visualization module. Specifically, the back-end module collects the necessary logs from the embedded VFL model and processes the information required for feature and data sample selection. The output of the back-end engine module is fed to the front-end visualization module for further analysis. The back-end engine module also receives interactive commands from the user through the front-end visualization module during the feature and sample selection phases of model training and prediction.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2210.00472/assets/figures/pipeline.png" id="S4.F3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="203" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Overview of our approach. We divide the pipeline of our approach into two phases, namely <span id="S4.F3.10.1" class="ltx_text ltx_font_italic">modeling stage</span> and <span id="S4.F3.11.2" class="ltx_text ltx_font_italic">inference stage</span>. In the modeling stage, we first configure the backend using <span id="S4.F3.12.3" class="ltx_text ltx_font_italic">LR-based vertical federated learning</span>. Features distributed on two parties, i.e., host and guest, are selected and fine-tuned in <span id="S4.F3.13.4" class="ltx_text ltx_font_italic">Features for Modeling</span> and <span id="S4.F3.14.5" class="ltx_text ltx_font_italic">Feature Selection View</span>. After determining the features, we select the appropriate samples for modeling via <span id="S4.F3.15.6" class="ltx_text ltx_font_italic">Sample Selection View</span>. Then, we fine-tune the local model via <span id="S4.F3.16.7" class="ltx_text ltx_font_italic">Model Performance View</span> until we are satisfied and run the VFL model using the identified features and the samples initialized by the host side. Note that the local model can be fine-tuned several times. During the inference phase, all instances used for inference are compared and sampled via <span id="S4.F3.17.8" class="ltx_text ltx_font_italic">Inference View</span>. Finally, in <span id="S4.F3.18.9" class="ltx_text ltx_font_italic">Inference View</span>, samples with low confidence are fed into the VFL model for prediction; otherwise, samples with high confidence are provided to the local model for prediction.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>VFL Architecture</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.8" class="ltx_p">In this subsection, we illustrate the general architecture and basic background knowledge of a VFL system. According to the definition proposed by Yang et al. <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2019c</a>)</cite>, VFL is suitable for scenarios with many overlapping instances but few overlapping features. For example, suppose two companies, <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">A</annotation></semantics></math> and <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">B</annotation></semantics></math>, want to jointly train a machine learning model with their business data (i.e., they have different feature spaces). In addition, <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mi id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">B</annotation></semantics></math> has the label data that the model needs to predict. In this case, <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mi id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">B</annotation></semantics></math> is considered as the <span id="S4.SS1.p1.8.1" class="ltx_text ltx_font_bold">Host</span> and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">A</annotation></semantics></math> as the <span id="S4.SS1.p1.8.2" class="ltx_text ltx_font_bold">Guest</span>. Due to data privacy and security issues, the two companies cannot directly exchange their business data for training. To ensure data confidentiality during model training, an honest third party, usually played by an authority or a secure computing node, is introduced and participates without colluding with either party, i.e., <span id="S4.SS1.p1.8.3" class="ltx_text ltx_font_bold">Collaborator</span> <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><mi id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><ci id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">C</annotation></semantics></math>. Both parties (<math id="S4.SS1.p1.7.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.p1.7.m7.1a"><mi id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><ci id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">A</annotation></semantics></math>, <math id="S4.SS1.p1.8.m8.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.SS1.p1.8.m8.1a"><mi id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><ci id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">B</annotation></semantics></math>) are honest, but curious about each other’s data. It is worth noting that a VFL training process usually consists of the two following phases as shown in <a href="#S4.F4" title="Figure 4 ‣ 4.2. LR-based VFL Configuration ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 4</span></a>(a), i.e., <span id="S4.SS1.p1.8.4" class="ltx_text ltx_font_italic">Encrypted Entity Alignment</span> and <span id="S4.SS1.p1.8.5" class="ltx_text ltx_font_italic">Encrypted Model Training</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2019c</a>)</cite>. In the <span id="S4.SS1.p1.8.6" class="ltx_text ltx_font_italic">Encrypted Entity Alignment</span> phase, VFL utilizes an encryption-based user ID alignment technique called Private Set Intersection (PSI) <cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2012</a>)</cite>, based on some encryption techniques such as <span id="S4.SS1.p1.8.7" class="ltx_text ltx_font_italic">MD5</span> <cite class="ltx_cite ltx_citemacro_citep">(Rivest and Dusse, <a href="#bib.bib38" title="" class="ltx_ref">1992</a>)</cite> and <span id="S4.SS1.p1.8.8" class="ltx_text ltx_font_italic">Secure Hash Algorithm-1 (SHA-1)</span> <cite class="ltx_cite ltx_citemacro_citep">(Yuen and Wong, <a href="#bib.bib56" title="" class="ltx_ref">2011</a>)</cite> to identify common users who overlap on both sides without exposing their respective data. Note that the VFL system does not tell non-overlapping users during the encrypted entity alignment process. Regarding the <span id="S4.SS1.p1.8.9" class="ltx_text ltx_font_italic">Encrypted Model Training</span> stage, we adopt logistic regression (LR)-based VFL <cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2019a</a>)</cite> to showcase our approach. Other federated privacy-preserving ML algorithms such as secure linear regression <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2019c</a>)</cite> and SecureBoost <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite> can also be quickly adopted or replaced with our back-end VFL solution. Since the initiator of VFL is the host, our proposed co-design process for VFL modeling (i.e., <span id="S4.SS1.p1.8.10" class="ltx_text ltx_font_italic">VFLens</span>) is oriented to the host side.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>LR-based VFL Configuration</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We utilize LR and stochastic gradient descent in cooperation with an additive homomorphic encryption scheme and mask <cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2019a</a>)</cite>. The phase of encryption model training starts after identifying overlapping entities common to both parties, which are used to train the ML model. Notably, our goal is to have both parties, i.e., the host and the guest, compute the intermediate results of the gradient separately as much as possible, and then get their gradient results through the interaction of encrypted information. As shown in <a href="#S4.F4" title="Figure 4 ‣ 4.2. LR-based VFL Configuration ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 4</span></a>(b) (1 – 4), we divide the computational task as follows. That is, in each round of parameter update, each party needs to perform the following computations and interactions in turn and Step 1 – 4 are repeated until the model converges.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2210.00472/assets/figures/architecture.png" id="S4.F4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="173" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Architecture for a typical VFL system.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Step 1:</span> Guest A and Host B initialize their parameters, and Collaborator C generates a key pair and distributes the public key to A and B.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Step 2:</span> Guest A computes its part of the gradient, encrypts with the public key, and sends it to Host B. Host B calculates its own amount of the gradient, encrypts it with the public key, and sends it to Guest A. All exchanged information is homomorphically encrypted, so parameters can be computed like in non-encrypted procedures, but are not visible. After receiving the corresponding parts, both parties compute their respective parts of the gradient separately.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Step 3:</span> Both parties send the encrypted part of the gradient to Collaborator C for decryption, but to prevent Collaborator C from getting the gradient directly, Guest A and Host B add a random mask to the gradient part and send it to Collaborator C. Thus, the gradient obtained by Collaborator C cannot be used directly.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">Step 4:</span> Collaborator C gets the two parts of the encryption gradient, decrypts them, and returns them to Guest A and Host B, respectively. Then, Guest A and Host B subtract the previously added random mask to get the actual gradient and update their parameters.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>VFL Modeling Phase</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this subsection, we first describe the general process of the VFL modeling phase. Then, we describe how <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span> supports domain experts to co-design the feature and sample space for VFL modeling.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>General Process of VFL Modeling</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.2" class="ltx_p">To train the VFL model, first, both host and guest collide de-identifiable<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>A process that removes personal identity and makes it impossible to identify or associate the subject of the personal information without additional information.</span></span></span> sample users id to determine the user intersection set. In the modeling phase, we decide which samples from the intersection will be used as training and testing samples (<a href="#S4.SS3.SSS4" title="4.3.4. Samples for Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref ltx_font_bold"><span class="ltx_text ltx_ref_tag">subsubsection 4.3.4</span></a><span id="S4.SS3.SSS1.p1.2.1" class="ltx_text ltx_font_bold"> Samples for Modeling</span>), where the training samples are used to train the VFL model and the testing samples are used to validate the model. Next, both parties train a “semi-model” using the features and labels of the samples. In addition to the samples, the model training also requires the determination of sample features (<a href="#S4.SS3.SSS2" title="4.3.2. Features for Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref ltx_font_bold"><span class="ltx_text ltx_ref_tag">subsubsection 4.3.2</span></a><span id="S4.SS3.SSS1.p1.2.2" class="ltx_text ltx_font_bold"> Features for Modeling</span>) and sample performance (sample labels). Specifically, the guest provides a certain amount of modeling sample features (<math id="S4.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="Feature_{guest}" display="inline"><semantics id="S4.SS3.SSS1.p1.1.m1.1a"><mrow id="S4.SS3.SSS1.p1.1.m1.1.1" xref="S4.SS3.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS1.p1.1.m1.1.1.2" xref="S4.SS3.SSS1.p1.1.m1.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.1" xref="S4.SS3.SSS1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.3" xref="S4.SS3.SSS1.p1.1.m1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.1a" xref="S4.SS3.SSS1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.4" xref="S4.SS3.SSS1.p1.1.m1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.1b" xref="S4.SS3.SSS1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.5" xref="S4.SS3.SSS1.p1.1.m1.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.1c" xref="S4.SS3.SSS1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.6" xref="S4.SS3.SSS1.p1.1.m1.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.1d" xref="S4.SS3.SSS1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.7" xref="S4.SS3.SSS1.p1.1.m1.1.1.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.1e" xref="S4.SS3.SSS1.p1.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS3.SSS1.p1.1.m1.1.1.8" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.cmml"><mi id="S4.SS3.SSS1.p1.1.m1.1.1.8.2" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.2.cmml">e</mi><mrow id="S4.SS3.SSS1.p1.1.m1.1.1.8.3" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.cmml"><mi id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.2" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.3" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1a" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.4" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1b" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.5" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1c" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.6" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.6.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p1.1.m1.1b"><apply id="S4.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1"><times id="S4.SS3.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.1"></times><ci id="S4.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.2">𝐹</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.3">𝑒</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.4.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.4">𝑎</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.5.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.5">𝑡</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.6.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.6">𝑢</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.7.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.7">𝑟</ci><apply id="S4.SS3.SSS1.p1.1.m1.1.1.8.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p1.1.m1.1.1.8.1.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8">subscript</csymbol><ci id="S4.SS3.SSS1.p1.1.m1.1.1.8.2.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.2">𝑒</ci><apply id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3"><times id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.1"></times><ci id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.2.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.2">𝑔</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.3.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.3">𝑢</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.4.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.4">𝑒</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.5.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.5">𝑠</ci><ci id="S4.SS3.SSS1.p1.1.m1.1.1.8.3.6.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1.8.3.6">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p1.1.m1.1c">Feature_{guest}</annotation></semantics></math>) for VFL model training, and completes its “semi-model” training in its local environment. The host provides labels of the modeling samples for VFL model training, but it is not necessary to provide the features (<math id="S4.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="Feature_{host}" display="inline"><semantics id="S4.SS3.SSS1.p1.2.m2.1a"><mrow id="S4.SS3.SSS1.p1.2.m2.1.1" xref="S4.SS3.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS1.p1.2.m2.1.1.2" xref="S4.SS3.SSS1.p1.2.m2.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.1" xref="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.3" xref="S4.SS3.SSS1.p1.2.m2.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.1a" xref="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.4" xref="S4.SS3.SSS1.p1.2.m2.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.1b" xref="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.5" xref="S4.SS3.SSS1.p1.2.m2.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.1c" xref="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.6" xref="S4.SS3.SSS1.p1.2.m2.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.1d" xref="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.7" xref="S4.SS3.SSS1.p1.2.m2.1.1.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.1e" xref="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml">​</mo><msub id="S4.SS3.SSS1.p1.2.m2.1.1.8" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.cmml"><mi id="S4.SS3.SSS1.p1.2.m2.1.1.8.2" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.2.cmml">e</mi><mrow id="S4.SS3.SSS1.p1.2.m2.1.1.8.3" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.cmml"><mi id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.2" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.3" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1a" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.4" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1b" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1.cmml">​</mo><mi id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.5" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.5.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p1.2.m2.1b"><apply id="S4.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1"><times id="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.1"></times><ci id="S4.SS3.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.2">𝐹</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.3">𝑒</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.4.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.4">𝑎</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.5.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.5">𝑡</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.6.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.6">𝑢</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.7.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.7">𝑟</ci><apply id="S4.SS3.SSS1.p1.2.m2.1.1.8.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p1.2.m2.1.1.8.1.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8">subscript</csymbol><ci id="S4.SS3.SSS1.p1.2.m2.1.1.8.2.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.2">𝑒</ci><apply id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3"><times id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.1"></times><ci id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.2.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.2">ℎ</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.3.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.3">𝑜</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.4.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.4">𝑠</ci><ci id="S4.SS3.SSS1.p1.2.m2.1.1.8.3.5.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.8.3.5">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p1.2.m2.1c">Feature_{host}</annotation></semantics></math>) of the modeling samples for VFL model training. Based on feedback from domain experts, “<span id="S4.SS3.SSS1.p1.2.3" class="ltx_text ltx_font_italic">host does not necessarily have the features of the modeling samples, but must have the labels of the modeling samples.</span>” Without loss of generality, we assume that the host also has some features of the modeling samples, i.e., in our case, the host has both some but limited features and all the labels of the modeling samples. Thus, the host can also train a “semi-model” locally by using these features and labels.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2210.00472/assets/figures/system.png" id="S4.F5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="347" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5. </span><span id="S4.F5.4.1" class="ltx_text ltx_font_italic">VFLens</span> interface: (a) A data loader for selecting cases of interest; (b) A feature selection view embeds five automatic feature selection methods. Users can select a certain number of local features and external “invisible” features by considering the internal feature importance and balancing the cost of VFL modeling. (c) The sample selection view shows the statistics information of the dataset and 2D embedding projection of all training samples. Users can select a particular data cluster in (c1) for selection and observe the detailed feature distribution of each cluster in (c2). (c3) An interactive scheme to select samples from the center to the periphery of a cluster. (c4) The quality of the training data set is evaluated by two metrics, <span id="S4.F5.5.2" class="ltx_text ltx_font_italic">homogeneity</span> and <span id="S4.F5.6.3" class="ltx_text ltx_font_italic">diversity</span>. (d1) Parameter selection for modeling. (d2) The model performance view for training the local and VFL model. (e) The summary view presents and visualizes the results of the classification results of all the samples to be predicted with our strategy.</figcaption>
</figure>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Features for Modeling</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">As mentioned earlier, we assume that the host holds user data that can be processed as features and labels. The host then needs to transform the user samples used for modeling into user features and user labels in order to complete the host’s “semi-model” training locally. Therefore, how to properly co-design the host samples with features is of great interest to federated learning practitioners.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.6" class="ltx_p">For internal features, we explore the feature importance-based host feature space <cite class="ltx_cite ltx_citemacro_citep">(Chatzimparmpas et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> using the following five representative automatic feature selection techniques. There are three methods for <span id="S4.SS3.SSS2.p2.6.1" class="ltx_text ltx_font_italic">Univariate Feature Selection</span> <cite class="ltx_cite ltx_citemacro_citep">(Jović et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2015</a>)</cite>. 1) The first one uses the method of <span id="S4.SS3.SSS2.p2.6.2" class="ltx_text ltx_font_italic">ANOVA</span> F-value test to select <math id="S4.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS2.p2.1.m1.1a"><mi id="S4.SS3.SSS2.p2.1.m1.1.1" xref="S4.SS3.SSS2.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.1.m1.1b"><ci id="S4.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.1.m1.1c">k</annotation></semantics></math> best features. To avoid automatic feature removal, we always set the value of <math id="S4.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS2.p2.2.m2.1a"><mi id="S4.SS3.SSS2.p2.2.m2.1.1" xref="S4.SS3.SSS2.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.2.m2.1b"><ci id="S4.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S4.SS3.SSS2.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.2.m2.1c">k</annotation></semantics></math> to the maximum value of all features retained and let the domain experts decide which features to retain. 2) The <math id="S4.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{X}^{2}" display="inline"><semantics id="S4.SS3.SSS2.p2.3.m3.1a"><msup id="S4.SS3.SSS2.p2.3.m3.1.1" xref="S4.SS3.SSS2.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS2.p2.3.m3.1.1.2" xref="S4.SS3.SSS2.p2.3.m3.1.1.2.cmml">𝒳</mi><mn id="S4.SS3.SSS2.p2.3.m3.1.1.3" xref="S4.SS3.SSS2.p2.3.m3.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.3.m3.1b"><apply id="S4.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S4.SS3.SSS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS2.p2.3.m3.1.1.1.cmml" xref="S4.SS3.SSS2.p2.3.m3.1.1">superscript</csymbol><ci id="S4.SS3.SSS2.p2.3.m3.1.1.2.cmml" xref="S4.SS3.SSS2.p2.3.m3.1.1.2">𝒳</ci><cn type="integer" id="S4.SS3.SSS2.p2.3.m3.1.1.3.cmml" xref="S4.SS3.SSS2.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.3.m3.1c">\mathcal{X}^{2}</annotation></semantics></math>-based method uses a chi-square test to select the <math id="S4.SS3.SSS2.p2.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS2.p2.4.m4.1a"><mi id="S4.SS3.SSS2.p2.4.m4.1.1" xref="S4.SS3.SSS2.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.4.m4.1b"><ci id="S4.SS3.SSS2.p2.4.m4.1.1.cmml" xref="S4.SS3.SSS2.p2.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.4.m4.1c">k</annotation></semantics></math> best features. 3) The mutual information method estimates the mutual information of discrete target variables, with higher values implying stronger dependencies. 4) <span id="S4.SS3.SSS2.p2.6.3" class="ltx_text ltx_font_italic">Impurity-based Feature Importance</span> <cite class="ltx_cite ltx_citemacro_citep">(Scornet, <a href="#bib.bib42" title="" class="ltx_ref">2020</a>)</cite>. This is related to the intrinsic nature of the ensemble algorithm, i.e., outputting feature importance after training. Therefore, we derive the feature importance from the best model found so far. 5) <span id="S4.SS3.SSS2.p2.6.4" class="ltx_text ltx_font_italic">Permutation Feature Importance</span> <cite class="ltx_cite ltx_citemacro_citep">(Altmann et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2010</a>)</cite>. This is a technique for monitoring the reduction of model scores when individual feature values are randomly shuffled. To put them in the same context for comparison, we normalize the output from <math id="S4.SS3.SSS2.p2.5.m5.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS3.SSS2.p2.5.m5.1a"><mn id="S4.SS3.SSS2.p2.5.m5.1.1" xref="S4.SS3.SSS2.p2.5.m5.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.5.m5.1b"><cn type="integer" id="S4.SS3.SSS2.p2.5.m5.1.1.cmml" xref="S4.SS3.SSS2.p2.5.m5.1.1">0</cn></annotation-xml></semantics></math> to <math id="S4.SS3.SSS2.p2.6.m6.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS3.SSS2.p2.6.m6.1a"><mn id="S4.SS3.SSS2.p2.6.m6.1.1" xref="S4.SS3.SSS2.p2.6.m6.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.6.m6.1b"><cn type="integer" id="S4.SS3.SSS2.p2.6.m6.1.1.cmml" xref="S4.SS3.SSS2.p2.6.m6.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.6.m6.1c">1</annotation></semantics></math>. We also calculate their average value to represent the feature performance on an average basis.</p>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p id="S4.SS3.SSS2.p3.1" class="ltx_p">For external features, since they are invisible to the host, the data requester does not have access to the data information of the training participants in advance. The simplest way is that if the host wants to perform VFL jointly, they need to try all combinations of external features. This would waste a lot of training time. Existing work usually utilize feature bucketing <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>, <a href="#bib.bib9" title="" class="ltx_ref">2018</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite> for external feature engineering and secures the data to measure the importance of external features. In this work, we also utilize the cryptographic communication method of feature bucketing to compute the information values (iv) of external features.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3. </span>Feature Selection View</h4>

<figure id="S4.F6" class="ltx_figure"><img src="/html/2210.00472/assets/figures/Feature_selection_view.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="261" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Design alternatives for feature selection.</figcaption>
</figure>
<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">Based on the above internal feature selection for modeling, we design a feature selection view <a href="#S4.F6" title="Figure 6 ‣ 4.3.3. Feature Selection View ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 6</span></a>(a) that supports domain experts to interactively select essential features from internal and external features based on feature importance (<span id="S4.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_bold">R2</span>). The view is designed using a heatmap <cite class="ltx_cite ltx_citemacro_citep">(Chatzimparmpas et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>, where the horizontal axis refers to different feature selection methods and the vertical axis represents different features. The color depth of the heatmap represents the importance of the features, and the penultimate column is the average of the first five methods, which serves as a reference for our selection. The last column can be interactively toggled to select and decide which local feature we finally choose for modeling. For external feature selection, due to the privacy mechanism of federated feature modeling, domain experts only have access to the importance of federated features and the anonymous ID of external feature. Therefore, <span id="S4.SS3.SSS3.p1.1.2" class="ltx_text ltx_font_italic">VFLens</span> uses the depth of the color to encode the information values (iv) in the VFL feature selection view <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(b).</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<p id="S4.SS3.SSS3.p2.1" class="ltx_p">We initially considered an alternative design solution displayed as a radial stacked bar chart <a href="#S4.F6" title="Figure 6 ‣ 4.3.3. Feature Selection View ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 6</span></a>(b). We accumulate the scores of the different automatic feature selection methods in a stacked plot, which can directly display the most critical feature. In addition, thin lines connect the features, and their thickness represents the correlation between the two corresponding features. However, this initial design was not accepted by our collaboration experts when comparing the differences between the various feature selection methods. In addition, we need to consider the contribution of features from the external party. Therefore, we finally chose the first design.</p>
</div>
</section>
<section id="S4.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4. </span>Samples for Modeling</h4>

<figure id="S4.F7" class="ltx_figure"><img src="/html/2210.00472/assets/figures/sample.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="150" height="91" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>Illustration of interactive sampling stage.</figcaption>
</figure>
<div id="S4.SS3.SSS4.p1" class="ltx_para">
<p id="S4.SS3.SSS4.p1.1" class="ltx_p">In addition to assessing the contribution of features, another concern of VFL practitioners is to prepare suitable samples for the VFL modeling process. By selecting relevant samples, the labels of the samples can be potentially balanced (<span id="S4.SS3.SSS4.p1.1.1" class="ltx_text ltx_font_bold">R1</span>) and the diversity of sample features can be maintained, which can potentially improve model performance <cite class="ltx_cite ltx_citemacro_citep">(Li and Jun, <a href="#bib.bib34" title="" class="ltx_ref">2006</a>)</cite>. To this end, we propose an interactive sampling and evaluation procedure, which consists of two phases, <span id="S4.SS3.SSS4.p1.1.2" class="ltx_text ltx_font_italic">projection and clustering</span> and <span id="S4.SS3.SSS4.p1.1.3" class="ltx_text ltx_font_italic">interactive sampling for each cluster</span>.</p>
</div>
<div id="S4.SS3.SSS4.p2" class="ltx_para">
<p id="S4.SS3.SSS4.p2.1" class="ltx_p"><span id="S4.SS3.SSS4.p2.1.1" class="ltx_text ltx_font_bold">Projection and Clustering.</span> We utilize <span id="S4.SS3.SSS4.p2.1.2" class="ltx_text ltx_font_italic">t-SNE</span> as a dimensionality reduction technique because it is particularly good at conveying meaningful insights about the data, such as clusters and outliers <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2018a</a>)</cite>. Nevertheless, it may not be feasible to transform all avaiable samples in the intersection user set (i.e., the samples for training, validation, and prediction) into a two-dimensional representation based on the data features residing in the host and depict them on a two-dimensional space, as the data size may be huge. To deal with this potential problem, we abstract the raw training data into several clusters using <span id="S4.SS3.SSS4.p2.1.3" class="ltx_text ltx_font_italic">KMeans++</span> <cite class="ltx_cite ltx_citemacro_citep">(Arthur and Vassilvitskii, <a href="#bib.bib4" title="" class="ltx_ref">2006</a>)</cite>, which augments <span id="S4.SS3.SSS4.p2.1.4" class="ltx_text ltx_font_italic">KMeans</span> with a
random and direct seeding technique that greatly improves its speed. We determine the number of clusters using the Elbow method <cite class="ltx_cite ltx_citemacro_citep">(Syakur et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S4.SS3.SSS4.p3" class="ltx_para">
<p id="S4.SS3.SSS4.p3.11" class="ltx_p"><span id="S4.SS3.SSS4.p3.11.1" class="ltx_text ltx_font_bold">Interactive Sampling.</span> Sampling is a simple but practically meaningful method to greatly reduce the data while maintaining certain data properties. We propose an interactive sampling scheme for each cluster. The basic principle is to drop most of the internal samples and keep the boundary samples to ensure strong learning and generalization <cite class="ltx_cite ltx_citemacro_citep">(Li and Jun, <a href="#bib.bib34" title="" class="ltx_ref">2006</a>)</cite>. Users can interactively control the sampling ratio for a given data interval by adjusting the sampling slider in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(c3).
<a href="#S4.F7" title="Figure 7 ‣ 4.3.4. Samples for Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 7</span></a> is a schematic of the sample data around the cluster, and the dashed circles are intervals divided from the origin outward, centered on the center of the cluster. The intuitive idea is that some nodes at the center of the cluster are more concentrated and representative, while sample data that are off-center tend to have some noise. We divide each cluster into intervals of <math id="S4.SS3.SSS4.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS3.SSS4.p3.1.m1.1a"><mi id="S4.SS3.SSS4.p3.1.m1.1.1" xref="S4.SS3.SSS4.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.1.m1.1b"><ci id="S4.SS3.SSS4.p3.1.m1.1.1.cmml" xref="S4.SS3.SSS4.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.1.m1.1c">n</annotation></semantics></math> from the center to the circle margin as <math id="S4.SS3.SSS4.p3.2.m2.1" class="ltx_Math" alttext="[0:\sqrt{r}]" display="inline"><semantics id="S4.SS3.SSS4.p3.2.m2.1a"><mrow id="S4.SS3.SSS4.p3.2.m2.1.1.1" xref="S4.SS3.SSS4.p3.2.m2.1.1.2.cmml"><mo stretchy="false" id="S4.SS3.SSS4.p3.2.m2.1.1.1.2" xref="S4.SS3.SSS4.p3.2.m2.1.1.2.1.cmml">[</mo><mrow id="S4.SS3.SSS4.p3.2.m2.1.1.1.1" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.cmml"><mn id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.2" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.2.cmml">0</mn><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.1" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.1.cmml">:</mo><msqrt id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3.cmml"><mi id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3.2" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3.2.cmml">r</mi></msqrt></mrow><mo stretchy="false" id="S4.SS3.SSS4.p3.2.m2.1.1.1.3" xref="S4.SS3.SSS4.p3.2.m2.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.2.m2.1b"><apply id="S4.SS3.SSS4.p3.2.m2.1.1.2.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1"><csymbol cd="latexml" id="S4.SS3.SSS4.p3.2.m2.1.1.2.1.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.2">delimited-[]</csymbol><apply id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1"><ci id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.1">:</ci><cn type="integer" id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.2">0</cn><apply id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3"><root id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3a.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3"></root><ci id="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3.2.cmml" xref="S4.SS3.SSS4.p3.2.m2.1.1.1.1.3.2">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.2.m2.1c">[0:\sqrt{r}]</annotation></semantics></math>,<math id="S4.SS3.SSS4.p3.3.m3.1" class="ltx_Math" alttext="[\sqrt{r}:\sqrt{2r}]" display="inline"><semantics id="S4.SS3.SSS4.p3.3.m3.1a"><mrow id="S4.SS3.SSS4.p3.3.m3.1.1.1" xref="S4.SS3.SSS4.p3.3.m3.1.1.2.cmml"><mo stretchy="false" id="S4.SS3.SSS4.p3.3.m3.1.1.1.2" xref="S4.SS3.SSS4.p3.3.m3.1.1.2.1.cmml">[</mo><mrow id="S4.SS3.SSS4.p3.3.m3.1.1.1.1" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.cmml"><msqrt id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2.cmml"><mi id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2.2" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2.2.cmml">r</mi></msqrt><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.1" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.1.cmml">:</mo><msqrt id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.cmml"><mrow id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.cmml"><mn id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.2" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.1" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.1.cmml">​</mo><mi id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.3" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.3.cmml">r</mi></mrow></msqrt></mrow><mo stretchy="false" id="S4.SS3.SSS4.p3.3.m3.1.1.1.3" xref="S4.SS3.SSS4.p3.3.m3.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.3.m3.1b"><apply id="S4.SS3.SSS4.p3.3.m3.1.1.2.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1"><csymbol cd="latexml" id="S4.SS3.SSS4.p3.3.m3.1.1.2.1.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.2">delimited-[]</csymbol><apply id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1"><ci id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.1">:</ci><apply id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2"><root id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2a.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2"></root><ci id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2.2.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.2.2">𝑟</ci></apply><apply id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3"><root id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3a.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3"></root><apply id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2"><times id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.1.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.1"></times><cn type="integer" id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.2.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.2">2</cn><ci id="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.3.cmml" xref="S4.SS3.SSS4.p3.3.m3.1.1.1.1.3.2.3">𝑟</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.3.m3.1c">[\sqrt{r}:\sqrt{2r}]</annotation></semantics></math>,<math id="S4.SS3.SSS4.p3.4.m4.1" class="ltx_Math" alttext="\dots" display="inline"><semantics id="S4.SS3.SSS4.p3.4.m4.1a"><mi mathvariant="normal" id="S4.SS3.SSS4.p3.4.m4.1.1" xref="S4.SS3.SSS4.p3.4.m4.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.4.m4.1b"><ci id="S4.SS3.SSS4.p3.4.m4.1.1.cmml" xref="S4.SS3.SSS4.p3.4.m4.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.4.m4.1c">\dots</annotation></semantics></math>,<math id="S4.SS3.SSS4.p3.5.m5.3" class="ltx_Math" alttext="[\sqrt{(n-2)r}:\sqrt{(n-1)r}]" display="inline"><semantics id="S4.SS3.SSS4.p3.5.m5.3a"><mrow id="S4.SS3.SSS4.p3.5.m5.3.3.1" xref="S4.SS3.SSS4.p3.5.m5.3.3.2.cmml"><mo stretchy="false" id="S4.SS3.SSS4.p3.5.m5.3.3.1.2" xref="S4.SS3.SSS4.p3.5.m5.3.3.2.1.cmml">[</mo><mrow id="S4.SS3.SSS4.p3.5.m5.3.3.1.1" xref="S4.SS3.SSS4.p3.5.m5.3.3.1.1.cmml"><msqrt id="S4.SS3.SSS4.p3.5.m5.1.1" xref="S4.SS3.SSS4.p3.5.m5.1.1.cmml"><mrow id="S4.SS3.SSS4.p3.5.m5.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.cmml"><mrow id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.2" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.cmml"><mi id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.2" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.2.cmml">n</mi><mo id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.3" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.3" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.SS3.SSS4.p3.5.m5.1.1.1.2" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.2.cmml">​</mo><mi id="S4.SS3.SSS4.p3.5.m5.1.1.1.3" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.3.cmml">r</mi></mrow></msqrt><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.SSS4.p3.5.m5.3.3.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.3.3.1.1.1.cmml">:</mo><msqrt id="S4.SS3.SSS4.p3.5.m5.2.2" xref="S4.SS3.SSS4.p3.5.m5.2.2.cmml"><mrow id="S4.SS3.SSS4.p3.5.m5.2.2.1" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.cmml"><mrow id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.2" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.cmml"><mi id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.2" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.2.cmml">n</mi><mo id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.1" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.1.cmml">−</mo><mn id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.3" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.3" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.SS3.SSS4.p3.5.m5.2.2.1.2" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.2.cmml">​</mo><mi id="S4.SS3.SSS4.p3.5.m5.2.2.1.3" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.3.cmml">r</mi></mrow></msqrt></mrow><mo stretchy="false" id="S4.SS3.SSS4.p3.5.m5.3.3.1.3" xref="S4.SS3.SSS4.p3.5.m5.3.3.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.5.m5.3b"><apply id="S4.SS3.SSS4.p3.5.m5.3.3.2.cmml" xref="S4.SS3.SSS4.p3.5.m5.3.3.1"><csymbol cd="latexml" id="S4.SS3.SSS4.p3.5.m5.3.3.2.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.3.3.1.2">delimited-[]</csymbol><apply id="S4.SS3.SSS4.p3.5.m5.3.3.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.3.3.1.1"><ci id="S4.SS3.SSS4.p3.5.m5.3.3.1.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.3.3.1.1.1">:</ci><apply id="S4.SS3.SSS4.p3.5.m5.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1"><root id="S4.SS3.SSS4.p3.5.m5.1.1a.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1"></root><apply id="S4.SS3.SSS4.p3.5.m5.1.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1.1"><times id="S4.SS3.SSS4.p3.5.m5.1.1.1.2.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.2"></times><apply id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1"><minus id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.1"></minus><ci id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.1.1.1.3">2</cn></apply><ci id="S4.SS3.SSS4.p3.5.m5.1.1.1.3.cmml" xref="S4.SS3.SSS4.p3.5.m5.1.1.1.3">𝑟</ci></apply></apply><apply id="S4.SS3.SSS4.p3.5.m5.2.2.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2"><root id="S4.SS3.SSS4.p3.5.m5.2.2a.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2"></root><apply id="S4.SS3.SSS4.p3.5.m5.2.2.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2.1"><times id="S4.SS3.SSS4.p3.5.m5.2.2.1.2.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.2"></times><apply id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1"><minus id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.1"></minus><ci id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.2">𝑛</ci><cn type="integer" id="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.1.1.1.3">1</cn></apply><ci id="S4.SS3.SSS4.p3.5.m5.2.2.1.3.cmml" xref="S4.SS3.SSS4.p3.5.m5.2.2.1.3">𝑟</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.5.m5.3c">[\sqrt{(n-2)r}:\sqrt{(n-1)r}]</annotation></semantics></math> and <math id="S4.SS3.SSS4.p3.6.m6.2" class="ltx_Math" alttext="[\sqrt{(n-1)r}:+\infty]" display="inline"><semantics id="S4.SS3.SSS4.p3.6.m6.2a"><mrow id="S4.SS3.SSS4.p3.6.m6.2.2.1" xref="S4.SS3.SSS4.p3.6.m6.2.2.2.cmml"><mo stretchy="false" id="S4.SS3.SSS4.p3.6.m6.2.2.1.2" xref="S4.SS3.SSS4.p3.6.m6.2.2.2.1.cmml">[</mo><mrow id="S4.SS3.SSS4.p3.6.m6.2.2.1.1" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.cmml"><msqrt id="S4.SS3.SSS4.p3.6.m6.1.1" xref="S4.SS3.SSS4.p3.6.m6.1.1.cmml"><mrow id="S4.SS3.SSS4.p3.6.m6.1.1.1" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.cmml"><mrow id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.2" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.cmml"><mi id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.2" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.2.cmml">n</mi><mo id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.1" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.3" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.3" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.SS3.SSS4.p3.6.m6.1.1.1.2" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.2.cmml">​</mo><mi id="S4.SS3.SSS4.p3.6.m6.1.1.1.3" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.3.cmml">r</mi></mrow></msqrt><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.1" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.1.cmml">:</mo><mrow id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.cmml"><mo id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2a" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.cmml">+</mo><mi mathvariant="normal" id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.2" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.2.cmml">∞</mi></mrow></mrow><mo stretchy="false" id="S4.SS3.SSS4.p3.6.m6.2.2.1.3" xref="S4.SS3.SSS4.p3.6.m6.2.2.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.6.m6.2b"><apply id="S4.SS3.SSS4.p3.6.m6.2.2.2.cmml" xref="S4.SS3.SSS4.p3.6.m6.2.2.1"><csymbol cd="latexml" id="S4.SS3.SSS4.p3.6.m6.2.2.2.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.2">delimited-[]</csymbol><apply id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1"><ci id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.1">:</ci><apply id="S4.SS3.SSS4.p3.6.m6.1.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1"><root id="S4.SS3.SSS4.p3.6.m6.1.1a.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1"></root><apply id="S4.SS3.SSS4.p3.6.m6.1.1.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1.1"><times id="S4.SS3.SSS4.p3.6.m6.1.1.1.2.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.2"></times><apply id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1"><minus id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.1"></minus><ci id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.1.1.1.3">1</cn></apply><ci id="S4.SS3.SSS4.p3.6.m6.1.1.1.3.cmml" xref="S4.SS3.SSS4.p3.6.m6.1.1.1.3">𝑟</ci></apply></apply><apply id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.cmml" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2"><plus id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.1.cmml" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2"></plus><infinity id="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.2.cmml" xref="S4.SS3.SSS4.p3.6.m6.2.2.1.1.2.2"></infinity></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.6.m6.2c">[\sqrt{(n-1)r}:+\infty]</annotation></semantics></math> with a constant <math id="S4.SS3.SSS4.p3.7.m7.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.SS3.SSS4.p3.7.m7.1a"><mi id="S4.SS3.SSS4.p3.7.m7.1.1" xref="S4.SS3.SSS4.p3.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.7.m7.1b"><ci id="S4.SS3.SSS4.p3.7.m7.1.1.cmml" xref="S4.SS3.SSS4.p3.7.m7.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.7.m7.1c">r</annotation></semantics></math> just as <a href="#S4.F7" title="Figure 7 ‣ 4.3.4. Samples for Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 7</span></a> (in this work, we define the value of <math id="S4.SS3.SSS4.p3.8.m8.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS3.SSS4.p3.8.m8.1a"><mi id="S4.SS3.SSS4.p3.8.m8.1.1" xref="S4.SS3.SSS4.p3.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.8.m8.1b"><ci id="S4.SS3.SSS4.p3.8.m8.1.1.cmml" xref="S4.SS3.SSS4.p3.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.8.m8.1c">n</annotation></semantics></math> as <math id="S4.SS3.SSS4.p3.9.m9.1" class="ltx_Math" alttext="11" display="inline"><semantics id="S4.SS3.SSS4.p3.9.m9.1a"><mn id="S4.SS3.SSS4.p3.9.m9.1.1" xref="S4.SS3.SSS4.p3.9.m9.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.9.m9.1b"><cn type="integer" id="S4.SS3.SSS4.p3.9.m9.1.1.cmml" xref="S4.SS3.SSS4.p3.9.m9.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.9.m9.1c">11</annotation></semantics></math>, <math id="S4.SS3.SSS4.p3.10.m10.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.SS3.SSS4.p3.10.m10.1a"><mi id="S4.SS3.SSS4.p3.10.m10.1.1" xref="S4.SS3.SSS4.p3.10.m10.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.10.m10.1b"><ci id="S4.SS3.SSS4.p3.10.m10.1.1.cmml" xref="S4.SS3.SSS4.p3.10.m10.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.10.m10.1c">r</annotation></semantics></math> as <math id="S4.SS3.SSS4.p3.11.m11.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS3.SSS4.p3.11.m11.1a"><mn id="S4.SS3.SSS4.p3.11.m11.1.1" xref="S4.SS3.SSS4.p3.11.m11.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p3.11.m11.1b"><cn type="float" id="S4.SS3.SSS4.p3.11.m11.1.1.cmml" xref="S4.SS3.SSS4.p3.11.m11.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p3.11.m11.1c">0.5</annotation></semantics></math> after several experiments). This sampling scheme ensures that each individual region within the cluster occupies the same area. We sample the data according to a polar coordinates design because of the clustering mechanism of <span id="S4.SS3.SSS4.p3.11.2" class="ltx_text ltx_font_italic">KMeans</span>, which clusters the samples according to the distance between the samples and the centroids. After completing the sampling of each cluster, we merge the sampled instances to the data pool.</p>
</div>
<div id="S4.SS3.SSS4.p4" class="ltx_para">
<p id="S4.SS3.SSS4.p4.9" class="ltx_p"><span id="S4.SS3.SSS4.p4.9.1" class="ltx_text ltx_font_bold">Data Sampling Evaluation.</span> We utilize <span id="S4.SS3.SSS4.p4.9.2" class="ltx_text ltx_font_italic">target label balance</span> and <span id="S4.SS3.SSS4.p4.9.3" class="ltx_text ltx_font_italic">feature diversity</span> as core metrics to help evaluate the combined data samples after interactive sampling. Regarding the target label of the training data, we find that the performance of the model deteriorates significantly as the imbalance increases <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2021d</a>)</cite>. When the classification distributions of the datasets are almost identical, the reduction in content diversity will lead to a considerable loss of accuracy. Thus, larger homogeneity and content diversity are likely to lead to better model performance. These two metrics are defined as follows. (1) <span id="S4.SS3.SSS4.p4.9.4" class="ltx_text ltx_font_italic">Statistical Homogeneity.</span> Let <math id="S4.SS3.SSS4.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{Y}" display="inline"><semantics id="S4.SS3.SSS4.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.1.m1.1.1" xref="S4.SS3.SSS4.p4.1.m1.1.1.cmml">𝒴</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.1.m1.1b"><ci id="S4.SS3.SSS4.p4.1.m1.1.1.cmml" xref="S4.SS3.SSS4.p4.1.m1.1.1">𝒴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.1.m1.1c">\mathcal{Y}</annotation></semantics></math> is the set of target categories. Cluster <math id="S4.SS3.SSS4.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{C}_{k}" display="inline"><semantics id="S4.SS3.SSS4.p4.2.m2.1a"><msub id="S4.SS3.SSS4.p4.2.m2.1.1" xref="S4.SS3.SSS4.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.2.m2.1.1.2" xref="S4.SS3.SSS4.p4.2.m2.1.1.2.cmml">𝒞</mi><mi id="S4.SS3.SSS4.p4.2.m2.1.1.3" xref="S4.SS3.SSS4.p4.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.2.m2.1b"><apply id="S4.SS3.SSS4.p4.2.m2.1.1.cmml" xref="S4.SS3.SSS4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.2.m2.1.1.1.cmml" xref="S4.SS3.SSS4.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.2.m2.1.1.2.cmml" xref="S4.SS3.SSS4.p4.2.m2.1.1.2">𝒞</ci><ci id="S4.SS3.SSS4.p4.2.m2.1.1.3.cmml" xref="S4.SS3.SSS4.p4.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.2.m2.1c">\mathcal{C}_{k}</annotation></semantics></math> has a dataset <math id="S4.SS3.SSS4.p4.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{k}=\left\{\left(x_{k},y_{k}\right)\right\}" display="inline"><semantics id="S4.SS3.SSS4.p4.3.m3.1a"><mrow id="S4.SS3.SSS4.p4.3.m3.1.1" xref="S4.SS3.SSS4.p4.3.m3.1.1.cmml"><msub id="S4.SS3.SSS4.p4.3.m3.1.1.3" xref="S4.SS3.SSS4.p4.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.3.m3.1.1.3.2" xref="S4.SS3.SSS4.p4.3.m3.1.1.3.2.cmml">𝒟</mi><mi id="S4.SS3.SSS4.p4.3.m3.1.1.3.3" xref="S4.SS3.SSS4.p4.3.m3.1.1.3.3.cmml">k</mi></msub><mo id="S4.SS3.SSS4.p4.3.m3.1.1.2" xref="S4.SS3.SSS4.p4.3.m3.1.1.2.cmml">=</mo><mrow id="S4.SS3.SSS4.p4.3.m3.1.1.1.1" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.2.cmml"><mo id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.2" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.2.cmml">{</mo><mrow id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.3.cmml"><mo id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.3" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.3.cmml">(</mo><msub id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.cmml"><mi id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.2" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.3" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.4" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.3.cmml">,</mo><msub id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.cmml"><mi id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.2" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.3" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.3.cmml">k</mi></msub><mo id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.5" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.3" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.3.m3.1b"><apply id="S4.SS3.SSS4.p4.3.m3.1.1.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1"><eq id="S4.SS3.SSS4.p4.3.m3.1.1.2.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.2"></eq><apply id="S4.SS3.SSS4.p4.3.m3.1.1.3.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.3.m3.1.1.3.1.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.3">subscript</csymbol><ci id="S4.SS3.SSS4.p4.3.m3.1.1.3.2.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.3.2">𝒟</ci><ci id="S4.SS3.SSS4.p4.3.m3.1.1.3.3.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.3.3">𝑘</ci></apply><set id="S4.SS3.SSS4.p4.3.m3.1.1.1.2.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1"><interval closure="open" id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2"><apply id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.1.1.3">𝑘</ci></apply><apply id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.1.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.2.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.3.cmml" xref="S4.SS3.SSS4.p4.3.m3.1.1.1.1.1.2.2.3">𝑘</ci></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.3.m3.1c">\mathcal{D}_{k}=\left\{\left(x_{k},y_{k}\right)\right\}</annotation></semantics></math>, where each data <math id="S4.SS3.SSS4.p4.4.m4.1" class="ltx_Math" alttext="x_{k}" display="inline"><semantics id="S4.SS3.SSS4.p4.4.m4.1a"><msub id="S4.SS3.SSS4.p4.4.m4.1.1" xref="S4.SS3.SSS4.p4.4.m4.1.1.cmml"><mi id="S4.SS3.SSS4.p4.4.m4.1.1.2" xref="S4.SS3.SSS4.p4.4.m4.1.1.2.cmml">x</mi><mi id="S4.SS3.SSS4.p4.4.m4.1.1.3" xref="S4.SS3.SSS4.p4.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.4.m4.1b"><apply id="S4.SS3.SSS4.p4.4.m4.1.1.cmml" xref="S4.SS3.SSS4.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.4.m4.1.1.1.cmml" xref="S4.SS3.SSS4.p4.4.m4.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.4.m4.1.1.2.cmml" xref="S4.SS3.SSS4.p4.4.m4.1.1.2">𝑥</ci><ci id="S4.SS3.SSS4.p4.4.m4.1.1.3.cmml" xref="S4.SS3.SSS4.p4.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.4.m4.1c">x_{k}</annotation></semantics></math> has a label <math id="S4.SS3.SSS4.p4.5.m5.2" class="ltx_Math" alttext="y_{k}.\mathcal{D}_{k}" display="inline"><semantics id="S4.SS3.SSS4.p4.5.m5.2a"><mrow id="S4.SS3.SSS4.p4.5.m5.2.2.2" xref="S4.SS3.SSS4.p4.5.m5.2.2.3.cmml"><msub id="S4.SS3.SSS4.p4.5.m5.1.1.1.1" xref="S4.SS3.SSS4.p4.5.m5.1.1.1.1.cmml"><mi id="S4.SS3.SSS4.p4.5.m5.1.1.1.1.2" xref="S4.SS3.SSS4.p4.5.m5.1.1.1.1.2.cmml">y</mi><mi id="S4.SS3.SSS4.p4.5.m5.1.1.1.1.3" xref="S4.SS3.SSS4.p4.5.m5.1.1.1.1.3.cmml">k</mi></msub><mo lspace="0em" rspace="0.167em" id="S4.SS3.SSS4.p4.5.m5.2.2.2.3" xref="S4.SS3.SSS4.p4.5.m5.2.2.3a.cmml">.</mo><msub id="S4.SS3.SSS4.p4.5.m5.2.2.2.2" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.5.m5.2.2.2.2.2" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.2.2.cmml">𝒟</mi><mi id="S4.SS3.SSS4.p4.5.m5.2.2.2.2.3" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.2.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.5.m5.2b"><apply id="S4.SS3.SSS4.p4.5.m5.2.2.3.cmml" xref="S4.SS3.SSS4.p4.5.m5.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.5.m5.2.2.3a.cmml" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS3.SSS4.p4.5.m5.1.1.1.1.cmml" xref="S4.SS3.SSS4.p4.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.5.m5.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p4.5.m5.1.1.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.5.m5.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p4.5.m5.1.1.1.1.2">𝑦</ci><ci id="S4.SS3.SSS4.p4.5.m5.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p4.5.m5.1.1.1.1.3">𝑘</ci></apply><apply id="S4.SS3.SSS4.p4.5.m5.2.2.2.2.cmml" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.5.m5.2.2.2.2.1.cmml" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.2">subscript</csymbol><ci id="S4.SS3.SSS4.p4.5.m5.2.2.2.2.2.cmml" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.2.2">𝒟</ci><ci id="S4.SS3.SSS4.p4.5.m5.2.2.2.2.3.cmml" xref="S4.SS3.SSS4.p4.5.m5.2.2.2.2.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.5.m5.2c">y_{k}.\mathcal{D}_{k}</annotation></semantics></math> follows a categorical distribution <math id="S4.SS3.SSS4.p4.6.m6.1" class="ltx_Math" alttext="q_{k}" display="inline"><semantics id="S4.SS3.SSS4.p4.6.m6.1a"><msub id="S4.SS3.SSS4.p4.6.m6.1.1" xref="S4.SS3.SSS4.p4.6.m6.1.1.cmml"><mi id="S4.SS3.SSS4.p4.6.m6.1.1.2" xref="S4.SS3.SSS4.p4.6.m6.1.1.2.cmml">q</mi><mi id="S4.SS3.SSS4.p4.6.m6.1.1.3" xref="S4.SS3.SSS4.p4.6.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.6.m6.1b"><apply id="S4.SS3.SSS4.p4.6.m6.1.1.cmml" xref="S4.SS3.SSS4.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.6.m6.1.1.1.cmml" xref="S4.SS3.SSS4.p4.6.m6.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.6.m6.1.1.2.cmml" xref="S4.SS3.SSS4.p4.6.m6.1.1.2">𝑞</ci><ci id="S4.SS3.SSS4.p4.6.m6.1.1.3.cmml" xref="S4.SS3.SSS4.p4.6.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.6.m6.1c">q_{k}</annotation></semantics></math>. The uniform categorical distribution over <math id="S4.SS3.SSS4.p4.7.m7.1" class="ltx_Math" alttext="\mathcal{Y}" display="inline"><semantics id="S4.SS3.SSS4.p4.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.7.m7.1.1" xref="S4.SS3.SSS4.p4.7.m7.1.1.cmml">𝒴</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.7.m7.1b"><ci id="S4.SS3.SSS4.p4.7.m7.1.1.cmml" xref="S4.SS3.SSS4.p4.7.m7.1.1">𝒴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.7.m7.1c">\mathcal{Y}</annotation></semantics></math> is <math id="S4.SS3.SSS4.p4.8.m8.1" class="ltx_Math" alttext="q_{u}" display="inline"><semantics id="S4.SS3.SSS4.p4.8.m8.1a"><msub id="S4.SS3.SSS4.p4.8.m8.1.1" xref="S4.SS3.SSS4.p4.8.m8.1.1.cmml"><mi id="S4.SS3.SSS4.p4.8.m8.1.1.2" xref="S4.SS3.SSS4.p4.8.m8.1.1.2.cmml">q</mi><mi id="S4.SS3.SSS4.p4.8.m8.1.1.3" xref="S4.SS3.SSS4.p4.8.m8.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.8.m8.1b"><apply id="S4.SS3.SSS4.p4.8.m8.1.1.cmml" xref="S4.SS3.SSS4.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.8.m8.1.1.1.cmml" xref="S4.SS3.SSS4.p4.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.8.m8.1.1.2.cmml" xref="S4.SS3.SSS4.p4.8.m8.1.1.2">𝑞</ci><ci id="S4.SS3.SSS4.p4.8.m8.1.1.3.cmml" xref="S4.SS3.SSS4.p4.8.m8.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.8.m8.1c">q_{u}</annotation></semantics></math>. The statistical homogeneity of <math id="S4.SS3.SSS4.p4.9.m9.1" class="ltx_Math" alttext="\mathcal{D}_{k}" display="inline"><semantics id="S4.SS3.SSS4.p4.9.m9.1a"><msub id="S4.SS3.SSS4.p4.9.m9.1.1" xref="S4.SS3.SSS4.p4.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.9.m9.1.1.2" xref="S4.SS3.SSS4.p4.9.m9.1.1.2.cmml">𝒟</mi><mi id="S4.SS3.SSS4.p4.9.m9.1.1.3" xref="S4.SS3.SSS4.p4.9.m9.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.9.m9.1b"><apply id="S4.SS3.SSS4.p4.9.m9.1.1.cmml" xref="S4.SS3.SSS4.p4.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.9.m9.1.1.1.cmml" xref="S4.SS3.SSS4.p4.9.m9.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.9.m9.1.1.2.cmml" xref="S4.SS3.SSS4.p4.9.m9.1.1.2">𝒟</ci><ci id="S4.SS3.SSS4.p4.9.m9.1.1.3.cmml" xref="S4.SS3.SSS4.p4.9.m9.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.9.m9.1c">\mathcal{D}_{k}</annotation></semantics></math> is defined as  <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2018a</a>)</cite>,</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.2" class="ltx_Math" alttext="\mu_{k}=2-\sqrt{\sum_{y\in\mathcal{Y}}\left|q_{k}\left(y_{k}=y\right)-q_{u}\left(y_{u}=y\right)\right|^{2}}," display="block"><semantics id="S4.E1.m1.2a"><mrow id="S4.E1.m1.2.2.1" xref="S4.E1.m1.2.2.1.1.cmml"><mrow id="S4.E1.m1.2.2.1.1" xref="S4.E1.m1.2.2.1.1.cmml"><msub id="S4.E1.m1.2.2.1.1.2" xref="S4.E1.m1.2.2.1.1.2.cmml"><mi id="S4.E1.m1.2.2.1.1.2.2" xref="S4.E1.m1.2.2.1.1.2.2.cmml">μ</mi><mi id="S4.E1.m1.2.2.1.1.2.3" xref="S4.E1.m1.2.2.1.1.2.3.cmml">k</mi></msub><mo id="S4.E1.m1.2.2.1.1.1" xref="S4.E1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S4.E1.m1.2.2.1.1.3" xref="S4.E1.m1.2.2.1.1.3.cmml"><mn id="S4.E1.m1.2.2.1.1.3.2" xref="S4.E1.m1.2.2.1.1.3.2.cmml">2</mn><mo id="S4.E1.m1.2.2.1.1.3.1" xref="S4.E1.m1.2.2.1.1.3.1.cmml">−</mo><msqrt id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.cmml"><munder id="S4.E1.m1.1.1.1.2" xref="S4.E1.m1.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E1.m1.1.1.1.2.2" xref="S4.E1.m1.1.1.1.2.2.cmml">∑</mo><mrow id="S4.E1.m1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.2.3.cmml"><mi id="S4.E1.m1.1.1.1.2.3.2" xref="S4.E1.m1.1.1.1.2.3.2.cmml">y</mi><mo id="S4.E1.m1.1.1.1.2.3.1" xref="S4.E1.m1.1.1.1.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.2.3.3" xref="S4.E1.m1.1.1.1.2.3.3.cmml">𝒴</mi></mrow></munder><msup id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.2.cmml"><mo lspace="0em" id="S4.E1.m1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E1.m1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml">q</mi><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">k</mi></msub><mo id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">=</mo><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.cmml"><msub id="S4.E1.m1.1.1.1.1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.2.3.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.3.2.cmml">q</mi><mi id="S4.E1.m1.1.1.1.1.1.1.1.2.3.3" xref="S4.E1.m1.1.1.1.1.1.1.1.2.3.3.cmml">u</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1.1.2.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.2.cmml">​</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.cmml"><mo id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.cmml"><msub id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.2.cmml">y</mi><mi id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.3.cmml">u</mi></msub><mo id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.1.cmml">=</mo><mi id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.3.cmml">y</mi></mrow><mo id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E1.m1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mn id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.3.cmml">2</mn></msup></mrow></msqrt></mrow></mrow><mo id="S4.E1.m1.2.2.1.2" xref="S4.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.2b"><apply id="S4.E1.m1.2.2.1.1.cmml" xref="S4.E1.m1.2.2.1"><eq id="S4.E1.m1.2.2.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1"></eq><apply id="S4.E1.m1.2.2.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.2.1.cmml" xref="S4.E1.m1.2.2.1.1.2">subscript</csymbol><ci id="S4.E1.m1.2.2.1.1.2.2.cmml" xref="S4.E1.m1.2.2.1.1.2.2">𝜇</ci><ci id="S4.E1.m1.2.2.1.1.2.3.cmml" xref="S4.E1.m1.2.2.1.1.2.3">𝑘</ci></apply><apply id="S4.E1.m1.2.2.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.3"><minus id="S4.E1.m1.2.2.1.1.3.1.cmml" xref="S4.E1.m1.2.2.1.1.3.1"></minus><cn type="integer" id="S4.E1.m1.2.2.1.1.3.2.cmml" xref="S4.E1.m1.2.2.1.1.3.2">2</cn><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"><root id="S4.E1.m1.1.1a.cmml" xref="S4.E1.m1.1.1"></root><apply id="S4.E1.m1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"><apply id="S4.E1.m1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.2">subscript</csymbol><sum id="S4.E1.m1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.2.2"></sum><apply id="S4.E1.m1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.2.3"><in id="S4.E1.m1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.1.1.1.2.3.1"></in><ci id="S4.E1.m1.1.1.1.2.3.2.cmml" xref="S4.E1.m1.1.1.1.2.3.2">𝑦</ci><ci id="S4.E1.m1.1.1.1.2.3.3.cmml" xref="S4.E1.m1.1.1.1.2.3.3">𝒴</ci></apply></apply><apply id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1">superscript</csymbol><apply id="S4.E1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1"><abs id="S4.E1.m1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2"></abs><apply id="S4.E1.m1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1"><minus id="S4.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.3"></minus><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1"><times id="S4.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2"></times><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.2">𝑞</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.3">𝑘</ci></apply><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1"><eq id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1"></eq><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑘</ci></apply><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝑦</ci></apply></apply><apply id="S4.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2"><times id="S4.E1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.2"></times><apply id="S4.E1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.3.2">𝑞</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.3.3">𝑢</ci></apply><apply id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1"><eq id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.1"></eq><apply id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.2">𝑦</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.2.3">𝑢</ci></apply><ci id="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.1.1.3">𝑦</ci></apply></apply></apply></apply><cn type="integer" id="S4.E1.m1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.2c">\mu_{k}=2-\sqrt{\sum_{y\in\mathcal{Y}}\left|q_{k}\left(y_{k}=y\right)-q_{u}\left(y_{u}=y\right)\right|^{2}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS3.SSS4.p4.20" class="ltx_p">measuring the similarity between distributions <math id="S4.SS3.SSS4.p4.10.m1.1" class="ltx_Math" alttext="q_{k}" display="inline"><semantics id="S4.SS3.SSS4.p4.10.m1.1a"><msub id="S4.SS3.SSS4.p4.10.m1.1.1" xref="S4.SS3.SSS4.p4.10.m1.1.1.cmml"><mi id="S4.SS3.SSS4.p4.10.m1.1.1.2" xref="S4.SS3.SSS4.p4.10.m1.1.1.2.cmml">q</mi><mi id="S4.SS3.SSS4.p4.10.m1.1.1.3" xref="S4.SS3.SSS4.p4.10.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.10.m1.1b"><apply id="S4.SS3.SSS4.p4.10.m1.1.1.cmml" xref="S4.SS3.SSS4.p4.10.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.10.m1.1.1.1.cmml" xref="S4.SS3.SSS4.p4.10.m1.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.10.m1.1.1.2.cmml" xref="S4.SS3.SSS4.p4.10.m1.1.1.2">𝑞</ci><ci id="S4.SS3.SSS4.p4.10.m1.1.1.3.cmml" xref="S4.SS3.SSS4.p4.10.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.10.m1.1c">q_{k}</annotation></semantics></math> and <math id="S4.SS3.SSS4.p4.11.m2.1" class="ltx_Math" alttext="q_{u}" display="inline"><semantics id="S4.SS3.SSS4.p4.11.m2.1a"><msub id="S4.SS3.SSS4.p4.11.m2.1.1" xref="S4.SS3.SSS4.p4.11.m2.1.1.cmml"><mi id="S4.SS3.SSS4.p4.11.m2.1.1.2" xref="S4.SS3.SSS4.p4.11.m2.1.1.2.cmml">q</mi><mi id="S4.SS3.SSS4.p4.11.m2.1.1.3" xref="S4.SS3.SSS4.p4.11.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.11.m2.1b"><apply id="S4.SS3.SSS4.p4.11.m2.1.1.cmml" xref="S4.SS3.SSS4.p4.11.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.11.m2.1.1.1.cmml" xref="S4.SS3.SSS4.p4.11.m2.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.11.m2.1.1.2.cmml" xref="S4.SS3.SSS4.p4.11.m2.1.1.2">𝑞</ci><ci id="S4.SS3.SSS4.p4.11.m2.1.1.3.cmml" xref="S4.SS3.SSS4.p4.11.m2.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.11.m2.1c">q_{u}</annotation></semantics></math> over <math id="S4.SS3.SSS4.p4.12.m3.1" class="ltx_Math" alttext="\mathcal{Y}" display="inline"><semantics id="S4.SS3.SSS4.p4.12.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.12.m3.1.1" xref="S4.SS3.SSS4.p4.12.m3.1.1.cmml">𝒴</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.12.m3.1b"><ci id="S4.SS3.SSS4.p4.12.m3.1.1.cmml" xref="S4.SS3.SSS4.p4.12.m3.1.1">𝒴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.12.m3.1c">\mathcal{Y}</annotation></semantics></math>. (2) <span id="S4.SS3.SSS4.p4.20.1" class="ltx_text ltx_font_italic">Content Diversity.</span> Given a dataset <math id="S4.SS3.SSS4.p4.13.m4.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS3.SSS4.p4.13.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.13.m4.1.1" xref="S4.SS3.SSS4.p4.13.m4.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.13.m4.1b"><ci id="S4.SS3.SSS4.p4.13.m4.1.1.cmml" xref="S4.SS3.SSS4.p4.13.m4.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.13.m4.1c">\mathcal{D}</annotation></semantics></math> having <math id="S4.SS3.SSS4.p4.14.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS3.SSS4.p4.14.m5.1a"><mi id="S4.SS3.SSS4.p4.14.m5.1.1" xref="S4.SS3.SSS4.p4.14.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.14.m5.1b"><ci id="S4.SS3.SSS4.p4.14.m5.1.1.cmml" xref="S4.SS3.SSS4.p4.14.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.14.m5.1c">M</annotation></semantics></math> samples or <math id="S4.SS3.SSS4.p4.15.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS3.SSS4.p4.15.m6.1a"><mi id="S4.SS3.SSS4.p4.15.m6.1.1" xref="S4.SS3.SSS4.p4.15.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.15.m6.1b"><ci id="S4.SS3.SSS4.p4.15.m6.1.1.cmml" xref="S4.SS3.SSS4.p4.15.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.15.m6.1c">M</annotation></semantics></math> sub-collections of samples and let <math id="S4.SS3.SSS4.p4.16.m7.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="S4.SS3.SSS4.p4.16.m7.1a"><msub id="S4.SS3.SSS4.p4.16.m7.1.1" xref="S4.SS3.SSS4.p4.16.m7.1.1.cmml"><mi id="S4.SS3.SSS4.p4.16.m7.1.1.2" xref="S4.SS3.SSS4.p4.16.m7.1.1.2.cmml">v</mi><mi id="S4.SS3.SSS4.p4.16.m7.1.1.3" xref="S4.SS3.SSS4.p4.16.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.16.m7.1b"><apply id="S4.SS3.SSS4.p4.16.m7.1.1.cmml" xref="S4.SS3.SSS4.p4.16.m7.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.16.m7.1.1.1.cmml" xref="S4.SS3.SSS4.p4.16.m7.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.16.m7.1.1.2.cmml" xref="S4.SS3.SSS4.p4.16.m7.1.1.2">𝑣</ci><ci id="S4.SS3.SSS4.p4.16.m7.1.1.3.cmml" xref="S4.SS3.SSS4.p4.16.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.16.m7.1c">v_{i}</annotation></semantics></math> be the flattened features vector of the <math id="S4.SS3.SSS4.p4.17.m8.1" class="ltx_Math" alttext="i^{th}" display="inline"><semantics id="S4.SS3.SSS4.p4.17.m8.1a"><msup id="S4.SS3.SSS4.p4.17.m8.1.1" xref="S4.SS3.SSS4.p4.17.m8.1.1.cmml"><mi id="S4.SS3.SSS4.p4.17.m8.1.1.2" xref="S4.SS3.SSS4.p4.17.m8.1.1.2.cmml">i</mi><mrow id="S4.SS3.SSS4.p4.17.m8.1.1.3" xref="S4.SS3.SSS4.p4.17.m8.1.1.3.cmml"><mi id="S4.SS3.SSS4.p4.17.m8.1.1.3.2" xref="S4.SS3.SSS4.p4.17.m8.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS4.p4.17.m8.1.1.3.1" xref="S4.SS3.SSS4.p4.17.m8.1.1.3.1.cmml">​</mo><mi id="S4.SS3.SSS4.p4.17.m8.1.1.3.3" xref="S4.SS3.SSS4.p4.17.m8.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.17.m8.1b"><apply id="S4.SS3.SSS4.p4.17.m8.1.1.cmml" xref="S4.SS3.SSS4.p4.17.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.17.m8.1.1.1.cmml" xref="S4.SS3.SSS4.p4.17.m8.1.1">superscript</csymbol><ci id="S4.SS3.SSS4.p4.17.m8.1.1.2.cmml" xref="S4.SS3.SSS4.p4.17.m8.1.1.2">𝑖</ci><apply id="S4.SS3.SSS4.p4.17.m8.1.1.3.cmml" xref="S4.SS3.SSS4.p4.17.m8.1.1.3"><times id="S4.SS3.SSS4.p4.17.m8.1.1.3.1.cmml" xref="S4.SS3.SSS4.p4.17.m8.1.1.3.1"></times><ci id="S4.SS3.SSS4.p4.17.m8.1.1.3.2.cmml" xref="S4.SS3.SSS4.p4.17.m8.1.1.3.2">𝑡</ci><ci id="S4.SS3.SSS4.p4.17.m8.1.1.3.3.cmml" xref="S4.SS3.SSS4.p4.17.m8.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.17.m8.1c">i^{th}</annotation></semantics></math> sample or <math id="S4.SS3.SSS4.p4.18.m9.1" class="ltx_Math" alttext="i^{th}" display="inline"><semantics id="S4.SS3.SSS4.p4.18.m9.1a"><msup id="S4.SS3.SSS4.p4.18.m9.1.1" xref="S4.SS3.SSS4.p4.18.m9.1.1.cmml"><mi id="S4.SS3.SSS4.p4.18.m9.1.1.2" xref="S4.SS3.SSS4.p4.18.m9.1.1.2.cmml">i</mi><mrow id="S4.SS3.SSS4.p4.18.m9.1.1.3" xref="S4.SS3.SSS4.p4.18.m9.1.1.3.cmml"><mi id="S4.SS3.SSS4.p4.18.m9.1.1.3.2" xref="S4.SS3.SSS4.p4.18.m9.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS4.p4.18.m9.1.1.3.1" xref="S4.SS3.SSS4.p4.18.m9.1.1.3.1.cmml">​</mo><mi id="S4.SS3.SSS4.p4.18.m9.1.1.3.3" xref="S4.SS3.SSS4.p4.18.m9.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.18.m9.1b"><apply id="S4.SS3.SSS4.p4.18.m9.1.1.cmml" xref="S4.SS3.SSS4.p4.18.m9.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.18.m9.1.1.1.cmml" xref="S4.SS3.SSS4.p4.18.m9.1.1">superscript</csymbol><ci id="S4.SS3.SSS4.p4.18.m9.1.1.2.cmml" xref="S4.SS3.SSS4.p4.18.m9.1.1.2">𝑖</ci><apply id="S4.SS3.SSS4.p4.18.m9.1.1.3.cmml" xref="S4.SS3.SSS4.p4.18.m9.1.1.3"><times id="S4.SS3.SSS4.p4.18.m9.1.1.3.1.cmml" xref="S4.SS3.SSS4.p4.18.m9.1.1.3.1"></times><ci id="S4.SS3.SSS4.p4.18.m9.1.1.3.2.cmml" xref="S4.SS3.SSS4.p4.18.m9.1.1.3.2">𝑡</ci><ci id="S4.SS3.SSS4.p4.18.m9.1.1.3.3.cmml" xref="S4.SS3.SSS4.p4.18.m9.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.18.m9.1c">i^{th}</annotation></semantics></math> subcollection of samples, the similarity function of two vectors is <math id="S4.SS3.SSS4.p4.19.m10.2" class="ltx_Math" alttext="S\left(v_{i},v_{j}\right)" display="inline"><semantics id="S4.SS3.SSS4.p4.19.m10.2a"><mrow id="S4.SS3.SSS4.p4.19.m10.2.2" xref="S4.SS3.SSS4.p4.19.m10.2.2.cmml"><mi id="S4.SS3.SSS4.p4.19.m10.2.2.4" xref="S4.SS3.SSS4.p4.19.m10.2.2.4.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS4.p4.19.m10.2.2.3" xref="S4.SS3.SSS4.p4.19.m10.2.2.3.cmml">​</mo><mrow id="S4.SS3.SSS4.p4.19.m10.2.2.2.2" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.3.cmml"><mo id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.3" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.3.cmml">(</mo><msub id="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1" xref="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.cmml"><mi id="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.2" xref="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.2.cmml">v</mi><mi id="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.3" xref="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.4" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.3.cmml">,</mo><msub id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.cmml"><mi id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.2" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.2.cmml">v</mi><mi id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.3" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.5" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.19.m10.2b"><apply id="S4.SS3.SSS4.p4.19.m10.2.2.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2"><times id="S4.SS3.SSS4.p4.19.m10.2.2.3.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2.3"></times><ci id="S4.SS3.SSS4.p4.19.m10.2.2.4.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2.4">𝑆</ci><interval closure="open" id="S4.SS3.SSS4.p4.19.m10.2.2.2.3.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2"><apply id="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1">subscript</csymbol><ci id="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.2">𝑣</ci><ci id="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS4.p4.19.m10.1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.1.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2">subscript</csymbol><ci id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.2.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.2">𝑣</ci><ci id="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.3.cmml" xref="S4.SS3.SSS4.p4.19.m10.2.2.2.2.2.3">𝑗</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.19.m10.2c">S\left(v_{i},v_{j}\right)</annotation></semantics></math>. The content diversity of <math id="S4.SS3.SSS4.p4.20.m11.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS3.SSS4.p4.20.m11.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS4.p4.20.m11.1.1" xref="S4.SS3.SSS4.p4.20.m11.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p4.20.m11.1b"><ci id="S4.SS3.SSS4.p4.20.m11.1.1.cmml" xref="S4.SS3.SSS4.p4.20.m11.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p4.20.m11.1c">\mathcal{D}</annotation></semantics></math> is defined as  <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2015</a>)</cite>,</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.9" class="ltx_Math" alttext="\rho(\mathcal{D})=1-\frac{\sum_{i,j\in[M],i\neq j}2S\left(v_{i},v_{j}\right)}{M(M-1)}" display="block"><semantics id="S4.E2.m1.9a"><mrow id="S4.E2.m1.9.10" xref="S4.E2.m1.9.10.cmml"><mrow id="S4.E2.m1.9.10.2" xref="S4.E2.m1.9.10.2.cmml"><mi id="S4.E2.m1.9.10.2.2" xref="S4.E2.m1.9.10.2.2.cmml">ρ</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.9.10.2.1" xref="S4.E2.m1.9.10.2.1.cmml">​</mo><mrow id="S4.E2.m1.9.10.2.3.2" xref="S4.E2.m1.9.10.2.cmml"><mo stretchy="false" id="S4.E2.m1.9.10.2.3.2.1" xref="S4.E2.m1.9.10.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.9.9" xref="S4.E2.m1.9.9.cmml">𝒟</mi><mo stretchy="false" id="S4.E2.m1.9.10.2.3.2.2" xref="S4.E2.m1.9.10.2.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.9.10.1" xref="S4.E2.m1.9.10.1.cmml">=</mo><mrow id="S4.E2.m1.9.10.3" xref="S4.E2.m1.9.10.3.cmml"><mn id="S4.E2.m1.9.10.3.2" xref="S4.E2.m1.9.10.3.2.cmml">1</mn><mo id="S4.E2.m1.9.10.3.1" xref="S4.E2.m1.9.10.3.1.cmml">−</mo><mfrac id="S4.E2.m1.8.8" xref="S4.E2.m1.8.8.cmml"><mrow id="S4.E2.m1.7.7.7" xref="S4.E2.m1.7.7.7.cmml"><msub id="S4.E2.m1.7.7.7.8" xref="S4.E2.m1.7.7.7.8.cmml"><mo id="S4.E2.m1.7.7.7.8.2" xref="S4.E2.m1.7.7.7.8.2.cmml">∑</mo><mrow id="S4.E2.m1.5.5.5.5.5.5" xref="S4.E2.m1.5.5.5.5.5.6.cmml"><mrow id="S4.E2.m1.4.4.4.4.4.4.1" xref="S4.E2.m1.4.4.4.4.4.4.1.cmml"><mrow id="S4.E2.m1.4.4.4.4.4.4.1.2.2" xref="S4.E2.m1.4.4.4.4.4.4.1.2.1.cmml"><mi id="S4.E2.m1.2.2.2.2.2.2" xref="S4.E2.m1.2.2.2.2.2.2.cmml">i</mi><mo id="S4.E2.m1.4.4.4.4.4.4.1.2.2.1" xref="S4.E2.m1.4.4.4.4.4.4.1.2.1.cmml">,</mo><mi id="S4.E2.m1.3.3.3.3.3.3" xref="S4.E2.m1.3.3.3.3.3.3.cmml">j</mi></mrow><mo id="S4.E2.m1.4.4.4.4.4.4.1.1" xref="S4.E2.m1.4.4.4.4.4.4.1.1.cmml">∈</mo><mrow id="S4.E2.m1.4.4.4.4.4.4.1.3.2" xref="S4.E2.m1.4.4.4.4.4.4.1.3.1.cmml"><mo stretchy="false" id="S4.E2.m1.4.4.4.4.4.4.1.3.2.1" xref="S4.E2.m1.4.4.4.4.4.4.1.3.1.1.cmml">[</mo><mi id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml">M</mi><mo stretchy="false" id="S4.E2.m1.4.4.4.4.4.4.1.3.2.2" xref="S4.E2.m1.4.4.4.4.4.4.1.3.1.1.cmml">]</mo></mrow></mrow><mo id="S4.E2.m1.5.5.5.5.5.5.3" xref="S4.E2.m1.5.5.5.5.5.6a.cmml">,</mo><mrow id="S4.E2.m1.5.5.5.5.5.5.2" xref="S4.E2.m1.5.5.5.5.5.5.2.cmml"><mi id="S4.E2.m1.5.5.5.5.5.5.2.2" xref="S4.E2.m1.5.5.5.5.5.5.2.2.cmml">i</mi><mo id="S4.E2.m1.5.5.5.5.5.5.2.1" xref="S4.E2.m1.5.5.5.5.5.5.2.1.cmml">≠</mo><mi id="S4.E2.m1.5.5.5.5.5.5.2.3" xref="S4.E2.m1.5.5.5.5.5.5.2.3.cmml">j</mi></mrow></mrow></msub><mrow id="S4.E2.m1.7.7.7.7" xref="S4.E2.m1.7.7.7.7.cmml"><mn id="S4.E2.m1.7.7.7.7.4" xref="S4.E2.m1.7.7.7.7.4.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.E2.m1.7.7.7.7.3" xref="S4.E2.m1.7.7.7.7.3.cmml">​</mo><mi id="S4.E2.m1.7.7.7.7.5" xref="S4.E2.m1.7.7.7.7.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.7.7.7.7.3a" xref="S4.E2.m1.7.7.7.7.3.cmml">​</mo><mrow id="S4.E2.m1.7.7.7.7.2.2" xref="S4.E2.m1.7.7.7.7.2.3.cmml"><mo id="S4.E2.m1.7.7.7.7.2.2.3" xref="S4.E2.m1.7.7.7.7.2.3.cmml">(</mo><msub id="S4.E2.m1.6.6.6.6.1.1.1" xref="S4.E2.m1.6.6.6.6.1.1.1.cmml"><mi id="S4.E2.m1.6.6.6.6.1.1.1.2" xref="S4.E2.m1.6.6.6.6.1.1.1.2.cmml">v</mi><mi id="S4.E2.m1.6.6.6.6.1.1.1.3" xref="S4.E2.m1.6.6.6.6.1.1.1.3.cmml">i</mi></msub><mo id="S4.E2.m1.7.7.7.7.2.2.4" xref="S4.E2.m1.7.7.7.7.2.3.cmml">,</mo><msub id="S4.E2.m1.7.7.7.7.2.2.2" xref="S4.E2.m1.7.7.7.7.2.2.2.cmml"><mi id="S4.E2.m1.7.7.7.7.2.2.2.2" xref="S4.E2.m1.7.7.7.7.2.2.2.2.cmml">v</mi><mi id="S4.E2.m1.7.7.7.7.2.2.2.3" xref="S4.E2.m1.7.7.7.7.2.2.2.3.cmml">j</mi></msub><mo id="S4.E2.m1.7.7.7.7.2.2.5" xref="S4.E2.m1.7.7.7.7.2.3.cmml">)</mo></mrow></mrow></mrow><mrow id="S4.E2.m1.8.8.8" xref="S4.E2.m1.8.8.8.cmml"><mi id="S4.E2.m1.8.8.8.3" xref="S4.E2.m1.8.8.8.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.8.8.8.2" xref="S4.E2.m1.8.8.8.2.cmml">​</mo><mrow id="S4.E2.m1.8.8.8.1.1" xref="S4.E2.m1.8.8.8.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.8.8.8.1.1.2" xref="S4.E2.m1.8.8.8.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.8.8.8.1.1.1" xref="S4.E2.m1.8.8.8.1.1.1.cmml"><mi id="S4.E2.m1.8.8.8.1.1.1.2" xref="S4.E2.m1.8.8.8.1.1.1.2.cmml">M</mi><mo id="S4.E2.m1.8.8.8.1.1.1.1" xref="S4.E2.m1.8.8.8.1.1.1.1.cmml">−</mo><mn id="S4.E2.m1.8.8.8.1.1.1.3" xref="S4.E2.m1.8.8.8.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.E2.m1.8.8.8.1.1.3" xref="S4.E2.m1.8.8.8.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.9b"><apply id="S4.E2.m1.9.10.cmml" xref="S4.E2.m1.9.10"><eq id="S4.E2.m1.9.10.1.cmml" xref="S4.E2.m1.9.10.1"></eq><apply id="S4.E2.m1.9.10.2.cmml" xref="S4.E2.m1.9.10.2"><times id="S4.E2.m1.9.10.2.1.cmml" xref="S4.E2.m1.9.10.2.1"></times><ci id="S4.E2.m1.9.10.2.2.cmml" xref="S4.E2.m1.9.10.2.2">𝜌</ci><ci id="S4.E2.m1.9.9.cmml" xref="S4.E2.m1.9.9">𝒟</ci></apply><apply id="S4.E2.m1.9.10.3.cmml" xref="S4.E2.m1.9.10.3"><minus id="S4.E2.m1.9.10.3.1.cmml" xref="S4.E2.m1.9.10.3.1"></minus><cn type="integer" id="S4.E2.m1.9.10.3.2.cmml" xref="S4.E2.m1.9.10.3.2">1</cn><apply id="S4.E2.m1.8.8.cmml" xref="S4.E2.m1.8.8"><divide id="S4.E2.m1.8.8.9.cmml" xref="S4.E2.m1.8.8"></divide><apply id="S4.E2.m1.7.7.7.cmml" xref="S4.E2.m1.7.7.7"><apply id="S4.E2.m1.7.7.7.8.cmml" xref="S4.E2.m1.7.7.7.8"><csymbol cd="ambiguous" id="S4.E2.m1.7.7.7.8.1.cmml" xref="S4.E2.m1.7.7.7.8">subscript</csymbol><sum id="S4.E2.m1.7.7.7.8.2.cmml" xref="S4.E2.m1.7.7.7.8.2"></sum><apply id="S4.E2.m1.5.5.5.5.5.6.cmml" xref="S4.E2.m1.5.5.5.5.5.5"><csymbol cd="ambiguous" id="S4.E2.m1.5.5.5.5.5.6a.cmml" xref="S4.E2.m1.5.5.5.5.5.5.3">formulae-sequence</csymbol><apply id="S4.E2.m1.4.4.4.4.4.4.1.cmml" xref="S4.E2.m1.4.4.4.4.4.4.1"><in id="S4.E2.m1.4.4.4.4.4.4.1.1.cmml" xref="S4.E2.m1.4.4.4.4.4.4.1.1"></in><list id="S4.E2.m1.4.4.4.4.4.4.1.2.1.cmml" xref="S4.E2.m1.4.4.4.4.4.4.1.2.2"><ci id="S4.E2.m1.2.2.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2.2.2">𝑖</ci><ci id="S4.E2.m1.3.3.3.3.3.3.cmml" xref="S4.E2.m1.3.3.3.3.3.3">𝑗</ci></list><apply id="S4.E2.m1.4.4.4.4.4.4.1.3.1.cmml" xref="S4.E2.m1.4.4.4.4.4.4.1.3.2"><csymbol cd="latexml" id="S4.E2.m1.4.4.4.4.4.4.1.3.1.1.cmml" xref="S4.E2.m1.4.4.4.4.4.4.1.3.2.1">delimited-[]</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1">𝑀</ci></apply></apply><apply id="S4.E2.m1.5.5.5.5.5.5.2.cmml" xref="S4.E2.m1.5.5.5.5.5.5.2"><neq id="S4.E2.m1.5.5.5.5.5.5.2.1.cmml" xref="S4.E2.m1.5.5.5.5.5.5.2.1"></neq><ci id="S4.E2.m1.5.5.5.5.5.5.2.2.cmml" xref="S4.E2.m1.5.5.5.5.5.5.2.2">𝑖</ci><ci id="S4.E2.m1.5.5.5.5.5.5.2.3.cmml" xref="S4.E2.m1.5.5.5.5.5.5.2.3">𝑗</ci></apply></apply></apply><apply id="S4.E2.m1.7.7.7.7.cmml" xref="S4.E2.m1.7.7.7.7"><times id="S4.E2.m1.7.7.7.7.3.cmml" xref="S4.E2.m1.7.7.7.7.3"></times><cn type="integer" id="S4.E2.m1.7.7.7.7.4.cmml" xref="S4.E2.m1.7.7.7.7.4">2</cn><ci id="S4.E2.m1.7.7.7.7.5.cmml" xref="S4.E2.m1.7.7.7.7.5">𝑆</ci><interval closure="open" id="S4.E2.m1.7.7.7.7.2.3.cmml" xref="S4.E2.m1.7.7.7.7.2.2"><apply id="S4.E2.m1.6.6.6.6.1.1.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.6.6.1.1.1.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1">subscript</csymbol><ci id="S4.E2.m1.6.6.6.6.1.1.1.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.2">𝑣</ci><ci id="S4.E2.m1.6.6.6.6.1.1.1.3.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.3">𝑖</ci></apply><apply id="S4.E2.m1.7.7.7.7.2.2.2.cmml" xref="S4.E2.m1.7.7.7.7.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.7.7.7.7.2.2.2.1.cmml" xref="S4.E2.m1.7.7.7.7.2.2.2">subscript</csymbol><ci id="S4.E2.m1.7.7.7.7.2.2.2.2.cmml" xref="S4.E2.m1.7.7.7.7.2.2.2.2">𝑣</ci><ci id="S4.E2.m1.7.7.7.7.2.2.2.3.cmml" xref="S4.E2.m1.7.7.7.7.2.2.2.3">𝑗</ci></apply></interval></apply></apply><apply id="S4.E2.m1.8.8.8.cmml" xref="S4.E2.m1.8.8.8"><times id="S4.E2.m1.8.8.8.2.cmml" xref="S4.E2.m1.8.8.8.2"></times><ci id="S4.E2.m1.8.8.8.3.cmml" xref="S4.E2.m1.8.8.8.3">𝑀</ci><apply id="S4.E2.m1.8.8.8.1.1.1.cmml" xref="S4.E2.m1.8.8.8.1.1"><minus id="S4.E2.m1.8.8.8.1.1.1.1.cmml" xref="S4.E2.m1.8.8.8.1.1.1.1"></minus><ci id="S4.E2.m1.8.8.8.1.1.1.2.cmml" xref="S4.E2.m1.8.8.8.1.1.1.2">𝑀</ci><cn type="integer" id="S4.E2.m1.8.8.8.1.1.1.3.cmml" xref="S4.E2.m1.8.8.8.1.1.1.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.9c">\rho(\mathcal{D})=1-\frac{\sum_{i,j\in[M],i\neq j}2S\left(v_{i},v_{j}\right)}{M(M-1)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S4.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.5. </span>Sample Selection View</h4>

<div id="S4.SS3.SSS5.p1" class="ltx_para">
<p id="S4.SS3.SSS5.p1.2" class="ltx_p">We design a sample selection view to facilitate the mentioned interactive sampling for modeling. As shown in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(c1), after projecting the clusters into a 2D space, a key issue is to convey the data characteristics of each cluster in terms of label distribution and salient features to facilitate the exploration of the data. Notably, we design a novel glyph to represent the data characteristic of each cluster. It consists of an inner radar chart and an outer ring. The data features are arranged in the clockwise direction of the glyph. The values on each axis of the radar chart represent the distance between the probability distribution of the data in this dimension of the cluster and the probability distribution of the entire training data, calculated using EMD distance (i.e., Wasserstein distance) <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2018a</a>)</cite>. The outer ring shows the label distribution, with yellow representing <math id="S4.SS3.SSS5.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS3.SSS5.p1.1.m1.1a"><mn id="S4.SS3.SSS5.p1.1.m1.1.1" xref="S4.SS3.SSS5.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS5.p1.1.m1.1b"><cn type="integer" id="S4.SS3.SSS5.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS5.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS5.p1.1.m1.1c">1</annotation></semantics></math> and the blue representing <math id="S4.SS3.SSS5.p1.2.m2.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS3.SSS5.p1.2.m2.1a"><mn id="S4.SS3.SSS5.p1.2.m2.1.1" xref="S4.SS3.SSS5.p1.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS5.p1.2.m2.1b"><cn type="integer" id="S4.SS3.SSS5.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS5.p1.2.m2.1.1">0</cn></annotation-xml></semantics></math>, e.g., in the case of binary classification. When users click on a glyph in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(c1), <span id="S4.SS3.SSS5.p1.2.1" class="ltx_text ltx_font_italic">VFLens</span> displays its data features in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(c2) as a reference for the subsequent sampling operation in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(c3). It is worth noting that users can conduct an interactive sampling procedure for each cluster by filtering any number of samples from the center to the subcontinent (<span id="S4.SS3.SSS5.p1.2.2" class="ltx_text ltx_font_bold">R4</span>). In general, the principle of interactive sampling is to balance the data labels to diversify and enrich the characteristics of the samples. Therefore, we evaluate the overall data after sampling in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(c4), involving <span id="S4.SS3.SSS5.p1.2.3" class="ltx_text ltx_font_italic">sample count</span>, <span id="S4.SS3.SSS5.p1.2.4" class="ltx_text ltx_font_italic">homogeneity</span>, <span id="S4.SS3.SSS5.p1.2.5" class="ltx_text ltx_font_italic">diversity</span>.</p>
</div>
</section>
<section id="S4.SS3.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.6. </span>VFL/Local Modeling and Model Verification</h4>

<div id="S4.SS3.SSS6.p1" class="ltx_para">
<p id="S4.SS3.SSS6.p1.1" class="ltx_p">After identifying the features and samples to be modeled, we come to the VFL modeling stage. Multiple rounds of communication are required between host and guest to exchange encrypted gradients, and both parties transmit the following information to each other: 1) encrypted gradient information, i.e., the derivation of weights derived from sample features and labels; 2) de-identifiable sample ID, which are used to align the gradient information and transmit the convergence direction of the model. This process is a typical VFL, and the specific information interaction and communication process can be referred to the LR-based VFL configuration. Users can train the model by pressing the buttons in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(d1). After VFL modeling, a VFL model is built at this point. In addition, since the host contains certain features and full sample labels, we can train a local model at the host side.</p>
</div>
<div id="S4.SS3.SSS6.p2" class="ltx_para">
<p id="S4.SS3.SSS6.p2.1" class="ltx_p">After building the initial VFL model, both parties verify the accuracy of the VFL model using de-identifiable user ID, features, and labels of the verification user set. For ease of understanding, we describe the verification process as follows: 1) The host transmits the de-identified ID of the verification user set to the guest to verify whether the guest holds the data of the validation user set. If not, the verification process ends. 2) If the guest holds the verification user set, both parties start invoking their own “semi-models” to compute the corresponding prediction score. Specifically, the guest obtains the features of the verification user set from its local data and inputs them into the guest’s semi-model to calculate the prediction score. Similarly, since the host has certain sample features, it can also calculate its prediction scores by feeding the sample features into the host’s semi-model. Admittedly, in some cases, the host may have only sample labels without any feature dimensions, so there is no need to compute its prediction score. 3) After computing the prediction scores for both parties, the guest transmits the prediction score to the host, who aggregates the prediction score of both parties to obtain the final prediction result. 4) Finally, the host compares the prediction results with the ground truth labels and decides whether to fine-tune the model.</p>
</div>
</section>
<section id="S4.SS3.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.7. </span>Model Performance View</h4>

<div id="S4.SS3.SSS7.p1" class="ltx_para">
<p id="S4.SS3.SSS7.p1.1" class="ltx_p">In the model performance view, we display the results of the metrics used to evaluate the performance of the local and VFL models for each configuration (<span id="S4.SS3.SSS7.p1.1.1" class="ltx_text ltx_font_bold">R3</span>). We can iterate over the local model multiple times, since all communication and modeling processes occur locally. However, for the VFL model, we should iterate carefully if good enough performance is achieved.. Notably, as shown in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(d2), this view shows the traditional metrics used to evaluate binary or multiclass classifications, such as <span id="S4.SS3.SSS7.p1.1.2" class="ltx_text ltx_font_italic">accuracy</span>, <span id="S4.SS3.SSS7.p1.1.3" class="ltx_text ltx_font_italic">loss</span>, <span id="S4.SS3.SSS7.p1.1.4" class="ltx_text ltx_font_italic">KS</span>, and <span id="S4.SS3.SSS7.p1.1.5" class="ltx_text ltx_font_italic">AUC</span>. Each iteration of the local and VFL models is recorded to facilitate the selection of the best model for the final model prediction.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Inference Stage</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In the inference stage, the host can initiate a prediction based on its real-world requirement and invoke the “semi-model” of both parties for inference. Generally, the “semi-model” of both parties will give a prediction score, and the guest will send its prediction score to the host. The host will aggregate the prediction scores of both parties to get the final prediction result. Specifically, the vertical federated learning inference process is as follows: 1) the host de-identifies the target user ID to be predicted and transmits the de-identified IDs to the guest. After receiving the de-identified IDs, the guest queries whether it holds these corresponding features of these IDs. If the guest does not have these features, the prediction ends; 2) If the guest contains the features of these IDs, both parties invoke their respective “semi-models” to calculate the prediction scores. For example, the guest reaches the target user data locally, obtains the features of the target IDs, and then inputs the guest’s “semi-model” to obtain the prediction scores. Similarly, if the host holds some user features, the host computes its prediction scores for the target user IDs; otherwise, if the host does not have user features, it does not need to compute the prediction scores; 3) The guest transmits the prediction scores of its “semi-model” to the host, and the host aggregates the two parts to obtain the final prediction result. At this point, the VFL inference stage is over and all samples that need to be predicted will get the prediction result by VFL inference.</p>
</div>
<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1. </span>Instances for Inference and Sample Selection</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">In reality, the number of samples to be predicted can be very large. In the inference phase of VFL, “semi-models” from both parties are required to cooperate online to complete the prediction, which poses a great challenge in terms of communication quality, modeling resources and economic costs. According to the expert feedback, VFL can improve the confidence of prediction results by expanding the feature space, but “<span id="S4.SS4.SSS1.p1.1.1" class="ltx_text ltx_font_italic">this is not suitable for all samples to be predicted.</span>” It is worth noting that with limited budget cost, E1 and E5 want a less costly method to accomplish prediction for all samples to be predicted, while guaranteeing the quality of the prediction results to some extent. Therefore, we need to classify the samples to be predicted and send only those samples with high uncertainty to the VFL model for inference. And for the samples with high label confidence, we can use the local model of the host for prediction (<span id="S4.SS4.SSS1.p1.1.2" class="ltx_text ltx_font_bold">R4</span>).</p>
</div>
<div id="S4.SS4.SSS1.p2" class="ltx_para">
<p id="S4.SS4.SSS1.p2.8" class="ltx_p">For this purpose, we design the following sample selection schemes in the inference stage: 1) The sample <math id="S4.SS4.SSS1.p2.1.m1.1" class="ltx_Math" alttext="{ps}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.1.m1.1a"><mrow id="S4.SS4.SSS1.p2.1.m1.1.1" xref="S4.SS4.SSS1.p2.1.m1.1.1.cmml"><mi id="S4.SS4.SSS1.p2.1.m1.1.1.2" xref="S4.SS4.SSS1.p2.1.m1.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.1.m1.1.1.1" xref="S4.SS4.SSS1.p2.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.1.m1.1.1.3" xref="S4.SS4.SSS1.p2.1.m1.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.1.m1.1.1.3.2" xref="S4.SS4.SSS1.p2.1.m1.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.1.m1.1.1.3.3" xref="S4.SS4.SSS1.p2.1.m1.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.1.m1.1b"><apply id="S4.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1"><times id="S4.SS4.SSS1.p2.1.m1.1.1.1.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.1"></times><ci id="S4.SS4.SSS1.p2.1.m1.1.1.2.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.2">𝑝</ci><apply id="S4.SS4.SSS1.p2.1.m1.1.1.3.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.1.m1.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.1.m1.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.1.m1.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.1.m1.1c">{ps}_{i}</annotation></semantics></math> to be predicted is input into the local model of the host for inference, and the prediction result is obtained. Note that the local model here is different from the “semi-model” of the host. The local model only considers the data features residing on the host side and the data labels. 2) In the sample space, we compute the similarity between <math id="S4.SS4.SSS1.p2.2.m2.1" class="ltx_Math" alttext="{ps}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.2.m2.1a"><mrow id="S4.SS4.SSS1.p2.2.m2.1.1" xref="S4.SS4.SSS1.p2.2.m2.1.1.cmml"><mi id="S4.SS4.SSS1.p2.2.m2.1.1.2" xref="S4.SS4.SSS1.p2.2.m2.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.2.m2.1.1.1" xref="S4.SS4.SSS1.p2.2.m2.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.2.m2.1.1.3" xref="S4.SS4.SSS1.p2.2.m2.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.2.m2.1.1.3.2" xref="S4.SS4.SSS1.p2.2.m2.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.2.m2.1.1.3.3" xref="S4.SS4.SSS1.p2.2.m2.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.2.m2.1b"><apply id="S4.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1"><times id="S4.SS4.SSS1.p2.2.m2.1.1.1.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.1"></times><ci id="S4.SS4.SSS1.p2.2.m2.1.1.2.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.2">𝑝</ci><apply id="S4.SS4.SSS1.p2.2.m2.1.1.3.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.2.m2.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.2.m2.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.2.m2.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.2.m2.1c">{ps}_{i}</annotation></semantics></math> and all training samples in terms of the host feature space, e.g., using the Euclidean distance to obtain the training sample <math id="S4.SS4.SSS1.p2.3.m3.1" class="ltx_Math" alttext="{ps}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.3.m3.1a"><mrow id="S4.SS4.SSS1.p2.3.m3.1.1" xref="S4.SS4.SSS1.p2.3.m3.1.1.cmml"><mi id="S4.SS4.SSS1.p2.3.m3.1.1.2" xref="S4.SS4.SSS1.p2.3.m3.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.3.m3.1.1.1" xref="S4.SS4.SSS1.p2.3.m3.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.3.m3.1.1.3" xref="S4.SS4.SSS1.p2.3.m3.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.3.m3.1.1.3.2" xref="S4.SS4.SSS1.p2.3.m3.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.3.m3.1.1.3.3" xref="S4.SS4.SSS1.p2.3.m3.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.3.m3.1b"><apply id="S4.SS4.SSS1.p2.3.m3.1.1.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1"><times id="S4.SS4.SSS1.p2.3.m3.1.1.1.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.1"></times><ci id="S4.SS4.SSS1.p2.3.m3.1.1.2.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.2">𝑝</ci><apply id="S4.SS4.SSS1.p2.3.m3.1.1.3.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.3.m3.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.3.m3.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.3.m3.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.3.m3.1c">{ps}_{i}</annotation></semantics></math> that is closest to <math id="S4.SS4.SSS1.p2.4.m4.1" class="ltx_Math" alttext="{ts}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.4.m4.1a"><mrow id="S4.SS4.SSS1.p2.4.m4.1.1" xref="S4.SS4.SSS1.p2.4.m4.1.1.cmml"><mi id="S4.SS4.SSS1.p2.4.m4.1.1.2" xref="S4.SS4.SSS1.p2.4.m4.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.4.m4.1.1.1" xref="S4.SS4.SSS1.p2.4.m4.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.4.m4.1.1.3" xref="S4.SS4.SSS1.p2.4.m4.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.4.m4.1.1.3.2" xref="S4.SS4.SSS1.p2.4.m4.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.4.m4.1.1.3.3" xref="S4.SS4.SSS1.p2.4.m4.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.4.m4.1b"><apply id="S4.SS4.SSS1.p2.4.m4.1.1.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1"><times id="S4.SS4.SSS1.p2.4.m4.1.1.1.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.1"></times><ci id="S4.SS4.SSS1.p2.4.m4.1.1.2.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.2">𝑡</ci><apply id="S4.SS4.SSS1.p2.4.m4.1.1.3.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.4.m4.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.4.m4.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.4.m4.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.4.m4.1c">{ts}_{i}</annotation></semantics></math>. 3) For <math id="S4.SS4.SSS1.p2.5.m5.1" class="ltx_Math" alttext="{ts}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.5.m5.1a"><mrow id="S4.SS4.SSS1.p2.5.m5.1.1" xref="S4.SS4.SSS1.p2.5.m5.1.1.cmml"><mi id="S4.SS4.SSS1.p2.5.m5.1.1.2" xref="S4.SS4.SSS1.p2.5.m5.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.5.m5.1.1.1" xref="S4.SS4.SSS1.p2.5.m5.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.5.m5.1.1.3" xref="S4.SS4.SSS1.p2.5.m5.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.5.m5.1.1.3.2" xref="S4.SS4.SSS1.p2.5.m5.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.5.m5.1.1.3.3" xref="S4.SS4.SSS1.p2.5.m5.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.5.m5.1b"><apply id="S4.SS4.SSS1.p2.5.m5.1.1.cmml" xref="S4.SS4.SSS1.p2.5.m5.1.1"><times id="S4.SS4.SSS1.p2.5.m5.1.1.1.cmml" xref="S4.SS4.SSS1.p2.5.m5.1.1.1"></times><ci id="S4.SS4.SSS1.p2.5.m5.1.1.2.cmml" xref="S4.SS4.SSS1.p2.5.m5.1.1.2">𝑡</ci><apply id="S4.SS4.SSS1.p2.5.m5.1.1.3.cmml" xref="S4.SS4.SSS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.5.m5.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.5.m5.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.5.m5.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.5.m5.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.5.m5.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.5.m5.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.5.m5.1c">{ts}_{i}</annotation></semantics></math>, determine its ground truth label, the local model’s prediction result and the prediction results of the VFL model are consistent. We consider <math id="S4.SS4.SSS1.p2.6.m6.1" class="ltx_Math" alttext="{ps}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.6.m6.1a"><mrow id="S4.SS4.SSS1.p2.6.m6.1.1" xref="S4.SS4.SSS1.p2.6.m6.1.1.cmml"><mi id="S4.SS4.SSS1.p2.6.m6.1.1.2" xref="S4.SS4.SSS1.p2.6.m6.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.6.m6.1.1.1" xref="S4.SS4.SSS1.p2.6.m6.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.6.m6.1.1.3" xref="S4.SS4.SSS1.p2.6.m6.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.6.m6.1.1.3.2" xref="S4.SS4.SSS1.p2.6.m6.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.6.m6.1.1.3.3" xref="S4.SS4.SSS1.p2.6.m6.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.6.m6.1b"><apply id="S4.SS4.SSS1.p2.6.m6.1.1.cmml" xref="S4.SS4.SSS1.p2.6.m6.1.1"><times id="S4.SS4.SSS1.p2.6.m6.1.1.1.cmml" xref="S4.SS4.SSS1.p2.6.m6.1.1.1"></times><ci id="S4.SS4.SSS1.p2.6.m6.1.1.2.cmml" xref="S4.SS4.SSS1.p2.6.m6.1.1.2">𝑝</ci><apply id="S4.SS4.SSS1.p2.6.m6.1.1.3.cmml" xref="S4.SS4.SSS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.6.m6.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.6.m6.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.6.m6.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.6.m6.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.6.m6.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.6.m6.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.6.m6.1c">{ps}_{i}</annotation></semantics></math> a plausible sample if and only if the results of the three parts agree and are the same as the prediction results of the host local model for <math id="S4.SS4.SSS1.p2.7.m7.1" class="ltx_Math" alttext="{ps}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.7.m7.1a"><mrow id="S4.SS4.SSS1.p2.7.m7.1.1" xref="S4.SS4.SSS1.p2.7.m7.1.1.cmml"><mi id="S4.SS4.SSS1.p2.7.m7.1.1.2" xref="S4.SS4.SSS1.p2.7.m7.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.7.m7.1.1.1" xref="S4.SS4.SSS1.p2.7.m7.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.7.m7.1.1.3" xref="S4.SS4.SSS1.p2.7.m7.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.7.m7.1.1.3.2" xref="S4.SS4.SSS1.p2.7.m7.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.7.m7.1.1.3.3" xref="S4.SS4.SSS1.p2.7.m7.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.7.m7.1b"><apply id="S4.SS4.SSS1.p2.7.m7.1.1.cmml" xref="S4.SS4.SSS1.p2.7.m7.1.1"><times id="S4.SS4.SSS1.p2.7.m7.1.1.1.cmml" xref="S4.SS4.SSS1.p2.7.m7.1.1.1"></times><ci id="S4.SS4.SSS1.p2.7.m7.1.1.2.cmml" xref="S4.SS4.SSS1.p2.7.m7.1.1.2">𝑝</ci><apply id="S4.SS4.SSS1.p2.7.m7.1.1.3.cmml" xref="S4.SS4.SSS1.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.7.m7.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.7.m7.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.7.m7.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.7.m7.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.7.m7.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.7.m7.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.7.m7.1c">{ps}_{i}</annotation></semantics></math>, where the prediction results of the host local model can be directly used as the final prediction results; otherwise, <math id="S4.SS4.SSS1.p2.8.m8.1" class="ltx_Math" alttext="{ps}_{i}" display="inline"><semantics id="S4.SS4.SSS1.p2.8.m8.1a"><mrow id="S4.SS4.SSS1.p2.8.m8.1.1" xref="S4.SS4.SSS1.p2.8.m8.1.1.cmml"><mi id="S4.SS4.SSS1.p2.8.m8.1.1.2" xref="S4.SS4.SSS1.p2.8.m8.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p2.8.m8.1.1.1" xref="S4.SS4.SSS1.p2.8.m8.1.1.1.cmml">​</mo><msub id="S4.SS4.SSS1.p2.8.m8.1.1.3" xref="S4.SS4.SSS1.p2.8.m8.1.1.3.cmml"><mi id="S4.SS4.SSS1.p2.8.m8.1.1.3.2" xref="S4.SS4.SSS1.p2.8.m8.1.1.3.2.cmml">s</mi><mi id="S4.SS4.SSS1.p2.8.m8.1.1.3.3" xref="S4.SS4.SSS1.p2.8.m8.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.8.m8.1b"><apply id="S4.SS4.SSS1.p2.8.m8.1.1.cmml" xref="S4.SS4.SSS1.p2.8.m8.1.1"><times id="S4.SS4.SSS1.p2.8.m8.1.1.1.cmml" xref="S4.SS4.SSS1.p2.8.m8.1.1.1"></times><ci id="S4.SS4.SSS1.p2.8.m8.1.1.2.cmml" xref="S4.SS4.SSS1.p2.8.m8.1.1.2">𝑝</ci><apply id="S4.SS4.SSS1.p2.8.m8.1.1.3.cmml" xref="S4.SS4.SSS1.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.8.m8.1.1.3.1.cmml" xref="S4.SS4.SSS1.p2.8.m8.1.1.3">subscript</csymbol><ci id="S4.SS4.SSS1.p2.8.m8.1.1.3.2.cmml" xref="S4.SS4.SSS1.p2.8.m8.1.1.3.2">𝑠</ci><ci id="S4.SS4.SSS1.p2.8.m8.1.1.3.3.cmml" xref="S4.SS4.SSS1.p2.8.m8.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.8.m8.1c">{ps}_{i}</annotation></semantics></math> is considered to have high uncertainty and needs to be predicted by the VFL model. At this time, all the samples to be predicted will be automatically divided into two categories. One category is samples with high credibility that do not require federated prediction, and the other category is samples that require further inference using the VFL model.</p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2. </span>Inference View</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">As mentioned before, we obtained the two classes of samples to be predicted. To visualize the results and present the current classification of our strategy (<span id="S4.SS4.SSS2.p1.1.1" class="ltx_text ltx_font_bold">R4 – R5</span>), we compute a many-to-many mapping based on the shortest distance from the predicted data to the training samples. In particular, as shown in <a href="#S4.F5" title="Figure 5 ‣ 4.3.1. General Process of VFL Modeling ‣ 4.3. VFL Modeling Phase ‣ 4. Co-design the Modeling Process of VFL ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>(e), we use the <span id="S4.SS4.SSS2.p1.1.2" class="ltx_text ltx_font_italic">t-SNE</span> and <span id="S4.SS4.SSS2.p1.1.3" class="ltx_text ltx_font_italic">KMeans++</span> clustering methods to abstract the large number of samples to be predicted into the Sankey diagram. The flow from left to right in the Sankey diagram is the number of samples to be predicted. The leftmost column shows the eight label combinations of the training samples, corresponding to three cases (i.e., ground truth label, local model prediction result, and VFL model prediction results). The middle two columns correspond to the training data and the samples to be predicted, respectively. The last column lists the number of samples with high reliability and the number of samples that need to be predicted by the VFL model.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Interaction Among the Views</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Rich interactions are integrated into <span id="S4.SS5.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span> to build a low-cost VFL model. <span id="S4.SS5.p1.1.2" class="ltx_text ltx_font_italic">1) Sorting</span>. After the user clicks the average button in the feature selection view, the system will sort the average importance of all local features from highest to lowest. In the VFL feature selection view, we encode the importance of VFL feature as the color depth of the color block, and the color block color will change after the specified feature is selected. <span id="S4.SS5.p1.1.3" class="ltx_text ltx_font_italic">2) Hover on.</span> In the sample selection view, when the user selects a data cluster, a zoomed-in view of the cluster content is presented at the edge of the view, which helps the user to identify the specific feature patterns of different clusters. <span id="S4.SS5.p1.1.4" class="ltx_text ltx_font_italic">3) Parameter editing.</span> In the sample view, we adjust the scale of the samples in different regions by mediating the height of the bars with the mouse.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Evaluation</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Usage Scenario</h3>

<figure id="S5.F8" class="ltx_figure"><img src="/html/2210.00472/assets/figures/case.png" id="S5.F8.g1" class="ltx_graphics ltx_img_landscape" width="598" height="260" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>Usage Scenario: (1) Select the top-ranked local features in the local feature selection view. (2) External features with high iv values are selected in the VFL feature selection view. (3) In the sample selection view, we select different clusters for sampling based on the proportional of label in the cluster and the specific feature distribution information encoded in the clusters. (4) Observe the specific feature distribution information of the data in the cluster. (5) Set the sampling weight for different regions in each cluster. (6) Observe the two statistical indicators of the overall data that has been sampled and we will stop sampling when the amount of data and the two statistical indicators reach the basic expectation value. (7) Adjust the learning parameters and start model training. (8) Run the local inference model, check the proportion of samples to be predicted, and verify the validity of the model.</figcaption>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.6" class="ltx_p">The modeling data from the real estate industry mentioned in the observational study has confidentially rules and cannot be used as experimental data. As an alternative, we take a publicly available credit card dataset <cite class="ltx_cite ltx_citemacro_citep">(Yeh and Lien, <a href="#bib.bib55" title="" class="ltx_ref">2009</a>)</cite>, where financial institutions can use their own customer data to predict various customer performance. Although most customer data are limited in the finance context, if other information can be used for joint modeling, financial institutions can obtain more accurate prediction models to further provide better services and reduce potential banking risks. To model this scenario, we use the dataset of customer defaults in Taiwan <cite class="ltx_cite ltx_citemacro_citep">(Yeh and Lien, <a href="#bib.bib55" title="" class="ltx_ref">2009</a>)</cite>. Notably, we use the first <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="14" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">14</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">14</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">14</annotation></semantics></math> dimensions as internal features and the last <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn type="integer" id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">9</annotation></semantics></math> dimensions as the federated external features. We also derive several alternative features. Finally, we obtain <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><mn id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><cn type="integer" id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">20</annotation></semantics></math> local features and <math id="S5.SS1.p1.4.m4.1" class="ltx_Math" alttext="33" display="inline"><semantics id="S5.SS1.p1.4.m4.1a"><mn id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml">33</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><cn type="integer" id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1">33</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">33</annotation></semantics></math> external features for VFL modeling. In VFL, the host knows everything about the local features. Nevertheless, due to the privacy-preserving mechanism, we only use IDs to represent the federated external features. We use <math id="S5.SS1.p1.5.m5.2" class="ltx_Math" alttext="15,000" display="inline"><semantics id="S5.SS1.p1.5.m5.2a"><mrow id="S5.SS1.p1.5.m5.2.3.2" xref="S5.SS1.p1.5.m5.2.3.1.cmml"><mn id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml">15</mn><mo id="S5.SS1.p1.5.m5.2.3.2.1" xref="S5.SS1.p1.5.m5.2.3.1.cmml">,</mo><mn id="S5.SS1.p1.5.m5.2.2" xref="S5.SS1.p1.5.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.2b"><list id="S5.SS1.p1.5.m5.2.3.1.cmml" xref="S5.SS1.p1.5.m5.2.3.2"><cn type="integer" id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1">15</cn><cn type="integer" id="S5.SS1.p1.5.m5.2.2.cmml" xref="S5.SS1.p1.5.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.2c">15,000</annotation></semantics></math> rows of total data in the VFL modeling stage and <math id="S5.SS1.p1.6.m6.2" class="ltx_Math" alttext="15,000" display="inline"><semantics id="S5.SS1.p1.6.m6.2a"><mrow id="S5.SS1.p1.6.m6.2.3.2" xref="S5.SS1.p1.6.m6.2.3.1.cmml"><mn id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml">15</mn><mo id="S5.SS1.p1.6.m6.2.3.2.1" xref="S5.SS1.p1.6.m6.2.3.1.cmml">,</mo><mn id="S5.SS1.p1.6.m6.2.2" xref="S5.SS1.p1.6.m6.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.2b"><list id="S5.SS1.p1.6.m6.2.3.1.cmml" xref="S5.SS1.p1.6.m6.2.3.2"><cn type="integer" id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1">15</cn><cn type="integer" id="S5.SS1.p1.6.m6.2.2.cmml" xref="S5.SS1.p1.6.m6.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.2c">15,000</annotation></semantics></math> rows in the VFL inference stage.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.2" class="ltx_p"><span id="S5.SS1.p2.2.1" class="ltx_text ltx_font_bold">Feature Space Interaction.</span> After loading the local data into <span id="S5.SS1.p2.2.2" class="ltx_text ltx_font_italic">VFLens</span>, we select the top <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="13" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mn id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">13</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><cn type="integer" id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">13</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">13</annotation></semantics></math> local features based on the recommended results of the standard automatic feature selection methods, as shown in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(1). Regarding external features, to simulate reality, we randomly select <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><mn id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><cn type="integer" id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">15</annotation></semantics></math> remote external features for VFL modeling.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.31" class="ltx_p"><span id="S5.SS1.p3.31.1" class="ltx_text ltx_font_bold">Sample Space Interaction.</span> After the initial determination of the internal and external features, the host must select the appropriate number of samples for VFL model training. We turn to the sample selection view and first see a sharp feature in the upper left corner of the radar chart of cluster No.<math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mn id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><cn type="integer" id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">4</annotation></semantics></math>. Based on the radar chart visualization, we find a similar distribution of features in clusters No.<math id="S5.SS1.p3.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS1.p3.2.m2.1a"><mn id="S5.SS1.p3.2.m2.1.1" xref="S5.SS1.p3.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.2.m2.1b"><cn type="integer" id="S5.SS1.p3.2.m2.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.2.m2.1c">1</annotation></semantics></math>, No.<math id="S5.SS1.p3.3.m3.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S5.SS1.p3.3.m3.1a"><mn id="S5.SS1.p3.3.m3.1.1" xref="S5.SS1.p3.3.m3.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.3.m3.1b"><cn type="integer" id="S5.SS1.p3.3.m3.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.3.m3.1c">8</annotation></semantics></math>, No. <math id="S5.SS1.p3.4.m4.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S5.SS1.p3.4.m4.1a"><mn id="S5.SS1.p3.4.m4.1.1" xref="S5.SS1.p3.4.m4.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.4.m4.1b"><cn type="integer" id="S5.SS1.p3.4.m4.1.1.cmml" xref="S5.SS1.p3.4.m4.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.4.m4.1c">15</annotation></semantics></math>, and No.<math id="S5.SS1.p3.5.m5.1" class="ltx_Math" alttext="11" display="inline"><semantics id="S5.SS1.p3.5.m5.1a"><mn id="S5.SS1.p3.5.m5.1.1" xref="S5.SS1.p3.5.m5.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.5.m5.1b"><cn type="integer" id="S5.SS1.p3.5.m5.1.1.cmml" xref="S5.SS1.p3.5.m5.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.5.m5.1c">11</annotation></semantics></math> next to cluster <math id="S5.SS1.p3.6.m6.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p3.6.m6.1a"><mn id="S5.SS1.p3.6.m6.1.1" xref="S5.SS1.p3.6.m6.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.6.m6.1b"><cn type="integer" id="S5.SS1.p3.6.m6.1.1.cmml" xref="S5.SS1.p3.6.m6.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.6.m6.1c">4</annotation></semantics></math>. We then click on cluster No.<math id="S5.SS1.p3.7.m7.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p3.7.m7.1a"><mn id="S5.SS1.p3.7.m7.1.1" xref="S5.SS1.p3.7.m7.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.7.m7.1b"><cn type="integer" id="S5.SS1.p3.7.m7.1.1.cmml" xref="S5.SS1.p3.7.m7.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.7.m7.1c">4</annotation></semantics></math> and further observe the specific indicator of the radar chart enlarged on the right side of the view <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(3A) and its feature distribution in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(4). We find that the feature distribution of this cluster has firm consistency. Therefore, we decide to reduce the overall sampling rate of these clusters to reduce the number of samples within these clusters for training, and to reduce the training cost while maintaining the loss of data features. More specifically, we first select cluster No. <math id="S5.SS1.p3.8.m8.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p3.8.m8.1a"><mn id="S5.SS1.p3.8.m8.1.1" xref="S5.SS1.p3.8.m8.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.8.m8.1b"><cn type="integer" id="S5.SS1.p3.8.m8.1.1.cmml" xref="S5.SS1.p3.8.m8.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.8.m8.1c">4</annotation></semantics></math>, and in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(4), we determine that the salient feature of this cluster is <span id="S5.SS1.p3.31.2" class="ltx_text ltx_font_italic">limit_bal_log</span>. The other features are similar to those of the overall samples. In <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(5), we reduce the number of duplicate training samples by reducing the sampling rate of the central region samples. Then we click the “Start Sampling” button of cluster No.<math id="S5.SS1.p3.9.m9.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p3.9.m9.1a"><mn id="S5.SS1.p3.9.m9.1.1" xref="S5.SS1.p3.9.m9.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.9.m9.1b"><cn type="integer" id="S5.SS1.p3.9.m9.1.1.cmml" xref="S5.SS1.p3.9.m9.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.9.m9.1c">4</annotation></semantics></math>. The relevant information after sampling is displayed in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(6). We can observe that <span id="S5.SS1.p3.31.3" class="ltx_text ltx_font_italic">Homogeneity</span> is <math id="S5.SS1.p3.10.m10.1" class="ltx_Math" alttext="1.58" display="inline"><semantics id="S5.SS1.p3.10.m10.1a"><mn id="S5.SS1.p3.10.m10.1.1" xref="S5.SS1.p3.10.m10.1.1.cmml">1.58</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.10.m10.1b"><cn type="float" id="S5.SS1.p3.10.m10.1.1.cmml" xref="S5.SS1.p3.10.m10.1.1">1.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.10.m10.1c">1.58</annotation></semantics></math>, which reflects that the balance of data labels is moderate. The metric of <span id="S5.SS1.p3.31.4" class="ltx_text ltx_font_italic">Content Diversity</span> is <math id="S5.SS1.p3.11.m11.1" class="ltx_Math" alttext="0.10" display="inline"><semantics id="S5.SS1.p3.11.m11.1a"><mn id="S5.SS1.p3.11.m11.1.1" xref="S5.SS1.p3.11.m11.1.1.cmml">0.10</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.11.m11.1b"><cn type="float" id="S5.SS1.p3.11.m11.1.1.cmml" xref="S5.SS1.p3.11.m11.1.1">0.10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.11.m11.1c">0.10</annotation></semantics></math>, which indicates that the current sample features are relatively concentrated with a low degree of diversity. Following a similar procedure, we sample cluster No.<math id="S5.SS1.p3.12.m12.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS1.p3.12.m12.1a"><mn id="S5.SS1.p3.12.m12.1.1" xref="S5.SS1.p3.12.m12.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.12.m12.1b"><cn type="integer" id="S5.SS1.p3.12.m12.1.1.cmml" xref="S5.SS1.p3.12.m12.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.12.m12.1c">1</annotation></semantics></math>, cluster No.<math id="S5.SS1.p3.13.m13.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S5.SS1.p3.13.m13.1a"><mn id="S5.SS1.p3.13.m13.1.1" xref="S5.SS1.p3.13.m13.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.13.m13.1b"><cn type="integer" id="S5.SS1.p3.13.m13.1.1.cmml" xref="S5.SS1.p3.13.m13.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.13.m13.1c">8</annotation></semantics></math>, cluster No.<math id="S5.SS1.p3.14.m14.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S5.SS1.p3.14.m14.1a"><mn id="S5.SS1.p3.14.m14.1.1" xref="S5.SS1.p3.14.m14.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.14.m14.1b"><cn type="integer" id="S5.SS1.p3.14.m14.1.1.cmml" xref="S5.SS1.p3.14.m14.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.14.m14.1c">15</annotation></semantics></math>, and cluster No.<math id="S5.SS1.p3.15.m15.1" class="ltx_Math" alttext="11" display="inline"><semantics id="S5.SS1.p3.15.m15.1a"><mn id="S5.SS1.p3.15.m15.1.1" xref="S5.SS1.p3.15.m15.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.15.m15.1b"><cn type="integer" id="S5.SS1.p3.15.m15.1.1.cmml" xref="S5.SS1.p3.15.m15.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.15.m15.1c">11</annotation></semantics></math> at a lower sampling rate. The metric of <span id="S5.SS1.p3.31.5" class="ltx_text ltx_font_italic">Homogeneity</span> at this point becomes <math id="S5.SS1.p3.16.m16.1" class="ltx_Math" alttext="1.58" display="inline"><semantics id="S5.SS1.p3.16.m16.1a"><mn id="S5.SS1.p3.16.m16.1.1" xref="S5.SS1.p3.16.m16.1.1.cmml">1.58</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.16.m16.1b"><cn type="float" id="S5.SS1.p3.16.m16.1.1.cmml" xref="S5.SS1.p3.16.m16.1.1">1.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.16.m16.1c">1.58</annotation></semantics></math>, while <span id="S5.SS1.p3.31.6" class="ltx_text ltx_font_italic">Content Diversity</span> becomes <math id="S5.SS1.p3.17.m17.1" class="ltx_Math" alttext="0.12" display="inline"><semantics id="S5.SS1.p3.17.m17.1a"><mn id="S5.SS1.p3.17.m17.1.1" xref="S5.SS1.p3.17.m17.1.1.cmml">0.12</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.17.m17.1b"><cn type="float" id="S5.SS1.p3.17.m17.1.1.cmml" xref="S5.SS1.p3.17.m17.1.1">0.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.17.m17.1c">0.12</annotation></semantics></math>. We can see that the balance of the current samples is not significantly improved, since most of the target labels of these clusters are <math id="S5.SS1.p3.18.m18.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S5.SS1.p3.18.m18.1a"><mn id="S5.SS1.p3.18.m18.1.1" xref="S5.SS1.p3.18.m18.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.18.m18.1b"><cn type="integer" id="S5.SS1.p3.18.m18.1.1.cmml" xref="S5.SS1.p3.18.m18.1.1">0</cn></annotation-xml></semantics></math>. Inspired by this, we select clusters with more target labels of <math id="S5.SS1.p3.19.m19.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS1.p3.19.m19.1a"><mn id="S5.SS1.p3.19.m19.1.1" xref="S5.SS1.p3.19.m19.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.19.m19.1b"><cn type="integer" id="S5.SS1.p3.19.m19.1.1.cmml" xref="S5.SS1.p3.19.m19.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.19.m19.1c">1</annotation></semantics></math>, such as cluster No.<math id="S5.SS1.p3.20.m20.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S5.SS1.p3.20.m20.1a"><mn id="S5.SS1.p3.20.m20.1.1" xref="S5.SS1.p3.20.m20.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.20.m20.1b"><cn type="integer" id="S5.SS1.p3.20.m20.1.1.cmml" xref="S5.SS1.p3.20.m20.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.20.m20.1c">6</annotation></semantics></math>, cluster No.<math id="S5.SS1.p3.21.m21.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS1.p3.21.m21.1a"><mn id="S5.SS1.p3.21.m21.1.1" xref="S5.SS1.p3.21.m21.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.21.m21.1b"><cn type="integer" id="S5.SS1.p3.21.m21.1.1.cmml" xref="S5.SS1.p3.21.m21.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.21.m21.1c">10</annotation></semantics></math>, cluster No.<math id="S5.SS1.p3.22.m22.1" class="ltx_Math" alttext="14" display="inline"><semantics id="S5.SS1.p3.22.m22.1a"><mn id="S5.SS1.p3.22.m22.1.1" xref="S5.SS1.p3.22.m22.1.1.cmml">14</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.22.m22.1b"><cn type="integer" id="S5.SS1.p3.22.m22.1.1.cmml" xref="S5.SS1.p3.22.m22.1.1">14</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.22.m22.1c">14</annotation></semantics></math>, and cluster No.<math id="S5.SS1.p3.23.m23.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S5.SS1.p3.23.m23.1a"><mn id="S5.SS1.p3.23.m23.1.1" xref="S5.SS1.p3.23.m23.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.23.m23.1b"><cn type="integer" id="S5.SS1.p3.23.m23.1.1.cmml" xref="S5.SS1.p3.23.m23.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.23.m23.1c">16</annotation></semantics></math> in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(3B). We first sample cluster No.<math id="S5.SS1.p3.24.m24.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S5.SS1.p3.24.m24.1a"><mn id="S5.SS1.p3.24.m24.1.1" xref="S5.SS1.p3.24.m24.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.24.m24.1b"><cn type="integer" id="S5.SS1.p3.24.m24.1.1.cmml" xref="S5.SS1.p3.24.m24.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.24.m24.1c">6</annotation></semantics></math> and No.<math id="S5.SS1.p3.25.m25.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS1.p3.25.m25.1a"><mn id="S5.SS1.p3.25.m25.1.1" xref="S5.SS1.p3.25.m25.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.25.m25.1b"><cn type="integer" id="S5.SS1.p3.25.m25.1.1.cmml" xref="S5.SS1.p3.25.m25.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.25.m25.1c">10</annotation></semantics></math> in appropriate proportions and observe that <span id="S5.SS1.p3.31.7" class="ltx_text ltx_font_italic">Homogeneity</span> changes to <math id="S5.SS1.p3.26.m26.1" class="ltx_Math" alttext="1.77" display="inline"><semantics id="S5.SS1.p3.26.m26.1a"><mn id="S5.SS1.p3.26.m26.1.1" xref="S5.SS1.p3.26.m26.1.1.cmml">1.77</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.26.m26.1b"><cn type="float" id="S5.SS1.p3.26.m26.1.1.cmml" xref="S5.SS1.p3.26.m26.1.1">1.77</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.26.m26.1c">1.77</annotation></semantics></math> with significant improvement, while <span id="S5.SS1.p3.31.8" class="ltx_text ltx_font_italic">Content Diversity</span> (i.e., <math id="S5.SS1.p3.27.m27.1" class="ltx_Math" alttext="0.21" display="inline"><semantics id="S5.SS1.p3.27.m27.1a"><mn id="S5.SS1.p3.27.m27.1.1" xref="S5.SS1.p3.27.m27.1.1.cmml">0.21</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.27.m27.1b"><cn type="float" id="S5.SS1.p3.27.m27.1.1.cmml" xref="S5.SS1.p3.27.m27.1.1">0.21</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.27.m27.1c">0.21</annotation></semantics></math>), which also shows a huge improvement. However, we are still not satisfied with the value of <span id="S5.SS1.p3.31.9" class="ltx_text ltx_font_italic">Content Diversity</span>. We continue to operate on the cluster No.<math id="S5.SS1.p3.28.m28.1" class="ltx_Math" alttext="13" display="inline"><semantics id="S5.SS1.p3.28.m28.1a"><mn id="S5.SS1.p3.28.m28.1.1" xref="S5.SS1.p3.28.m28.1.1.cmml">13</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.28.m28.1b"><cn type="integer" id="S5.SS1.p3.28.m28.1.1.cmml" xref="S5.SS1.p3.28.m28.1.1">13</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.28.m28.1c">13</annotation></semantics></math> and No.<math id="S5.SS1.p3.29.m29.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS1.p3.29.m29.1a"><mn id="S5.SS1.p3.29.m29.1.1" xref="S5.SS1.p3.29.m29.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.29.m29.1b"><cn type="integer" id="S5.SS1.p3.29.m29.1.1.cmml" xref="S5.SS1.p3.29.m29.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.29.m29.1c">5</annotation></semantics></math> in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(3C) because they have more target labels. Finally, the <span id="S5.SS1.p3.31.10" class="ltx_text ltx_font_italic">Homogeneity</span> and <span id="S5.SS1.p3.31.11" class="ltx_text ltx_font_italic">Content Diversity</span> become <math id="S5.SS1.p3.30.m30.1" class="ltx_Math" alttext="1.77" display="inline"><semantics id="S5.SS1.p3.30.m30.1a"><mn id="S5.SS1.p3.30.m30.1.1" xref="S5.SS1.p3.30.m30.1.1.cmml">1.77</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.30.m30.1b"><cn type="float" id="S5.SS1.p3.30.m30.1.1.cmml" xref="S5.SS1.p3.30.m30.1.1">1.77</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.30.m30.1c">1.77</annotation></semantics></math> and <math id="S5.SS1.p3.31.m31.1" class="ltx_Math" alttext="0.64" display="inline"><semantics id="S5.SS1.p3.31.m31.1a"><mn id="S5.SS1.p3.31.m31.1.1" xref="S5.SS1.p3.31.m31.1.1.cmml">0.64</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.31.m31.1b"><cn type="float" id="S5.SS1.p3.31.m31.1.1.cmml" xref="S5.SS1.p3.31.m31.1.1">0.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.31.m31.1c">0.64</annotation></semantics></math>, satisfying our modeling requirements.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.11" class="ltx_p"><span id="S5.SS1.p4.11.1" class="ltx_text ltx_font_bold">Modeling Training and Result Analysis.</span> Since the features and samples for training are ready, we come to the training phase, set the learning rate to <math id="S5.SS1.p4.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S5.SS1.p4.1.m1.1a"><mn id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><cn type="float" id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">0.1</annotation></semantics></math>, and the number of iterations to <math id="S5.SS1.p4.2.m2.2" class="ltx_Math" alttext="2,000" display="inline"><semantics id="S5.SS1.p4.2.m2.2a"><mrow id="S5.SS1.p4.2.m2.2.3.2" xref="S5.SS1.p4.2.m2.2.3.1.cmml"><mn id="S5.SS1.p4.2.m2.1.1" xref="S5.SS1.p4.2.m2.1.1.cmml">2</mn><mo id="S5.SS1.p4.2.m2.2.3.2.1" xref="S5.SS1.p4.2.m2.2.3.1.cmml">,</mo><mn id="S5.SS1.p4.2.m2.2.2" xref="S5.SS1.p4.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.2b"><list id="S5.SS1.p4.2.m2.2.3.1.cmml" xref="S5.SS1.p4.2.m2.2.3.2"><cn type="integer" id="S5.SS1.p4.2.m2.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1">2</cn><cn type="integer" id="S5.SS1.p4.2.m2.2.2.cmml" xref="S5.SS1.p4.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.2c">2,000</annotation></semantics></math> in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(7), and then perform VFL modeling. As shown in <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(8), we can see that the results of the training model are updated in real time for each iteration. Finally, the ACC of the local model is <math id="S5.SS1.p4.3.m3.1" class="ltx_Math" alttext="0.68" display="inline"><semantics id="S5.SS1.p4.3.m3.1a"><mn id="S5.SS1.p4.3.m3.1.1" xref="S5.SS1.p4.3.m3.1.1.cmml">0.68</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.3.m3.1b"><cn type="float" id="S5.SS1.p4.3.m3.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1">0.68</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.3.m3.1c">0.68</annotation></semantics></math>, and the AUC is <math id="S5.SS1.p4.4.m4.1" class="ltx_Math" alttext="0.60" display="inline"><semantics id="S5.SS1.p4.4.m4.1a"><mn id="S5.SS1.p4.4.m4.1.1" xref="S5.SS1.p4.4.m4.1.1.cmml">0.60</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.4.m4.1b"><cn type="float" id="S5.SS1.p4.4.m4.1.1.cmml" xref="S5.SS1.p4.4.m4.1.1">0.60</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.4.m4.1c">0.60</annotation></semantics></math>. The vertical federated model has an ACC of <math id="S5.SS1.p4.5.m5.1" class="ltx_Math" alttext="0.75" display="inline"><semantics id="S5.SS1.p4.5.m5.1a"><mn id="S5.SS1.p4.5.m5.1.1" xref="S5.SS1.p4.5.m5.1.1.cmml">0.75</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.5.m5.1b"><cn type="float" id="S5.SS1.p4.5.m5.1.1.cmml" xref="S5.SS1.p4.5.m5.1.1">0.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.5.m5.1c">0.75</annotation></semantics></math> and an AUC of <math id="S5.SS1.p4.6.m6.1" class="ltx_Math" alttext="0.69" display="inline"><semantics id="S5.SS1.p4.6.m6.1a"><mn id="S5.SS1.p4.6.m6.1.1" xref="S5.SS1.p4.6.m6.1.1.cmml">0.69</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.6.m6.1b"><cn type="float" id="S5.SS1.p4.6.m6.1.1.cmml" xref="S5.SS1.p4.6.m6.1.1">0.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.6.m6.1c">0.69</annotation></semantics></math>. The results show that our trained VFL model achieves better performance than the host’s local model. However, the current AUC is still below <math id="S5.SS1.p4.7.m7.1" class="ltx_Math" alttext="0.7" display="inline"><semantics id="S5.SS1.p4.7.m7.1a"><mn id="S5.SS1.p4.7.m7.1.1" xref="S5.SS1.p4.7.m7.1.1.cmml">0.7</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.7.m7.1b"><cn type="float" id="S5.SS1.p4.7.m7.1.1.cmml" xref="S5.SS1.p4.7.m7.1.1">0.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.7.m7.1c">0.7</annotation></semantics></math>. We follow the above procedure to further improve the model performance, such as adding more external features required by the host and sampling other clusters for model training. Finally, the ACC of the local model reaches <math id="S5.SS1.p4.8.m8.1" class="ltx_Math" alttext="0.78" display="inline"><semantics id="S5.SS1.p4.8.m8.1a"><mn id="S5.SS1.p4.8.m8.1.1" xref="S5.SS1.p4.8.m8.1.1.cmml">0.78</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.8.m8.1b"><cn type="float" id="S5.SS1.p4.8.m8.1.1.cmml" xref="S5.SS1.p4.8.m8.1.1">0.78</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.8.m8.1c">0.78</annotation></semantics></math> and its AUC reaches <math id="S5.SS1.p4.9.m9.1" class="ltx_Math" alttext="0.64" display="inline"><semantics id="S5.SS1.p4.9.m9.1a"><mn id="S5.SS1.p4.9.m9.1.1" xref="S5.SS1.p4.9.m9.1.1.cmml">0.64</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.9.m9.1b"><cn type="float" id="S5.SS1.p4.9.m9.1.1.cmml" xref="S5.SS1.p4.9.m9.1.1">0.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.9.m9.1c">0.64</annotation></semantics></math>, while the ACC of the VFL model is <math id="S5.SS1.p4.10.m10.1" class="ltx_Math" alttext="0.79" display="inline"><semantics id="S5.SS1.p4.10.m10.1a"><mn id="S5.SS1.p4.10.m10.1.1" xref="S5.SS1.p4.10.m10.1.1.cmml">0.79</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.10.m10.1b"><cn type="float" id="S5.SS1.p4.10.m10.1.1.cmml" xref="S5.SS1.p4.10.m10.1.1">0.79</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.10.m10.1c">0.79</annotation></semantics></math> and its AUC is <math id="S5.SS1.p4.11.m11.1" class="ltx_Math" alttext="0.75" display="inline"><semantics id="S5.SS1.p4.11.m11.1a"><mn id="S5.SS1.p4.11.m11.1.1" xref="S5.SS1.p4.11.m11.1.1.cmml">0.75</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.11.m11.1b"><cn type="float" id="S5.SS1.p4.11.m11.1.1.cmml" xref="S5.SS1.p4.11.m11.1.1">0.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.11.m11.1c">0.75</annotation></semantics></math>.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p id="S5.SS1.p5.8" class="ltx_p"><span id="S5.SS1.p5.8.1" class="ltx_text ltx_font_bold">Model Inference.</span> After the model training, we then come to the model inference stage by clicking the “start predict” button. We observe that <math id="S5.SS1.p5.1.m1.1" class="ltx_Math" alttext="6798" display="inline"><semantics id="S5.SS1.p5.1.m1.1a"><mn id="S5.SS1.p5.1.m1.1.1" xref="S5.SS1.p5.1.m1.1.1.cmml">6798</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.1.m1.1b"><cn type="integer" id="S5.SS1.p5.1.m1.1.1.cmml" xref="S5.SS1.p5.1.m1.1.1">6798</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.1.m1.1c">6798</annotation></semantics></math> records require further VFL inference, and the remaining <math id="S5.SS1.p5.2.m2.1" class="ltx_Math" alttext="8202" display="inline"><semantics id="S5.SS1.p5.2.m2.1a"><mn id="S5.SS1.p5.2.m2.1.1" xref="S5.SS1.p5.2.m2.1.1.cmml">8202</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.2.m2.1b"><cn type="integer" id="S5.SS1.p5.2.m2.1.1.cmml" xref="S5.SS1.p5.2.m2.1.1">8202</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.2.m2.1c">8202</annotation></semantics></math> samples do not require calling the VFL model <a href="#S5.F8" title="Figure 8 ‣ 5.1. Usage Scenario ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>(9) (i.e., the rejection rate is <math id="S5.SS1.p5.3.m3.1" class="ltx_Math" alttext="54.6" display="inline"><semantics id="S5.SS1.p5.3.m3.1a"><mn id="S5.SS1.p5.3.m3.1.1" xref="S5.SS1.p5.3.m3.1.1.cmml">54.6</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.3.m3.1b"><cn type="float" id="S5.SS1.p5.3.m3.1.1.cmml" xref="S5.SS1.p5.3.m3.1.1">54.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.3.m3.1c">54.6</annotation></semantics></math>%). To evaluate the efficacy of our interactive sampling strategy, we run the VFL model on the samples that do not need to invoke the VFL model to obtain their labels generated by the VFL model. We find that the results of federated inference for <math id="S5.SS1.p5.4.m4.1" class="ltx_Math" alttext="7782" display="inline"><semantics id="S5.SS1.p5.4.m4.1a"><mn id="S5.SS1.p5.4.m4.1.1" xref="S5.SS1.p5.4.m4.1.1.cmml">7782</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.4.m4.1b"><cn type="integer" id="S5.SS1.p5.4.m4.1.1.cmml" xref="S5.SS1.p5.4.m4.1.1">7782</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.4.m4.1c">7782</annotation></semantics></math> samples are the same as the those of the local model (i.e., a hit rate of <math id="S5.SS1.p5.5.m5.1" class="ltx_Math" alttext="94" display="inline"><semantics id="S5.SS1.p5.5.m5.1a"><mn id="S5.SS1.p5.5.m5.1.1" xref="S5.SS1.p5.5.m5.1.1.cmml">94</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.5.m5.1b"><cn type="integer" id="S5.SS1.p5.5.m5.1.1.cmml" xref="S5.SS1.p5.5.m5.1.1">94</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.5.m5.1c">94</annotation></semantics></math>%), indicating that our interactive feature and sample selection strategy helps improve the efficacy of VFL modeling. As a comparison, we also use the VFL model to predict samples that require further VFL inference and find that the VFL model results for the <math id="S5.SS1.p5.6.m6.1" class="ltx_Math" alttext="4707" display="inline"><semantics id="S5.SS1.p5.6.m6.1a"><mn id="S5.SS1.p5.6.m6.1.1" xref="S5.SS1.p5.6.m6.1.1.cmml">4707</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.6.m6.1b"><cn type="integer" id="S5.SS1.p5.6.m6.1.1.cmml" xref="S5.SS1.p5.6.m6.1.1">4707</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.6.m6.1c">4707</annotation></semantics></math> samples are the same as those of the local model. Compared to <math id="S5.SS1.p5.7.m7.1" class="ltx_Math" alttext="94" display="inline"><semantics id="S5.SS1.p5.7.m7.1a"><mn id="S5.SS1.p5.7.m7.1.1" xref="S5.SS1.p5.7.m7.1.1.cmml">94</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.7.m7.1b"><cn type="integer" id="S5.SS1.p5.7.m7.1.1.cmml" xref="S5.SS1.p5.7.m7.1.1">94</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.7.m7.1c">94</annotation></semantics></math>% hit rate for the unnecessary samples, <math id="S5.SS1.p5.8.m8.1" class="ltx_Math" alttext="69.2" display="inline"><semantics id="S5.SS1.p5.8.m8.1a"><mn id="S5.SS1.p5.8.m8.1.1" xref="S5.SS1.p5.8.m8.1.1.cmml">69.2</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.8.m8.1b"><cn type="float" id="S5.SS1.p5.8.m8.1.1.cmml" xref="S5.SS1.p5.8.m8.1.1">69.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.8.m8.1c">69.2</annotation></semantics></math>% hit rate suggests that a larger proportion of samples is not confident in their labels. For these samples, we need to fine-tune more good features and train a better prediction model.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Quantitative Experiment</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We also conduct quantitative experiments to compare the effect of <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span> with other cases that do not use interactive feature selection and sample selection. As shown in <a href="#S5.T1" title="Table 1 ‣ 5.2. Quantitative Experiment ‣ 5. Evaluation ‣ VFLens: Co-design the Modeling Process for Efficient Vertical Federated Learning via Visualization" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>, we can analyze that using only local data for modeling (Exp.1), the training will be very fast because no cryptographic operations are needed. However, the accuracy of the model will be very low due to the poor features. In Exp.2, all external features provided by the data provider are selected for federated modeling to obtain a better model. However, in real business scenarios, the cost spent on federated modeling is proportional to the sample size involved in the modeling process. So there is no need to select the entire aligned data for federated modeling. From the perspective of data reduction and reducing unnecessary costs, the corresponding (Exp.3 – 4) is about <span id="S5.SS2.p1.1.2" class="ltx_text ltx_font_italic">VFLens</span>’s ability to use local feature selection and federated feature selection to eliminate some redundant features and also to reduce the tie of fine-tuning the model by domain experts. In Exp.5, we further use <span id="S5.SS2.p1.1.3" class="ltx_text ltx_font_italic">VFLens</span> for sample selection based on Exp.4, and we can see that the accuracy of the model is not significantly reduced, demonstrating the practical value of <span id="S5.SS2.p1.1.4" class="ltx_text ltx_font_italic">VFLens</span> in business scenarios.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Training time(s) of local model and federated learning model on <span id="S5.T1.6.1" class="ltx_text ltx_font_italic">Default Credits Prediction</span> data in different situations.</figcaption>
<table id="S5.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.4.5.1" class="ltx_tr">
<th id="S5.T1.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Experiment id</th>
<th id="S5.T1.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Local feature</th>
<th id="S5.T1.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">FL feature</th>
<th id="S5.T1.4.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Sample number</th>
<th id="S5.T1.4.5.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">AUC</th>
<th id="S5.T1.4.5.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">ACC</th>
<th id="S5.T1.4.5.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Time</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.1.1" class="ltx_tr">
<td id="S5.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S5.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">All(20/20)</td>
<td id="S5.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">None(0/30)</td>
<td id="S5.T1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">10000</td>
<td id="S5.T1.1.1.6" class="ltx_td ltx_align_left ltx_border_t">0.68</td>
<td id="S5.T1.1.1.7" class="ltx_td ltx_align_left ltx_border_t">0.70</td>
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S5.T1.1.1.1.m1.1" class="ltx_Math" alttext="&lt;1" display="inline"><semantics id="S5.T1.1.1.1.m1.1a"><mrow id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml"><mi id="S5.T1.1.1.1.m1.1.1.2" xref="S5.T1.1.1.1.m1.1.1.2.cmml"></mi><mo id="S5.T1.1.1.1.m1.1.1.1" xref="S5.T1.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S5.T1.1.1.1.m1.1.1.3" xref="S5.T1.1.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><apply id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"><lt id="S5.T1.1.1.1.m1.1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S5.T1.1.1.1.m1.1.1.2.cmml" xref="S5.T1.1.1.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.T1.1.1.1.m1.1.1.3.cmml" xref="S5.T1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">&lt;1</annotation></semantics></math> min</td>
</tr>
<tr id="S5.T1.2.2" class="ltx_tr">
<td id="S5.T1.2.2.2" class="ltx_td ltx_align_center">2</td>
<td id="S5.T1.2.2.3" class="ltx_td ltx_align_center">All(20/20)</td>
<td id="S5.T1.2.2.4" class="ltx_td ltx_align_center">All(30/30)</td>
<td id="S5.T1.2.2.5" class="ltx_td ltx_align_center">10000</td>
<td id="S5.T1.2.2.6" class="ltx_td ltx_align_left">0.78</td>
<td id="S5.T1.2.2.7" class="ltx_td ltx_align_left">0.82</td>
<td id="S5.T1.2.2.1" class="ltx_td ltx_align_center">
<math id="S5.T1.2.2.1.m1.1" class="ltx_Math" alttext="&gt;1" display="inline"><semantics id="S5.T1.2.2.1.m1.1a"><mrow id="S5.T1.2.2.1.m1.1.1" xref="S5.T1.2.2.1.m1.1.1.cmml"><mi id="S5.T1.2.2.1.m1.1.1.2" xref="S5.T1.2.2.1.m1.1.1.2.cmml"></mi><mo id="S5.T1.2.2.1.m1.1.1.1" xref="S5.T1.2.2.1.m1.1.1.1.cmml">&gt;</mo><mn id="S5.T1.2.2.1.m1.1.1.3" xref="S5.T1.2.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.1.m1.1b"><apply id="S5.T1.2.2.1.m1.1.1.cmml" xref="S5.T1.2.2.1.m1.1.1"><gt id="S5.T1.2.2.1.m1.1.1.1.cmml" xref="S5.T1.2.2.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S5.T1.2.2.1.m1.1.1.2.cmml" xref="S5.T1.2.2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.T1.2.2.1.m1.1.1.3.cmml" xref="S5.T1.2.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.1.m1.1c">&gt;1</annotation></semantics></math> day</td>
</tr>
<tr id="S5.T1.3.3" class="ltx_tr">
<td id="S5.T1.3.3.2" class="ltx_td ltx_align_center">3</td>
<td id="S5.T1.3.3.3" class="ltx_td ltx_align_center">Part(13/20)</td>
<td id="S5.T1.3.3.4" class="ltx_td ltx_align_center">All(30/30)</td>
<td id="S5.T1.3.3.5" class="ltx_td ltx_align_center">10000</td>
<td id="S5.T1.3.3.6" class="ltx_td ltx_align_left">0.78</td>
<td id="S5.T1.3.3.7" class="ltx_td ltx_align_left">0.80</td>
<td id="S5.T1.3.3.1" class="ltx_td ltx_align_center">
<math id="S5.T1.3.3.1.m1.1" class="ltx_Math" alttext="&gt;12" display="inline"><semantics id="S5.T1.3.3.1.m1.1a"><mrow id="S5.T1.3.3.1.m1.1.1" xref="S5.T1.3.3.1.m1.1.1.cmml"><mi id="S5.T1.3.3.1.m1.1.1.2" xref="S5.T1.3.3.1.m1.1.1.2.cmml"></mi><mo id="S5.T1.3.3.1.m1.1.1.1" xref="S5.T1.3.3.1.m1.1.1.1.cmml">&gt;</mo><mn id="S5.T1.3.3.1.m1.1.1.3" xref="S5.T1.3.3.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.1.m1.1b"><apply id="S5.T1.3.3.1.m1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1"><gt id="S5.T1.3.3.1.m1.1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S5.T1.3.3.1.m1.1.1.2.cmml" xref="S5.T1.3.3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.T1.3.3.1.m1.1.1.3.cmml" xref="S5.T1.3.3.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.1.m1.1c">&gt;12</annotation></semantics></math> hours</td>
</tr>
<tr id="S5.T1.4.4" class="ltx_tr">
<td id="S5.T1.4.4.2" class="ltx_td ltx_align_center">4</td>
<td id="S5.T1.4.4.3" class="ltx_td ltx_align_center">Part(13/20)</td>
<td id="S5.T1.4.4.4" class="ltx_td ltx_align_center">Part(21/30)</td>
<td id="S5.T1.4.4.5" class="ltx_td ltx_align_center">10000</td>
<td id="S5.T1.4.4.6" class="ltx_td ltx_align_left">0.77</td>
<td id="S5.T1.4.4.7" class="ltx_td ltx_align_left">0.80</td>
<td id="S5.T1.4.4.1" class="ltx_td ltx_align_center">
<math id="S5.T1.4.4.1.m1.1" class="ltx_Math" alttext="&gt;6" display="inline"><semantics id="S5.T1.4.4.1.m1.1a"><mrow id="S5.T1.4.4.1.m1.1.1" xref="S5.T1.4.4.1.m1.1.1.cmml"><mi id="S5.T1.4.4.1.m1.1.1.2" xref="S5.T1.4.4.1.m1.1.1.2.cmml"></mi><mo id="S5.T1.4.4.1.m1.1.1.1" xref="S5.T1.4.4.1.m1.1.1.1.cmml">&gt;</mo><mn id="S5.T1.4.4.1.m1.1.1.3" xref="S5.T1.4.4.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.1.m1.1b"><apply id="S5.T1.4.4.1.m1.1.1.cmml" xref="S5.T1.4.4.1.m1.1.1"><gt id="S5.T1.4.4.1.m1.1.1.1.cmml" xref="S5.T1.4.4.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S5.T1.4.4.1.m1.1.1.2.cmml" xref="S5.T1.4.4.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.T1.4.4.1.m1.1.1.3.cmml" xref="S5.T1.4.4.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.1.m1.1c">&gt;6</annotation></semantics></math> hours</td>
</tr>
<tr id="S5.T1.4.6.1" class="ltx_tr">
<td id="S5.T1.4.6.1.1" class="ltx_td ltx_align_center ltx_border_b">5</td>
<td id="S5.T1.4.6.1.2" class="ltx_td ltx_align_center ltx_border_b">Part(13/20)</td>
<td id="S5.T1.4.6.1.3" class="ltx_td ltx_align_center ltx_border_b">Part(21/30)</td>
<td id="S5.T1.4.6.1.4" class="ltx_td ltx_align_center ltx_border_b">2100</td>
<td id="S5.T1.4.6.1.5" class="ltx_td ltx_align_left ltx_border_b">0.75</td>
<td id="S5.T1.4.6.1.6" class="ltx_td ltx_align_left ltx_border_b">0.79</td>
<td id="S5.T1.4.6.1.7" class="ltx_td ltx_align_center ltx_border_b">2 hours</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Discussion and Limitation</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We conduct semi-structured interviews with all experts (E1 – E5) to assess the efficacy of <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span> and to determine whether our approach could help them improve the efficiency of VFL modeling.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">System Performance.</span> All experts agreed that <span id="S6.p2.1.2" class="ltx_text ltx_font_italic">VFLens</span> demonstrates a straightforward data science process with an intuitive visual design and practical implications. “<span id="S6.p2.1.3" class="ltx_text ltx_font_italic">The system is very useful for hosts to assess the quality of their data and to further evaluate how much resources are needed for VFL modeling,</span>” said E1. Our system has the potential to help a variety of commercial enterprises and sectors build economically usable VFL models. Considering the balance between resource input and model accuracy, the results seem to be quite good. <span id="S6.p2.1.4" class="ltx_text ltx_font_italic">VFLens</span> is the first system that attempts to address realistic pain points across business sectors, which will go a long way to “<span id="S6.p2.1.5" class="ltx_text ltx_font_italic">enrich and complement existing federated learning frameworks</span>”. In discussing with our collaborating experts what inspired them most about our system, E2 said that they were most impressed with the fine-tuning and interactive sampling of local data features based on dimensionality reduction results, which “<span id="S6.p2.1.6" class="ltx_text ltx_font_italic">fits our sense and it was very valuable.</span>”</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p"><span id="S6.p3.1.1" class="ltx_text ltx_font_bold">Visual Design and Learnability.</span> We draw from observational studies of experts working routinely in real-world scenario to inform the system design and classicial interfaces used in commercial federated learning products (e.g., <span id="S6.p3.1.2" class="ltx_text ltx_font_italic">FateBoard</span> in <span id="S6.p3.1.3" class="ltx_text ltx_font_italic">FATE</span> <cite class="ltx_cite ltx_citemacro_citep">(Fan, <a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite>). For example, the matrix design visually presents the feature importance provided by different automatic feature selection algorithms. The model performance represented by various metrics and the sample distribution represented by the histogram design are familiar visual metaphors in traditional data science pipelines and analysis. Experts commented, “<span id="S6.p3.1.4" class="ltx_text ltx_font_italic">we can quickly get used to visual encoding because the interactions are the same as in traditional modeling.</span>” Specifically, after a briefly introduction to each view and its capabilities, the experts developed customized exploration paths for interactive VFL modeling and inference.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold">Generalizability and Scalability.</span> In this work, we only show our pipeline using LR-based VFL. Tree-based models such as <span id="S6.p4.1.2" class="ltx_text ltx_font_italic">XGBoost</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen and Guestrin, <a href="#bib.bib11" title="" class="ltx_ref">2016</a>)</cite> and <span id="S6.p4.1.3" class="ltx_text ltx_font_italic">Random Forest</span> <cite class="ltx_cite ltx_citemacro_citep">(Ho, <a href="#bib.bib20" title="" class="ltx_ref">1995</a>)</cite> are more commonly used in various commercial domains. Incorporating such models into <span id="S6.p4.1.4" class="ltx_text ltx_font_italic">VFLens</span> is not a difficult task. Nevertheless, the visualization design of the front-end may require unavoidable alternations, as the underlying models may introduce the necessary specific information to be checked. Notably, if other types of models or even deep learning models are used, the deployment and implementation of VFL versions of the models and a detailed discussion of model performance comparisons are major concerns for future work.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p"><span id="S6.p5.1.1" class="ltx_text ltx_font_bold">Contributions Over Previous Work.</span> Compared to previous works, our system has inspired experts in many ways. They commented that when they utilize VFL in real-world scenarios, they often experience poor data quality or lack of sufficient data attributes when a large enterprise group consists of different affiliated business units that are unable to share data. Some business units even lack data labels. All of these real-world problems pose a huge challenge for VFL modeling. Experts said that if they want to leverage external data sources from the Guest using VFL, <span id="S6.p5.1.2" class="ltx_text ltx_font_italic">VFLens</span> can greatly help them sort out the current data quality before modeling. With an understanding of overall data and feature quality, experts can better understand whether they need to call on external data sources for VFL modeling. “<span id="S6.p5.1.3" class="ltx_text ltx_font_italic">VFLens could help business units in companies assess data quality, such as data fill rate, label fill rate,</span>” said E1, adding that this needs to be done before FL modeling. Also, <span id="S6.p5.1.4" class="ltx_text ltx_font_italic">VFLens</span> can help experts understand data samples and features before modeling, which has high application value in real-world scenarios.</p>
</div>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p"><span id="S6.p6.1.1" class="ltx_text ltx_font_bold">Limitation.</span> Our work has several limitations. First, interactive samplings of predicted clusters relies heavily on user’s experience and domain knowledge, introducing uncertainty in sample selection. We should provide more intelligent guideline to help users perform interactive sampling more efficiently and confidently. Second, we only utilize representative metrics such as <span id="S6.p6.1.2" class="ltx_text ltx_font_italic">accuracy</span> and <span id="S6.p6.1.3" class="ltx_text ltx_font_italic">AUC</span> to compare different versions of the model. We did not consider using the internal information of the models themselves, such as gradient distribution and weight information, which may be more critical when employing tree-based or deep learning models.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion and Future work</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this study, we present <span id="S7.p1.1.1" class="ltx_text ltx_font_italic">VFLens</span>, a visual analytics system for interactive VFL modeling and inference, which improves VFL modeling efficiency by supporting domain experts to co-design internal features and interactively manipulate sample spaces. A usage scenario, a quantitative experiment, and expert feedback confirm the efficacy of <span id="S7.p1.1.2" class="ltx_text ltx_font_italic">VFLens</span>. In the future, we will combine more models with the FL version to enable experts to achieve better prediction results. Also, we will introduce more sampling methods to reduce the impact of anomalous samples on training and further discuss the design space when involving other types of models, such as tree-based or deep learning-based models.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We are grateful for the valuable feedback and comments provided by the anonymous reviewers. This work is partially supported by the Research Start-up Fund of ShanghaiTech University and HKUST-WeBank Joint Laboratory Project Grant No.: WEB19EG01-d.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Altmann et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
André Altmann, Laura
Toloşi, Oliver Sander, and Thomas
Lengauer. 2010.

</span>
<span class="ltx_bibblock">Permutation importance: a corrected feature
importance measure.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">Bioinformatics</em> 26,
10 (2010), 1340–1347.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aphinyanaphongs et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Yindalon Aphinyanaphongs,
Lawrence D Fu, Zhiguo Li,
Eric R Peskin, Efstratios Efstathiadis,
Constantin F Aliferis, and Alexander
Statnikov. 2014.

</span>
<span class="ltx_bibblock">A comprehensive empirical comparison of modern
supervised classification and feature selection methods for text
categorization.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Journal of the Association for Information
Science and Technology</em> 65, 10
(2014), 1964–1987.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arthur and Vassilvitskii (2006)</span>
<span class="ltx_bibblock">
David Arthur and Sergei
Vassilvitskii. 2006.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">k-means++: The advantages of careful
seeding</em>.

</span>
<span class="ltx_bibblock">Technical Report.
Stanford.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blum and Langley (1997)</span>
<span class="ltx_bibblock">
Avrim L Blum and Pat
Langley. 1997.

</span>
<span class="ltx_bibblock">Selection of relevant features and examples in
machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence</em>
97, 1-2 (1997),
245–271.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brendan McMahan et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
H. Brendan McMahan,
Eider Moore, Daniel Ramage,
Seth Hampson, and Blaise Agüera y
Arcas. 2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks
from decentralized data. In <em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
20th International Conference on Artificial Intelligence and Statistics,
AISTATS 2017</em>.

</span>
<span class="ltx_bibblock">
arXiv:1602.05629

<a target="_blank" href="https://arxiv.org/pdf/1602.05629.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1602.05629.pdf</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chandrashekar and Sahin (2014)</span>
<span class="ltx_bibblock">
Girish Chandrashekar and
Ferat Sahin. 2014.

</span>
<span class="ltx_bibblock">A survey on feature selection methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Electrical Engineering</em>
40, 1 (2014),
16–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chatzimparmpas et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Angelos Chatzimparmpas,
Rafael M Martins, Kostiantyn Kucher,
and Andreas Kerren. 2021.

</span>
<span class="ltx_bibblock">FeatureEnVi: Visual Analytics for Feature
Engineering Using Stepwise Selection and Semi-Automatic Extraction
Approaches.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.14539</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Hao Chen, Zhicong Huang,
Kim Laine, and Peter Rindal.
2018.

</span>
<span class="ltx_bibblock">Labeled PSI from fully homomorphic encryption with
malicious security. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 ACM
SIGSAC Conference on Computer and Communications Security</em>.
1223–1237.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Hao Chen, Kim Laine,
and Peter Rindal. 2017.

</span>
<span class="ltx_bibblock">Fast private set intersection from homomorphic
encryption. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security</em>.
1243–1255.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Guestrin (2016)</span>
<span class="ltx_bibblock">
Tianqi Chen and Carlos
Guestrin. 2016.

</span>
<span class="ltx_bibblock">Xgboost: A scalable tree boosting system. In
<em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd acm sigkdd international
conference on knowledge discovery and data mining</em>.
785–794.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Kewei Cheng, Tao Fan,
Yilun Jin, Yang Liu,
Tianjian Chen, Dimitrios Papadopoulos,
and Qiang Yang. 2021.

</span>
<span class="ltx_bibblock">Secureboost: A lossless federated learning
framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan (2018)</span>
<span class="ltx_bibblock">
Tao Fan. 2018.

</span>
<span class="ltx_bibblock">FATE-Board_FATE’s Visualization Toolkit.

</span>
<span class="ltx_bibblock">, 11 pages.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://github.com/FederatedAI/FATE-Board" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/FederatedAI/FATE-Board</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fedai (2019)</span>
<span class="ltx_bibblock">
Fedai. 2019.

</span>
<span class="ltx_bibblock">Computer vision Platform powered by Federated
Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.fedai.org/cases/computer-vision-platform-powered-by-federated-learning/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.fedai.org/cases/computer-vision-platform-powered-by-federated-learning/</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Forman et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2003)</span>
<span class="ltx_bibblock">
George Forman et al<span id="bib.bib15.3.1" class="ltx_text">.</span>
2003.

</span>
<span class="ltx_bibblock">An extensive empirical study of feature selection
metrics for text classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.4.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em> 3,
Mar (2003), 1289–1305.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guyon and Elisseeff (2003)</span>
<span class="ltx_bibblock">
Isabelle Guyon and
André Elisseeff. 2003.

</span>
<span class="ltx_bibblock">An introduction to variable and feature selection.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Journal of machine learning research</em>
3, Mar (2003),
1157–1182.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Halevy et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Alon Halevy, Peter
Norvig, and Fernando Pereira.
2009.

</span>
<span class="ltx_bibblock">The unreasonable effectiveness of data.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>
24, 2 (2009),
8–12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka
Rao, Rajiv Mathews, Swaroop Ramaswamy,
Françoise Beaufays, Sean
Augenstein, Hubert Eichner, Chloé
Kiddon, and Daniel Ramage.
2018.

</span>
<span class="ltx_bibblock">Federated Learning for Mobile Keyboard
Prediction.

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">arXiv:1811.03604

<a target="_blank" href="http://arxiv.org/abs/1811.03604" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1811.03604</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardy et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Stephen Hardy, Wilko
Henecka, Hamish Ivey-Law, Richard Nock,
Giorgio Patrini, Guillaume Smith, and
Brian Thorne. 2017.

</span>
<span class="ltx_bibblock">Private federated learning on vertically
partitioned data via entity resolution and additively homomorphic
encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.10677</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho (1995)</span>
<span class="ltx_bibblock">
Tin Kam Ho.
1995.

</span>
<span class="ltx_bibblock">Random decision forests. In
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of 3rd international conference on
document analysis and recognition</em>, Vol. 1. IEEE,
278–282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hohman et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Fred Hohman, Kanit
Wongsuphasawat, Mary Beth Kery, and
Kayur Patel. 2020.

</span>
<span class="ltx_bibblock">Understanding and visualizing data iteration in
machine learning. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 CHI
Conference on Human Factors in Computing Systems</em>. 1–13.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Yan Huang, David Evans,
and Jonathan Katz. 2012.

</span>
<span class="ltx_bibblock">Private set intersection: Are garbled circuits
better than custom protocols?. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">NDSS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jing et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Qinghe Jing, Weiyan Wang,
Junxue Zhang, Han Tian, and
Kai Chen. 2019.

</span>
<span class="ltx_bibblock">Quantifying the performance of federated transfer
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.12795</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jović et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Alan Jović, Karla
Brkić, and Nikola Bogunović.
2015.

</span>
<span class="ltx_bibblock">A review of feature selection methods with
applications. In <em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">2015 38th international
convention on information and communication technology, electronics and
microelectronics (MIPRO)</em>. Ieee, 1200–1205.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan
McMahan, Brendan Avent, Aurélien
Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, et al<span id="bib.bib25.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.04977</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kohavi and John (1997)</span>
<span class="ltx_bibblock">
Ron Kohavi and George H
John. 1997.

</span>
<span class="ltx_bibblock">Wrappers for feature subset selection.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence</em>
97, 1-2 (1997),
273–324.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Anran Li, Lan Zhang,
Juntao Tan, Yaxuan Qin,
Junhao Wang, and Xiang-Yang Li.
2021c.

</span>
<span class="ltx_bibblock">Sample-level Data Selection for Federated
Learning. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2021-IEEE Conference on
Computer Communications</em>. IEEE, 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2021d)</span>
<span class="ltx_bibblock">
Anran Li, Lan Zhang,
Juntao Tan, Yaxuan Qin,
Junhao Wang, and Xiang-Yang Li.
2021d.

</span>
<span class="ltx_bibblock">Sample-level Data Selection for Federated
Learning. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2021 - IEEE Conference
on Computer Communications</em>. 1–10.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/INFOCOM42981.2021.9488723" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/INFOCOM42981.2021.9488723</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Qinbin Li, Bingsheng He,
and Dawn Song. 2021a.

</span>
<span class="ltx_bibblock">Model-Contrastive Federated Learning. In
<em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>. 10713–10722.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Quan Li, Kristanto Sean
Njotoprawiro, Hammad Haleem, Qiaoan
Chen, Chris Yi, and Xiaojuan Ma.
2018a.

</span>
<span class="ltx_bibblock">Embeddingvis: A visual analytics approach to
comparative network embedding inspection. In <em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">2018
IEEE Conference on Visual Analytics Science and Technology (VAST)</em>. IEEE,
48–59.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Quan Li, Xiguang Wei,
Huanbin Lin, Yang Liu,
Tianjian Chen, and Xiaojuan Ma.
2021b.

</span>
<span class="ltx_bibblock">Inspecting the Running Process of Horizontal
Federated Learning via Visual Analytics.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Visualization and
Computer Graphics</em> (2021), 1–1.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TVCG.2021.3074010" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TVCG.2021.3074010</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen,
and Bingsheng He. 2020.

</span>
<span class="ltx_bibblock">Practical federated gradient boosting decision
trees. In <em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em>, Vol. 34.
4642–4649.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu,
Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith.
2018b.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.06127</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Jun (2006)</span>
<span class="ltx_bibblock">
Zhang Li and Guo Jun.
2006.

</span>
<span class="ltx_bibblock">A method for the selection of training samples
based on boundary samples.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Journal of Beijing University of Posts and
Telecommunications</em> 29, 4
(2006), 77.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehrabi et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ninareh Mehrabi, Fred
Morstatter, Nripsuta Saxena, Kristina
Lerman, and Aram Galstyan.
2021.

</span>
<span class="ltx_bibblock">A survey on bias and fairness in machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>
54, 6 (2021),
1–35.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mike (2018)</span>
<span class="ltx_bibblock">
Mike. 2018.

</span>
<span class="ltx_bibblock">Federated learning: distributed machine learning
with data locality and privacy.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://blog.fastforwardlabs.com/2018/11/14/federated-learning.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://blog.fastforwardlabs.com/2018/11/14/federated-learning.html</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohri et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mehryar Mohri, Gary
Sivek, and Ananda Theertha Suresh.
2019.

</span>
<span class="ltx_bibblock">Agnostic federated learning. In
<em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.
PMLR, 4615–4625.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rivest and Dusse (1992)</span>
<span class="ltx_bibblock">
Ronald Rivest and S
Dusse. 1992.

</span>
<span class="ltx_bibblock">The MD5 message-digest algorithm.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rojek (2018)</span>
<span class="ltx_bibblock">
Marcin Rojek.
2018.

</span>
<span class="ltx_bibblock">Devices learning from each other ? See it live this
September at AI Summit in San Francisco !

</span>
<span class="ltx_bibblock">, 7–11 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roschewitz et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
David Roschewitz,
Mary-Anne Hartley, Luca Corinzia, and
Martin Jaggi. 2021.

</span>
<span class="ltx_bibblock">IFedAvg: Interpretable Data-Interoperability for
Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06580</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sambasivan et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Nithya Sambasivan, Shivani
Kapania, Hannah Highfill, Diana Akrong,
Praveen Paritosh, and Lora M Aroyo.
2021.

</span>
<span class="ltx_bibblock">“Everyone wants to do the model work, not the
data work”: Data Cascades in High-Stakes AI. In
<em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">proceedings of the 2021 CHI Conference on Human
Factors in Computing Systems</em>. 1–15.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scornet (2020)</span>
<span class="ltx_bibblock">
Erwan Scornet.
2020.

</span>
<span class="ltx_bibblock">Trees, forests, and impurity-based variable
importance.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.04295</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seo and Shneiderman (2005)</span>
<span class="ltx_bibblock">
Jinwook Seo and Ben
Shneiderman. 2005.

</span>
<span class="ltx_bibblock">A rank-by-feature framework for interactive
exploration of multidimensional data.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Information visualization</em>
4, 2 (2005),
96–113.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Syakur et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
MA Syakur, BK Khotimah,
EMS Rochman, and Budi Dwi Satoto.
2018.

</span>
<span class="ltx_bibblock">Integration k-means clustering method and elbow
method for identification of the best customer profile cluster. In
<em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">IOP conference series: materials science and
engineering</em>, Vol. 336. IOP Publishing,
012017.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vepakomma et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Praneeth Vepakomma,
Otkrist Gupta, Tristan Swedish, and
Ramesh Raskar. 2018.

</span>
<span class="ltx_bibblock">Split learning for health: Distributed deep learning
without sharing raw patient data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1812.00564 [cs.LG]

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2019)</span>
<span class="ltx_bibblock">
Guan Wang.
2019.

</span>
<span class="ltx_bibblock">Interpret federated learning with shapley values.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.04519</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hongyi Wang, Mikhail
Yurochkin, Yuekai Sun, Dimitris
Papailiopoulos, and Yasaman Khazaeni.
2020.

</span>
<span class="ltx_bibblock">Federated learning with matched averaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.06440</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Xiguang Wei, Quan Li,
Yang Liu, Han Yu,
Tianjian Chen, and Qiang Yang.
2019.

</span>
<span class="ltx_bibblock">Multi-Agent Visualization for Explaining Federated
Learning. In <em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-Eighth
International Joint Conference on Artificial Intelligence,
<span id="bib.bib48.3.1.1" class="ltx_text ltx_font_upright">{</span>IJCAI-19<span id="bib.bib48.3.1.2" class="ltx_text ltx_font_upright">}</span></em>. International Joint Conferences on
Artificial Intelligence Organization, 6572–6574.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.24963/ijcai.2019/960" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.24963/ijcai.2019/960</a>

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Ting Wu, Lei Chen,
Pan Hui, Chen Jason Zhang, and
Weikai Li. 2015.

</span>
<span class="ltx_bibblock">Hear the whole story: Towards the diversity of
opinion in crowdsourcing markets.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB Endowment</em>
8, 5 (2015),
485–496.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Kai Yang, Tao Fan,
Tianjian Chen, Yuanming Shi, and
Qiang Yang. 2019a.

</span>
<span class="ltx_bibblock">A quasi-newton method based vertical federated
learning framework for logistic regression.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.00513</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Liu Yang, Ben Tan,
Vincent W Zheng, Kai Chen, and
Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">Federated recommendation systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">Federated Learning</em>.
Springer, 225–239.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu,
Tianjian Chen, and Yongxin Tong.
2019b.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and
applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology</em> 10, 2
(2019), 1–19.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3298981" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3298981</a>
arXiv:1902.04885

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2019c)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu,
Yong Cheng, Yan Kang,
Tianjian Chen, and Han Yu.
2019c.

</span>
<span class="ltx_bibblock">Federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Synthesis Lectures on Artificial Intelligence
and Machine Learning</em> 13, 3
(2019), 1–207.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yee et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2003)</span>
<span class="ltx_bibblock">
Ka-Ping Yee, Kirsten
Swearingen, Kevin Li, and Marti
Hearst. 2003.

</span>
<span class="ltx_bibblock">Faceted metadata for image search and browsing. In
<em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Proceedings of the SIGCHI conference on Human
factors in computing systems</em>. 401–408.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yeh and Lien (2009)</span>
<span class="ltx_bibblock">
I-Cheng Yeh and Che-hui
Lien. 2009.

</span>
<span class="ltx_bibblock">The comparisons of data mining techniques for the
predictive accuracy of probability of default of credit card clients.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>
36, 2 (2009),
2473–2480.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuen and Wong (2011)</span>
<span class="ltx_bibblock">
Ching-Hung Yuen and
Kwok-Wo Wong. 2011.

</span>
<span class="ltx_bibblock">A chaos-based joint image compression and
encryption scheme using DCT and SHA-1.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Applied Soft Computing</em>
11, 8 (2011),
5092–5098.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yurochkin et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mikhail Yurochkin, Mayank
Agarwal, Soumya Ghosh, Kristjan
Greenewald, Nghia Hoang, and Yasaman
Khazaeni. 2019.

</span>
<span class="ltx_bibblock">Bayesian nonparametric federated learning of neural
networks. In <em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 7252–7261.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib58.6.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chengliang Zhang, Suyi
Li, Junzhe Xia, Wei Wang,
Feng Yan, and Yang Liu.
2020.

</span>
<span class="ltx_bibblock"><math id="bib.bib58.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib58.1.m1.1a"><mo stretchy="false" id="bib.bib58.1.m1.1.1" xref="bib.bib58.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib58.1.m1.1b"><ci id="bib.bib58.1.m1.1.1.cmml" xref="bib.bib58.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib58.1.m1.1c">\{</annotation></semantics></math>BatchCrypt<math id="bib.bib58.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib58.2.m2.1a"><mo stretchy="false" id="bib.bib58.2.m2.1.1" xref="bib.bib58.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib58.2.m2.1b"><ci id="bib.bib58.2.m2.1.1.cmml" xref="bib.bib58.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib58.2.m2.1c">\}</annotation></semantics></math>: Efficient Homomorphic
Encryption for <math id="bib.bib58.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib58.3.m3.1a"><mo stretchy="false" id="bib.bib58.3.m3.1.1" xref="bib.bib58.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib58.3.m3.1b"><ci id="bib.bib58.3.m3.1.1.cmml" xref="bib.bib58.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib58.3.m3.1c">\{</annotation></semantics></math>Cross-Silo<math id="bib.bib58.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib58.4.m4.1a"><mo stretchy="false" id="bib.bib58.4.m4.1.1" xref="bib.bib58.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib58.4.m4.1b"><ci id="bib.bib58.4.m4.1.1.cmml" xref="bib.bib58.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib58.4.m4.1c">\}</annotation></semantics></math> Federated Learning. In
<em id="bib.bib58.7.1" class="ltx_emph ltx_font_italic">2020 USENIX Annual Technical Conference (USENIX ATC
20)</em>. 493–506.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Lingchen Zhao, Lihao Ni,
Shengshan Hu, Yaniiao Chen,
Pan Zhou, Fu Xiao, and
Libing Wu. 2018b.

</span>
<span class="ltx_bibblock">Inprivate digging: Enabling tree-based distributed
data mining with differential privacy. In <em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">IEEE
INFOCOM 2018-IEEE Conference on Computer Communications</em>. IEEE,
2087–2095.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li,
Liangzhen Lai, Naveen Suda,
Damon Civin, and Vikas Chandra.
2018a.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00582</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Fanglan Zheng, Kun Li,
Jiang Tian, Xiaojia Xiang,
et al<span id="bib.bib61.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">A vertical federated learning method for
interpretable scorecard and its application in credit scoring.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.06218</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2210.00471" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2210.00472" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2210.00472">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2210.00472" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2210.00473" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 01:47:41 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
