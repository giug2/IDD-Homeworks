<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2206.10526] QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization</title><meta property="og:description" content="Deep learning-based face recognition models follow the common trend in deep neural networks by utilizing full-precision floating-point networks with high computational costs. Deploying such networks in use-cases constr…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2206.10526">

<!--Generated on Mon Mar 11 17:19:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fadi Boutros



</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fadi Boutros<sup id="id6.6.id1" class="ltx_sup"><span id="id6.6.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Naser Damer<sup id="id7.7.id2" class="ltx_sup"><span id="id7.7.id2.1" class="ltx_text ltx_font_italic">1,2</span></sup>,
Arjan Kuijper<sup id="id8.8.id3" class="ltx_sup"><span id="id8.8.id3.1" class="ltx_text ltx_font_italic">1,2</span></sup>
<br class="ltx_break"><sup id="id9.9.id4" class="ltx_sup"><span id="id9.9.id4.1" class="ltx_text ltx_font_italic">1</span></sup>Fraunhofer Institute for Computer Graphics Research IGD,
Darmstadt, Germany
<br class="ltx_break"><sup id="id10.10.id5" class="ltx_sup"><span id="id10.10.id5.1" class="ltx_text ltx_font_italic">2</span></sup>Department of Computer Science, TU Darmstadt,
Darmstadt, Germany
<br class="ltx_break">Email: fadi.boutros@igd.fraunhofer.de
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Fraunhofer Institute for Computer Graphics Research IGD,
Darmstadt, Germany
<br class="ltx_break">Mathematical and Applied Visual Computing, TU Darmstadt,
Darmstadt, Germany
<br class="ltx_break">Email: fadi.boutros@igd.fraunhofer.de
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Naser Damer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Fraunhofer Institute for Computer Graphics Research IGD,
Darmstadt, Germany
<br class="ltx_break">Department of Computer Science, TU Darmstadt,
Darmstadt, Germany
<br class="ltx_break">Email: naser.damer.boutros@igd.fraunhofer.de
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arjan Kuijper
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Fraunhofer Institute for Computer Graphics Research IGD,
Darmstadt, Germany
<br class="ltx_break">Department of Computer Science, TU Darmstadt,
Darmstadt, Germany
<br class="ltx_break">Email: arjan.kuijper@igd.fraunhofer.de
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">Deep learning-based face recognition models follow the common trend in deep neural networks by utilizing full-precision floating-point networks with high computational costs. Deploying such networks in use-cases constrained by computational requirements is often infeasible due to the large memory required by the full-precision model.
Previous compact face recognition approaches proposed to design special compact architectures and train them from scratch using real training data, which may not be available in a real-world scenario due to privacy concerns.
We present in this work the QuantFace solution based on low-bit precision format model quantization.
QuantFace reduces the required computational cost of the existing face recognition models without the need for designing a particular architecture or accessing real training data.
QuantFace introduces privacy-friendly synthetic face data to the quantization process to mitigate potential privacy concerns and issues related to the accessibility to real training data.
Through extensive evaluation experiments on seven benchmarks and four network architectures, we demonstrate that QuantFace can successfully reduce the model size up to 5x while maintaining, to a large degree, the verification performance of the full-precision model without accessing real training datasets. All training codes are publicly available <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/fdbtrs/QuantFace" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/fdbtrs/QuantFace</a></span></span></span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recent high performing deep neural networks (DNN) rely on over-parameterized networks with high computational cost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. State-of-the-art (SOTA) face recognition (FR) models followed this common trend by relying on over-parameterized DNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
However, deploying such extremely large models with hundreds of megabytes (MB) of memory requirements on embedded <span id="S1.p1.1.1" class="ltx_text" style="color:#000000;">devices and</span> other use-cases constrained by the computational capabilities and high throughput <span id="S1.p1.1.2" class="ltx_text" style="color:#000000;">requirements is</span> still challenging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Enabling FR on domains limited with computational capabilities requires designing a special architecture or compressing the current solutions to meet the computational requirements of the deployment environments.
Several efficient FR models have been proposed in the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. The core idea of many of these works depended on utilizing efficient architecture designed for common computer version tasks such as MixNets, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, MobileNetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, ShuffleNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, VarGNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> for FR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
Very recently, few of works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> proposed architectures based on face-specific neural architecture search (NAS) for efficient FR.
However, none of all previous efficient FR works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> explored the potential of using model quantization to reduce the computational cost of existing widely used FR architectures, e.g. ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> or SE-ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Model quantization approaches compress the DNN by reducing the number of bits required to represent each weight, e.g., using <span id="S1.p3.1.1" class="ltx_text" style="color:#000000;">a</span> lower precision format than full-precision (FP) floating-point, such as 4-bit <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> or 8-bit <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> signed integer.
Such methods have shown great success in reducing the computation cost of DNN and are supported by most deep learning accelerators <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
Model quantization enables performance gains in different areas.
First, it reduces the model size, which can be directly measured using the number of bits required to represent each parameter. For example, applying model quantization using 8bit bandwidth on ResNet100 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> (65.2M parameters) reduces the model size from 261.2MB to 65.3 MB.
Second, many deep learning accelerators such as Pytorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and TensorFlow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> can run a quantized model faster than a FP one. For example, Pytorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> can run a quantized model 2-4x faster than the FP model and reduce the required memory bandwidth by 2-4x <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. However, the exact inference speed and memory bandwidth are highly dependent on the underlying <span id="S1.p3.1.2" class="ltx_text" style="color:#000000;">hardware and</span> deep learning accelerator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
Once the model is quantized, the model weights and quantization parameters need to be tuned and calibrated.
These processes commonly require access to the training data, either entirely or partially <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2206.10526/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="130" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;"> An overview of the proposed QuantFace framework. Given a Gaussian noise Z from a normal distribution, the pretrained generator produces a fake data sample and feeds it into the FP and the b-bit quantized model. The KD loss is then computed between the normalized feature embeddings of the FP model and the quantized model. </span></figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This need for data if quantization is used on FR networks follows that of deep FR models reliance on large-scale training datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> such as MS1M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, VGGFace2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.
Existing efficient FR solutions are not different as they also require face image databases, whether for conventional training and/or knowledge distillation (KD) from teacher networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
Most of the recent face datasets used in the literature have been collected from the web <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
According to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, 45 of face datasets have been created after 2014, and around 78% of these datasets are derived from the web.
However, it is not a trivial task, and it may not be feasible to further collect face datasets for biometric processing from the web due to legal privacy issues in some countries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
Privacy regulations, just as the GDPR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, gives individuals the right to withdraw their consent to store or use their private data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, a process that can practically be very challenging when a database is widely distributed, which puts the privacy rights of individuals in jeopardy.
Following such concerns, datasets such as VGGFace2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and CASIA-WebFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> are not anymore publicly accessible in many countries. Companies like Facebook announced that they will shut down their FR system due to such privacy concerns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.
This motivated several recent works to explore the <span id="S1.p4.1.1" class="ltx_text" style="color:#000000;"> potential</span> of using synthetically generated face data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">This work presents contributions towards enhancing the compactness of FR models while maintaining high accuracy in a privacy-friendly process that does not require real face databases.
Towards that, this work is, to the best of our knowledge, the first to regulate the FR computational cost by applying quantization-aware training.
We additionally propose a training paradigm involving KD that uses synthetically generated face data to fine-tune the quantized model <span id="S1.p5.1.1" class="ltx_text" style="color:#000000;">and adapt</span> the quantization operator parameters.
We empirically prove the success of the proposed approach in reducing the bit bandwidth up to 5x of the evaluated models while maintaining, to a large degree, the model verification performance.
Additionally, the use of synthetic data within the proposed training paradigm proved to be highly effective and produced quantized models that performed competitively with models quantized using real data, even outperforming them in many experimental setups.
Our quantized models based on synthetic data did outperform other full precision models with higher memory footprints, as will be demonstrated later in this work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related works</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">There is a large body of works that proposed efficient FR models based on designing compact convolution building <span id="S2.p1.1.1" class="ltx_text" style="color:#000000;">blocks</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
Such efficient FR models followed those of deep image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, which in terms evolved from the depthwise separable convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.
Additionally, efficient FR models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> opted to replace the fully connected (FC) layer on the top of CNN with a global depthwise convolution to reduce the large number of parameters caused by the FC layer.
MobileFaceNets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> is a popular network architecture that has been widely adopted in different compact FR solutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
MobileFaceNets contains around one million trainable parameters with 443M FLOPs.
MobileFaceNets architecture is based on the residual bottlenecks proposed by MobileNetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and depth-wise separable convolutions layer.
VarGFaceNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> deployed the variable group convolutional network proposed by VarGNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to design a compact FR model with 5m trainable parameters. ShuffleFaceNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> is a compact FR model based on ShuffleNet-V2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
MixFaceNets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> proposed a family of efficient FR models by extending the MixConv block <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> with a channel shuffle operation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> aiming at increasing the discriminative ability of MixFaceNets.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">An alternative to previous handcrafted DNN designs is utilizing NAS, KD, or a combination of different model compression techniques.
KD transfers the acquired knowledge learned by a larger network to a smaller one <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. KD has shown great success in improving the verification performance of compact FR models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.
Furthermore, the combination of KD with other model compression techniques such as compact model design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, or NAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> <span id="S2.p2.1.1" class="ltx_text" style="color:#000000;"> demonstrated</span> very promising accuracies in FR.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">One must note that all the discussed FR models are built with FP single floating-point, and none has adopted model quantization techniques.
Additionally, all these works required the privacy-sensitive use of real face data, either during their conventional training or during the KD from a larger pre-trained network. This stresses the main contributions of this work, i.e., the use of unlabeled synthetic data in the proposed quantization paradigm.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methodology</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This work presents a privacy-friendly framework to minimize the computational complexity of deep learning-based FR models.
Towards that, given an FR model with a FP floating point, we propose to quantize the weights and activations to b-bit precision format through uniform quantization aware training.
The quantization process commonly requires fine-tuning/retraining the quantized model to adjust the quantization operator parameters and recover the model accuracy after applying the quantization process.
Quantization usually requires the original model training data, or part of it, for this calibration or fine-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.
This original data may not be accessible after training the model due to restrictions related to privacy, security, data ownership, and data availability restrictions (e.g., model shared from a data owner to a third party).
To mitigate this challenge and promote privacy-aware solutions, our proposed framework utilizes synthetically generated face data to fine-tune and calibrate the quantized model.
Moreover, to maintain the performance and enable the use of unlabeled synthetic data, the proposed framework combines the quantization process with KD during the fine-tuning phase. This step enables fine-tuning the quantized model without accessing the real training dataset or any prior assumption about the training dataset labels.
Figure <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents an overview of the proposed framework.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">This section presents first the quantization process applied to the FP floating-point FR model. Then, it presents the training paradigm utilized to fine-tune the quantized model.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Model Quantization</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.11" class="ltx_p">Quantization involves two main operators: Quantize and Dequantize.
Let <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="x\in[\beta,\alpha]" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3" xref="S3.SS1.p1.1.m1.2.3.cmml"><mi id="S3.SS1.p1.1.m1.2.3.2" xref="S3.SS1.p1.1.m1.2.3.2.cmml">x</mi><mo id="S3.SS1.p1.1.m1.2.3.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">∈</mo><mrow id="S3.SS1.p1.1.m1.2.3.3.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.1" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">[</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">β</mi><mo id="S3.SS1.p1.1.m1.2.3.3.2.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">α</mi><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.3" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.3"><in id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.1"></in><ci id="S3.SS1.p1.1.m1.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.3.2">𝑥</ci><interval closure="closed" id="S3.SS1.p1.1.m1.2.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.2"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝛽</ci><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">𝛼</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">x\in[\beta,\alpha]</annotation></semantics></math> be a real value and <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">b</annotation></semantics></math> is the bit width of a low precision format.
<math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\beta</annotation></semantics></math> and <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\alpha</annotation></semantics></math> are minimum and maximum values of <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">x</annotation></semantics></math>.
A <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="2^{b}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msup id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mn id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">2</mn><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">superscript</csymbol><cn type="integer" id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">2</cn><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">2^{b}</annotation></semantics></math> possible integer values can be represented using b-bit format and the value range of a b-bit signed integer precision format is between <span id="S3.SS1.p1.7.1" class="ltx_text" style="color:#000000;"> <math id="S3.SS1.p1.7.1.m1.2" class="ltx_Math" alttext="[-2^{b-1},2^{b-1}-1]" display="inline"><semantics id="S3.SS1.p1.7.1.m1.2a"><mrow id="S3.SS1.p1.7.1.m1.2.2.2" xref="S3.SS1.p1.7.1.m1.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.SS1.p1.7.1.m1.2.2.2.3" xref="S3.SS1.p1.7.1.m1.2.2.3.cmml">[</mo><mrow id="S3.SS1.p1.7.1.m1.1.1.1.1" xref="S3.SS1.p1.7.1.m1.1.1.1.1.cmml"><mo mathcolor="#000000" id="S3.SS1.p1.7.1.m1.1.1.1.1a" xref="S3.SS1.p1.7.1.m1.1.1.1.1.cmml">−</mo><msup id="S3.SS1.p1.7.1.m1.1.1.1.1.2" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.cmml"><mn mathcolor="#000000" id="S3.SS1.p1.7.1.m1.1.1.1.1.2.2" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.2.cmml">2</mn><mrow id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.cmml"><mi mathcolor="#000000" id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.2" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.2.cmml">b</mi><mo mathcolor="#000000" id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.1" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.3" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msup></mrow><mo mathcolor="#000000" id="S3.SS1.p1.7.1.m1.2.2.2.4" xref="S3.SS1.p1.7.1.m1.2.2.3.cmml">,</mo><mrow id="S3.SS1.p1.7.1.m1.2.2.2.2" xref="S3.SS1.p1.7.1.m1.2.2.2.2.cmml"><msup id="S3.SS1.p1.7.1.m1.2.2.2.2.2" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.cmml"><mn mathcolor="#000000" id="S3.SS1.p1.7.1.m1.2.2.2.2.2.2" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.2.cmml">2</mn><mrow id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.cmml"><mi mathcolor="#000000" id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.2" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.2.cmml">b</mi><mo mathcolor="#000000" id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.1" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.3" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow></msup><mo mathcolor="#000000" id="S3.SS1.p1.7.1.m1.2.2.2.2.1" xref="S3.SS1.p1.7.1.m1.2.2.2.2.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.7.1.m1.2.2.2.2.3" xref="S3.SS1.p1.7.1.m1.2.2.2.2.3.cmml">1</mn></mrow><mo mathcolor="#000000" stretchy="false" id="S3.SS1.p1.7.1.m1.2.2.2.5" xref="S3.SS1.p1.7.1.m1.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.1.m1.2b"><interval closure="closed" id="S3.SS1.p1.7.1.m1.2.2.3.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2"><apply id="S3.SS1.p1.7.1.m1.1.1.1.1.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1"><minus id="S3.SS1.p1.7.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1"></minus><apply id="S3.SS1.p1.7.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S3.SS1.p1.7.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.2">2</cn><apply id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3"><minus id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.1"></minus><ci id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.2">𝑏</ci><cn type="integer" id="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p1.7.1.m1.1.1.1.1.2.3.3">1</cn></apply></apply></apply><apply id="S3.SS1.p1.7.1.m1.2.2.2.2.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2"><minus id="S3.SS1.p1.7.1.m1.2.2.2.2.1.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.1"></minus><apply id="S3.SS1.p1.7.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2">superscript</csymbol><cn type="integer" id="S3.SS1.p1.7.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.2">2</cn><apply id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3"><minus id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.1"></minus><ci id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.2">𝑏</ci><cn type="integer" id="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.2.3.3">1</cn></apply></apply><cn type="integer" id="S3.SS1.p1.7.1.m1.2.2.2.2.3.cmml" xref="S3.SS1.p1.7.1.m1.2.2.2.2.3">1</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.1.m1.2c">[-2^{b-1},2^{b-1}-1]</annotation></semantics></math></span>.
A real value of a FP model in this work refers to a 32-bit single-precision floating-point.
Quantization maps a real value <math id="S3.SS1.p1.8.m7.2" class="ltx_Math" alttext="x\in[\beta,\alpha]" display="inline"><semantics id="S3.SS1.p1.8.m7.2a"><mrow id="S3.SS1.p1.8.m7.2.3" xref="S3.SS1.p1.8.m7.2.3.cmml"><mi id="S3.SS1.p1.8.m7.2.3.2" xref="S3.SS1.p1.8.m7.2.3.2.cmml">x</mi><mo id="S3.SS1.p1.8.m7.2.3.1" xref="S3.SS1.p1.8.m7.2.3.1.cmml">∈</mo><mrow id="S3.SS1.p1.8.m7.2.3.3.2" xref="S3.SS1.p1.8.m7.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.8.m7.2.3.3.2.1" xref="S3.SS1.p1.8.m7.2.3.3.1.cmml">[</mo><mi id="S3.SS1.p1.8.m7.1.1" xref="S3.SS1.p1.8.m7.1.1.cmml">β</mi><mo id="S3.SS1.p1.8.m7.2.3.3.2.2" xref="S3.SS1.p1.8.m7.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.8.m7.2.2" xref="S3.SS1.p1.8.m7.2.2.cmml">α</mi><mo stretchy="false" id="S3.SS1.p1.8.m7.2.3.3.2.3" xref="S3.SS1.p1.8.m7.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m7.2b"><apply id="S3.SS1.p1.8.m7.2.3.cmml" xref="S3.SS1.p1.8.m7.2.3"><in id="S3.SS1.p1.8.m7.2.3.1.cmml" xref="S3.SS1.p1.8.m7.2.3.1"></in><ci id="S3.SS1.p1.8.m7.2.3.2.cmml" xref="S3.SS1.p1.8.m7.2.3.2">𝑥</ci><interval closure="closed" id="S3.SS1.p1.8.m7.2.3.3.1.cmml" xref="S3.SS1.p1.8.m7.2.3.3.2"><ci id="S3.SS1.p1.8.m7.1.1.cmml" xref="S3.SS1.p1.8.m7.1.1">𝛽</ci><ci id="S3.SS1.p1.8.m7.2.2.cmml" xref="S3.SS1.p1.8.m7.2.2">𝛼</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m7.2c">x\in[\beta,\alpha]</annotation></semantics></math> to lie within the range value of low precision b-bit <math id="S3.SS1.p1.9.m8.2" class="ltx_Math" alttext="[-2^{b-1},2^{b-1}-1]" display="inline"><semantics id="S3.SS1.p1.9.m8.2a"><mrow id="S3.SS1.p1.9.m8.2.2.2" xref="S3.SS1.p1.9.m8.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.SS1.p1.9.m8.2.2.2.3" xref="S3.SS1.p1.9.m8.2.2.3.cmml">[</mo><mrow id="S3.SS1.p1.9.m8.1.1.1.1" xref="S3.SS1.p1.9.m8.1.1.1.1.cmml"><mo mathcolor="#000000" id="S3.SS1.p1.9.m8.1.1.1.1a" xref="S3.SS1.p1.9.m8.1.1.1.1.cmml">−</mo><msup id="S3.SS1.p1.9.m8.1.1.1.1.2" xref="S3.SS1.p1.9.m8.1.1.1.1.2.cmml"><mn mathcolor="#000000" id="S3.SS1.p1.9.m8.1.1.1.1.2.2" xref="S3.SS1.p1.9.m8.1.1.1.1.2.2.cmml">2</mn><mrow id="S3.SS1.p1.9.m8.1.1.1.1.2.3" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3.cmml"><mi mathcolor="#000000" id="S3.SS1.p1.9.m8.1.1.1.1.2.3.2" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3.2.cmml">b</mi><mo mathcolor="#000000" id="S3.SS1.p1.9.m8.1.1.1.1.2.3.1" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.9.m8.1.1.1.1.2.3.3" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3.3.cmml">1</mn></mrow></msup></mrow><mo mathcolor="#000000" id="S3.SS1.p1.9.m8.2.2.2.4" xref="S3.SS1.p1.9.m8.2.2.3.cmml">,</mo><mrow id="S3.SS1.p1.9.m8.2.2.2.2" xref="S3.SS1.p1.9.m8.2.2.2.2.cmml"><msup id="S3.SS1.p1.9.m8.2.2.2.2.2" xref="S3.SS1.p1.9.m8.2.2.2.2.2.cmml"><mn mathcolor="#000000" id="S3.SS1.p1.9.m8.2.2.2.2.2.2" xref="S3.SS1.p1.9.m8.2.2.2.2.2.2.cmml">2</mn><mrow id="S3.SS1.p1.9.m8.2.2.2.2.2.3" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3.cmml"><mi mathcolor="#000000" id="S3.SS1.p1.9.m8.2.2.2.2.2.3.2" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3.2.cmml">b</mi><mo mathcolor="#000000" id="S3.SS1.p1.9.m8.2.2.2.2.2.3.1" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.9.m8.2.2.2.2.2.3.3" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3.3.cmml">1</mn></mrow></msup><mo mathcolor="#000000" id="S3.SS1.p1.9.m8.2.2.2.2.1" xref="S3.SS1.p1.9.m8.2.2.2.2.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.9.m8.2.2.2.2.3" xref="S3.SS1.p1.9.m8.2.2.2.2.3.cmml">1</mn></mrow><mo mathcolor="#000000" stretchy="false" id="S3.SS1.p1.9.m8.2.2.2.5" xref="S3.SS1.p1.9.m8.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m8.2b"><interval closure="closed" id="S3.SS1.p1.9.m8.2.2.3.cmml" xref="S3.SS1.p1.9.m8.2.2.2"><apply id="S3.SS1.p1.9.m8.1.1.1.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1"><minus id="S3.SS1.p1.9.m8.1.1.1.1.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1"></minus><apply id="S3.SS1.p1.9.m8.1.1.1.1.2.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m8.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S3.SS1.p1.9.m8.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.2.2">2</cn><apply id="S3.SS1.p1.9.m8.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3"><minus id="S3.SS1.p1.9.m8.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3.1"></minus><ci id="S3.SS1.p1.9.m8.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3.2">𝑏</ci><cn type="integer" id="S3.SS1.p1.9.m8.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p1.9.m8.1.1.1.1.2.3.3">1</cn></apply></apply></apply><apply id="S3.SS1.p1.9.m8.2.2.2.2.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2"><minus id="S3.SS1.p1.9.m8.2.2.2.2.1.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.1"></minus><apply id="S3.SS1.p1.9.m8.2.2.2.2.2.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m8.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.2">superscript</csymbol><cn type="integer" id="S3.SS1.p1.9.m8.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.2.2">2</cn><apply id="S3.SS1.p1.9.m8.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3"><minus id="S3.SS1.p1.9.m8.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3.1"></minus><ci id="S3.SS1.p1.9.m8.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3.2">𝑏</ci><cn type="integer" id="S3.SS1.p1.9.m8.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.2.3.3">1</cn></apply></apply><cn type="integer" id="S3.SS1.p1.9.m8.2.2.2.2.3.cmml" xref="S3.SS1.p1.9.m8.2.2.2.2.3">1</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m8.2c">[-2^{b-1},2^{b-1}-1]</annotation></semantics></math>.
Quantization operator consists of two processes: value transformation and clipping process. Formally, the transformation process that maps <math id="S3.SS1.p1.10.m9.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p1.10.m9.1a"><mi id="S3.SS1.p1.10.m9.1.1" xref="S3.SS1.p1.10.m9.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m9.1b"><ci id="S3.SS1.p1.10.m9.1.1.cmml" xref="S3.SS1.p1.10.m9.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m9.1c">x</annotation></semantics></math> into <math id="S3.SS1.p1.11.m10.1" class="ltx_Math" alttext="x_{q}" display="inline"><semantics id="S3.SS1.p1.11.m10.1a"><msub id="S3.SS1.p1.11.m10.1.1" xref="S3.SS1.p1.11.m10.1.1.cmml"><mi id="S3.SS1.p1.11.m10.1.1.2" xref="S3.SS1.p1.11.m10.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.11.m10.1.1.3" xref="S3.SS1.p1.11.m10.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m10.1b"><apply id="S3.SS1.p1.11.m10.1.1.cmml" xref="S3.SS1.p1.11.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m10.1.1.1.cmml" xref="S3.SS1.p1.11.m10.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m10.1.1.2.cmml" xref="S3.SS1.p1.11.m10.1.1.2">𝑥</ci><ci id="S3.SS1.p1.11.m10.1.1.3.cmml" xref="S3.SS1.p1.11.m10.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m10.1c">x_{q}</annotation></semantics></math> can be defined as follows:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="T(x,s,z)=round(\frac{x}{s}-z)," display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml"><mi id="S3.E1.m1.4.4.1.1.3.2" xref="S3.E1.m1.4.4.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.3.1" xref="S3.E1.m1.4.4.1.1.3.1.cmml">​</mo><mrow id="S3.E1.m1.4.4.1.1.3.3.2" xref="S3.E1.m1.4.4.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.1.1.3.3.2.1" xref="S3.E1.m1.4.4.1.1.3.3.1.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">x</mi><mo id="S3.E1.m1.4.4.1.1.3.3.2.2" xref="S3.E1.m1.4.4.1.1.3.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">s</mi><mo id="S3.E1.m1.4.4.1.1.3.3.2.3" xref="S3.E1.m1.4.4.1.1.3.3.1.cmml">,</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">z</mi><mo stretchy="false" id="S3.E1.m1.4.4.1.1.3.3.2.4" xref="S3.E1.m1.4.4.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.4.4.1.1.1" xref="S3.E1.m1.4.4.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.4.4.1.1.1.4" xref="S3.E1.m1.4.4.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.1.2a" xref="S3.E1.m1.4.4.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.4.4.1.1.1.5" xref="S3.E1.m1.4.4.1.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.1.2b" xref="S3.E1.m1.4.4.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.4.4.1.1.1.6" xref="S3.E1.m1.4.4.1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.1.2c" xref="S3.E1.m1.4.4.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.4.4.1.1.1.7" xref="S3.E1.m1.4.4.1.1.1.7.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.1.2d" xref="S3.E1.m1.4.4.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.4.4.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml"><mfrac id="S3.E1.m1.4.4.1.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.2.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.2.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.3.cmml">s</mi></mfrac><mo id="S3.E1.m1.4.4.1.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml">z</mi></mrow><mo stretchy="false" id="S3.E1.m1.4.4.1.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1"><eq id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2"></eq><apply id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3"><times id="S3.E1.m1.4.4.1.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.3.1"></times><ci id="S3.E1.m1.4.4.1.1.3.2.cmml" xref="S3.E1.m1.4.4.1.1.3.2">𝑇</ci><vector id="S3.E1.m1.4.4.1.1.3.3.1.cmml" xref="S3.E1.m1.4.4.1.1.3.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑥</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝑠</ci><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑧</ci></vector></apply><apply id="S3.E1.m1.4.4.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1"><times id="S3.E1.m1.4.4.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.2"></times><ci id="S3.E1.m1.4.4.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.3">𝑟</ci><ci id="S3.E1.m1.4.4.1.1.1.4.cmml" xref="S3.E1.m1.4.4.1.1.1.4">𝑜</ci><ci id="S3.E1.m1.4.4.1.1.1.5.cmml" xref="S3.E1.m1.4.4.1.1.1.5">𝑢</ci><ci id="S3.E1.m1.4.4.1.1.1.6.cmml" xref="S3.E1.m1.4.4.1.1.1.6">𝑛</ci><ci id="S3.E1.m1.4.4.1.1.1.7.cmml" xref="S3.E1.m1.4.4.1.1.1.7">𝑑</ci><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1"><minus id="S3.E1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.1"></minus><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2"><divide id="S3.E1.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2"></divide><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.3">𝑠</ci></apply><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3">𝑧</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">T(x,s,z)=round(\frac{x}{s}-z),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.17" class="ltx_p">where <math id="S3.SS1.p1.12.m1.1" class="ltx_Math" alttext="round()" display="inline"><semantics id="S3.SS1.p1.12.m1.1a"><mrow id="S3.SS1.p1.12.m1.1.1" xref="S3.SS1.p1.12.m1.1.1.cmml"><mi id="S3.SS1.p1.12.m1.1.1.2" xref="S3.SS1.p1.12.m1.1.1.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.12.m1.1.1.1" xref="S3.SS1.p1.12.m1.1.1.1.cmml">​</mo><mi id="S3.SS1.p1.12.m1.1.1.3" xref="S3.SS1.p1.12.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.12.m1.1.1.1a" xref="S3.SS1.p1.12.m1.1.1.1.cmml">​</mo><mi id="S3.SS1.p1.12.m1.1.1.4" xref="S3.SS1.p1.12.m1.1.1.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.12.m1.1.1.1b" xref="S3.SS1.p1.12.m1.1.1.1.cmml">​</mo><mi id="S3.SS1.p1.12.m1.1.1.5" xref="S3.SS1.p1.12.m1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.12.m1.1.1.1c" xref="S3.SS1.p1.12.m1.1.1.1.cmml">​</mo><mi id="S3.SS1.p1.12.m1.1.1.6" xref="S3.SS1.p1.12.m1.1.1.6.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.12.m1.1.1.1d" xref="S3.SS1.p1.12.m1.1.1.1.cmml">​</mo><mrow id="S3.SS1.p1.12.m1.1.1.7.2" xref="S3.SS1.p1.12.m1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.12.m1.1.1.7.2.1" xref="S3.SS1.p1.12.m1.1.1.7.1.cmml">(</mo><mo stretchy="false" id="S3.SS1.p1.12.m1.1.1.7.2.2" xref="S3.SS1.p1.12.m1.1.1.7.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m1.1b"><apply id="S3.SS1.p1.12.m1.1.1.cmml" xref="S3.SS1.p1.12.m1.1.1"><times id="S3.SS1.p1.12.m1.1.1.1.cmml" xref="S3.SS1.p1.12.m1.1.1.1"></times><ci id="S3.SS1.p1.12.m1.1.1.2.cmml" xref="S3.SS1.p1.12.m1.1.1.2">𝑟</ci><ci id="S3.SS1.p1.12.m1.1.1.3.cmml" xref="S3.SS1.p1.12.m1.1.1.3">𝑜</ci><ci id="S3.SS1.p1.12.m1.1.1.4.cmml" xref="S3.SS1.p1.12.m1.1.1.4">𝑢</ci><ci id="S3.SS1.p1.12.m1.1.1.5.cmml" xref="S3.SS1.p1.12.m1.1.1.5">𝑛</ci><ci id="S3.SS1.p1.12.m1.1.1.6.cmml" xref="S3.SS1.p1.12.m1.1.1.6">𝑑</ci><list id="S3.SS1.p1.12.m1.1.1.7.1.cmml" xref="S3.SS1.p1.12.m1.1.1.7.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m1.1c">round()</annotation></semantics></math> is the rounding method that defines the rounding step in which a value is rounded up or down to an integer. <math id="S3.SS1.p1.13.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS1.p1.13.m2.1a"><mi id="S3.SS1.p1.13.m2.1.1" xref="S3.SS1.p1.13.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m2.1b"><ci id="S3.SS1.p1.13.m2.1.1.cmml" xref="S3.SS1.p1.13.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m2.1c">z</annotation></semantics></math> is a constant parameter (zero-point) of the same type as the quantized value.
It represents the quantized value <math id="S3.SS1.p1.14.m3.1" class="ltx_Math" alttext="x_{q}" display="inline"><semantics id="S3.SS1.p1.14.m3.1a"><msub id="S3.SS1.p1.14.m3.1.1" xref="S3.SS1.p1.14.m3.1.1.cmml"><mi id="S3.SS1.p1.14.m3.1.1.2" xref="S3.SS1.p1.14.m3.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.14.m3.1.1.3" xref="S3.SS1.p1.14.m3.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m3.1b"><apply id="S3.SS1.p1.14.m3.1.1.cmml" xref="S3.SS1.p1.14.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.14.m3.1.1.1.cmml" xref="S3.SS1.p1.14.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.14.m3.1.1.2.cmml" xref="S3.SS1.p1.14.m3.1.1.2">𝑥</ci><ci id="S3.SS1.p1.14.m3.1.1.3.cmml" xref="S3.SS1.p1.14.m3.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m3.1c">x_{q}</annotation></semantics></math> corresponding to the real zero value.
<math id="S3.SS1.p1.15.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS1.p1.15.m4.1a"><mi id="S3.SS1.p1.15.m4.1.1" xref="S3.SS1.p1.15.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m4.1b"><ci id="S3.SS1.p1.15.m4.1.1.cmml" xref="S3.SS1.p1.15.m4.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m4.1c">s</annotation></semantics></math> is a real-valued scaling factor that <span id="S3.SS1.p1.17.1" class="ltx_text" style="color:#000000;">divides</span> the real value range into a number of fractions.
In asymmetric quantization (<math id="S3.SS1.p1.16.m5.1" class="ltx_Math" alttext="-\alpha\neq\beta" display="inline"><semantics id="S3.SS1.p1.16.m5.1a"><mrow id="S3.SS1.p1.16.m5.1.1" xref="S3.SS1.p1.16.m5.1.1.cmml"><mrow id="S3.SS1.p1.16.m5.1.1.2" xref="S3.SS1.p1.16.m5.1.1.2.cmml"><mo id="S3.SS1.p1.16.m5.1.1.2a" xref="S3.SS1.p1.16.m5.1.1.2.cmml">−</mo><mi id="S3.SS1.p1.16.m5.1.1.2.2" xref="S3.SS1.p1.16.m5.1.1.2.2.cmml">α</mi></mrow><mo id="S3.SS1.p1.16.m5.1.1.1" xref="S3.SS1.p1.16.m5.1.1.1.cmml">≠</mo><mi id="S3.SS1.p1.16.m5.1.1.3" xref="S3.SS1.p1.16.m5.1.1.3.cmml">β</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m5.1b"><apply id="S3.SS1.p1.16.m5.1.1.cmml" xref="S3.SS1.p1.16.m5.1.1"><neq id="S3.SS1.p1.16.m5.1.1.1.cmml" xref="S3.SS1.p1.16.m5.1.1.1"></neq><apply id="S3.SS1.p1.16.m5.1.1.2.cmml" xref="S3.SS1.p1.16.m5.1.1.2"><minus id="S3.SS1.p1.16.m5.1.1.2.1.cmml" xref="S3.SS1.p1.16.m5.1.1.2"></minus><ci id="S3.SS1.p1.16.m5.1.1.2.2.cmml" xref="S3.SS1.p1.16.m5.1.1.2.2">𝛼</ci></apply><ci id="S3.SS1.p1.16.m5.1.1.3.cmml" xref="S3.SS1.p1.16.m5.1.1.3">𝛽</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m5.1c">-\alpha\neq\beta</annotation></semantics></math>), the scaling factor <math id="S3.SS1.p1.17.m6.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS1.p1.17.m6.1a"><mi id="S3.SS1.p1.17.m6.1.1" xref="S3.SS1.p1.17.m6.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.17.m6.1b"><ci id="S3.SS1.p1.17.m6.1.1.cmml" xref="S3.SS1.p1.17.m6.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.17.m6.1c">s</annotation></semantics></math> and zero-point are defined as follows <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="s=\frac{\alpha-\beta}{2^{b}-1}." display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">s</mi><mo id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml">=</mo><mfrac id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.3.2.2.cmml">α</mi><mo id="S3.E2.m1.1.1.1.1.3.2.1" xref="S3.E2.m1.1.1.1.1.3.2.1.cmml">−</mo><mi id="S3.E2.m1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.3.2.3.cmml">β</mi></mrow><mrow id="S3.E2.m1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.3.3.cmml"><msup id="S3.E2.m1.1.1.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.3.3.2.cmml"><mn id="S3.E2.m1.1.1.1.1.3.3.2.2" xref="S3.E2.m1.1.1.1.1.3.3.2.2.cmml">2</mn><mi id="S3.E2.m1.1.1.1.1.3.3.2.3" xref="S3.E2.m1.1.1.1.1.3.3.2.3.cmml">b</mi></msup><mo id="S3.E2.m1.1.1.1.1.3.3.1" xref="S3.E2.m1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S3.E2.m1.1.1.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.3.3.3.cmml">1</mn></mrow></mfrac></mrow><mo lspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"></eq><ci id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2">𝑠</ci><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><divide id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3"></divide><apply id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2"><minus id="S3.E2.m1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.1"></minus><ci id="S3.E2.m1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2">𝛼</ci><ci id="S3.E2.m1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3">𝛽</ci></apply><apply id="S3.E2.m1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3"><minus id="S3.E2.m1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.3.1"></minus><apply id="S3.E2.m1.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2">superscript</csymbol><cn type="integer" id="S3.E2.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.2">2</cn><ci id="S3.E2.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2.3">𝑏</ci></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">s=\frac{\alpha-\beta}{2^{b}-1}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_math_unparsed" alttext="z=round(\beta.\frac{2^{b}-1}{\alpha-\beta}+2^{b-1})." display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1b"><mi id="S3.E3.m1.1.1">z</mi><mo id="S3.E3.m1.1.2">=</mo><mi id="S3.E3.m1.1.3">r</mi><mi id="S3.E3.m1.1.4">o</mi><mi id="S3.E3.m1.1.5">u</mi><mi id="S3.E3.m1.1.6">n</mi><mi id="S3.E3.m1.1.7">d</mi><mrow id="S3.E3.m1.1.8"><mo stretchy="false" id="S3.E3.m1.1.8.1">(</mo><mi id="S3.E3.m1.1.8.2">β</mi><mo lspace="0em" rspace="0.167em" id="S3.E3.m1.1.8.3">.</mo><mfrac id="S3.E3.m1.1.8.4"><mrow id="S3.E3.m1.1.8.4.2"><msup id="S3.E3.m1.1.8.4.2.2"><mn id="S3.E3.m1.1.8.4.2.2.2">2</mn><mi id="S3.E3.m1.1.8.4.2.2.3">b</mi></msup><mo id="S3.E3.m1.1.8.4.2.1">−</mo><mn id="S3.E3.m1.1.8.4.2.3">1</mn></mrow><mrow id="S3.E3.m1.1.8.4.3"><mi id="S3.E3.m1.1.8.4.3.2">α</mi><mo id="S3.E3.m1.1.8.4.3.1">−</mo><mi id="S3.E3.m1.1.8.4.3.3">β</mi></mrow></mfrac><mo id="S3.E3.m1.1.8.5">+</mo><msup id="S3.E3.m1.1.8.6"><mn id="S3.E3.m1.1.8.6.2">2</mn><mrow id="S3.E3.m1.1.8.6.3"><mi id="S3.E3.m1.1.8.6.3.2">b</mi><mo id="S3.E3.m1.1.8.6.3.1">−</mo><mn id="S3.E3.m1.1.8.6.3.3">1</mn></mrow></msup><mo stretchy="false" id="S3.E3.m1.1.8.7">)</mo></mrow><mo lspace="0em" id="S3.E3.m1.1.9">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.1c">z=round(\beta.\frac{2^{b}-1}{\alpha-\beta}+2^{b-1}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.19" class="ltx_p">The clipping process clips <math id="S3.SS1.p1.18.m1.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S3.SS1.p1.18.m1.1a"><msub id="S3.SS1.p1.18.m1.1.1" xref="S3.SS1.p1.18.m1.1.1.cmml"><mi id="S3.SS1.p1.18.m1.1.1.2" xref="S3.SS1.p1.18.m1.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.18.m1.1.1.3" xref="S3.SS1.p1.18.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.18.m1.1b"><apply id="S3.SS1.p1.18.m1.1.1.cmml" xref="S3.SS1.p1.18.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.18.m1.1.1.1.cmml" xref="S3.SS1.p1.18.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.18.m1.1.1.2.cmml" xref="S3.SS1.p1.18.m1.1.1.2">𝑥</ci><ci id="S3.SS1.p1.18.m1.1.1.3.cmml" xref="S3.SS1.p1.18.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.18.m1.1c">x_{t}</annotation></semantics></math> (the output of Equation <a href="#S3.E1" title="In III-A Model Quantization ‣ III Methodology ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) to lie within the range <math id="S3.SS1.p1.19.m2.2" class="ltx_Math" alttext="[-2^{b-1},2^{b-1}-1]" display="inline"><semantics id="S3.SS1.p1.19.m2.2a"><mrow id="S3.SS1.p1.19.m2.2.2.2" xref="S3.SS1.p1.19.m2.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.SS1.p1.19.m2.2.2.2.3" xref="S3.SS1.p1.19.m2.2.2.3.cmml">[</mo><mrow id="S3.SS1.p1.19.m2.1.1.1.1" xref="S3.SS1.p1.19.m2.1.1.1.1.cmml"><mo mathcolor="#000000" id="S3.SS1.p1.19.m2.1.1.1.1a" xref="S3.SS1.p1.19.m2.1.1.1.1.cmml">−</mo><msup id="S3.SS1.p1.19.m2.1.1.1.1.2" xref="S3.SS1.p1.19.m2.1.1.1.1.2.cmml"><mn mathcolor="#000000" id="S3.SS1.p1.19.m2.1.1.1.1.2.2" xref="S3.SS1.p1.19.m2.1.1.1.1.2.2.cmml">2</mn><mrow id="S3.SS1.p1.19.m2.1.1.1.1.2.3" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3.cmml"><mi mathcolor="#000000" id="S3.SS1.p1.19.m2.1.1.1.1.2.3.2" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3.2.cmml">b</mi><mo mathcolor="#000000" id="S3.SS1.p1.19.m2.1.1.1.1.2.3.1" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.19.m2.1.1.1.1.2.3.3" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3.3.cmml">1</mn></mrow></msup></mrow><mo mathcolor="#000000" id="S3.SS1.p1.19.m2.2.2.2.4" xref="S3.SS1.p1.19.m2.2.2.3.cmml">,</mo><mrow id="S3.SS1.p1.19.m2.2.2.2.2" xref="S3.SS1.p1.19.m2.2.2.2.2.cmml"><msup id="S3.SS1.p1.19.m2.2.2.2.2.2" xref="S3.SS1.p1.19.m2.2.2.2.2.2.cmml"><mn mathcolor="#000000" id="S3.SS1.p1.19.m2.2.2.2.2.2.2" xref="S3.SS1.p1.19.m2.2.2.2.2.2.2.cmml">2</mn><mrow id="S3.SS1.p1.19.m2.2.2.2.2.2.3" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3.cmml"><mi mathcolor="#000000" id="S3.SS1.p1.19.m2.2.2.2.2.2.3.2" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3.2.cmml">b</mi><mo mathcolor="#000000" id="S3.SS1.p1.19.m2.2.2.2.2.2.3.1" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.19.m2.2.2.2.2.2.3.3" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3.3.cmml">1</mn></mrow></msup><mo mathcolor="#000000" id="S3.SS1.p1.19.m2.2.2.2.2.1" xref="S3.SS1.p1.19.m2.2.2.2.2.1.cmml">−</mo><mn mathcolor="#000000" id="S3.SS1.p1.19.m2.2.2.2.2.3" xref="S3.SS1.p1.19.m2.2.2.2.2.3.cmml">1</mn></mrow><mo mathcolor="#000000" stretchy="false" id="S3.SS1.p1.19.m2.2.2.2.5" xref="S3.SS1.p1.19.m2.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.19.m2.2b"><interval closure="closed" id="S3.SS1.p1.19.m2.2.2.3.cmml" xref="S3.SS1.p1.19.m2.2.2.2"><apply id="S3.SS1.p1.19.m2.1.1.1.1.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1"><minus id="S3.SS1.p1.19.m2.1.1.1.1.1.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1"></minus><apply id="S3.SS1.p1.19.m2.1.1.1.1.2.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.19.m2.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S3.SS1.p1.19.m2.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1.2.2">2</cn><apply id="S3.SS1.p1.19.m2.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3"><minus id="S3.SS1.p1.19.m2.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3.1"></minus><ci id="S3.SS1.p1.19.m2.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3.2">𝑏</ci><cn type="integer" id="S3.SS1.p1.19.m2.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p1.19.m2.1.1.1.1.2.3.3">1</cn></apply></apply></apply><apply id="S3.SS1.p1.19.m2.2.2.2.2.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2"><minus id="S3.SS1.p1.19.m2.2.2.2.2.1.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.1"></minus><apply id="S3.SS1.p1.19.m2.2.2.2.2.2.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.19.m2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.2">superscript</csymbol><cn type="integer" id="S3.SS1.p1.19.m2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.2.2">2</cn><apply id="S3.SS1.p1.19.m2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3"><minus id="S3.SS1.p1.19.m2.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3.1"></minus><ci id="S3.SS1.p1.19.m2.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3.2">𝑏</ci><cn type="integer" id="S3.SS1.p1.19.m2.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.2.3.3">1</cn></apply></apply><cn type="integer" id="S3.SS1.p1.19.m2.2.2.2.2.3.cmml" xref="S3.SS1.p1.19.m2.2.2.2.2.3">1</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.19.m2.2c">[-2^{b-1},2^{b-1}-1]</annotation></semantics></math>. The clip operation can be defined as follows:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.9" class="ltx_Math" alttext="clip(x_{t},l,u)=\begin{cases}l&amp;\text{if }x_{t}&lt;l\\
x&amp;\text{if }l\leq x_{t}\leq u\\
u&amp;\text{if }x&gt;u,\end{cases}" display="block"><semantics id="S3.E4.m1.9a"><mrow id="S3.E4.m1.9.9" xref="S3.E4.m1.9.9.cmml"><mrow id="S3.E4.m1.9.9.1" xref="S3.E4.m1.9.9.1.cmml"><mi id="S3.E4.m1.9.9.1.3" xref="S3.E4.m1.9.9.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.9.9.1.2" xref="S3.E4.m1.9.9.1.2.cmml">​</mo><mi id="S3.E4.m1.9.9.1.4" xref="S3.E4.m1.9.9.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.9.9.1.2a" xref="S3.E4.m1.9.9.1.2.cmml">​</mo><mi id="S3.E4.m1.9.9.1.5" xref="S3.E4.m1.9.9.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.9.9.1.2b" xref="S3.E4.m1.9.9.1.2.cmml">​</mo><mi id="S3.E4.m1.9.9.1.6" xref="S3.E4.m1.9.9.1.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.9.9.1.2c" xref="S3.E4.m1.9.9.1.2.cmml">​</mo><mrow id="S3.E4.m1.9.9.1.1.1" xref="S3.E4.m1.9.9.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.9.9.1.1.1.2" xref="S3.E4.m1.9.9.1.1.2.cmml">(</mo><msub id="S3.E4.m1.9.9.1.1.1.1" xref="S3.E4.m1.9.9.1.1.1.1.cmml"><mi id="S3.E4.m1.9.9.1.1.1.1.2" xref="S3.E4.m1.9.9.1.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.9.9.1.1.1.1.3" xref="S3.E4.m1.9.9.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E4.m1.9.9.1.1.1.3" xref="S3.E4.m1.9.9.1.1.2.cmml">,</mo><mi id="S3.E4.m1.7.7" xref="S3.E4.m1.7.7.cmml">l</mi><mo id="S3.E4.m1.9.9.1.1.1.4" xref="S3.E4.m1.9.9.1.1.2.cmml">,</mo><mi id="S3.E4.m1.8.8" xref="S3.E4.m1.8.8.cmml">u</mi><mo stretchy="false" id="S3.E4.m1.9.9.1.1.1.5" xref="S3.E4.m1.9.9.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.9.9.2" xref="S3.E4.m1.9.9.2.cmml">=</mo><mrow id="S3.E4.m1.6.6" xref="S3.E4.m1.9.9.3.1.cmml"><mo id="S3.E4.m1.6.6.7" xref="S3.E4.m1.9.9.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E4.m1.6.6.6" xref="S3.E4.m1.9.9.3.1.cmml"><mtr id="S3.E4.m1.6.6.6a" xref="S3.E4.m1.9.9.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.6.6.6b" xref="S3.E4.m1.9.9.3.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml">l</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.6.6.6c" xref="S3.E4.m1.9.9.3.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1" xref="S3.E4.m1.2.2.2.2.2.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1.2" xref="S3.E4.m1.2.2.2.2.2.1.2.cmml"><mtext id="S3.E4.m1.2.2.2.2.2.1.2.2" xref="S3.E4.m1.2.2.2.2.2.1.2.2a.cmml">if </mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.2.1.2.1" xref="S3.E4.m1.2.2.2.2.2.1.2.1.cmml">​</mo><msub id="S3.E4.m1.2.2.2.2.2.1.2.3" xref="S3.E4.m1.2.2.2.2.2.1.2.3.cmml"><mi id="S3.E4.m1.2.2.2.2.2.1.2.3.2" xref="S3.E4.m1.2.2.2.2.2.1.2.3.2.cmml">x</mi><mi id="S3.E4.m1.2.2.2.2.2.1.2.3.3" xref="S3.E4.m1.2.2.2.2.2.1.2.3.3.cmml">t</mi></msub></mrow><mo id="S3.E4.m1.2.2.2.2.2.1.1" xref="S3.E4.m1.2.2.2.2.2.1.1.cmml">&lt;</mo><mi id="S3.E4.m1.2.2.2.2.2.1.3" xref="S3.E4.m1.2.2.2.2.2.1.3.cmml">l</mi></mrow></mtd></mtr><mtr id="S3.E4.m1.6.6.6d" xref="S3.E4.m1.9.9.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.6.6.6e" xref="S3.E4.m1.9.9.3.1.cmml"><mi id="S3.E4.m1.3.3.3.3.1.1" xref="S3.E4.m1.3.3.3.3.1.1.cmml">x</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.6.6.6f" xref="S3.E4.m1.9.9.3.1.cmml"><mrow id="S3.E4.m1.4.4.4.4.2.1" xref="S3.E4.m1.4.4.4.4.2.1.cmml"><mrow id="S3.E4.m1.4.4.4.4.2.1.2" xref="S3.E4.m1.4.4.4.4.2.1.2.cmml"><mtext id="S3.E4.m1.4.4.4.4.2.1.2.2" xref="S3.E4.m1.4.4.4.4.2.1.2.2a.cmml">if </mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.4.4.2.1.2.1" xref="S3.E4.m1.4.4.4.4.2.1.2.1.cmml">​</mo><mi id="S3.E4.m1.4.4.4.4.2.1.2.3" xref="S3.E4.m1.4.4.4.4.2.1.2.3.cmml">l</mi></mrow><mo id="S3.E4.m1.4.4.4.4.2.1.3" xref="S3.E4.m1.4.4.4.4.2.1.3.cmml">≤</mo><msub id="S3.E4.m1.4.4.4.4.2.1.4" xref="S3.E4.m1.4.4.4.4.2.1.4.cmml"><mi id="S3.E4.m1.4.4.4.4.2.1.4.2" xref="S3.E4.m1.4.4.4.4.2.1.4.2.cmml">x</mi><mi id="S3.E4.m1.4.4.4.4.2.1.4.3" xref="S3.E4.m1.4.4.4.4.2.1.4.3.cmml">t</mi></msub><mo id="S3.E4.m1.4.4.4.4.2.1.5" xref="S3.E4.m1.4.4.4.4.2.1.5.cmml">≤</mo><mi id="S3.E4.m1.4.4.4.4.2.1.6" xref="S3.E4.m1.4.4.4.4.2.1.6.cmml">u</mi></mrow></mtd></mtr><mtr id="S3.E4.m1.6.6.6g" xref="S3.E4.m1.9.9.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.6.6.6h" xref="S3.E4.m1.9.9.3.1.cmml"><mi id="S3.E4.m1.5.5.5.5.1.1" xref="S3.E4.m1.5.5.5.5.1.1.cmml">u</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.6.6.6i" xref="S3.E4.m1.9.9.3.1.cmml"><mrow id="S3.E4.m1.6.6.6.6.2.1.1" xref="S3.E4.m1.6.6.6.6.2.1.1.1.cmml"><mrow id="S3.E4.m1.6.6.6.6.2.1.1.1" xref="S3.E4.m1.6.6.6.6.2.1.1.1.cmml"><mrow id="S3.E4.m1.6.6.6.6.2.1.1.1.2" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.cmml"><mtext id="S3.E4.m1.6.6.6.6.2.1.1.1.2.2" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.2a.cmml">if </mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.2.1.1.1.2.1" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.1.cmml">​</mo><mi id="S3.E4.m1.6.6.6.6.2.1.1.1.2.3" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.3.cmml">x</mi></mrow><mo id="S3.E4.m1.6.6.6.6.2.1.1.1.1" xref="S3.E4.m1.6.6.6.6.2.1.1.1.1.cmml">&gt;</mo><mi id="S3.E4.m1.6.6.6.6.2.1.1.1.3" xref="S3.E4.m1.6.6.6.6.2.1.1.1.3.cmml">u</mi></mrow><mo id="S3.E4.m1.6.6.6.6.2.1.1.2" xref="S3.E4.m1.6.6.6.6.2.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.9b"><apply id="S3.E4.m1.9.9.cmml" xref="S3.E4.m1.9.9"><eq id="S3.E4.m1.9.9.2.cmml" xref="S3.E4.m1.9.9.2"></eq><apply id="S3.E4.m1.9.9.1.cmml" xref="S3.E4.m1.9.9.1"><times id="S3.E4.m1.9.9.1.2.cmml" xref="S3.E4.m1.9.9.1.2"></times><ci id="S3.E4.m1.9.9.1.3.cmml" xref="S3.E4.m1.9.9.1.3">𝑐</ci><ci id="S3.E4.m1.9.9.1.4.cmml" xref="S3.E4.m1.9.9.1.4">𝑙</ci><ci id="S3.E4.m1.9.9.1.5.cmml" xref="S3.E4.m1.9.9.1.5">𝑖</ci><ci id="S3.E4.m1.9.9.1.6.cmml" xref="S3.E4.m1.9.9.1.6">𝑝</ci><vector id="S3.E4.m1.9.9.1.1.2.cmml" xref="S3.E4.m1.9.9.1.1.1"><apply id="S3.E4.m1.9.9.1.1.1.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.9.9.1.1.1.1.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.9.9.1.1.1.1.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.2">𝑥</ci><ci id="S3.E4.m1.9.9.1.1.1.1.3.cmml" xref="S3.E4.m1.9.9.1.1.1.1.3">𝑡</ci></apply><ci id="S3.E4.m1.7.7.cmml" xref="S3.E4.m1.7.7">𝑙</ci><ci id="S3.E4.m1.8.8.cmml" xref="S3.E4.m1.8.8">𝑢</ci></vector></apply><apply id="S3.E4.m1.9.9.3.1.cmml" xref="S3.E4.m1.6.6"><csymbol cd="latexml" id="S3.E4.m1.9.9.3.1.1.cmml" xref="S3.E4.m1.6.6.7">cases</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1">𝑙</ci><apply id="S3.E4.m1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1"><lt id="S3.E4.m1.2.2.2.2.2.1.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1"></lt><apply id="S3.E4.m1.2.2.2.2.2.1.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2"><times id="S3.E4.m1.2.2.2.2.2.1.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.1"></times><ci id="S3.E4.m1.2.2.2.2.2.1.2.2a.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.2"><mtext id="S3.E4.m1.2.2.2.2.2.1.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.2">if </mtext></ci><apply id="S3.E4.m1.2.2.2.2.2.1.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.2.1.2.3.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.2.1.2.3.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.3.2">𝑥</ci><ci id="S3.E4.m1.2.2.2.2.2.1.2.3.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.3.3">𝑡</ci></apply></apply><ci id="S3.E4.m1.2.2.2.2.2.1.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.3">𝑙</ci></apply><ci id="S3.E4.m1.3.3.3.3.1.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1">𝑥</ci><apply id="S3.E4.m1.4.4.4.4.2.1.cmml" xref="S3.E4.m1.4.4.4.4.2.1"><and id="S3.E4.m1.4.4.4.4.2.1a.cmml" xref="S3.E4.m1.4.4.4.4.2.1"></and><apply id="S3.E4.m1.4.4.4.4.2.1b.cmml" xref="S3.E4.m1.4.4.4.4.2.1"><leq id="S3.E4.m1.4.4.4.4.2.1.3.cmml" xref="S3.E4.m1.4.4.4.4.2.1.3"></leq><apply id="S3.E4.m1.4.4.4.4.2.1.2.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2"><times id="S3.E4.m1.4.4.4.4.2.1.2.1.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.1"></times><ci id="S3.E4.m1.4.4.4.4.2.1.2.2a.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.2"><mtext id="S3.E4.m1.4.4.4.4.2.1.2.2.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.2">if </mtext></ci><ci id="S3.E4.m1.4.4.4.4.2.1.2.3.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.3">𝑙</ci></apply><apply id="S3.E4.m1.4.4.4.4.2.1.4.cmml" xref="S3.E4.m1.4.4.4.4.2.1.4"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.4.4.2.1.4.1.cmml" xref="S3.E4.m1.4.4.4.4.2.1.4">subscript</csymbol><ci id="S3.E4.m1.4.4.4.4.2.1.4.2.cmml" xref="S3.E4.m1.4.4.4.4.2.1.4.2">𝑥</ci><ci id="S3.E4.m1.4.4.4.4.2.1.4.3.cmml" xref="S3.E4.m1.4.4.4.4.2.1.4.3">𝑡</ci></apply></apply><apply id="S3.E4.m1.4.4.4.4.2.1c.cmml" xref="S3.E4.m1.4.4.4.4.2.1"><leq id="S3.E4.m1.4.4.4.4.2.1.5.cmml" xref="S3.E4.m1.4.4.4.4.2.1.5"></leq><share href="#S3.E4.m1.4.4.4.4.2.1.4.cmml" id="S3.E4.m1.4.4.4.4.2.1d.cmml" xref="S3.E4.m1.4.4.4.4.2.1"></share><ci id="S3.E4.m1.4.4.4.4.2.1.6.cmml" xref="S3.E4.m1.4.4.4.4.2.1.6">𝑢</ci></apply></apply><ci id="S3.E4.m1.5.5.5.5.1.1.cmml" xref="S3.E4.m1.5.5.5.5.1.1">𝑢</ci><apply id="S3.E4.m1.6.6.6.6.2.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1"><gt id="S3.E4.m1.6.6.6.6.2.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1.1.1"></gt><apply id="S3.E4.m1.6.6.6.6.2.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2"><times id="S3.E4.m1.6.6.6.6.2.1.1.1.2.1.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.1"></times><ci id="S3.E4.m1.6.6.6.6.2.1.1.1.2.2a.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.2"><mtext id="S3.E4.m1.6.6.6.6.2.1.1.1.2.2.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.2">if </mtext></ci><ci id="S3.E4.m1.6.6.6.6.2.1.1.1.2.3.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1.1.2.3">𝑥</ci></apply><ci id="S3.E4.m1.6.6.6.6.2.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.2.1.1.1.3">𝑢</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.9c">clip(x_{t},l,u)=\begin{cases}l&amp;\text{if }x_{t}&lt;l\\
x&amp;\text{if }l\leq x_{t}\leq u\\
u&amp;\text{if }x&gt;u,\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.22" class="ltx_p">where <math id="S3.SS1.p1.20.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS1.p1.20.m1.1a"><mi id="S3.SS1.p1.20.m1.1.1" xref="S3.SS1.p1.20.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.20.m1.1b"><ci id="S3.SS1.p1.20.m1.1.1.cmml" xref="S3.SS1.p1.20.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.20.m1.1c">l</annotation></semantics></math> and <math id="S3.SS1.p1.21.m2.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S3.SS1.p1.21.m2.1a"><mi id="S3.SS1.p1.21.m2.1.1" xref="S3.SS1.p1.21.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.21.m2.1b"><ci id="S3.SS1.p1.21.m2.1.1.cmml" xref="S3.SS1.p1.21.m2.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.21.m2.1c">u</annotation></semantics></math> are the minimum and maximum values of the quantization value range.
The quantization of real value <math id="S3.SS1.p1.22.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p1.22.m3.1a"><mi id="S3.SS1.p1.22.m3.1.1" xref="S3.SS1.p1.22.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.22.m3.1b"><ci id="S3.SS1.p1.22.m3.1.1.cmml" xref="S3.SS1.p1.22.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.22.m3.1c">x</annotation></semantics></math> to a b-bit precision format is given by:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.6" class="ltx_Math" alttext="Q(x,b)=clip(T(x,s,z),-2^{b-1},2^{b-1}-1)." display="block"><semantics id="S3.E5.m1.6a"><mrow id="S3.E5.m1.6.6.1" xref="S3.E5.m1.6.6.1.1.cmml"><mrow id="S3.E5.m1.6.6.1.1" xref="S3.E5.m1.6.6.1.1.cmml"><mrow id="S3.E5.m1.6.6.1.1.5" xref="S3.E5.m1.6.6.1.1.5.cmml"><mi id="S3.E5.m1.6.6.1.1.5.2" xref="S3.E5.m1.6.6.1.1.5.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.6.6.1.1.5.1" xref="S3.E5.m1.6.6.1.1.5.1.cmml">​</mo><mrow id="S3.E5.m1.6.6.1.1.5.3.2" xref="S3.E5.m1.6.6.1.1.5.3.1.cmml"><mo stretchy="false" id="S3.E5.m1.6.6.1.1.5.3.2.1" xref="S3.E5.m1.6.6.1.1.5.3.1.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">x</mi><mo id="S3.E5.m1.6.6.1.1.5.3.2.2" xref="S3.E5.m1.6.6.1.1.5.3.1.cmml">,</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">b</mi><mo stretchy="false" id="S3.E5.m1.6.6.1.1.5.3.2.3" xref="S3.E5.m1.6.6.1.1.5.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.6.6.1.1.4" xref="S3.E5.m1.6.6.1.1.4.cmml">=</mo><mrow id="S3.E5.m1.6.6.1.1.3" xref="S3.E5.m1.6.6.1.1.3.cmml"><mi id="S3.E5.m1.6.6.1.1.3.5" xref="S3.E5.m1.6.6.1.1.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.6.6.1.1.3.4" xref="S3.E5.m1.6.6.1.1.3.4.cmml">​</mo><mi id="S3.E5.m1.6.6.1.1.3.6" xref="S3.E5.m1.6.6.1.1.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.6.6.1.1.3.4a" xref="S3.E5.m1.6.6.1.1.3.4.cmml">​</mo><mi id="S3.E5.m1.6.6.1.1.3.7" xref="S3.E5.m1.6.6.1.1.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.6.6.1.1.3.4b" xref="S3.E5.m1.6.6.1.1.3.4.cmml">​</mo><mi id="S3.E5.m1.6.6.1.1.3.8" xref="S3.E5.m1.6.6.1.1.3.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.6.6.1.1.3.4c" xref="S3.E5.m1.6.6.1.1.3.4.cmml">​</mo><mrow id="S3.E5.m1.6.6.1.1.3.3.3" xref="S3.E5.m1.6.6.1.1.3.3.4.cmml"><mo stretchy="false" id="S3.E5.m1.6.6.1.1.3.3.3.4" xref="S3.E5.m1.6.6.1.1.3.3.4.cmml">(</mo><mrow id="S3.E5.m1.6.6.1.1.1.1.1.1" xref="S3.E5.m1.6.6.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.6.6.1.1.1.1.1.1.2" xref="S3.E5.m1.6.6.1.1.1.1.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.6.6.1.1.1.1.1.1.1" xref="S3.E5.m1.6.6.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E5.m1.6.6.1.1.1.1.1.1.3.2" xref="S3.E5.m1.6.6.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E5.m1.6.6.1.1.1.1.1.1.3.2.1" xref="S3.E5.m1.6.6.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml">x</mi><mo id="S3.E5.m1.6.6.1.1.1.1.1.1.3.2.2" xref="S3.E5.m1.6.6.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml">s</mi><mo id="S3.E5.m1.6.6.1.1.1.1.1.1.3.2.3" xref="S3.E5.m1.6.6.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml">z</mi><mo stretchy="false" id="S3.E5.m1.6.6.1.1.1.1.1.1.3.2.4" xref="S3.E5.m1.6.6.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.6.6.1.1.3.3.3.5" xref="S3.E5.m1.6.6.1.1.3.3.4.cmml">,</mo><mrow id="S3.E5.m1.6.6.1.1.2.2.2.2" xref="S3.E5.m1.6.6.1.1.2.2.2.2.cmml"><mo id="S3.E5.m1.6.6.1.1.2.2.2.2a" xref="S3.E5.m1.6.6.1.1.2.2.2.2.cmml">−</mo><msup id="S3.E5.m1.6.6.1.1.2.2.2.2.2" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.cmml"><mn id="S3.E5.m1.6.6.1.1.2.2.2.2.2.2" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.2.cmml">2</mn><mrow id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.cmml"><mi id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.2" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.2.cmml">b</mi><mo id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.1" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.1.cmml">−</mo><mn id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.3" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.3.cmml">1</mn></mrow></msup></mrow><mo id="S3.E5.m1.6.6.1.1.3.3.3.6" xref="S3.E5.m1.6.6.1.1.3.3.4.cmml">,</mo><mrow id="S3.E5.m1.6.6.1.1.3.3.3.3" xref="S3.E5.m1.6.6.1.1.3.3.3.3.cmml"><msup id="S3.E5.m1.6.6.1.1.3.3.3.3.2" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.cmml"><mn id="S3.E5.m1.6.6.1.1.3.3.3.3.2.2" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.2.cmml">2</mn><mrow id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.cmml"><mi id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.2" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.2.cmml">b</mi><mo id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.1" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.1.cmml">−</mo><mn id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.3" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.3.cmml">1</mn></mrow></msup><mo id="S3.E5.m1.6.6.1.1.3.3.3.3.1" xref="S3.E5.m1.6.6.1.1.3.3.3.3.1.cmml">−</mo><mn id="S3.E5.m1.6.6.1.1.3.3.3.3.3" xref="S3.E5.m1.6.6.1.1.3.3.3.3.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.E5.m1.6.6.1.1.3.3.3.7" xref="S3.E5.m1.6.6.1.1.3.3.4.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E5.m1.6.6.1.2" xref="S3.E5.m1.6.6.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.6b"><apply id="S3.E5.m1.6.6.1.1.cmml" xref="S3.E5.m1.6.6.1"><eq id="S3.E5.m1.6.6.1.1.4.cmml" xref="S3.E5.m1.6.6.1.1.4"></eq><apply id="S3.E5.m1.6.6.1.1.5.cmml" xref="S3.E5.m1.6.6.1.1.5"><times id="S3.E5.m1.6.6.1.1.5.1.cmml" xref="S3.E5.m1.6.6.1.1.5.1"></times><ci id="S3.E5.m1.6.6.1.1.5.2.cmml" xref="S3.E5.m1.6.6.1.1.5.2">𝑄</ci><interval closure="open" id="S3.E5.m1.6.6.1.1.5.3.1.cmml" xref="S3.E5.m1.6.6.1.1.5.3.2"><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝑥</ci><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">𝑏</ci></interval></apply><apply id="S3.E5.m1.6.6.1.1.3.cmml" xref="S3.E5.m1.6.6.1.1.3"><times id="S3.E5.m1.6.6.1.1.3.4.cmml" xref="S3.E5.m1.6.6.1.1.3.4"></times><ci id="S3.E5.m1.6.6.1.1.3.5.cmml" xref="S3.E5.m1.6.6.1.1.3.5">𝑐</ci><ci id="S3.E5.m1.6.6.1.1.3.6.cmml" xref="S3.E5.m1.6.6.1.1.3.6">𝑙</ci><ci id="S3.E5.m1.6.6.1.1.3.7.cmml" xref="S3.E5.m1.6.6.1.1.3.7">𝑖</ci><ci id="S3.E5.m1.6.6.1.1.3.8.cmml" xref="S3.E5.m1.6.6.1.1.3.8">𝑝</ci><vector id="S3.E5.m1.6.6.1.1.3.3.4.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3"><apply id="S3.E5.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.1"><times id="S3.E5.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.1.1"></times><ci id="S3.E5.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.1.2">𝑇</ci><vector id="S3.E5.m1.6.6.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.1.3.2"><ci id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3">𝑥</ci><ci id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4">𝑠</ci><ci id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5">𝑧</ci></vector></apply><apply id="S3.E5.m1.6.6.1.1.2.2.2.2.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2"><minus id="S3.E5.m1.6.6.1.1.2.2.2.2.1.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2"></minus><apply id="S3.E5.m1.6.6.1.1.2.2.2.2.2.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.1.1.2.2.2.2.2.1.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2">superscript</csymbol><cn type="integer" id="S3.E5.m1.6.6.1.1.2.2.2.2.2.2.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.2">2</cn><apply id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3"><minus id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.1.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.1"></minus><ci id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.2.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.2">𝑏</ci><cn type="integer" id="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.3.cmml" xref="S3.E5.m1.6.6.1.1.2.2.2.2.2.3.3">1</cn></apply></apply></apply><apply id="S3.E5.m1.6.6.1.1.3.3.3.3.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3"><minus id="S3.E5.m1.6.6.1.1.3.3.3.3.1.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.1"></minus><apply id="S3.E5.m1.6.6.1.1.3.3.3.3.2.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.1.1.3.3.3.3.2.1.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2">superscript</csymbol><cn type="integer" id="S3.E5.m1.6.6.1.1.3.3.3.3.2.2.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.2">2</cn><apply id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3"><minus id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.1.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.1"></minus><ci id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.2.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.2">𝑏</ci><cn type="integer" id="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.3.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.2.3.3">1</cn></apply></apply><cn type="integer" id="S3.E5.m1.6.6.1.1.3.3.3.3.3.cmml" xref="S3.E5.m1.6.6.1.1.3.3.3.3.3">1</cn></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.6c">Q(x,b)=clip(T(x,s,z),-2^{b-1},2^{b-1}-1).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.23" class="ltx_p">Dequantization operation that approximates the real value of the quantized one is defined as follows:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.2" class="ltx_Math" alttext="D(q)=s\cdot(q+z)." display="block"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1.3" xref="S3.E6.m1.2.2.1.1.3.cmml"><mi id="S3.E6.m1.2.2.1.1.3.2" xref="S3.E6.m1.2.2.1.1.3.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.3.1" xref="S3.E6.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S3.E6.m1.2.2.1.1.3.3.2" xref="S3.E6.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.3.3.2.1" xref="S3.E6.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">q</mi><mo stretchy="false" id="S3.E6.m1.2.2.1.1.3.3.2.2" xref="S3.E6.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.2.2.1.1.2" xref="S3.E6.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.2.2.1.1.1" xref="S3.E6.m1.2.2.1.1.1.cmml"><mi id="S3.E6.m1.2.2.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.3.cmml">s</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.2.2.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.2.cmml">⋅</mo><mrow id="S3.E6.m1.2.2.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2.cmml">q</mi><mo id="S3.E6.m1.2.2.1.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml">+</mo><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.3.cmml">z</mi></mrow><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E6.m1.2.2.1.2" xref="S3.E6.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.2.1.1.cmml" xref="S3.E6.m1.2.2.1"><eq id="S3.E6.m1.2.2.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.2"></eq><apply id="S3.E6.m1.2.2.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.3"><times id="S3.E6.m1.2.2.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.3.1"></times><ci id="S3.E6.m1.2.2.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.3.2">𝐷</ci><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">𝑞</ci></apply><apply id="S3.E6.m1.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1"><ci id="S3.E6.m1.2.2.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.2">⋅</ci><ci id="S3.E6.m1.2.2.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.3">𝑠</ci><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1"><plus id="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1"></plus><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2">𝑞</ci><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.3">𝑧</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">D(q)=s\cdot(q+z).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Tensor Quantization Granularity</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">Tensor quantization granularity defines how the quantization operator parameters are calculated and shared among the model tensors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.
Quantization granularity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> can be categorized into three groups: per-layer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, per-group of channels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and per-channel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. In this work, we opt to use the popular choice of per-channel granularity as it provides a high quantization resolution and it has repeatedly led to high accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.
Per-channel granularity uses <span id="S3.SS1.SSS0.Px1.p1.1.1" class="ltx_text" style="color:#000000;">a fixed quantization parameter for each channel</span>, independently from other channels.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.2.1.1" class="ltx_tr">
<td id="S3.T1.2.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.2.1.1.1.1" class="ltx_text">Model</span></td>
<td id="S3.T1.2.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.2.1.1.2.1" class="ltx_text">param</span></td>
<td id="S3.T1.2.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.2.1.1.3.1" class="ltx_text">
<span id="S3.T1.2.1.1.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.2.1.1.3.1.1.1" class="ltx_tr">
<span id="S3.T1.2.1.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Quantization</span></span>
<span id="S3.T1.2.1.1.3.1.1.2" class="ltx_tr">
<span id="S3.T1.2.1.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">data</span></span>
</span></span></td>
<td id="S3.T1.2.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.2.1.1.4.1" class="ltx_text">Bits</span></td>
<td id="S3.T1.2.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.2.1.1.5.1" class="ltx_text">Size (MB)</span></td>
<td id="S3.T1.2.1.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">LFW</td>
<td id="S3.T1.2.1.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">CFP</td>
<td id="S3.T1.2.1.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AgeDb-30</td>
<td id="S3.T1.2.1.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">CALFW</td>
<td id="S3.T1.2.1.1.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">CPLFW</td>
<td id="S3.T1.2.1.1.11" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">IJB-C</td>
<td id="S3.T1.2.1.1.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">IJB-B</td>
</tr>
<tr id="S3.T1.2.2.2" class="ltx_tr">
<td id="S3.T1.2.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="5">Accuracy (%)</td>
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2">TAR@FAR 1e-4 (%)</td>
</tr>
<tr id="S3.T1.2.3.3" class="ltx_tr">
<td id="S3.T1.2.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.3.3.1.1" class="ltx_text">ResNet100</span></td>
<td id="S3.T1.2.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.3.3.2.1" class="ltx_text">65.2M</span></td>
<td id="S3.T1.2.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S3.T1.2.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FP32</td>
<td id="S3.T1.2.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">261.22</td>
<td id="S3.T1.2.3.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.83</td>
<td id="S3.T1.2.3.3.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">98.40</td>
<td id="S3.T1.2.3.3.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">98.33</td>
<td id="S3.T1.2.3.3.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.13</td>
<td id="S3.T1.2.3.3.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">93.22</td>
<td id="S3.T1.2.3.3.11" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.50</td>
<td id="S3.T1.2.3.3.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.25</td>
</tr>
<tr id="S3.T1.2.4.4" class="ltx_tr">
<td id="S3.T1.2.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">65.31</td>
<td id="S3.T1.2.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.4.4.4.1" class="ltx_text ltx_font_bold">99.80</span></td>
<td id="S3.T1.2.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.4.4.5.1" class="ltx_text ltx_font_bold">98.31</span></td>
<td id="S3.T1.2.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.4.4.6.1" class="ltx_text ltx_font_bold">98.13</span></td>
<td id="S3.T1.2.4.4.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.4.4.7.1" class="ltx_text ltx_font_bold">96.05</span></td>
<td id="S3.T1.2.4.4.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.4.4.8.1" class="ltx_text ltx_font_bold">92.92</span></td>
<td id="S3.T1.2.4.4.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.4.4.9.1" class="ltx_text ltx_font_bold">96.38</span></td>
<td id="S3.T1.2.4.4.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.4.4.10.1" class="ltx_text ltx_font_bold">95.13</span></td>
</tr>
<tr id="S3.T1.2.5.5" class="ltx_tr">
<td id="S3.T1.2.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.5.5.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">65.31</td>
<td id="S3.T1.2.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.5.5.4.1" class="ltx_text ltx_font_bold">99.80</span></td>
<td id="S3.T1.2.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">98.14</td>
<td id="S3.T1.2.5.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97.95</td>
<td id="S3.T1.2.5.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.02</td>
<td id="S3.T1.2.5.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">92.90</td>
<td id="S3.T1.2.5.5.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.09</td>
<td id="S3.T1.2.5.5.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.74</td>
</tr>
<tr id="S3.T1.2.6.6" class="ltx_tr">
<td id="S3.T1.2.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.01</td>
<td id="S3.T1.2.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.6.6.4.1" class="ltx_text ltx_font_bold">99.55</span></td>
<td id="S3.T1.2.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">89.14</td>
<td id="S3.T1.2.6.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.85</td>
<td id="S3.T1.2.6.6.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.42</td>
<td id="S3.T1.2.6.6.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">85.63</td>
<td id="S3.T1.2.6.6.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">85.80</td>
<td id="S3.T1.2.6.6.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">84.08</td>
</tr>
<tr id="S3.T1.2.7.7" class="ltx_tr">
<td id="S3.T1.2.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.7.7.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.01</td>
<td id="S3.T1.2.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.45</td>
<td id="S3.T1.2.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.7.7.5.1" class="ltx_text ltx_font_bold">91.00</span></td>
<td id="S3.T1.2.7.7.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.7.7.6.1" class="ltx_text ltx_font_bold">96.43</span></td>
<td id="S3.T1.2.7.7.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.7.7.7.1" class="ltx_text ltx_font_bold">95.58</span></td>
<td id="S3.T1.2.7.7.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.7.7.8.1" class="ltx_text ltx_font_bold">86.60</span></td>
<td id="S3.T1.2.7.7.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.7.7.9.1" class="ltx_text ltx_font_bold">87.00</span></td>
<td id="S3.T1.2.7.7.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.7.7.10.1" class="ltx_text ltx_font_bold">85.06</span></td>
</tr>
<tr id="S3.T1.2.8.8" class="ltx_tr">
<td id="S3.T1.2.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.8.8.1.1" class="ltx_text">ResNet50</span></td>
<td id="S3.T1.2.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.8.8.2.1" class="ltx_text">43.6M</span></td>
<td id="S3.T1.2.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S3.T1.2.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FP32</td>
<td id="S3.T1.2.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">174.68</td>
<td id="S3.T1.2.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.80</td>
<td id="S3.T1.2.8.8.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">98.01</td>
<td id="S3.T1.2.8.8.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">98.08</td>
<td id="S3.T1.2.8.8.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.10</td>
<td id="S3.T1.2.8.8.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">92.43</td>
<td id="S3.T1.2.8.8.11" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.74</td>
<td id="S3.T1.2.8.8.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.19</td>
</tr>
<tr id="S3.T1.2.9.9" class="ltx_tr">
<td id="S3.T1.2.9.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.67</td>
<td id="S3.T1.2.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.9.9.4.1" class="ltx_text ltx_font_bold">99.78</span></td>
<td id="S3.T1.2.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.9.9.5.1" class="ltx_text ltx_font_bold">97.70</span></td>
<td id="S3.T1.2.9.9.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.9.9.6.1" class="ltx_text ltx_font_bold">98.00</span></td>
<td id="S3.T1.2.9.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.9.9.7.1" class="ltx_text ltx_font_bold">96.00</span></td>
<td id="S3.T1.2.9.9.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.9.9.8.1" class="ltx_text ltx_font_bold">92.17</span></td>
<td id="S3.T1.2.9.9.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.9.9.9.1" class="ltx_text ltx_font_bold">95.66</span></td>
<td id="S3.T1.2.9.9.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.9.9.10.1" class="ltx_text ltx_font_bold">94.15</span></td>
</tr>
<tr id="S3.T1.2.10.10" class="ltx_tr">
<td id="S3.T1.2.10.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.10.10.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.67</td>
<td id="S3.T1.2.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.10.10.4.1" class="ltx_text ltx_font_bold">99.78</span></td>
<td id="S3.T1.2.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97.43</td>
<td id="S3.T1.2.10.10.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97.97</td>
<td id="S3.T1.2.10.10.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.87</td>
<td id="S3.T1.2.10.10.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">92.08</td>
<td id="S3.T1.2.10.10.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.18</td>
<td id="S3.T1.2.10.10.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">93.67</td>
</tr>
<tr id="S3.T1.2.11.11" class="ltx_tr">
<td id="S3.T1.2.11.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.77</td>
<td id="S3.T1.2.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.11.11.4.1" class="ltx_text ltx_font_bold">99.70</span></td>
<td id="S3.T1.2.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.00</td>
<td id="S3.T1.2.11.11.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97.17</td>
<td id="S3.T1.2.11.11.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.11.11.7.1" class="ltx_text ltx_font_bold">95.87</span></td>
<td id="S3.T1.2.11.11.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.17</td>
<td id="S3.T1.2.11.11.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.11.11.9.1" class="ltx_text ltx_font_bold">91.74</span></td>
<td id="S3.T1.2.11.11.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.11.11.10.1" class="ltx_text ltx_font_bold">90.07</span></td>
</tr>
<tr id="S3.T1.2.12.12" class="ltx_tr">
<td id="S3.T1.2.12.12.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.12.12.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.77</td>
<td id="S3.T1.2.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.68</td>
<td id="S3.T1.2.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.12.12.5.1" class="ltx_text ltx_font_bold">95.17</span></td>
<td id="S3.T1.2.12.12.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.12.12.6.1" class="ltx_text ltx_font_bold">97.43</span></td>
<td id="S3.T1.2.12.12.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.70</td>
<td id="S3.T1.2.12.12.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.12.12.8.1" class="ltx_text ltx_font_bold">90.38</span></td>
<td id="S3.T1.2.12.12.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.72</td>
<td id="S3.T1.2.12.12.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">89.44</td>
</tr>
<tr id="S3.T1.2.13.13" class="ltx_tr">
<td id="S3.T1.2.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.13.13.1.1" class="ltx_text">ResNet18</span></td>
<td id="S3.T1.2.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.13.13.2.1" class="ltx_text">24.0M</span></td>
<td id="S3.T1.2.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S3.T1.2.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FP32</td>
<td id="S3.T1.2.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.22</td>
<td id="S3.T1.2.13.13.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.67</td>
<td id="S3.T1.2.13.13.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.47</td>
<td id="S3.T1.2.13.13.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97.13</td>
<td id="S3.T1.2.13.13.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.70</td>
<td id="S3.T1.2.13.13.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">89.73</td>
<td id="S3.T1.2.13.13.11" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">93.56</td>
<td id="S3.T1.2.13.13.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">91.64</td>
</tr>
<tr id="S3.T1.2.14.14" class="ltx_tr">
<td id="S3.T1.2.14.14.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">24.10</td>
<td id="S3.T1.2.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.14.14.4.1" class="ltx_text ltx_font_bold">99.63</span></td>
<td id="S3.T1.2.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.14.14.5.1" class="ltx_text ltx_font_bold">94.46</span></td>
<td id="S3.T1.2.14.14.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97.03</td>
<td id="S3.T1.2.14.14.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.14.14.7.1" class="ltx_text ltx_font_bold">95.72</span></td>
<td id="S3.T1.2.14.14.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">89.48</td>
<td id="S3.T1.2.14.14.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.14.14.9.1" class="ltx_text ltx_font_bold">93.56</span></td>
<td id="S3.T1.2.14.14.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.14.14.10.1" class="ltx_text ltx_font_bold">91.57</span></td>
</tr>
<tr id="S3.T1.2.15.15" class="ltx_tr">
<td id="S3.T1.2.15.15.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.15.15.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">24.10</td>
<td id="S3.T1.2.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.55</td>
<td id="S3.T1.2.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.04</td>
<td id="S3.T1.2.15.15.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.15.15.6.1" class="ltx_text ltx_font_bold">97.07</span></td>
<td id="S3.T1.2.15.15.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.58</td>
<td id="S3.T1.2.15.15.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.15.15.8.1" class="ltx_text ltx_font_bold">89.53</span></td>
<td id="S3.T1.2.15.15.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">92.87</td>
<td id="S3.T1.2.15.15.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">91.01</td>
</tr>
<tr id="S3.T1.2.16.16" class="ltx_tr">
<td id="S3.T1.2.16.16.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.10</td>
<td id="S3.T1.2.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.52</td>
<td id="S3.T1.2.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">93.23</td>
<td id="S3.T1.2.16.16.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.55</td>
<td id="S3.T1.2.16.16.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.16.16.7.1" class="ltx_text ltx_font_bold">95.58</span></td>
<td id="S3.T1.2.16.16.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">88.37</td>
<td id="S3.T1.2.16.16.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.16.16.9.1" class="ltx_text ltx_font_bold">93.03</span></td>
<td id="S3.T1.2.16.16.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.16.16.10.1" class="ltx_text ltx_font_bold">91.08</span></td>
</tr>
<tr id="S3.T1.2.17.17" class="ltx_tr">
<td id="S3.T1.2.17.17.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.17.17.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.10</td>
<td id="S3.T1.2.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.17.17.4.1" class="ltx_text ltx_font_bold">99.55</span></td>
<td id="S3.T1.2.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.17.17.5.1" class="ltx_text ltx_font_bold">93.34</span></td>
<td id="S3.T1.2.17.17.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.17.17.6.1" class="ltx_text ltx_font_bold">96.62</span></td>
<td id="S3.T1.2.17.17.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.32</td>
<td id="S3.T1.2.17.17.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.17.17.8.1" class="ltx_text ltx_font_bold">89.05</span></td>
<td id="S3.T1.2.17.17.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">92.36</td>
<td id="S3.T1.2.17.17.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.38</td>
</tr>
<tr id="S3.T1.2.18.18" class="ltx_tr">
<td id="S3.T1.2.18.18.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.18.18.1.1" class="ltx_text">MobileFaceNet</span></td>
<td id="S3.T1.2.18.18.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" rowspan="5"><span id="S3.T1.2.18.18.2.1" class="ltx_text">1.1M</span></td>
<td id="S3.T1.2.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S3.T1.2.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FP32</td>
<td id="S3.T1.2.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4.21</td>
<td id="S3.T1.2.18.18.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.47</td>
<td id="S3.T1.2.18.18.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">91.59</td>
<td id="S3.T1.2.18.18.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.62</td>
<td id="S3.T1.2.18.18.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.15</td>
<td id="S3.T1.2.18.18.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">87.98</td>
<td id="S3.T1.2.18.18.11" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.88</td>
<td id="S3.T1.2.18.18.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">88.54</td>
</tr>
<tr id="S3.T1.2.19.19" class="ltx_tr">
<td id="S3.T1.2.19.19.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.10</td>
<td id="S3.T1.2.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.19.19.4.1" class="ltx_text ltx_font_bold">99.43</span></td>
<td id="S3.T1.2.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.19.19.5.1" class="ltx_text ltx_font_bold">91.40</span></td>
<td id="S3.T1.2.19.19.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.19.19.6.1" class="ltx_text ltx_font_bold">95.47</span></td>
<td id="S3.T1.2.19.19.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.19.19.7.1" class="ltx_text ltx_font_bold">95.05</span></td>
<td id="S3.T1.2.19.19.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.19.19.8.1" class="ltx_text ltx_font_bold">87.95</span></td>
<td id="S3.T1.2.19.19.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.19.19.9.1" class="ltx_text ltx_font_bold">90.57</span></td>
<td id="S3.T1.2.19.19.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.19.19.10.1" class="ltx_text ltx_font_bold">88.32</span></td>
</tr>
<tr id="S3.T1.2.20.20" class="ltx_tr">
<td id="S3.T1.2.20.20.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.20.20.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w8a8</td>
<td id="S3.T1.2.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.10</td>
<td id="S3.T1.2.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">99.35</td>
<td id="S3.T1.2.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.84</td>
<td id="S3.T1.2.20.20.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.37</td>
<td id="S3.T1.2.20.20.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.78</td>
<td id="S3.T1.2.20.20.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">87.73</td>
<td id="S3.T1.2.20.20.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">89.21</td>
<td id="S3.T1.2.20.20.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">86.98</td>
</tr>
<tr id="S3.T1.2.21.21" class="ltx_tr">
<td id="S3.T1.2.21.21.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Real data</td>
<td id="S3.T1.2.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.79</td>
<td id="S3.T1.2.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">98.87</td>
<td id="S3.T1.2.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.21.21.5.1" class="ltx_text ltx_font_bold">87.69</span></td>
<td id="S3.T1.2.21.21.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.21.21.6.1" class="ltx_text ltx_font_bold">93.03</span></td>
<td id="S3.T1.2.21.21.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">93.30</td>
<td id="S3.T1.2.21.21.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">84.57</td>
<td id="S3.T1.2.21.21.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.2.21.21.9.1" class="ltx_text ltx_font_bold">83.13</span></td>
<td id="S3.T1.2.21.21.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80.53</td>
</tr>
<tr id="S3.T1.2.22.22" class="ltx_tr">
<td id="S3.T1.2.22.22.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T1.2.22.22.1.1" class="ltx_text" style="color:#000000;">Synthetic</span> data</td>
<td id="S3.T1.2.22.22.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">w6a6</td>
<td id="S3.T1.2.22.22.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">0.79</td>
<td id="S3.T1.2.22.22.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.2.22.22.4.1" class="ltx_text ltx_font_bold">99.08</span></td>
<td id="S3.T1.2.22.22.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">87.64</td>
<td id="S3.T1.2.22.22.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">91.77</td>
<td id="S3.T1.2.22.22.7" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.2.22.22.7.1" class="ltx_text ltx_font_bold">93.48</span></td>
<td id="S3.T1.2.22.22.8" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.2.22.22.8.1" class="ltx_text ltx_font_bold">84.85</span></td>
<td id="S3.T1.2.22.22.9" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">82.94</td>
<td id="S3.T1.2.22.22.10" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.2.22.22.10.1" class="ltx_text ltx_font_bold">80.58</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.3.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S3.T1.4.2" class="ltx_text" style="font-size:90%;">B-bit precision data vs. performance on LFW , CFP , AgeDb-30 , CALFW, CPLFW (Accuracy %), IJB-C and IJB-B (TAR at FAR 1e-4). The results is reported for FP model (32-bit), quantized models to 8-bit (w8a8) and 6-bit (w6a6) using real and synthetic data. All decimal points are rounded up to two decimal places. The top verification performances under the same quantization settings (network architecture and bit bandwidth) are in bold.</span></figcaption>
</figure>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Quantization-Aware Training (QAT)</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">QAT, utilized in QuantFace, is a common approach to adjust the quantized model parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. This adjustment is often required for model quantization because rounding the weights of a pre-trained model often results in lower accuracy, especially if the weights and the activation functions have a wide range of values.
QAT inserts fake (simulated) quantization operations in the network to emulate inference-time quantization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. QAT requires training or fine-tuning the model. In QAT, the forward and backward passes are usually carried out in a floating-point precision, and the model weights and activations are quantized after each gradient update <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.
After each training iteration, the derivatives of the quantized network weights need to be calculated to compute the loss gradients for backpropagation.
However, the gradients of the fake quantized operations are predominantly zero <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, making the standard backpropagation not applicable. QuantFace follows the common QAT approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> by addressing this issue <span id="S3.SS2.p1.2.1" class="ltx_text" style="color:#000000;">by</span> using Straight Through Estimator (STE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> to approximate the gradient of fake quantization operators using a threshold, where the derivatives of fake quantization operators are set to one for inputs within the clipping range, i.e. when <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">x</annotation></semantics></math> is in the range <math id="S3.SS2.p1.2.m2.2" class="ltx_Math" alttext="[\beta,\alpha]" display="inline"><semantics id="S3.SS2.p1.2.m2.2a"><mrow id="S3.SS2.p1.2.m2.2.3.2" xref="S3.SS2.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.p1.2.m2.2.3.2.1" xref="S3.SS2.p1.2.m2.2.3.1.cmml">[</mo><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">β</mi><mo id="S3.SS2.p1.2.m2.2.3.2.2" xref="S3.SS2.p1.2.m2.2.3.1.cmml">,</mo><mi id="S3.SS2.p1.2.m2.2.2" xref="S3.SS2.p1.2.m2.2.2.cmml">α</mi><mo stretchy="false" id="S3.SS2.p1.2.m2.2.3.2.3" xref="S3.SS2.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.2b"><interval closure="closed" id="S3.SS2.p1.2.m2.2.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3.2"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝛽</ci><ci id="S3.SS2.p1.2.m2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2">𝛼</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.2c">[\beta,\alpha]</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Training paradigm</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.4" class="ltx_p">QAT requires access to the original labeled training dataset to fine-tune the quantized model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, which may be infeasible for privacy concerns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.
Very recently, a number of works proposed to fine-tune a quantized model with generated data from conditional generative models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.
However, these works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> required to generate data with labels that are aware of the data labels used to train the FP models.
Such knowledge of training class labels is often unobtainable, given only a pre-trained FR model.
To solve this, we propose a solution that utilizes unlabeled synthetic data along with a KD-based training paradigm that wavers the requirement of training data labels.
<span id="S3.SS3.p1.4.1" class="ltx_text" style="color:#000000;">
Unlike conventional KD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> that optimizes the classification output (require labeled data), the utilized KD-based training paradigm optimizes the feature representation needed for biometric verification i.e. given a batch of <span id="S3.SS3.p1.4.1.1" class="ltx_text ltx_font_italic">unlabeled</span> face images, the quantized model is fine-tuned to learn producing feature representation similar to the one learned by the full precision model
as will be detailed in this section. </span>
We propose to use synthetically generated data from a Generative Adversarial Network (GAN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> to fine-tune the quantized model.
We sample noise <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">Z</annotation></semantics></math> <span id="S3.SS3.p1.4.2" class="ltx_text" style="color:#000000;">from</span> a Gaussian distribution <math id="S3.SS3.p1.2.m2.2" class="ltx_Math" alttext="N(0,1)" display="inline"><semantics id="S3.SS3.p1.2.m2.2a"><mrow id="S3.SS3.p1.2.m2.2.3" xref="S3.SS3.p1.2.m2.2.3.cmml"><mi id="S3.SS3.p1.2.m2.2.3.2" xref="S3.SS3.p1.2.m2.2.3.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.2.3.1" xref="S3.SS3.p1.2.m2.2.3.1.cmml">​</mo><mrow id="S3.SS3.p1.2.m2.2.3.3.2" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS3.p1.2.m2.2.3.3.2.1" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml">(</mo><mn id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">0</mn><mo id="S3.SS3.p1.2.m2.2.3.3.2.2" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.SS3.p1.2.m2.2.2" xref="S3.SS3.p1.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS3.p1.2.m2.2.3.3.2.3" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.2b"><apply id="S3.SS3.p1.2.m2.2.3.cmml" xref="S3.SS3.p1.2.m2.2.3"><times id="S3.SS3.p1.2.m2.2.3.1.cmml" xref="S3.SS3.p1.2.m2.2.3.1"></times><ci id="S3.SS3.p1.2.m2.2.3.2.cmml" xref="S3.SS3.p1.2.m2.2.3.2">𝑁</ci><interval closure="open" id="S3.SS3.p1.2.m2.2.3.3.1.cmml" xref="S3.SS3.p1.2.m2.2.3.3.2"><cn type="integer" id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">0</cn><cn type="integer" id="S3.SS3.p1.2.m2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.2c">N(0,1)</annotation></semantics></math> and feed it into a pretrained generator <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">G</annotation></semantics></math> to generate unlabeled synthetic data <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">x</annotation></semantics></math>, as shown in Figure <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Formally, the synthetically generated data is obtained by:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.4" class="ltx_Math" alttext="x=G(z),\quad Z\sim N(0,1)." display="block"><semantics id="S3.E7.m1.4a"><mrow id="S3.E7.m1.4.4.1"><mrow id="S3.E7.m1.4.4.1.1.2" xref="S3.E7.m1.4.4.1.1.3.cmml"><mrow id="S3.E7.m1.4.4.1.1.1.1" xref="S3.E7.m1.4.4.1.1.1.1.cmml"><mi id="S3.E7.m1.4.4.1.1.1.1.2" xref="S3.E7.m1.4.4.1.1.1.1.2.cmml">x</mi><mo id="S3.E7.m1.4.4.1.1.1.1.1" xref="S3.E7.m1.4.4.1.1.1.1.1.cmml">=</mo><mrow id="S3.E7.m1.4.4.1.1.1.1.3" xref="S3.E7.m1.4.4.1.1.1.1.3.cmml"><mi id="S3.E7.m1.4.4.1.1.1.1.3.2" xref="S3.E7.m1.4.4.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.4.4.1.1.1.1.3.1" xref="S3.E7.m1.4.4.1.1.1.1.3.1.cmml">​</mo><mrow id="S3.E7.m1.4.4.1.1.1.1.3.3.2" xref="S3.E7.m1.4.4.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E7.m1.4.4.1.1.1.1.3.3.2.1" xref="S3.E7.m1.4.4.1.1.1.1.3.cmml">(</mo><mi id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml">z</mi><mo stretchy="false" id="S3.E7.m1.4.4.1.1.1.1.3.3.2.2" xref="S3.E7.m1.4.4.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo rspace="1.167em" id="S3.E7.m1.4.4.1.1.2.3" xref="S3.E7.m1.4.4.1.1.3a.cmml">,</mo><mrow id="S3.E7.m1.4.4.1.1.2.2" xref="S3.E7.m1.4.4.1.1.2.2.cmml"><mi id="S3.E7.m1.4.4.1.1.2.2.2" xref="S3.E7.m1.4.4.1.1.2.2.2.cmml">Z</mi><mo id="S3.E7.m1.4.4.1.1.2.2.1" xref="S3.E7.m1.4.4.1.1.2.2.1.cmml">∼</mo><mrow id="S3.E7.m1.4.4.1.1.2.2.3" xref="S3.E7.m1.4.4.1.1.2.2.3.cmml"><mi id="S3.E7.m1.4.4.1.1.2.2.3.2" xref="S3.E7.m1.4.4.1.1.2.2.3.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.4.4.1.1.2.2.3.1" xref="S3.E7.m1.4.4.1.1.2.2.3.1.cmml">​</mo><mrow id="S3.E7.m1.4.4.1.1.2.2.3.3.2" xref="S3.E7.m1.4.4.1.1.2.2.3.3.1.cmml"><mo stretchy="false" id="S3.E7.m1.4.4.1.1.2.2.3.3.2.1" xref="S3.E7.m1.4.4.1.1.2.2.3.3.1.cmml">(</mo><mn id="S3.E7.m1.2.2" xref="S3.E7.m1.2.2.cmml">0</mn><mo id="S3.E7.m1.4.4.1.1.2.2.3.3.2.2" xref="S3.E7.m1.4.4.1.1.2.2.3.3.1.cmml">,</mo><mn id="S3.E7.m1.3.3" xref="S3.E7.m1.3.3.cmml">1</mn><mo stretchy="false" id="S3.E7.m1.4.4.1.1.2.2.3.3.2.3" xref="S3.E7.m1.4.4.1.1.2.2.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E7.m1.4.4.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.4b"><apply id="S3.E7.m1.4.4.1.1.3.cmml" xref="S3.E7.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.1.1.3a.cmml" xref="S3.E7.m1.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E7.m1.4.4.1.1.1.1.cmml" xref="S3.E7.m1.4.4.1.1.1.1"><eq id="S3.E7.m1.4.4.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.1.1.1.1.1"></eq><ci id="S3.E7.m1.4.4.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.1.1.1.1.2">𝑥</ci><apply id="S3.E7.m1.4.4.1.1.1.1.3.cmml" xref="S3.E7.m1.4.4.1.1.1.1.3"><times id="S3.E7.m1.4.4.1.1.1.1.3.1.cmml" xref="S3.E7.m1.4.4.1.1.1.1.3.1"></times><ci id="S3.E7.m1.4.4.1.1.1.1.3.2.cmml" xref="S3.E7.m1.4.4.1.1.1.1.3.2">𝐺</ci><ci id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1">𝑧</ci></apply></apply><apply id="S3.E7.m1.4.4.1.1.2.2.cmml" xref="S3.E7.m1.4.4.1.1.2.2"><csymbol cd="latexml" id="S3.E7.m1.4.4.1.1.2.2.1.cmml" xref="S3.E7.m1.4.4.1.1.2.2.1">similar-to</csymbol><ci id="S3.E7.m1.4.4.1.1.2.2.2.cmml" xref="S3.E7.m1.4.4.1.1.2.2.2">𝑍</ci><apply id="S3.E7.m1.4.4.1.1.2.2.3.cmml" xref="S3.E7.m1.4.4.1.1.2.2.3"><times id="S3.E7.m1.4.4.1.1.2.2.3.1.cmml" xref="S3.E7.m1.4.4.1.1.2.2.3.1"></times><ci id="S3.E7.m1.4.4.1.1.2.2.3.2.cmml" xref="S3.E7.m1.4.4.1.1.2.2.3.2">𝑁</ci><interval closure="open" id="S3.E7.m1.4.4.1.1.2.2.3.3.1.cmml" xref="S3.E7.m1.4.4.1.1.2.2.3.3.2"><cn type="integer" id="S3.E7.m1.2.2.cmml" xref="S3.E7.m1.2.2">0</cn><cn type="integer" id="S3.E7.m1.3.3.cmml" xref="S3.E7.m1.3.3">1</cn></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.4c">x=G(z),\quad Z\sim N(0,1).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.17" class="ltx_p">Then, the synthetically generated data is aligned and cropped (See Section <a href="#S4" title="IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>).
This data is unlabeled, as the random <math id="S3.SS3.p1.5.m1.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S3.SS3.p1.5.m1.1a"><mi id="S3.SS3.p1.5.m1.1.1" xref="S3.SS3.p1.5.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m1.1b"><ci id="S3.SS3.p1.5.m1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m1.1c">Z</annotation></semantics></math> produces random identities unrelated to those used to train the FP model. Thus, the model cannot be directly fine-tuned with the generated data.
Given this restriction, we propose in this work to fine-tune the quantized model using KD from the FP model. Specifically, the quantized model is trained to learn feature embedding similar to the ones from the FP model in the normalized embedding space.
<span id="S3.SS3.p1.9.4" class="ltx_text" style="color:#000000;">
During the fine-tuning phase, a batch of size <math id="S3.SS3.p1.6.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS3.p1.6.1.m1.1a"><mi mathcolor="#000000" id="S3.SS3.p1.6.1.m1.1.1" xref="S3.SS3.p1.6.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.1.m1.1b"><ci id="S3.SS3.p1.6.1.m1.1.1.cmml" xref="S3.SS3.p1.6.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.1.m1.1c">M</annotation></semantics></math> of unlabeled synthetic images <math id="S3.SS3.p1.7.2.m2.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S3.SS3.p1.7.2.m2.1a"><mi mathcolor="#000000" id="S3.SS3.p1.7.2.m2.1.1" xref="S3.SS3.p1.7.2.m2.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.2.m2.1b"><ci id="S3.SS3.p1.7.2.m2.1.1.cmml" xref="S3.SS3.p1.7.2.m2.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.2.m2.1c">X</annotation></semantics></math> is sampled and fed into the quantized and full precision model to obtain feature embeddings <math id="S3.SS3.p1.8.3.m3.1" class="ltx_Math" alttext="f^{q}" display="inline"><semantics id="S3.SS3.p1.8.3.m3.1a"><msup id="S3.SS3.p1.8.3.m3.1.1" xref="S3.SS3.p1.8.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.8.3.m3.1.1.2" xref="S3.SS3.p1.8.3.m3.1.1.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.8.3.m3.1.1.3" xref="S3.SS3.p1.8.3.m3.1.1.3.cmml">q</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.3.m3.1b"><apply id="S3.SS3.p1.8.3.m3.1.1.cmml" xref="S3.SS3.p1.8.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.8.3.m3.1.1.1.cmml" xref="S3.SS3.p1.8.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p1.8.3.m3.1.1.2.cmml" xref="S3.SS3.p1.8.3.m3.1.1.2">𝑓</ci><ci id="S3.SS3.p1.8.3.m3.1.1.3.cmml" xref="S3.SS3.p1.8.3.m3.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.3.m3.1c">f^{q}</annotation></semantics></math> and <math id="S3.SS3.p1.9.4.m4.1" class="ltx_Math" alttext="f^{t}" display="inline"><semantics id="S3.SS3.p1.9.4.m4.1a"><msup id="S3.SS3.p1.9.4.m4.1.1" xref="S3.SS3.p1.9.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.9.4.m4.1.1.2" xref="S3.SS3.p1.9.4.m4.1.1.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.9.4.m4.1.1.3" xref="S3.SS3.p1.9.4.m4.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.4.m4.1b"><apply id="S3.SS3.p1.9.4.m4.1.1.cmml" xref="S3.SS3.p1.9.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.4.m4.1.1.1.cmml" xref="S3.SS3.p1.9.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p1.9.4.m4.1.1.2.cmml" xref="S3.SS3.p1.9.4.m4.1.1.2">𝑓</ci><ci id="S3.SS3.p1.9.4.m4.1.1.3.cmml" xref="S3.SS3.p1.9.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.4.m4.1c">f^{t}</annotation></semantics></math>, respectively.</span>
<span id="S3.SS3.p1.16.11" class="ltx_text" style="color:#000000;">
Then, <math id="S3.SS3.p1.10.5.m1.1" class="ltx_Math" alttext="f^{q}" display="inline"><semantics id="S3.SS3.p1.10.5.m1.1a"><msup id="S3.SS3.p1.10.5.m1.1.1" xref="S3.SS3.p1.10.5.m1.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.10.5.m1.1.1.2" xref="S3.SS3.p1.10.5.m1.1.1.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.10.5.m1.1.1.3" xref="S3.SS3.p1.10.5.m1.1.1.3.cmml">q</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.5.m1.1b"><apply id="S3.SS3.p1.10.5.m1.1.1.cmml" xref="S3.SS3.p1.10.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.10.5.m1.1.1.1.cmml" xref="S3.SS3.p1.10.5.m1.1.1">superscript</csymbol><ci id="S3.SS3.p1.10.5.m1.1.1.2.cmml" xref="S3.SS3.p1.10.5.m1.1.1.2">𝑓</ci><ci id="S3.SS3.p1.10.5.m1.1.1.3.cmml" xref="S3.SS3.p1.10.5.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.5.m1.1c">f^{q}</annotation></semantics></math> and <math id="S3.SS3.p1.11.6.m2.1" class="ltx_Math" alttext="f^{t}" display="inline"><semantics id="S3.SS3.p1.11.6.m2.1a"><msup id="S3.SS3.p1.11.6.m2.1.1" xref="S3.SS3.p1.11.6.m2.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.11.6.m2.1.1.2" xref="S3.SS3.p1.11.6.m2.1.1.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.11.6.m2.1.1.3" xref="S3.SS3.p1.11.6.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.11.6.m2.1b"><apply id="S3.SS3.p1.11.6.m2.1.1.cmml" xref="S3.SS3.p1.11.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.11.6.m2.1.1.1.cmml" xref="S3.SS3.p1.11.6.m2.1.1">superscript</csymbol><ci id="S3.SS3.p1.11.6.m2.1.1.2.cmml" xref="S3.SS3.p1.11.6.m2.1.1.2">𝑓</ci><ci id="S3.SS3.p1.11.6.m2.1.1.3.cmml" xref="S3.SS3.p1.11.6.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.11.6.m2.1c">f^{t}</annotation></semantics></math> are normalized (<math id="S3.SS3.p1.12.7.m3.1" class="ltx_Math" alttext="f^{q}=\frac{f^{q}}{||f^{q}||_{2}}" display="inline"><semantics id="S3.SS3.p1.12.7.m3.1a"><mrow id="S3.SS3.p1.12.7.m3.1.2" xref="S3.SS3.p1.12.7.m3.1.2.cmml"><msup id="S3.SS3.p1.12.7.m3.1.2.2" xref="S3.SS3.p1.12.7.m3.1.2.2.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.2.2.2" xref="S3.SS3.p1.12.7.m3.1.2.2.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.2.2.3" xref="S3.SS3.p1.12.7.m3.1.2.2.3.cmml">q</mi></msup><mo mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.2.1" xref="S3.SS3.p1.12.7.m3.1.2.1.cmml">=</mo><mfrac mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.1" xref="S3.SS3.p1.12.7.m3.1.1.cmml"><msup id="S3.SS3.p1.12.7.m3.1.1.3" xref="S3.SS3.p1.12.7.m3.1.1.3.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.1.3.2" xref="S3.SS3.p1.12.7.m3.1.1.3.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.1.3.3" xref="S3.SS3.p1.12.7.m3.1.1.3.3.cmml">q</mi></msup><msub id="S3.SS3.p1.12.7.m3.1.1.1" xref="S3.SS3.p1.12.7.m3.1.1.1.cmml"><mrow id="S3.SS3.p1.12.7.m3.1.1.1.1.1" xref="S3.SS3.p1.12.7.m3.1.1.1.1.2.cmml"><mo mathcolor="#000000" maxsize="142%" minsize="142%" id="S3.SS3.p1.12.7.m3.1.1.1.1.1.2" xref="S3.SS3.p1.12.7.m3.1.1.1.1.2.1.cmml">‖</mo><msup id="S3.SS3.p1.12.7.m3.1.1.1.1.1.1" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.2" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.3" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.3.cmml">q</mi></msup><mo mathcolor="#000000" maxsize="142%" minsize="142%" id="S3.SS3.p1.12.7.m3.1.1.1.1.1.3" xref="S3.SS3.p1.12.7.m3.1.1.1.1.2.1.cmml">‖</mo></mrow><mn mathcolor="#000000" id="S3.SS3.p1.12.7.m3.1.1.1.3" xref="S3.SS3.p1.12.7.m3.1.1.1.3.cmml">2</mn></msub></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.12.7.m3.1b"><apply id="S3.SS3.p1.12.7.m3.1.2.cmml" xref="S3.SS3.p1.12.7.m3.1.2"><eq id="S3.SS3.p1.12.7.m3.1.2.1.cmml" xref="S3.SS3.p1.12.7.m3.1.2.1"></eq><apply id="S3.SS3.p1.12.7.m3.1.2.2.cmml" xref="S3.SS3.p1.12.7.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.12.7.m3.1.2.2.1.cmml" xref="S3.SS3.p1.12.7.m3.1.2.2">superscript</csymbol><ci id="S3.SS3.p1.12.7.m3.1.2.2.2.cmml" xref="S3.SS3.p1.12.7.m3.1.2.2.2">𝑓</ci><ci id="S3.SS3.p1.12.7.m3.1.2.2.3.cmml" xref="S3.SS3.p1.12.7.m3.1.2.2.3">𝑞</ci></apply><apply id="S3.SS3.p1.12.7.m3.1.1.cmml" xref="S3.SS3.p1.12.7.m3.1.1"><divide id="S3.SS3.p1.12.7.m3.1.1.2.cmml" xref="S3.SS3.p1.12.7.m3.1.1"></divide><apply id="S3.SS3.p1.12.7.m3.1.1.3.cmml" xref="S3.SS3.p1.12.7.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.12.7.m3.1.1.3.1.cmml" xref="S3.SS3.p1.12.7.m3.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.12.7.m3.1.1.3.2.cmml" xref="S3.SS3.p1.12.7.m3.1.1.3.2">𝑓</ci><ci id="S3.SS3.p1.12.7.m3.1.1.3.3.cmml" xref="S3.SS3.p1.12.7.m3.1.1.3.3">𝑞</ci></apply><apply id="S3.SS3.p1.12.7.m3.1.1.1.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.12.7.m3.1.1.1.2.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1">subscript</csymbol><apply id="S3.SS3.p1.12.7.m3.1.1.1.1.2.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.12.7.m3.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.2">norm</csymbol><apply id="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.2">𝑓</ci><ci id="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1.1.1.1.3">𝑞</ci></apply></apply><cn type="integer" id="S3.SS3.p1.12.7.m3.1.1.1.3.cmml" xref="S3.SS3.p1.12.7.m3.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.12.7.m3.1c">f^{q}=\frac{f^{q}}{||f^{q}||_{2}}</annotation></semantics></math> ,<math id="S3.SS3.p1.13.8.m4.1" class="ltx_Math" alttext="f^{t}=\frac{f^{t}}{||f^{t}||_{2}}" display="inline"><semantics id="S3.SS3.p1.13.8.m4.1a"><mrow id="S3.SS3.p1.13.8.m4.1.2" xref="S3.SS3.p1.13.8.m4.1.2.cmml"><msup id="S3.SS3.p1.13.8.m4.1.2.2" xref="S3.SS3.p1.13.8.m4.1.2.2.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.2.2.2" xref="S3.SS3.p1.13.8.m4.1.2.2.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.2.2.3" xref="S3.SS3.p1.13.8.m4.1.2.2.3.cmml">t</mi></msup><mo mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.2.1" xref="S3.SS3.p1.13.8.m4.1.2.1.cmml">=</mo><mfrac mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.1" xref="S3.SS3.p1.13.8.m4.1.1.cmml"><msup id="S3.SS3.p1.13.8.m4.1.1.3" xref="S3.SS3.p1.13.8.m4.1.1.3.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.1.3.2" xref="S3.SS3.p1.13.8.m4.1.1.3.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.1.3.3" xref="S3.SS3.p1.13.8.m4.1.1.3.3.cmml">t</mi></msup><msub id="S3.SS3.p1.13.8.m4.1.1.1" xref="S3.SS3.p1.13.8.m4.1.1.1.cmml"><mrow id="S3.SS3.p1.13.8.m4.1.1.1.1.1" xref="S3.SS3.p1.13.8.m4.1.1.1.1.2.cmml"><mo mathcolor="#000000" maxsize="142%" minsize="142%" id="S3.SS3.p1.13.8.m4.1.1.1.1.1.2" xref="S3.SS3.p1.13.8.m4.1.1.1.1.2.1.cmml">‖</mo><msup id="S3.SS3.p1.13.8.m4.1.1.1.1.1.1" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.2" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.2.cmml">f</mi><mi mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.3" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.3.cmml">t</mi></msup><mo mathcolor="#000000" maxsize="142%" minsize="142%" id="S3.SS3.p1.13.8.m4.1.1.1.1.1.3" xref="S3.SS3.p1.13.8.m4.1.1.1.1.2.1.cmml">‖</mo></mrow><mn mathcolor="#000000" id="S3.SS3.p1.13.8.m4.1.1.1.3" xref="S3.SS3.p1.13.8.m4.1.1.1.3.cmml">2</mn></msub></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.13.8.m4.1b"><apply id="S3.SS3.p1.13.8.m4.1.2.cmml" xref="S3.SS3.p1.13.8.m4.1.2"><eq id="S3.SS3.p1.13.8.m4.1.2.1.cmml" xref="S3.SS3.p1.13.8.m4.1.2.1"></eq><apply id="S3.SS3.p1.13.8.m4.1.2.2.cmml" xref="S3.SS3.p1.13.8.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.13.8.m4.1.2.2.1.cmml" xref="S3.SS3.p1.13.8.m4.1.2.2">superscript</csymbol><ci id="S3.SS3.p1.13.8.m4.1.2.2.2.cmml" xref="S3.SS3.p1.13.8.m4.1.2.2.2">𝑓</ci><ci id="S3.SS3.p1.13.8.m4.1.2.2.3.cmml" xref="S3.SS3.p1.13.8.m4.1.2.2.3">𝑡</ci></apply><apply id="S3.SS3.p1.13.8.m4.1.1.cmml" xref="S3.SS3.p1.13.8.m4.1.1"><divide id="S3.SS3.p1.13.8.m4.1.1.2.cmml" xref="S3.SS3.p1.13.8.m4.1.1"></divide><apply id="S3.SS3.p1.13.8.m4.1.1.3.cmml" xref="S3.SS3.p1.13.8.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.13.8.m4.1.1.3.1.cmml" xref="S3.SS3.p1.13.8.m4.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.13.8.m4.1.1.3.2.cmml" xref="S3.SS3.p1.13.8.m4.1.1.3.2">𝑓</ci><ci id="S3.SS3.p1.13.8.m4.1.1.3.3.cmml" xref="S3.SS3.p1.13.8.m4.1.1.3.3">𝑡</ci></apply><apply id="S3.SS3.p1.13.8.m4.1.1.1.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.13.8.m4.1.1.1.2.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1">subscript</csymbol><apply id="S3.SS3.p1.13.8.m4.1.1.1.1.2.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.13.8.m4.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.2">norm</csymbol><apply id="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.2">𝑓</ci><ci id="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1.1.1.1.3">𝑡</ci></apply></apply><cn type="integer" id="S3.SS3.p1.13.8.m4.1.1.1.3.cmml" xref="S3.SS3.p1.13.8.m4.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.13.8.m4.1c">f^{t}=\frac{f^{t}}{||f^{t}||_{2}}</annotation></semantics></math>) and used to compute the <math id="S3.SS3.p1.14.9.m5.1" class="ltx_Math" alttext="\mathcal{L}_{kd}" display="inline"><semantics id="S3.SS3.p1.14.9.m5.1a"><msub id="S3.SS3.p1.14.9.m5.1.1" xref="S3.SS3.p1.14.9.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S3.SS3.p1.14.9.m5.1.1.2" xref="S3.SS3.p1.14.9.m5.1.1.2.cmml">ℒ</mi><mrow id="S3.SS3.p1.14.9.m5.1.1.3" xref="S3.SS3.p1.14.9.m5.1.1.3.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.14.9.m5.1.1.3.2" xref="S3.SS3.p1.14.9.m5.1.1.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.14.9.m5.1.1.3.1" xref="S3.SS3.p1.14.9.m5.1.1.3.1.cmml">​</mo><mi mathcolor="#000000" id="S3.SS3.p1.14.9.m5.1.1.3.3" xref="S3.SS3.p1.14.9.m5.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.14.9.m5.1b"><apply id="S3.SS3.p1.14.9.m5.1.1.cmml" xref="S3.SS3.p1.14.9.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.14.9.m5.1.1.1.cmml" xref="S3.SS3.p1.14.9.m5.1.1">subscript</csymbol><ci id="S3.SS3.p1.14.9.m5.1.1.2.cmml" xref="S3.SS3.p1.14.9.m5.1.1.2">ℒ</ci><apply id="S3.SS3.p1.14.9.m5.1.1.3.cmml" xref="S3.SS3.p1.14.9.m5.1.1.3"><times id="S3.SS3.p1.14.9.m5.1.1.3.1.cmml" xref="S3.SS3.p1.14.9.m5.1.1.3.1"></times><ci id="S3.SS3.p1.14.9.m5.1.1.3.2.cmml" xref="S3.SS3.p1.14.9.m5.1.1.3.2">𝑘</ci><ci id="S3.SS3.p1.14.9.m5.1.1.3.3.cmml" xref="S3.SS3.p1.14.9.m5.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.14.9.m5.1c">\mathcal{L}_{kd}</annotation></semantics></math> loss based on the cosine distance between the normalized features.
Finally, the gradient of the <math id="S3.SS3.p1.15.10.m6.1" class="ltx_Math" alttext="\mathcal{L}_{kd}" display="inline"><semantics id="S3.SS3.p1.15.10.m6.1a"><msub id="S3.SS3.p1.15.10.m6.1.1" xref="S3.SS3.p1.15.10.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S3.SS3.p1.15.10.m6.1.1.2" xref="S3.SS3.p1.15.10.m6.1.1.2.cmml">ℒ</mi><mrow id="S3.SS3.p1.15.10.m6.1.1.3" xref="S3.SS3.p1.15.10.m6.1.1.3.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.15.10.m6.1.1.3.2" xref="S3.SS3.p1.15.10.m6.1.1.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.15.10.m6.1.1.3.1" xref="S3.SS3.p1.15.10.m6.1.1.3.1.cmml">​</mo><mi mathcolor="#000000" id="S3.SS3.p1.15.10.m6.1.1.3.3" xref="S3.SS3.p1.15.10.m6.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.15.10.m6.1b"><apply id="S3.SS3.p1.15.10.m6.1.1.cmml" xref="S3.SS3.p1.15.10.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.15.10.m6.1.1.1.cmml" xref="S3.SS3.p1.15.10.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.15.10.m6.1.1.2.cmml" xref="S3.SS3.p1.15.10.m6.1.1.2">ℒ</ci><apply id="S3.SS3.p1.15.10.m6.1.1.3.cmml" xref="S3.SS3.p1.15.10.m6.1.1.3"><times id="S3.SS3.p1.15.10.m6.1.1.3.1.cmml" xref="S3.SS3.p1.15.10.m6.1.1.3.1"></times><ci id="S3.SS3.p1.15.10.m6.1.1.3.2.cmml" xref="S3.SS3.p1.15.10.m6.1.1.3.2">𝑘</ci><ci id="S3.SS3.p1.15.10.m6.1.1.3.3.cmml" xref="S3.SS3.p1.15.10.m6.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.15.10.m6.1c">\mathcal{L}_{kd}</annotation></semantics></math> loss function is computed and used to update the weight parameters.
Different from supervised classification losses e.g. cross-entropy or conventional KD losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> that require class label for calculating the loss value, <math id="S3.SS3.p1.16.11.m7.1" class="ltx_Math" alttext="\mathcal{L}_{kd}" display="inline"><semantics id="S3.SS3.p1.16.11.m7.1a"><msub id="S3.SS3.p1.16.11.m7.1.1" xref="S3.SS3.p1.16.11.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S3.SS3.p1.16.11.m7.1.1.2" xref="S3.SS3.p1.16.11.m7.1.1.2.cmml">ℒ</mi><mrow id="S3.SS3.p1.16.11.m7.1.1.3" xref="S3.SS3.p1.16.11.m7.1.1.3.cmml"><mi mathcolor="#000000" id="S3.SS3.p1.16.11.m7.1.1.3.2" xref="S3.SS3.p1.16.11.m7.1.1.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.16.11.m7.1.1.3.1" xref="S3.SS3.p1.16.11.m7.1.1.3.1.cmml">​</mo><mi mathcolor="#000000" id="S3.SS3.p1.16.11.m7.1.1.3.3" xref="S3.SS3.p1.16.11.m7.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.16.11.m7.1b"><apply id="S3.SS3.p1.16.11.m7.1.1.cmml" xref="S3.SS3.p1.16.11.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.16.11.m7.1.1.1.cmml" xref="S3.SS3.p1.16.11.m7.1.1">subscript</csymbol><ci id="S3.SS3.p1.16.11.m7.1.1.2.cmml" xref="S3.SS3.p1.16.11.m7.1.1.2">ℒ</ci><apply id="S3.SS3.p1.16.11.m7.1.1.3.cmml" xref="S3.SS3.p1.16.11.m7.1.1.3"><times id="S3.SS3.p1.16.11.m7.1.1.3.1.cmml" xref="S3.SS3.p1.16.11.m7.1.1.3.1"></times><ci id="S3.SS3.p1.16.11.m7.1.1.3.2.cmml" xref="S3.SS3.p1.16.11.m7.1.1.3.2">𝑘</ci><ci id="S3.SS3.p1.16.11.m7.1.1.3.3.cmml" xref="S3.SS3.p1.16.11.m7.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.16.11.m7.1c">\mathcal{L}_{kd}</annotation></semantics></math> loss is calculated based on the feature embedding layers. Thus, it mitigates the need to have identity labels for the input training images.</span>
Formally, the <math id="S3.SS3.p1.17.m2.1" class="ltx_Math" alttext="\mathcal{L}_{kd}" display="inline"><semantics id="S3.SS3.p1.17.m2.1a"><msub id="S3.SS3.p1.17.m2.1.1" xref="S3.SS3.p1.17.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.17.m2.1.1.2" xref="S3.SS3.p1.17.m2.1.1.2.cmml">ℒ</mi><mrow id="S3.SS3.p1.17.m2.1.1.3" xref="S3.SS3.p1.17.m2.1.1.3.cmml"><mi id="S3.SS3.p1.17.m2.1.1.3.2" xref="S3.SS3.p1.17.m2.1.1.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.17.m2.1.1.3.1" xref="S3.SS3.p1.17.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.17.m2.1.1.3.3" xref="S3.SS3.p1.17.m2.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.17.m2.1b"><apply id="S3.SS3.p1.17.m2.1.1.cmml" xref="S3.SS3.p1.17.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.17.m2.1.1.1.cmml" xref="S3.SS3.p1.17.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.17.m2.1.1.2.cmml" xref="S3.SS3.p1.17.m2.1.1.2">ℒ</ci><apply id="S3.SS3.p1.17.m2.1.1.3.cmml" xref="S3.SS3.p1.17.m2.1.1.3"><times id="S3.SS3.p1.17.m2.1.1.3.1.cmml" xref="S3.SS3.p1.17.m2.1.1.3.1"></times><ci id="S3.SS3.p1.17.m2.1.1.3.2.cmml" xref="S3.SS3.p1.17.m2.1.1.3.2">𝑘</ci><ci id="S3.SS3.p1.17.m2.1.1.3.3.cmml" xref="S3.SS3.p1.17.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.17.m2.1c">\mathcal{L}_{kd}</annotation></semantics></math> loss is defined as <span id="S3.SS3.p1.17.12" class="ltx_text" style="color:#000000;">follows</span>:</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.5" class="ltx_Math" alttext="\mathcal{L}_{kd}=1-\frac{1}{M}\sum\limits_{i\in M}\frac{f^{q}_{i}.f^{t}_{i}}{||f^{q}_{i}||\;||f^{t}_{i}||}." display="block"><semantics id="S3.E8.m1.5a"><mrow id="S3.E8.m1.5.5.1" xref="S3.E8.m1.5.5.1.1.cmml"><mrow id="S3.E8.m1.5.5.1.1" xref="S3.E8.m1.5.5.1.1.cmml"><msub id="S3.E8.m1.5.5.1.1.2" xref="S3.E8.m1.5.5.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.5.5.1.1.2.2" xref="S3.E8.m1.5.5.1.1.2.2.cmml">ℒ</mi><mrow id="S3.E8.m1.5.5.1.1.2.3" xref="S3.E8.m1.5.5.1.1.2.3.cmml"><mi id="S3.E8.m1.5.5.1.1.2.3.2" xref="S3.E8.m1.5.5.1.1.2.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.5.5.1.1.2.3.1" xref="S3.E8.m1.5.5.1.1.2.3.1.cmml">​</mo><mi id="S3.E8.m1.5.5.1.1.2.3.3" xref="S3.E8.m1.5.5.1.1.2.3.3.cmml">d</mi></mrow></msub><mo id="S3.E8.m1.5.5.1.1.1" xref="S3.E8.m1.5.5.1.1.1.cmml">=</mo><mrow id="S3.E8.m1.5.5.1.1.3" xref="S3.E8.m1.5.5.1.1.3.cmml"><mn id="S3.E8.m1.5.5.1.1.3.2" xref="S3.E8.m1.5.5.1.1.3.2.cmml">1</mn><mo id="S3.E8.m1.5.5.1.1.3.1" xref="S3.E8.m1.5.5.1.1.3.1.cmml">−</mo><mrow id="S3.E8.m1.5.5.1.1.3.3" xref="S3.E8.m1.5.5.1.1.3.3.cmml"><mfrac id="S3.E8.m1.5.5.1.1.3.3.2" xref="S3.E8.m1.5.5.1.1.3.3.2.cmml"><mn id="S3.E8.m1.5.5.1.1.3.3.2.2" xref="S3.E8.m1.5.5.1.1.3.3.2.2.cmml">1</mn><mi id="S3.E8.m1.5.5.1.1.3.3.2.3" xref="S3.E8.m1.5.5.1.1.3.3.2.3.cmml">M</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E8.m1.5.5.1.1.3.3.1" xref="S3.E8.m1.5.5.1.1.3.3.1.cmml">​</mo><mrow id="S3.E8.m1.5.5.1.1.3.3.3" xref="S3.E8.m1.5.5.1.1.3.3.3.cmml"><munder id="S3.E8.m1.5.5.1.1.3.3.3.1" xref="S3.E8.m1.5.5.1.1.3.3.3.1.cmml"><mo movablelimits="false" id="S3.E8.m1.5.5.1.1.3.3.3.1.2" xref="S3.E8.m1.5.5.1.1.3.3.3.1.2.cmml">∑</mo><mrow id="S3.E8.m1.5.5.1.1.3.3.3.1.3" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3.cmml"><mi id="S3.E8.m1.5.5.1.1.3.3.3.1.3.2" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3.2.cmml">i</mi><mo id="S3.E8.m1.5.5.1.1.3.3.3.1.3.1" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3.1.cmml">∈</mo><mi id="S3.E8.m1.5.5.1.1.3.3.3.1.3.3" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3.3.cmml">M</mi></mrow></munder><mfrac id="S3.E8.m1.4.4" xref="S3.E8.m1.4.4.cmml"><mrow id="S3.E8.m1.2.2.2.2" xref="S3.E8.m1.2.2.2.3.cmml"><msubsup id="S3.E8.m1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.1.2.2.cmml">f</mi><mi id="S3.E8.m1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.3.cmml">i</mi><mi id="S3.E8.m1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.1.2.3.cmml">q</mi></msubsup><mo lspace="0em" rspace="0.167em" id="S3.E8.m1.2.2.2.2.3" xref="S3.E8.m1.2.2.2.3a.cmml">.</mo><msubsup id="S3.E8.m1.2.2.2.2.2" xref="S3.E8.m1.2.2.2.2.2.cmml"><mi id="S3.E8.m1.2.2.2.2.2.2.2" xref="S3.E8.m1.2.2.2.2.2.2.2.cmml">f</mi><mi id="S3.E8.m1.2.2.2.2.2.3" xref="S3.E8.m1.2.2.2.2.2.3.cmml">i</mi><mi id="S3.E8.m1.2.2.2.2.2.2.3" xref="S3.E8.m1.2.2.2.2.2.2.3.cmml">t</mi></msubsup></mrow><mrow id="S3.E8.m1.4.4.4" xref="S3.E8.m1.4.4.4.cmml"><mrow id="S3.E8.m1.3.3.3.1.1" xref="S3.E8.m1.3.3.3.1.2.cmml"><mo stretchy="false" id="S3.E8.m1.3.3.3.1.1.2" xref="S3.E8.m1.3.3.3.1.2.1.cmml">‖</mo><msubsup id="S3.E8.m1.3.3.3.1.1.1" xref="S3.E8.m1.3.3.3.1.1.1.cmml"><mi id="S3.E8.m1.3.3.3.1.1.1.2.2" xref="S3.E8.m1.3.3.3.1.1.1.2.2.cmml">f</mi><mi id="S3.E8.m1.3.3.3.1.1.1.3" xref="S3.E8.m1.3.3.3.1.1.1.3.cmml">i</mi><mi id="S3.E8.m1.3.3.3.1.1.1.2.3" xref="S3.E8.m1.3.3.3.1.1.1.2.3.cmml">q</mi></msubsup><mo stretchy="false" id="S3.E8.m1.3.3.3.1.1.3" xref="S3.E8.m1.3.3.3.1.2.1.cmml">‖</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E8.m1.4.4.4.3" xref="S3.E8.m1.4.4.4.3.cmml">​</mo><mrow id="S3.E8.m1.4.4.4.2.1" xref="S3.E8.m1.4.4.4.2.2.cmml"><mo stretchy="false" id="S3.E8.m1.4.4.4.2.1.2" xref="S3.E8.m1.4.4.4.2.2.1.cmml">‖</mo><msubsup id="S3.E8.m1.4.4.4.2.1.1" xref="S3.E8.m1.4.4.4.2.1.1.cmml"><mi id="S3.E8.m1.4.4.4.2.1.1.2.2" xref="S3.E8.m1.4.4.4.2.1.1.2.2.cmml">f</mi><mi id="S3.E8.m1.4.4.4.2.1.1.3" xref="S3.E8.m1.4.4.4.2.1.1.3.cmml">i</mi><mi id="S3.E8.m1.4.4.4.2.1.1.2.3" xref="S3.E8.m1.4.4.4.2.1.1.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.E8.m1.4.4.4.2.1.3" xref="S3.E8.m1.4.4.4.2.2.1.cmml">‖</mo></mrow></mrow></mfrac></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E8.m1.5.5.1.2" xref="S3.E8.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.5b"><apply id="S3.E8.m1.5.5.1.1.cmml" xref="S3.E8.m1.5.5.1"><eq id="S3.E8.m1.5.5.1.1.1.cmml" xref="S3.E8.m1.5.5.1.1.1"></eq><apply id="S3.E8.m1.5.5.1.1.2.cmml" xref="S3.E8.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.5.5.1.1.2.1.cmml" xref="S3.E8.m1.5.5.1.1.2">subscript</csymbol><ci id="S3.E8.m1.5.5.1.1.2.2.cmml" xref="S3.E8.m1.5.5.1.1.2.2">ℒ</ci><apply id="S3.E8.m1.5.5.1.1.2.3.cmml" xref="S3.E8.m1.5.5.1.1.2.3"><times id="S3.E8.m1.5.5.1.1.2.3.1.cmml" xref="S3.E8.m1.5.5.1.1.2.3.1"></times><ci id="S3.E8.m1.5.5.1.1.2.3.2.cmml" xref="S3.E8.m1.5.5.1.1.2.3.2">𝑘</ci><ci id="S3.E8.m1.5.5.1.1.2.3.3.cmml" xref="S3.E8.m1.5.5.1.1.2.3.3">𝑑</ci></apply></apply><apply id="S3.E8.m1.5.5.1.1.3.cmml" xref="S3.E8.m1.5.5.1.1.3"><minus id="S3.E8.m1.5.5.1.1.3.1.cmml" xref="S3.E8.m1.5.5.1.1.3.1"></minus><cn type="integer" id="S3.E8.m1.5.5.1.1.3.2.cmml" xref="S3.E8.m1.5.5.1.1.3.2">1</cn><apply id="S3.E8.m1.5.5.1.1.3.3.cmml" xref="S3.E8.m1.5.5.1.1.3.3"><times id="S3.E8.m1.5.5.1.1.3.3.1.cmml" xref="S3.E8.m1.5.5.1.1.3.3.1"></times><apply id="S3.E8.m1.5.5.1.1.3.3.2.cmml" xref="S3.E8.m1.5.5.1.1.3.3.2"><divide id="S3.E8.m1.5.5.1.1.3.3.2.1.cmml" xref="S3.E8.m1.5.5.1.1.3.3.2"></divide><cn type="integer" id="S3.E8.m1.5.5.1.1.3.3.2.2.cmml" xref="S3.E8.m1.5.5.1.1.3.3.2.2">1</cn><ci id="S3.E8.m1.5.5.1.1.3.3.2.3.cmml" xref="S3.E8.m1.5.5.1.1.3.3.2.3">𝑀</ci></apply><apply id="S3.E8.m1.5.5.1.1.3.3.3.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3"><apply id="S3.E8.m1.5.5.1.1.3.3.3.1.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S3.E8.m1.5.5.1.1.3.3.3.1.1.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3.1">subscript</csymbol><sum id="S3.E8.m1.5.5.1.1.3.3.3.1.2.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3.1.2"></sum><apply id="S3.E8.m1.5.5.1.1.3.3.3.1.3.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3"><in id="S3.E8.m1.5.5.1.1.3.3.3.1.3.1.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3.1"></in><ci id="S3.E8.m1.5.5.1.1.3.3.3.1.3.2.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3.2">𝑖</ci><ci id="S3.E8.m1.5.5.1.1.3.3.3.1.3.3.cmml" xref="S3.E8.m1.5.5.1.1.3.3.3.1.3.3">𝑀</ci></apply></apply><apply id="S3.E8.m1.4.4.cmml" xref="S3.E8.m1.4.4"><divide id="S3.E8.m1.4.4.5.cmml" xref="S3.E8.m1.4.4"></divide><apply id="S3.E8.m1.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.3a.cmml" xref="S3.E8.m1.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E8.m1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.E8.m1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.2.2">𝑓</ci><ci id="S3.E8.m1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.2.3">𝑞</ci></apply><ci id="S3.E8.m1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E8.m1.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.2.2">subscript</csymbol><apply id="S3.E8.m1.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.2.2">superscript</csymbol><ci id="S3.E8.m1.2.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2.2">𝑓</ci><ci id="S3.E8.m1.2.2.2.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2.2.2.3">𝑡</ci></apply><ci id="S3.E8.m1.2.2.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2.2.3">𝑖</ci></apply></apply><apply id="S3.E8.m1.4.4.4.cmml" xref="S3.E8.m1.4.4.4"><times id="S3.E8.m1.4.4.4.3.cmml" xref="S3.E8.m1.4.4.4.3"></times><apply id="S3.E8.m1.3.3.3.1.2.cmml" xref="S3.E8.m1.3.3.3.1.1"><csymbol cd="latexml" id="S3.E8.m1.3.3.3.1.2.1.cmml" xref="S3.E8.m1.3.3.3.1.1.2">norm</csymbol><apply id="S3.E8.m1.3.3.3.1.1.1.cmml" xref="S3.E8.m1.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.3.1.1.1.1.cmml" xref="S3.E8.m1.3.3.3.1.1.1">subscript</csymbol><apply id="S3.E8.m1.3.3.3.1.1.1.2.cmml" xref="S3.E8.m1.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.3.1.1.1.2.1.cmml" xref="S3.E8.m1.3.3.3.1.1.1">superscript</csymbol><ci id="S3.E8.m1.3.3.3.1.1.1.2.2.cmml" xref="S3.E8.m1.3.3.3.1.1.1.2.2">𝑓</ci><ci id="S3.E8.m1.3.3.3.1.1.1.2.3.cmml" xref="S3.E8.m1.3.3.3.1.1.1.2.3">𝑞</ci></apply><ci id="S3.E8.m1.3.3.3.1.1.1.3.cmml" xref="S3.E8.m1.3.3.3.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E8.m1.4.4.4.2.2.cmml" xref="S3.E8.m1.4.4.4.2.1"><csymbol cd="latexml" id="S3.E8.m1.4.4.4.2.2.1.cmml" xref="S3.E8.m1.4.4.4.2.1.2">norm</csymbol><apply id="S3.E8.m1.4.4.4.2.1.1.cmml" xref="S3.E8.m1.4.4.4.2.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.2.1.1.1.cmml" xref="S3.E8.m1.4.4.4.2.1.1">subscript</csymbol><apply id="S3.E8.m1.4.4.4.2.1.1.2.cmml" xref="S3.E8.m1.4.4.4.2.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.2.1.1.2.1.cmml" xref="S3.E8.m1.4.4.4.2.1.1">superscript</csymbol><ci id="S3.E8.m1.4.4.4.2.1.1.2.2.cmml" xref="S3.E8.m1.4.4.4.2.1.1.2.2">𝑓</ci><ci id="S3.E8.m1.4.4.4.2.1.1.2.3.cmml" xref="S3.E8.m1.4.4.4.2.1.1.2.3">𝑡</ci></apply><ci id="S3.E8.m1.4.4.4.2.1.1.3.cmml" xref="S3.E8.m1.4.4.4.2.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.5c">\mathcal{L}_{kd}=1-\frac{1}{M}\sum\limits_{i\in M}\frac{f^{q}_{i}.f^{t}_{i}}{||f^{q}_{i}||\;||f^{t}_{i}||}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.2" class="ltx_p"><span id="S3.SS3.p2.2.2" class="ltx_text" style="color:#000000;">Using synthetic data to train FR model might lead to sub-optimal verification performances <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> due to a possible domain gap between the real and synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, especially if the model is trained from scratch to learn identity representation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, which might require conducting domain adaption e.g. adversarial domain adaptation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> to reduce such effect.
However, our goal in this work is not to learn identity representation from scratch through optimizing classification loss e.g. cross entropy, we rather fine-tune the pretrained model with synthetic data to adjust the model weights and quantization parameters after applying quantization process.
Thus, by utilizing the proposed training paradigm, we restrict our use of the synthetic data to ensure that the response of the pretrained quantized model to input <math id="S3.SS3.p2.1.1.m1.1" class="ltx_Math" alttext="x\in X" display="inline"><semantics id="S3.SS3.p2.1.1.m1.1a"><mrow id="S3.SS3.p2.1.1.m1.1.1" xref="S3.SS3.p2.1.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p2.1.1.m1.1.1.2" xref="S3.SS3.p2.1.1.m1.1.1.2.cmml">x</mi><mo mathcolor="#000000" id="S3.SS3.p2.1.1.m1.1.1.1" xref="S3.SS3.p2.1.1.m1.1.1.1.cmml">∈</mo><mi mathcolor="#000000" id="S3.SS3.p2.1.1.m1.1.1.3" xref="S3.SS3.p2.1.1.m1.1.1.3.cmml">X</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.1.m1.1b"><apply id="S3.SS3.p2.1.1.m1.1.1.cmml" xref="S3.SS3.p2.1.1.m1.1.1"><in id="S3.SS3.p2.1.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.1.m1.1.1.1"></in><ci id="S3.SS3.p2.1.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.1.m1.1.1.2">𝑥</ci><ci id="S3.SS3.p2.1.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.1.m1.1.1.3">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.1.m1.1c">x\in X</annotation></semantics></math> during the fine-tuning phase is similar to the response of the full precision model to the same input <math id="S3.SS3.p2.2.2.m2.1" class="ltx_Math" alttext="x\in X" display="inline"><semantics id="S3.SS3.p2.2.2.m2.1a"><mrow id="S3.SS3.p2.2.2.m2.1.1" xref="S3.SS3.p2.2.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.p2.2.2.m2.1.1.2" xref="S3.SS3.p2.2.2.m2.1.1.2.cmml">x</mi><mo mathcolor="#000000" id="S3.SS3.p2.2.2.m2.1.1.1" xref="S3.SS3.p2.2.2.m2.1.1.1.cmml">∈</mo><mi mathcolor="#000000" id="S3.SS3.p2.2.2.m2.1.1.3" xref="S3.SS3.p2.2.2.m2.1.1.3.cmml">X</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.2.m2.1b"><apply id="S3.SS3.p2.2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.2.m2.1.1"><in id="S3.SS3.p2.2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.2.m2.1.1.1"></in><ci id="S3.SS3.p2.2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.2.m2.1.1.2">𝑥</ci><ci id="S3.SS3.p2.2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.2.m2.1.1.3">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.2.m2.1c">x\in X</annotation></semantics></math>.
We demonstrate that this process is not largely effected by the potential domain gap between the real and synthetic data by (1) comparing the model responses to real and synthetic data i.e. activation function value ranges of two models fine-tuned with real and synthetic data <a href="#S4.F2" title="Figure 2 ‣ IV-B Quantization implementation details ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, respectively and by (2) comparing the evaluation results of these models on real data benchmarks (details in Section <a href="#S5.SS3" title="V-C Impact of quantization data source ‣ V Results ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span></span></a>).
</span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experimental setup</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents the baseline models with implementation details, model quantization implementation details, and evaluation benchmarks used in this work.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Baselines</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.3" class="ltx_p">The FP models in this work are trained with ArcFace loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> on MS1MV2 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
The MS1MV2 is a refined version of the MS-Celeb-1M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> containing 5.8M images of 85K identities.
The baseline backbones are ResNet100 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, ResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, ResNet18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and MobileFaceNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
We follow the training setting of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> to set the scale parameter <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">s</annotation></semantics></math> to 64 and the margin <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">m</annotation></semantics></math> to 0.5.
We set the mini-batch size to 512 and trained the presented models on one Linux machine (Ubuntu 20.04.2 LTS) with Intel(R) Xeon(R) Gold 5218 CPU 2.30GHz, 512G RAM, and four Nvidia GeForce RTX-6000 GPUs.
The FP models and the quantization operators in this paper are implemented using Pytorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
All models are trained with Stochastic Gradient Descent (SGD) optimizer.
We used random horizontal flipping with a probability of 0.5 for data augmentation during the training.
We set the momentum to 0.9 and the weight decay to 5e-4.
All the images in the evaluation and training datasets are aligned and cropped to <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="112\times 112" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mn id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">112</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">×</mo><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">112</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><times id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></times><cn type="integer" id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">112</cn><cn type="integer" id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">112</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">112\times 112</annotation></semantics></math>, as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
The initial learning rate of the FP models is 0.1, and it is divided by 10 at 100K and 160K training iterations, following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. The training is stopped after 180K iterations.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Quantization implementation details</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We quantize the weights and activations of all the baseline FP models to two, 6-bit and 8-bit, precision formats.
We reported the results of the quantized models under two settings.
First, the quantized models are fine-tuned and calibrated with the original (real) training data, MS1MV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> (described in Section <a href="#S4.SS1" title="IV-A Baselines ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>).
Second, the quantized models are fine-tuned and calibrated with the synthetically generated data.
We utilized the official open source implementation <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/NVlabs/stylegan2-ada" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/NVlabs/stylegan2-ada</a></span></span></span> of StyleGAN2-ADA to randomly generate 0.5M synthetic face images.
These images are then cropped and aligned using the method described in Section <a href="#S4.SS1" title="IV-A Baselines ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>.
In both settings, the quantized models are fine-tuned for 11K iterations with a learning rate of 1e-4.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x2.png" id="S4.F2.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="445" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">ResNet100 6-bit</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x3.png" id="S4.F2.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="445" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">ResNet100 8-bit</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.8.4.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.6.3" class="ltx_text" style="font-size:90%;">Correlation between the activation functions (Act) value ranges (<math id="S4.F2.4.1.m1.2" class="ltx_Math" alttext="[\beta,\alpha]" display="inline"><semantics id="S4.F2.4.1.m1.2b"><mrow id="S4.F2.4.1.m1.2.3.2" xref="S4.F2.4.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.F2.4.1.m1.2.3.2.1" xref="S4.F2.4.1.m1.2.3.1.cmml">[</mo><mi id="S4.F2.4.1.m1.1.1" xref="S4.F2.4.1.m1.1.1.cmml">β</mi><mo id="S4.F2.4.1.m1.2.3.2.2" xref="S4.F2.4.1.m1.2.3.1.cmml">,</mo><mi id="S4.F2.4.1.m1.2.2" xref="S4.F2.4.1.m1.2.2.cmml">α</mi><mo stretchy="false" id="S4.F2.4.1.m1.2.3.2.3" xref="S4.F2.4.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.4.1.m1.2c"><interval closure="closed" id="S4.F2.4.1.m1.2.3.1.cmml" xref="S4.F2.4.1.m1.2.3.2"><ci id="S4.F2.4.1.m1.1.1.cmml" xref="S4.F2.4.1.m1.1.1">𝛽</ci><ci id="S4.F2.4.1.m1.2.2.cmml" xref="S4.F2.4.1.m1.2.2">𝛼</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.4.1.m1.2d">[\beta,\alpha]</annotation></semantics></math>) of the ResNet100 quantized using real (solid orange) and synthetic data (dashed black).
The y-axis represents the depth of the backbone activation function e.g. depth 1 is the first activation function.
These plots represent a fixed-precision quantization bit bandwidth of 6-bit (<a href="#S4.F2.sf1" title="In Figure 2 ‣ IV-B Quantization implementation details ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(a)</span></a>) and 8-bit (<a href="#S4.F2.sf2" title="In Figure 2 ‣ IV-B Quantization implementation details ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(b)</span></a>).
Each line in the plot represents the range value of the activation function where the start point is <math id="S4.F2.5.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.F2.5.2.m2.1b"><mi id="S4.F2.5.2.m2.1.1" xref="S4.F2.5.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.F2.5.2.m2.1c"><ci id="S4.F2.5.2.m2.1.1.cmml" xref="S4.F2.5.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.5.2.m2.1d">\beta</annotation></semantics></math> and end point is <math id="S4.F2.6.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F2.6.3.m3.1b"><mi id="S4.F2.6.3.m3.1.1" xref="S4.F2.6.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.F2.6.3.m3.1c"><ci id="S4.F2.6.3.m3.1.1.cmml" xref="S4.F2.6.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.6.3.m3.1d">\alpha</annotation></semantics></math>.
The high correlation indicates that the quantized model is able to capture sufficient data information from the synthetic data, in comparison to real data.
</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Evaluation benchmarks and metrics</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The evaluation results of the FP and quantized models are reported on seven mainstream benchmarks: Labeled Faces in the Wild (LFW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, AgeDB-30 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, Celebrities in Frontal-Profile in the Wild (CFP-FP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, Cross-age LFW (CALFW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, Cross-Pose LFW (CPLFW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, IARPA Janus Benchmark–C and B (IJB-C) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> and (IJB-B) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.
We follow the evaluation metrics defined in the utilized benchmarks as follows: LFW (accuracy), CA-LFW (accuracy), CP-LFW (accuracy), CFP-FP (accuracy), AgeDB-30 (accuracy), IJB-C, and IJB-B (true acceptance rate at a false acceptance rate of 1e-4, noted as TAR at FAR1e-4).</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x4.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">LFW</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x5.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">cfp</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="" id="S4.F3.sf3.g1" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">AgeDb-30</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x7.png" id="S4.F3.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F3.sf4.3.2" class="ltx_text" style="font-size:90%;">CALFW</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x8.png" id="S4.F3.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S4.F3.sf5.3.2" class="ltx_text" style="font-size:90%;">CPLFW</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x9.png" id="S4.F3.sf6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S4.F3.sf6.3.2" class="ltx_text" style="font-size:90%;">IJB-C</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.sf7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.10526/assets/x10.png" id="S4.F3.sf7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf7.2.1.1" class="ltx_text" style="font-size:90%;">(g)</span> </span><span id="S4.F3.sf7.3.2" class="ltx_text" style="font-size:90%;">IJB-B</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.4.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.5.2" class="ltx_text" style="font-size:90%;">The model size (in MB) vs. performance on LFW (accuracy), CFP (accuracy), AgeDB-30 (accuracy), CALFW (accuracy), CPLFW (accuracy), IJB-C (TAR at FAR1e-4), and IJB-B (TAR at FAR1e-4). The FP models are marked with <span id="S4.F3.5.2.1" class="ltx_text" style="color:#000000;"> a cross</span>. The 8bit and 6bit quantized models using synthetic data are marked with full circles and stars, respectively. The models <span id="S4.F3.5.2.2" class="ltx_text" style="color:#000000;">, after quantization, only lose</span> marginal performance while their sizes are significantly reduced. Quantized models (e.g. ResNet100(w8a8), blue circle) in most cases outperforms larger full precision models (e.g. ResNet50 (green cross) and ResNet18 (red cross)).
</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Table <a href="#S3.T1" title="TABLE I ‣ Tensor Quantization Granularity ‣ III-A Model Quantization ‣ III Methodology ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> presents the achieved FR performance results by the FP models (ResNet100, ResNet50, ResNet18, and MobileFaceNet), along with the achieved ones by the quantized models to 8-bit weights and 8-bit activation (noted as w8a8), and to 6-bit weights and 6-bit activation (noted as w6a6) using synthetic or real data quantization. The results are grouped by each network architecture. In each group of rows, the results are first presented for the FP model (baseline), followed by the quantized models.
The size (in MB) of the FP models is approximately 4x the number of parameters, i.e., each parameter requires 4 bytes.
In both real and synthetic data quantization settings, the reductions in bit bandwidth, and thus the model size, using w8a8 and w6a6, are around 4x and 5.3x, respectively. Also, model quantization enables performance gains in inference speed and memory bandwidth. However, the exact measures of inference speed and memory bandwidth depend on the underlying hardware and deep learning accelerator, as we discussed in Section <a href="#S1" title="I Introduction ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. Therefore, the presented results in this section are discussed as a trade-off between FR performance and the bit bandwidth, and thus, model size.
Figure <a href="#S4.F3" title="Figure 3 ‣ IV-C Evaluation benchmarks and metrics ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> presents the trade-off between the model size (in MB) and the achieved verification performance by the FP floating-point 32 models (FP32) and their respective quantized models using synthetically generated data.
The model that has the best trade-off between the verification performance and model size tends to be on the top left in the plot <a href="#S4.F3" title="Figure 3 ‣ IV-C Evaluation benchmarks and metrics ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
The following observations can be made based on the achieved results in Table <a href="#S3.T1" title="TABLE I ‣ Tensor Quantization Granularity ‣ III-A Model Quantization ‣ III Methodology ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>:</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Impact of 8-bit bandwidth quantization</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">When the model is quantized to 8-bit (w8a8 setting), the achieved verification performances in all experimental settings are slightly degraded. However, the bit bandwidth is significantly reduced (around 4x) when the considered models are quantized. For example, the achieved accuracy by ResNet100 (261.22 MB) on <span id="S5.SS1.p1.1.1" class="ltx_text" style="color:#000000;">AgeDb-30</span> is 98.33%.
This accuracy slightly dropped to 98.13% and 97.95% when the ResNet-100 is quantized to 8-bit (65.31 MB) and fine-tuned with real and synthetic data, respectively. Similar observations can be made when all considered models are quantized to 8-bit. Another important observation can be drawn from the achieved results: when ResNet100 is quantized to 8-bit and fine-tuned with synthetic data (65.31 MB), it significantly outperformed ResNet18 (96.22 MB) on all considered benchmarks, resulting in around 30% less model size. Impressively, the ResNet100 quantized to 8-bit outperformed the FP ResNet50 on most benchmarks while being more than 60% smaller.
This observation can be visually seen
by comparing the (x,y) positions of blue circle (ResNet100(w8a8)) and green cross (ResNet50) marks in
the trade-off plots of Figure <a href="#S4.F3" title="Figure 3 ‣ IV-C Evaluation benchmarks and metrics ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
On large-scale evaluation <span id="S5.SS1.p1.1.2" class="ltx_text" style="color:#000000;">benchmarks</span>, the achieved TAR at FAR 1e-4 on IJB-C by quantized models using real and synthetic data is very competitive to the FP model. For example, the achieved verification performance by the FP ResNet19 is 93.56% TAR at FAR 1e-4, and the achieved performance by the quantized models with real and synthetic data are 93.56% and 92.87%, respectively.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Impact of 6-bit bandwidth quantization</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Using 6-bit bandwidth, the achieved results by quantized models are, as expected, lower than the ones achieved by the 8-bit quantization. However, the reduction in model size is significantly higher than the 8-bit quantization. However, using 6-bit bandwidth can still achieve competitive results to the FP model for use-cases that are extremely limited with computational cost.
Moving below 6-bit bandwidth, e.g., 4-bit, our experiments showed that none of the considered models converged during the fine-tuning process.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Impact of quantization data source</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The quantized models <span id="S5.SS3.p1.1.1" class="ltx_text" style="color:#000000;">fine-tuned</span> with synthetic data achieved very competitive results to the ones <span id="S5.SS3.p1.1.2" class="ltx_text" style="color:#000000;">fine-tuned</span> with real data, and even, in many cases, the quantized models <span id="S5.SS3.p1.1.3" class="ltx_text" style="color:#000000;">fine-tuned</span> with synthetic data outperformed the quantized model with real data. This is especially true for the 6-bit bandwidth, as shown in Table <a href="#S3.T1" title="TABLE I ‣ Tensor Quantization Granularity ‣ III-A Model Quantization ‣ III Methodology ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. For example, using 6-bit bandwidth, the achieved accuracies on LFW by ResNet100 quantized with real and synthetic data are 99.55% and 99.45%, respectively.
To illustrate the correlation between the quantized models using real and synthetic data, Figure <a href="#S4.F2" title="Figure 2 ‣ IV-B Quantization implementation details ‣ IV Experimental setup ‣ QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the activation functions value range variables (<math id="S5.SS3.p1.1.m1.2" class="ltx_Math" alttext="[\beta,\alpha]" display="inline"><semantics id="S5.SS3.p1.1.m1.2a"><mrow id="S5.SS3.p1.1.m1.2.3.2" xref="S5.SS3.p1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.SS3.p1.1.m1.2.3.2.1" xref="S5.SS3.p1.1.m1.2.3.1.cmml">[</mo><mi id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">β</mi><mo id="S5.SS3.p1.1.m1.2.3.2.2" xref="S5.SS3.p1.1.m1.2.3.1.cmml">,</mo><mi id="S5.SS3.p1.1.m1.2.2" xref="S5.SS3.p1.1.m1.2.2.cmml">α</mi><mo stretchy="false" id="S5.SS3.p1.1.m1.2.3.2.3" xref="S5.SS3.p1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.2b"><interval closure="closed" id="S5.SS3.p1.1.m1.2.3.1.cmml" xref="S5.SS3.p1.1.m1.2.3.2"><ci id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">𝛽</ci><ci id="S5.SS3.p1.1.m1.2.2.cmml" xref="S5.SS3.p1.1.m1.2.2">𝛼</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.2c">[\beta,\alpha]</annotation></semantics></math>) of quantized models using real and synthetic data. The high correlation between the activation functions value range of the quantized model using real and synthetic data can be noticed from the overlap in the value range. This indicates that the quantized model is able to capture sufficient data information from the synthetic data to match the FP model output.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work is the first to explore the potential of regulating the computational cost of existing deep face recognition using low-bit format model quantization in a privacy-friendly process.
In particular, once the model is quantized, synthetically generated face data from unconditional GAN is fed into the FP and quantized model.
Then, the proposed training paradigm matches the feature embeddings of the FP and quantized model in a normalized embedding space.
The reported results pointed out the effectiveness of the presented approach in regulating the computational cost of the face recognition model without accessing the original training data or any prior knowledge about the actual data used to train the FP model.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research work has been funded by the German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research and the Arts within their joint support of the National Research Center for Applied Cybersecurity ATHENE. This work has been partially funded by the German Federal Ministry of Education and Research (BMBF) through the Software Campus Project.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">2016 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016</em>, 2016, pp.
770–778. [Online]. Available: <a target="_blank" href="https://doi.org/10.1109/CVPR.2016.90" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPR.2016.90</a>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Hu, L. Shen, and G. Sun, “Squeeze-and-excitation networks,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2018
IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018,
Salt Lake City, UT, USA, June 18-22, 2018</em>, 2018, pp. 7132–7141.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J. Deng, J. Guo, N. Xue, and S. Zafeiriou, “Arcface: Additive angular margin
loss for deep face recognition,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer
Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20,
2019</em>.   Computer Vision Foundation /
IEEE, 2019, pp. 4690–4699.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
F. Boutros, N. Damer, F. Kirchbuchner, and A. Kuijper, “Elasticface: Elastic
margin loss for deep face recognition,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, June
2022, pp. 1578–1587.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, “Vggface2: A
dataset for recognising faces across pose and age,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">13th IEEE
International Conference on Automatic Face &amp; Gesture Recognition, FG
2018, Xi’an, China, May 15-19, 2018</em>.   IEEE Computer Society, 2018, pp. 67–74. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1109/FG.2018.00020" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/FG.2018.00020</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Martínez-Díaz, M. Nicolás-Díaz,
H. Méndez-Vázquez, L. S. Luevano, L. Chang, M. Gonzalez-Mendoza, and
L. E. Sucar, “Benchmarking lightweight face architectures on specific face
recognition scenarios,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Review</em>, pp. 1–44,
2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Deng, J. Guo, D. Zhang, Y. Deng, X. Lu, and S. Shi, “Lightweight face
recognition challenge,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF ICCV, ICCV Workshops
2019, Seoul, Korea (South), October 27-28, 2019</em>.   IEEE, 2019, pp. 2638–2646.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S. Chen, Y. Liu, X. Gao, and Z. Han, “Mobilefacenets: Efficient cnns for
accurate real-time face verification on mobile devices,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">CCBR 2018,
Urumqi, China, August 11-12, 2018, Proceedings</em>, ser. Lecture Notes in
Computer Science, vol. 10996.   Springer, 2018, pp. 428–438. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1007/978-3-319-97909-0_46" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-319-97909-0_46</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y. Martínez-Díaz, L. S. Luevano, H. M. Vazquez,
M. Nicolás-Díaz, L. Chang, and M. González-Mendoza,
“Shufflefacenet: A lightweight face architecture for efficient and
highly-accurate face recognition,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF ICCVW, ICCV
Workshops 2019, Seoul, Korea (South), October 27-28, 2019</em>.   IEEE, 2019, pp. 2721–2728.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
F. Boutros, P. Siebke, M. Klemt, N. Damer, F. Kirchbuchner, and A. Kuijper,
“Pocketnet: Extreme lightweight face recognition network using neural
architecture search and multistep knowledge distillation,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol. 10, pp. 46 823–46 833, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. Yan, M. Zhao, Z. Xu, Q. Zhang, G. Wang, and Z. Su, “Vargfacenet: An
efficient variable group convolutional neural network for lightweight face
recognition,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF ICCVW, ICCV Workshops 2019, Seoul,
Korea (South), October 27-28, 2019</em>, 2019, pp. 2647–2654. [Online].
Available: <a target="_blank" href="https://doi.org/10.1109/ICCVW.2019.00323" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCVW.2019.00323</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. Tan and Q. V. Le, “Mixconv: Mixed depthwise convolutional kernels,” in
<em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">30th British Machine Vision Conference 2019, BMVC 2019, Cardiff, UK,
September 9-12, 2019</em>, 2019, p. 74.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. Sandler, A. G. Howard, M. Zhu, A. Zhmoginov, and L. Chen, “Mobilenetv2:
Inverted residuals and linear bottlenecks,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CVPR 2018, Salt Lake
City, UT, USA, June 18-22, 2018</em>.   IEEE Computer Society, 2018, pp. 4510–4520.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
N. Ma, X. Zhang, H. Zheng, and J. Sun, “Shufflenet V2: practical guidelines
for efficient CNN architecture design,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ECCV 2018, Munich,
Germany, September 8-14, 2018, Proceedings, Part XIV</em>, ser. Lecture Notes
in Computer Science, vol. 11218.   Springer, 2018, pp. 122–138.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Q. Zhang, J. Li, M. Yao, L. Song, H. Zhou, Z. Li, W. Meng, X. Zhang, and
G. Wang, “Vargnet: Variable group convolutional neural network for efficient
embedded computing,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1907.05653, 2019. [Online].
Available: <a target="_blank" href="http://arxiv.org/abs/1907.05653" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1907.05653</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
F. Boutros, N. Damer, M. Fang, F. Kirchbuchner, and A. Kuijper, “Mixfacenets:
Extremely efficient face recognition networks,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International
IEEE Joint Conference on Biometrics, IJCB 2021, Shenzhen, China, August
4-7, 2021</em>, 2021, pp. 1–8. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1109/IJCB52358.2021.9484374" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/IJCB52358.2021.9484374</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
X. Wang, “Teacher guided neural architecture search for face recognition,” in
<em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021,
Thirty-Third Conference on Innovative Applications of Artificial
Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in
Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021</em>,
2021, pp. 2817–2825.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
R. Banner, Y. Nahshan, and D. Soudry, “Post training 4-bit quantization of
convolutional networks for rapid-deployment,” in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems 32: Annual Conference on Neural Information
Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,
Canada</em>, 2019, pp. 7948–7956. [Online]. Available:
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/hash/c0a62e133894cdce435bcb4a5df1db2d-Abstract.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/hash/c0a62e133894cdce435bcb4a5df1db2d-Abstract.html</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Z. Yao, Z. Dong, Z. Zheng, A. Gholami, J. Yu, E. Tan, L. Wang, Q. Huang,
Y. Wang, M. W. Mahoney, and K. Keutzer, “HAWQ-V3: dyadic neural network
quantization,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 38th International Conference on
Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event</em>, 2021, pp.
11 875–11 886. [Online]. Available:
<a target="_blank" href="http://proceedings.mlr.press/v139/yao21a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://proceedings.mlr.press/v139/yao21a.html</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
R. Krishnamoorthi, “Quantizing deep convolutional networks for efficient
inference: A whitepaper,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.08342</em>, 2018.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. Howard, H. Adam, and
D. Kalenichenko, “Quantization and training of neural networks for efficient
integer-arithmetic-only inference,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE
conference on computer vision and pattern recognition</em>, 2018, pp. 2704–2713.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito,
M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and
S. Chintala, “Pytorch: An imperative style, high-performance deep learning
library,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
32</em>.   Curran Associates, Inc., 2019,
pp. 8024–8035.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga,
S. Moore, D. G. Murray, B. Steiner, P. A. Tucker, V. Vasudevan, P. Warden,
M. Wicke, Y. Yu, and X. Zheng, “Tensorflow: A system for large-scale
machine learning,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">12th USENIX Symposium on Operating Systems
Design and Implementation, OSDI 2016, Savannah, GA, USA, November 2-4,
2016</em>, 2016, pp. 265–283.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Y. Choukroun, E. Kravchik, F. Yang, and P. Kisilev, “Low-bit quantization of
neural networks for efficient inference,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF
International Conference on Computer Vision Workshops, ICCV Workshops 2019,
Seoul, Korea (South), October 27-28, 2019</em>, 2019, pp. 3009–3018. [Online].
Available: <a target="_blank" href="https://doi.org/10.1109/ICCVW.2019.00363" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCVW.2019.00363</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao, “Ms-celeb-1m: A dataset and
benchmark for large-scale face recognition,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Computer Vision -
ECCV 2016 - 14th European Conference, Amsterdam, The Netherlands, October
11-14, 2016, Proceedings, Part III</em>, ser. Lecture Notes in Computer
Science, vol. 9907.   Springer, 2016,
pp. 87–102.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
D. Yi, Z. Lei, S. Liao, and S. Z. Li, “Learning face representation from
scratch,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1411.7923, 2014. [Online]. Available:
<a target="_blank" href="http://arxiv.org/abs/1411.7923" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1411.7923</a>

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
I. D. Raji and G. Fried, “About face: A survey of facial recognition
evaluation,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2102.00813, 2021. [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/2102.00813" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2102.00813</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
F. Boutros, M. Huber, P. Siebke, T. Rieber, and N. Damer, “Sface:
Privacy-friendly and accurate face recognition using synthetic data,”
<em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint</em>, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
H. Qiu, B. Yu, D. Gong, Z. Li, W. Liu, and D. Tao, “Synface: Face recognition
with synthetic data,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International
Conference on Computer Vision (ICCV)</em>, October 2021, pp. 10 880–10 890.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
P. Voigt and A. v. d. Bussche, <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">The EU General Data Protection Regulation
(GDPR): A Practical Guide</em>, 1st ed.   Springer, 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
N. Damer, C. A. F. López, M. Fang, N. Spiller, M. V. Pham, and F. Boutros,
“Privacy-friendly synthetic data for the development of face morphing attack
detectors,” in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR) Workshops</em>, June 2022, pp. 1606–1617.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
B. Meden, P. Rot, P. Terhörst, N. Damer, A. Kuijper, W. J. Scheirer,
A. Ross, P. Peer, and V. Struc, “Privacy-enhancing face biometrics: A
comprehensive survey,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Inf. Forensics Secur.</em>, vol. 16,
pp. 4147–4183, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J. Pesenti. (2021) An update on our use of face recognition. [Online].
Available:
<a target="_blank" href="https://about.fb.com/news/2021/11/update-on-use-of-face-recognition/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://about.fb.com/news/2021/11/update-on-use-of-face-recognition/</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
C. Rong, X. Zhang, and Y. Lin, “Feature-improving generative adversarial
network for face frontalization,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, pp.
68 842–68 851, 2020. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1109/ACCESS.2020.2986079" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACCESS.2020.2986079</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
F. Chollet, “Xception: Deep learning with depthwise separable convolutions,”
in <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">2017 IEEE Conference on Computer Vision and Pattern Recognition,
CVPR 2017, Honolulu, HI, USA, July 21-26, 2017</em>, 2017, pp. 1800–1807.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
X. Li, F. Wang, Q. Hu, and C. Leng, “Airface: Lightweight and efficient model
for face recognition,” in <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF ICCV Workshops 2019, Seoul,
Korea (South), October 27-28, 2019</em>, 2019, pp. 2678–2682. [Online].
Available: <a target="_blank" href="https://doi.org/10.1109/ICCVW.2019.00327" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCVW.2019.00327</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
G. E. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
network,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1503.02531, 2015. [Online]. Available:
<a target="_blank" href="http://arxiv.org/abs/1503.02531" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1503.02531</a>

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
M. Huber, F. Boutros, F. Kirchbuchner, and N. Damer, “Mask-invariant face
recognition through template-level knowledge distillation,” in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">2021
16th IEEE International Conference on Automatic Face and Gesture Recognition
(FG 2021)</em>, 2021, pp. 1–8.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
F. Boutros, N. Damer, K. Raja, F. Kirchbuchner, and A. Kuijper,
“Template-driven knowledge distillation for compact and accurate periocular
biometrics deep-learning models,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 22, no. 5, 2022.
[Online]. Available: <a target="_blank" href="https://www.mdpi.com/1424-8220/22/5/1921" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/1424-8220/22/5/1921</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. G. Howard, H. Adam, and
D. Kalenichenko, “Quantization and training of neural networks for efficient
integer-arithmetic-only inference,” in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">2018 IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT,
USA, June 18-22, 2018</em>, 2018, pp. 2704–2713.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, and K. Keutzer, “A survey
of quantization methods for efficient neural network inference,”
<em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2103.13630, 2021. [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/2103.13630" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2103.13630</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
R. Krishnamoorthi, “Quantizing deep convolutional networks for efficient
inference: A whitepaper,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1806.08342, 2018.
[Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1806.08342" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1806.08342</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
S. Shen, Z. Dong, J. Ye, L. Ma, Z. Yao, A. Gholami, M. W. Mahoney, and
K. Keutzer, “Q-BERT: hessian based ultra low precision quantization of
BERT,” in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">The Thirty-Fourth AAAI Conference on Artificial
Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of
Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium
on Educational Advances in Artificial Intelligence, EAAI 2020, New York,
NY, USA, February 7-12, 2020</em>, 2020, pp. 8815–8821.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Q. Huang, D. Wang, Z. Dong, Y. Gao, Y. Cai, T. Li, B. Wu, K. Keutzer, and
J. Wawrzynek, “Codenet: Efficient deployment of input-adaptive object
detection on embedded fpgas,” in <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">FPGA ’21: The 2021 ACM/SIGDA
International Symposium on Field Programmable Gate Arrays, Virtual Event,
USA, February 28 - March 2, 2021</em>, 2021, pp. 206–216.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
D. Zhang, J. Yang, D. Ye, and G. Hua, “Lq-nets: Learned quantization for
highly accurate and compact deep neural networks,” in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Computer Vision
- ECCV 2018 - 15th European Conference, Munich, Germany, September 8-14,
2018, Proceedings, Part VIII</em>, 2018, pp. 373–390.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
J. Wu, C. Leng, Y. Wang, Q. Hu, and J. Cheng, “Quantized convolutional neural
networks for mobile devices,” in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">2016 IEEE Conference on Computer
Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30,
2016</em>, 2016, pp. 4820–4828.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Y. Bengio, N. Léonard, and A. C. Courville, “Estimating or propagating
gradients through stochastic neurons for conditional computation,”
<em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1308.3432, 2013. [Online]. Available:
<a target="_blank" href="http://arxiv.org/abs/1308.3432" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1308.3432</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Y. Choi, J. P. Choi, M. El-Khamy, and J. Lee, “Data-free network
quantization with adversarial knowledge distillation,” in <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">2020
IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR
Workshops 2020, Seattle, WA, USA, June 14-19, 2020</em>, 2020, pp. 3047–3057.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
S. Xu, H. Li, B. Zhuang, J. Liu, J. Cao, C. Liang, and M. Tan, “Generative
low-bitwidth data free quantization,” in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Computer Vision - ECCV 2020
- 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings,
Part XII</em>, 2020, pp. 1–17.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. C. Courville, and Y. Bengio, “Generative adversarial nets,” in
<em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 27: Annual Conference
on Neural Information Processing Systems 2014, December 8-13 2014, Montreal,
Quebec, Canada</em>, 2014, pp. 2672–2680.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
T. Karras, M. Aittala, J. Hellsten, S. Laine, J. Lehtinen, and T. Aila,
“Training generative adversarial networks with limited data,” in
<em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual</em>, 2020.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
M. Xu, J. Zhang, B. Ni, T. Li, C. Wang, Q. Tian, and W. Zhang, “Adversarial
domain adaptation with domain mixup,” in <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">The Thirty-Fourth AAAI
Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second
Innovative Applications of Artificial Intelligence Conference, IAAI 2020,
The Tenth AAAI Symposium on Educational Advances in Artificial
Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020</em>.   AAAI Press, 2020, pp. 6502–6509.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
S. Sankaranarayanan, Y. Balaji, A. Jain, S. Lim, and R. Chellappa, “Learning
from synthetic data: Addressing domain shift for semantic segmentation,” in
<em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">2018 IEEE Conference on Computer Vision and Pattern Recognition,
CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018</em>.   Computer Vision Foundation / IEEE Computer Society, 2018,
pp. 3752–3761.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
S. Lee, E. Park, H. Yi, and S. H. Lee, “Strdan: Synthetic-to-real domain
adaptation network for vehicle re-identification,” in <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">2020 IEEE/CVF
Conference on Computer Vision and Pattern Recognition, CVPR Workshops 2020,
Seattle, WA, USA, June 14-19, 2020</em>.   Computer Vision Foundation / IEEE, 2020, pp. 2590–2597.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller, “Labeled faces in the
wild: A database for studying face recognition in unconstrained
environments,” University of Massachusetts, Amherst, Tech. Rep. 07-49,
October 2007.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
S. Moschoglou, A. Papaioannou, C. Sagonas, J. Deng, I. Kotsia, and
S. Zafeiriou, “Agedb: The first manually collected, in-the-wild age
database,” in <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">2017 IEEE CVPRW, CVPR Workshops 2017, Honolulu, HI,
USA, July 21-26, 2017</em>.   IEEE
Computer Society, 2017, pp. 1997–2005.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
S. Sengupta, J. Chen, C. D. Castillo, V. M. Patel, R. Chellappa, and D. W.
Jacobs, “Frontal to profile face verification in the wild,” in <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">2016
IEEE Winter Conference on Applications of Computer Vision, WACV 2016,
Lake Placid, NY, USA, March 7-10, 2016</em>.   IEEE Computer Society, 2016, pp. 1–9.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
T. Zheng, W. Deng, and J. Hu, “Cross-age LFW: A database for studying
cross-age face recognition in unconstrained environments,” <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/1708.08197, 2017. [Online]. Available:
<a target="_blank" href="http://arxiv.org/abs/1708.08197" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1708.08197</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
T. Zheng and W. Deng, “Cross-pose lfw: A database for studying cross-pose face
recognition in unconstrained environments,” Beijing University of Posts and
Telecommunications, Tech. Rep. 18-01, February 2018.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
B. Maze, J. C. Adams, J. A. Duncan, N. D. Kalka, T. Miller, C. Otto, A. K.
Jain, W. T. Niggel, J. Anderson, J. Cheney, and P. Grother, “IARPA janus
benchmark - C: face dataset and protocol,” in <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">2018 International
Conference on Biometrics, ICB 2018, Gold Coast, Australia, February 20-23,
2018</em>.   IEEE, 2018, pp. 158–165.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
C. Whitelam, E. Taborsky, A. Blanton, B. Maze, J. C. Adams, T. Miller, N. D.
Kalka, A. K. Jain, J. A. Duncan, K. Allen, J. Cheney, and P. Grother,
“IARPA janus benchmark-b face dataset,” in <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">2017 IEEE CVPRW,
CVPR Workshops 2017, Honolulu, HI, USA, July 21-26, 2017</em>.   IEEE Computer Society, 2017, pp. 592–600.
[Online]. Available: <a target="_blank" href="https://doi.org/10.1109/CVPRW.2017.87" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPRW.2017.87</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2206.10525" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2206.10526" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2206.10526">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2206.10526" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2206.10527" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 17:19:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
