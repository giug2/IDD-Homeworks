<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology</title>
<!--Generated on Thu Sep 26 12:07:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.17775v1/"/></head>
<body>
<nav class="ltx_page_navbar">
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
<sup class="ltx_sup" id="id1.1"><span class="ltx_text" id="id1.1.1" style="font-size:90%;">1</span></sup><span class="ltx_text" id="id1.2" style="font-size:90%;"> Helmholtz Munich - German Research Center for Environmental Health, Munich, Germany
<br class="ltx_break"/><sup class="ltx_sup" id="id1.2.1">2</sup> School of Computation and Information Technology, Technical University of Munich, Munich, Germany
<br class="ltx_break"/><sup class="ltx_sup" id="id1.2.2">3</sup> Department of Cardiology, German Heart Centre Munich, TUM University Hospital, Munich, Germany
<br class="ltx_break"/><sup class="ltx_sup" id="id1.2.3">4</sup> MLL Munich Leukemia Laboratory, Munich, Germany
<br class="ltx_break"/><sup class="ltx_sup" id="id1.2.4">5</sup> DZHK (German Center for Cardiovascular Research), Partner Site Munich Heart Alliance, Munich, Germany
<br class="ltx_break"/><sup class="ltx_sup" id="id1.2.5">6</sup> School of Biomedical Engineering and Imaging Sciences, King’s College London, UK
<br class="ltx_break"/>*,+ equal contribution
</span></span></span></span>
<h1 class="ltx_title ltx_font_bold ltx_title_document">UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Valentin Koch<sup class="ltx_sup" id="id1.1.id1">*,1,2</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Sabine Bauer<sup class="ltx_sup" id="id2.1.id1">*,3,5</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Valerio Luppberger<sup class="ltx_sup" id="id3.1.id1">4</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Michael Joner<sup class="ltx_sup" id="id4.1.id1">3,5</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Heribert Schunkert<sup class="ltx_sup" id="id5.1.id1">3,5</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Julia A. Schnabel<sup class="ltx_sup" id="id6.1.id1">1,2,6</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Moritz von Scheidt<sup class="ltx_sup" id="id7.1.id1">+,3,5</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Carsten Marr<sup class="ltx_sup" id="id8.1.id1">+,1</sup>
</span></span>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">Background:</span> The integration of multi-stain histopathology images through deep learning poses a significant challenge in digital histopathology. Current multi-modal approaches struggle with data heterogeneity and missing data. This study aims to overcome these limitations by developing a novel transformer model for multi-stain integration that can handle missing data during training as well as inference. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<p class="ltx_p" id="p2.1"><span class="ltx_text ltx_font_bold" id="p2.1.1">Methods:</span> We propose UNICORN (UNiversal modality Integration Network for CORonary classificatioN) a multi-modal transformer capable of processing multi-stain histopathology for atherosclerosis severity class prediction. The architecture comprises a two-stage, end-to-end trainable model with specialized modules utilizing transformer self-attention blocks. The initial stage employs domain-specific expert modules to extract features from each modality. In the subsequent stage, an aggregation expert module integrates these features by learning the interactions between the different data modalities. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="p3">
<p class="ltx_p" id="p3.1"><span class="ltx_text ltx_font_bold" id="p3.1.1">Results:</span> Evaluation was performed using a multi-class dataset of atherosclerotic lesions from the Munich Cardiovascular Studies Biobank (MISSION), using over 4,000 paired multi-stain whole slide images (WSIs) from 170 deceased individuals on 7 prespecified segments of the coronary tree, each stained according to four histopathological protocols. UNICORN achieved a classification accuracy of 0.67, outperforming other state-of-the-art models. The model effectively identifies relevant tissue phenotypes across stainings and implicitly models disease progression. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="p4">
<p class="ltx_p" id="p4.1"><span class="ltx_text ltx_font_bold" id="p4.1.1">Conclusion:</span> Our proposed multi-modal transformer model addresses key challenges in medical data analysis, including data heterogeneity and missing modalities. Explainability and the model’s effectiveness in predicting atherosclerosis progression underscores its potential for broader applications in medical research. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Introduction</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Atherosclerosis, a complex inflammatory disease of the arterial wall, is a leading cause of cardiovascular morbidity and mortality worldwide. Histopathological classification of atherosclerosis, as proposed by Stary et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib21" title="">21</a>]</cite> and adapted by Virmani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib23" title="">23</a>]</cite> and Otsuka et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib19" title="">19</a>]</cite>, plays a crucial role in assessing disease severity, progression and potential therapeutic interventions. This classification scheme assesses features such as the thickness of the fibrous cap, the presence of a necrotic core, the degree of inflammation and the extent of calcification within arterial plaques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib11" title="">11</a>]</cite>.
Whole slide imaging (WSI) allows detailed visualization of tissue samples at micrometer resolution, providing critical insight into various medical conditions. While the most commonly used staining method, haematoxylin and eosin (H&amp;E), provides a sufficient overview of the tissue and is used to diagnose many diseases, in some cases further staining protocols are required to fully understand underlying tissue characteristics<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib15" title="">15</a>]</cite>. For example, immunohistochemistry (IHC) staining is essential for cancer detection, providing critical prognostic, diagnostic, and therapeutic information that enables precise and personalized treatment strategies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib12" title="">12</a>]</cite>. Specific staining methods, like von Kossa silver stain or Movat pentachrome stain, highlight particular tissue components, such as mineralisation or connective tissue composition and lipid distribution <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib10" title="">10</a>]</cite>. Manual integration and interpretation of multi-stain data is challenging, as multiple high-resolution images that are each potentially gigabytes in size need to be examined in detail.
In recent years, computational pathology, focusing on the analysis of digitized pathology slides, has seen remarkable advances, largely driven by modern machine learning techniques, especially deep learning. These advances cover several areas including disease classification, tissue segmentation, and mutation prediction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib2" title="">2</a>]</cite>. Given the large size of WSIs, a common strategy is to decompose them into manageable-sized image patches. Subsequently, a pre-trained feature extractor condenses each patch into a low-dimensional feature vector, which is then processed by a Multiple Instance Learning (MIL) network <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib20" title="">20</a>]</cite>. Recent developments in transformer architectures, in particular Vision Transformers (ViT), have shown promising results as the backbone of state-of-the-art feature extractors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib24" title="">24</a>]</cite>, and when applied as WSI classification networks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib25" title="">25</a>]</cite>. Although there has been a lot of research on cancer prediction and using deep learning on WSIs, computational pathology is quite new in the field of atherosclerosis. Holmberg et al. used co-registered histopathology and OCT images to improve segmentation of calcification and lesions in OCT images using a UNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib7" title="">7</a>]</cite>. The open-source tool Vesseg has been developed to segment lesions using U-nets on H&amp;E stained brachiocephalic arteries<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib17" title="">17</a>]</cite>.
In our work, we introduce UNICORN, a two-stage, end-to-end trainable transformer architecture capable of handling different modalities, in particular features obtained from WSIs with various staining protocols. To our knowledge, this is the first AI model tailored for multi-stain histopathological classification. We show how UNICORN implicitly captures disease progression in atherosclerosis, handles missing data effectively during both training and inference, demonstrating its robust applicability in real-world settings.</p>
</div>
<figure class="ltx_figure" id="Sx1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="282" id="Sx1.F1.g1" src="x1.png" width="830"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="401" id="Sx1.F1.g2" src="x2.png" width="831"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="Sx1.F1.12.1">MISSION biobank and UNICORN architecture.</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx1.F1.13.2">a)</span> Coronary artery segments used in this study. 1+2: proximal and distal part of the right coronary artery, 3: main stem, 4+5: proximal and distal part of the left coronary artery, 6+7: proximal and distal part of the left circumflex coronary artery. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx1.F1.14.3">b)</span> Histological classification of coronary arteries according to an adapted and simplified AHA classification based on Virmani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib23" title="">23</a>]</cite>. H&amp;E stains are shown for AIT, PIT, EFA, LFA and von Kossa silver stain is shown for CFA, all exemplary with zoomed in regions of interest. Blue and red arrows show class specific characteristics.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx1.F1.15.4">c)</span> Class distribution in the study cohort of MISSION with each n=7 segments of 170 individuals. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx1.F1.16.5">d)</span> UNICORN architecture: features extracted from WSIs with the four different stainings Hematoxylin and Eosin (H&amp;E), Elastica van Gieson (EvG), von Kossa (vK) and Movat pentachrome (Movat) are forwarded to four expert models consisting of two transformer blocks (e) that are specialized in processing data from a certain staining. Similar to the class token (CLS), information from each domain is aggregated in a modality token (<span class="ltx_text ltx_font_bold" id="Sx1.F1.17.6">MT</span>) which is used as input to the expert aggregation model, that combines information across stainings into the CLS token. The final classification score is derived from a fully connected (FC) layer that uses the CLS token as input. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx1.F1.18.7">e)</span> Transformer blocks: transformer blocks used in expert models and expert aggregation models are shown in detail. <span class="ltx_text ltx_font_bold" id="Sx1.F1.19.8">MLP</span>: multi-layer perceptron 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx1.F1.20.9">f)</span> Explainable output of UNICORN: using attention values, UNICORN can provide explainable output, highlighting regions of importance across stainings. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx1.F1.21.10">IT</span>: Intima thickening, <span class="ltx_text ltx_font_bold" id="Sx1.F1.22.11">NC</span>: necrotic core</figcaption>
</figure>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Results</h2>
<section class="ltx_subsection" id="Sx2.SSx1">
<h3 class="ltx_title ltx_title_subsection">UNICORN architecture</h3>
<div class="ltx_para" id="Sx2.SSx1.p1">
<p class="ltx_p" id="Sx2.SSx1.p1.1">UNICORN (UNiversal stain Integration network for CORonary classificatioN) is a network capable of integrating and processing heterogeneous data across different tissue stainings (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>). The model is end-to-end trainable and exhibits resilience to data incompleteness during both training and inference. The network comprises specialized modules, each having the same architecture. These modules include a two-layer self-attention transformer block with four attention heads, as illustrated in figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>e. Initially, the input data is encoded: the entire slide image is tiled into 256x256 px sized patches. A pre-trained feature extractor is then used to generate embeddings for each patch (see Methods for details). Each staining is individually processed by specialized domain expert modules that learn unique domain-specific features (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>d). Each of the expert modules propagates a modality token (MT), analogous to the class token (CLS) used in vision transformers, to the aggregation expert module. The aggregation expert module learns to aggregate the information from the different stainings in a CLS token, which is ultimately used as input to the fully-connected (FC) layer which outputs a classification score (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>d). Since the aggregation expert module, like all expert modules, is a transformer that can handle a variable number of input tokens, it is capable of processing data with missing modalities both during training and inference. UNICORN is evaluated on a multi-stain, multi-class atherosclerosis dataset where it classifies five stages of coronary atherosclerosis.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx2">
<h3 class="ltx_title ltx_title_subsection">MISSION: Multi-stain atherosclerosis classification dataset</h3>
<div class="ltx_para" id="Sx2.SSx2.p1">
<p class="ltx_p" id="Sx2.SSx2.p1.1">The dataset consists of tissue sets from 170 deceased individuals. Each set contains 7 segments from different parts of the coronary tree (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>a): proximal and distal part of the right coronary artery, main stem, proximal and distal part of the left coronary artery, proximal and distal part of the left circumflex coronary artery. Each segment is stained using four different staining methods: Hematoxylin and Eosin (H&amp;E), Elastica van Gieson (EvG), von Kossa (vK) and Movat pentachrome (Movat) stain. For lesion classification, a modified scheme according to the AHA and the classification method described by Virmani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib19" title="">19</a>]</cite> was employed: adaptive intima thickening (AIT), pathological intima thickening (PIT), early fibroatheroma (EFA), late fibroatheroma (LFA) and calcified fibroatheroma (CFA). These labels (see Methods and figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a> for detailed description) have been assigned by two biomedical experts after reviewing all four stainings. Disease severity increases from AIT over PIT, EFA, and LFA to CFA. Class specific characteristics are highlighted in figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>b: AIT samples show intima thickening (IT) but intact cell structure and smooth muscle cell layer in a proteoglycan and collagen rich matrix. PIT is described as preatherosclerotic lesions with focal fat-laden macrophages (red triangles), inflammatory cells (blue triangles) and fatty streaks. The gray circle shows matrix remodeling resulting in a varying degree of smooth muscle cells. In the EFA sample, the black circle highlights the necrotic core (NC), the blue arrows show inflammatory cells and the red arrows point to the lipid pool. The black dotted circle shows cell debris. In the LFA case, the gray circle shows the NC with cholesterol crafts and fibrocalcific surrounding, the red arrows point to neovascularization. The red arrows in CFA show calcification in the necrotic core in the vK stained slide.</p>
</div>
<figure class="ltx_figure" id="Sx2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="494" id="Sx2.F2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="Sx2.F2.5.1">UNICORN integrates information from four stainings.
<br class="ltx_break"/>a)</span> Confusion matrix shows UNICORN classifying multi-stain atherosclerosis WSIs into five classes with high accuracy. Values are color coded from white (0) to dark blue (1).
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx2.F2.6.2">b)</span> Performance of UNICORN using just one staining as input. The highest F1-Score is achieved when using all four stainings (grey dotted line), indicating that UNICORN successfully aggregates information of the different stainings.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx2.F2.7.3">c)</span> The attention mechanism of the UNICORN aggregation expert module functions well, with higher attention values noted for stainings exerting a high influence on performance for a given class. The mean attention value of the CLS token to the four modality tokens corresponding to a given staining is shown.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx2.F2.8.4">d)</span> F1-Score difference when utilizing three of four stainings vs. all stainings (gray dotted zero line), bar colors indicate which staining was excluded. Findings demonstrate robust correlation between two importance measurements (b, d) based on performance with the learnt attention scores (c) by UNICORN.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="Sx2.SSx3">
<h3 class="ltx_title ltx_title_subsection">Evaluation</h3>
<div class="ltx_para" id="Sx2.SSx3.p1">
<p class="ltx_p" id="Sx2.SSx3.p1.1">UNICORN is evaluated in a 5-fold cross validation scheme, splitting the dataset into 60/20/20 train/validation/test set for each fold (see Methods for details). We show that the network outperforms simple approaches that do not take into account the multi-modality of the data (Table 1). Our model achieves an average F1-Score of 0.66 ± 0.04 (mean ± standard deviation) and an accuracy of 0.67 ± 0.05 compared to an F1-Score of 0.63 ± 0.05 and accuracy of 0.64 ± 0.05 for the second-best model.</p>
</div>
<figure class="ltx_table" id="Sx2.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="Sx2.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="Sx2.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="Sx2.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="Sx2.T1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column" id="Sx2.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="Sx2.T1.1.1.1.2.1">F1-Score</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column" id="Sx2.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="Sx2.T1.1.1.1.3.1">Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Sx2.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Sx2.T1.1.2.1.1">AttentionMIL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib8" title="">8</a>]</cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="Sx2.T1.1.2.1.2">0.43 ± 0.03</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="Sx2.T1.1.2.1.3">0.55 ± 0.02</td>
</tr>
<tr class="ltx_tr" id="Sx2.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx2.T1.1.3.2.1">Perceiver <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib9" title="">9</a>]</cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="Sx2.T1.1.3.2.2">0.53 ± 0.08</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="Sx2.T1.1.3.2.3">0.56 ± 0.11</td>
</tr>
<tr class="ltx_tr" id="Sx2.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx2.T1.1.4.3.1">Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib25" title="">25</a>]</cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="Sx2.T1.1.4.3.2">0.63 ± 0.05</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="Sx2.T1.1.4.3.3">0.64 ± 0.05</td>
</tr>
<tr class="ltx_tr" id="Sx2.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Sx2.T1.1.5.4.1"><span class="ltx_text ltx_font_bold" id="Sx2.T1.1.5.4.1.1">UNICORN</span></th>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="Sx2.T1.1.5.4.2"><span class="ltx_text ltx_font_bold" id="Sx2.T1.1.5.4.2.1">0.66 ± 0.04</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="Sx2.T1.1.5.4.3"><span class="ltx_text ltx_font_bold" id="Sx2.T1.1.5.4.3.1">0.67 ± 0.05</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance comparison between UNICORN and three other multiple instance models on multi-stain coronary artery classification.</figcaption>
</figure>
<div class="ltx_para" id="Sx2.SSx3.p2">
<p class="ltx_p" id="Sx2.SSx3.p2.1">Most misclassifications are observed between adjacent disease stages, which are inherently difficult to classify and distinguish even for highly trained experts (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>a). Our model demonstrates strong performance with single-staining inputs, but achieves optimal results when utilizing all available staining methods (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>b), demonstrating its capabilities of aggregating information. When using only one staining as input, the vK staining performs best in classifying CFA and LFA and second best on EFA. Using H&amp;E staining works best for the classes AIT, PIT and EFA. Movat and EvG perform roughly on par across classes (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>b).
The attention of the CLS token to the stain specific modality token in the expert aggregation model (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>c) demonstrates that the model effectively focuses on the most relevant staining for its predictions. H&amp;E staining is predominantly given the highest attention, except for LFA and CFA, where vK staining is essential, aligning well with findings from figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>b. EvG is given slightly higher attention than Movat on AIT and PIT, again in concordance with <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>b, where EvG staining performs slightly better on these classes.
In figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>d, one staining is left out at inference to visualize the difference in accuracy compared to inference with all four stainings. This gives another measurement of how important a specific staining is to the model’s performance. The results again align well with the other experiments: Excluding von Kossa silver stain reduces the classification performance in advanced phenotypes (LFA, CFA), while H&amp;E is the most important staining for the remaining classes. Removing EvG or Movat has little effect and sometimes even improves performance, potential explanations are discussed below.</p>
</div>
<div class="ltx_para" id="Sx2.SSx3.p3">
<p class="ltx_p" id="Sx2.SSx3.p3.1">The results presented in figures <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>b-c are not only consistent with one another, but also illustrate the relevance of the different stainings for manual characterization and the underlying biological processes. For instance, the vK staining, which imparts a black chromatic hue to calcifications, is of particular importance for the identification and differentiation of the calcified fibroatheroma (CFA) and lipid-rich late fibrous atheromas (LFA). As also illustrated in figures <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>b and <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>c, H&amp;E staining remains a fundamental tool for evaluating cell densities and general tissue structure, which is the most crucial aspect for differentiating AIT and PIT. AIT and PIT represent different stages of atherogenesis, with variations in cell density, inflammatory infiltration, and extracellular matrix organization.</p>
</div>
<figure class="ltx_figure" id="Sx2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="224" id="Sx2.F3.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="Sx2.F3.5.1">High resolution heatmaps highlight relevant regions for classification decisions.
<br class="ltx_break"/>a)</span> Original von Kossa silver stain image showing black calcification regions.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx2.F3.6.2">b)</span> Coloring indicates the presence of structures associated with the most severe disease classes (EFA=blue, LFA=yellow, CFA=red).
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx2.F3.7.3">c)</span> Attention scores (lower score = blue, high score/high importance= red) show high attention regions.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx2.F3.8.4">d)</span> Multiplication of attention score (lower score = blue, high score/high importance = red) by the probability of the class that is predicted by UNICORN illustrates which region UNICORN considers important and also suspects the class it predicts to be in.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="Sx2.SSx4">
<h3 class="ltx_title ltx_title_subsection">UNICORN highlights explainable features</h3>
<div class="ltx_para" id="Sx2.SSx4.p1">
<p class="ltx_p" id="Sx2.SSx4.p1.1">Three different visualization methods are provided to improve explainability: the typical attention mechanism, resulting from an attention rollout <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib1" title="">1</a>]</cite> over both stages of the transformer (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F3" title="Figure 3 ‣ Evaluation ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">3</span></a>). Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F3" title="Figure 3 ‣ Evaluation ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">3</span></a>b illustrates a tissue phenotype visualization, where tissue regions are highlighted based on the model’s interpretation of the class most indicative of each area (see Methods). Due to practical reasons, in this case only the three most progressed disease tissue types are considered. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F3" title="Figure 3 ‣ Evaluation ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">3</span></a>c highlights areas of attention computed by attention rollout independently per staining. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F3" title="Figure 3 ‣ Evaluation ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">3</span></a>d combines the information of the first two methods into ”class attention,” which highlights the tissue phenotypes that the model identifies with high attention and associates with its predicted class. In conclusion, three meaningful visualization maps are given: a) “Where does the model attend to?” b) “Where does the model find phenotypes of the respective classes”, and c) “Where does it attend to the predicted class” which in our experiments highlights the areas of interest best and which are used in the following figures. These visualizations improve the interpretability of the model’s decisions significantly, allowing researchers and clinicians to map the model’s predictions to specific tissue regions. This method not only helps confirm the accuracy of the model’s outputs with recognized pathological features but also increases confidence in the model by transparently highlighting its decision-making process.</p>
</div>
<figure class="ltx_figure" id="Sx2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="245" id="Sx2.F4.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="Sx2.F4.2.1">UMAP reveals disease progression modeling capabilities.
<br class="ltx_break"/></span>UMAP of features of the final layer illustrates that the model learns the natural disease progression from AIT to CFA (a) implicitly. This finding is consistent when using only one staining as an input (b), and the model is able to distinguish which staining it is processing (c).
</figcaption>
</figure>
<div class="ltx_para" id="Sx2.SSx4.p2">
<p class="ltx_p" id="Sx2.SSx4.p2.1">Moreover, figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F4" title="Figure 4 ‣ UNICORN highlights explainable features ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">4</span></a>a illustrates that UNICORN is capable of accurately modeling the natural progression of atherosclerosis, as evidenced by a UMAP of an additional internal dataset comprising 768 segments from 114 individuals. The capacity of UNICORN to capture this progression is particularly noteworthy as it implies that the model is not only performing classification but is also learning a representation that aligns with the underlying biological process of the disease. This suggests that the model’s decision-making is grounded in clinically relevant features, which could enhance its utility in both diagnostic and research settings.
Furthermore, the progression model exhibits consistency when considering individual stainings, as shown in figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F4" title="Figure 4 ‣ UNICORN highlights explainable features ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">4</span></a>b. The model’s robustness when limited to a single staining demonstrates its adaptability and resilience in scenarios where multimodal data might not be available. This means that the model can still provide meaningful insights even when only partial data is accessible, which is common in real-world clinical environments. The ability to generalize to a single staining suggests that the features learned by the model are rooted in the biological characteristics of the tissue, rather than being artifacts of the specific staining technique. As illustrated in figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F4" title="Figure 4 ‣ UNICORN highlights explainable features ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">4</span></a>c, the model’s capacity to differentiate between various stainings is supported by empirical evidence. This ability to distinguish the particular staining processing is a crucial step towards effectively handling missing data, as it inherently recognizes what information is absent.</p>
</div>
<figure class="ltx_figure" id="Sx2.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="Sx2.F5.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="Sx2.F5.2.1">UNICORN highlights stain specific classification relevant regions.
<br class="ltx_break"/></span>Highest class attention regions are shown in red across the four different stainings (H&amp;E, EvG, vK, Movat) for a calcified fibroatheroma (CFA) case. The enlarged regions show highest class attention regions. For H&amp;E and EvG the most relevant structures are highlighted with blue arrows.
</figcaption>
</figure>
<div class="ltx_para" id="Sx2.SSx4.p3">
<p class="ltx_p" id="Sx2.SSx4.p3.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F5" title="Figure 5 ‣ UNICORN highlights explainable features ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">5</span></a> shows, as an example for the CFA class, class attention maps and corresponding high class attention patches according to figure 3d, revealing regions identified by UNICORN as critical for classification. Additional examples for AIT, PIT, EFA and LFA cases are shown in the appendix (supplementary figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx3.F1" title="Figure S1 ‣ Supplemental material ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">S1</span></a>). The high class attention patches in the CFA case demonstrate the most relevant regions for the phenotype learned by the model and closely match the expert opinion. The sections show a lipid-rich necrotic core consisting of extracellular lipid deposits and cellular debris across the four different stains. The necrotic core is covered by a fibrous cap composed of smooth muscle cells, collagen and other extracellular matrix components.</p>
</div>
<div class="ltx_para" id="Sx2.SSx4.p4">
<p class="ltx_p" id="Sx2.SSx4.p4.1">In the H&amp;E-stained sections, the algorithm focuses on regions characterized by dense fibrotic areas and calcified necrotic cores (blue arrows), which are typical of advanced fibroatheromas. These areas, highlighted in purple, correlate with expert annotations marking regions of calcification and fibrosis. In the EvG stain, the algorithm detects regions rich in extracellular matrix components, particularly elastic and collagen fibers, shown as red wavy structures (blue arrows). These structures, particularly in the shoulder region, outer necrotic core and intima are critical in distinguishing CFA from earlier lesion stages, as CFA indicates less extracellular matrix due to remodeling in the vessel wall. Von Kossa (vK) staining accentuates calcifications, with the model placing particular attention to black-stained regions, indicating areas of significant calcium deposition within the intima. This focus assists in the differentiation of CFA, where calcification is a defining feature. Finally, the Movat pentachrome stain highlights the lipid-rich necrotic core in yellow-green, which the algorithm correctly identifies as a key pathological feature of CFA. By focusing on these areas, the algorithm demonstrates its ability to distinguish CFA from less advanced fibroatheromas. These visualization results, together with the results shown in figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F2" title="Figure 2 ‣ MISSION: Multi-stain atherosclerosis classification dataset ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">2</span></a>, underscore the algorithm’s ability to accurately identify relevant histologic features across multiple staining techniques.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx5">
<h3 class="ltx_title ltx_title_subsection">Discussion</h3>
<div class="ltx_para" id="Sx2.SSx5.p1">
<p class="ltx_p" id="Sx2.SSx5.p1.1">In our study, we present UNICORN, a transformer-based model designed to analyze multi-stain histopathological data. UNICORN represents a significant advancement in histopathology, particularly in integrating multi-modal data for improved diagnostic accuracy. As precision medicine and personalized healthcare advance, the model’s capability to handle missing data and synthesize information from various sources makes it a valuable tool in research and clinical practice. UNICORN might augment pathologist workflows by providing explainable preliminary assessments and highlighting critical areas of interest in tissue samples, thereby expediting the diagnostic process. Its ability to perform inference on only a subset of possible stains can reduce the need for additional staining, optimizing resource use and cost.
The UNICORN framework holds promise for application beyond coronary artery disease. Its architecture is adaptable to other disease phenotypes and could be augmented by integrating high-throughput functional or longitudinal data. This integration would offer deeper insights into disease mechanisms and support more precise phenotyping. Future research could also investigate the replacement of initial expert modules with alternative networks, such as Convolutional Neural Networks or Vision Transformers, to further enhance model performance. Additionally, the incorporation of clinical and high-throughput data into the model could provide a more comprehensive understanding of disease specific pathology, functional biology and improve classification accuracy.

<br class="ltx_break"/>Despite its promising capabilities UNICORN incorporates several limitations. The performance of the model is dependent on the quality and diversity of used staining protocols. In cases where specific stains, such as Movat or Elastica van Gieson, are less informative when other stains are present, the model’s effectiveness may be reduced. Additionally, the current feature extractor, optimized primarily for H&amp;E staining, may not fully leverage information from other stains, potentially limiting the model’s overall performance. Future work should explore fine-tuning strategies and the integration of alternative networks to address this issue. Furthermore, while UNICORN handles missing data well, its generalizability to other phenotypes and the integration of multi-omics data remains to be validated. Finally, the practical implementation in research and clinical settings will require significant investment in training and adaptation of existing workflows. In conclusion, the UNICORN model represents a significant advancement in the integration and analysis of multi-stain histopathological data. Its ability to handle missing modalities and provide comprehensive insights across diverse staining techniques positions it as a valuable tool for enhancing diagnostic accuracy and efficiency. While the model shows promising results in atherosclerosis classification, further optimization and validation are needed to fully realize its potential across various disease phenotypes. The integration of UNICORN into research and clinical workflows has the potential to significantly improve diagnostic consistency and support explainable personalized medicine.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx6">
<h3 class="ltx_title ltx_title_subsection">Methods</h3>
<section class="ltx_subsubsection" id="Sx2.SSx6.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Histological data compilation, selection and staining</h4>
<div class="ltx_para" id="Sx2.SSx6.SSSx1.p1">
<p class="ltx_p" id="Sx2.SSx6.SSSx1.p1.1">The Munich cardIovaScular StudIes biObaNk (MISSION) was launched in 2019 and comprises seven cardiovascular relevant tissue samples from each individual, such as coronary and carotid artery tissue samples, as well as myocardium. It also includes blood and plasma, liver, skeletal muscle and various adipose tissues from more than 1000 deceased individuals, collected in formalin for FFPE sections (formalin fixed paraffin embedded) and fresh frozen at -80°C. tissue sections were deparaffinized in xylene substitute and rehydrated through graded alcohol series. A total of 1045 tissue samples from 170 individuals were analyzed in this study, covering the following coronary arteries: each proximal and distal RCA (right coronary artery), the LAD (left anterior descending artery) and the LCX (left circumflex coronary artery) as well as the LM (left main) (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>a). Each tissue section was subjected to a series of histopathological analyses, including hematoxylin and eosin (H&amp;E) staining, Elastica van Gieson (EvG) staining, von Kossa (vK) silver staining, and Movat Pentachrome (Movat) staining. These techniques were employed to assess the histopathological characteristics of atherosclerotic lesions.</p>
</div>
<div class="ltx_para" id="Sx2.SSx6.SSSx1.p2">
<p class="ltx_p" id="Sx2.SSx6.SSSx1.p2.1">The histological classification of the atherosclerotic lesions was performed in accordance with the American Heart Association (AHA) classification and the adapted classification system proposed by Virmani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib23" title="">23</a>]</cite>. The lesions were categorized into the following five stages (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx1.F1" title="Figure 1 ‣ Introduction ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">1</span></a>b). Advanced intima thickening (AIT) is defined by diffuse intimal thickening composed of smooth muscle cells and extracellular matrix in the absence of significant lipid accumulation or inflammatory infiltration. The pathological intima thickening (PIT) is primarily defined by the accumulation of extracellular lipid and inflammatory cells within the intima, though a necrotic core is absent. For the vulnerable stages, early, late, and calcified fibroatheroma (EFA, LFA, and CFA) are distinguished. Early fibroatheroma (EFA) is distinguished by a thin fibrous cap and a developing lipid core whereas the late fibroatheroma (LFA) is more advanced, exhibiting a larger necrotic core and a thicker, though still potentially unstable, fibrous cap. Additionally, LFA displays greater inflammatory involvement. Calcified fibroatheroma (CFA) represents the late stage of fibroatheroma development, with microscopically and macroscopically calcification present within the necrotic core. The fibrous cap may be thickened, and the lesion exhibits reduced cellularity due to extensive calcification.</p>
</div>
<div class="ltx_para" id="Sx2.SSx6.SSSx1.p3">
<p class="ltx_p" id="Sx2.SSx6.SSSx1.p3.1">The institutional review board and ethics committee of the Technical University of Munich, Germany, approved the protocol of the MISSION Biobank (2018-325-S-KK - 22.08.2018). The study was performed in accordance with the provisions of the Declaration of Helsinki and the International Conference on Harmonisation guidelines for good clinical practice. Human data from the MISSION Biobank can be requested by qualified researchers at the German Heart Center Munich.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Sx2.SSx6.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Image patching and feature extraction</h4>
<div class="ltx_para" id="Sx2.SSx6.SSSx2.p1">
<p class="ltx_p" id="Sx2.SSx6.SSSx2.p1.1">A publicly available pipeline from Wagner et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib25" title="">25</a>]</cite> was used to extract patches and the corresponding features from the WSIs. As the feature extractor, CTransPath <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib26" title="">26</a>]</cite> was used for each staining. Blurred regions and uncoloured background are excluded using a Canny edge detection algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib4" title="">4</a>]</cite> with a threshold of one edge to be detected per patch. A resolution of 5x for atherosclerosis prediction was used, as it empirically has shown to work best.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Sx2.SSx6.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Model training</h4>
<div class="ltx_para" id="Sx2.SSx6.SSSx3.p1">
<p class="ltx_p" id="Sx2.SSx6.SSSx3.p1.1">UNICORN is trained for 30 epochs using an AdamW <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib16" title="">16</a>]</cite> optimizer. The learning rate and the weight decay are set to 2.0e-5. Gradients are accumulated across 16 batches with batch size 1 before an update step is made. To increase robustness and force the model to be able to handle missing data well, it is trained with high domain dropout, where domains are randomly masked and not used as input. During training, for each input, one of the input domains is randomly chosen that will not be masked; all other stainings or additional domains have a chance of 0.7 to be masked. As the loss function, standard cross-entropy is used.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Sx2.SSx6.SSSx4">
<h4 class="ltx_title ltx_title_subsubsection">Model attention visualization</h4>
<div class="ltx_para" id="Sx2.SSx6.SSSx4.p1">
<p class="ltx_p" id="Sx2.SSx6.SSSx4.p1.1">To get high resolution attention maps, slides are patched with 95% overlap between patches, after which features are extracted. This results in 400 distinct feature bags, each representing the full slide. Each of these bags is independently forwarded through the network. The attention that is generated by attention rollout <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#bib.bib1" title="">1</a>]</cite> on the expert modules for each of the patches for each bag are all saved. Additionally, for each bag, only a single patch is forwarded and let the model predict a class based on one patch only, which results in the class scores. Using these class scores, one can visualize the Multiclass visualization (figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17775v1#Sx2.F3" title="Figure 3 ‣ Evaluation ‣ Results ‣ UNICORN: A Deep Learning Model for Integrating Multi-Stain Data in Histopathology"><span class="ltx_text ltx_ref_tag">3</span></a>b) by multiplying the color corresponding to a certain class by the class probability for a patch. Multiplying the attention scores with the multiclass score of the predicted class then gives the class attention score. In the end, the scores across overlapping patches are averaged for the detailed maps. All scores are normalized between 0 and 1 in the end.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Sx2.SSx7">
<h3 class="ltx_title ltx_title_subsection">Acknowledgements</h3>
<div class="ltx_para" id="Sx2.SSx7.p1">
<p class="ltx_p" id="Sx2.SSx7.p1.1">V.K. was supported by the Helmholtz Association under the joint research school “Munich School for Data Science - MUDS”. This work was also supported by the BMBF-funded de.NBI Cloud within the German Network for Bioinformatics Infrastructure (de.NBI) (031A532B, 031A533A, 031A533B, 031A534A, 031A535A, 031A537A, 031A537B, 031A537C, 031A537D, 031A538A). C.M. has received funding from the European Research Council under the European Union’s Horizon 2020 research and innovation program (grant agreement number 866411 and 101113551) and is supported by the Hightech Agenda Bayern. M.v.S. is supported by an excellence grant of the German Center for Cardiovascular Research (DZHK-81X3600506), the German Heart Foundation (Deutsche Herzstiftung e.V.), a Leducq PlaqOmics Junior Investigator Grant and a Junior Research Group Cardiovascular Diseases Grant of the CORONA Foundation (S199/10085/2021). The acquisition of the automated ZEISS AxioScan 7 slide scanning system was supported by the German Research Foundation (DFG-95/1713-1) and the German Center for Cardiovascular Research (DZHK-81Z0600501). H.S. is co-applicant of the British Heart Foundation (BHF)/German Centre of Cardiovascular Research (DZHK)-collaboration (DZHK-BHF: 81X2600522) and the Leducq Foundation for Cardiovascular Research (PlaqOmics: 18CVD02). Additional support has been received from the German Research Foundation (DFG) as part of the Sonderforschungsbereich SFB 1123 (B02) and the Sonderforschungsbereich SFB TRR 267 (B05). Further, we kindly acknowledge the support of the Bavarian State Ministry of Health and Care who funded this work with DigiMed Bayern (grant No: DMB-1805-0001) within its Masterplan “Bayern Digital II” and of the German Federal Ministry of Economics and Energy in its scheme of ModulMax (grant No: ZF4590201BA8). This study was supported by Deutsches CHIP Register e.V. (www.chip-register.de) and funded by the German Center for Cardiovascular Research (DZHK), Berlin, Germany, (DZHK81X2200145 and DZHK-81X2600520).</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx8">
<h3 class="ltx_title ltx_title_subsection">Contributions</h3>
<div class="ltx_para" id="Sx2.SSx8.p1">
<p class="ltx_p" id="Sx2.SSx8.p1.1">VK led the development of the code, model design, and conducted the evaluations. SB was responsible for data collection and annotation. VK and SB were the primary authors of the manuscript and created the figures. VL and SB started the project. MJ provided guidance to SB on classification tasks, and JS and CM offered advisory support to VK. MS and CM oversaw the project’s initiation. All authors contributed to the critical revision and enhancement of the manuscript.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Abnar, S., Zuidema, W.: Quantifying attention flow in transformers. arXiv preprint arXiv:2005.00928 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Al-Kofahi, Y., Lassoued, W., Lee, W., Roysam, B.: Improved automatic detection and segmentation of cell nuclei in histopathology images. IEEE Trans. Biomed. Eng. <span class="ltx_text ltx_font_bold" id="bib.bib2.1.1">57</span>(4), 841–852 (Apr 2010)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Campanella, G., Kwan, R., Fluder, E., Zeng, J., Stock, A., Veremis, B., Polydorides, A.D., Hedvat, C., Schoenfeld, A., Vanderbilt, C., et al.: Computational pathology at health system scale–self-supervised foundation models from three billion images. arXiv preprint arXiv:2310.07033 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Canny, J.: A computational approach to edge detection. IEEE Transactions on pattern analysis and machine intelligence (6), 679–698 (1986)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chen, R.J., Chen, C., Li, Y., Chen, T.Y., Trister, A.D., Krishnan, R.G., Mahmood, F.: Scaling vision transformers to gigapixel images via hierarchical self-supervised learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 16144–16155 (Jun 2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chen, R.J., Ding, T., Lu, M.Y., Williamson, D.F., Jaume, G., Song, A.H., Chen, B., Zhang, A., Shao, D., Shaban, M., et al.: Towards a general-purpose foundation model for computational pathology. Nature Medicine <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">30</span>(3), 850–862 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Holmberg, O., Lenz, T., Koch, V., Alyagoob, A., Utsch, L., Rank, A., Sabic, E., Seguchi, M., Xhepa, E., Kufner, S., Cassese, S., Kastrati, A., Marr, C., Joner, M., Nicol, P.: Histopathology-based deep-learning predicts atherosclerotic lesions in intravascular imaging. Front Cardiovasc Med <span class="ltx_text ltx_font_bold" id="bib.bib7.1.1">8</span>, 779807 (Dec 2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Ilse, M., Tomczak, J., Welling, M.: Attention-based deep multiple instance learning. In: Dy, J., Krause, A. (eds.) Proceedings of the 35th International Conference on Machine Learning. Proceedings of Machine Learning Research, vol. 80, pp. 2127–2136. PMLR (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jaegle, A., Gimeno, F., Brock, A., Vinyals, O., Zisserman, A., Carreira, J.: Perceiver: General perception with iterative attention. In: International conference on machine learning. pp. 4651–4664. PMLR (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Jones, M.L., Bancroft, J.D., Gamble, M.: 10 - connective tissues and stains. In: Bancroft, J.D., Gamble, M. (eds.) Theory and Practice of Histological Techniques (Sixth Edition), pp. 135–160. Churchill Livingstone, Edinburgh (Jan 2008)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Kassis, N., Kovarnik, T., Chen, Z., Weber, J.R., Martin, B., Darki, A., Woo, V., Wahle, A., Sonka, M., Lopez, J.J.: Fibrous cap thickness predicts stable coronary plaque progression: early clinical validation of a semiautomated oct technology. Journal of the Society for Cardiovascular Angiography &amp; Interventions <span class="ltx_text ltx_font_bold" id="bib.bib11.1.1">1</span>(5), 100400 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Kim, S.W., Roh, J., Park, C.S.: Immunohistochemistry for pathologists: protocols, pitfalls, and tips. Journal of pathology and translational medicine <span class="ltx_text ltx_font_bold" id="bib.bib12.1.1">50</span>(6), 411–418 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
van der Laak, J., Litjens, G., Ciompi, F.: Deep learning in histopathology: the path to the clinic. Nat. Med. <span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">27</span>(5), 775–784 (May 2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Lee, H.Y., Lim, S., Park, S.: Erratum: Role of inflammation in arterial calcification. Korean Circulation Journal <span class="ltx_text ltx_font_bold" id="bib.bib14.1.1">51</span>(3),  286 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Leong, A.S.Y.: Quantitative immunohistology: tissue section thickness, another glitch in the path to standardization. Appl. Immunohistochem. Mol. Morphol. <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">17</span>(6), 465–469 (Dec 2009)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv [cs.LG] (Nov 2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Murray, J.M., Pfeffer, P., Seifert, R., Hermann, A., others: Vesseg: An open-source tool for deep learning-based atherosclerotic plaque quantification in histopathology Images—Brief report. , and vascular biology (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Onnis, C., Virmani, R., Kawai, K., Nardi, V., Lerman, A., Cademartiri, F., Scicolone, R., Boi, A., Congiu, T., Faa, G., et al.: Coronary artery calcification: current concepts and clinical implications. Circulation <span class="ltx_text ltx_font_bold" id="bib.bib18.1.1">149</span>(3), 251–266 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Otsuka, F., Joner, M., Prati, F., Virmani, R., Narula, J.: Clinical classification of plaque morphology in coronary disease. Nat. Rev. Cardiol. <span class="ltx_text ltx_font_bold" id="bib.bib19.1.1">11</span>(7), 379–389 (Jul 2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Shao, Z., Bian, H., Chen, Y., Wang, Y., Zhang, J., Ji, X., et al.: Transmil: Transformer based correlated multiple instance learning for whole slide image classification. Advances in neural information processing systems <span class="ltx_text ltx_font_bold" id="bib.bib20.1.1">34</span>, 2136–2147 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Stary, H.C., Chandler, A.B., Dinsmore, R.E., Fuster, V., Glagov, S., Insull, Jr, W., Rosenfeld, M.E., Schwartz, C.J., Wagner, W.D., Wissler, R.W.: A definition of advanced types of atherosclerotic lesions and a histological classification of atherosclerosis. a report from the committee on vascular lesions of the council on arteriosclerosis, american heart association. Circulation <span class="ltx_text ltx_font_bold" id="bib.bib21.1.1">92</span>(5), 1355–1374 (Sep 1995)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Stary, H.C., Chandler, A.B., Glagov, S., Guyton, J.R., Insull, Jr, W., Rosenfeld, M.E., Schaffer, S.A., Schwartz, C.J., Wagner, W.D., Wissler, R.W.: A definition of initial, fatty streak, and intermediate lesions of atherosclerosis. a report from the committee on vascular lesions of the council on arteriosclerosis, american heart-association. Circulation <span class="ltx_text ltx_font_bold" id="bib.bib22.1.1">89</span>(5), 2462–2478 (May 1994)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Virmani, R., Kolodgie, F.D., Burke, A.P., Farb, A., Schwartz, S.M.: Lessons from sudden coronary death: a comprehensive morphological classification scheme for atherosclerotic lesions. Arterioscler. Thromb. Vasc. Biol. <span class="ltx_text ltx_font_bold" id="bib.bib23.1.1">20</span>(5), 1262–1275 (May 2000)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Vorontsov, E., Bozkurt, A., Casson, A., Shaikovski, G., Zelechowski, M., Liu, S., Severson, K., Zimmermann, E., Hall, J., Tenenholtz, N., Fusi, N., Mathieu, P., van Eck, A., Lee, D., Viret, J., Robert, E., Wang, Y.K., Kunz, J.D., Lee, M.C.H., Bernhard, J., Godrich, R.A., Oakley, G., Millar, E., Hanna, M., Retamero, J., Moye, W.A., Yousfi, R., Kanan, C., Klimstra, D., Rothrock, B., Fuchs, T.J.: Virchow: A million-slide digital pathology foundation model (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2309.07778" title="">https://arxiv.org/abs/2309.07778</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Wagner, S.J., Reisenbüchler, D., West, N.P., Niehues, J.M., Zhu, J., Foersch, S., Veldhuizen, G.P., Quirke, P., Grabsch, H.I., van den Brandt, P.A., Hutchins, G.G.A., Richman, S.D., Yuan, T., Langer, R., Jenniskens, J.C.A., Offermans, K., Mueller, W., Gray, R., Gruber, S.B., Greenson, J.K., Rennert, G., Bonner, J.D., Schmolze, D., Jonnagaddala, J., Hawkins, N.J., Ward, R.L., Morton, D., Seymour, M., Magill, L., Nowak, M., Hay, J., Koelzer, V.H., Church, D.N., TransSCOT consortium, Matek, C., Geppert, C., Peng, C., Zhi, C., Ouyang, X., James, J.A., Loughrey, M.B., Salto-Tellez, M., Brenner, H., Hoffmeister, M., Truhn, D., Schnabel, J.A., Boxberg, M., Peng, T., Kather, J.N.: Transformer-based biomarker prediction from colorectal cancer histology: A large-scale multicentric study. Cancer Cell <span class="ltx_text ltx_font_bold" id="bib.bib25.1.1">41</span>(9), 1650–1661.e4 (Sep 2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Yang, W., Huang, J., Han, X.: Transformer-based unsupervised contrastive learning for histopathological image classification. Medical image analysis <span class="ltx_text ltx_font_bold" id="bib.bib26.1.1">81</span>, 102559 (2022)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">Supplemental material</h2>
<figure class="ltx_figure" id="Sx3.2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="467" id="Sx3.1.g1" src="x7.png" width="830"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="417" id="Sx3.2.g2" src="x8.png" width="830"/></div>
</div>
</figure>
<figure class="ltx_figure" id="Sx3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="417" id="Sx3.F1.g1" src="x9.png" width="830"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="432" id="Sx3.F1.g2" src="x10.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure S1: </span><span class="ltx_text ltx_font_bold" id="Sx3.F1.6.1">UNICORN highlights stain specific classification relevant regions.</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx3.F1.7.2">a)</span> UNICORN effectively identifies and classifies adaptive intima thickening (AIT) using four distinct stainings: Hematoxylin and Eosin (H&amp;E), Elastica van Gieson (EvG), von Kossa, and Movat Pentachrome (Movat). The prioritized patches with the highest score illustrate thickening of the intima with intact cell structures, highlighting the accumulation of smooth muscle cells and extracellular matrix within the arterial wall’s intimal layer.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx3.F1.8.3">b)</span> Pathologic intima thickening (PIT). The highlighted patches reveal increased numbers of smooth muscle cells within the intima, enhanced deposition of extracellular matrix components such as collagen and proteoglycans, the presence of extracellular lipid pools or droplets within the intimal layer without the formation of a necrotic core, and absent inflammatory cell infiltration.

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx3.F1.9.4">c)</span> Early fibroatheroma (EFA). The highlighted patches reveal a well-defined lipid-rich necrotic core within the intima, consisting of extracellular lipid deposits and cellular debris. A fibrous cap, composed of smooth muscle cells, collagen, and other extracellular matrix components, covers the necrotic core. There is a presence of macrophages and foam cells at the edges of the necrotic core, along with initial signs of inflammation indicated by some infiltration of inflammatory cells, though not as prominent as in advanced lesions.

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx3.F1.10.5">d)</span> Late fibroatheroma (LFA). The highlighted patches reveal a prominent, well-defined lipid-rich necrotic core consisting of extracellular lipid deposits, cholesterol crystals, and cellular debris. This core is covered by a thick fibrous cap composed of layers of smooth muscle cells, collagen, and other extracellular matrix components. The presence of macrophages, foam cells, and other inflammatory cells is noted particularly at the edges of the necrotic core and within the fibrous cap. 
<br class="ltx_break"/></figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 26 12:07:07 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
