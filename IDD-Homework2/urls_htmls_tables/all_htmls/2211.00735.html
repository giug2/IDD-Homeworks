<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2211.00735] TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments</title><meta property="og:description" content="With the increased legislation around data privacy, federated learning (FL) has emerged as a promising technique that allows the clients (end-user) to collaboratively train deep learning (DL) models without transferrinâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2211.00735">

<!--Generated on Thu Mar 14 07:59:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\sidecaptionvpos</span>
<p id="p1.2" class="ltx_p">figurec





</p>
</div>
<h1 class="ltx_title ltx_title_document">TorchFL: A Performant Library for 
<br class="ltx_break">Bootstrapping Federated Learning Experiments</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vivek Khimani
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Drexel University
<br class="ltx_break">{vck29, shahin}@drexel.edu
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shahin Jabbari
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Drexel University
<br class="ltx_break">{vck29, shahin}@drexel.edu
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">With the increased legislation around data privacy, federated learning (FL) has emerged as a promising technique that allows the clients (end-user) to collaboratively train deep learning (DL) models without transferring and storing the data in a centralized, third-party server. We introduce <span id="id1.id1.1" class="ltx_text ltx_font_italic">TorchFL</span> <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The code can be found at <a target="_blank" href="https://github.com/vivekkhimani/torchfl" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/vivekkhimani/torchfl</a> and the documentation can be found at <a target="_blank" href="https://torchfl.readthedocs.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://torchfl.readthedocs.io/</a>.</span></span></span>, a performant library for (i) bootstrapping the FL experiments, (ii) executing them using various hardware accelerators, (iii) profiling the performance, and (iv) logging the overall and agent-specific results on the go. Being built on a bottom-up design using PyTorch and Lightning, <span id="id1.id1.2" class="ltx_text ltx_font_italic">TorchFL</span> provides ready-to-use abstractions for models, datasets, and FL algorithms, while allowing the developers to customize them as and when required. This paper aims to dig deeper into the architecture and design of <span id="id1.id1.3" class="ltx_text ltx_font_italic">TorchFL</span>, elaborate on how it allows researchers to bootstrap the federated learning experience, and provide experiments and code snippets for the same. With the ready-to-use implementation of state-of-the-art DL models, datasets, and federated learning support, <span id="id1.id1.4" class="ltx_text ltx_font_italic">TorchFL</span> aims to allow researchers with little to no engineering background to set up FL experiments with minimal coding and infrastructure overhead.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the rapid advancement of sensing and computing capabilities, the amount of data generated from mobile (client) devices has exponentially increased in recent years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. The increased volume of data has enabled deep learning (DL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> to become a widely adopted technique to train the computational models on the usersâ€™ data and actively learn from their browsing patterns. In addition to the availability of the data, the recent research advances in specialized hardware <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> have enabled us to achieve astonishing results in ad targeting, language translation, image generation, content recommendations, and a lot more problems that were difficult to solve without a neural network (NN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Given the magnitude of data and computational resources required to train these models, the user data is often sent and collected in a centralized server, and the trained model is deployed on the device. While this technique has been effective, the stricter legislation and norms around data privacy make it difficult to use the data for training the DL models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. As a result, federated learning (FL) has emerged as a promising technique for training models across multiple clients (e.g., edge or mobile devices) without requiring the exchange of locally stored data but only that of the parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Despite being applied and having displayed initial success with the Google Keyboard <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, FL faces serious hardware and infrastructure challenges before it can provide the same results as the traditional DL techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">While part of the research community is dealing with these hardware and infrastructure challenges, most of the community focuses on designing new sampling algorithms, incentive mechanisms, aggregation protocols, defense mechanisms, and all of the other components that are integral to the FL pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. While working on these problems, it is often a common practice to simulate the FL experiments where the clients, datasets, and FL models are spawned on a single machine and the empirical results are collected. In this paper, we present <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">TorchFL</span>, a plug-and-play and performant library for bootstrapping simulated FL experiments.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Running an end-to-end FL experiment using a specific DL framework - PyTorch in this case - consists of various steps including but not limited to the following:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Selecting and building a DL model compatible with the framework,</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Collecting the data and preparing it for training,</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Federating the dataset using iid or non-iid configuration,</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Writing an aggregation protocol that is used by the server for federation,</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Wrapping it all together in a single module,</p>
</div>
</li>
<li id="S1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="S1.I1.i6.p1" class="ltx_para">
<p id="S1.I1.i6.p1.1" class="ltx_p">Setting up the infrastructure to run everything using the accelerated hardware (GPUs, TPUs, etc.).</p>
</div>
</li>
</ol>
<p id="S1.p4.2" class="ltx_p">As the DL models are getting more complex, and constant innovations are being made on the hardware accelerators as well as the tools around the data collection and visualizations, <span id="S1.p4.2.1" class="ltx_text ltx_font_italic">TorchFL</span> aims to eliminate such barriers for the FL community by abstracting the hardware, infrastructure, data, and DL implementations to set up the experiments.
Hence, the main contribution of the <span id="S1.p4.2.2" class="ltx_text ltx_font_italic">TorchFL</span> is to provide researchers with no engineering background and novice data scientists a toolkit to set up FL experiments with minimal coding and infrastructure overhead (See SectionÂ <a href="#S5" title="5 Related Work â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> for a comparison of TorchFL and other FL toolkits). Given that Python and PyTorch are the most popular languages and frameworks used for DL respectively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, <span id="S1.p4.2.3" class="ltx_text ltx_font_italic">TorchFL</span> is a Python library that is built on PyTorch and can be used by a developer to run an end-to-end experiment by providing the following features:</p>
<ol id="S1.I2" class="ltx_enumerate">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">Wrappers for state-of-the-art DL models that can be trained in federated or non-federated settings,</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">Wrappers for the most commonly used state-of-the-art datasets and the ability to automatically create the data shards based on the FL configuration,</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">Added support for the fine-tuning or feature extraction from the pre-trained DL models, allowing for faster training using federated transfer learning,</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p">Customizable FL layer with the ready-to-use implementation of FL clients, samplers, and aggregators, which can be used to quickly spawn the experiments using the configuration files,</p>
</div>
</li>
<li id="S1.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I2.i5.p1" class="ltx_para">
<p id="S1.I2.i5.p1.1" class="ltx_p">Backward compatibility with the PyTorch Lightning loggers, profilers, hardware accelerators, and the latest DevOps tools to help avoid the implementation and performance overhead for recording and collecting the experimental results.</p>
</div>
</li>
</ol>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In addition to the aforementioned features, abstractions, and ease-of-use, <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">TorchFL</span> is implemented using a bottom-up approach as shown in Figure <a href="#S2.F2" title="Figure 2 â€£ 2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, which allows the developers to customize every layer and build on top of the library to validate their research and hypothesis.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">While <span id="S1.p6.1.1" class="ltx_text ltx_font_italic">TorchFL</span> is designed to address the pain points mentioned earlier, it is a relatively new project with its own limitations that we hope to overcome by open-sourcing it and getting feedback from the community. We will dig deeper into these limitations in SectionÂ <a href="#S6" title="6 Limitations and Future Work â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The rest of the paper is organized as follows. In SectionÂ <a href="#S2" title="2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we present background material on FL. SectionÂ <a href="#S3" title="3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> discusses the detailed explanation and design decisions for the <span id="S1.p7.1.1" class="ltx_text ltx_font_italic">TorchFL</span> architecture. In SectionÂ <a href="#S4" title="4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we run FL experiments using <span id="S1.p7.1.2" class="ltx_text ltx_font_italic">TorchFL</span> and provide examples to demonstrate the abstraction, effectiveness, and customizability of the framework. We wrap up by reviewing the existing FL toolkits (SectionÂ <a href="#S5" title="5 Related Work â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) and discussing limitations and future work (SectionÂ <a href="#S6" title="6 Limitations and Future Work â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>)</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background on FL</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FL is a machine-learning setting where many clients collaboratively train a model under the orchestration of a central serverÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. In this work, we focus on <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">cross-device FL</span>, where clients are a very large number of mobile or edge devices with private and locally stored training data. Given a learning objective, the goal of the server is to train a model optimizing for the aforementioned objective by performing updates and aggregation using clientsâ€™ data without transferring or exchanging any data from the clients. This model can then be deployed on clients as well as new users. The lifecycle of a <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">cross-device</span> FL system can be better understood using the visual representation provided in Figure <a href="#S2.F1" title="Figure 1 â€£ 2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2211.00735/assets/FL_background.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="220" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.4.2" class="ltx_text" style="font-size:90%;">The lifecycle of a <span id="S2.F1.4.2.1" class="ltx_text ltx_font_italic">cross-device FL</span> system with multiple client devices and a single server. The figure is adopted fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</span></figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.19" class="ltx_p">Mathematically, the goal in cross-device FL is to optimize a loss function <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">L</annotation></semantics></math> using a model <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">M</annotation></semantics></math> parameterized by a vector <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="W_{M}\in R^{d}" display="inline"><semantics id="S2.p2.3.m3.1a"><mrow id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml"><msub id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml"><mi id="S2.p2.3.m3.1.1.2.2" xref="S2.p2.3.m3.1.1.2.2.cmml">W</mi><mi id="S2.p2.3.m3.1.1.2.3" xref="S2.p2.3.m3.1.1.2.3.cmml">M</mi></msub><mo id="S2.p2.3.m3.1.1.1" xref="S2.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml"><mi id="S2.p2.3.m3.1.1.3.2" xref="S2.p2.3.m3.1.1.3.2.cmml">R</mi><mi id="S2.p2.3.m3.1.1.3.3" xref="S2.p2.3.m3.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"><in id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1.1"></in><apply id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.p2.3.m3.1.1.2.1.cmml" xref="S2.p2.3.m3.1.1.2">subscript</csymbol><ci id="S2.p2.3.m3.1.1.2.2.cmml" xref="S2.p2.3.m3.1.1.2.2">ğ‘Š</ci><ci id="S2.p2.3.m3.1.1.2.3.cmml" xref="S2.p2.3.m3.1.1.2.3">ğ‘€</ci></apply><apply id="S2.p2.3.m3.1.1.3.cmml" xref="S2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.p2.3.m3.1.1.3.1.cmml" xref="S2.p2.3.m3.1.1.3">superscript</csymbol><ci id="S2.p2.3.m3.1.1.3.2.cmml" xref="S2.p2.3.m3.1.1.3.2">ğ‘…</ci><ci id="S2.p2.3.m3.1.1.3.3.cmml" xref="S2.p2.3.m3.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">W_{M}\in R^{d}</annotation></semantics></math> in <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.p2.4.m4.1a"><mi id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">T</annotation></semantics></math> rounds via a training dataset <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.p2.5.m5.1a"><mi id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><ci id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">D</annotation></semantics></math>, which is distributed and privately stored among a set of <math id="S2.p2.6.m6.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p2.6.m6.1a"><mi id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><ci id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">K</annotation></semantics></math> devices or agents <math id="S2.p2.7.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.p2.7.m7.1a"><mi id="S2.p2.7.m7.1.1" xref="S2.p2.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.1b"><ci id="S2.p2.7.m7.1.1.cmml" xref="S2.p2.7.m7.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.7.m7.1c">A</annotation></semantics></math> (i.e., <math id="S2.p2.8.m8.1" class="ltx_Math" alttext="D=D_{1}\cup D_{2}\cup...\cup D_{K}" display="inline"><semantics id="S2.p2.8.m8.1a"><mrow id="S2.p2.8.m8.1.1" xref="S2.p2.8.m8.1.1.cmml"><mi id="S2.p2.8.m8.1.1.2" xref="S2.p2.8.m8.1.1.2.cmml">D</mi><mo id="S2.p2.8.m8.1.1.1" xref="S2.p2.8.m8.1.1.1.cmml">=</mo><mrow id="S2.p2.8.m8.1.1.3" xref="S2.p2.8.m8.1.1.3.cmml"><msub id="S2.p2.8.m8.1.1.3.2" xref="S2.p2.8.m8.1.1.3.2.cmml"><mi id="S2.p2.8.m8.1.1.3.2.2" xref="S2.p2.8.m8.1.1.3.2.2.cmml">D</mi><mn id="S2.p2.8.m8.1.1.3.2.3" xref="S2.p2.8.m8.1.1.3.2.3.cmml">1</mn></msub><mo id="S2.p2.8.m8.1.1.3.1" xref="S2.p2.8.m8.1.1.3.1.cmml">âˆª</mo><msub id="S2.p2.8.m8.1.1.3.3" xref="S2.p2.8.m8.1.1.3.3.cmml"><mi id="S2.p2.8.m8.1.1.3.3.2" xref="S2.p2.8.m8.1.1.3.3.2.cmml">D</mi><mn id="S2.p2.8.m8.1.1.3.3.3" xref="S2.p2.8.m8.1.1.3.3.3.cmml">2</mn></msub><mo id="S2.p2.8.m8.1.1.3.1a" xref="S2.p2.8.m8.1.1.3.1.cmml">âˆª</mo><mi mathvariant="normal" id="S2.p2.8.m8.1.1.3.4" xref="S2.p2.8.m8.1.1.3.4.cmml">â€¦</mi><mo id="S2.p2.8.m8.1.1.3.1b" xref="S2.p2.8.m8.1.1.3.1.cmml">âˆª</mo><msub id="S2.p2.8.m8.1.1.3.5" xref="S2.p2.8.m8.1.1.3.5.cmml"><mi id="S2.p2.8.m8.1.1.3.5.2" xref="S2.p2.8.m8.1.1.3.5.2.cmml">D</mi><mi id="S2.p2.8.m8.1.1.3.5.3" xref="S2.p2.8.m8.1.1.3.5.3.cmml">K</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.8.m8.1b"><apply id="S2.p2.8.m8.1.1.cmml" xref="S2.p2.8.m8.1.1"><eq id="S2.p2.8.m8.1.1.1.cmml" xref="S2.p2.8.m8.1.1.1"></eq><ci id="S2.p2.8.m8.1.1.2.cmml" xref="S2.p2.8.m8.1.1.2">ğ·</ci><apply id="S2.p2.8.m8.1.1.3.cmml" xref="S2.p2.8.m8.1.1.3"><union id="S2.p2.8.m8.1.1.3.1.cmml" xref="S2.p2.8.m8.1.1.3.1"></union><apply id="S2.p2.8.m8.1.1.3.2.cmml" xref="S2.p2.8.m8.1.1.3.2"><csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.3.2.1.cmml" xref="S2.p2.8.m8.1.1.3.2">subscript</csymbol><ci id="S2.p2.8.m8.1.1.3.2.2.cmml" xref="S2.p2.8.m8.1.1.3.2.2">ğ·</ci><cn type="integer" id="S2.p2.8.m8.1.1.3.2.3.cmml" xref="S2.p2.8.m8.1.1.3.2.3">1</cn></apply><apply id="S2.p2.8.m8.1.1.3.3.cmml" xref="S2.p2.8.m8.1.1.3.3"><csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.3.3.1.cmml" xref="S2.p2.8.m8.1.1.3.3">subscript</csymbol><ci id="S2.p2.8.m8.1.1.3.3.2.cmml" xref="S2.p2.8.m8.1.1.3.3.2">ğ·</ci><cn type="integer" id="S2.p2.8.m8.1.1.3.3.3.cmml" xref="S2.p2.8.m8.1.1.3.3.3">2</cn></apply><ci id="S2.p2.8.m8.1.1.3.4.cmml" xref="S2.p2.8.m8.1.1.3.4">â€¦</ci><apply id="S2.p2.8.m8.1.1.3.5.cmml" xref="S2.p2.8.m8.1.1.3.5"><csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.3.5.1.cmml" xref="S2.p2.8.m8.1.1.3.5">subscript</csymbol><ci id="S2.p2.8.m8.1.1.3.5.2.cmml" xref="S2.p2.8.m8.1.1.3.5.2">ğ·</ci><ci id="S2.p2.8.m8.1.1.3.5.3.cmml" xref="S2.p2.8.m8.1.1.3.5.3">ğ¾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.8.m8.1c">D=D_{1}\cup D_{2}\cup...\cup D_{K}</annotation></semantics></math>). At each round <math id="S2.p2.9.m9.3" class="ltx_Math" alttext="t\in\{1,\ldots,T\}" display="inline"><semantics id="S2.p2.9.m9.3a"><mrow id="S2.p2.9.m9.3.4" xref="S2.p2.9.m9.3.4.cmml"><mi id="S2.p2.9.m9.3.4.2" xref="S2.p2.9.m9.3.4.2.cmml">t</mi><mo id="S2.p2.9.m9.3.4.1" xref="S2.p2.9.m9.3.4.1.cmml">âˆˆ</mo><mrow id="S2.p2.9.m9.3.4.3.2" xref="S2.p2.9.m9.3.4.3.1.cmml"><mo stretchy="false" id="S2.p2.9.m9.3.4.3.2.1" xref="S2.p2.9.m9.3.4.3.1.cmml">{</mo><mn id="S2.p2.9.m9.1.1" xref="S2.p2.9.m9.1.1.cmml">1</mn><mo id="S2.p2.9.m9.3.4.3.2.2" xref="S2.p2.9.m9.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.p2.9.m9.2.2" xref="S2.p2.9.m9.2.2.cmml">â€¦</mi><mo id="S2.p2.9.m9.3.4.3.2.3" xref="S2.p2.9.m9.3.4.3.1.cmml">,</mo><mi id="S2.p2.9.m9.3.3" xref="S2.p2.9.m9.3.3.cmml">T</mi><mo stretchy="false" id="S2.p2.9.m9.3.4.3.2.4" xref="S2.p2.9.m9.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.9.m9.3b"><apply id="S2.p2.9.m9.3.4.cmml" xref="S2.p2.9.m9.3.4"><in id="S2.p2.9.m9.3.4.1.cmml" xref="S2.p2.9.m9.3.4.1"></in><ci id="S2.p2.9.m9.3.4.2.cmml" xref="S2.p2.9.m9.3.4.2">ğ‘¡</ci><set id="S2.p2.9.m9.3.4.3.1.cmml" xref="S2.p2.9.m9.3.4.3.2"><cn type="integer" id="S2.p2.9.m9.1.1.cmml" xref="S2.p2.9.m9.1.1">1</cn><ci id="S2.p2.9.m9.2.2.cmml" xref="S2.p2.9.m9.2.2">â€¦</ci><ci id="S2.p2.9.m9.3.3.cmml" xref="S2.p2.9.m9.3.3">ğ‘‡</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.9.m9.3c">t\in\{1,\ldots,T\}</annotation></semantics></math>, a subset of agents, <math id="S2.p2.10.m10.1" class="ltx_Math" alttext="A^{t}\subseteq A" display="inline"><semantics id="S2.p2.10.m10.1a"><mrow id="S2.p2.10.m10.1.1" xref="S2.p2.10.m10.1.1.cmml"><msup id="S2.p2.10.m10.1.1.2" xref="S2.p2.10.m10.1.1.2.cmml"><mi id="S2.p2.10.m10.1.1.2.2" xref="S2.p2.10.m10.1.1.2.2.cmml">A</mi><mi id="S2.p2.10.m10.1.1.2.3" xref="S2.p2.10.m10.1.1.2.3.cmml">t</mi></msup><mo id="S2.p2.10.m10.1.1.1" xref="S2.p2.10.m10.1.1.1.cmml">âŠ†</mo><mi id="S2.p2.10.m10.1.1.3" xref="S2.p2.10.m10.1.1.3.cmml">A</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.10.m10.1b"><apply id="S2.p2.10.m10.1.1.cmml" xref="S2.p2.10.m10.1.1"><subset id="S2.p2.10.m10.1.1.1.cmml" xref="S2.p2.10.m10.1.1.1"></subset><apply id="S2.p2.10.m10.1.1.2.cmml" xref="S2.p2.10.m10.1.1.2"><csymbol cd="ambiguous" id="S2.p2.10.m10.1.1.2.1.cmml" xref="S2.p2.10.m10.1.1.2">superscript</csymbol><ci id="S2.p2.10.m10.1.1.2.2.cmml" xref="S2.p2.10.m10.1.1.2.2">ğ´</ci><ci id="S2.p2.10.m10.1.1.2.3.cmml" xref="S2.p2.10.m10.1.1.2.3">ğ‘¡</ci></apply><ci id="S2.p2.10.m10.1.1.3.cmml" xref="S2.p2.10.m10.1.1.3">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.10.m10.1c">A^{t}\subseteq A</annotation></semantics></math>, is chosen by the server for training. This process is called sampling. The goal of each sampled agent <math id="S2.p2.11.m11.1" class="ltx_Math" alttext="i\in A^{T}" display="inline"><semantics id="S2.p2.11.m11.1a"><mrow id="S2.p2.11.m11.1.1" xref="S2.p2.11.m11.1.1.cmml"><mi id="S2.p2.11.m11.1.1.2" xref="S2.p2.11.m11.1.1.2.cmml">i</mi><mo id="S2.p2.11.m11.1.1.1" xref="S2.p2.11.m11.1.1.1.cmml">âˆˆ</mo><msup id="S2.p2.11.m11.1.1.3" xref="S2.p2.11.m11.1.1.3.cmml"><mi id="S2.p2.11.m11.1.1.3.2" xref="S2.p2.11.m11.1.1.3.2.cmml">A</mi><mi id="S2.p2.11.m11.1.1.3.3" xref="S2.p2.11.m11.1.1.3.3.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.11.m11.1b"><apply id="S2.p2.11.m11.1.1.cmml" xref="S2.p2.11.m11.1.1"><in id="S2.p2.11.m11.1.1.1.cmml" xref="S2.p2.11.m11.1.1.1"></in><ci id="S2.p2.11.m11.1.1.2.cmml" xref="S2.p2.11.m11.1.1.2">ğ‘–</ci><apply id="S2.p2.11.m11.1.1.3.cmml" xref="S2.p2.11.m11.1.1.3"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.3.1.cmml" xref="S2.p2.11.m11.1.1.3">superscript</csymbol><ci id="S2.p2.11.m11.1.1.3.2.cmml" xref="S2.p2.11.m11.1.1.3.2">ğ´</ci><ci id="S2.p2.11.m11.1.1.3.3.cmml" xref="S2.p2.11.m11.1.1.3.3">ğ‘‡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.11.m11.1c">i\in A^{T}</annotation></semantics></math> is to minimize the loss function <math id="S2.p2.12.m12.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p2.12.m12.1a"><mi id="S2.p2.12.m12.1.1" xref="S2.p2.12.m12.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p2.12.m12.1b"><ci id="S2.p2.12.m12.1.1.cmml" xref="S2.p2.12.m12.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.12.m12.1c">L</annotation></semantics></math> over its own privately stored data min-batch of data <math id="S2.p2.13.m13.1" class="ltx_Math" alttext="D_{i}^{t}" display="inline"><semantics id="S2.p2.13.m13.1a"><msubsup id="S2.p2.13.m13.1.1" xref="S2.p2.13.m13.1.1.cmml"><mi id="S2.p2.13.m13.1.1.2.2" xref="S2.p2.13.m13.1.1.2.2.cmml">D</mi><mi id="S2.p2.13.m13.1.1.2.3" xref="S2.p2.13.m13.1.1.2.3.cmml">i</mi><mi id="S2.p2.13.m13.1.1.3" xref="S2.p2.13.m13.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p2.13.m13.1b"><apply id="S2.p2.13.m13.1.1.cmml" xref="S2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S2.p2.13.m13.1.1.1.cmml" xref="S2.p2.13.m13.1.1">superscript</csymbol><apply id="S2.p2.13.m13.1.1.2.cmml" xref="S2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S2.p2.13.m13.1.1.2.1.cmml" xref="S2.p2.13.m13.1.1">subscript</csymbol><ci id="S2.p2.13.m13.1.1.2.2.cmml" xref="S2.p2.13.m13.1.1.2.2">ğ·</ci><ci id="S2.p2.13.m13.1.1.2.3.cmml" xref="S2.p2.13.m13.1.1.2.3">ğ‘–</ci></apply><ci id="S2.p2.13.m13.1.1.3.cmml" xref="S2.p2.13.m13.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.13.m13.1c">D_{i}^{t}</annotation></semantics></math> at time <math id="S2.p2.14.m14.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.p2.14.m14.1a"><mi id="S2.p2.14.m14.1.1" xref="S2.p2.14.m14.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.p2.14.m14.1b"><ci id="S2.p2.14.m14.1.1.cmml" xref="S2.p2.14.m14.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.14.m14.1c">t</annotation></semantics></math>. The agents minimize the loss <math id="S2.p2.15.m15.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p2.15.m15.1a"><mi id="S2.p2.15.m15.1.1" xref="S2.p2.15.m15.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p2.15.m15.1b"><ci id="S2.p2.15.m15.1.1.cmml" xref="S2.p2.15.m15.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.15.m15.1c">L</annotation></semantics></math> by starting from the global weight vector <math id="S2.p2.16.m16.1" class="ltx_Math" alttext="W^{t}_{M}" display="inline"><semantics id="S2.p2.16.m16.1a"><msubsup id="S2.p2.16.m16.1.1" xref="S2.p2.16.m16.1.1.cmml"><mi id="S2.p2.16.m16.1.1.2.2" xref="S2.p2.16.m16.1.1.2.2.cmml">W</mi><mi id="S2.p2.16.m16.1.1.3" xref="S2.p2.16.m16.1.1.3.cmml">M</mi><mi id="S2.p2.16.m16.1.1.2.3" xref="S2.p2.16.m16.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p2.16.m16.1b"><apply id="S2.p2.16.m16.1.1.cmml" xref="S2.p2.16.m16.1.1"><csymbol cd="ambiguous" id="S2.p2.16.m16.1.1.1.cmml" xref="S2.p2.16.m16.1.1">subscript</csymbol><apply id="S2.p2.16.m16.1.1.2.cmml" xref="S2.p2.16.m16.1.1"><csymbol cd="ambiguous" id="S2.p2.16.m16.1.1.2.1.cmml" xref="S2.p2.16.m16.1.1">superscript</csymbol><ci id="S2.p2.16.m16.1.1.2.2.cmml" xref="S2.p2.16.m16.1.1.2.2">ğ‘Š</ci><ci id="S2.p2.16.m16.1.1.2.3.cmml" xref="S2.p2.16.m16.1.1.2.3">ğ‘¡</ci></apply><ci id="S2.p2.16.m16.1.1.3.cmml" xref="S2.p2.16.m16.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.16.m16.1c">W^{t}_{M}</annotation></semantics></math> at time <math id="S2.p2.17.m17.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.p2.17.m17.1a"><mi id="S2.p2.17.m17.1.1" xref="S2.p2.17.m17.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.p2.17.m17.1b"><ci id="S2.p2.17.m17.1.1.cmml" xref="S2.p2.17.m17.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.17.m17.1c">t</annotation></semantics></math> and running an algorithm such as stochastic gradient descent (SGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. At the end of the update, the agent <math id="S2.p2.18.m18.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.p2.18.m18.1a"><mi id="S2.p2.18.m18.1.1" xref="S2.p2.18.m18.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.p2.18.m18.1b"><ci id="S2.p2.18.m18.1.1.cmml" xref="S2.p2.18.m18.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.18.m18.1c">i</annotation></semantics></math> obtains a local weight vector <math id="S2.p2.19.m19.1" class="ltx_Math" alttext="W_{M_{i}}^{t+1}" display="inline"><semantics id="S2.p2.19.m19.1a"><msubsup id="S2.p2.19.m19.1.1" xref="S2.p2.19.m19.1.1.cmml"><mi id="S2.p2.19.m19.1.1.2.2" xref="S2.p2.19.m19.1.1.2.2.cmml">W</mi><msub id="S2.p2.19.m19.1.1.2.3" xref="S2.p2.19.m19.1.1.2.3.cmml"><mi id="S2.p2.19.m19.1.1.2.3.2" xref="S2.p2.19.m19.1.1.2.3.2.cmml">M</mi><mi id="S2.p2.19.m19.1.1.2.3.3" xref="S2.p2.19.m19.1.1.2.3.3.cmml">i</mi></msub><mrow id="S2.p2.19.m19.1.1.3" xref="S2.p2.19.m19.1.1.3.cmml"><mi id="S2.p2.19.m19.1.1.3.2" xref="S2.p2.19.m19.1.1.3.2.cmml">t</mi><mo id="S2.p2.19.m19.1.1.3.1" xref="S2.p2.19.m19.1.1.3.1.cmml">+</mo><mn id="S2.p2.19.m19.1.1.3.3" xref="S2.p2.19.m19.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.p2.19.m19.1b"><apply id="S2.p2.19.m19.1.1.cmml" xref="S2.p2.19.m19.1.1"><csymbol cd="ambiguous" id="S2.p2.19.m19.1.1.1.cmml" xref="S2.p2.19.m19.1.1">superscript</csymbol><apply id="S2.p2.19.m19.1.1.2.cmml" xref="S2.p2.19.m19.1.1"><csymbol cd="ambiguous" id="S2.p2.19.m19.1.1.2.1.cmml" xref="S2.p2.19.m19.1.1">subscript</csymbol><ci id="S2.p2.19.m19.1.1.2.2.cmml" xref="S2.p2.19.m19.1.1.2.2">ğ‘Š</ci><apply id="S2.p2.19.m19.1.1.2.3.cmml" xref="S2.p2.19.m19.1.1.2.3"><csymbol cd="ambiguous" id="S2.p2.19.m19.1.1.2.3.1.cmml" xref="S2.p2.19.m19.1.1.2.3">subscript</csymbol><ci id="S2.p2.19.m19.1.1.2.3.2.cmml" xref="S2.p2.19.m19.1.1.2.3.2">ğ‘€</ci><ci id="S2.p2.19.m19.1.1.2.3.3.cmml" xref="S2.p2.19.m19.1.1.2.3.3">ğ‘–</ci></apply></apply><apply id="S2.p2.19.m19.1.1.3.cmml" xref="S2.p2.19.m19.1.1.3"><plus id="S2.p2.19.m19.1.1.3.1.cmml" xref="S2.p2.19.m19.1.1.3.1"></plus><ci id="S2.p2.19.m19.1.1.3.2.cmml" xref="S2.p2.19.m19.1.1.3.2">ğ‘¡</ci><cn type="integer" id="S2.p2.19.m19.1.1.3.3.cmml" xref="S2.p2.19.m19.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.19.m19.1c">W_{M_{i}}^{t+1}</annotation></semantics></math> using only their privately stored mini-batch of data samples, computes</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\delta_{i}^{t+1}=W_{M_{i}}^{t+1}-W_{M}^{t}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><msubsup id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.2.2.2" xref="S2.E1.m1.1.1.2.2.2.cmml">Î´</mi><mi id="S2.E1.m1.1.1.2.2.3" xref="S2.E1.m1.1.1.2.2.3.cmml">i</mi><mrow id="S2.E1.m1.1.1.2.3" xref="S2.E1.m1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.2.3.2" xref="S2.E1.m1.1.1.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.2.3.1" xref="S2.E1.m1.1.1.2.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.2.3.3" xref="S2.E1.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><msubsup id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mi id="S2.E1.m1.1.1.3.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.cmml">W</mi><msub id="S2.E1.m1.1.1.3.2.2.3" xref="S2.E1.m1.1.1.3.2.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.2.3.2" xref="S2.E1.m1.1.1.3.2.2.3.2.cmml">M</mi><mi id="S2.E1.m1.1.1.3.2.2.3.3" xref="S2.E1.m1.1.1.3.2.2.3.3.cmml">i</mi></msub><mrow id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2" xref="S2.E1.m1.1.1.3.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.3.2.3.1" xref="S2.E1.m1.1.1.3.2.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.3.2.3.3" xref="S2.E1.m1.1.1.3.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml">âˆ’</mo><msubsup id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.3.3.2.2" xref="S2.E1.m1.1.1.3.3.2.2.cmml">W</mi><mi id="S2.E1.m1.1.1.3.3.2.3" xref="S2.E1.m1.1.1.3.3.2.3.cmml">M</mi><mi id="S2.E1.m1.1.1.3.3.3" xref="S2.E1.m1.1.1.3.3.3.cmml">t</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></eq><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.2">superscript</csymbol><apply id="S2.E1.m1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.2.1.cmml" xref="S2.E1.m1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.2.2.2.cmml" xref="S2.E1.m1.1.1.2.2.2">ğ›¿</ci><ci id="S2.E1.m1.1.1.2.2.3.cmml" xref="S2.E1.m1.1.1.2.2.3">ğ‘–</ci></apply><apply id="S2.E1.m1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.2.3"><plus id="S2.E1.m1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.2.3.1"></plus><ci id="S2.E1.m1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S2.E1.m1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><minus id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"></minus><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2">superscript</csymbol><apply id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2">ğ‘Š</ci><apply id="S2.E1.m1.1.1.3.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.2.3.2">ğ‘€</ci><ci id="S2.E1.m1.1.1.3.2.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.2.3.3">ğ‘–</ci></apply></apply><apply id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3"><plus id="S2.E1.m1.1.1.3.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3.1"></plus><ci id="S2.E1.m1.1.1.3.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2">ğ‘¡</ci><cn type="integer" id="S2.E1.m1.1.1.3.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.3.3">superscript</csymbol><apply id="S2.E1.m1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.3.2.1.cmml" xref="S2.E1.m1.1.1.3.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.3.2.2.cmml" xref="S2.E1.m1.1.1.3.3.2.2">ğ‘Š</ci><ci id="S2.E1.m1.1.1.3.3.2.3.cmml" xref="S2.E1.m1.1.1.3.3.2.3">ğ‘€</ci></apply><ci id="S2.E1.m1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.3.3.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\delta_{i}^{t+1}=W_{M_{i}}^{t+1}-W_{M}^{t}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p2.21" class="ltx_p">and sends it to the server. To update the global weight vector <math id="S2.p2.20.m1.1" class="ltx_Math" alttext="W_{M}^{t+1}" display="inline"><semantics id="S2.p2.20.m1.1a"><msubsup id="S2.p2.20.m1.1.1" xref="S2.p2.20.m1.1.1.cmml"><mi id="S2.p2.20.m1.1.1.2.2" xref="S2.p2.20.m1.1.1.2.2.cmml">W</mi><mi id="S2.p2.20.m1.1.1.2.3" xref="S2.p2.20.m1.1.1.2.3.cmml">M</mi><mrow id="S2.p2.20.m1.1.1.3" xref="S2.p2.20.m1.1.1.3.cmml"><mi id="S2.p2.20.m1.1.1.3.2" xref="S2.p2.20.m1.1.1.3.2.cmml">t</mi><mo id="S2.p2.20.m1.1.1.3.1" xref="S2.p2.20.m1.1.1.3.1.cmml">+</mo><mn id="S2.p2.20.m1.1.1.3.3" xref="S2.p2.20.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.p2.20.m1.1b"><apply id="S2.p2.20.m1.1.1.cmml" xref="S2.p2.20.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.20.m1.1.1.1.cmml" xref="S2.p2.20.m1.1.1">superscript</csymbol><apply id="S2.p2.20.m1.1.1.2.cmml" xref="S2.p2.20.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.20.m1.1.1.2.1.cmml" xref="S2.p2.20.m1.1.1">subscript</csymbol><ci id="S2.p2.20.m1.1.1.2.2.cmml" xref="S2.p2.20.m1.1.1.2.2">ğ‘Š</ci><ci id="S2.p2.20.m1.1.1.2.3.cmml" xref="S2.p2.20.m1.1.1.2.3">ğ‘€</ci></apply><apply id="S2.p2.20.m1.1.1.3.cmml" xref="S2.p2.20.m1.1.1.3"><plus id="S2.p2.20.m1.1.1.3.1.cmml" xref="S2.p2.20.m1.1.1.3.1"></plus><ci id="S2.p2.20.m1.1.1.3.2.cmml" xref="S2.p2.20.m1.1.1.3.2">ğ‘¡</ci><cn type="integer" id="S2.p2.20.m1.1.1.3.3.cmml" xref="S2.p2.20.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.20.m1.1c">W_{M}^{t+1}</annotation></semantics></math> for the next round, an <span id="S2.p2.21.1" class="ltx_text ltx_font_italic">aggregation mechanism</span> is used over all the collected parameter updates <math id="S2.p2.21.m2.1" class="ltx_Math" alttext="\Delta^{t+1}=\{\delta_{i}^{t+1}\}_{i\in A^{t}}" display="inline"><semantics id="S2.p2.21.m2.1a"><mrow id="S2.p2.21.m2.1.1" xref="S2.p2.21.m2.1.1.cmml"><msup id="S2.p2.21.m2.1.1.3" xref="S2.p2.21.m2.1.1.3.cmml"><mi mathvariant="normal" id="S2.p2.21.m2.1.1.3.2" xref="S2.p2.21.m2.1.1.3.2.cmml">Î”</mi><mrow id="S2.p2.21.m2.1.1.3.3" xref="S2.p2.21.m2.1.1.3.3.cmml"><mi id="S2.p2.21.m2.1.1.3.3.2" xref="S2.p2.21.m2.1.1.3.3.2.cmml">t</mi><mo id="S2.p2.21.m2.1.1.3.3.1" xref="S2.p2.21.m2.1.1.3.3.1.cmml">+</mo><mn id="S2.p2.21.m2.1.1.3.3.3" xref="S2.p2.21.m2.1.1.3.3.3.cmml">1</mn></mrow></msup><mo id="S2.p2.21.m2.1.1.2" xref="S2.p2.21.m2.1.1.2.cmml">=</mo><msub id="S2.p2.21.m2.1.1.1" xref="S2.p2.21.m2.1.1.1.cmml"><mrow id="S2.p2.21.m2.1.1.1.1.1" xref="S2.p2.21.m2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p2.21.m2.1.1.1.1.1.2" xref="S2.p2.21.m2.1.1.1.1.2.cmml">{</mo><msubsup id="S2.p2.21.m2.1.1.1.1.1.1" xref="S2.p2.21.m2.1.1.1.1.1.1.cmml"><mi id="S2.p2.21.m2.1.1.1.1.1.1.2.2" xref="S2.p2.21.m2.1.1.1.1.1.1.2.2.cmml">Î´</mi><mi id="S2.p2.21.m2.1.1.1.1.1.1.2.3" xref="S2.p2.21.m2.1.1.1.1.1.1.2.3.cmml">i</mi><mrow id="S2.p2.21.m2.1.1.1.1.1.1.3" xref="S2.p2.21.m2.1.1.1.1.1.1.3.cmml"><mi id="S2.p2.21.m2.1.1.1.1.1.1.3.2" xref="S2.p2.21.m2.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="S2.p2.21.m2.1.1.1.1.1.1.3.1" xref="S2.p2.21.m2.1.1.1.1.1.1.3.1.cmml">+</mo><mn id="S2.p2.21.m2.1.1.1.1.1.1.3.3" xref="S2.p2.21.m2.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="S2.p2.21.m2.1.1.1.1.1.3" xref="S2.p2.21.m2.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p2.21.m2.1.1.1.3" xref="S2.p2.21.m2.1.1.1.3.cmml"><mi id="S2.p2.21.m2.1.1.1.3.2" xref="S2.p2.21.m2.1.1.1.3.2.cmml">i</mi><mo id="S2.p2.21.m2.1.1.1.3.1" xref="S2.p2.21.m2.1.1.1.3.1.cmml">âˆˆ</mo><msup id="S2.p2.21.m2.1.1.1.3.3" xref="S2.p2.21.m2.1.1.1.3.3.cmml"><mi id="S2.p2.21.m2.1.1.1.3.3.2" xref="S2.p2.21.m2.1.1.1.3.3.2.cmml">A</mi><mi id="S2.p2.21.m2.1.1.1.3.3.3" xref="S2.p2.21.m2.1.1.1.3.3.3.cmml">t</mi></msup></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.21.m2.1b"><apply id="S2.p2.21.m2.1.1.cmml" xref="S2.p2.21.m2.1.1"><eq id="S2.p2.21.m2.1.1.2.cmml" xref="S2.p2.21.m2.1.1.2"></eq><apply id="S2.p2.21.m2.1.1.3.cmml" xref="S2.p2.21.m2.1.1.3"><csymbol cd="ambiguous" id="S2.p2.21.m2.1.1.3.1.cmml" xref="S2.p2.21.m2.1.1.3">superscript</csymbol><ci id="S2.p2.21.m2.1.1.3.2.cmml" xref="S2.p2.21.m2.1.1.3.2">Î”</ci><apply id="S2.p2.21.m2.1.1.3.3.cmml" xref="S2.p2.21.m2.1.1.3.3"><plus id="S2.p2.21.m2.1.1.3.3.1.cmml" xref="S2.p2.21.m2.1.1.3.3.1"></plus><ci id="S2.p2.21.m2.1.1.3.3.2.cmml" xref="S2.p2.21.m2.1.1.3.3.2">ğ‘¡</ci><cn type="integer" id="S2.p2.21.m2.1.1.3.3.3.cmml" xref="S2.p2.21.m2.1.1.3.3.3">1</cn></apply></apply><apply id="S2.p2.21.m2.1.1.1.cmml" xref="S2.p2.21.m2.1.1.1"><csymbol cd="ambiguous" id="S2.p2.21.m2.1.1.1.2.cmml" xref="S2.p2.21.m2.1.1.1">subscript</csymbol><set id="S2.p2.21.m2.1.1.1.1.2.cmml" xref="S2.p2.21.m2.1.1.1.1.1"><apply id="S2.p2.21.m2.1.1.1.1.1.1.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.21.m2.1.1.1.1.1.1.1.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p2.21.m2.1.1.1.1.1.1.2.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.21.m2.1.1.1.1.1.1.2.1.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p2.21.m2.1.1.1.1.1.1.2.2.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1.2.2">ğ›¿</ci><ci id="S2.p2.21.m2.1.1.1.1.1.1.2.3.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S2.p2.21.m2.1.1.1.1.1.1.3.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1.3"><plus id="S2.p2.21.m2.1.1.1.1.1.1.3.1.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1.3.1"></plus><ci id="S2.p2.21.m2.1.1.1.1.1.1.3.2.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1.3.2">ğ‘¡</ci><cn type="integer" id="S2.p2.21.m2.1.1.1.1.1.1.3.3.cmml" xref="S2.p2.21.m2.1.1.1.1.1.1.3.3">1</cn></apply></apply></set><apply id="S2.p2.21.m2.1.1.1.3.cmml" xref="S2.p2.21.m2.1.1.1.3"><in id="S2.p2.21.m2.1.1.1.3.1.cmml" xref="S2.p2.21.m2.1.1.1.3.1"></in><ci id="S2.p2.21.m2.1.1.1.3.2.cmml" xref="S2.p2.21.m2.1.1.1.3.2">ğ‘–</ci><apply id="S2.p2.21.m2.1.1.1.3.3.cmml" xref="S2.p2.21.m2.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.p2.21.m2.1.1.1.3.3.1.cmml" xref="S2.p2.21.m2.1.1.1.3.3">superscript</csymbol><ci id="S2.p2.21.m2.1.1.1.3.3.2.cmml" xref="S2.p2.21.m2.1.1.1.3.3.2">ğ´</ci><ci id="S2.p2.21.m2.1.1.1.3.3.3.cmml" xref="S2.p2.21.m2.1.1.1.3.3.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.21.m2.1c">\Delta^{t+1}=\{\delta_{i}^{t+1}\}_{i\in A^{t}}</annotation></semantics></math>. A commonly used aggregation mechanism is weighted averagingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="W_{M}^{t+1}=W_{M}^{t}+\sum_{i\in A^{t}}\Gamma_{i}^{t}\delta_{i}^{t+1}," display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><msubsup id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.1.1.2.2.2" xref="S2.E2.m1.1.1.1.1.2.2.2.cmml">W</mi><mi id="S2.E2.m1.1.1.1.1.2.2.3" xref="S2.E2.m1.1.1.1.1.2.2.3.cmml">M</mi><mrow id="S2.E2.m1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.E2.m1.1.1.1.1.2.3.1" xref="S2.E2.m1.1.1.1.1.2.3.1.cmml">+</mo><mn id="S2.E2.m1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.3.cmml"><msubsup id="S2.E2.m1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.3.2.cmml"><mi id="S2.E2.m1.1.1.1.1.3.2.2.2" xref="S2.E2.m1.1.1.1.1.3.2.2.2.cmml">W</mi><mi id="S2.E2.m1.1.1.1.1.3.2.2.3" xref="S2.E2.m1.1.1.1.1.3.2.2.3.cmml">M</mi><mi id="S2.E2.m1.1.1.1.1.3.2.3" xref="S2.E2.m1.1.1.1.1.3.2.3.cmml">t</mi></msubsup><mo rspace="0.055em" id="S2.E2.m1.1.1.1.1.3.1" xref="S2.E2.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.E2.m1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.3.3.cmml"><munder id="S2.E2.m1.1.1.1.1.3.3.1" xref="S2.E2.m1.1.1.1.1.3.3.1.cmml"><mo movablelimits="false" id="S2.E2.m1.1.1.1.1.3.3.1.2" xref="S2.E2.m1.1.1.1.1.3.3.1.2.cmml">âˆ‘</mo><mrow id="S2.E2.m1.1.1.1.1.3.3.1.3" xref="S2.E2.m1.1.1.1.1.3.3.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.1.3.2" xref="S2.E2.m1.1.1.1.1.3.3.1.3.2.cmml">i</mi><mo id="S2.E2.m1.1.1.1.1.3.3.1.3.1" xref="S2.E2.m1.1.1.1.1.3.3.1.3.1.cmml">âˆˆ</mo><msup id="S2.E2.m1.1.1.1.1.3.3.1.3.3" xref="S2.E2.m1.1.1.1.1.3.3.1.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.1.3.3.2" xref="S2.E2.m1.1.1.1.1.3.3.1.3.3.2.cmml">A</mi><mi id="S2.E2.m1.1.1.1.1.3.3.1.3.3.3" xref="S2.E2.m1.1.1.1.1.3.3.1.3.3.3.cmml">t</mi></msup></mrow></munder><mrow id="S2.E2.m1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.3.3.2.cmml"><msubsup id="S2.E2.m1.1.1.1.1.3.3.2.2" xref="S2.E2.m1.1.1.1.1.3.3.2.2.cmml"><mi mathvariant="normal" id="S2.E2.m1.1.1.1.1.3.3.2.2.2.2" xref="S2.E2.m1.1.1.1.1.3.3.2.2.2.2.cmml">Î“</mi><mi id="S2.E2.m1.1.1.1.1.3.3.2.2.2.3" xref="S2.E2.m1.1.1.1.1.3.3.2.2.2.3.cmml">i</mi><mi id="S2.E2.m1.1.1.1.1.3.3.2.2.3" xref="S2.E2.m1.1.1.1.1.3.3.2.2.3.cmml">t</mi></msubsup><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.3.2.1" xref="S2.E2.m1.1.1.1.1.3.3.2.1.cmml">â€‹</mo><msubsup id="S2.E2.m1.1.1.1.1.3.3.2.3" xref="S2.E2.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.2.3.2.2" xref="S2.E2.m1.1.1.1.1.3.3.2.3.2.2.cmml">Î´</mi><mi id="S2.E2.m1.1.1.1.1.3.3.2.3.2.3" xref="S2.E2.m1.1.1.1.1.3.3.2.3.2.3.cmml">i</mi><mrow id="S2.E2.m1.1.1.1.1.3.3.2.3.3" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.2.3.3.2" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3.2.cmml">t</mi><mo id="S2.E2.m1.1.1.1.1.3.3.2.3.3.1" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3.1.cmml">+</mo><mn id="S2.E2.m1.1.1.1.1.3.3.2.3.3.3" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3.3.cmml">1</mn></mrow></msubsup></mrow></mrow></mrow></mrow><mo id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><eq id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"></eq><apply id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2.2.2">ğ‘Š</ci><ci id="S2.E2.m1.1.1.1.1.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3">ğ‘€</ci></apply><apply id="S2.E2.m1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3"><plus id="S2.E2.m1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.2.3.1"></plus><ci id="S2.E2.m1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E2.m1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3"><plus id="S2.E2.m1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.1"></plus><apply id="S2.E2.m1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2.2">ğ‘Š</ci><ci id="S2.E2.m1.1.1.1.1.3.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2.3">ğ‘€</ci></apply><ci id="S2.E2.m1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3">ğ‘¡</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3"><apply id="S2.E2.m1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.3.1.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1">subscript</csymbol><sum id="S2.E2.m1.1.1.1.1.3.3.1.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.2"></sum><apply id="S2.E2.m1.1.1.1.1.3.3.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.3"><in id="S2.E2.m1.1.1.1.1.3.3.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.3.1"></in><ci id="S2.E2.m1.1.1.1.1.3.3.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.3.2">ğ‘–</ci><apply id="S2.E2.m1.1.1.1.1.3.3.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.3.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.3.3">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.3.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.3.3.2">ğ´</ci><ci id="S2.E2.m1.1.1.1.1.3.3.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.1.3.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S2.E2.m1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2"><times id="S2.E2.m1.1.1.1.1.3.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.1"></times><apply id="S2.E2.m1.1.1.1.1.3.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.2">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.3.2.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.3.2.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.2.2.2">Î“</ci><ci id="S2.E2.m1.1.1.1.1.3.3.2.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.2.2.3">ğ‘–</ci></apply><ci id="S2.E2.m1.1.1.1.1.3.3.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.2.3">ğ‘¡</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.3.2.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.3.2.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3.2.2">ğ›¿</ci><ci id="S2.E2.m1.1.1.1.1.3.3.2.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3.2.3">ğ‘–</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3"><plus id="S2.E2.m1.1.1.1.1.3.3.2.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3.1"></plus><ci id="S2.E2.m1.1.1.1.1.3.3.2.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3.2">ğ‘¡</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.3.3.2.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">W_{M}^{t+1}=W_{M}^{t}+\sum_{i\in A^{t}}\Gamma_{i}^{t}\delta_{i}^{t+1},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.p2.25" class="ltx_p">where <math id="S2.p2.22.m1.1" class="ltx_Math" alttext="\Gamma_{i}^{t}" display="inline"><semantics id="S2.p2.22.m1.1a"><msubsup id="S2.p2.22.m1.1.1" xref="S2.p2.22.m1.1.1.cmml"><mi mathvariant="normal" id="S2.p2.22.m1.1.1.2.2" xref="S2.p2.22.m1.1.1.2.2.cmml">Î“</mi><mi id="S2.p2.22.m1.1.1.2.3" xref="S2.p2.22.m1.1.1.2.3.cmml">i</mi><mi id="S2.p2.22.m1.1.1.3" xref="S2.p2.22.m1.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p2.22.m1.1b"><apply id="S2.p2.22.m1.1.1.cmml" xref="S2.p2.22.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.22.m1.1.1.1.cmml" xref="S2.p2.22.m1.1.1">superscript</csymbol><apply id="S2.p2.22.m1.1.1.2.cmml" xref="S2.p2.22.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.22.m1.1.1.2.1.cmml" xref="S2.p2.22.m1.1.1">subscript</csymbol><ci id="S2.p2.22.m1.1.1.2.2.cmml" xref="S2.p2.22.m1.1.1.2.2">Î“</ci><ci id="S2.p2.22.m1.1.1.2.3.cmml" xref="S2.p2.22.m1.1.1.2.3">ğ‘–</ci></apply><ci id="S2.p2.22.m1.1.1.3.cmml" xref="S2.p2.22.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.22.m1.1c">\Gamma_{i}^{t}</annotation></semantics></math> is the non-negative weight assigned to agent <math id="S2.p2.23.m2.1" class="ltx_Math" alttext="i\in A^{t}" display="inline"><semantics id="S2.p2.23.m2.1a"><mrow id="S2.p2.23.m2.1.1" xref="S2.p2.23.m2.1.1.cmml"><mi id="S2.p2.23.m2.1.1.2" xref="S2.p2.23.m2.1.1.2.cmml">i</mi><mo id="S2.p2.23.m2.1.1.1" xref="S2.p2.23.m2.1.1.1.cmml">âˆˆ</mo><msup id="S2.p2.23.m2.1.1.3" xref="S2.p2.23.m2.1.1.3.cmml"><mi id="S2.p2.23.m2.1.1.3.2" xref="S2.p2.23.m2.1.1.3.2.cmml">A</mi><mi id="S2.p2.23.m2.1.1.3.3" xref="S2.p2.23.m2.1.1.3.3.cmml">t</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.23.m2.1b"><apply id="S2.p2.23.m2.1.1.cmml" xref="S2.p2.23.m2.1.1"><in id="S2.p2.23.m2.1.1.1.cmml" xref="S2.p2.23.m2.1.1.1"></in><ci id="S2.p2.23.m2.1.1.2.cmml" xref="S2.p2.23.m2.1.1.2">ğ‘–</ci><apply id="S2.p2.23.m2.1.1.3.cmml" xref="S2.p2.23.m2.1.1.3"><csymbol cd="ambiguous" id="S2.p2.23.m2.1.1.3.1.cmml" xref="S2.p2.23.m2.1.1.3">superscript</csymbol><ci id="S2.p2.23.m2.1.1.3.2.cmml" xref="S2.p2.23.m2.1.1.3.2">ğ´</ci><ci id="S2.p2.23.m2.1.1.3.3.cmml" xref="S2.p2.23.m2.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.23.m2.1c">i\in A^{t}</annotation></semantics></math> at time <math id="S2.p2.24.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.p2.24.m3.1a"><mi id="S2.p2.24.m3.1.1" xref="S2.p2.24.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.p2.24.m3.1b"><ci id="S2.p2.24.m3.1.1.cmml" xref="S2.p2.24.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.24.m3.1c">t</annotation></semantics></math> and <math id="S2.p2.25.m4.1" class="ltx_Math" alttext="\Sigma_{i\in A^{t}}\Gamma_{i}^{t}=1" display="inline"><semantics id="S2.p2.25.m4.1a"><mrow id="S2.p2.25.m4.1.1" xref="S2.p2.25.m4.1.1.cmml"><mrow id="S2.p2.25.m4.1.1.2" xref="S2.p2.25.m4.1.1.2.cmml"><msub id="S2.p2.25.m4.1.1.2.2" xref="S2.p2.25.m4.1.1.2.2.cmml"><mi mathvariant="normal" id="S2.p2.25.m4.1.1.2.2.2" xref="S2.p2.25.m4.1.1.2.2.2.cmml">Î£</mi><mrow id="S2.p2.25.m4.1.1.2.2.3" xref="S2.p2.25.m4.1.1.2.2.3.cmml"><mi id="S2.p2.25.m4.1.1.2.2.3.2" xref="S2.p2.25.m4.1.1.2.2.3.2.cmml">i</mi><mo id="S2.p2.25.m4.1.1.2.2.3.1" xref="S2.p2.25.m4.1.1.2.2.3.1.cmml">âˆˆ</mo><msup id="S2.p2.25.m4.1.1.2.2.3.3" xref="S2.p2.25.m4.1.1.2.2.3.3.cmml"><mi id="S2.p2.25.m4.1.1.2.2.3.3.2" xref="S2.p2.25.m4.1.1.2.2.3.3.2.cmml">A</mi><mi id="S2.p2.25.m4.1.1.2.2.3.3.3" xref="S2.p2.25.m4.1.1.2.2.3.3.3.cmml">t</mi></msup></mrow></msub><mo lspace="0em" rspace="0em" id="S2.p2.25.m4.1.1.2.1" xref="S2.p2.25.m4.1.1.2.1.cmml">â€‹</mo><msubsup id="S2.p2.25.m4.1.1.2.3" xref="S2.p2.25.m4.1.1.2.3.cmml"><mi mathvariant="normal" id="S2.p2.25.m4.1.1.2.3.2.2" xref="S2.p2.25.m4.1.1.2.3.2.2.cmml">Î“</mi><mi id="S2.p2.25.m4.1.1.2.3.2.3" xref="S2.p2.25.m4.1.1.2.3.2.3.cmml">i</mi><mi id="S2.p2.25.m4.1.1.2.3.3" xref="S2.p2.25.m4.1.1.2.3.3.cmml">t</mi></msubsup></mrow><mo id="S2.p2.25.m4.1.1.1" xref="S2.p2.25.m4.1.1.1.cmml">=</mo><mn id="S2.p2.25.m4.1.1.3" xref="S2.p2.25.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.25.m4.1b"><apply id="S2.p2.25.m4.1.1.cmml" xref="S2.p2.25.m4.1.1"><eq id="S2.p2.25.m4.1.1.1.cmml" xref="S2.p2.25.m4.1.1.1"></eq><apply id="S2.p2.25.m4.1.1.2.cmml" xref="S2.p2.25.m4.1.1.2"><times id="S2.p2.25.m4.1.1.2.1.cmml" xref="S2.p2.25.m4.1.1.2.1"></times><apply id="S2.p2.25.m4.1.1.2.2.cmml" xref="S2.p2.25.m4.1.1.2.2"><csymbol cd="ambiguous" id="S2.p2.25.m4.1.1.2.2.1.cmml" xref="S2.p2.25.m4.1.1.2.2">subscript</csymbol><ci id="S2.p2.25.m4.1.1.2.2.2.cmml" xref="S2.p2.25.m4.1.1.2.2.2">Î£</ci><apply id="S2.p2.25.m4.1.1.2.2.3.cmml" xref="S2.p2.25.m4.1.1.2.2.3"><in id="S2.p2.25.m4.1.1.2.2.3.1.cmml" xref="S2.p2.25.m4.1.1.2.2.3.1"></in><ci id="S2.p2.25.m4.1.1.2.2.3.2.cmml" xref="S2.p2.25.m4.1.1.2.2.3.2">ğ‘–</ci><apply id="S2.p2.25.m4.1.1.2.2.3.3.cmml" xref="S2.p2.25.m4.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S2.p2.25.m4.1.1.2.2.3.3.1.cmml" xref="S2.p2.25.m4.1.1.2.2.3.3">superscript</csymbol><ci id="S2.p2.25.m4.1.1.2.2.3.3.2.cmml" xref="S2.p2.25.m4.1.1.2.2.3.3.2">ğ´</ci><ci id="S2.p2.25.m4.1.1.2.2.3.3.3.cmml" xref="S2.p2.25.m4.1.1.2.2.3.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S2.p2.25.m4.1.1.2.3.cmml" xref="S2.p2.25.m4.1.1.2.3"><csymbol cd="ambiguous" id="S2.p2.25.m4.1.1.2.3.1.cmml" xref="S2.p2.25.m4.1.1.2.3">superscript</csymbol><apply id="S2.p2.25.m4.1.1.2.3.2.cmml" xref="S2.p2.25.m4.1.1.2.3"><csymbol cd="ambiguous" id="S2.p2.25.m4.1.1.2.3.2.1.cmml" xref="S2.p2.25.m4.1.1.2.3">subscript</csymbol><ci id="S2.p2.25.m4.1.1.2.3.2.2.cmml" xref="S2.p2.25.m4.1.1.2.3.2.2">Î“</ci><ci id="S2.p2.25.m4.1.1.2.3.2.3.cmml" xref="S2.p2.25.m4.1.1.2.3.2.3">ğ‘–</ci></apply><ci id="S2.p2.25.m4.1.1.2.3.3.cmml" xref="S2.p2.25.m4.1.1.2.3.3">ğ‘¡</ci></apply></apply><cn type="integer" id="S2.p2.25.m4.1.1.3.cmml" xref="S2.p2.25.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.25.m4.1c">\Sigma_{i\in A^{t}}\Gamma_{i}^{t}=1</annotation></semantics></math>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">In summary, the FL process consists of multiple components including but not limited to <em id="S2.p3.1.1" class="ltx_emph ltx_font_italic">(i)</em> data distribution among the agents, <em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">(i)</em> global model selection, <em id="S2.p3.1.3" class="ltx_emph ltx_font_italic">(iii)</em> agent sampling, <em id="S2.p3.1.4" class="ltx_emph ltx_font_italic">(iv)</em> local model training and <em id="S2.p3.1.5" class="ltx_emph ltx_font_italic">(v)</em> aggregation mechanism to update the global model. A practical implementation of a FL system should allow different choices for each of these components. See SectionÂ <a href="#S3" title="3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for more details.</p>
</div>
<div id="Thmremark1" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremark1.1.1.1" class="ltx_text ltx_font_bold">Remark 1</span></span><span id="Thmremark1.2.2" class="ltx_text ltx_font_bold">.</span>
</h6>
<div id="Thmremark1.p1" class="ltx_para">
<p id="Thmremark1.p1.2" class="ltx_p"><span id="Thmremark1.p1.2.2" class="ltx_text ltx_font_italic">The type of data distribution heavily impacts the convergence rate and the performance of FL systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. There are two common data distributions: (1) <em id="Thmremark1.p1.2.2.1" class="ltx_emph ltx_font_upright">Independent and Identically Distributed (IID)</em> and (2) <em id="Thmremark1.p1.2.2.2" class="ltx_emph ltx_font_upright">Non-Independent and Identically Distributed (Non-IID)</em>. Having IID data for the agents means that each batch of data used for a clientâ€™s local update is statistically identical to a uniformly drawn sample (with replacement) from the entire training dataset <math id="Thmremark1.p1.1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="Thmremark1.p1.1.1.m1.1a"><mi id="Thmremark1.p1.1.1.m1.1.1" xref="Thmremark1.p1.1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="Thmremark1.p1.1.1.m1.1b"><ci id="Thmremark1.p1.1.1.m1.1.1.cmml" xref="Thmremark1.p1.1.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmremark1.p1.1.1.m1.1c">D</annotation></semantics></math> (which is the union of all local datasets for the <math id="Thmremark1.p1.2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="Thmremark1.p1.2.2.m2.1a"><mi id="Thmremark1.p1.2.2.m2.1.1" xref="Thmremark1.p1.2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Thmremark1.p1.2.2.m2.1b"><ci id="Thmremark1.p1.2.2.m2.1.1.cmml" xref="Thmremark1.p1.2.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmremark1.p1.2.2.m2.1c">K</annotation></semantics></math> agents). In practice, it is unreasonable to assume that every agent has IID data, and hence, throughout the discussion, we heavily focus on the availability of the non-IID datasets.</span></p>
</div>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2211.00735/assets/TorchFL_Intro.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="242" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">The architectural design of TorchFL.</span></figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Architecture of TorchFL</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Cross-device FL is a multi-step learning process with a lot of implementation, hardware, communication, and systems overhead. Despite the tremendous theoretical success <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, research and work are being done to use FL for real-world applications on actual client devices. Yet, as constant research is being done to explore the non-systemic challenges in FL, <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> aims to provide an end-to-end toolkit for the researchers and developers to quickly bootstrap an FL experiment, orchestrate it on multiple devices, and execute it using the hardware accelerators. As shown in Figure <a href="#S2.F2" title="Figure 2 â€£ 2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> is built using a bottom-up approach to allow the customizability of datasets, models, and the entire FL layer. <span id="S3.p1.1.3" class="ltx_text ltx_font_italic">TorchFL</span> is primarily built using Python, PyTorch, and Lightning frameworks and is backward compatible with PyTorch Lightning loggers, profilers, and accelerators. In this section, we explain the motivation behind the design of <span id="S3.p1.1.4" class="ltx_text ltx_font_italic">TorchFL</span> and describe each of the layers in <span id="S3.p1.1.5" class="ltx_text ltx_font_italic">TorchFL</span>â€™s architecture.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets and Models Libraries</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">As shown in Equation <a href="#S2.E1" title="In 2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the local training updates computed by the selected agents are shared with the server to compute the global model parameters as shown in Equation <a href="#S2.E2" title="In 2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In this section, we dig deeper into the design, features, and abstractions offered by the <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">datasets</span> and <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">DL model</span> offerings in <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">TorchFL</span>. As these modules are the first step in setting up an FL experiment, they appear at the lowest layer in Figure <a href="#S2.F2" title="Figure 2 â€£ 2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.21.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.22.2" class="ltx_text" style="font-size:90%;">Collection of datasets currently supported by <span id="S3.T1.22.2.1" class="ltx_text ltx_font_italic">TorchFL</span> and the availability of IID and non-IID distribution for the agents</span></figcaption>
<br class="ltx_break">
<table id="S3.T1.18.18" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.18.18.19.1" class="ltx_tr">
<td id="S3.T1.18.18.19.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T1.18.18.19.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Group</span></td>
<td id="S3.T1.18.18.19.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.18.18.19.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Datasets</span></td>
<td id="S3.T1.18.18.19.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.18.18.19.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">IID</span></td>
<td id="S3.T1.18.18.19.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.18.18.19.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Non-IID</span></td>
</tr>
<tr id="S3.T1.2.2.2" class="ltx_tr">
<td id="S3.T1.2.2.2.3" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S3.T1.2.2.2.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">CIFAR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></span></td>
<td id="S3.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.2.2.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">CIFAR-10</span></td>
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.1.1.1.1.m1.1a"><mo mathsize="90%" id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.2.2.2.2.m1.1a"><mo mathsize="90%" id="S3.T1.2.2.2.2.m1.1.1" xref="S3.T1.2.2.2.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S3.T1.2.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.4.4.4" class="ltx_tr">
<td id="S3.T1.4.4.4.3" class="ltx_td ltx_align_center"><span id="S3.T1.4.4.4.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">CIFAR-100</span></td>
<td id="S3.T1.3.3.3.1" class="ltx_td ltx_align_center"><math id="S3.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.3.3.3.1.m1.1a"><mo mathsize="90%" id="S3.T1.3.3.3.1.m1.1.1" xref="S3.T1.3.3.3.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S3.T1.3.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.4.4.4.2" class="ltx_td ltx_align_center"><math id="S3.T1.4.4.4.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.4.4.4.2.m1.1a"><mo mathsize="90%" id="S3.T1.4.4.4.2.m1.1.1" xref="S3.T1.4.4.4.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.2.m1.1b"><csymbol cd="latexml" id="S3.T1.4.4.4.2.m1.1.1.cmml" xref="S3.T1.4.4.4.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.6.6.6" class="ltx_tr">
<td id="S3.T1.6.6.6.3" class="ltx_td ltx_align_left ltx_border_t" rowspan="6"><span id="S3.T1.6.6.6.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">EMNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite></span></td>
<td id="S3.T1.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.6.6.6.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">By Class</span></td>
<td id="S3.T1.5.5.5.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T1.5.5.5.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.5.5.5.1.m1.1a"><mo mathsize="90%" id="S3.T1.5.5.5.1.m1.1.1" xref="S3.T1.5.5.5.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S3.T1.5.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.5.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T1.6.6.6.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.6.6.6.2.m1.1a"><mo mathsize="90%" id="S3.T1.6.6.6.2.m1.1.1" xref="S3.T1.6.6.6.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.2.m1.1b"><csymbol cd="latexml" id="S3.T1.6.6.6.2.m1.1.1.cmml" xref="S3.T1.6.6.6.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.8.8.8" class="ltx_tr">
<td id="S3.T1.8.8.8.3" class="ltx_td ltx_align_center"><span id="S3.T1.8.8.8.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">By Merge</span></td>
<td id="S3.T1.7.7.7.1" class="ltx_td ltx_align_center"><math id="S3.T1.7.7.7.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.7.7.7.1.m1.1a"><mo mathsize="90%" id="S3.T1.7.7.7.1.m1.1.1" xref="S3.T1.7.7.7.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.m1.1b"><csymbol cd="latexml" id="S3.T1.7.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.7.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.8.8.8.2" class="ltx_td ltx_align_center"><math id="S3.T1.8.8.8.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.8.8.8.2.m1.1a"><mo mathsize="90%" id="S3.T1.8.8.8.2.m1.1.1" xref="S3.T1.8.8.8.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.2.m1.1b"><csymbol cd="latexml" id="S3.T1.8.8.8.2.m1.1.1.cmml" xref="S3.T1.8.8.8.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.10.10.10" class="ltx_tr">
<td id="S3.T1.10.10.10.3" class="ltx_td ltx_align_center"><span id="S3.T1.10.10.10.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Balanced</span></td>
<td id="S3.T1.9.9.9.1" class="ltx_td ltx_align_center"><math id="S3.T1.9.9.9.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.9.9.9.1.m1.1a"><mo mathsize="90%" id="S3.T1.9.9.9.1.m1.1.1" xref="S3.T1.9.9.9.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.1.m1.1b"><csymbol cd="latexml" id="S3.T1.9.9.9.1.m1.1.1.cmml" xref="S3.T1.9.9.9.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.10.10.10.2" class="ltx_td ltx_align_center"><math id="S3.T1.10.10.10.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.10.10.10.2.m1.1a"><mo mathsize="90%" id="S3.T1.10.10.10.2.m1.1.1" xref="S3.T1.10.10.10.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.2.m1.1b"><csymbol cd="latexml" id="S3.T1.10.10.10.2.m1.1.1.cmml" xref="S3.T1.10.10.10.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.12.12.12" class="ltx_tr">
<td id="S3.T1.12.12.12.3" class="ltx_td ltx_align_center"><span id="S3.T1.12.12.12.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Digits</span></td>
<td id="S3.T1.11.11.11.1" class="ltx_td ltx_align_center"><math id="S3.T1.11.11.11.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.11.11.11.1.m1.1a"><mo mathsize="90%" id="S3.T1.11.11.11.1.m1.1.1" xref="S3.T1.11.11.11.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.1.m1.1b"><csymbol cd="latexml" id="S3.T1.11.11.11.1.m1.1.1.cmml" xref="S3.T1.11.11.11.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.12.12.12.2" class="ltx_td ltx_align_center"><math id="S3.T1.12.12.12.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.12.12.12.2.m1.1a"><mo mathsize="90%" id="S3.T1.12.12.12.2.m1.1.1" xref="S3.T1.12.12.12.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.12.2.m1.1b"><csymbol cd="latexml" id="S3.T1.12.12.12.2.m1.1.1.cmml" xref="S3.T1.12.12.12.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.12.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.14.14.14" class="ltx_tr">
<td id="S3.T1.14.14.14.3" class="ltx_td ltx_align_center"><span id="S3.T1.14.14.14.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Letters</span></td>
<td id="S3.T1.13.13.13.1" class="ltx_td ltx_align_center"><math id="S3.T1.13.13.13.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.13.13.13.1.m1.1a"><mo mathsize="90%" id="S3.T1.13.13.13.1.m1.1.1" xref="S3.T1.13.13.13.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.13.1.m1.1b"><csymbol cd="latexml" id="S3.T1.13.13.13.1.m1.1.1.cmml" xref="S3.T1.13.13.13.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.13.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.14.14.14.2" class="ltx_td ltx_align_center"><math id="S3.T1.14.14.14.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.14.14.14.2.m1.1a"><mo mathsize="90%" id="S3.T1.14.14.14.2.m1.1.1" xref="S3.T1.14.14.14.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S3.T1.14.14.14.2.m1.1.1.cmml" xref="S3.T1.14.14.14.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.14.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.16.16.16" class="ltx_tr">
<td id="S3.T1.16.16.16.3" class="ltx_td ltx_align_center"><span id="S3.T1.16.16.16.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">EMNIST</span></td>
<td id="S3.T1.15.15.15.1" class="ltx_td ltx_align_center"><math id="S3.T1.15.15.15.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.15.15.15.1.m1.1a"><mo mathsize="90%" id="S3.T1.15.15.15.1.m1.1.1" xref="S3.T1.15.15.15.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.15.1.m1.1b"><csymbol cd="latexml" id="S3.T1.15.15.15.1.m1.1.1.cmml" xref="S3.T1.15.15.15.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.15.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.16.16.16.2" class="ltx_td ltx_align_center"><math id="S3.T1.16.16.16.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.16.16.16.2.m1.1a"><mo mathsize="90%" id="S3.T1.16.16.16.2.m1.1.1" xref="S3.T1.16.16.16.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.16.2.m1.1b"><csymbol cd="latexml" id="S3.T1.16.16.16.2.m1.1.1.cmml" xref="S3.T1.16.16.16.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.16.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.18.18.18" class="ltx_tr">
<td id="S3.T1.18.18.18.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S3.T1.18.18.18.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">FashionMNIST </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.18.18.18.3.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a><span id="S3.T1.18.18.18.3.3.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T1.18.18.18.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T1.18.18.18.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">FMNIST</span></td>
<td id="S3.T1.17.17.17.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S3.T1.17.17.17.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.17.17.17.1.m1.1a"><mo mathsize="90%" id="S3.T1.17.17.17.1.m1.1.1" xref="S3.T1.17.17.17.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.17.17.17.1.m1.1b"><csymbol cd="latexml" id="S3.T1.17.17.17.1.m1.1.1.cmml" xref="S3.T1.17.17.17.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.17.17.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T1.18.18.18.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S3.T1.18.18.18.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T1.18.18.18.2.m1.1a"><mo mathsize="90%" id="S3.T1.18.18.18.2.m1.1.1" xref="S3.T1.18.18.18.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T1.18.18.18.2.m1.1b"><csymbol cd="latexml" id="S3.T1.18.18.18.2.m1.1.1.cmml" xref="S3.T1.18.18.18.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.18.18.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Datamodules</span>: <span id="S3.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> currently supports all the datasets listed in Table <a href="#S3.T1" title="Table 1 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and provides an end-to-end pipeline for retrieval and distribution of the data. Note that <span id="S3.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">TorchFL</span> only currently supports basic computer vision datasets to serve as a proof-of-concept. We hope to add more complex vision-based (Example: ImageNet) and a broader group of datasets in the future.
All of these data-related features have been wrapped under the <span id="S3.I1.i1.p1.1.4" class="ltx_text ltx_font_italic">datamodules</span> module in the codebase and an easy-to-use abstract base class has also been provided for the developers to easily add new datasets. The design of the datamodules interface is explained using a UML diagram in Figure <a href="#S3.F3" title="Figure 3 â€£ item 1 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2211.00735/assets/TorchFL_datamodule.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="240" height="213" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">Design and implementation of the datamodules interface in <span id="S3.F3.4.2.1" class="ltx_text ltx_font_italic">TorchFL</span>.</span></figcaption>
</figure>
<div id="S3.I1.i1.p2" class="ltx_para">
<p id="S3.I1.i1.p2.1" class="ltx_p">Notably, the abstract base class is inherited and made backward compatible with PyTorch Lightning Datamodule to make full use of their infrastructure and loggers offerings. This design allows us to collect the metadata related to the data distribution alongside all the model-related information which we will see in future sections. As shown in Figure <a href="#S3.F3" title="Figure 3 â€£ item 1 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the <span id="S3.I1.i1.p2.1.1" class="ltx_text ltx_font_italic">datamodules</span> also provides methods for creating the IID and non-IID distributions for FL. In fact, all of the logic for these methods have been written such that it works out of the box for any new dataset. The non-IID dataloader also provides a parameter named <span id="S3.I1.i1.p2.1.2" class="ltx_text ltx_font_italic">niid_factor</span> which allows the developers to control the intensity of the distribution between the agents. Higher <span id="S3.I1.i1.p2.1.3" class="ltx_text ltx_font_italic">niid_factor</span> would mean a higher imbalance in the labels split between the agents. In summary, any developer willing to add a custom dataset must create a new class, inherit from the <span id="S3.I1.i1.p2.1.4" class="ltx_text ltx_font_italic">BaseDatamodule</span>, and only override the relevant methods as required.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.21.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.22.2" class="ltx_text" style="font-size:90%;">Collection of models currently supported by <span id="S3.T2.22.2.1" class="ltx_text ltx_font_italic">TorchFL</span> and the availability of feature extraction and finetuning for every group.</span></figcaption>
<br class="ltx_break">
<table id="S3.T2.18.18" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.18.18.19.1" class="ltx_tr">
<th id="S3.T2.18.18.19.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S3.T2.18.18.19.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Models</span></th>
<th id="S3.T2.18.18.19.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.18.18.19.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Variants</span></th>
<th id="S3.T2.18.18.19.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.18.18.19.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Feature Extraction</span></th>
<th id="S3.T2.18.18.19.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.18.18.19.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fine Tuning</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.2.2.2" class="ltx_tr">
<th id="S3.T2.2.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T2.2.2.2.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">AlexNet</span></th>
<td id="S3.T2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.2.2.2.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">1</span></td>
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo mathsize="90%" id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><times id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.2.2.2.2.m1.1a"><mo mathsize="90%" id="S3.T2.2.2.2.2.m1.1.1" xref="S3.T2.2.2.2.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.m1.1b"><times id="S3.T2.2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.4.4.4" class="ltx_tr">
<th id="S3.T2.4.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.4.4.4.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">DenseNet</span></th>
<td id="S3.T2.4.4.4.4" class="ltx_td ltx_align_center"><span id="S3.T2.4.4.4.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">4</span></td>
<td id="S3.T2.3.3.3.1" class="ltx_td ltx_align_center"><math id="S3.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.3.3.3.1.m1.1a"><mo mathsize="90%" id="S3.T2.3.3.3.1.m1.1.1" xref="S3.T2.3.3.3.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S3.T2.3.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T2.4.4.4.2" class="ltx_td ltx_align_center"><math id="S3.T2.4.4.4.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.4.4.4.2.m1.1a"><mo mathsize="90%" id="S3.T2.4.4.4.2.m1.1.1" xref="S3.T2.4.4.4.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.2.m1.1b"><csymbol cd="latexml" id="S3.T2.4.4.4.2.m1.1.1.cmml" xref="S3.T2.4.4.4.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.6.6.6" class="ltx_tr">
<th id="S3.T2.6.6.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.6.6.6.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">LeNet</span></th>
<td id="S3.T2.6.6.6.4" class="ltx_td ltx_align_center"><span id="S3.T2.6.6.6.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">1</span></td>
<td id="S3.T2.5.5.5.1" class="ltx_td ltx_align_center"><math id="S3.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.5.5.5.1.m1.1a"><mo mathsize="90%" id="S3.T2.5.5.5.1.m1.1.1" xref="S3.T2.5.5.5.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.1.m1.1b"><times id="S3.T2.5.5.5.1.m1.1.1.cmml" xref="S3.T2.5.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T2.6.6.6.2" class="ltx_td ltx_align_center"><math id="S3.T2.6.6.6.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.6.6.6.2.m1.1a"><mo mathsize="90%" id="S3.T2.6.6.6.2.m1.1.1" xref="S3.T2.6.6.6.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.2.m1.1b"><times id="S3.T2.6.6.6.2.m1.1.1.cmml" xref="S3.T2.6.6.6.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.6.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.8.8.8" class="ltx_tr">
<th id="S3.T2.8.8.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.8.8.8.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">MLP</span></th>
<td id="S3.T2.8.8.8.4" class="ltx_td ltx_align_center"><span id="S3.T2.8.8.8.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">1</span></td>
<td id="S3.T2.7.7.7.1" class="ltx_td ltx_align_center"><math id="S3.T2.7.7.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.7.7.7.1.m1.1a"><mo mathsize="90%" id="S3.T2.7.7.7.1.m1.1.1" xref="S3.T2.7.7.7.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.1.m1.1b"><times id="S3.T2.7.7.7.1.m1.1.1.cmml" xref="S3.T2.7.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.7.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T2.8.8.8.2" class="ltx_td ltx_align_center"><math id="S3.T2.8.8.8.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.8.8.8.2.m1.1a"><mo mathsize="90%" id="S3.T2.8.8.8.2.m1.1.1" xref="S3.T2.8.8.8.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.8.2.m1.1b"><times id="S3.T2.8.8.8.2.m1.1.1.cmml" xref="S3.T2.8.8.8.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.8.2.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.10.10.10" class="ltx_tr">
<th id="S3.T2.10.10.10.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.10.10.10.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">MobileNet</span></th>
<td id="S3.T2.10.10.10.4" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">3</span></td>
<td id="S3.T2.9.9.9.1" class="ltx_td ltx_align_center"><math id="S3.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.9.9.9.1.m1.1a"><mo mathsize="90%" id="S3.T2.9.9.9.1.m1.1.1" xref="S3.T2.9.9.9.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.9.1.m1.1b"><csymbol cd="latexml" id="S3.T2.9.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.9.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.9.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T2.10.10.10.2" class="ltx_td ltx_align_center"><math id="S3.T2.10.10.10.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.10.10.10.2.m1.1a"><mo mathsize="90%" id="S3.T2.10.10.10.2.m1.1.1" xref="S3.T2.10.10.10.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.10.2.m1.1b"><csymbol cd="latexml" id="S3.T2.10.10.10.2.m1.1.1.cmml" xref="S3.T2.10.10.10.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.10.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.12.12.12" class="ltx_tr">
<th id="S3.T2.12.12.12.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.12.12.12.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">ResNet</span></th>
<td id="S3.T2.12.12.12.4" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">9</span></td>
<td id="S3.T2.11.11.11.1" class="ltx_td ltx_align_center"><math id="S3.T2.11.11.11.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.11.11.11.1.m1.1a"><mo mathsize="90%" id="S3.T2.11.11.11.1.m1.1.1" xref="S3.T2.11.11.11.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.11.1.m1.1b"><csymbol cd="latexml" id="S3.T2.11.11.11.1.m1.1.1.cmml" xref="S3.T2.11.11.11.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.11.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T2.12.12.12.2" class="ltx_td ltx_align_center"><math id="S3.T2.12.12.12.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.12.12.12.2.m1.1a"><mo mathsize="90%" id="S3.T2.12.12.12.2.m1.1.1" xref="S3.T2.12.12.12.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.12.12.12.2.m1.1b"><csymbol cd="latexml" id="S3.T2.12.12.12.2.m1.1.1.cmml" xref="S3.T2.12.12.12.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.12.12.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.14.14.14" class="ltx_tr">
<th id="S3.T2.14.14.14.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.14.14.14.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">ShuffleNet</span></th>
<td id="S3.T2.14.14.14.4" class="ltx_td ltx_align_center"><span id="S3.T2.14.14.14.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">4</span></td>
<td id="S3.T2.13.13.13.1" class="ltx_td ltx_align_center"><math id="S3.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.13.13.13.1.m1.1a"><mo mathsize="90%" id="S3.T2.13.13.13.1.m1.1.1" xref="S3.T2.13.13.13.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.13.13.13.1.m1.1b"><csymbol cd="latexml" id="S3.T2.13.13.13.1.m1.1.1.cmml" xref="S3.T2.13.13.13.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.13.13.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T2.14.14.14.2" class="ltx_td ltx_align_center"><math id="S3.T2.14.14.14.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.14.14.14.2.m1.1a"><mo mathsize="90%" id="S3.T2.14.14.14.2.m1.1.1" xref="S3.T2.14.14.14.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S3.T2.14.14.14.2.m1.1.1.cmml" xref="S3.T2.14.14.14.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.14.14.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.16.16.16" class="ltx_tr">
<th id="S3.T2.16.16.16.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.16.16.16.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">SqueezeNet</span></th>
<td id="S3.T2.16.16.16.4" class="ltx_td ltx_align_center"><span id="S3.T2.16.16.16.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">2</span></td>
<td id="S3.T2.15.15.15.1" class="ltx_td ltx_align_center"><math id="S3.T2.15.15.15.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.15.15.15.1.m1.1a"><mo mathsize="90%" id="S3.T2.15.15.15.1.m1.1.1" xref="S3.T2.15.15.15.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.15.15.15.1.m1.1b"><csymbol cd="latexml" id="S3.T2.15.15.15.1.m1.1.1.cmml" xref="S3.T2.15.15.15.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.15.15.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T2.16.16.16.2" class="ltx_td ltx_align_center"><math id="S3.T2.16.16.16.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.16.16.16.2.m1.1a"><mo mathsize="90%" id="S3.T2.16.16.16.2.m1.1.1" xref="S3.T2.16.16.16.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.16.16.16.2.m1.1b"><csymbol cd="latexml" id="S3.T2.16.16.16.2.m1.1.1.cmml" xref="S3.T2.16.16.16.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.16.16.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.18.18.18" class="ltx_tr">
<th id="S3.T2.18.18.18.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S3.T2.18.18.18.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">VGG</span></th>
<td id="S3.T2.18.18.18.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.18.18.18.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">8</span></td>
<td id="S3.T2.17.17.17.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S3.T2.17.17.17.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.17.17.17.1.m1.1a"><mo mathsize="90%" id="S3.T2.17.17.17.1.m1.1.1" xref="S3.T2.17.17.17.1.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.17.17.17.1.m1.1b"><csymbol cd="latexml" id="S3.T2.17.17.17.1.m1.1.1.cmml" xref="S3.T2.17.17.17.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.17.17.17.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S3.T2.18.18.18.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S3.T2.18.18.18.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S3.T2.18.18.18.2.m1.1a"><mo mathsize="90%" id="S3.T2.18.18.18.2.m1.1.1" xref="S3.T2.18.18.18.2.m1.1.1.cmml">âˆš</mo><annotation-xml encoding="MathML-Content" id="S3.T2.18.18.18.2.m1.1b"><csymbol cd="latexml" id="S3.T2.18.18.18.2.m1.1.1.cmml" xref="S3.T2.18.18.18.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.18.18.18.2.m1.1c">\surd</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.8" class="ltx_p"><span id="S3.I1.i2.p1.8.1" class="ltx_text ltx_font_bold">DL Models</span>: Once the global dataset <math id="S3.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.I1.i2.p1.1.m1.1a"><mi id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><ci id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">D</annotation></semantics></math> has been set up and distributed among the set of <math id="S3.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">K</annotation></semantics></math> agents <math id="S3.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.I1.i2.p1.3.m3.1a"><mi id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b"><ci id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">A</annotation></semantics></math>, the next step in the FL process is to initialize a global model <math id="S3.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.I1.i2.p1.4.m4.1a"><mi id="S3.I1.i2.p1.4.m4.1.1" xref="S3.I1.i2.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.4.m4.1b"><ci id="S3.I1.i2.p1.4.m4.1.1.cmml" xref="S3.I1.i2.p1.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.4.m4.1c">M</annotation></semantics></math> which is maintained by a service provider, and assign individual models <math id="S3.I1.i2.p1.5.m5.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S3.I1.i2.p1.5.m5.1a"><msub id="S3.I1.i2.p1.5.m5.1.1" xref="S3.I1.i2.p1.5.m5.1.1.cmml"><mi id="S3.I1.i2.p1.5.m5.1.1.2" xref="S3.I1.i2.p1.5.m5.1.1.2.cmml">M</mi><mi id="S3.I1.i2.p1.5.m5.1.1.3" xref="S3.I1.i2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.5.m5.1b"><apply id="S3.I1.i2.p1.5.m5.1.1.cmml" xref="S3.I1.i2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.5.m5.1.1.1.cmml" xref="S3.I1.i2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.I1.i2.p1.5.m5.1.1.2.cmml" xref="S3.I1.i2.p1.5.m5.1.1.2">ğ‘€</ci><ci id="S3.I1.i2.p1.5.m5.1.1.3.cmml" xref="S3.I1.i2.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.5.m5.1c">M_{i}</annotation></semantics></math> to every agent <math id="S3.I1.i2.p1.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.I1.i2.p1.6.m6.1a"><mi id="S3.I1.i2.p1.6.m6.1.1" xref="S3.I1.i2.p1.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.6.m6.1b"><ci id="S3.I1.i2.p1.6.m6.1.1.cmml" xref="S3.I1.i2.p1.6.m6.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.6.m6.1c">i</annotation></semantics></math>. To serve both of these purposes, <math id="S3.I1.i2.p1.7.m7.1" class="ltx_Math" alttext="TorchFL" display="inline"><semantics id="S3.I1.i2.p1.7.m7.1a"><mrow id="S3.I1.i2.p1.7.m7.1.1" xref="S3.I1.i2.p1.7.m7.1.1.cmml"><mi id="S3.I1.i2.p1.7.m7.1.1.2" xref="S3.I1.i2.p1.7.m7.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.7.m7.1.1.1" xref="S3.I1.i2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.7.m7.1.1.3" xref="S3.I1.i2.p1.7.m7.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.7.m7.1.1.1a" xref="S3.I1.i2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.7.m7.1.1.4" xref="S3.I1.i2.p1.7.m7.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.7.m7.1.1.1b" xref="S3.I1.i2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.7.m7.1.1.5" xref="S3.I1.i2.p1.7.m7.1.1.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.7.m7.1.1.1c" xref="S3.I1.i2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.7.m7.1.1.6" xref="S3.I1.i2.p1.7.m7.1.1.6.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.7.m7.1.1.1d" xref="S3.I1.i2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.7.m7.1.1.7" xref="S3.I1.i2.p1.7.m7.1.1.7.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.7.m7.1.1.1e" xref="S3.I1.i2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.7.m7.1.1.8" xref="S3.I1.i2.p1.7.m7.1.1.8.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.7.m7.1b"><apply id="S3.I1.i2.p1.7.m7.1.1.cmml" xref="S3.I1.i2.p1.7.m7.1.1"><times id="S3.I1.i2.p1.7.m7.1.1.1.cmml" xref="S3.I1.i2.p1.7.m7.1.1.1"></times><ci id="S3.I1.i2.p1.7.m7.1.1.2.cmml" xref="S3.I1.i2.p1.7.m7.1.1.2">ğ‘‡</ci><ci id="S3.I1.i2.p1.7.m7.1.1.3.cmml" xref="S3.I1.i2.p1.7.m7.1.1.3">ğ‘œ</ci><ci id="S3.I1.i2.p1.7.m7.1.1.4.cmml" xref="S3.I1.i2.p1.7.m7.1.1.4">ğ‘Ÿ</ci><ci id="S3.I1.i2.p1.7.m7.1.1.5.cmml" xref="S3.I1.i2.p1.7.m7.1.1.5">ğ‘</ci><ci id="S3.I1.i2.p1.7.m7.1.1.6.cmml" xref="S3.I1.i2.p1.7.m7.1.1.6">â„</ci><ci id="S3.I1.i2.p1.7.m7.1.1.7.cmml" xref="S3.I1.i2.p1.7.m7.1.1.7">ğ¹</ci><ci id="S3.I1.i2.p1.7.m7.1.1.8.cmml" xref="S3.I1.i2.p1.7.m7.1.1.8">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.7.m7.1c">TorchFL</annotation></semantics></math> contains a <span id="S3.I1.i2.p1.8.2" class="ltx_text ltx_font_italic">models</span> module which contains an extensive library of state-of-the-art DL models as shown in Table <a href="#S3.T2" title="Table 2 â€£ item 1 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Every major model has various architectures, a popular example being ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> with variants like ResNet18, ResNet34, etc. Although <math id="S3.I1.i2.p1.8.m8.1" class="ltx_Math" alttext="TorchFL" display="inline"><semantics id="S3.I1.i2.p1.8.m8.1a"><mrow id="S3.I1.i2.p1.8.m8.1.1" xref="S3.I1.i2.p1.8.m8.1.1.cmml"><mi id="S3.I1.i2.p1.8.m8.1.1.2" xref="S3.I1.i2.p1.8.m8.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.8.m8.1.1.1" xref="S3.I1.i2.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.8.m8.1.1.3" xref="S3.I1.i2.p1.8.m8.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.8.m8.1.1.1a" xref="S3.I1.i2.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.8.m8.1.1.4" xref="S3.I1.i2.p1.8.m8.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.8.m8.1.1.1b" xref="S3.I1.i2.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.8.m8.1.1.5" xref="S3.I1.i2.p1.8.m8.1.1.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.8.m8.1.1.1c" xref="S3.I1.i2.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.8.m8.1.1.6" xref="S3.I1.i2.p1.8.m8.1.1.6.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.8.m8.1.1.1d" xref="S3.I1.i2.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.8.m8.1.1.7" xref="S3.I1.i2.p1.8.m8.1.1.7.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.8.m8.1.1.1e" xref="S3.I1.i2.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.I1.i2.p1.8.m8.1.1.8" xref="S3.I1.i2.p1.8.m8.1.1.8.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.8.m8.1b"><apply id="S3.I1.i2.p1.8.m8.1.1.cmml" xref="S3.I1.i2.p1.8.m8.1.1"><times id="S3.I1.i2.p1.8.m8.1.1.1.cmml" xref="S3.I1.i2.p1.8.m8.1.1.1"></times><ci id="S3.I1.i2.p1.8.m8.1.1.2.cmml" xref="S3.I1.i2.p1.8.m8.1.1.2">ğ‘‡</ci><ci id="S3.I1.i2.p1.8.m8.1.1.3.cmml" xref="S3.I1.i2.p1.8.m8.1.1.3">ğ‘œ</ci><ci id="S3.I1.i2.p1.8.m8.1.1.4.cmml" xref="S3.I1.i2.p1.8.m8.1.1.4">ğ‘Ÿ</ci><ci id="S3.I1.i2.p1.8.m8.1.1.5.cmml" xref="S3.I1.i2.p1.8.m8.1.1.5">ğ‘</ci><ci id="S3.I1.i2.p1.8.m8.1.1.6.cmml" xref="S3.I1.i2.p1.8.m8.1.1.6">â„</ci><ci id="S3.I1.i2.p1.8.m8.1.1.7.cmml" xref="S3.I1.i2.p1.8.m8.1.1.7">ğ¹</ci><ci id="S3.I1.i2.p1.8.m8.1.1.8.cmml" xref="S3.I1.i2.p1.8.m8.1.1.8">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.8.m8.1c">TorchFL</annotation></semantics></math> currently only supports the computer vision models, Figure <a href="#S3.F4" title="Figure 4 â€£ item 2 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> explains how the module has been designed with multiple layers of abstraction to prioritize extensibility and ease of adding new models in the future. When trying to add a new model, the developer needs to take the following steps: (i) define the core PyTorch logic at the bottommost layer, (ii) use the templating-based code generator to generate the boilerplate code to ensure compatibility with the datasets, (iii) use the entry points to pass the model and optimizer hyperparameters to generate a trainable model object, and (iv) use the generated models and existing datamodules to initialize a Lightning, compatible trainer.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2211.00735/assets/TorchFL_models.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="224" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.4.2" class="ltx_text" style="font-size:90%;">Design and implementation of the modelâ€™s library in <span id="S3.F4.4.2.1" class="ltx_text ltx_font_italic">TorchFL</span>. The bottom-up approach allows us to implement the core logic and code-generating the boilerplate code for variants. The goal is to have the users utilize the abstraction provided by the trainers at the top.</span></figcaption>
</figure>
<div id="S3.I1.i2.p2" class="ltx_para">
<p id="S3.I1.i2.p2.1" class="ltx_p">In addition to the ease of selecting and using state-of-the-art models, <span id="S3.I1.i2.p2.1.1" class="ltx_text ltx_font_italic">TorchFL</span> also supports federated transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Given the millions of trainable parameters, and the amount of time and hardware resources required to achieve convergence, it is unreasonable to expect mobile devices to be able to train these models from scratch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. As such, transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> within FL systems is heavily being studied. The primary idea of transfer learning is to reuse the DL model trained on an existing task for a similar new task. It is analogous to expecting a human proficient at riding bikes to be able to apply or reuse balance and navigation skills while learning to ride motorbikes. <span id="S3.I1.i2.p2.1.2" class="ltx_text ltx_font_italic">TorchFL</span> supports the following transfer learning paradigms:</p>
<ol id="S3.I1.i2.I1" class="ltx_enumerate">
<li id="S3.I1.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="S3.I1.i2.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i2.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Finetuning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>: This approach requires the agents to start with the model parameters pre-trained on an existing task, and retrain them for the new task. Despite the complete retraining, we expect the overall training time to be lower as the initial parameters are not randomly initialized.</p>
</div>
</li>
<li id="S3.I1.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="S3.I1.i2.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Feature Extraction</span>: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>: This approach requires the agents to start with the pre-trained model parameters and only retrain the final classification layers instead of the entire model. This technique results in a substantial decrease in the number of trainable parameters and hence accounts for lower training time.</p>
</div>
</li>
</ol>
</div>
<div id="S3.I1.i2.p3" class="ltx_para">
<p id="S3.I1.i2.p3.1" class="ltx_p">Table <a href="#S3.T2" title="Table 2 â€£ item 1 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> contains an archive of all the models available in <span id="S3.I1.i2.p3.1.1" class="ltx_text ltx_font_italic">TorchFL</span> that support finetuning and feature extraction. Relevant hyperparameters have been provided in the model entry points to allow the developers to retrieve a finetuned or feature-extracted model on the ImageNet dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. In SectionÂ <a href="#S4" title="4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we demonstrate how transfer learning in FL can help drastically reduce the trainable parameters and training time while achieving optimal performance.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Federated Module</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In this section, we discuss how FL modules are designed to work with the datasets and models while being backward compatible with various PyTorch Lightning utilities.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<ol id="S3.I2" class="ltx_enumerate">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><span id="S3.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Agents</span>: The primary entity of any FL system is an agent, which is synonymous with a client, mobile, or edge device in the real world. In most of the simulated FL experiments, agents are usually treated as a collection of uniquely identifiable integers which are subject to random sampling and selection for every training round. However, as extensive research is currently being done in areas like reputation-based sampling protocols <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, robust defense mechanisms against model poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, and game-theoretic incentive systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, we saw value decoupling the <span id="S3.I2.i1.p1.1.2" class="ltx_text ltx_font_italic">agent</span> as a separate entity in <span id="S3.I2.i1.p1.1.3" class="ltx_text ltx_font_italic">TorchFL</span>. Currently, a <span id="S3.I2.i1.p1.1.4" class="ltx_text ltx_font_italic">TorchFL</span> <span id="S3.I2.i1.p1.1.5" class="ltx_text ltx_font_italic">agent</span> is identified by a unique identifier, and a shard of the federated dataset when initialized. However, it is designed to be extendable to store more metadata as required. For example, if an incentive mechanism computes the reputation of an agent and uses it to incentivize them for every training round, this can be supported by the <span id="S3.I2.i1.p1.1.6" class="ltx_text ltx_font_italic">agent</span> object by adding the relevant fields with relevant datatypes. Lastly, the <span id="S3.I2.i1.p1.1.7" class="ltx_text ltx_font_italic">agent</span> object is wrapped under a PyTorch Lightning wrapper which allows us to log and collect all the agent-related metadata, individual agent training performance, and statistics, as and when required.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p"><span id="S3.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Sampler</span>: Once the agents are initialized and assigned their shards of the federated data, the <span id="S3.I2.i2.p1.1.2" class="ltx_text ltx_font_italic">sampler</span> module is responsible to take the collection of <span id="S3.I2.i2.p1.1.3" class="ltx_text ltx_font_italic">agent</span> as an input, and outputting the ones that are selected for training. <span id="S3.I2.i2.p1.1.4" class="ltx_text ltx_font_italic">TorchFL</span> currently supports <span id="S3.I2.i2.p1.1.5" class="ltx_text ltx_font_italic">random sampling</span> as the baseline algorithm, however, extensive work is being done in exploring the sampling approaches to optimize the learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. In order to add a custom sampling mechanism, the developers need to adhere to the base <span id="S3.I2.i2.p1.1.6" class="ltx_text ltx_font_italic">sampler</span> interface and populate the relevant methods with their custom code. Once a new sampler is defined, it can easily be used in any FL experiments via config files to the entry points.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.4" class="ltx_p"><span id="S3.I2.i3.p1.4.1" class="ltx_text ltx_font_bold">Aggregator</span>: As explained in Equation <a href="#S2.E2" title="In 2 Background on FL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, weight or gradient <span id="S3.I2.i3.p1.4.2" class="ltx_text ltx_font_italic">aggregation</span> is a core component in the FL pipeline which is responsible for training the global model <math id="S3.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.I2.i3.p1.1.m1.1a"><mi id="S3.I2.i3.p1.1.m1.1.1" xref="S3.I2.i3.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.1.m1.1b"><ci id="S3.I2.i3.p1.1.m1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.1.m1.1c">M</annotation></semantics></math>. Again, <span id="S3.I2.i3.p1.4.3" class="ltx_text ltx_font_italic">aggregator</span> has been defined as a separate module in <span id="S3.I2.i3.p1.4.4" class="ltx_text ltx_font_italic">TorchFL</span> which takes individual agent models <math id="S3.I2.i3.p1.2.m2.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S3.I2.i3.p1.2.m2.1a"><msub id="S3.I2.i3.p1.2.m2.1.1" xref="S3.I2.i3.p1.2.m2.1.1.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.2.cmml">M</mi><mi id="S3.I2.i3.p1.2.m2.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.2.m2.1b"><apply id="S3.I2.i3.p1.2.m2.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.2">ğ‘€</ci><ci id="S3.I2.i3.p1.2.m2.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.2.m2.1c">M_{i}</annotation></semantics></math> as input and updates the parameters <math id="S3.I2.i3.p1.3.m3.1" class="ltx_Math" alttext="W_{M}" display="inline"><semantics id="S3.I2.i3.p1.3.m3.1a"><msub id="S3.I2.i3.p1.3.m3.1.1" xref="S3.I2.i3.p1.3.m3.1.1.cmml"><mi id="S3.I2.i3.p1.3.m3.1.1.2" xref="S3.I2.i3.p1.3.m3.1.1.2.cmml">W</mi><mi id="S3.I2.i3.p1.3.m3.1.1.3" xref="S3.I2.i3.p1.3.m3.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.3.m3.1b"><apply id="S3.I2.i3.p1.3.m3.1.1.cmml" xref="S3.I2.i3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I2.i3.p1.3.m3.1.1.1.cmml" xref="S3.I2.i3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I2.i3.p1.3.m3.1.1.2.cmml" xref="S3.I2.i3.p1.3.m3.1.1.2">ğ‘Š</ci><ci id="S3.I2.i3.p1.3.m3.1.1.3.cmml" xref="S3.I2.i3.p1.3.m3.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.3.m3.1c">W_{M}</annotation></semantics></math> of the global model <math id="S3.I2.i3.p1.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.I2.i3.p1.4.m4.1a"><mi id="S3.I2.i3.p1.4.m4.1.1" xref="S3.I2.i3.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.4.m4.1b"><ci id="S3.I2.i3.p1.4.m4.1.1.cmml" xref="S3.I2.i3.p1.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.4.m4.1c">M</annotation></semantics></math>. Currently, <span id="S3.I2.i3.p1.4.5" class="ltx_text ltx_font_italic">TorchFL</span> supports the classic aggregation protocols like <span id="S3.I2.i3.p1.4.6" class="ltx_text ltx_font_italic">FedAvg</span> and <span id="S3.I2.i3.p1.4.7" class="ltx_text ltx_font_italic">FedSGD</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, but an interface has been provided for the developers to implement their own custom aggregators.</p>
</div>
</li>
<li id="S3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I2.i4.p1" class="ltx_para">
<p id="S3.I2.i4.p1.1" class="ltx_p"><span id="S3.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">Entrypoint</span>: Once we have the <span id="S3.I2.i4.p1.1.2" class="ltx_text ltx_font_italic">models</span>, <span id="S3.I2.i4.p1.1.3" class="ltx_text ltx_font_italic">dataset</span>, <span id="S3.I2.i4.p1.1.4" class="ltx_text ltx_font_italic">agent</span>, the <span id="S3.I2.i4.p1.1.5" class="ltx_text ltx_font_italic">sampler</span>, and an <span id="S3.I2.i4.p1.1.6" class="ltx_text ltx_font_italic">aggregator</span>, the last step is to wrap them all to produce a complete FL experiment which can execute on various hardware accelerators, and log the metadata and performance as required. <span id="S3.I2.i4.p1.1.7" class="ltx_text ltx_font_italic">TorchFL</span> provides an <span id="S3.I2.i4.p1.1.8" class="ltx_text ltx_font_italic">entrypoint</span> module which handles all of these parts and the users are only required to supply their hyperparameters via a config file when initializing the <span id="S3.I2.i4.p1.1.9" class="ltx_text ltx_font_italic">entrpoint</span> object. Some good examples of the FL hyperparameters are (i) the number of agents, (ii) the number of global training epochs, (iii) local training epochs, (iv) performance benchmark, (iv) IID or non-IID dataset split, (v) type of sampling mechanism, (vi) type of aggregation protocol, (vii) type of hardware accelerator (TPU, GPU, CPU, or more), (viii) type of logger (CSV, TensorBoard, etc.) and more. As the <span id="S3.I2.i4.p1.1.10" class="ltx_text ltx_font_italic">entrypoint</span> module in <span id="S3.I2.i4.p1.1.11" class="ltx_text ltx_font_italic">TorchFL</span> automatically abstracts all of these hyperparameters, the developers can only focus on running the required set of experiments.
See FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.2 Federated Module â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> for more details.</p>
</div>
</li>
</ol>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2211.00735/assets/TorchFL_federated.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.7.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.8.2" class="ltx_text" style="font-size:90%;">Design and relationships between FL modules in <span id="S3.F5.8.2.1" class="ltx_text ltx_font_italic">TorchFL</span>. As demonstrated in the flowchart, the <span id="S3.F5.8.2.2" class="ltx_text ltx_font_italic">agents</span>, <span id="S3.F5.8.2.3" class="ltx_text ltx_font_italic">samplers</span>, and the <span id="S3.F5.8.2.4" class="ltx_text ltx_font_italic">aggregator</span> are all wrapped by an <span id="S3.F5.8.2.5" class="ltx_text ltx_font_italic">entrypoint</span> object, which is eventually used by the end-user.</span></figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Backward Compatibility with PyTorch Lightning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">While discussing the design and architecture of various modules in the previous subsections, we have repeatedly emphasized making modules backward compatible with PyTorch Lightning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. For context, Lightning is a DL framework and wrapper which is built on PyTorch to provide infrastructure support and features without sacrificing the training performance at scale. By making the <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> modules backward compatible with Lightning, we are able to leverage the following features.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<ol id="S3.I3" class="ltx_enumerate">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p"><span id="S3.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Logging</span>: It is extremely important to be able to log metadata, metrics, or even configurations while running the experiments. Especially in an FL setting with multiple agents, logging overhead might account for a significant portion of the overall training time, if the loggers are written from scratch in an inefficient manner. As a result, <span id="S3.I3.i1.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> modules have been written to be backward compatible with Lightning loggers which include but are not limited to CSV, MLFLow, TensorBoard, WeightsAndBiases, and more. Developers can readily configure these loggers without performance or implementation overhead and choose to log anything they need from the experiments.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p"><span id="S3.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Profiling</span>: Monitoring the performance or time spent on executing individual components while running massive experiments can be useful. <span id="S3.I3.i2.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span>â€™s PyTorch Lightning compatibility allows the developers to easily set up the <span id="S3.I3.i2.p1.1.3" class="ltx_text ltx_font_italic">PyTorchProfiler</span>, <span id="S3.I3.i2.p1.1.4" class="ltx_text ltx_font_italic">XLAProfiler</span> or even build their own profiler as and when required.</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p"><span id="S3.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Hardware Acceleration</span>: As long as the developers have access to the hardware, this feature allows them to use anything ranging from <span id="S3.I3.i3.p1.1.2" class="ltx_text ltx_font_italic">CPU</span>, <span id="S3.I3.i3.p1.1.3" class="ltx_text ltx_font_italic">GPU</span>, <span id="S3.I3.i3.p1.1.4" class="ltx_text ltx_font_italic">HPU</span>, <span id="S3.I3.i3.p1.1.5" class="ltx_text ltx_font_italic">IPU</span>, or even <span id="S3.I3.i3.p1.1.6" class="ltx_text ltx_font_italic">TPU</span>. Users can easily choose an accelerator while triggering their experiments or can even switch between accelerators without having to worry about the boilerplate infrastructure setup.</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p id="S3.I3.i4.p1.1" class="ltx_p"><span id="S3.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">Distributed Training</span>: In a scenario where the developers have access to multiple hardware accelerators, they can leverage the Lightning distributed training <span id="S3.I3.i4.p1.1.2" class="ltx_text ltx_font_italic">strategies</span> to parallelize the training process and reduce the overall training time. Notably, FL aggregation falls under an <span id="S3.I3.i4.p1.1.3" class="ltx_text ltx_font_italic">embarrassingly parallel</span> algorithm category, and hence distributed training strategies can provide a huge value if chosen meaningfully.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present experimental results using <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> to demonstrate its features. All experiments are performed on the following devices: (i) a virtual machine running on a node with 60GB of RAM, 30 CPU cores, virtualized with the hypervisor running on AMD Epyc cores, and no hardware accelerator, (ii) a virtual machine running on a node with 32GB of RAM, 8 CPU cores, virtualized with the hypervisor running on AMD Epyc cores, and NVIDIA Tesla T4 GPU. For the rest of the section, we will refer to these devices as CPU and GPU, respectively.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Usage &amp; Demo</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Before we dig deeper into the advanced features, we start by demonstrating the basic techniques to use the toolkit and quickly bootstrap the datasets, models, and FL experiments.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/data_distribution/merged_data_distribution_5.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="345" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.8.4.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.6.3" class="ltx_text" style="font-size:90%;">Distribution of labels held by each agent when CIFAR-10 training data (50000) images are split among 5 agents in the following manner: (i) IID, (ii) Non-IID (<math id="S4.F6.4.1.m1.1" class="ltx_Math" alttext="niid=1" display="inline"><semantics id="S4.F6.4.1.m1.1b"><mrow id="S4.F6.4.1.m1.1.1" xref="S4.F6.4.1.m1.1.1.cmml"><mrow id="S4.F6.4.1.m1.1.1.2" xref="S4.F6.4.1.m1.1.1.2.cmml"><mi id="S4.F6.4.1.m1.1.1.2.2" xref="S4.F6.4.1.m1.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.F6.4.1.m1.1.1.2.1" xref="S4.F6.4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.4.1.m1.1.1.2.3" xref="S4.F6.4.1.m1.1.1.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F6.4.1.m1.1.1.2.1b" xref="S4.F6.4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.4.1.m1.1.1.2.4" xref="S4.F6.4.1.m1.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F6.4.1.m1.1.1.2.1c" xref="S4.F6.4.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.4.1.m1.1.1.2.5" xref="S4.F6.4.1.m1.1.1.2.5.cmml">d</mi></mrow><mo id="S4.F6.4.1.m1.1.1.1" xref="S4.F6.4.1.m1.1.1.1.cmml">=</mo><mn id="S4.F6.4.1.m1.1.1.3" xref="S4.F6.4.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.4.1.m1.1c"><apply id="S4.F6.4.1.m1.1.1.cmml" xref="S4.F6.4.1.m1.1.1"><eq id="S4.F6.4.1.m1.1.1.1.cmml" xref="S4.F6.4.1.m1.1.1.1"></eq><apply id="S4.F6.4.1.m1.1.1.2.cmml" xref="S4.F6.4.1.m1.1.1.2"><times id="S4.F6.4.1.m1.1.1.2.1.cmml" xref="S4.F6.4.1.m1.1.1.2.1"></times><ci id="S4.F6.4.1.m1.1.1.2.2.cmml" xref="S4.F6.4.1.m1.1.1.2.2">ğ‘›</ci><ci id="S4.F6.4.1.m1.1.1.2.3.cmml" xref="S4.F6.4.1.m1.1.1.2.3">ğ‘–</ci><ci id="S4.F6.4.1.m1.1.1.2.4.cmml" xref="S4.F6.4.1.m1.1.1.2.4">ğ‘–</ci><ci id="S4.F6.4.1.m1.1.1.2.5.cmml" xref="S4.F6.4.1.m1.1.1.2.5">ğ‘‘</ci></apply><cn type="integer" id="S4.F6.4.1.m1.1.1.3.cmml" xref="S4.F6.4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.4.1.m1.1d">niid=1</annotation></semantics></math>), (iii) Non-IID (<math id="S4.F6.5.2.m2.1" class="ltx_Math" alttext="niid=3" display="inline"><semantics id="S4.F6.5.2.m2.1b"><mrow id="S4.F6.5.2.m2.1.1" xref="S4.F6.5.2.m2.1.1.cmml"><mrow id="S4.F6.5.2.m2.1.1.2" xref="S4.F6.5.2.m2.1.1.2.cmml"><mi id="S4.F6.5.2.m2.1.1.2.2" xref="S4.F6.5.2.m2.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.F6.5.2.m2.1.1.2.1" xref="S4.F6.5.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.5.2.m2.1.1.2.3" xref="S4.F6.5.2.m2.1.1.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F6.5.2.m2.1.1.2.1b" xref="S4.F6.5.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.5.2.m2.1.1.2.4" xref="S4.F6.5.2.m2.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F6.5.2.m2.1.1.2.1c" xref="S4.F6.5.2.m2.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.5.2.m2.1.1.2.5" xref="S4.F6.5.2.m2.1.1.2.5.cmml">d</mi></mrow><mo id="S4.F6.5.2.m2.1.1.1" xref="S4.F6.5.2.m2.1.1.1.cmml">=</mo><mn id="S4.F6.5.2.m2.1.1.3" xref="S4.F6.5.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.5.2.m2.1c"><apply id="S4.F6.5.2.m2.1.1.cmml" xref="S4.F6.5.2.m2.1.1"><eq id="S4.F6.5.2.m2.1.1.1.cmml" xref="S4.F6.5.2.m2.1.1.1"></eq><apply id="S4.F6.5.2.m2.1.1.2.cmml" xref="S4.F6.5.2.m2.1.1.2"><times id="S4.F6.5.2.m2.1.1.2.1.cmml" xref="S4.F6.5.2.m2.1.1.2.1"></times><ci id="S4.F6.5.2.m2.1.1.2.2.cmml" xref="S4.F6.5.2.m2.1.1.2.2">ğ‘›</ci><ci id="S4.F6.5.2.m2.1.1.2.3.cmml" xref="S4.F6.5.2.m2.1.1.2.3">ğ‘–</ci><ci id="S4.F6.5.2.m2.1.1.2.4.cmml" xref="S4.F6.5.2.m2.1.1.2.4">ğ‘–</ci><ci id="S4.F6.5.2.m2.1.1.2.5.cmml" xref="S4.F6.5.2.m2.1.1.2.5">ğ‘‘</ci></apply><cn type="integer" id="S4.F6.5.2.m2.1.1.3.cmml" xref="S4.F6.5.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.5.2.m2.1d">niid=3</annotation></semantics></math>), and (iv) Non-IID (<math id="S4.F6.6.3.m3.1" class="ltx_Math" alttext="niid=5" display="inline"><semantics id="S4.F6.6.3.m3.1b"><mrow id="S4.F6.6.3.m3.1.1" xref="S4.F6.6.3.m3.1.1.cmml"><mrow id="S4.F6.6.3.m3.1.1.2" xref="S4.F6.6.3.m3.1.1.2.cmml"><mi id="S4.F6.6.3.m3.1.1.2.2" xref="S4.F6.6.3.m3.1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.F6.6.3.m3.1.1.2.1" xref="S4.F6.6.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.6.3.m3.1.1.2.3" xref="S4.F6.6.3.m3.1.1.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F6.6.3.m3.1.1.2.1b" xref="S4.F6.6.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.6.3.m3.1.1.2.4" xref="S4.F6.6.3.m3.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F6.6.3.m3.1.1.2.1c" xref="S4.F6.6.3.m3.1.1.2.1.cmml">â€‹</mo><mi id="S4.F6.6.3.m3.1.1.2.5" xref="S4.F6.6.3.m3.1.1.2.5.cmml">d</mi></mrow><mo id="S4.F6.6.3.m3.1.1.1" xref="S4.F6.6.3.m3.1.1.1.cmml">=</mo><mn id="S4.F6.6.3.m3.1.1.3" xref="S4.F6.6.3.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.6.3.m3.1c"><apply id="S4.F6.6.3.m3.1.1.cmml" xref="S4.F6.6.3.m3.1.1"><eq id="S4.F6.6.3.m3.1.1.1.cmml" xref="S4.F6.6.3.m3.1.1.1"></eq><apply id="S4.F6.6.3.m3.1.1.2.cmml" xref="S4.F6.6.3.m3.1.1.2"><times id="S4.F6.6.3.m3.1.1.2.1.cmml" xref="S4.F6.6.3.m3.1.1.2.1"></times><ci id="S4.F6.6.3.m3.1.1.2.2.cmml" xref="S4.F6.6.3.m3.1.1.2.2">ğ‘›</ci><ci id="S4.F6.6.3.m3.1.1.2.3.cmml" xref="S4.F6.6.3.m3.1.1.2.3">ğ‘–</ci><ci id="S4.F6.6.3.m3.1.1.2.4.cmml" xref="S4.F6.6.3.m3.1.1.2.4">ğ‘–</ci><ci id="S4.F6.6.3.m3.1.1.2.5.cmml" xref="S4.F6.6.3.m3.1.1.2.5">ğ‘‘</ci></apply><cn type="integer" id="S4.F6.6.3.m3.1.1.3.cmml" xref="S4.F6.6.3.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.6.3.m3.1d">niid=5</annotation></semantics></math>). The number of uniquely held labels by individual agents increases at the niid_factor increases, with IID being the most evenly balanced configuration.</span></figcaption>
</figure>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Datasets</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.3" class="ltx_p">We discussed the design of the <span id="S4.SS1.SSS1.p1.3.1" class="ltx_text ltx_font_italic">datamodules</span> in Section <a href="#S3.SS1" title="3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> and listed all of our dataset offerings in Table <a href="#S3.T1" title="Table 1 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In this section, we demonstrate the usage of <span id="S4.SS1.SSS1.p1.3.2" class="ltx_text ltx_font_italic">TorchFL</span> to promptly set up the CIFAR-10 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and present some visualizations to explain the results. For background, CIFAR-10 is one of the most extensively used datasets in academia given the dimensions and number of total images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. It consists of 60000 32<math id="S4.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.SSS1.p1.1.m1.1a"><mo id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b"><times id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">\times</annotation></semantics></math>32 color images in 10 classes containing 6000 images each, which are evenly split into 5000 training images and 1000 testing images per class. This means that the dataset consists of 50000 training images and 10000 testing images in total. Each label in the CIFAR-10 dataset can be identified using a unique integer in the range <math id="S4.SS1.SSS1.p1.2.m2.2" class="ltx_Math" alttext="[0,9]" display="inline"><semantics id="S4.SS1.SSS1.p1.2.m2.2a"><mrow id="S4.SS1.SSS1.p1.2.m2.2.3.2" xref="S4.SS1.SSS1.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.SSS1.p1.2.m2.2.3.2.1" xref="S4.SS1.SSS1.p1.2.m2.2.3.1.cmml">[</mo><mn id="S4.SS1.SSS1.p1.2.m2.1.1" xref="S4.SS1.SSS1.p1.2.m2.1.1.cmml">0</mn><mo id="S4.SS1.SSS1.p1.2.m2.2.3.2.2" xref="S4.SS1.SSS1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS1.SSS1.p1.2.m2.2.2" xref="S4.SS1.SSS1.p1.2.m2.2.2.cmml">9</mn><mo stretchy="false" id="S4.SS1.SSS1.p1.2.m2.2.3.2.3" xref="S4.SS1.SSS1.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.2.m2.2b"><interval closure="closed" id="S4.SS1.SSS1.p1.2.m2.2.3.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.2.3.2"><cn type="integer" id="S4.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1">0</cn><cn type="integer" id="S4.SS1.SSS1.p1.2.m2.2.2.cmml" xref="S4.SS1.SSS1.p1.2.m2.2.2">9</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.2.m2.2c">[0,9]</annotation></semantics></math>. For the first experiment, we split the CIFAR-10 training data between <math id="S4.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS1.SSS1.p1.3.m3.1a"><mn id="S4.SS1.SSS1.p1.3.m3.1.1" xref="S4.SS1.SSS1.p1.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.3.m3.1b"><cn type="integer" id="S4.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.3.m3.1c">5</annotation></semantics></math> agents, split them using IID and various non-IID configurations provided by <span id="S4.SS1.SSS1.p1.3.3" class="ltx_text ltx_font_italic">TorchFL</span>â€™s datamodule, and visually represent the results in Figure <a href="#S4.F6" title="Figure 6 â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p">All of the datasets-related results shown on the CIFAR-10 dataset with <math id="S4.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS1.SSS1.p2.1.m1.1a"><mn id="S4.SS1.SSS1.p2.1.m1.1.1" xref="S4.SS1.SSS1.p2.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p2.1.m1.1b"><cn type="integer" id="S4.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p2.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p2.1.m1.1c">5</annotation></semantics></math> agents would apply to systems consisting of more agents, or training larger or more complex datasets with more unique labels. Good examples of such datasets are CIFAR-100 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> with 100 labels, or even ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> with 1000 labels. We chose to first demonstrate the results on a smaller experiment configuration to provide more granular visualizations.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Models</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">We discussed the design of <span id="S4.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s <span id="S4.SS1.SSS2.p1.1.2" class="ltx_text ltx_font_italic">models</span> in Section <a href="#S3.SS1" title="3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> and listed all of our DL model offerings in Table <a href="#S3.T2" title="Table 2 â€£ item 1 â€£ 3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We also discussed the concepts of feature extraction and finetuning in transfer learning to help the models quickly achieve global convergence. In this subsection, we utilize <span id="S4.SS1.SSS2.p1.1.3" class="ltx_text ltx_font_italic">TorchFl</span> <span id="S4.SS1.SSS2.p1.1.4" class="ltx_text ltx_font_italic">model</span> module to quickly bootstrap various state-of-the-art DL models and provide results to demonstrate the benefits of transfer learning paradigms.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">For this set of experiments, we train ResNet152, which is one of the variants of the deep residual networks for image recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. In summary, ResNets are a variant of convolutional neural networks (CNN) that democratized the concepts of residual learning and skip connections to enable the training of much deeper models. The model will be trained on the CIFAR-10 dataset, and we experiment on the following settings - (i) training the model from scratch using randomly initialized weights, (ii) finetuning the model which is initialized using the weights pre-trained on the ImageNet dataset, and (iii) feature-extraction, i.e. retraining the classification layers of the model while reusing the pre-trained weights for other layers.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.3.2" class="ltx_text" style="font-size:90%;">Distribution of the trainable, non-trainable, total parameters, and training time in seconds (per epoch) when ResNet152 is trained on CIFAR-10 using an NVIDIA Tesla T4 GPU.</span></figcaption>
<br class="ltx_break">
<table id="S4.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.4.1.1" class="ltx_tr">
<th id="S4.T3.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Setting</span></th>
<th id="S4.T3.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.4.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Train. Param.</span></th>
<th id="S4.T3.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.4.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Non-Train. Param.</span></th>
<th id="S4.T3.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.4.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Total Param.</span></th>
<th id="S4.T3.4.1.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.4.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Train. Time</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.4.2.1" class="ltx_tr">
<td id="S4.T3.4.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.4.2.1.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Scratch</span></td>
<td id="S4.T3.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.2.1.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">58.2M</span></td>
<td id="S4.T3.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.2.1.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">0</span></td>
<td id="S4.T3.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.2.1.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">58.2M</span></td>
<td id="S4.T3.4.2.1.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T3.4.2.1.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">1405s</span></td>
</tr>
<tr id="S4.T3.4.3.2" class="ltx_tr">
<td id="S4.T3.4.3.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.4.3.2.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Finetune</span></td>
<td id="S4.T3.4.3.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.3.2.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">58.2M</span></td>
<td id="S4.T3.4.3.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.3.2.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">0</span></td>
<td id="S4.T3.4.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.3.2.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">58.2M</span></td>
<td id="S4.T3.4.3.2.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T3.4.3.2.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">1380s</span></td>
</tr>
<tr id="S4.T3.4.4.3" class="ltx_tr">
<td id="S4.T3.4.4.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S4.T3.4.4.3.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Feature. Extract</span></td>
<td id="S4.T3.4.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.4.4.3.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">20.5K</span></td>
<td id="S4.T3.4.4.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.4.4.3.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">58.1M</span></td>
<td id="S4.T3.4.4.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.4.4.3.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">58.2M</span></td>
<td id="S4.T3.4.4.3.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T3.4.4.3.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">408s</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/models/resnet_plot.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="274" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Comparing the validation accuracy and CrossEntropy loss for CIFAR-10 dataset when ResNet152 was trained from scratch, finetuned, and feature-extracted. The comparison between the training time and parameters can be found in Table <a href="#S4.T3" title="Table 3 â€£ 4.1.2 Models â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</span></figcaption>
</figure>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/fl/merged_fl.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="164" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.8.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.9.2" class="ltx_text" style="font-size:90%;">CrossEntropy loss and validation accuracy for the global model when FL experiments are trained with various data distributions and setup using <span id="S4.F8.9.2.1" class="ltx_text ltx_font_italic">TorchFL</span>. (i) 100 agents, 10% randomly sampled for training, 50 global epochs, 5 local epochs, <span id="S4.F8.9.2.2" class="ltx_text ltx_font_italic">FedAvg</span> aggregation, <span id="S4.F8.9.2.3" class="ltx_text ltx_font_italic">LeNet-5</span> used as a global and local model, (ii) 10 agents, 50% randomly sampled for training, 10 global epochs, 2 local epochs, aggregated using <span id="S4.F8.9.2.4" class="ltx_text ltx_font_italic">FedAvg</span>, <span id="S4.F8.9.2.5" class="ltx_text ltx_font_italic">feature-extracted</span> <span id="S4.F8.9.2.6" class="ltx_text ltx_font_italic">MobileNetV3Small</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> used as a global and local model.</span></figcaption>
</figure>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<p id="S4.SS1.SSS2.p3.1" class="ltx_p">Again, no additional code was written to set up each of these experiments. In fact, we were able to pass the hyperparameters configuration via <span id="S4.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s <span id="S4.SS1.SSS2.p3.1.2" class="ltx_text ltx_font_italic">model</span> object and the setup was abstracted under the hood. Before we look at the experimental results, it is worth understanding the primary reason behind the differences in training time and resource utilization between each of these settings. ResNet152 being a massive model, Table <a href="#S4.T3" title="Table 3 â€£ 4.1.2 Models â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the number of the total, trainable, non-trainable parameters, and training time in seconds (per epoch) when we use either of these training paradigms. We can clearly see how the training time for the feature-extracted model drastically reduces as the number of trainable parameters decrease. As explained in Section <a href="#S3.SS1" title="3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, the finetuning technique still requires retraining of all the parameters, which means, the training time per epoch is the same as training from scratch. However, as the weights from pre-trained models are used (instead of random initialization), we expect to achieve convergence with a lesser number of epochs, which leads to a decrease in overall training time. The plot in Figure <a href="#S4.F7" title="Figure 7 â€£ 4.1.2 Models â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows how the validation accuracy and CrossEntropy loss for ResNet152 vary when trained for 10 epochs using different experimental settings. The plot clearly shows how finetuned and feature-extracted models start with a lower loss because of the pre-trained parameters. Notably, we only trained ResNet152 for 10 epochs as training an entire network on the ImageNet-1K dataset takes roughly more than 3 weeks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. For this work, our goal is to show how <span id="S4.SS1.SSS2.p3.1.3" class="ltx_text ltx_font_italic">TorchFL</span> is capable of bootstrapping a model as complicated as ResNet152 and also demonstrate its correctness through the reduction in CrossEntropy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> loss as shown in Figure <a href="#S4.F7" title="Figure 7 â€£ 4.1.2 Models â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="S4.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2211.00735/assets/experiments/fl/indi_agent_plot.png" id="S4.F9.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="419" height="274" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.4.2.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S4.F9.2.1" class="ltx_text" style="font-size:90%;">Visualizing the CrossEntropy loss and training accuracy of a randomly selected agent (<math id="S4.F9.2.1.m1.1" class="ltx_Math" alttext="id=99" display="inline"><semantics id="S4.F9.2.1.m1.1b"><mrow id="S4.F9.2.1.m1.1.1" xref="S4.F9.2.1.m1.1.1.cmml"><mrow id="S4.F9.2.1.m1.1.1.2" xref="S4.F9.2.1.m1.1.1.2.cmml"><mi id="S4.F9.2.1.m1.1.1.2.2" xref="S4.F9.2.1.m1.1.1.2.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F9.2.1.m1.1.1.2.1" xref="S4.F9.2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S4.F9.2.1.m1.1.1.2.3" xref="S4.F9.2.1.m1.1.1.2.3.cmml">d</mi></mrow><mo id="S4.F9.2.1.m1.1.1.1" xref="S4.F9.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.F9.2.1.m1.1.1.3" xref="S4.F9.2.1.m1.1.1.3.cmml">99</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F9.2.1.m1.1c"><apply id="S4.F9.2.1.m1.1.1.cmml" xref="S4.F9.2.1.m1.1.1"><eq id="S4.F9.2.1.m1.1.1.1.cmml" xref="S4.F9.2.1.m1.1.1.1"></eq><apply id="S4.F9.2.1.m1.1.1.2.cmml" xref="S4.F9.2.1.m1.1.1.2"><times id="S4.F9.2.1.m1.1.1.2.1.cmml" xref="S4.F9.2.1.m1.1.1.2.1"></times><ci id="S4.F9.2.1.m1.1.1.2.2.cmml" xref="S4.F9.2.1.m1.1.1.2.2">ğ‘–</ci><ci id="S4.F9.2.1.m1.1.1.2.3.cmml" xref="S4.F9.2.1.m1.1.1.2.3">ğ‘‘</ci></apply><cn type="integer" id="S4.F9.2.1.m1.1.1.3.cmml" xref="S4.F9.2.1.m1.1.1.3">99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F9.2.1.m1.1d">id=99</annotation></semantics></math>) during the local training when they were selected for training in three different federated global epochs (referred to as rounds in here)</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.F9.5" class="ltx_p ltx_figure_panel ltx_align_center">.</p>
</div>
</div>
</figure>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Federated Learning</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">We discussed the design of the federated module in <span id="S4.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> in Section <a href="#S3.SS2" title="3.2 Federated Module â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> and saw how the decoupled implementation of <span id="S4.SS1.SSS3.p1.1.2" class="ltx_text ltx_font_italic">agent</span>, <span id="S4.SS1.SSS3.p1.1.3" class="ltx_text ltx_font_italic">sampler</span>, and <span id="S4.SS1.SSS3.p1.1.4" class="ltx_text ltx_font_italic">aggregator</span> are used to provide an <span id="S4.SS1.SSS3.p1.1.5" class="ltx_text ltx_font_italic">entrypoint</span> object which is eventually used by the developer. In the previous subsections, we saw how <span id="S4.SS1.SSS3.p1.1.6" class="ltx_text ltx_font_italic">TorchFL</span> provides various abstractions around datasets and models. In this section, we will demonstrate an end-to-end FL experiment that utilizes the <span id="S4.SS1.SSS3.p1.1.7" class="ltx_text ltx_font_italic">datamodule</span>, <span id="S4.SS1.SSS3.p1.1.8" class="ltx_text ltx_font_italic">model</span>, <span id="S4.SS1.SSS3.p1.1.9" class="ltx_text ltx_font_italic">sampler</span>, and <span id="S4.SS1.SSS3.p1.1.10" class="ltx_text ltx_font_italic">aggregator</span> to train a global model.</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<p id="S4.SS1.SSS3.p2.1" class="ltx_p">For this set of experiments, we will use an MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, a database of handwritten digits. It has a training set of 60000 images and a test set of 10000 images. The images are single-channel, B&amp;W images, with the digits being size-normalized and centered. We choose MNIST over any other dataset for this experiment, as it is relatively easier to achieve convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> using a simple CNN like LeNet-5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. We used <span id="S4.SS1.SSS3.p2.1.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s datamodules, models, and FL modules to generate an <span id="S4.SS1.SSS3.p2.1.2" class="ltx_text ltx_font_italic">entrypoint</span> object, which was used to abstract and generate all the experiments. We primarily aimed to demonstrate FL from scratch and federated transfer learning using different FL configurations. As seen in Figure <a href="#S4.F8" title="Figure 8 â€£ 4.1.2 Models â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, the trend in the accuracy-loss curves clearly demonstrates learning. Further, we also clearly notice the impact of non-IID data on model convergence. The second plot in Figure <a href="#S4.F8" title="Figure 8 â€£ 4.1.2 Models â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the accuracy-loss trend for the federated transfer learning setup mentioned before. Again, there are multiple combinations of FL parameters that can be used for these experiments and would give us different results. However, our goal is to maximize the number of features used in the demo and hence we limit our experiments such that we can demonstrate FL training from scratch and also via transfer learning respectively.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Leveraging PyTorch Lightning Features</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In Section <a href="#S3.SS3" title="3.3 Backward Compatibility with PyTorch Lightning â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> we discussed various benefits provided by the PyTorch Lightning compatibility through various modules in the library. In this section, we present various ways in which we can use the Lightning profilers and loggers to generate meaningful metrics without any implementation or performance overhead.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Granular Metrics for Individual Agents</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Collecting granular training and hardware metrics for individual agents, over multiple local and glocal epochs can be tedious and compute inefficient especially while running a massive FL experiment. <span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s federated modules compatibility with Lightning loggers automatically logs the training metrics, sampling counts, parameters, device stats, etc. to the configured loggers. Figure <a href="#S4.F9" title="Figure 9 â€£ 4.1.2 Models â€£ 4.1 Usage &amp; Demo â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows how <span id="S4.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> was able to automatically collect the local training metrics of a randomly selected agent, every time they were selected for training.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Pinpointing the Bottlenecks Using Profilers</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The modules in <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> being backward compatible with the Lightning profilers, Table <a href="#S4.T4" title="Table 4 â€£ 4.2.2 Pinpointing the Bottlenecks Using Profilers â€£ 4.2 Leveraging PyTorch Lightning Features â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents a sample profiling result that was generated while training LeNet-5 on the MNIST dataset. Note that the results were generated using a <span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">SimpleProfiler</span> object which only monitors the time for core components. Granular details about the system calls and the bottlenecks can be found using an advanced cProfiler.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.14.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.15.2" class="ltx_text" style="font-size:90%;">Results generated by a <span id="S4.T4.15.2.1" class="ltx_text ltx_font_italic">SimpleProfiler</span> while training LeNet-5 on the MNIST dataset. Only the truncated results have been shown here but more granular results about each of these calls can be achieved via an advanced cProfiler.</span></figcaption>
<br class="ltx_break">
<table id="S4.T4.11.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.11.11.12.1" class="ltx_tr">
<th id="S4.T4.11.11.12.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.11.11.12.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Action</span></th>
<th id="S4.T4.11.11.12.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.11.11.12.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Mean Dur.(s)</span></th>
<th id="S4.T4.11.11.12.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.11.11.12.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Num Calls</span></th>
<th id="S4.T4.11.11.12.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.11.11.12.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Total(s)</span></th>
<th id="S4.T4.11.11.12.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.11.11.12.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Percent.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.3.3.3" class="ltx_tr">
<td id="S4.T4.3.3.3.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.3.3.3.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Total Run</span></td>
<td id="S4.T4.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.3.3.3.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">-</span></td>
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.1.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="55.7" display="inline"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mn id="S4.T4.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">55.7</mn><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><cn type="float" id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">55.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">55.7</annotation></semantics></math>K</span></td>
<td id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.2.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="36.191" display="inline"><semantics id="S4.T4.2.2.2.2.1.m1.1a"><mn id="S4.T4.2.2.2.2.1.m1.1.1" xref="S4.T4.2.2.2.2.1.m1.1.1.cmml">36.191</mn><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.1.m1.1b"><cn type="float" id="S4.T4.2.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1">36.191</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.1.m1.1c">36.191</annotation></semantics></math></span></td>
<td id="S4.T4.3.3.3.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T4.3.3.3.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.3.3.3.3.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.T4.3.3.3.3.1.m1.1a"><mn id="S4.T4.3.3.3.3.1.m1.1.1" xref="S4.T4.3.3.3.3.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.3.1.m1.1b"><cn type="integer" id="S4.T4.3.3.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.3.3.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.3.1.m1.1c">100</annotation></semantics></math></span></td>
</tr>
<tr id="S4.T4.11.11.13.1" class="ltx_tr">
<td id="S4.T4.11.11.13.1.1" class="ltx_td ltx_align_left"><span id="S4.T4.11.11.13.1.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">â€¦</span></td>
<td id="S4.T4.11.11.13.1.2" class="ltx_td ltx_align_center"><span id="S4.T4.11.11.13.1.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">â€¦</span></td>
<td id="S4.T4.11.11.13.1.3" class="ltx_td ltx_align_center"><span id="S4.T4.11.11.13.1.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">â€¦</span></td>
<td id="S4.T4.11.11.13.1.4" class="ltx_td ltx_align_center"><span id="S4.T4.11.11.13.1.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">â€¦</span></td>
<td id="S4.T4.11.11.13.1.5" class="ltx_td ltx_align_right"><span id="S4.T4.11.11.13.1.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">â€¦</span></td>
</tr>
<tr id="S4.T4.7.7.7" class="ltx_tr">
<td id="S4.T4.7.7.7.5" class="ltx_td ltx_align_left"><span id="S4.T4.7.7.7.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">LR Sched.</span></td>
<td id="S4.T4.4.4.4.1" class="ltx_td ltx_align_center"><span id="S4.T4.4.4.4.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.4.4.4.1.1.m1.1" class="ltx_Math" alttext="0.0006" display="inline"><semantics id="S4.T4.4.4.4.1.1.m1.1a"><mn id="S4.T4.4.4.4.1.1.m1.1.1" xref="S4.T4.4.4.4.1.1.m1.1.1.cmml">0.0006</mn><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.1.1.m1.1b"><cn type="float" id="S4.T4.4.4.4.1.1.m1.1.1.cmml" xref="S4.T4.4.4.4.1.1.m1.1.1">0.0006</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.1.1.m1.1c">0.0006</annotation></semantics></math></span></td>
<td id="S4.T4.5.5.5.2" class="ltx_td ltx_align_center"><span id="S4.T4.5.5.5.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.5.5.5.2.1.m1.1" class="ltx_Math" alttext="844" display="inline"><semantics id="S4.T4.5.5.5.2.1.m1.1a"><mn id="S4.T4.5.5.5.2.1.m1.1.1" xref="S4.T4.5.5.5.2.1.m1.1.1.cmml">844</mn><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.2.1.m1.1b"><cn type="integer" id="S4.T4.5.5.5.2.1.m1.1.1.cmml" xref="S4.T4.5.5.5.2.1.m1.1.1">844</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.2.1.m1.1c">844</annotation></semantics></math></span></td>
<td id="S4.T4.6.6.6.3" class="ltx_td ltx_align_center"><span id="S4.T4.6.6.6.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.6.6.6.3.1.m1.1" class="ltx_Math" alttext="0.1748" display="inline"><semantics id="S4.T4.6.6.6.3.1.m1.1a"><mn id="S4.T4.6.6.6.3.1.m1.1.1" xref="S4.T4.6.6.6.3.1.m1.1.1.cmml">0.1748</mn><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.3.1.m1.1b"><cn type="float" id="S4.T4.6.6.6.3.1.m1.1.1.cmml" xref="S4.T4.6.6.6.3.1.m1.1.1">0.1748</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.3.1.m1.1c">0.1748</annotation></semantics></math></span></td>
<td id="S4.T4.7.7.7.4" class="ltx_td ltx_align_right"><span id="S4.T4.7.7.7.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.7.7.7.4.1.m1.1" class="ltx_Math" alttext="0.4748" display="inline"><semantics id="S4.T4.7.7.7.4.1.m1.1a"><mn id="S4.T4.7.7.7.4.1.m1.1.1" xref="S4.T4.7.7.7.4.1.m1.1.1.cmml">0.4748</mn><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.7.4.1.m1.1b"><cn type="float" id="S4.T4.7.7.7.4.1.m1.1.1.cmml" xref="S4.T4.7.7.7.4.1.m1.1.1">0.4748</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.7.4.1.m1.1c">0.4748</annotation></semantics></math></span></td>
</tr>
<tr id="S4.T4.11.11.11" class="ltx_tr">
<td id="S4.T4.11.11.11.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T4.11.11.11.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Opt. Grad.</span></td>
<td id="S4.T4.8.8.8.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.8.8.8.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.8.8.8.1.1.m1.1" class="ltx_Math" alttext="0.0008" display="inline"><semantics id="S4.T4.8.8.8.1.1.m1.1a"><mn id="S4.T4.8.8.8.1.1.m1.1.1" xref="S4.T4.8.8.8.1.1.m1.1.1.cmml">0.0008</mn><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.8.1.1.m1.1b"><cn type="float" id="S4.T4.8.8.8.1.1.m1.1.1.cmml" xref="S4.T4.8.8.8.1.1.m1.1.1">0.0008</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.8.1.1.m1.1c">0.0008</annotation></semantics></math></span></td>
<td id="S4.T4.9.9.9.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.9.9.9.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.9.9.9.2.1.m1.1" class="ltx_Math" alttext="844" display="inline"><semantics id="S4.T4.9.9.9.2.1.m1.1a"><mn id="S4.T4.9.9.9.2.1.m1.1.1" xref="S4.T4.9.9.9.2.1.m1.1.1.cmml">844</mn><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.9.2.1.m1.1b"><cn type="integer" id="S4.T4.9.9.9.2.1.m1.1.1.cmml" xref="S4.T4.9.9.9.2.1.m1.1.1">844</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.9.2.1.m1.1c">844</annotation></semantics></math></span></td>
<td id="S4.T4.10.10.10.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.10.10.10.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.10.10.10.3.1.m1.1" class="ltx_Math" alttext="0.7654" display="inline"><semantics id="S4.T4.10.10.10.3.1.m1.1a"><mn id="S4.T4.10.10.10.3.1.m1.1.1" xref="S4.T4.10.10.10.3.1.m1.1.1.cmml">0.7654</mn><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.10.3.1.m1.1b"><cn type="float" id="S4.T4.10.10.10.3.1.m1.1.1.cmml" xref="S4.T4.10.10.10.3.1.m1.1.1">0.7654</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.10.3.1.m1.1c">0.7654</annotation></semantics></math></span></td>
<td id="S4.T4.11.11.11.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T4.11.11.11.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;"><math id="S4.T4.11.11.11.4.1.m1.1" class="ltx_Math" alttext="2.1151" display="inline"><semantics id="S4.T4.11.11.11.4.1.m1.1a"><mn id="S4.T4.11.11.11.4.1.m1.1.1" xref="S4.T4.11.11.11.4.1.m1.1.1.cmml">2.1151</mn><annotation-xml encoding="MathML-Content" id="S4.T4.11.11.11.4.1.m1.1b"><cn type="float" id="S4.T4.11.11.11.4.1.m1.1.1.cmml" xref="S4.T4.11.11.11.4.1.m1.1.1">2.1151</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.11.11.4.1.m1.1c">2.1151</annotation></semantics></math></span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/bytes_usage.png" id="S4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="186" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S4.F10.3.2" class="ltx_text" style="font-size:90%;">The stacked area chart represents the distribution between the bytes allocated, bytes freed, and bytes used through the batches as we train LeNet-5 for 1 epoch on the MNIST dataset.</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Monitoring the Core Accelerator Resources</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">State-of-the-art DL models by themselves require significant memory usage, threads, and pools while training on a hardware accelerator (i.e. GPU). Especially, with FL experiments allocating multiple copies of models for individual agents, this usage is only expected to shoot upwards. As a result, <span id="S4.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s ability to monitor the hardware used for individual agent models provides significant value to the developers. Figure <a href="#S4.F10" title="Figure 10 â€£ 4.2.2 Pinpointing the Bottlenecks Using Profilers â€£ 4.2 Leveraging PyTorch Lightning Features â€£ 4 Experiments â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> is an example of how <span id="S4.SS2.SSS3.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> can monitor the memory usage on the hardware accelerator through the training process. Some other useful metrics recorded by <span id="S4.SS2.SSS3.p1.1.3" class="ltx_text ltx_font_italic">TorchFL</span> include thread pool allocation and thread usage within the individual pools.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we discuss, compare, and analyze various open-source toolkits in the FL space. The goal of this section is to provide a broad, high-level overview of tools available to the best of our knowledge, and analyze how they compare to <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>, or can even be used in tandem with <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Lately, a few open-source offerings have emerged in the FL space with one of the most promising ones being FedML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. With a multi-layer architecture, and beta offerings for iOS, Android, and IoT devices, FedML aims to provide a complete ecosystem to implement an end-to-end, real-world FL system. However, due to a lack of a standardized underlying framework (eg. PyTorch), setting up FL experiments on FedML still require overhead costs of implementing the models, datasets, and FL utilities that are compatible with the core API offering. On the other hand, with the features like models and dataset offerings, granular metric collection, and customizable interfaces, <span id="S5.p2.1.1" class="ltx_text ltx_font_italic">TorchFL</span> aims to solely optimize for the ease of bootstrapping the FL experiments and integrate state-of-the-art research (samplers, aggregators, etc.) with minimum overhead.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">LEAF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> is another promising framework that aims to open-source and benchmark suitable datasets for FL settings. A few of their notable dataset offerings include Reddit data for language modeling, Shakespeare manuscripts for next-character prediction, and more. We believe these datasets can be readily ported into a <span id="S5.p3.1.1" class="ltx_text ltx_font_italic">TorchFL</span> <span id="S5.p3.1.2" class="ltx_text ltx_font_italic">datamodule</span> interface and can readily be trained and tested with our DL model offerings.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Moreover, Tensorflow-Federated (TFF) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, PySyft <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, FATE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, FLUTE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, FedScale <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, and FLOWER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> are among the few other notable toolkits in the FL space. TFF has extensive support for various aggregation protocols, analytics, profiling, backends, and more, but itâ€™s built on top of Tensorflow and lacks standardized support for data modules as of yet. While PySyft is an actively-maintained and robust offering, their major contributions are ready-to-use algorithms for privacy-preserving techniques like differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> and encrypted computation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. PySyftâ€™s FL offering is the infrastructure to being able to set up privacy-aware agents and service providers as separate entities and able to develop custom PyTorch models, and aggregation protocols on top of it while ensuring private exchange of the computational structures, i.e. tensors. Next, FATE is a group of multiple FL frameworks that aim to let developers deploy their FL workflows on industrial-grade infrastructure and allow multiple organizations to potentially engage in the FL training process. In addition to their primary FL offering, they offer multiple tools for serving FL models on various environments and utilities for exchanging the data over the network. Lastly, FLUTEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> is another promising toolkit thatâ€™s built for PyTorch and aims to streamline the FL experiments and simulations. Itâ€™s meant to be configurable using YAML file format and still requires the developers to build their own PyTorch models.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations and Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This section contains a high-level overview of the plans of maintaining, improving, and refactoring <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> in the future. As mentioned before, <span id="S6.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> is a relatively new project with its own limitations and we plan to overcome them by open-sourcing the project and getting feedback from the community. As there are multiple directions in which this work can be extended, we restrict the scope of this discussion and attempt to summarize it in the following manner.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Exploring Performance Enhancements</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">As mentioned earlier in Section <a href="#S3.SS3" title="3.3 Backward Compatibility with PyTorch Lightning â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>, Lightning distributed training strategies can be used in <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> to reduce the training time if developers have access to multiple hardware accelerators. In addition, the recent release of PyTorch C++ API and the related tools (TorchScript, ATen, etc.) now allows developers to leverage Python and PyTorch to write custom kernels using CUDA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, that is backward compatible with the original PyTorch implementations. Once we ensure the stability of the current features and offerings, we are inclined to explore the possibilities of high-performance frontiers on <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span>.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Added Support for More Models and Datasets</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Currently, TorchFL only supports major datasets that are oriented toward solving image recognition, classification, or computer vision tasks in general. The models we support are also state-of-the-art models which are used to solve image recognition and segmentation tasks. However, the design and interfaces that we discussed in Section <a href="#S3.SS1" title="3.1 Datasets and Models Libraries â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, are backward compatible with a more diverse range of DL tasks including but not limited to natural language processing (NLP) or reinforcement learning (RL). As we plan to actively maintain <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>, we are considering adding a diverse range of datasets and model implementations in the future. Again, it would only require the developers to make the new offerings backward compatible with the <span id="S6.SS2.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> modules and it would automatically work with all the FL components.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Broader Range of FL Components</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">One of the primary motivations to design the federated modules as explained in Section <a href="#S3.SS2" title="3.2 Federated Module â€£ 3 Architecture of TorchFL â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> was to provide an easy-to-use interface to quickly prototype and validate the latest FL components. As the FL community is constantly innovating approaches toward sampling, agent incentivization, defense mechanisms, gradient/parameter encryption, and more, we plan to add those modules in addition to the samplers and aggregators that we currently support. In addition, we also aim to add more samplers and aggregator offerings which will serve as an example for the users who are willing to customize <span id="S6.SS3.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> for their experiments.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Benchmarking Against or Integrating with the Existing Toolkits</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">In the previous section, we recognized various toolkits and the meaningful related works in the FL experiments and simulation space. One of our future goals is to benchmark <span id="S6.SS4.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> against such toolkits in terms of performance, ease-of-use, models and datasets offerings, and more. As the DL community is making rapid progress, one of the major challenges is to keep up with state-of-the-art research, prototype the algorithm, and integrate it into the framework. As a result, one of our major goals is to get community feedback and support through our open-source offerings, and also focus on developer tooling and documentation which will hopefully make contributing to <span id="S6.SS4.p1.1.2" class="ltx_text ltx_font_italic">TorchFL</span> a lot easier. In addition to benchmarking, we believe that a lot of toolkits can also integrate and work with <span id="S6.SS4.p1.1.3" class="ltx_text ltx_font_italic">TorchFL</span> helping us to reduce the maintainable code. We are also open to focusing on such collaborations moving forward.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">tff [2018]</span>
<span class="ltx_bibblock">
TensorFlow Federated, 12 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://github.com/tensorflow/federated" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tensorflow/federated</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ardalan and Subbian [2022]</span>
<span class="ltx_bibblock">
Zaniar Ardalan and Vignesh Subbian.

</span>
<span class="ltx_bibblock">Transfer Learning Approaches for Neuroimaging Analysis: A Scoping
Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Frontiers in Artificial Intelligence</em>, 5, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beutel etÂ al. [2020]</span>
<span class="ltx_bibblock">
DanielÂ J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, and
NicholasÂ D Lane.

</span>
<span class="ltx_bibblock">Flower: A friendly federated learning research framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14390</em>, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas etÂ al. [2018]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai MeherÂ Karthik Duddu, Peter Wu, Tian Li, Jakub
KoneÄná»³, HÂ Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">LEAF: A Benchmark for Federated Settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen etÂ al. [2017]</span>
<span class="ltx_bibblock">
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre VanÂ Schaik.

</span>
<span class="ltx_bibblock">Emnist: Extending mnist to handwritten letters.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2017 international joint conference on neural networks
(IJCNN)</em>, pages 2921â€“2926. IEEE, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai and Berleant [2019]</span>
<span class="ltx_bibblock">
Wei Dai and Daniel Berleant.

</span>
<span class="ltx_bibblock">Benchmarking contemporary deep learning hardware and frameworks: A
survey of qualitative metrics.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">2019 IEEE First International Conference on Cognitive
Machine Intelligence (CogMI)</em>, pages 148â€“155. IEEE, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dehal etÂ al. [2018]</span>
<span class="ltx_bibblock">
RamandeepÂ Singh Dehal, Chirag Munjal, ArquishÂ Ali Ansari, and AnupÂ Singh
Kushwaha.

</span>
<span class="ltx_bibblock">GPU Computing Revolution: CUDA.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2018 International Conference on Advances in Computing,
Communication Control and Networking (ICACCCN)</em>, pages 197â€“201, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICACCCN.2018.8748495</span>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng etÂ al. [2009]</span>
<span class="ltx_bibblock">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and LiÂ Fei-Fei.

</span>
<span class="ltx_bibblock">ImageNet: A large-scale hierarchical image database.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">2009 IEEE Conference on Computer Vision and Pattern
Recognition</em>, pages 248â€“255, 2009.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPR.2009.5206848</span>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng [2012]</span>
<span class="ltx_bibblock">
LiÂ Deng.

</span>
<span class="ltx_bibblock">The MNIST database of handwritten digit images for machine learning
research.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>, 29(6):141â€“142, 2012.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong etÂ al. [2021]</span>
<span class="ltx_bibblock">
Shi Dong, Ping Wang, and Khushnood Abbas.

</span>
<span class="ltx_bibblock">A Survey on Deep Learning and its Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Computer Science Review</em>, 40:100379, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Falcon et al. [2019]</span>
<span class="ltx_bibblock">
William Falcon et al.

</span>
<span class="ltx_bibblock">PyTorch Lightning.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">GitHub. Note:
https://github.com/PyTorchLightning/pytorch-lightning</em>, 3, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garcia etÂ al. [2022]</span>
<span class="ltx_bibblock">
MirianÂ Hipolito Garcia, Andre Manoel, DanielÂ Madrigal Diaz, Fatemehsadat
Mireshghallah, Robert Sim, and Dimitrios Dimitriadis.

</span>
<span class="ltx_bibblock">Flute: A scalable, extensible framework for high-performance
federated learning simulations, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2203.13789" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2203.13789</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard etÂ al. [2018]</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, FranÃ§oise
Beaufays, Sean Augenstein, Hubert Eichner, ChloÃ© Kiddon, and Daniel Ramage.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/1811.03604" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1811.03604</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hassan etÂ al. [2019]</span>
<span class="ltx_bibblock">
MuneebÂ Ul Hassan, MubashirÂ Husain Rehmani, and Jinjun Chen.

</span>
<span class="ltx_bibblock">Differential privacy techniques for cyber physical systems: a
survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, 22(1):746â€“789, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. [2020]</span>
<span class="ltx_bibblock">
Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, MiÂ Zhang, Hongyi Wang, Xiaoyang
Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, etÂ al.

</span>
<span class="ltx_bibblock">FedML: A Research Library and Benchmark for Federated Machine
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. [2016]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 770â€“778, 2016.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Howard etÂ al. [2019]</span>
<span class="ltx_bibblock">
Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, BoÂ Chen, Mingxing
Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, etÂ al.

</span>
<span class="ltx_bibblock">Searching for MobilenetV3.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on
computer vision</em>, pages 1314â€“1324, 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji etÂ al. [2021]</span>
<span class="ltx_bibblock">
Shaoxiong Ji, Teemu Saravirta, Shirui Pan, Guodong Long, and Anwar Walid.

</span>
<span class="ltx_bibblock">Emerging Trends in Federated Learning: From Model Fusion to
Federated x Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.12920</em>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz etÂ al. [2021]</span>
<span class="ltx_bibblock">
Peter Kairouz, HÂ Brendan McMahan, Brendan Avent, AurÃ©lien Bellet, Mehdi
Bennis, ArjunÂ Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
Cormode, Rachel Cummings, etÂ al.

</span>
<span class="ltx_bibblock">Advances and Open Problems in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Foundations and TrendsÂ® in Machine Learning</em>,
14(1â€“2):1â€“210, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan etÂ al. [2021]</span>
<span class="ltx_bibblock">
LatifÂ U Khan, Walid Saad, Zhu Han, Ekram Hossain, and ChoongÂ Seon Hong.

</span>
<span class="ltx_bibblock">Federated learning for the Internet of things: Recent advances,
taxonomy, and open challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky [2009]</span>
<span class="ltx_bibblock">
Alex Krizhevsky.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">Technical report, 2009.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky etÂ al. [2009]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, etÂ al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar etÂ al. [2022]</span>
<span class="ltx_bibblock">
Abhishek Kumar, Vivek Khimani, Dimitris Chatzopoulos, and Pan Hui.

</span>
<span class="ltx_bibblock">FedClean: A Defense Mechanism against Parameter Poisoning Attacks in
Federated Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022 - 2022 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 4333â€“4337, 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICASSP43922.2022.9747497</span>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai etÂ al. [2021]</span>
<span class="ltx_bibblock">
Fan Lai, Yinwei Dai, SanjayÂ S. Singapuram, Jiachen Liu, Xiangfeng Zhu,
HarshaÂ V. Madhyastha, and Mosharaf Chowdhury.

</span>
<span class="ltx_bibblock">Fedscale: Benchmarking model and system performance of federated
learning at scale.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/ARXIV.2105.11367</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2105.11367" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2105.11367</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lecun etÂ al. [1998]</span>
<span class="ltx_bibblock">
Y.Â Lecun, L.Â Bottou, Y.Â Bengio, and P.Â Haffner.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 86(11):2278â€“2324, 1998.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/5.726791</span>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun [2019]</span>
<span class="ltx_bibblock">
Yann LeCun.

</span>
<span class="ltx_bibblock">1.1 Deep Learning Hardware: Past, Present, and Future.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International Solid-State Circuits Conference -
(ISSCC)</em>, pages 12â€“19, 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ISSCC.2019.8662396</span>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun etÂ al. [2015]</span>
<span class="ltx_bibblock">
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">nature</em>, 521(7553):436â€“444, 2015.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. [2021]</span>
<span class="ltx_bibblock">
Yang Liu, Tao Fan, Tianjian Chen, Qian Xu, and Qiang Yang.

</span>
<span class="ltx_bibblock">FATE: An Industrial Grade Platform for Collaborative Learning With
Data Protection.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 22(226):1â€“6, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marjani etÂ al. [2017]</span>
<span class="ltx_bibblock">
Mohsen Marjani, Fariza Nasaruddin, Abdullah Gani, Ahmad Karim, Ibrahim
AbakerÂ Targio Hashem, Aisha Siddiqa, and Ibrar Yaqoob.

</span>
<span class="ltx_bibblock">Big IoT Data Analytics: Architecture, Opportunities, and Open
Research Challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 5:5247â€“5261, 2017.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ACCESS.2017.2689040</span>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan etÂ al. [2017]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise AgueraÂ y
Arcas.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from Decentralized
Data.

</span>
<span class="ltx_bibblock">In Aarti Singh and Jerry Zhu, editors, <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th
International Conference on Artificial Intelligence and Statistics</em>,
volumeÂ 54 of <em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages
1273â€“1282. PMLR, 20â€“22 Apr 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mustapha etÂ al. [2020]</span>
<span class="ltx_bibblock">
Aatila Mustapha, Lachgar Mohamed, and Kartit Ali.

</span>
<span class="ltx_bibblock">An Overview of Gradient Descent Algorithm Optimization in Machine
Learning: Application in the Ophthalmology Field.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">International Conference on Smart Applications and Data
Analysis</em>, pages 349â€“359. Springer, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Obaid etÂ al. [2020]</span>
<span class="ltx_bibblock">
KaviÂ B Obaid, Subhi Zeebaree, OmarÂ M Ahmed, etÂ al.

</span>
<span class="ltx_bibblock">Deep Learning Models based on Image Classification: a review.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">International Journal of Science and Business</em>, 4(11):75â€“81, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pak and Kim [2017]</span>
<span class="ltx_bibblock">
Myeongsuk Pak and Sanghoon Kim.

</span>
<span class="ltx_bibblock">A Review of Deep Learning in Image Recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">2017 4th international conference on computer applications
and information processing technology (CAIPT)</em>, pages 1â€“3. IEEE, 2017.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryffel etÂ al. [2018]</span>
<span class="ltx_bibblock">
Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel
Rueckert, and Jonathan Passerat-Palmbach.

</span>
<span class="ltx_bibblock">A generic framework for privacy-preserving deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.04017</em>, 2018.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saleh etÂ al. [2016]</span>
<span class="ltx_bibblock">
Eyad Saleh, Ahmad Alsaâ€™deh, Ahmad Kayed, and Christoph Meinel.

</span>
<span class="ltx_bibblock">Processing over encrypted data: between theory and practice.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">ACM SIGMOD Record</em>, 45(3):5â€“16, 2016.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">StanÄin and JoviÄ‡ [2019]</span>
<span class="ltx_bibblock">
Igor StanÄin and Alan JoviÄ‡.

</span>
<span class="ltx_bibblock">An overview and comparison of free Python libraries for data mining
and big data analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">2019 42nd International Convention on Information and
Communication Technology, Electronics and Microelectronics (MIPRO)</em>, pages
977â€“982. IEEE, 2019.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vegh [2018]</span>
<span class="ltx_bibblock">
Laura Vegh.

</span>
<span class="ltx_bibblock">A Survey of Privacy and Security Issues for the Internet of Things
in the GDPR Era.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">2018 International Conference on Communications (COMM)</em>,
pages 453â€“458, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICComm.2018.8484769</span>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2016]</span>
<span class="ltx_bibblock">
Wei Wang, Meihui Zhang, Gang Chen, HVÂ Jagadish, BengÂ Chin Ooi, and Kian-Lee
Tan.

</span>
<span class="ltx_bibblock">Database meets deep learning: Challenges and opportunities.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">ACM SIGMOD Record</em>, 45(2):17â€“22, 2016.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao etÂ al. [2017]</span>
<span class="ltx_bibblock">
Han Xiao, Kashif Rasul, and Roland Vollgraf.

</span>
<span class="ltx_bibblock">Fashion-mnist: a novel image dataset for benchmarking machine
learning algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.07747</em>, 2017.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin etÂ al. [2021]</span>
<span class="ltx_bibblock">
Xuefei Yin, Yanming Zhu, and Jiankun Hu.

</span>
<span class="ltx_bibblock">A comprehensive survey of privacy-preserving federated learning: A
taxonomy, review, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, 54(6):1â€“36,
2021.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng etÂ al. [2021]</span>
<span class="ltx_bibblock">
Rongfei Zeng, Chao Zeng, Xingwei Wang, BoÂ Li, and Xiaowen Chu.

</span>
<span class="ltx_bibblock">A comprehensive survey of incentive mechanism for federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.15406</em>, 2021.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Sabuncu [2018]</span>
<span class="ltx_bibblock">
Zhilu Zhang and MertÂ R. Sabuncu.

</span>
<span class="ltx_bibblock">Generalized Cross Entropy Loss for Training Deep Neural Networks
with Noisy Labels.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd International Conference on Neural
Information Processing Systems</em>, NIPSâ€™18, page 8792â€“8802, Red Hook, NY,
USA, 2018. Curran Associates Inc.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang etÂ al. [2020]</span>
<span class="ltx_bibblock">
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui
Xiong, and Qing He.

</span>
<span class="ltx_bibblock">A comprehensive survey on transfer learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 109(1):43â€“76,
2020.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Code Snippets</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">This section will provide instructions and example code snippets for the users to get quickly started with <span id="A1.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>. First, it will provide an example to use the <span id="A1.p1.1.2" class="ltx_text ltx_font_italic">datamodules</span> and <span id="A1.p1.1.3" class="ltx_text ltx_font_italic">models</span>, and later, it will demonstrate how to build on top of those to bootstrap an FL experiment.</p>
</div>
<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Using Datasets &amp; Models</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">The following steps should be followed to bootstrap an experiment with EMNIST (MNIST) dataset and DenseNet121 model.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<ol id="A1.I1" class="ltx_enumerate">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p">Import the relevant modules as done in Figure <a href="#A1.F11" title="Figure 11 â€£ item 1 â€£ A.1 Using Datasets &amp; Models â€£ Appendix A Code Snippets â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<figure id="A1.F11" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/usage/usage_1.png" id="A1.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F11.3.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="A1.F11.4.2" class="ltx_text" style="font-size:90%;">Import the relevant <span id="A1.F11.4.2.1" class="ltx_text ltx_font_italic">TorchFL</span> and PyTorch Lightning modules to get started. For more details, view the full list of PyTorch Lightning <a target="_blank" href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/callbacks.html#callback" title="" class="ltx_ref ltx_href">callbacks</a> and <a target="_blank" href="https://pytorch-lightning.readthedocs.io/en/latest/api_references.html#loggers" title="" class="ltx_ref ltx_href">loggers</a>.</span></figcaption>
</figure>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p">Set up the PyTorch Lightning Trainer API object as done in Figure <a href="#A1.F12" title="Figure 12 â€£ item 2 â€£ A.1 Using Datasets &amp; Models â€£ Appendix A Code Snippets â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>.</p>
</div>
<figure id="A1.F12" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/usage/usage_2.png" id="A1.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="A1.F12.3.2" class="ltx_text" style="font-size:90%;">Set up the PyTorch Lightning Trainer object to initiate the training process. More details about the PyTorch Lightning <a target="_blank" href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html" title="" class="ltx_ref ltx_href">Trainer API</a> can be found on their official website.</span></figcaption>
</figure>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.1" class="ltx_p">Prepare the dataset and model using the wrappers provided by the <span id="A1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s <span id="A1.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">datamodules</span> and <span id="A1.I1.i3.p1.1.3" class="ltx_text ltx_font_italic">models</span> as shown in Figure <a href="#A1.F13" title="Figure 13 â€£ item 3 â€£ A.1 Using Datasets &amp; Models â€£ Appendix A Code Snippets â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>.</p>
</div>
<figure id="A1.F13" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/usage/usage_3.png" id="A1.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F13.5.1.1" class="ltx_text" style="font-size:90%;">Figure 13</span>: </span><span id="A1.F13.6.2" class="ltx_text" style="font-size:90%;">Prepare the dataset and model using <span id="A1.F13.6.2.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s <span id="A1.F13.6.2.2" class="ltx_text ltx_font_italic">datamodules</span> and <span id="A1.F13.6.2.3" class="ltx_text ltx_font_italic">models</span> wrappers.</span></figcaption>
</figure>
</li>
<li id="A1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A1.I1.i4.p1" class="ltx_para">
<p id="A1.I1.i4.p1.1" class="ltx_p">The corresponding files for the experiment (checkpoints, metadata, etc.) will be stored at the <span id="A1.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">default_root_dir</span> argument given to the PyTorch Lightning Trainer object in Step 2. For this experiment, we use the <a target="_blank" href="https://www.tensorflow.org/tensorboard" title="" class="ltx_ref ltx_href">Tensorboard</a> logger. To view the logs (and related plots and metrics), go to the <span id="A1.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">default_root_dir</span> path and find the Tensorboard log files. Upload the files to the Tensorboard Development portal following the instructions <a target="_blank" href="https://tensorboard.dev/#get-started" title="" class="ltx_ref ltx_href">here</a>. Note that, <span id="A1.I1.i4.p1.1.3" class="ltx_text ltx_font_italic">TorchFL</span> is compatible with all the loggers supported by PyTorch Lightning. More information about the Lightning loggers can be found <a target="_blank" href="https://tensorboard.dev/experiment/Q1tw19FySLSjLN6CW5DaUw/" title="" class="ltx_ref ltx_href">here</a>.</p>
</div>
</li>
<li id="A1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="A1.I1.i5.p1" class="ltx_para">
<p id="A1.I1.i5.p1.1" class="ltx_p">More example scripts with various models and datasets can be found <a target="_blank" href="https://github.com/vivekkhimani/torchfl/tree/master/examples/trainers" title="" class="ltx_ref ltx_href">here</a>.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Federated Learning</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">Using the previously set up dataset and models, an FL experiment can be set up in the following manner.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para">
<ol id="A1.I2" class="ltx_enumerate">
<li id="A1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A1.I2.i1.p1" class="ltx_para">
<p id="A1.I2.i1.p1.1" class="ltx_p">Use the dataset generated by <span id="A1.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span>â€™s <span id="A1.I2.i1.p1.1.2" class="ltx_text ltx_font_italic">datamodules</span> to create federated data shards with IID or non-IID distribution as shown in Figure <a href="#A1.F14" title="Figure 14 â€£ item 1 â€£ A.2 Federated Learning â€£ Appendix A Code Snippets â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>.</p>
</div>
<figure id="A1.F14" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/usage/usage_4.png" id="A1.F14.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="139" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F14.2.1.1" class="ltx_text" style="font-size:90%;">Figure 14</span>: </span><span id="A1.F14.3.2" class="ltx_text" style="font-size:90%;">Create the data shards for the agents using the previously initialized dataset and model.</span></figcaption>
</figure>
</li>
<li id="A1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A1.I2.i2.p1" class="ltx_para">
<p id="A1.I2.i2.p1.1" class="ltx_p">Initialize a global model, and agents, and distribute the global model parameters to every agent as shown in Figure <a href="#A1.F15" title="Figure 15 â€£ item 2 â€£ A.2 Federated Learning â€£ Appendix A Code Snippets â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a>.</p>
</div>
<figure id="A1.F15" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/usage/usage_5.png" id="A1.F15.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="317" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F15.2.1.1" class="ltx_text" style="font-size:90%;">Figure 15</span>: </span><span id="A1.F15.3.2" class="ltx_text" style="font-size:90%;">Initialize a global model, and agents, and distribute the global model parameters to every agent.</span></figcaption>
</figure>
</li>
<li id="A1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A1.I2.i3.p1" class="ltx_para">
<p id="A1.I2.i3.p1.1" class="ltx_p">Initialize a <span id="A1.I2.i3.p1.1.1" class="ltx_text ltx_font_italic">TorchFL</span> <span id="A1.I2.i3.p1.1.2" class="ltx_text ltx_font_italic">FLParam</span> object with the desired FL hyperparameters and pass it on to the <span id="A1.I2.i3.p1.1.3" class="ltx_text ltx_font_italic">Entrypoint</span> object which will abstract the training as shown in Figure <a href="#A1.F16" title="Figure 16 â€£ item 3 â€£ A.2 Federated Learning â€£ Appendix A Code Snippets â€£ TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>.</p>
</div>
<figure id="A1.F16" class="ltx_figure"><img src="/html/2211.00735/assets/experiments/usage/usage_6.png" id="A1.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="182" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F16.5.1.1" class="ltx_text" style="font-size:90%;">Figure 16</span>: </span><span id="A1.F16.6.2" class="ltx_text" style="font-size:90%;">Initialize a <span id="A1.F16.6.2.1" class="ltx_text ltx_font_italic">TorchFL</span> <span id="A1.F16.6.2.2" class="ltx_text ltx_font_italic">FLParam</span> object with the desired FL hyperparameters and pass it on to the <span id="A1.F16.6.2.3" class="ltx_text ltx_font_italic">Entrypoint</span> object.</span></figcaption>
</figure>
</li>
<li id="A1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A1.I2.i4.p1" class="ltx_para">
<p id="A1.I2.i4.p1.1" class="ltx_p">More federated learning example scripts can be found <a target="_blank" href="https://github.com/vivekkhimani/torchfl/tree/master/examples/federated" title="" class="ltx_ref ltx_href">here</a>.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2211.00734" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2211.00735" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2211.00735">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2211.00735" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2211.00737" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 07:59:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
